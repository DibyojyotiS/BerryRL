copied Agent.py to .temp\2022-6-19 17-52-55/pyfiles-backup
copied debugging.py to .temp\2022-6-19 17-52-55/pyfiles-backup/agent_utils/debugging
copied debugging_utils.py to .temp\2022-6-19 17-52-55/pyfiles-backup/agent_utils/debugging
copied __init__.py to .temp\2022-6-19 17-52-55/pyfiles-backup/agent_utils/debugging

copied fubar.py to .temp\2022-6-19 17-52-55/pyfiles-backup/agent_utils/exploration_subroutines
copied random_exploration.py to .temp\2022-6-19 17-52-55/pyfiles-backup/agent_utils/exploration_subroutines
copied random_exploration_v1.py to .temp\2022-6-19 17-52-55/pyfiles-backup/agent_utils/exploration_subroutines
copied skipsteps.py to .temp\2022-6-19 17-52-55/pyfiles-backup/agent_utils/exploration_subroutines/utils
copied __init__.py to .temp\2022-6-19 17-52-55/pyfiles-backup/agent_utils/exploration_subroutines/utils

copied __init__.py to .temp\2022-6-19 17-52-55/pyfiles-backup/agent_utils/exploration_subroutines

copied patch_discovery.py to .temp\2022-6-19 17-52-55/pyfiles-backup/agent_utils/intrinsic_rewards
copied __init__.py to .temp\2022-6-19 17-52-55/pyfiles-backup/agent_utils/intrinsic_rewards

copied plots.py to .temp\2022-6-19 17-52-55/pyfiles-backup/agent_utils/misc
copied printing.py to .temp\2022-6-19 17-52-55/pyfiles-backup/agent_utils/misc
copied __init__.py to .temp\2022-6-19 17-52-55/pyfiles-backup/agent_utils/misc

copied make_net.py to .temp\2022-6-19 17-52-55/pyfiles-backup/agent_utils/nn_utils
copied __init__.py to .temp\2022-6-19 17-52-55/pyfiles-backup/agent_utils/nn_utils

copied berry_worth_function.py to .temp\2022-6-19 17-52-55/pyfiles-backup/agent_utils/state_utils
copied sectorized_states.py to .temp\2022-6-19 17-52-55/pyfiles-backup/agent_utils/state_utils
copied __init__.py to .temp\2022-6-19 17-52-55/pyfiles-backup/agent_utils/state_utils

copied __init__.py to .temp\2022-6-19 17-52-55/pyfiles-backup/agent_utils

copied ensemble.py to .temp\2022-6-19 17-52-55/pyfiles-backup
copied eval.py to .temp\2022-6-19 17-52-55/pyfiles-backup
copied train.py to .temp\2022-6-19 17-52-55/pyfiles-backup
copied utils.py to .temp\2022-6-19 17-52-55/pyfiles-backup/utils/copyfiles
copied __init__.py to .temp\2022-6-19 17-52-55/pyfiles-backup/utils/copyfiles

copied random_env.py to .temp\2022-6-19 17-52-55/pyfiles-backup/utils/env_generation
copied __init__.py to .temp\2022-6-19 17-52-55/pyfiles-backup/utils/env_generation

copied utils.py to .temp\2022-6-19 17-52-55/pyfiles-backup/utils/printing
copied __init__.py to .temp\2022-6-19 17-52-55/pyfiles-backup/utils/printing

copied env_picture.py to .temp\2022-6-19 17-52-55/pyfiles-backup/utils/visualization
copied graphs.py to .temp\2022-6-19 17-52-55/pyfiles-backup/utils/visualization
copied __init__.py to .temp\2022-6-19 17-52-55/pyfiles-backup/utils/visualization

copied __init__.py to .temp\2022-6-19 17-52-55/pyfiles-backup/utils


random_train_env
getBabyEnv :
	 logDir : .temp\2022-6-19 17-52-55
	 initial_juice : 0.5
	 end_on_boundary_hit : False
	 penalize_boundary_hit : False
	 allow_no_action : False
	 no_action_threshold : 0.7
	 add_exploration : True
	 field_size : (20000, 20000)
	 initial_pos_around_berry : True
	 nberries : 80
	 num_patches : 10
	 patch_size : (2600, 2600)
	 patch_with_agent_at_center : True
	 sampling_type : 0
	 seperation : 2400
	 show : False
	 spawn_radius : 100


Agent :
	 self : <Agent.Agent object at 0x00000213BCC15D48>
	 berryField : <BerryFieldEnv instance>
	 mode : train
	 angle : 45
	 persistence : 0.8
	 worth_offset : 0.05
	 noise : 0.01
	 nstep_transition : [1]
	 positive_emphasis : 0
	 skipStep : 10
	 reward_patch_discovery : True
	 add_exploration : True
	 time_memory_factor : 0.5
	 time_memory_exp : 1.0
	 time_memory_sizes : [50, 100, 200]
	 render : False
	 debug : False
	 debugDir : .temp
	 device : cuda


total-params:  2098
rewards scaled by 2/(berryField.REWARD_RATE*MAXSIZE)
rewards are clipped between 0 and 2
Exploration subroutine as an action
p_action: 7
Rewarding patch discovery
rewards scaled by 2/(berryField.REWARD_RATE*MAXSIZE)
rewards are clipped between 0 and 2
Exploration subroutine as an action
p_action: 5
Rewarding patch discovery
net(
  (feedforward): ModuleList(
    (0): Linear(in_features=41, out_features=32, bias=True)
    (1): LeakyReLU(negative_slope=0.1)
    (2): Linear(in_features=32, out_features=16, bias=True)
    (3): LeakyReLU(negative_slope=0.1)
  )
  (final_stage): ModuleList(
    (0): Linear(in_features=16, out_features=8, bias=True)
    (1): LeakyReLU(negative_slope=0.1)
  )
  (valueL): Linear(in_features=8, out_features=1, bias=True)
  (actadvs): Linear(in_features=8, out_features=9, bias=True)
)
PrioritizedBuffer of type replace-min
optim = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005
    weight_decay: 0
), num_gradient_steps= 25
optimizing the online-model after every 100 actions
batch size=512, gamma=0.9, alpha=0.95
polyak_tau=0.1, update_freq=5

=== episode:0 Env-steps-taken:52320
 	picked: 14 |actions: {0: 142, 1: 121, 2: 147, 3: 929, 4: 149, 5: 336, 6: 134, 7: 124, 8: 340}
episode: 0/2000 -> reward: 23.197916666666664, steps:2422, time-taken: 0.88min, time-elasped: 0.88min
-> berries picked: 14 of 800 | patches-visited: [0, 1, 4, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 17 | amount-filled: 4.04%
	| action-stats:  [3, 4, 5, 8] [8, 2, 1, 6]
	| approx positives in sample 512: 41
	| approx action-dist in sample 512: [3, 4, 5, 8] [25, 4, 5, 7]
	Time taken saving stuff: 0.04s

=== episode:0 Env-steps-taken:49152
 	picked: 4 |actions: {0: 0, 1: 0, 2: 0, 3: 23, 4: 93, 5: 150, 6: 0, 7: 0, 8: 277}

==================================================
eval-episode: 0 -> reward: 6.270833333333334, steps: 543.0, wall-time: 18.82s
-> berries picked: 4 of 800 | patches-visited: [1, 3] | juice left:-0.00
==================================================


=== episode:1 Env-steps-taken:50208
 	picked: 7 |actions: {0: 100, 1: 103, 2: 107, 3: 312, 4: 317, 5: 262, 6: 148, 7: 120, 8: 433}
episode: 1/2000 -> reward: 11.098958333333334, steps:1902, time-taken: 0.85min, time-elasped: 2.05min
-> berries picked: 7 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 24 | amount-filled: 7.21%
	| action-stats:  [2, 3, 4, 5, 6, 8] [1, 8, 5, 3, 1, 6]
	| approx positives in sample 512: 43
	| approx action-dist in sample 512: [2, 3, 4, 5, 6, 8] [4, 9, 13, 6, 1, 10]
	Time taken saving stuff: 0.00s

=== episode:2 Env-steps-taken:50112
 	picked: 7 |actions: {0: 132, 1: 130, 2: 192, 3: 351, 4: 143, 5: 258, 6: 254, 7: 576, 8: 341}
episode: 2/2000 -> reward: 11.098958333333336, steps:2377, time-taken: 0.89min, time-elasped: 2.93min
-> berries picked: 7 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 32 | amount-filled: 11.17%
	| action-stats:  [2, 3, 4, 5, 6, 7, 8] [3, 8, 8, 4, 1, 1, 7]
	| approx positives in sample 512: 24
	| approx action-dist in sample 512: [2, 3, 4, 5, 6, 7, 8] [3, 8, 3, 5, 2, 1, 2]
	Time taken saving stuff: 0.00s

=== episode:3 Env-steps-taken:53088
 	picked: 18 |actions: {0: 142, 1: 179, 2: 295, 3: 288, 4: 215, 5: 402, 6: 180, 7: 632, 8: 317}
episode: 3/2000 -> reward: 25.96875, steps:2650, time-taken: 1.02min, time-elasped: 3.95min
-> berries picked: 18 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 51 | amount-filled: 15.59%
	| action-stats:  [0, 2, 3, 4, 5, 6, 7, 8] [1, 4, 9, 13, 7, 2, 5, 10]
	| approx positives in sample 512: 24
	| approx action-dist in sample 512: [0, 2, 3, 4, 5, 7, 8] [1, 2, 4, 8, 1, 4, 4]
	Time taken saving stuff: 0.00s

=== episode:4 Env-steps-taken:55776
 	picked: 24 |actions: {0: 215, 1: 833, 2: 244, 3: 313, 4: 261, 5: 608, 6: 221, 7: 831, 8: 658}
episode: 4/2000 -> reward: 39.62500000000001, steps:4184, time-taken: 1.46min, time-elasped: 5.42min
-> berries picked: 24 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 76 | amount-filled: 22.56%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [2, 9, 6, 9, 16, 9, 2, 10, 13]
	| approx positives in sample 512: 38
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 7, 8] [9, 1, 2, 5, 6, 8, 7]
	Time taken saving stuff: 0.00s

=== episode:5 Env-steps-taken:52512
 	picked: 16 |actions: {0: 205, 1: 315, 2: 240, 3: 213, 4: 150, 5: 246, 6: 143, 7: 569, 8: 434}
episode: 5/2000 -> reward: 22.583333333333336, steps:2515, time-taken: 1.04min, time-elasped: 6.46min
-> berries picked: 16 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 92 | amount-filled: 26.75%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 9, 6, 11, 17, 14, 4, 13, 15]
	| approx positives in sample 512: 34
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 4, 2, 1, 4, 5, 2, 8, 5]
	Time taken saving stuff: 0.00s

=== episode:6 Env-steps-taken:56736
 	picked: 29 |actions: {0: 771, 1: 638, 2: 356, 3: 449, 4: 317, 5: 484, 6: 448, 7: 818, 8: 877}
episode: 6/2000 -> reward: 43.83854166666669, steps:5158, time-taken: 1.86min, time-elasped: 8.32min
-> berries picked: 29 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 121 | amount-filled: 35.35%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 15, 9, 14, 19, 19, 9, 17, 15]
	| approx positives in sample 512: 37
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 6, 2, 2, 8, 6, 1, 6, 3]
	Time taken saving stuff: 0.00s

=== episode:7 Env-steps-taken:54144
 	picked: 23 |actions: {0: 480, 1: 561, 2: 276, 3: 307, 4: 283, 5: 389, 6: 464, 7: 565, 8: 571}
episode: 7/2000 -> reward: 31.182291666666654, steps:3896, time-taken: 1.30min, time-elasped: 9.62min
-> berries picked: 23 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 145 | amount-filled: 41.84%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 17, 10, 18, 23, 25, 11, 19, 18]
	| approx positives in sample 512: 38
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [2, 4, 2, 4, 6, 10, 1, 5, 4]
	Time taken saving stuff: 0.00s

=== episode:8 Env-steps-taken:52608
 	picked: 18 |actions: {0: 421, 1: 502, 2: 239, 3: 259, 4: 411, 5: 372, 6: 468, 7: 415, 8: 654}
episode: 8/2000 -> reward: 23.468749999999996, steps:3741, time-taken: 1.30min, time-elasped: 10.92min
-> berries picked: 18 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 164 | amount-filled: 48.08%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 23, 10, 20, 24, 30, 11, 22, 19]
	| approx positives in sample 512: 37
	| approx action-dist in sample 512: [0, 1, 3, 4, 5, 6, 7, 8] [4, 8, 4, 4, 2, 1, 9, 5]
	Time taken saving stuff: 0.00s

=== episode:9 Env-steps-taken:50112
 	picked: 7 |actions: {0: 264, 1: 686, 2: 458, 3: 239, 4: 640, 5: 238, 6: 345, 7: 670, 8: 480}
episode: 9/2000 -> reward: 10.598958333333332, steps:4020, time-taken: 1.34min, time-elasped: 12.27min
-> berries picked: 7 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 171 | amount-filled: 54.77%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 23, 10, 20, 25, 32, 12, 24, 20]
	| approx positives in sample 512: 32
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7, 8] [6, 5, 4, 6, 5, 2, 2, 2]
	Time taken saving stuff: 0.00s

=== episode:10 Env-steps-taken:50496
 	picked: 10 |actions: {0: 374, 1: 536, 2: 424, 3: 589, 4: 207, 5: 307, 6: 331, 7: 312, 8: 334}
episode: 10/2000 -> reward: 12.427083333333336, steps:3414, time-taken: 1.18min, time-elasped: 13.45min
-> berries picked: 10 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 181 | amount-filled: 60.47%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 23, 11, 23, 25, 35, 13, 25, 21]
	| approx positives in sample 512: 37
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [1, 7, 4, 4, 4, 6, 1, 4, 6]
	Time taken saving stuff: 0.05s

=== episode:1 Env-steps-taken:50208
 	picked: 8 |actions: {0: 124, 1: 1888, 2: 325, 3: 9, 4: 12, 5: 1831, 6: 314, 7: 61, 8: 1}

==================================================
eval-episode: 10 -> reward: 11.041666666666668, steps: 4565.0, wall-time: 33.52s
-> berries picked: 8 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:11 Env-steps-taken:49728
 	picked: 8 |actions: {0: 427, 1: 302, 2: 435, 3: 667, 4: 199, 5: 237, 6: 537, 7: 292, 8: 227}
episode: 11/2000 -> reward: 8.541666666666668, steps:3323, time-taken: 1.24min, time-elasped: 15.25min
-> berries picked: 8 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 189 | amount-filled: 66.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 23, 12, 24, 25, 36, 15, 26, 21]
	| approx positives in sample 512: 26
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7, 8] [6, 2, 4, 3, 4, 3, 3, 1]
	Time taken saving stuff: 0.00s

=== episode:12 Env-steps-taken:52800
 	picked: 17 |actions: {0: 462, 1: 586, 2: 550, 3: 551, 4: 376, 5: 312, 6: 488, 7: 343, 8: 321}
episode: 12/2000 -> reward: 24.52604166666667, steps:3989, time-taken: 1.36min, time-elasped: 16.62min
-> berries picked: 17 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 207 | amount-filled: 72.65%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 26, 12, 25, 30, 38, 19, 28, 22]
	| approx positives in sample 512: 26
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7, 8] [4, 4, 3, 4, 4, 2, 1, 4]
	Time taken saving stuff: 0.00s

=== episode:13 Env-steps-taken:53952
 	picked: 22 |actions: {0: 374, 1: 600, 2: 526, 3: 621, 4: 568, 5: 594, 6: 768, 7: 511, 8: 343}
episode: 13/2000 -> reward: 29.739583333333325, steps:4905, time-taken: 1.68min, time-elasped: 18.30min
-> berries picked: 22 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 229 | amount-filled: 80.83%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 28, 13, 31, 35, 43, 21, 29, 22]
	| approx positives in sample 512: 29
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 7] [3, 9, 1, 1, 7, 7, 1]
	Time taken saving stuff: 0.00s

=== episode:14 Env-steps-taken:52992
 	picked: 19 |actions: {0: 249, 1: 456, 2: 256, 3: 309, 4: 216, 5: 275, 6: 595, 7: 381, 8: 254}
episode: 14/2000 -> reward: 24.911458333333336, steps:2991, time-taken: 1.14min, time-elasped: 19.45min
-> berries picked: 19 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 248 | amount-filled: 85.81%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 30, 14, 33, 36, 51, 21, 32, 23]
	| approx positives in sample 512: 20
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 7] [2, 6, 1, 1, 3, 6, 1]
	Time taken saving stuff: 0.00s

=== episode:15 Env-steps-taken:52800
 	picked: 15 |actions: {0: 134, 1: 344, 2: 184, 3: 201, 4: 262, 5: 204, 6: 396, 7: 294, 8: 137}
episode: 15/2000 -> reward: 24.140625, steps:2156, time-taken: 0.88min, time-elasped: 20.33min
-> berries picked: 15 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 263 | amount-filled: 89.41%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 31, 15, 35, 36, 55, 22, 38, 23]
	| approx positives in sample 512: 23
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 7, 8] [4, 2, 2, 3, 4, 6, 2]
	Time taken saving stuff: 0.00s

=== episode:16 Env-steps-taken:55872
 	picked: 26 |actions: {0: 331, 1: 569, 2: 346, 3: 719, 4: 527, 5: 510, 6: 559, 7: 1171, 8: 348}
episode: 16/2000 -> reward: 39.51041666666667, steps:5080, time-taken: 1.72min, time-elasped: 22.05min
-> berries picked: 26 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 289 | amount-filled: 97.87%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 32, 16, 36, 39, 61, 25, 48, 23]
	| approx positives in sample 512: 19
	| approx action-dist in sample 512: [2, 3, 4, 5, 6, 7, 8] [1, 3, 5, 3, 2, 3, 2]
	Time taken saving stuff: 0.00s

=== episode:17 Env-steps-taken:64800
 	picked: 57 |actions: {0: 453, 1: 794, 2: 409, 3: 459, 4: 598, 5: 681, 6: 484, 7: 760, 8: 402}
episode: 17/2000 -> reward: 83.84895833333331, steps:5040, time-taken: 1.72min, time-elasped: 23.77min
-> berries picked: 57 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 344 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 37, 17, 39, 50, 78, 26, 59, 26]
	| approx positives in sample 512: 29
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [2, 5, 4, 3, 2, 7, 1, 4, 1]
	Time taken saving stuff: 0.00s

=== episode:18 Env-steps-taken:66240
 	picked: 66 |actions: {0: 520, 1: 755, 2: 450, 3: 612, 4: 911, 5: 1032, 6: 435, 7: 778, 8: 529}
episode: 18/2000 -> reward: 89.83333333333329, steps:6022, time-taken: 2.04min, time-elasped: 25.81min
-> berries picked: 66 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 405 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 43, 19, 43, 64, 100, 28, 65, 28]
	| approx positives in sample 512: 32
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [1, 3, 2, 5, 4, 4, 4, 7, 2]
	Time taken saving stuff: 0.01s

=== episode:19 Env-steps-taken:61440
 	picked: 47 |actions: {0: 417, 1: 715, 2: 344, 3: 600, 4: 466, 5: 758, 6: 399, 7: 669, 8: 316}
episode: 19/2000 -> reward: 67.8072916666667, steps:4684, time-taken: 1.63min, time-elasped: 27.44min
-> berries picked: 47 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 449 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 45, 21, 44, 70, 115, 31, 77, 29]
	| approx positives in sample 512: 38
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 4, 3, 4, 4, 11, 2, 9]
	Time taken saving stuff: 0.00s

=== episode:20 Env-steps-taken:59808
 	picked: 47 |actions: {0: 601, 1: 748, 2: 419, 3: 680, 4: 550, 5: 951, 6: 416, 7: 519, 8: 369}
episode: 20/2000 -> reward: 56.92187500000005, steps:5253, time-taken: 1.67min, time-elasped: 29.11min
-> berries picked: 47 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 485 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 52, 21, 46, 75, 127, 33, 83, 29]
	| approx positives in sample 512: 33
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 5, 1, 4, 2, 6, 2, 4, 3]
	Time taken saving stuff: 0.05s

=== episode:2 Env-steps-taken:64320
 	picked: 55 |actions: {0: 215, 1: 1675, 2: 181, 3: 640, 4: 80, 5: 1455, 6: 384, 7: 466, 8: 155}

==================================================
eval-episode: 20 -> reward: 82.34895833333331, steps: 5251.0, wall-time: 34.53s
-> berries picked: 55 of 800 | patches-visited: [1, 6] | juice left:-0.00
==================================================


=== episode:21 Env-steps-taken:57024
 	picked: 32 |actions: {0: 419, 1: 500, 2: 302, 3: 922, 4: 360, 5: 492, 6: 298, 7: 370, 8: 520}
episode: 21/2000 -> reward: 45.16666666666669, steps:4183, time-taken: 1.49min, time-elasped: 31.19min
-> berries picked: 32 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 510 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 57, 21, 47, 82, 131, 34, 85, 31]
	| approx positives in sample 512: 38
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7, 8] [3, 4, 3, 2, 7, 4, 12, 3]
	Time taken saving stuff: 0.11s

=== episode:22 Env-steps-taken:59904
 	picked: 44 |actions: {0: 558, 1: 624, 2: 326, 3: 564, 4: 447, 5: 550, 6: 312, 7: 434, 8: 478}
episode: 22/2000 -> reward: 59.593750000000036, steps:4293, time-taken: 1.43min, time-elasped: 32.62min
-> berries picked: 44 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 552 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [25, 64, 21, 50, 88, 142, 36, 92, 34]
	| approx positives in sample 512: 48
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7, 8] [8, 4, 1, 8, 11, 5, 9, 2]
	Time taken saving stuff: 0.00s

=== episode:23 Env-steps-taken:59712
 	picked: 44 |actions: {0: 484, 1: 872, 2: 352, 3: 447, 4: 340, 5: 999, 6: 601, 7: 671, 8: 663}
episode: 23/2000 -> reward: 58.47916666666671, steps:5429, time-taken: 1.80min, time-elasped: 34.42min
-> berries picked: 44 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 590 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [26, 70, 23, 52, 90, 153, 38, 102, 36]
	| approx positives in sample 512: 39
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 3, 4, 5, 4, 8, 1, 12]
	Time taken saving stuff: 0.02s

=== episode:24 Env-steps-taken:66240
 	picked: 67 |actions: {0: 565, 1: 493, 2: 353, 3: 504, 4: 528, 5: 994, 6: 709, 7: 570, 8: 775}
episode: 24/2000 -> reward: 91.16145833333326, steps:5491, time-taken: 1.78min, time-elasped: 36.20min
-> berries picked: 67 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 650 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [32, 78, 25, 53, 97, 168, 51, 107, 39]
	| approx positives in sample 512: 51
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [1, 11, 4, 5, 2, 11, 3, 12, 2]
	Time taken saving stuff: 0.00s

=== episode:25 Env-steps-taken:63360
 	picked: 55 |actions: {0: 610, 1: 576, 2: 391, 3: 495, 4: 371, 5: 675, 6: 438, 7: 415, 8: 567}
episode: 25/2000 -> reward: 77.34895833333334, steps:4538, time-taken: 1.59min, time-elasped: 37.80min
-> berries picked: 55 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 704 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [36, 87, 26, 56, 105, 181, 59, 112, 42]
	| approx positives in sample 512: 40
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 5, 1, 2, 4, 8, 2, 10, 1]
	Time taken saving stuff: 0.10s

=== episode:26 Env-steps-taken:64416
 	picked: 61 |actions: {0: 672, 1: 600, 2: 530, 3: 434, 4: 446, 5: 637, 6: 588, 7: 382, 8: 608}
episode: 26/2000 -> reward: 82.50520833333331, steps:4897, time-taken: 1.64min, time-elasped: 39.44min
-> berries picked: 61 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 763 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [44, 94, 27, 59, 116, 195, 69, 115, 44]
	| approx positives in sample 512: 57
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 3, 2, 3, 9, 15, 2, 12, 4]
	Time taken saving stuff: 0.00s

=== episode:27 Env-steps-taken:60288
 	picked: 48 |actions: {0: 432, 1: 397, 2: 705, 3: 345, 4: 422, 5: 598, 6: 634, 7: 332, 8: 536}
episode: 27/2000 -> reward: 61.75000000000004, steps:4401, time-taken: 1.52min, time-elasped: 40.97min
-> berries picked: 48 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 803 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [47, 102, 28, 59, 124, 206, 74, 117, 46]
	| approx positives in sample 512: 56
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [1, 5, 1, 4, 6, 13, 9, 13, 4]
	Time taken saving stuff: 0.11s

=== episode:28 Env-steps-taken:71520
 	picked: 83 |actions: {0: 668, 1: 702, 2: 809, 3: 510, 4: 651, 5: 768, 6: 850, 7: 426, 8: 536}
episode: 28/2000 -> reward: 118.24479166666653, steps:5920, time-taken: 2.04min, time-elasped: 43.02min
-> berries picked: 83 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 882 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [53, 113, 30, 61, 145, 219, 90, 124, 47]
	| approx positives in sample 512: 61
	| approx action-dist in sample 512: [0, 1, 3, 4, 5, 6, 7, 8] [2, 10, 6, 12, 12, 7, 9, 3]
	Time taken saving stuff: 0.00s

=== episode:29 Env-steps-taken:65664
 	picked: 67 |actions: {0: 788, 1: 686, 2: 1230, 3: 486, 4: 615, 5: 610, 6: 573, 7: 374, 8: 579}
episode: 29/2000 -> reward: 88.1614583333333, steps:5941, time-taken: 1.90min, time-elasped: 44.91min
-> berries picked: 67 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 938 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [59, 120, 34, 67, 153, 226, 102, 128, 49]
	| approx positives in sample 512: 51
	| approx action-dist in sample 512: [0, 1, 3, 4, 5, 6, 7, 8] [4, 6, 2, 8, 9, 11, 6, 5]
	Time taken saving stuff: 0.00s

=== episode:30 Env-steps-taken:71520
 	picked: 83 |actions: {0: 644, 1: 686, 2: 824, 3: 454, 4: 712, 5: 716, 6: 778, 7: 401, 8: 651}
episode: 30/2000 -> reward: 118.24479166666656, steps:5866, time-taken: 1.97min, time-elasped: 46.89min
-> berries picked: 83 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1013 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [65, 133, 40, 71, 173, 233, 115, 130, 53]
	| approx positives in sample 512: 58
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 6, 3, 4, 4, 14, 6, 8, 5]
	Time taken saving stuff: 0.05s

=== episode:3 Env-steps-taken:62688
 	picked: 53 |actions: {0: 181, 1: 246, 2: 757, 3: 8, 4: 238, 5: 151, 6: 399, 7: 157, 8: 409}

==================================================
eval-episode: 30 -> reward: 73.46354166666666, steps: 2546.0, wall-time: 32.03s
-> berries picked: 53 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:31 Env-steps-taken:59424
 	picked: 39 |actions: {0: 302, 1: 351, 2: 521, 3: 241, 4: 379, 5: 261, 6: 408, 7: 221, 8: 339}
episode: 31/2000 -> reward: 57.76562500000005, steps:3023, time-taken: 1.18min, time-elasped: 48.60min
-> berries picked: 39 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1046 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [72, 136, 42, 73, 181, 238, 115, 131, 58]
	| approx positives in sample 512: 49
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 9, 2, 3, 5, 9, 8, 6, 1]
	Time taken saving stuff: 0.00s

=== episode:32 Env-steps-taken:69024
 	picked: 74 |actions: {0: 538, 1: 734, 2: 1030, 3: 396, 4: 530, 5: 576, 6: 719, 7: 417, 8: 548}
episode: 32/2000 -> reward: 105.7604166666666, steps:5488, time-taken: 1.92min, time-elasped: 50.53min
-> berries picked: 74 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1110 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [77, 151, 50, 79, 189, 250, 115, 140, 59]
	| approx positives in sample 512: 61
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [2, 12, 3, 1, 11, 13, 10, 6, 3]
	Time taken saving stuff: 0.00s

=== episode:33 Env-steps-taken:68640
 	picked: 74 |actions: {0: 648, 1: 635, 2: 727, 3: 493, 4: 635, 5: 639, 6: 561, 7: 537, 8: 624}
episode: 33/2000 -> reward: 103.76041666666657, steps:5499, time-taken: 1.83min, time-elasped: 52.36min
-> berries picked: 74 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1173 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [80, 165, 55, 80, 197, 266, 124, 142, 64]
	| approx positives in sample 512: 47
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 7, 3, 2, 8, 7, 5, 9, 2]
	Time taken saving stuff: 0.00s

=== episode:34 Env-steps-taken:65952
 	picked: 65 |actions: {0: 468, 1: 407, 2: 829, 3: 421, 4: 586, 5: 518, 6: 515, 7: 377, 8: 483}
episode: 34/2000 -> reward: 90.27604166666663, steps:4604, time-taken: 1.57min, time-elasped: 53.93min
-> berries picked: 65 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1226 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [88, 171, 61, 86, 197, 285, 133, 141, 64]
	| approx positives in sample 512: 66
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 9, 4, 1, 6, 16, 9, 10, 3]
	Time taken saving stuff: 0.00s

=== episode:35 Env-steps-taken:63648
 	picked: 56 |actions: {0: 699, 1: 584, 2: 892, 3: 421, 4: 528, 5: 542, 6: 519, 7: 375, 8: 670}
episode: 35/2000 -> reward: 78.79166666666667, steps:5230, time-taken: 1.72min, time-elasped: 55.66min
-> berries picked: 56 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1272 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [99, 177, 67, 89, 203, 294, 136, 143, 64]
	| approx positives in sample 512: 71
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 10, 7, 5, 9, 8, 13, 8, 5]
	Time taken saving stuff: 0.00s

=== episode:36 Env-steps-taken:67584
 	picked: 76 |actions: {0: 417, 1: 424, 2: 631, 3: 442, 4: 608, 5: 491, 6: 431, 7: 360, 8: 489}
episode: 36/2000 -> reward: 98.64583333333327, steps:4293, time-taken: 1.50min, time-elasped: 57.16min
-> berries picked: 76 of 800 | patches-visited: [0, 1, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1341 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [102, 186, 73, 98, 217, 303, 143, 151, 68]
	| approx positives in sample 512: 74
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 8, 5, 7, 14, 13, 10, 10, 4]
	Time taken saving stuff: 0.00s

=== episode:37 Env-steps-taken:63072
 	picked: 48 |actions: {0: 374, 1: 402, 2: 465, 3: 283, 4: 371, 5: 342, 6: 316, 7: 301, 8: 333}
episode: 37/2000 -> reward: 76.24999999999999, steps:3187, time-taken: 1.15min, time-elasped: 58.31min
-> berries picked: 48 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1383 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [111, 189, 76, 103, 222, 313, 146, 153, 70]
	| approx positives in sample 512: 72
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 10, 6, 6, 6, 19, 10, 4, 5]
	Time taken saving stuff: 0.00s

=== episode:38 Env-steps-taken:60480
 	picked: 42 |actions: {0: 387, 1: 383, 2: 365, 3: 258, 4: 320, 5: 394, 6: 278, 7: 237, 8: 352}
episode: 38/2000 -> reward: 63.09375000000006, steps:2974, time-taken: 1.15min, time-elasped: 59.46min
-> berries picked: 42 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1417 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [115, 197, 78, 105, 221, 320, 151, 155, 75]
	| approx positives in sample 512: 71
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 8, 12, 5, 7, 13, 11, 4, 4]
	Time taken saving stuff: 0.00s

=== episode:39 Env-steps-taken:64800
 	picked: 61 |actions: {0: 474, 1: 429, 2: 317, 3: 439, 4: 444, 5: 549, 6: 538, 7: 433, 8: 436}
episode: 39/2000 -> reward: 84.11979166666666, steps:4059, time-taken: 1.43min, time-elasped: 60.89min
-> berries picked: 61 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1470 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [120, 206, 80, 110, 228, 331, 156, 161, 78]
	| approx positives in sample 512: 77
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 14, 4, 2, 10, 14, 10, 14, 1]
	Time taken saving stuff: 0.00s

=== episode:40 Env-steps-taken:65280
 	picked: 66 |actions: {0: 535, 1: 530, 2: 760, 3: 559, 4: 496, 5: 496, 6: 502, 7: 363, 8: 679}
episode: 40/2000 -> reward: 86.71874999999996, steps:4920, time-taken: 1.65min, time-elasped: 62.54min
-> berries picked: 66 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1524 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [125, 216, 85, 118, 233, 341, 160, 164, 82]
	| approx positives in sample 512: 81
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 17, 3, 2, 15, 11, 9, 9, 6]
	Time taken saving stuff: 0.05s

=== episode:4 Env-steps-taken:73536
 	picked: 94 |actions: {0: 612, 1: 445, 2: 692, 3: 571, 4: 186, 5: 304, 6: 741, 7: 57, 8: 794}

==================================================
eval-episode: 40 -> reward: 127.17187499999982, steps: 4402.0, wall-time: 34.96s
-> berries picked: 94 of 800 | patches-visited: [1, 8] | juice left:-0.00
==================================================


=== episode:41 Env-steps-taken:66720
 	picked: 66 |actions: {0: 447, 1: 459, 2: 434, 3: 528, 4: 388, 5: 597, 6: 549, 7: 464, 8: 519}
episode: 41/2000 -> reward: 94.21874999999996, steps:4385, time-taken: 1.58min, time-elasped: 64.71min
-> berries picked: 66 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1577 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [131, 222, 87, 128, 237, 353, 166, 170, 83]
	| approx positives in sample 512: 78
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 15, 1, 6, 8, 12, 13, 7, 7]
	Time taken saving stuff: 0.00s

=== episode:42 Env-steps-taken:65952
 	picked: 72 |actions: {0: 482, 1: 631, 2: 611, 3: 727, 4: 554, 5: 572, 6: 667, 7: 580, 8: 631}
episode: 42/2000 -> reward: 89.37499999999993, steps:5455, time-taken: 1.79min, time-elasped: 66.50min
-> berries picked: 72 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1622 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [136, 233, 90, 129, 243, 350, 178, 177, 86]
	| approx positives in sample 512: 58
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 9, 6, 3, 9, 11, 4, 10, 2]
	Time taken saving stuff: 0.03s

=== episode:43 Env-steps-taken:62976
 	picked: 48 |actions: {0: 283, 1: 355, 2: 370, 3: 405, 4: 284, 5: 461, 6: 511, 7: 332, 8: 425}
episode: 43/2000 -> reward: 75.75000000000001, steps:3426, time-taken: 1.32min, time-elasped: 67.82min
-> berries picked: 48 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1659 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [140, 236, 92, 134, 247, 350, 189, 184, 87]
	| approx positives in sample 512: 88
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 10, 7, 6, 9, 9, 19, 6, 9]
	Time taken saving stuff: 0.00s

=== episode:44 Env-steps-taken:75360
 	picked: 102 |actions: {0: 746, 1: 824, 2: 729, 3: 880, 4: 533, 5: 644, 6: 759, 7: 618, 8: 762}
episode: 44/2000 -> reward: 137.15624999999994, steps:6495, time-taken: 2.14min, time-elasped: 69.97min
-> berries picked: 102 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1733 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [151, 252, 95, 142, 252, 359, 200, 192, 90]
	| approx positives in sample 512: 84
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 19, 7, 4, 8, 14, 9, 8, 7]
	Time taken saving stuff: 0.08s

=== episode:45 Env-steps-taken:63552
 	picked: 61 |actions: {0: 460, 1: 484, 2: 593, 3: 709, 4: 581, 5: 655, 6: 663, 7: 380, 8: 582}
episode: 45/2000 -> reward: 77.50520833333334, steps:5107, time-taken: 1.74min, time-elasped: 71.71min
-> berries picked: 61 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1781 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [156, 257, 97, 145, 262, 367, 212, 193, 92]
	| approx positives in sample 512: 71
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 10, 8, 5, 10, 8, 7, 8, 6]
	Time taken saving stuff: 0.00s

=== episode:46 Env-steps-taken:61632
 	picked: 47 |actions: {0: 216, 1: 283, 2: 345, 3: 400, 4: 382, 5: 460, 6: 462, 7: 246, 8: 460}
episode: 46/2000 -> reward: 68.8072916666667, steps:3254, time-taken: 1.33min, time-elasped: 73.04min
-> berries picked: 47 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1818 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [159, 261, 99, 151, 269, 375, 217, 194, 93]
	| approx positives in sample 512: 80
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 11, 7, 8, 9, 12, 10, 10, 5]
	Time taken saving stuff: 0.02s

=== episode:47 Env-steps-taken:62880
 	picked: 48 |actions: {0: 245, 1: 388, 2: 597, 3: 385, 4: 283, 5: 297, 6: 393, 7: 377, 8: 350}
episode: 47/2000 -> reward: 75.25, steps:3315, time-taken: 1.18min, time-elasped: 74.23min
-> berries picked: 48 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1854 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [161, 268, 102, 156, 273, 375, 222, 200, 97]
	| approx positives in sample 512: 79
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 11, 5, 12, 9, 12, 10, 10, 4]
	Time taken saving stuff: 0.00s

=== episode:48 Env-steps-taken:73728
 	picked: 89 |actions: {0: 610, 1: 678, 2: 359, 3: 776, 4: 524, 5: 489, 6: 502, 7: 500, 8: 395}
episode: 48/2000 -> reward: 129.40104166666652, steps:4833, time-taken: 1.69min, time-elasped: 75.92min
-> berries picked: 89 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1925 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [173, 281, 102, 168, 281, 381, 230, 211, 98]
	| approx positives in sample 512: 85
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 18, 8, 4, 7, 16, 11, 10, 6]
	Time taken saving stuff: 0.00s

=== episode:49 Env-steps-taken:62400
 	picked: 53 |actions: {0: 193, 1: 301, 2: 320, 3: 448, 4: 373, 5: 366, 6: 323, 7: 254, 8: 317}
episode: 49/2000 -> reward: 72.46354166666666, steps:2895, time-taken: 1.06min, time-elasped: 76.98min
-> berries picked: 53 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1964 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [174, 288, 104, 176, 285, 378, 242, 217, 100]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 16, 6, 8, 20, 12, 13, 7, 8]
	Time taken saving stuff: 0.00s

=== episode:50 Env-steps-taken:63552
 	picked: 55 |actions: {0: 377, 1: 485, 2: 818, 3: 512, 4: 375, 5: 345, 6: 380, 7: 374, 8: 424}
episode: 50/2000 -> reward: 76.40625, steps:4090, time-taken: 1.41min, time-elasped: 78.39min
-> berries picked: 55 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2011 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [180, 298, 109, 183, 286, 381, 251, 222, 101]
	| approx positives in sample 512: 78
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 17, 3, 7, 10, 5, 12, 12, 2]
	Time taken saving stuff: 0.05s

=== episode:5 Env-steps-taken:69696
 	picked: 83 |actions: {0: 288, 1: 453, 2: 165, 3: 797, 4: 179, 5: 174, 6: 416, 7: 403, 8: 120}

==================================================
eval-episode: 50 -> reward: 108.74479166666656, steps: 2995.0, wall-time: 28.29s
-> berries picked: 83 of 800 | patches-visited: [1, 5] | juice left:-0.00
==================================================


=== episode:51 Env-steps-taken:66240
 	picked: 67 |actions: {0: 457, 1: 564, 2: 377, 3: 556, 4: 532, 5: 453, 6: 526, 7: 420, 8: 314}
episode: 51/2000 -> reward: 91.66145833333329, steps:4199, time-taken: 1.52min, time-elasped: 80.39min
-> berries picked: 67 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2053 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [188, 308, 114, 193, 287, 378, 255, 228, 102]
	| approx positives in sample 512: 85
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 15, 9, 13, 7, 7, 6, 9, 7]
	Time taken saving stuff: 0.00s

=== episode:52 Env-steps-taken:59040
 	picked: 45 |actions: {0: 351, 1: 427, 2: 555, 3: 353, 4: 325, 5: 309, 6: 459, 7: 307, 8: 408}
episode: 52/2000 -> reward: 54.92187500000007, steps:3494, time-taken: 1.22min, time-elasped: 81.61min
-> berries picked: 45 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2080 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [191, 318, 117, 197, 288, 379, 253, 236, 101]
	| approx positives in sample 512: 83
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 13, 6, 11, 8, 10, 8, 11, 5]
	Time taken saving stuff: 0.00s

=== episode:53 Env-steps-taken:62208
 	picked: 59 |actions: {0: 501, 1: 607, 2: 681, 3: 860, 4: 565, 5: 501, 6: 802, 7: 645, 8: 483}
episode: 53/2000 -> reward: 70.61979166666666, steps:5645, time-taken: 1.82min, time-elasped: 83.44min
-> berries picked: 59 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2118 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [196, 319, 120, 204, 289, 384, 257, 245, 104]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 25, 5, 13, 8, 7, 13, 8, 6]
	Time taken saving stuff: 0.00s

=== episode:54 Env-steps-taken:63360
 	picked: 59 |actions: {0: 499, 1: 605, 2: 603, 3: 769, 4: 481, 5: 495, 6: 772, 7: 461, 8: 435}
episode: 54/2000 -> reward: 75.73437499999999, steps:5120, time-taken: 1.72min, time-elasped: 85.16min
-> berries picked: 59 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2148 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [198, 333, 121, 208, 293, 383, 259, 250, 103]
	| approx positives in sample 512: 82
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 24, 5, 8, 6, 11, 4, 6, 4]
	Time taken saving stuff: 0.00s

=== episode:55 Env-steps-taken:63360
 	picked: 59 |actions: {0: 693, 1: 585, 2: 526, 3: 1201, 4: 561, 5: 496, 6: 754, 7: 482, 8: 462}
episode: 55/2000 -> reward: 76.61979166666666, steps:5760, time-taken: 1.85min, time-elasped: 87.01min
-> berries picked: 59 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2165 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [204, 345, 122, 214, 291, 379, 258, 249, 103]
	| approx positives in sample 512: 85
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 20, 7, 8, 4, 10, 14, 8, 4]
	Time taken saving stuff: 0.00s

=== episode:56 Env-steps-taken:64896
 	picked: 67 |actions: {0: 584, 1: 507, 2: 445, 3: 610, 4: 373, 5: 385, 6: 502, 7: 359, 8: 275}
episode: 56/2000 -> reward: 84.16145833333331, steps:4040, time-taken: 1.41min, time-elasped: 88.42min
-> berries picked: 67 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2219 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [215, 360, 125, 221, 298, 380, 262, 252, 106]
	| approx positives in sample 512: 81
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 21, 5, 6, 13, 8, 7, 3, 5]
	Time taken saving stuff: 0.00s

=== episode:57 Env-steps-taken:67296
 	picked: 75 |actions: {0: 662, 1: 838, 2: 645, 3: 701, 4: 556, 5: 466, 6: 680, 7: 725, 8: 475}
episode: 57/2000 -> reward: 95.76041666666659, steps:5748, time-taken: 1.96min, time-elasped: 90.38min
-> berries picked: 75 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2269 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [228, 375, 130, 227, 302, 377, 263, 261, 106]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 19, 14, 12, 9, 14, 9, 14, 5]
	Time taken saving stuff: 0.00s

=== episode:58 Env-steps-taken:66240
 	picked: 70 |actions: {0: 395, 1: 335, 2: 411, 3: 493, 4: 541, 5: 381, 6: 352, 7: 309, 8: 226}
episode: 58/2000 -> reward: 91.48958333333329, steps:3443, time-taken: 1.28min, time-elasped: 91.66min
-> berries picked: 70 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2320 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [238, 379, 136, 239, 303, 379, 273, 263, 110]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 32, 8, 12, 9, 15, 11, 8, 8]
	Time taken saving stuff: 0.10s

=== episode:59 Env-steps-taken:55680
 	picked: 26 |actions: {0: 256, 1: 267, 2: 322, 3: 296, 4: 270, 5: 268, 6: 275, 7: 234, 8: 169}
episode: 59/2000 -> reward: 38.51041666666668, steps:2357, time-taken: 0.95min, time-elasped: 92.62min
-> berries picked: 26 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2338 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [240, 381, 139, 241, 304, 380, 274, 268, 111]
	| approx positives in sample 512: 101
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 17, 6, 13, 13, 15, 8, 11, 5]
	Time taken saving stuff: 0.00s

=== episode:60 Env-steps-taken:70560
 	picked: 84 |actions: {0: 759, 1: 606, 2: 779, 3: 569, 4: 565, 5: 616, 6: 751, 7: 581, 8: 442}
episode: 60/2000 -> reward: 113.18749999999989, steps:5668, time-taken: 1.91min, time-elasped: 94.53min
-> berries picked: 84 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2395 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [252, 389, 147, 247, 312, 381, 278, 274, 115]
	| approx positives in sample 512: 94
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 17, 5, 2, 7, 11, 8, 19, 7]
	Time taken saving stuff: 0.07s

=== episode:6 Env-steps-taken:55008
 	picked: 25 |actions: {0: 50, 1: 818, 2: 85, 3: 117, 4: 159, 5: 273, 6: 75, 7: 397, 8: 762}

==================================================
eval-episode: 60 -> reward: 35.56770833333334, steps: 2736.0, wall-time: 24.12s
-> berries picked: 25 of 800 | patches-visited: [0, 1] | juice left:-0.00
==================================================


=== episode:61 Env-steps-taken:56736
 	picked: 36 |actions: {0: 452, 1: 335, 2: 510, 3: 313, 4: 560, 5: 472, 6: 437, 7: 496, 8: 399}
episode: 61/2000 -> reward: 43.93750000000002, steps:3974, time-taken: 1.35min, time-elasped: 96.28min
-> berries picked: 36 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2412 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [258, 387, 148, 247, 316, 382, 280, 278, 116]
	| approx positives in sample 512: 91
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 18, 8, 18, 5, 10, 3, 11, 6]
	Time taken saving stuff: 0.00s

=== episode:62 Env-steps-taken:55104
 	picked: 25 |actions: {0: 402, 1: 463, 2: 586, 3: 336, 4: 474, 5: 361, 6: 650, 7: 438, 8: 324}
episode: 62/2000 -> reward: 35.18229166666667, steps:4034, time-taken: 1.43min, time-elasped: 97.71min
-> berries picked: 25 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2418 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [260, 388, 151, 249, 311, 382, 283, 275, 119]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 30, 5, 13, 15, 12, 19, 13, 1]
	Time taken saving stuff: 0.00s

=== episode:63 Env-steps-taken:49728
 	picked: 6 |actions: {0: 44, 1: 22, 2: 56, 3: 74, 4: 83, 5: 45, 6: 76, 7: 44, 8: 46}
episode: 63/2000 -> reward: 8.65625, steps:490, time-taken: 0.48min, time-elasped: 98.19min
-> berries picked: 6 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2423 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [261, 388, 151, 250, 312, 383, 284, 275, 119]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 21, 16, 15, 10, 11, 7, 16, 8]
	Time taken saving stuff: 0.00s

=== episode:64 Env-steps-taken:60960
 	picked: 48 |actions: {0: 400, 1: 422, 2: 713, 3: 470, 4: 646, 5: 358, 6: 454, 7: 446, 8: 409}
episode: 64/2000 -> reward: 65.25000000000006, steps:4318, time-taken: 1.57min, time-elasped: 99.76min
-> berries picked: 48 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2458 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [268, 393, 155, 255, 321, 380, 284, 282, 120]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 26, 16, 11, 11, 14, 11, 11, 7]
	Time taken saving stuff: 0.10s

=== episode:65 Env-steps-taken:55584
 	picked: 29 |actions: {0: 236, 1: 333, 2: 532, 3: 334, 4: 554, 5: 425, 6: 277, 7: 347, 8: 387}
episode: 65/2000 -> reward: 37.838541666666664, steps:3425, time-taken: 1.31min, time-elasped: 101.08min
-> berries picked: 29 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2474 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [270, 394, 158, 258, 321, 383, 289, 280, 121]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 32, 9, 20, 14, 9, 8, 16, 4]
	Time taken saving stuff: 0.00s

=== episode:66 Env-steps-taken:67968
 	picked: 69 |actions: {0: 521, 1: 583, 2: 430, 3: 464, 4: 407, 5: 410, 6: 511, 7: 475, 8: 266}
episode: 66/2000 -> reward: 100.54687499999994, steps:4067, time-taken: 1.49min, time-elasped: 102.58min
-> berries picked: 69 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2517 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [285, 407, 159, 259, 328, 384, 289, 283, 123]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [23, 22, 7, 14, 13, 6, 12, 10, 4]
	Time taken saving stuff: 0.02s

=== episode:67 Env-steps-taken:50304
 	picked: 9 |actions: {0: 112, 1: 122, 2: 163, 3: 112, 4: 96, 5: 149, 6: 102, 7: 137, 8: 61}
episode: 67/2000 -> reward: 11.484375000000002, steps:1054, time-taken: 0.59min, time-elasped: 103.17min
-> berries picked: 9 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2516 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [285, 409, 158, 260, 327, 382, 289, 283, 123]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 33, 13, 16, 5, 17, 15, 9, 3]
	Time taken saving stuff: 0.00s

=== episode:68 Env-steps-taken:68352
 	picked: 74 |actions: {0: 507, 1: 583, 2: 750, 3: 821, 4: 624, 5: 441, 6: 715, 7: 624, 8: 448}
episode: 68/2000 -> reward: 102.26041666666656, steps:5513, time-taken: 1.94min, time-elasped: 105.11min
-> berries picked: 74 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2566 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [292, 420, 164, 266, 339, 381, 291, 289, 124]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 14, 10, 19, 11, 12, 8, 15, 13]
	Time taken saving stuff: 0.10s

=== episode:69 Env-steps-taken:67680
 	picked: 74 |actions: {0: 445, 1: 529, 2: 751, 3: 683, 4: 780, 5: 608, 6: 723, 7: 566, 8: 432}
episode: 69/2000 -> reward: 98.7604166666666, steps:5517, time-taken: 1.85min, time-elasped: 106.97min
-> berries picked: 74 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2622 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [301, 425, 171, 271, 351, 387, 298, 292, 126]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 35, 12, 10, 20, 9, 11, 12, 8]
	Time taken saving stuff: 0.00s

=== episode:70 Env-steps-taken:76224
 	picked: 98 |actions: {0: 887, 1: 515, 2: 747, 3: 607, 4: 726, 5: 687, 6: 755, 7: 685, 8: 471}
episode: 70/2000 -> reward: 141.4999999999999, steps:6080, time-taken: 2.02min, time-elasped: 108.99min
-> berries picked: 98 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2688 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [315, 426, 175, 285, 359, 385, 306, 305, 132]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 29, 7, 14, 8, 11, 11, 6, 7]
	Time taken saving stuff: 0.15s

=== episode:7 Env-steps-taken:51168
 	picked: 12 |actions: {0: 56, 1: 28, 2: 2177, 3: 20, 4: 42, 5: 41, 6: 2220, 7: 61, 8: 7}

==================================================
eval-episode: 70 -> reward: 15.8125, steps: 4652.0, wall-time: 28.27s
-> berries picked: 12 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:71 Env-steps-taken:65472
 	picked: 60 |actions: {0: 454, 1: 350, 2: 331, 3: 458, 4: 451, 5: 507, 6: 641, 7: 476, 8: 425}
episode: 71/2000 -> reward: 88.06249999999997, steps:4093, time-taken: 1.50min, time-elasped: 110.97min
-> berries picked: 60 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2732 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [316, 431, 176, 291, 365, 389, 311, 318, 135]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 34, 13, 15, 6, 10, 10, 14, 6]
	Time taken saving stuff: 0.00s

=== episode:72 Env-steps-taken:59616
 	picked: 44 |actions: {0: 319, 1: 432, 2: 487, 3: 469, 4: 503, 5: 424, 6: 709, 7: 408, 8: 463}
episode: 72/2000 -> reward: 57.9791666666667, steps:4214, time-taken: 1.47min, time-elasped: 112.44min
-> berries picked: 44 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2756 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [322, 436, 177, 299, 366, 391, 311, 319, 135]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 35, 13, 11, 13, 13, 10, 13, 7]
	Time taken saving stuff: 0.00s

=== episode:73 Env-steps-taken:64608
 	picked: 58 |actions: {0: 384, 1: 533, 2: 516, 3: 546, 4: 532, 5: 472, 6: 397, 7: 447, 8: 371}
episode: 73/2000 -> reward: 83.67708333333331, steps:4198, time-taken: 1.56min, time-elasped: 114.00min
-> berries picked: 58 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2784 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [330, 445, 182, 303, 365, 391, 308, 321, 139]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 24, 13, 17, 5, 16, 5, 14, 8]
	Time taken saving stuff: 0.00s

=== episode:74 Env-steps-taken:71520
 	picked: 84 |actions: {0: 680, 1: 678, 2: 656, 3: 689, 4: 710, 5: 678, 6: 682, 7: 624, 8: 484}
episode: 74/2000 -> reward: 117.30208333333323, steps:5881, time-taken: 1.92min, time-elasped: 115.92min
-> berries picked: 84 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2835 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [339, 458, 187, 309, 367, 391, 316, 328, 140]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 19, 9, 8, 8, 8, 12, 11, 7]
	Time taken saving stuff: 0.00s

=== episode:75 Env-steps-taken:65568
 	picked: 68 |actions: {0: 551, 1: 551, 2: 583, 3: 649, 4: 774, 5: 540, 6: 641, 7: 613, 8: 558}
episode: 75/2000 -> reward: 88.10416666666663, steps:5460, time-taken: 1.79min, time-elasped: 117.72min
-> berries picked: 68 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2879 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [352, 464, 187, 319, 370, 386, 322, 337, 142]
	| approx positives in sample 512: 99
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 22, 8, 16, 9, 9, 5, 11, 10]
	Time taken saving stuff: 0.00s

=== episode:76 Env-steps-taken:56352
 	picked: 36 |actions: {0: 526, 1: 469, 2: 638, 3: 756, 4: 692, 5: 435, 6: 592, 7: 563, 8: 452}
episode: 76/2000 -> reward: 41.437500000000014, steps:5123, time-taken: 1.63min, time-elasped: 119.35min
-> berries picked: 36 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2878 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [358, 467, 186, 319, 367, 382, 321, 337, 141]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 29, 14, 17, 15, 11, 13, 9, 2]
	Time taken saving stuff: 0.00s

=== episode:77 Env-steps-taken:69792
 	picked: 80 |actions: {0: 571, 1: 676, 2: 572, 3: 590, 4: 646, 5: 496, 6: 579, 7: 480, 8: 448}
episode: 77/2000 -> reward: 109.41666666666657, steps:5058, time-taken: 1.73min, time-elasped: 121.09min
-> berries picked: 80 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2919 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [369, 475, 191, 322, 377, 381, 324, 338, 142]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 21, 11, 10, 17, 8, 8, 14, 9]
	Time taken saving stuff: 0.00s

=== episode:78 Env-steps-taken:48384
 	picked: 1 |actions: {0: 459, 1: 258, 2: 368, 3: 646, 4: 462, 5: 621, 6: 434, 7: 691, 8: 460}
episode: 78/2000 -> reward: 1.9427083333333344, steps:4399, time-taken: 1.46min, time-elasped: 122.55min
-> berries picked: 1 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2890 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [368, 473, 191, 320, 372, 373, 318, 333, 142]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 27, 18, 18, 10, 8, 9, 10, 6]
	Time taken saving stuff: 0.00s

=== episode:79 Env-steps-taken:72384
 	picked: 91 |actions: {0: 556, 1: 668, 2: 564, 3: 682, 4: 629, 5: 587, 6: 1023, 7: 722, 8: 460}
episode: 79/2000 -> reward: 122.2864583333332, steps:5891, time-taken: 1.98min, time-elasped: 124.53min
-> berries picked: 91 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2927 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [382, 486, 195, 325, 372, 367, 314, 342, 144]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 31, 18, 17, 10, 8, 9, 15, 5]
	Time taken saving stuff: 0.00s

=== episode:80 Env-steps-taken:69888
 	picked: 79 |actions: {0: 618, 1: 553, 2: 593, 3: 667, 4: 573, 5: 686, 6: 555, 7: 507, 8: 536}
episode: 80/2000 -> reward: 110.0312499999999, steps:5288, time-taken: 1.79min, time-elasped: 126.32min
-> berries picked: 79 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2949 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [387, 493, 200, 323, 368, 366, 318, 348, 146]
	| approx positives in sample 512: 99
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 20, 11, 14, 10, 11, 3, 12, 7]
	Time taken saving stuff: 0.05s

=== episode:8 Env-steps-taken:72672
 	picked: 93 |actions: {0: 917, 1: 331, 2: 554, 3: 422, 4: 145, 5: 273, 6: 237, 7: 285, 8: 385}

==================================================
eval-episode: 80 -> reward: 123.67187499999983, steps: 3549.0, wall-time: 32.54s
-> berries picked: 93 of 800 | patches-visited: [1, 7] | juice left:-0.00
==================================================


=== episode:81 Env-steps-taken:70272
 	picked: 82 |actions: {0: 527, 1: 426, 2: 573, 3: 556, 4: 406, 5: 293, 6: 560, 7: 532, 8: 421}
episode: 81/2000 -> reward: 112.30208333333321, steps:4294, time-taken: 1.56min, time-elasped: 128.42min
-> berries picked: 82 of 800 | patches-visited: [0, 6, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3013 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [398, 497, 205, 337, 368, 363, 331, 361, 153]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 30, 16, 9, 9, 12, 9, 15, 8]
	Time taken saving stuff: 0.00s

=== episode:82 Env-steps-taken:66624
 	picked: 73 |actions: {0: 566, 1: 469, 2: 560, 3: 657, 4: 614, 5: 913, 6: 732, 7: 560, 8: 830}
episode: 82/2000 -> reward: 92.9322916666666, steps:5901, time-taken: 1.91min, time-elasped: 130.34min
-> berries picked: 73 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3028 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [397, 501, 210, 334, 365, 363, 337, 366, 155]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 32, 14, 10, 14, 9, 9, 14, 11]
	Time taken saving stuff: 0.00s

=== episode:83 Env-steps-taken:76224
 	picked: 110 |actions: {0: 657, 1: 625, 2: 642, 3: 699, 4: 638, 5: 457, 6: 793, 7: 562, 8: 575}
episode: 83/2000 -> reward: 141.69791666666663, steps:5648, time-taken: 1.98min, time-elasped: 132.32min
-> berries picked: 110 of 800 | patches-visited: [0, 4, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3087 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [403, 513, 224, 346, 363, 359, 348, 370, 161]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 20, 10, 9, 9, 3, 6, 15, 11]
	Time taken saving stuff: 0.00s

=== episode:84 Env-steps-taken:67968
 	picked: 73 |actions: {0: 451, 1: 446, 2: 550, 3: 546, 4: 618, 5: 487, 6: 681, 7: 473, 8: 539}
episode: 84/2000 -> reward: 100.31770833333323, steps:4791, time-taken: 1.74min, time-elasped: 134.07min
-> berries picked: 73 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3108 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [402, 520, 229, 348, 363, 357, 354, 373, 162]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 22, 10, 11, 9, 14, 9, 10, 8]
	Time taken saving stuff: 0.00s

=== episode:85 Env-steps-taken:65376
 	picked: 76 |actions: {0: 552, 1: 513, 2: 767, 3: 737, 4: 657, 5: 560, 6: 621, 7: 456, 8: 490}
episode: 85/2000 -> reward: 86.2031249999999, steps:5353, time-taken: 1.80min, time-elasped: 135.87min
-> berries picked: 76 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3125 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [405, 524, 238, 358, 357, 356, 353, 371, 163]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 14, 13, 10, 10, 9, 12, 14, 10]
	Time taken saving stuff: 0.00s

=== episode:86 Env-steps-taken:56160
 	picked: 28 |actions: {0: 185, 1: 146, 2: 158, 3: 137, 4: 226, 5: 250, 6: 322, 7: 162, 8: 261}
episode: 86/2000 -> reward: 40.89583333333335, steps:1847, time-taken: 0.81min, time-elasped: 136.68min
-> berries picked: 28 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3126 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [403, 523, 238, 358, 357, 358, 360, 367, 162]
	| approx positives in sample 512: 100
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 15, 14, 15, 11, 10, 9, 6, 9]
	Time taken saving stuff: 0.00s

=== episode:87 Env-steps-taken:67200
 	picked: 66 |actions: {0: 501, 1: 425, 2: 501, 3: 627, 4: 581, 5: 380, 6: 484, 7: 466, 8: 491}
episode: 87/2000 -> reward: 96.71874999999994, steps:4456, time-taken: 1.60min, time-elasped: 138.28min
-> berries picked: 66 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3137 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [400, 528, 241, 367, 362, 353, 362, 361, 163]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 21, 11, 13, 9, 11, 9, 14, 8]
	Time taken saving stuff: 0.00s

=== episode:88 Env-steps-taken:58848
 	picked: 42 |actions: {0: 206, 1: 195, 2: 300, 3: 299, 4: 207, 5: 258, 6: 257, 7: 258, 8: 215}
episode: 88/2000 -> reward: 54.09375000000004, steps:2195, time-taken: 0.88min, time-elasped: 139.17min
-> berries picked: 42 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3156 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [399, 530, 243, 374, 363, 355, 365, 362, 165]
	| approx positives in sample 512: 99
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 21, 16, 6, 8, 7, 11, 10, 10]
	Time taken saving stuff: 0.00s

=== episode:89 Env-steps-taken:59520
 	picked: 42 |actions: {0: 232, 1: 261, 2: 286, 3: 350, 4: 268, 5: 200, 6: 414, 7: 322, 8: 185}
episode: 89/2000 -> reward: 58.093750000000036, steps:2518, time-taken: 0.99min, time-elasped: 140.16min
-> berries picked: 42 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3163 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [398, 520, 251, 376, 360, 357, 368, 366, 167]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 19, 13, 10, 13, 20, 9, 14, 9]
	Time taken saving stuff: 0.00s

=== episode:90 Env-steps-taken:67488
 	picked: 71 |actions: {0: 509, 1: 481, 2: 484, 3: 637, 4: 505, 5: 376, 6: 605, 7: 476, 8: 415}
episode: 90/2000 -> reward: 97.93229166666656, steps:4488, time-taken: 1.55min, time-elasped: 141.72min
-> berries picked: 71 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3180 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [393, 532, 259, 382, 354, 351, 371, 367, 171]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 19, 16, 12, 13, 16, 4, 14, 10]
	Time taken saving stuff: 0.05s

=== episode:9 Env-steps-taken:80352
 	picked: 121 |actions: {0: 858, 1: 367, 2: 695, 3: 619, 4: 326, 5: 625, 6: 250, 7: 546, 8: 189}

==================================================
eval-episode: 90 -> reward: 160.68229166666669, steps: 4475.0, wall-time: 36.74s
-> berries picked: 121 of 800 | patches-visited: [0, 1, 8] | juice left:-0.00
==================================================


=== episode:91 Env-steps-taken:76128
 	picked: 108 |actions: {0: 766, 1: 714, 2: 885, 3: 773, 4: 713, 5: 573, 6: 859, 7: 657, 8: 530}
episode: 91/2000 -> reward: 138.92708333333323, steps:6470, time-taken: 2.19min, time-elasped: 144.53min
-> berries picked: 108 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3217 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [396, 543, 266, 386, 356, 345, 379, 375, 171]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 26, 6, 11, 8, 12, 11, 13, 8]
	Time taken saving stuff: 0.00s

=== episode:92 Env-steps-taken:72000
 	picked: 93 |actions: {0: 582, 1: 592, 2: 543, 3: 659, 4: 731, 5: 594, 6: 764, 7: 612, 8: 456}
episode: 92/2000 -> reward: 118.78645833333316, steps:5533, time-taken: 1.92min, time-elasped: 146.45min
-> berries picked: 93 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3242 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [392, 550, 271, 390, 357, 352, 378, 378, 174]
	| approx positives in sample 512: 90
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 6, 13, 4, 9, 7, 17, 14, 9]
	Time taken saving stuff: 0.00s

=== episode:93 Env-steps-taken:71040
 	picked: 84 |actions: {0: 500, 1: 520, 2: 450, 3: 556, 4: 504, 5: 451, 6: 715, 7: 579, 8: 350}
episode: 93/2000 -> reward: 113.74479166666654, steps:4625, time-taken: 1.62min, time-elasped: 148.06min
-> berries picked: 84 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3275 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [394, 550, 279, 395, 356, 355, 383, 387, 176]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 25, 12, 9, 15, 10, 11, 12, 5]
	Time taken saving stuff: 0.00s

=== episode:94 Env-steps-taken:79584
 	picked: 115 |actions: {0: 707, 1: 790, 2: 635, 3: 745, 4: 668, 5: 724, 6: 1011, 7: 606, 8: 770}
episode: 94/2000 -> reward: 158.46875000000014, steps:6656, time-taken: 2.26min, time-elasped: 150.33min
-> berries picked: 115 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3327 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [396, 550, 286, 397, 360, 371, 393, 395, 179]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 18, 7, 12, 14, 13, 9, 6, 12]
	Time taken saving stuff: 0.00s

=== episode:95 Env-steps-taken:64896
 	picked: 69 |actions: {0: 472, 1: 530, 2: 416, 3: 523, 4: 834, 5: 593, 6: 701, 7: 494, 8: 404}
episode: 95/2000 -> reward: 84.04687499999994, steps:4967, time-taken: 1.71min, time-elasped: 152.04min
-> berries picked: 69 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3337 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [394, 546, 290, 397, 367, 371, 399, 394, 179]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 17, 6, 12, 17, 17, 8, 13, 6]
	Time taken saving stuff: 0.00s

=== episode:96 Env-steps-taken:62496
 	picked: 56 |actions: {0: 465, 1: 488, 2: 324, 3: 296, 4: 315, 5: 247, 6: 452, 7: 374, 8: 364}
episode: 96/2000 -> reward: 72.79166666666669, steps:3325, time-taken: 1.18min, time-elasped: 153.22min
-> berries picked: 56 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3345 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [398, 543, 296, 391, 361, 374, 398, 404, 180]
	| approx positives in sample 512: 101
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 23, 14, 11, 1, 7, 13, 10, 7]
	Time taken saving stuff: 0.00s

=== episode:97 Env-steps-taken:63744
 	picked: 60 |actions: {0: 489, 1: 528, 2: 441, 3: 412, 4: 448, 5: 348, 6: 477, 7: 492, 8: 270}
episode: 97/2000 -> reward: 78.5625, steps:3905, time-taken: 1.37min, time-elasped: 154.59min
-> berries picked: 60 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3351 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [393, 545, 296, 394, 356, 372, 405, 411, 179]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 17, 12, 11, 6, 10, 11, 13, 13]
	Time taken saving stuff: 0.00s

=== episode:98 Env-steps-taken:70560
 	picked: 85 |actions: {0: 433, 1: 584, 2: 464, 3: 618, 4: 560, 5: 508, 6: 605, 7: 402, 8: 360}
episode: 98/2000 -> reward: 113.1302083333332, steps:4534, time-taken: 1.58min, time-elasped: 156.18min
-> berries picked: 85 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3375 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [390, 548, 299, 404, 359, 368, 410, 417, 180]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 16, 13, 15, 11, 13, 9, 14, 7]
	Time taken saving stuff: 0.00s

=== episode:99 Env-steps-taken:62976
 	picked: 52 |actions: {0: 367, 1: 531, 2: 426, 3: 507, 4: 547, 5: 358, 6: 483, 7: 353, 8: 314}
episode: 99/2000 -> reward: 75.52083333333336, steps:3886, time-taken: 1.39min, time-elasped: 157.57min
-> berries picked: 52 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3373 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [388, 552, 302, 405, 352, 368, 409, 415, 182]
	| approx positives in sample 512: 80
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 10, 14, 8, 2, 10, 11, 12, 3]
	Time taken saving stuff: 0.00s

=== episode:100 Env-steps-taken:73056
 	picked: 90 |actions: {0: 545, 1: 723, 2: 572, 3: 631, 4: 929, 5: 656, 6: 768, 7: 553, 8: 549}
episode: 100/2000 -> reward: 125.84374999999982, steps:5926, time-taken: 2.12min, time-elasped: 159.69min
-> berries picked: 90 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3383 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [383, 553, 304, 400, 352, 369, 419, 417, 186]
	| approx positives in sample 512: 87
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 13, 7, 13, 11, 8, 8, 12, 11]
	Time taken saving stuff: 0.05s

=== episode:10 Env-steps-taken:103392
 	picked: 212 |actions: {0: 984, 1: 839, 2: 827, 3: 979, 4: 800, 5: 648, 6: 1182, 7: 994, 8: 414}

==================================================
eval-episode: 100 -> reward: 277.8541666666671, steps: 7667.0, wall-time: 46.32s
-> berries picked: 212 of 800 | patches-visited: [1, 4, 5, 7] | juice left:-0.00
==================================================


=== episode:101 Env-steps-taken:69408
 	picked: 85 |actions: {0: 558, 1: 727, 2: 518, 3: 649, 4: 708, 5: 604, 6: 806, 7: 421, 8: 348}
episode: 101/2000 -> reward: 107.18749999999986, steps:5339, time-taken: 1.84min, time-elasped: 162.30min
-> berries picked: 85 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3378 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [379, 547, 307, 401, 353, 369, 414, 419, 189]
	| approx positives in sample 512: 91
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 10, 14, 10, 8, 9, 13, 11, 9]
	Time taken saving stuff: 0.00s

=== episode:102 Env-steps-taken:67200
 	picked: 74 |actions: {0: 589, 1: 549, 2: 541, 3: 642, 4: 630, 5: 476, 6: 701, 7: 455, 8: 484}
episode: 102/2000 -> reward: 96.26041666666657, steps:5067, time-taken: 1.74min, time-elasped: 164.05min
-> berries picked: 74 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3378 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [373, 549, 313, 403, 349, 370, 412, 419, 190]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 14, 17, 11, 10, 9, 11, 7, 10]
	Time taken saving stuff: 0.00s

=== episode:103 Env-steps-taken:64224
 	picked: 65 |actions: {0: 399, 1: 376, 2: 398, 3: 497, 4: 491, 5: 500, 6: 557, 7: 380, 8: 309}
episode: 103/2000 -> reward: 80.890625, steps:3907, time-taken: 1.40min, time-elasped: 165.45min
-> berries picked: 65 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3395 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [373, 544, 317, 400, 352, 375, 421, 418, 195]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 11, 6, 12, 7, 8, 15, 19, 9]
	Time taken saving stuff: 0.00s

=== episode:104 Env-steps-taken:72960
 	picked: 95 |actions: {0: 617, 1: 557, 2: 552, 3: 693, 4: 653, 5: 520, 6: 631, 7: 536, 8: 559}
episode: 104/2000 -> reward: 125.05729166666647, steps:5318, time-taken: 1.87min, time-elasped: 167.32min
-> berries picked: 95 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3400 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [370, 540, 325, 390, 347, 376, 429, 427, 196]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 16, 12, 10, 8, 11, 11, 13, 8]
	Time taken saving stuff: 0.00s

=== episode:105 Env-steps-taken:66528
 	picked: 71 |actions: {0: 599, 1: 583, 2: 468, 3: 449, 4: 529, 5: 493, 6: 626, 7: 482, 8: 481}
episode: 105/2000 -> reward: 92.93229166666659, steps:4710, time-taken: 1.69min, time-elasped: 169.01min
-> berries picked: 71 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3417 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [376, 541, 331, 382, 347, 376, 437, 431, 196]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 14, 11, 10, 8, 10, 16, 10, 7]
	Time taken saving stuff: 0.00s

=== episode:106 Env-steps-taken:86496
 	picked: 130 |actions: {0: 809, 1: 871, 2: 744, 3: 748, 4: 892, 5: 828, 6: 861, 7: 677, 8: 521}
episode: 106/2000 -> reward: 194.05208333333363, steps:6951, time-taken: 2.38min, time-elasped: 171.39min
-> berries picked: 130 of 800 | patches-visited: [0, 2, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3446 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [372, 548, 336, 382, 346, 380, 447, 433, 202]
	| approx positives in sample 512: 86
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 9, 7, 10, 11, 7, 11, 14, 6]
	Time taken saving stuff: 0.00s

=== episode:107 Env-steps-taken:64512
 	picked: 66 |actions: {0: 540, 1: 464, 2: 468, 3: 725, 4: 691, 5: 554, 6: 483, 7: 407, 8: 463}
episode: 107/2000 -> reward: 82.21874999999997, steps:4795, time-taken: 1.63min, time-elasped: 173.03min
-> berries picked: 66 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3435 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [364, 548, 340, 387, 347, 376, 443, 425, 205]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 17, 16, 10, 10, 9, 18, 9, 7]
	Time taken saving stuff: 0.00s

=== episode:108 Env-steps-taken:73632
 	picked: 96 |actions: {0: 744, 1: 765, 2: 645, 3: 704, 4: 702, 5: 552, 6: 721, 7: 517, 8: 505}
episode: 108/2000 -> reward: 128.49999999999983, steps:5855, time-taken: 1.93min, time-elasped: 174.95min
-> berries picked: 96 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3444 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [363, 552, 342, 387, 344, 389, 437, 422, 208]
	| approx positives in sample 512: 101
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 13, 10, 14, 10, 9, 16, 10, 10]
	Time taken saving stuff: 0.00s

=== episode:109 Env-steps-taken:70848
 	picked: 82 |actions: {0: 574, 1: 537, 2: 472, 3: 642, 4: 648, 5: 514, 6: 735, 7: 465, 8: 447}
episode: 109/2000 -> reward: 111.08854166666657, steps:5034, time-taken: 1.76min, time-elasped: 176.72min
-> berries picked: 82 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3453 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [363, 554, 345, 387, 344, 390, 439, 421, 210]
	| approx positives in sample 512: 88
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 9, 12, 10, 9, 9, 9, 12, 9]
	Time taken saving stuff: 0.00s

=== episode:110 Env-steps-taken:75168
 	picked: 101 |actions: {0: 590, 1: 668, 2: 501, 3: 507, 4: 691, 5: 598, 6: 792, 7: 610, 8: 467}
episode: 110/2000 -> reward: 136.71354166666652, steps:5424, time-taken: 1.91min, time-elasped: 178.63min
-> berries picked: 101 of 800 | patches-visited: [0, 1, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3469 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [364, 560, 345, 378, 337, 394, 446, 430, 215]
	| approx positives in sample 512: 100
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 20, 10, 10, 10, 6, 10, 15, 8]
	Time taken saving stuff: 0.05s

=== episode:11 Env-steps-taken:78336
 	picked: 118 |actions: {0: 455, 1: 643, 2: 200, 3: 1133, 4: 271, 5: 291, 6: 831, 7: 303, 8: 511}

==================================================
eval-episode: 110 -> reward: 149.85416666666663, steps: 4638.0, wall-time: 35.13s
-> berries picked: 118 of 800 | patches-visited: [0, 1] | juice left:-0.00
==================================================


=== episode:111 Env-steps-taken:74784
 	picked: 97 |actions: {0: 643, 1: 689, 2: 568, 3: 609, 4: 719, 5: 617, 6: 767, 7: 597, 8: 395}
episode: 111/2000 -> reward: 134.94270833333323, steps:5604, time-taken: 1.97min, time-elasped: 181.19min
-> berries picked: 97 of 800 | patches-visited: [0, 2, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3471 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [368, 560, 352, 364, 333, 395, 447, 432, 220]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 14, 12, 15, 9, 15, 9, 6, 13]
	Time taken saving stuff: 0.00s

=== episode:112 Env-steps-taken:75744
 	picked: 97 |actions: {0: 491, 1: 777, 2: 615, 3: 738, 4: 615, 5: 633, 6: 625, 7: 491, 8: 465}
episode: 112/2000 -> reward: 138.5572916666666, steps:5450, time-taken: 1.89min, time-elasped: 183.08min
-> berries picked: 97 of 800 | patches-visited: [0, 3, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3488 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [353, 567, 356, 372, 330, 402, 452, 435, 221]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 22, 10, 12, 8, 10, 9, 16, 10]
	Time taken saving stuff: 0.00s

=== episode:113 Env-steps-taken:75744
 	picked: 102 |actions: {0: 657, 1: 722, 2: 588, 3: 560, 4: 419, 5: 527, 6: 809, 7: 614, 8: 343}
episode: 113/2000 -> reward: 139.15624999999994, steps:5239, time-taken: 1.81min, time-elasped: 184.90min
-> berries picked: 102 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3513 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [353, 568, 368, 374, 323, 409, 453, 441, 224]
	| approx positives in sample 512: 90
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 17, 13, 12, 4, 12, 9, 8, 4]
	Time taken saving stuff: 0.00s

=== episode:114 Env-steps-taken:70368
 	picked: 79 |actions: {0: 410, 1: 435, 2: 407, 3: 530, 4: 448, 5: 385, 6: 476, 7: 362, 8: 308}
episode: 114/2000 -> reward: 112.9739583333332, steps:3761, time-taken: 1.38min, time-elasped: 186.28min
-> berries picked: 79 of 800 | patches-visited: [0, 5, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3522 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [349, 570, 376, 381, 319, 415, 452, 436, 224]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 20, 15, 9, 6, 7, 10, 15, 13]
	Time taken saving stuff: 0.00s

=== episode:115 Env-steps-taken:65952
 	picked: 63 |actions: {0: 502, 1: 704, 2: 584, 3: 478, 4: 529, 5: 551, 6: 677, 7: 369, 8: 430}
episode: 115/2000 -> reward: 89.00520833333327, steps:4824, time-taken: 1.63min, time-elasped: 187.92min
-> berries picked: 63 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3532 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [350, 570, 378, 384, 318, 419, 457, 430, 226]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 17, 11, 17, 10, 9, 10, 14, 10]
	Time taken saving stuff: 0.00s

=== episode:116 Env-steps-taken:55872
 	picked: 28 |actions: {0: 191, 1: 199, 2: 325, 3: 265, 4: 154, 5: 193, 6: 188, 7: 204, 8: 382}
episode: 116/2000 -> reward: 39.895833333333336, steps:2101, time-taken: 0.89min, time-elasped: 188.81min
-> berries picked: 28 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3528 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [350, 571, 377, 384, 320, 417, 456, 426, 227]
	| approx positives in sample 512: 88
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 11, 12, 7, 9, 11, 12, 12, 7]
	Time taken saving stuff: 0.00s

=== episode:117 Env-steps-taken:65952
 	picked: 65 |actions: {0: 446, 1: 409, 2: 449, 3: 553, 4: 512, 5: 498, 6: 501, 7: 307, 8: 488}
episode: 117/2000 -> reward: 90.7760416666666, steps:4163, time-taken: 1.48min, time-elasped: 190.30min
-> berries picked: 65 of 800 | patches-visited: [0, 1, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3519 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [349, 561, 378, 387, 324, 415, 451, 425, 229]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 18, 11, 10, 13, 11, 11, 16, 11]
	Time taken saving stuff: 0.00s

=== episode:118 Env-steps-taken:70080
 	picked: 88 |actions: {0: 636, 1: 651, 2: 594, 3: 605, 4: 755, 5: 516, 6: 753, 7: 530, 8: 574}
episode: 118/2000 -> reward: 110.45833333333319, steps:5614, time-taken: 1.91min, time-elasped: 192.21min
-> berries picked: 88 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3510 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [336, 553, 378, 385, 335, 416, 453, 422, 232]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 15, 9, 8, 10, 7, 17, 19, 15]
	Time taken saving stuff: 0.00s

=== episode:119 Env-steps-taken:66048
 	picked: 65 |actions: {0: 439, 1: 633, 2: 517, 3: 484, 4: 547, 5: 289, 6: 434, 7: 417, 8: 418}
episode: 119/2000 -> reward: 90.77604166666661, steps:4178, time-taken: 1.52min, time-elasped: 193.73min
-> berries picked: 65 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3500 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [328, 557, 373, 383, 337, 420, 450, 419, 233]
	| approx positives in sample 512: 101
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 15, 11, 9, 11, 10, 13, 10, 15]
	Time taken saving stuff: 0.00s

=== episode:120 Env-steps-taken:77088
 	picked: 104 |actions: {0: 521, 1: 837, 2: 799, 3: 831, 4: 877, 5: 537, 6: 698, 7: 562, 8: 571}
episode: 120/2000 -> reward: 146.04166666666669, steps:6233, time-taken: 2.07min, time-elasped: 195.80min
-> berries picked: 104 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3505 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [321, 553, 382, 386, 345, 424, 446, 414, 234]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 16, 17, 8, 5, 5, 12, 12, 14]
	Time taken saving stuff: 0.05s

=== episode:12 Env-steps-taken:52512
 	picked: 18 |actions: {0: 2730, 1: 2, 2: 26, 3: 4, 4: 148, 5: 42, 6: 1083, 7: 727, 8: 12}

==================================================
eval-episode: 120 -> reward: 22.468749999999993, steps: 4774.0, wall-time: 17.83s
-> berries picked: 18 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:121 Env-steps-taken:62784
 	picked: 51 |actions: {0: 272, 1: 384, 2: 297, 3: 331, 4: 488, 5: 332, 6: 505, 7: 339, 8: 292}
episode: 121/2000 -> reward: 74.57812500000001, steps:3240, time-taken: 1.21min, time-elasped: 197.30min
-> berries picked: 51 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3489 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [312, 548, 381, 383, 349, 426, 448, 408, 234]
	| approx positives in sample 512: 92
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 19, 4, 3, 9, 15, 11, 16, 6]
	Time taken saving stuff: 0.00s

=== episode:122 Env-steps-taken:73536
 	picked: 95 |actions: {0: 502, 1: 801, 2: 615, 3: 711, 4: 832, 5: 476, 6: 942, 7: 601, 8: 588}
episode: 122/2000 -> reward: 128.05729166666652, steps:6068, time-taken: 2.01min, time-elasped: 199.31min
-> berries picked: 95 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3480 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [295, 544, 382, 393, 357, 426, 441, 411, 231]
	| approx positives in sample 512: 71
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 5, 7, 4, 9, 10, 6, 9, 15]
	Time taken saving stuff: 0.00s

=== episode:123 Env-steps-taken:63936
 	picked: 65 |actions: {0: 399, 1: 641, 2: 490, 3: 604, 4: 566, 5: 526, 6: 751, 7: 485, 8: 538}
episode: 123/2000 -> reward: 79.77604166666666, steps:5000, time-taken: 1.72min, time-elasped: 201.04min
-> berries picked: 65 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3472 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [290, 535, 378, 393, 366, 425, 444, 410, 231]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 25, 11, 14, 10, 12, 12, 11, 12]
	Time taken saving stuff: 0.00s

=== episode:124 Env-steps-taken:63552
 	picked: 59 |actions: {0: 274, 1: 351, 2: 309, 3: 391, 4: 433, 5: 430, 6: 481, 7: 313, 8: 506}
episode: 124/2000 -> reward: 77.234375, steps:3488, time-taken: 1.29min, time-elasped: 202.32min
-> berries picked: 59 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3485 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [290, 535, 377, 399, 377, 423, 446, 406, 232]
	| approx positives in sample 512: 94
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 13, 12, 10, 10, 9, 12, 10, 13]
	Time taken saving stuff: 0.00s

=== episode:125 Env-steps-taken:61632
 	picked: 54 |actions: {0: 367, 1: 604, 2: 417, 3: 393, 4: 451, 5: 373, 6: 536, 7: 380, 8: 372}
episode: 125/2000 -> reward: 68.40625000000004, steps:3893, time-taken: 1.31min, time-elasped: 203.63min
-> berries picked: 54 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3466 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [286, 531, 371, 392, 382, 425, 440, 407, 232]
	| approx positives in sample 512: 96
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 10, 15, 11, 13, 5, 16, 6, 14]
	Time taken saving stuff: 0.00s

=== episode:126 Env-steps-taken:77568
 	picked: 110 |actions: {0: 621, 1: 724, 2: 622, 3: 608, 4: 628, 5: 795, 6: 751, 7: 538, 8: 491}
episode: 126/2000 -> reward: 147.8125, steps:5778, time-taken: 2.00min, time-elasped: 205.63min
-> berries picked: 110 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3468 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [296, 522, 362, 385, 389, 425, 451, 405, 233]
	| approx positives in sample 512: 87
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 7, 10, 13, 11, 9, 11, 7, 13]
	Time taken saving stuff: 0.00s

=== episode:127 Env-steps-taken:64128
 	picked: 67 |actions: {0: 404, 1: 578, 2: 574, 3: 646, 4: 638, 5: 485, 6: 677, 7: 434, 8: 541}
episode: 127/2000 -> reward: 80.16145833333333, steps:4977, time-taken: 1.62min, time-elasped: 207.25min
-> berries picked: 67 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3452 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [292, 524, 365, 381, 381, 427, 455, 395, 232]
	| approx positives in sample 512: 86
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 14, 6, 10, 9, 8, 9, 12, 7]
	Time taken saving stuff: 0.00s

=== episode:128 Env-steps-taken:70560
 	picked: 79 |actions: {0: 482, 1: 606, 2: 861, 3: 671, 4: 762, 5: 512, 6: 836, 7: 579, 8: 879}
episode: 128/2000 -> reward: 113.47395833333321, steps:6188, time-taken: 2.03min, time-elasped: 209.28min
-> berries picked: 79 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3441 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [291, 518, 363, 382, 381, 429, 456, 388, 233]
	| approx positives in sample 512: 85
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 12, 8, 8, 8, 16, 9, 11, 5]
	Time taken saving stuff: 0.00s

=== episode:129 Env-steps-taken:57504
 	picked: 30 |actions: {0: 149, 1: 188, 2: 185, 3: 187, 4: 233, 5: 129, 6: 274, 7: 184, 8: 149}
episode: 129/2000 -> reward: 47.78125000000002, steps:1678, time-taken: 0.72min, time-elasped: 210.01min
-> berries picked: 30 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3439 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [290, 516, 361, 380, 381, 427, 460, 391, 233]
	| approx positives in sample 512: 80
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 12, 8, 7, 6, 8, 12, 12, 10]
	Time taken saving stuff: 0.00s

=== episode:130 Env-steps-taken:72384
 	picked: 89 |actions: {0: 431, 1: 631, 2: 545, 3: 518, 4: 781, 5: 537, 6: 731, 7: 449, 8: 437}
episode: 130/2000 -> reward: 122.40104166666653, steps:5060, time-taken: 1.74min, time-elasped: 211.75min
-> berries picked: 89 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3463 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [292, 518, 361, 384, 376, 436, 461, 399, 236]
	| approx positives in sample 512: 87
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 11, 8, 5, 10, 14, 12, 10, 10]
	Time taken saving stuff: 0.05s

=== episode:13 Env-steps-taken:87456
 	picked: 149 |actions: {0: 474, 1: 322, 2: 929, 3: 253, 4: 1058, 5: 595, 6: 1126, 7: 323, 8: 1495}

==================================================
eval-episode: 130 -> reward: 197.96354166666703, steps: 6575.0, wall-time: 43.84s
-> berries picked: 149 of 800 | patches-visited: [1, 2, 5] | juice left:-0.00
==================================================


=== episode:131 Env-steps-taken:72672
 	picked: 97 |actions: {0: 611, 1: 752, 2: 654, 3: 594, 4: 709, 5: 686, 6: 651, 7: 556, 8: 538}
episode: 131/2000 -> reward: 123.44270833333312, steps:5751, time-taken: 1.95min, time-elasped: 214.43min
-> berries picked: 97 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3443 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [294, 512, 351, 375, 375, 438, 464, 398, 236]
	| approx positives in sample 512: 87
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 11, 10, 5, 6, 11, 13, 13, 9]
	Time taken saving stuff: 0.00s

=== episode:132 Env-steps-taken:63648
 	picked: 57 |actions: {0: 499, 1: 615, 2: 481, 3: 463, 4: 554, 5: 373, 6: 380, 7: 334, 8: 365}
episode: 132/2000 -> reward: 78.23437499999999, steps:4064, time-taken: 1.45min, time-elasped: 215.88min
-> berries picked: 57 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3444 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [298, 505, 350, 381, 373, 437, 464, 400, 236]
	| approx positives in sample 512: 80
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 7, 11, 8, 13, 8, 8, 7, 11]
	Time taken saving stuff: 0.00s

=== episode:133 Env-steps-taken:71808
 	picked: 89 |actions: {0: 533, 1: 786, 2: 922, 3: 647, 4: 581, 5: 542, 6: 716, 7: 560, 8: 582}
episode: 133/2000 -> reward: 119.40104166666652, steps:5869, time-taken: 2.00min, time-elasped: 217.88min
-> berries picked: 89 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3446 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [295, 505, 351, 378, 379, 435, 462, 404, 237]
	| approx positives in sample 512: 77
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 14, 8, 10, 9, 9, 9, 6, 9]
	Time taken saving stuff: 0.00s

=== episode:134 Env-steps-taken:64992
 	picked: 70 |actions: {0: 451, 1: 495, 2: 872, 3: 606, 4: 770, 5: 542, 6: 626, 7: 493, 8: 673}
episode: 134/2000 -> reward: 84.48958333333327, steps:5528, time-taken: 1.90min, time-elasped: 219.79min
-> berries picked: 70 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3443 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [278, 506, 351, 378, 385, 434, 468, 406, 237]
	| approx positives in sample 512: 74
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 7, 6, 10, 10, 6, 8, 14, 6]
	Time taken saving stuff: 0.00s

=== episode:135 Env-steps-taken:63552
 	picked: 53 |actions: {0: 547, 1: 606, 2: 651, 3: 643, 4: 733, 5: 498, 6: 520, 7: 499, 8: 679}
episode: 135/2000 -> reward: 78.46354166666667, steps:5376, time-taken: 1.78min, time-elasped: 221.57min
-> berries picked: 53 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3433 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [284, 500, 346, 377, 381, 433, 469, 403, 240]
	| approx positives in sample 512: 92
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 11, 10, 8, 5, 15, 14, 11, 11]
	Time taken saving stuff: 0.00s

=== episode:136 Env-steps-taken:72096
 	picked: 93 |actions: {0: 548, 1: 804, 2: 774, 3: 788, 4: 752, 5: 568, 6: 798, 7: 554, 8: 583}
episode: 136/2000 -> reward: 120.67187499999984, steps:6169, time-taken: 2.01min, time-elasped: 223.59min
-> berries picked: 93 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3437 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [283, 498, 348, 388, 379, 427, 471, 403, 240]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 15, 6, 17, 12, 15, 9, 10, 10]
	Time taken saving stuff: 0.01s

=== episode:137 Env-steps-taken:70656
 	picked: 80 |actions: {0: 466, 1: 537, 2: 584, 3: 672, 4: 708, 5: 647, 6: 561, 7: 432, 8: 729}
episode: 137/2000 -> reward: 114.41666666666654, steps:5336, time-taken: 1.80min, time-elasped: 225.39min
-> berries picked: 80 of 800 | patches-visited: [0, 2, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3444 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [278, 498, 343, 393, 387, 429, 470, 404, 242]
	| approx positives in sample 512: 92
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 17, 7, 11, 4, 6, 18, 14, 9]
	Time taken saving stuff: 0.00s

=== episode:138 Env-steps-taken:64992
 	picked: 58 |actions: {0: 373, 1: 531, 2: 648, 3: 488, 4: 514, 5: 435, 6: 689, 7: 379, 8: 449}
episode: 138/2000 -> reward: 85.67708333333329, steps:4506, time-taken: 1.58min, time-elasped: 226.98min
-> berries picked: 58 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3454 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [277, 495, 344, 393, 387, 433, 470, 410, 245]
	| approx positives in sample 512: 90
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 17, 5, 8, 13, 8, 9, 13, 11]
	Time taken saving stuff: 0.00s

=== episode:139 Env-steps-taken:61920
 	picked: 47 |actions: {0: 265, 1: 285, 2: 268, 3: 269, 4: 242, 5: 202, 6: 404, 7: 331, 8: 242}
episode: 139/2000 -> reward: 70.3072916666667, steps:2508, time-taken: 1.02min, time-elasped: 228.00min
-> berries picked: 47 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3462 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [279, 494, 340, 390, 385, 435, 475, 417, 247]
	| approx positives in sample 512: 79
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 19, 11, 6, 3, 10, 8, 8, 7]
	Time taken saving stuff: 0.00s

=== episode:140 Env-steps-taken:69120
 	picked: 79 |actions: {0: 456, 1: 554, 2: 645, 3: 683, 4: 845, 5: 632, 6: 724, 7: 517, 8: 562}
episode: 140/2000 -> reward: 105.97395833333326, steps:5618, time-taken: 1.82min, time-elasped: 229.82min
-> berries picked: 79 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3473 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [275, 488, 344, 387, 392, 437, 486, 415, 249]
	| approx positives in sample 512: 95
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 16, 5, 9, 13, 19, 9, 5, 13]
	Time taken saving stuff: 0.05s

=== episode:14 Env-steps-taken:75744
 	picked: 98 |actions: {0: 300, 1: 362, 2: 251, 3: 412, 4: 384, 5: 226, 6: 379, 7: 218, 8: 458}

==================================================
eval-episode: 140 -> reward: 139.8854166666666, steps: 2990.0, wall-time: 31.39s
-> berries picked: 98 of 800 | patches-visited: [0, 1, 3] | juice left:-0.00
==================================================


=== episode:141 Env-steps-taken:67776
 	picked: 69 |actions: {0: 436, 1: 561, 2: 532, 3: 332, 4: 416, 5: 404, 6: 553, 7: 409, 8: 383}
episode: 141/2000 -> reward: 100.04687499999993, steps:4026, time-taken: 1.49min, time-elasped: 231.84min
-> berries picked: 69 of 800 | patches-visited: [0, 3, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3501 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [278, 489, 344, 390, 394, 441, 490, 423, 252]
	| approx positives in sample 512: 82
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 8, 5, 8, 7, 15, 11, 10, 8]
	Time taken saving stuff: 0.00s

=== episode:142 Env-steps-taken:59616
 	picked: 44 |actions: {0: 344, 1: 332, 2: 273, 3: 331, 4: 448, 5: 382, 6: 432, 7: 209, 8: 388}
episode: 142/2000 -> reward: 56.036458333333364, steps:3139, time-taken: 1.54min, time-elasped: 233.39min
-> berries picked: 44 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3496 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [275, 486, 343, 395, 396, 443, 489, 416, 253]
	| approx positives in sample 512: 94
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 6, 10, 14, 6, 11, 18, 13, 11]
	Time taken saving stuff: 0.00s

=== episode:143 Env-steps-taken:66432
 	picked: 70 |actions: {0: 420, 1: 474, 2: 699, 3: 654, 4: 662, 5: 588, 6: 912, 7: 461, 8: 720}
episode: 143/2000 -> reward: 90.04687499999996, steps:5590, time-taken: 1.85min, time-elasped: 235.24min
-> berries picked: 70 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3501 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [268, 486, 343, 400, 396, 450, 492, 413, 253]
	| approx positives in sample 512: 76
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 11, 8, 10, 6, 4, 7, 11, 13]
	Time taken saving stuff: 0.00s

=== episode:144 Env-steps-taken:53760
 	picked: 20 |actions: {0: 99, 1: 98, 2: 77, 3: 123, 4: 160, 5: 166, 6: 187, 7: 78, 8: 238}
episode: 144/2000 -> reward: 29.354166666666668, steps:1226, time-taken: 0.65min, time-elasped: 235.89min
-> berries picked: 20 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3503 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [267, 482, 344, 400, 400, 452, 493, 411, 254]
	| approx positives in sample 512: 94
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 10, 14, 8, 13, 12, 17, 9, 6]
	Time taken saving stuff: 0.00s

=== episode:145 Env-steps-taken:62496
 	picked: 53 |actions: {0: 346, 1: 350, 2: 602, 3: 470, 4: 445, 5: 462, 6: 435, 7: 342, 8: 354}
episode: 145/2000 -> reward: 72.9635416666667, steps:3806, time-taken: 1.39min, time-elasped: 237.29min
-> berries picked: 53 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3510 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [269, 479, 343, 407, 406, 453, 488, 410, 255]
	| approx positives in sample 512: 90
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 5, 5, 13, 9, 14, 14, 13, 12]
	Time taken saving stuff: 0.00s

=== episode:146 Env-steps-taken:63744
 	picked: 57 |actions: {0: 349, 1: 391, 2: 351, 3: 424, 4: 376, 5: 269, 6: 320, 7: 262, 8: 257}
episode: 146/2000 -> reward: 79.234375, steps:2999, time-taken: 1.23min, time-elasped: 238.52min
-> berries picked: 57 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3527 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [269, 478, 346, 413, 412, 450, 492, 408, 259]
	| approx positives in sample 512: 91
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 8, 13, 9, 9, 10, 12, 12, 9]
	Time taken saving stuff: 0.00s

=== episode:147 Env-steps-taken:69408
 	picked: 77 |actions: {0: 373, 1: 492, 2: 712, 3: 656, 4: 622, 5: 627, 6: 624, 7: 472, 8: 618}
episode: 147/2000 -> reward: 107.58854166666654, steps:5196, time-taken: 1.72min, time-elasped: 240.24min
-> berries picked: 77 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3537 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [266, 475, 351, 417, 414, 460, 491, 404, 259]
	| approx positives in sample 512: 85
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 5, 13, 10, 9, 10, 14, 7, 11]
	Time taken saving stuff: 0.00s

=== episode:148 Env-steps-taken:56928
 	picked: 34 |actions: {0: 273, 1: 315, 2: 321, 3: 239, 4: 280, 5: 244, 6: 284, 7: 205, 8: 357}
episode: 148/2000 -> reward: 45.05208333333337, steps:2518, time-taken: 1.02min, time-elasped: 241.27min
-> berries picked: 34 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3548 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [265, 475, 353, 417, 418, 462, 494, 405, 259]
	| approx positives in sample 512: 91
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 7, 13, 8, 9, 13, 10, 14, 13]
	Time taken saving stuff: 0.00s

=== episode:149 Env-steps-taken:70848
 	picked: 85 |actions: {0: 452, 1: 532, 2: 518, 3: 468, 4: 611, 5: 583, 6: 575, 7: 556, 8: 353}
episode: 149/2000 -> reward: 114.63020833333319, steps:4648, time-taken: 1.66min, time-elasped: 242.93min
-> berries picked: 85 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3580 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [268, 467, 354, 424, 420, 475, 500, 411, 261]
	| approx positives in sample 512: 88
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 10, 8, 12, 10, 11, 15, 8, 7]
	Time taken saving stuff: 0.00s

=== episode:150 Env-steps-taken:60480
 	picked: 47 |actions: {0: 238, 1: 284, 2: 289, 3: 300, 4: 313, 5: 237, 6: 273, 7: 264, 8: 278}
episode: 150/2000 -> reward: 62.80729166666672, steps:2476, time-taken: 1.00min, time-elasped: 243.94min
-> berries picked: 47 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3597 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [269, 469, 359, 430, 421, 473, 503, 411, 262]
	| approx positives in sample 512: 100
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 19, 10, 9, 11, 12, 17, 8, 8]
	Time taken saving stuff: 0.05s

=== episode:15 Env-steps-taken:66048
 	picked: 63 |actions: {0: 290, 1: 142, 2: 898, 3: 163, 4: 409, 5: 93, 6: 735, 7: 115, 8: 288}

==================================================
eval-episode: 150 -> reward: 90.89062499999997, steps: 3133.0, wall-time: 30.04s
-> berries picked: 63 of 800 | patches-visited: [1, 4] | juice left:-0.00
==================================================


=== episode:151 Env-steps-taken:56256
 	picked: 31 |actions: {0: 178, 1: 321, 2: 334, 3: 180, 4: 370, 5: 321, 6: 231, 7: 270, 8: 260}
episode: 151/2000 -> reward: 41.22395833333335, steps:2465, time-taken: 0.96min, time-elasped: 245.40min
-> berries picked: 31 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3607 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [268, 471, 363, 429, 423, 477, 506, 409, 261]
	| approx positives in sample 512: 83
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 10, 5, 7, 7, 14, 13, 6, 17]
	Time taken saving stuff: 0.00s

=== episode:152 Env-steps-taken:60384
 	picked: 55 |actions: {0: 386, 1: 457, 2: 570, 3: 517, 4: 645, 5: 495, 6: 510, 7: 408, 8: 497}
episode: 152/2000 -> reward: 61.3489583333334, steps:4485, time-taken: 1.52min, time-elasped: 246.92min
-> berries picked: 55 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3625 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [269, 470, 365, 431, 425, 482, 511, 410, 262]
	| approx positives in sample 512: 85
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 12, 11, 7, 9, 11, 8, 11, 9]
	Time taken saving stuff: 0.00s

=== episode:153 Env-steps-taken:61056
 	picked: 50 |actions: {0: 206, 1: 231, 2: 279, 3: 331, 4: 464, 5: 347, 6: 335, 7: 291, 8: 278}
episode: 153/2000 -> reward: 64.25000000000004, steps:2762, time-taken: 1.06min, time-elasped: 247.98min
-> berries picked: 50 of 800 | patches-visited: [0, 8, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3638 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [269, 467, 368, 435, 422, 488, 519, 407, 263]
	| approx positives in sample 512: 74
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 15, 6, 12, 6, 4, 7, 11, 5]
	Time taken saving stuff: 0.00s

=== episode:154 Env-steps-taken:71040
 	picked: 85 |actions: {0: 498, 1: 709, 2: 778, 3: 690, 4: 815, 5: 608, 6: 608, 7: 506, 8: 570}
episode: 154/2000 -> reward: 115.63020833333319, steps:5782, time-taken: 1.97min, time-elasped: 249.95min
-> berries picked: 85 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3662 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [265, 468, 378, 438, 429, 492, 523, 406, 263]
	| approx positives in sample 512: 82
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 13, 5, 10, 9, 12, 12, 9, 8]
	Time taken saving stuff: 0.00s

=== episode:155 Env-steps-taken:51360
 	picked: 13 |actions: {0: 59, 1: 99, 2: 111, 3: 169, 4: 149, 5: 83, 6: 86, 7: 102, 8: 294}
episode: 155/2000 -> reward: 17.255208333333336, steps:1152, time-taken: 0.61min, time-elasped: 250.56min
-> berries picked: 13 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3657 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [266, 465, 373, 439, 431, 492, 523, 404, 264]
	| approx positives in sample 512: 100
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 10, 5, 13, 10, 7, 21, 13, 16]
	Time taken saving stuff: 0.00s

=== episode:156 Env-steps-taken:69312
 	picked: 74 |actions: {0: 382, 1: 357, 2: 342, 3: 401, 4: 353, 5: 455, 6: 403, 7: 417, 8: 389}
episode: 156/2000 -> reward: 107.26041666666657, steps:3499, time-taken: 1.26min, time-elasped: 251.83min
-> berries picked: 74 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3680 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [265, 466, 374, 440, 433, 500, 528, 409, 265]
	| approx positives in sample 512: 96
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [2, 12, 6, 13, 8, 11, 20, 12, 12]
	Time taken saving stuff: 0.00s

=== episode:157 Env-steps-taken:61632
 	picked: 49 |actions: {0: 372, 1: 374, 2: 527, 3: 495, 4: 825, 5: 569, 6: 568, 7: 367, 8: 617}
episode: 157/2000 -> reward: 68.19270833333334, steps:4714, time-taken: 1.63min, time-elasped: 253.46min
-> berries picked: 49 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3674 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [265, 458, 369, 435, 443, 504, 532, 403, 265]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 18, 9, 10, 14, 23, 9, 8, 5]
	Time taken saving stuff: 0.00s

=== episode:158 Env-steps-taken:70464
 	picked: 82 |actions: {0: 486, 1: 597, 2: 732, 3: 646, 4: 699, 5: 572, 6: 610, 7: 436, 8: 433}
episode: 158/2000 -> reward: 112.8020833333332, steps:5211, time-taken: 1.78min, time-elasped: 255.24min
-> berries picked: 82 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3693 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [259, 460, 370, 440, 445, 508, 539, 405, 267]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 11, 14, 13, 5, 20, 14, 10, 15]
	Time taken saving stuff: 0.00s

=== episode:159 Env-steps-taken:72576
 	picked: 90 |actions: {0: 523, 1: 693, 2: 814, 3: 759, 4: 671, 5: 617, 6: 706, 7: 516, 8: 515}
episode: 159/2000 -> reward: 121.40104166666652, steps:5814, time-taken: 1.96min, time-elasped: 257.21min
-> berries picked: 90 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3715 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [253, 461, 375, 449, 449, 509, 542, 408, 269]
	| approx positives in sample 512: 94
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 12, 10, 13, 8, 11, 12, 11, 8]
	Time taken saving stuff: 0.00s

=== episode:160 Env-steps-taken:65568
 	picked: 68 |actions: {0: 458, 1: 448, 2: 463, 3: 625, 4: 765, 5: 588, 6: 582, 7: 477, 8: 516}
episode: 160/2000 -> reward: 88.10416666666663, steps:4922, time-taken: 1.59min, time-elasped: 258.80min
-> berries picked: 68 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3728 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [247, 463, 371, 452, 459, 515, 543, 408, 270]
	| approx positives in sample 512: 100
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 15, 8, 4, 7, 24, 9, 10, 17]
	Time taken saving stuff: 0.05s

=== episode:16 Env-steps-taken:64608
 	picked: 61 |actions: {0: 561, 1: 226, 2: 459, 3: 150, 4: 764, 5: 178, 6: 287, 7: 48, 8: 115}

==================================================
eval-episode: 160 -> reward: 81.61979166666664, steps: 2788.0, wall-time: 29.35s
-> berries picked: 61 of 800 | patches-visited: [0, 1] | juice left:-0.00
==================================================


=== episode:161 Env-steps-taken:65472
 	picked: 65 |actions: {0: 296, 1: 425, 2: 428, 3: 395, 4: 580, 5: 514, 6: 412, 7: 404, 8: 319}
episode: 161/2000 -> reward: 87.39062499999996, steps:3773, time-taken: 1.34min, time-elasped: 260.63min
-> berries picked: 65 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3747 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [243, 460, 375, 457, 460, 524, 545, 409, 274]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 8, 8, 15, 17, 17, 11, 16, 8]
	Time taken saving stuff: 0.00s

=== episode:162 Env-steps-taken:72384
 	picked: 86 |actions: {0: 656, 1: 703, 2: 742, 3: 560, 4: 664, 5: 562, 6: 628, 7: 528, 8: 497}
episode: 162/2000 -> reward: 122.57291666666653, steps:5540, time-taken: 1.96min, time-elasped: 262.59min
-> berries picked: 86 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3763 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [243, 471, 381, 449, 450, 527, 554, 414, 274]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 16, 14, 14, 14, 13, 15, 12, 11]
	Time taken saving stuff: 0.00s

=== episode:163 Env-steps-taken:70080
 	picked: 76 |actions: {0: 529, 1: 647, 2: 566, 3: 736, 4: 547, 5: 537, 6: 772, 7: 496, 8: 457}
episode: 163/2000 -> reward: 111.14583333333321, steps:5287, time-taken: 1.81min, time-elasped: 264.41min
-> berries picked: 76 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3789 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [238, 474, 384, 454, 456, 533, 558, 416, 276]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 14, 7, 12, 15, 10, 21, 13, 11]
	Time taken saving stuff: 0.00s

=== episode:164 Env-steps-taken:58272
 	picked: 37 |actions: {0: 234, 1: 322, 2: 241, 3: 288, 4: 281, 5: 161, 6: 162, 7: 179, 8: 181}
episode: 164/2000 -> reward: 51.88020833333337, steps:2049, time-taken: 0.89min, time-elasped: 265.30min
-> berries picked: 37 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3805 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [239, 476, 386, 451, 460, 537, 562, 417, 277]
	| approx positives in sample 512: 99
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 13, 6, 14, 10, 12, 11, 15, 12]
	Time taken saving stuff: 0.00s

=== episode:165 Env-steps-taken:56928
 	picked: 32 |actions: {0: 244, 1: 255, 2: 384, 3: 312, 4: 278, 5: 238, 6: 335, 7: 253, 8: 305}
episode: 165/2000 -> reward: 45.166666666666686, steps:2604, time-taken: 1.02min, time-elasped: 266.32min
-> berries picked: 32 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3812 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [237, 474, 391, 449, 462, 539, 562, 418, 280]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 9, 7, 15, 10, 14, 17, 15, 9]
	Time taken saving stuff: 0.00s

=== episode:166 Env-steps-taken:66144
 	picked: 66 |actions: {0: 453, 1: 614, 2: 532, 3: 670, 4: 492, 5: 523, 6: 633, 7: 515, 8: 446}
episode: 166/2000 -> reward: 91.21874999999994, steps:4878, time-taken: 1.69min, time-elasped: 268.01min
-> berries picked: 66 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3822 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [234, 471, 388, 455, 466, 544, 566, 417, 281]
	| approx positives in sample 512: 95
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 20, 12, 9, 9, 9, 13, 7, 9]
	Time taken saving stuff: 0.00s

=== episode:167 Env-steps-taken:70176
 	picked: 82 |actions: {0: 519, 1: 672, 2: 589, 3: 715, 4: 744, 5: 659, 6: 805, 7: 521, 8: 456}
episode: 167/2000 -> reward: 111.30208333333319, steps:5680, time-taken: 1.96min, time-elasped: 269.97min
-> berries picked: 82 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3850 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [236, 474, 384, 452, 471, 554, 577, 419, 283]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 10, 12, 15, 18, 15, 12, 12, 12]
	Time taken saving stuff: 0.00s

=== episode:168 Env-steps-taken:66624
 	picked: 66 |actions: {0: 374, 1: 537, 2: 587, 3: 473, 4: 568, 5: 387, 6: 600, 7: 415, 8: 316}
episode: 168/2000 -> reward: 93.71874999999994, steps:4257, time-taken: 1.56min, time-elasped: 271.54min
-> berries picked: 66 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3868 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [231, 474, 392, 455, 473, 557, 583, 419, 284]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 17, 11, 10, 15, 21, 13, 8, 7]
	Time taken saving stuff: 0.00s

=== episode:169 Env-steps-taken:64608
 	picked: 62 |actions: {0: 475, 1: 678, 2: 557, 3: 544, 4: 841, 5: 519, 6: 716, 7: 461, 8: 510}
episode: 169/2000 -> reward: 82.94791666666664, steps:5301, time-taken: 1.88min, time-elasped: 273.41min
-> berries picked: 62 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3890 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [229, 472, 395, 458, 479, 563, 588, 418, 288]
	| approx positives in sample 512: 94
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 9, 11, 13, 13, 15, 9, 6, 10]
	Time taken saving stuff: 0.00s

=== episode:170 Env-steps-taken:70848
 	picked: 94 |actions: {0: 439, 1: 643, 2: 554, 3: 561, 4: 817, 5: 468, 6: 698, 7: 440, 8: 338}
episode: 170/2000 -> reward: 114.61458333333314, steps:4958, time-taken: 1.80min, time-elasped: 275.21min
-> berries picked: 94 of 800 | patches-visited: [0, 5, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3933 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [230, 480, 394, 458, 493, 573, 593, 420, 292]
	| approx positives in sample 512: 100
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 12, 8, 8, 10, 18, 14, 11, 11]
	Time taken saving stuff: 0.05s

=== episode:17 Env-steps-taken:63264
 	picked: 60 |actions: {0: 292, 1: 554, 2: 58, 3: 1613, 4: 632, 5: 117, 6: 288, 7: 121, 8: 1810}

==================================================
eval-episode: 170 -> reward: 76.0625, steps: 5485.0, wall-time: 35.78s
-> berries picked: 60 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:171 Env-steps-taken:74976
 	picked: 102 |actions: {0: 527, 1: 610, 2: 598, 3: 735, 4: 688, 5: 676, 6: 871, 7: 581, 8: 605}
episode: 171/2000 -> reward: 135.65624999999986, steps:5891, time-taken: 2.07min, time-elasped: 277.88min
-> berries picked: 102 of 800 | patches-visited: [0, 3, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3931 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [222, 473, 386, 456, 495, 587, 601, 418, 293]
	| approx positives in sample 512: 86
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 10, 8, 14, 12, 10, 17, 6, 6]
	Time taken saving stuff: 0.00s

=== episode:172 Env-steps-taken:73440
 	picked: 90 |actions: {0: 542, 1: 585, 2: 552, 3: 388, 4: 598, 5: 470, 6: 547, 7: 422, 8: 372}
episode: 172/2000 -> reward: 126.95833333333316, steps:4476, time-taken: 1.63min, time-elasped: 279.51min
-> berries picked: 90 of 800 | patches-visited: [0, 1, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3960 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [229, 472, 390, 457, 492, 593, 607, 426, 294]
	| approx positives in sample 512: 96
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 12, 9, 9, 9, 13, 12, 11, 14]
	Time taken saving stuff: 0.00s

=== episode:173 Env-steps-taken:75360
 	picked: 99 |actions: {0: 559, 1: 535, 2: 508, 3: 670, 4: 731, 5: 482, 6: 624, 7: 612, 8: 489}
episode: 173/2000 -> reward: 138.3281249999999, steps:5210, time-taken: 1.88min, time-elasped: 281.40min
-> berries picked: 99 of 800 | patches-visited: [0, 3, 5, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3990 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [233, 471, 390, 462, 494, 595, 616, 433, 296]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 16, 14, 14, 12, 8, 14, 11, 7]
	Time taken saving stuff: 0.00s

=== episode:174 Env-steps-taken:69216
 	picked: 87 |actions: {0: 436, 1: 577, 2: 578, 3: 642, 4: 669, 5: 509, 6: 697, 7: 456, 8: 475}
episode: 174/2000 -> reward: 106.51562499999989, steps:5039, time-taken: 1.76min, time-elasped: 283.16min
-> berries picked: 87 of 800 | patches-visited: [0, 1, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4010 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [228, 471, 388, 465, 503, 600, 629, 432, 294]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 15, 10, 13, 14, 16, 14, 12, 8]
	Time taken saving stuff: 0.00s

=== episode:175 Env-steps-taken:72480
 	picked: 92 |actions: {0: 535, 1: 638, 2: 604, 3: 654, 4: 625, 5: 553, 6: 661, 7: 480, 8: 707}
episode: 175/2000 -> reward: 123.22916666666652, steps:5457, time-taken: 1.87min, time-elasped: 285.03min
-> berries picked: 92 of 800 | patches-visited: [0, 1, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4033 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [228, 468, 392, 469, 504, 607, 631, 436, 298]
	| approx positives in sample 512: 89
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 9, 6, 6, 13, 14, 16, 10, 10]
	Time taken saving stuff: 0.00s

=== episode:176 Env-steps-taken:73824
 	picked: 98 |actions: {0: 494, 1: 810, 2: 725, 3: 583, 4: 682, 5: 615, 6: 774, 7: 494, 8: 485}
episode: 176/2000 -> reward: 129.3854166666665, steps:5662, time-taken: 1.88min, time-elasped: 286.91min
-> berries picked: 98 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4066 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [233, 467, 395, 477, 501, 616, 634, 440, 303]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 17, 6, 12, 11, 13, 12, 13, 8]
	Time taken saving stuff: 0.00s

=== episode:177 Env-steps-taken:67488
 	picked: 69 |actions: {0: 407, 1: 586, 2: 528, 3: 477, 4: 509, 5: 470, 6: 729, 7: 496, 8: 605}
episode: 177/2000 -> reward: 98.04687499999993, steps:4807, time-taken: 1.67min, time-elasped: 288.59min
-> berries picked: 69 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4074 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [235, 461, 386, 478, 510, 620, 640, 441, 303]
	| approx positives in sample 512: 100
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 9, 13, 10, 10, 14, 16, 11, 10]
	Time taken saving stuff: 0.00s

=== episode:178 Env-steps-taken:73824
 	picked: 94 |actions: {0: 549, 1: 643, 2: 557, 3: 667, 4: 678, 5: 492, 6: 493, 7: 386, 8: 384}
episode: 178/2000 -> reward: 129.61458333333317, steps:4849, time-taken: 1.69min, time-elasped: 290.28min
-> berries picked: 94 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4099 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [235, 466, 388, 486, 519, 629, 635, 439, 302]
	| approx positives in sample 512: 76
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [2, 3, 5, 13, 12, 11, 8, 11, 11]
	Time taken saving stuff: 0.00s

=== episode:179 Env-steps-taken:66912
 	picked: 67 |actions: {0: 415, 1: 461, 2: 617, 3: 453, 4: 484, 5: 344, 6: 449, 7: 301, 8: 525}
episode: 179/2000 -> reward: 95.21874999999994, steps:4049, time-taken: 1.43min, time-elasped: 291.71min
-> berries picked: 67 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4117 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [243, 472, 386, 489, 518, 630, 636, 440, 303]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 4, 8, 7, 21, 13, 14, 14, 12]
	Time taken saving stuff: 0.00s

=== episode:180 Env-steps-taken:61344
 	picked: 49 |actions: {0: 230, 1: 286, 2: 315, 3: 378, 4: 287, 5: 306, 6: 402, 7: 201, 8: 368}
episode: 180/2000 -> reward: 67.69270833333337, steps:2773, time-taken: 1.11min, time-elasped: 292.82min
-> berries picked: 49 of 800 | patches-visited: [0, 3, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4121 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [240, 474, 386, 489, 519, 631, 637, 438, 307]
	| approx positives in sample 512: 94
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 12, 6, 13, 10, 12, 11, 11, 13]
	Time taken saving stuff: 0.05s

=== episode:18 Env-steps-taken:92352
 	picked: 163 |actions: {0: 323, 1: 1314, 2: 226, 3: 866, 4: 565, 5: 514, 6: 1032, 7: 404, 8: 411}

==================================================
eval-episode: 180 -> reward: 223.16145833333383, steps: 5655.0, wall-time: 42.66s
-> berries picked: 163 of 800 | patches-visited: [0, 1, 2, 3] | juice left:-0.00
==================================================


=== episode:181 Env-steps-taken:62976
 	picked: 61 |actions: {0: 496, 1: 324, 2: 376, 3: 522, 4: 411, 5: 505, 6: 555, 7: 331, 8: 336}
episode: 181/2000 -> reward: 75.00520833333337, steps:3856, time-taken: 1.38min, time-elasped: 294.91min
-> berries picked: 61 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4139 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [243, 468, 391, 490, 520, 637, 639, 441, 310]
	| approx positives in sample 512: 89
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 12, 9, 8, 11, 12, 14, 7, 10]
	Time taken saving stuff: 0.00s

=== episode:182 Env-steps-taken:69600
 	picked: 73 |actions: {0: 392, 1: 609, 2: 409, 3: 562, 4: 469, 5: 708, 6: 557, 7: 398, 8: 513}
episode: 182/2000 -> reward: 108.8177083333332, steps:4617, time-taken: 1.63min, time-elasped: 296.54min
-> berries picked: 73 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4153 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [236, 473, 397, 488, 519, 639, 646, 441, 314]
	| approx positives in sample 512: 99
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 11, 10, 8, 9, 22, 12, 15, 7]
	Time taken saving stuff: 0.00s

=== episode:183 Env-steps-taken:72384
 	picked: 83 |actions: {0: 483, 1: 659, 2: 693, 3: 565, 4: 535, 5: 464, 6: 491, 7: 398, 8: 553}
episode: 183/2000 -> reward: 123.24479166666653, steps:4841, time-taken: 1.72min, time-elasped: 298.27min
-> berries picked: 83 of 800 | patches-visited: [0, 4, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4180 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [241, 476, 405, 493, 520, 637, 653, 442, 313]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 18, 12, 12, 8, 12, 12, 11, 10]
	Time taken saving stuff: 0.00s

=== episode:184 Env-steps-taken:76032
 	picked: 94 |actions: {0: 523, 1: 496, 2: 640, 3: 650, 4: 661, 5: 813, 6: 659, 7: 497, 8: 556}
episode: 184/2000 -> reward: 139.67187499999991, steps:5495, time-taken: 1.91min, time-elasped: 300.18min
-> berries picked: 94 of 800 | patches-visited: [0, 2, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4218 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [238, 478, 411, 499, 528, 647, 657, 445, 315]
	| approx positives in sample 512: 78
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 9, 6, 7, 8, 11, 16, 7, 9]
	Time taken saving stuff: 0.00s

=== episode:185 Env-steps-taken:69216
 	picked: 78 |actions: {0: 430, 1: 628, 2: 460, 3: 493, 4: 416, 5: 513, 6: 671, 7: 369, 8: 441}
episode: 185/2000 -> reward: 107.0312499999999, steps:4421, time-taken: 1.60min, time-elasped: 301.78min
-> berries picked: 78 of 800 | patches-visited: [0, 1, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4249 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [231, 482, 416, 503, 529, 655, 670, 444, 319]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 14, 6, 19, 14, 13, 23, 6, 14]
	Time taken saving stuff: 0.00s

=== episode:186 Env-steps-taken:70656
 	picked: 84 |actions: {0: 393, 1: 468, 2: 657, 3: 510, 4: 495, 5: 511, 6: 697, 7: 373, 8: 527}
episode: 186/2000 -> reward: 113.68749999999989, steps:4631, time-taken: 1.61min, time-elasped: 303.40min
-> berries picked: 84 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4272 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [232, 480, 414, 508, 534, 668, 675, 438, 323]
	| approx positives in sample 512: 94
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 14, 4, 7, 10, 9, 15, 14, 14]
	Time taken saving stuff: 0.00s

=== episode:187 Env-steps-taken:74208
 	picked: 91 |actions: {0: 523, 1: 697, 2: 684, 3: 587, 4: 578, 5: 665, 6: 680, 7: 457, 8: 565}
episode: 187/2000 -> reward: 131.7864583333332, steps:5436, time-taken: 1.90min, time-elasped: 305.30min
-> berries picked: 91 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4306 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [231, 484, 421, 513, 529, 676, 685, 443, 324]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 12, 12, 14, 12, 20, 13, 11, 11]
	Time taken saving stuff: 0.00s

=== episode:188 Env-steps-taken:66912
 	picked: 72 |actions: {0: 427, 1: 528, 2: 474, 3: 352, 4: 372, 5: 434, 6: 425, 7: 427, 8: 512}
episode: 188/2000 -> reward: 94.87499999999991, steps:3951, time-taken: 1.45min, time-elasped: 306.75min
-> berries picked: 72 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4330 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [232, 487, 427, 518, 532, 678, 684, 445, 327]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 11, 17, 11, 10, 19, 9, 9, 11]
	Time taken saving stuff: 0.00s

=== episode:189 Env-steps-taken:78240
 	picked: 112 |actions: {0: 581, 1: 699, 2: 720, 3: 686, 4: 911, 5: 827, 6: 784, 7: 599, 8: 661}
episode: 189/2000 -> reward: 151.19791666666663, steps:6468, time-taken: 2.22min, time-elasped: 308.97min
-> berries picked: 112 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4371 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [234, 496, 432, 518, 544, 683, 685, 450, 329]
	| approx positives in sample 512: 88
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 10, 5, 14, 13, 13, 9, 7, 9]
	Time taken saving stuff: 0.00s

=== episode:190 Env-steps-taken:68544
 	picked: 75 |actions: {0: 398, 1: 438, 2: 451, 3: 479, 4: 489, 5: 532, 6: 631, 7: 383, 8: 461}
episode: 190/2000 -> reward: 101.26041666666657, steps:4262, time-taken: 1.57min, time-elasped: 310.55min
-> berries picked: 75 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4390 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [237, 494, 435, 524, 550, 682, 686, 451, 331]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 13, 18, 13, 9, 10, 13, 14, 8]
	Time taken saving stuff: 0.05s

=== episode:19 Env-steps-taken:93888
 	picked: 173 |actions: {0: 611, 1: 944, 2: 388, 3: 317, 4: 1076, 5: 259, 6: 881, 7: 456, 8: 943}

==================================================
eval-episode: 190 -> reward: 229.70312500000063, steps: 5875.0, wall-time: 42.54s
-> berries picked: 173 of 800 | patches-visited: [1, 2, 3, 5] | juice left:-0.00
==================================================


=== episode:191 Env-steps-taken:68160
 	picked: 68 |actions: {0: 337, 1: 478, 2: 499, 3: 562, 4: 377, 5: 378, 6: 400, 7: 380, 8: 339}
episode: 191/2000 -> reward: 99.66145833333327, steps:3750, time-taken: 1.37min, time-elasped: 312.63min
-> berries picked: 68 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4404 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [237, 502, 436, 533, 552, 678, 692, 442, 332]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 19, 10, 14, 11, 11, 13, 11, 13]
	Time taken saving stuff: 0.00s

=== episode:192 Env-steps-taken:74016
 	picked: 97 |actions: {0: 569, 1: 669, 2: 658, 3: 689, 4: 596, 5: 622, 6: 839, 7: 447, 8: 554}
episode: 192/2000 -> reward: 130.44270833333317, steps:5643, time-taken: 1.86min, time-elasped: 314.48min
-> berries picked: 97 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4418 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [238, 499, 443, 538, 546, 682, 693, 442, 337]
	| approx positives in sample 512: 95
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 12, 15, 10, 12, 8, 12, 9, 11]
	Time taken saving stuff: 0.00s

=== episode:193 Env-steps-taken:76896
 	picked: 114 |actions: {0: 603, 1: 829, 2: 777, 3: 685, 4: 635, 5: 643, 6: 813, 7: 580, 8: 493}
episode: 193/2000 -> reward: 144.46874999999997, steps:6058, time-taken: 2.00min, time-elasped: 316.49min
-> berries picked: 114 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4454 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [233, 495, 452, 542, 549, 685, 704, 454, 340]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 6, 10, 12, 9, 16, 17, 7, 17]
	Time taken saving stuff: 0.00s

=== episode:194 Env-steps-taken:73824
 	picked: 99 |actions: {0: 614, 1: 686, 2: 676, 3: 743, 4: 790, 5: 591, 6: 708, 7: 509, 8: 486}
episode: 194/2000 -> reward: 128.94270833333314, steps:5803, time-taken: 1.94min, time-elasped: 318.44min
-> berries picked: 99 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4457 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [230, 493, 463, 535, 555, 684, 703, 454, 340]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 13, 7, 12, 12, 15, 16, 7, 10]
	Time taken saving stuff: 0.00s

=== episode:195 Env-steps-taken:78048
 	picked: 105 |actions: {0: 446, 1: 613, 2: 643, 3: 660, 4: 580, 5: 774, 6: 838, 7: 561, 8: 475}
episode: 195/2000 -> reward: 150.98437499999997, steps:5590, time-taken: 1.96min, time-elasped: 320.40min
-> berries picked: 105 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4485 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [229, 499, 468, 545, 563, 685, 707, 446, 343]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 12, 8, 13, 9, 20, 10, 17, 12]
	Time taken saving stuff: 0.00s

=== episode:196 Env-steps-taken:71040
 	picked: 92 |actions: {0: 761, 1: 715, 2: 534, 3: 538, 4: 840, 5: 628, 6: 627, 7: 453, 8: 498}
episode: 196/2000 -> reward: 115.22916666666652, steps:5594, time-taken: 1.82min, time-elasped: 322.22min
-> berries picked: 92 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4486 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [227, 507, 468, 538, 559, 686, 706, 450, 345]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 8, 15, 9, 18, 16, 17, 8, 11]
	Time taken saving stuff: 0.00s

=== episode:197 Env-steps-taken:61632
 	picked: 53 |actions: {0: 318, 1: 334, 2: 382, 3: 418, 4: 349, 5: 402, 6: 542, 7: 275, 8: 338}
episode: 197/2000 -> reward: 67.9635416666667, steps:3358, time-taken: 1.25min, time-elasped: 323.48min
-> berries picked: 53 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4500 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [229, 506, 468, 542, 567, 685, 714, 445, 344]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 11, 11, 20, 10, 11, 16, 12, 13]
	Time taken saving stuff: 0.01s

=== episode:198 Env-steps-taken:77376
 	picked: 108 |actions: {0: 596, 1: 818, 2: 686, 3: 633, 4: 775, 5: 752, 6: 943, 7: 506, 8: 511}
episode: 198/2000 -> reward: 147.31249999999994, steps:6220, time-taken: 2.17min, time-elasped: 325.65min
-> berries picked: 108 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4528 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [232, 501, 476, 540, 572, 694, 723, 444, 346]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 9, 14, 14, 9, 14, 24, 7, 14]
	Time taken saving stuff: 0.00s

=== episode:199 Env-steps-taken:69504
 	picked: 76 |actions: {0: 407, 1: 620, 2: 496, 3: 659, 4: 513, 5: 673, 6: 659, 7: 385, 8: 353}
episode: 199/2000 -> reward: 108.14583333333326, steps:4765, time-taken: 1.69min, time-elasped: 327.34min
-> berries picked: 76 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4533 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [232, 495, 480, 541, 567, 702, 725, 443, 348]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 16, 4, 10, 14, 16, 19, 11, 12]
	Time taken saving stuff: 0.00s

=== episode:200 Env-steps-taken:59808
 	picked: 42 |actions: {0: 250, 1: 254, 2: 201, 3: 348, 4: 286, 5: 342, 6: 359, 7: 289, 8: 203}
episode: 200/2000 -> reward: 59.59375000000005, steps:2532, time-taken: 0.98min, time-elasped: 328.32min
-> berries picked: 42 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4552 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [233, 496, 479, 543, 572, 706, 725, 448, 350]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 10, 7, 13, 12, 18, 16, 15, 8]
	Time taken saving stuff: 0.05s

=== episode:20 Env-steps-taken:69696
 	picked: 81 |actions: {0: 372, 1: 1141, 2: 221, 3: 301, 4: 201, 5: 1024, 6: 302, 7: 279, 8: 100}

==================================================
eval-episode: 200 -> reward: 108.8593749999999, steps: 3941.0, wall-time: 31.69s
-> berries picked: 81 of 800 | patches-visited: [1, 3] | juice left:-0.00
==================================================


=== episode:201 Env-steps-taken:65664
 	picked: 67 |actions: {0: 452, 1: 379, 2: 463, 3: 516, 4: 554, 5: 496, 6: 524, 7: 399, 8: 357}
episode: 201/2000 -> reward: 88.6614583333333, steps:4140, time-taken: 1.43min, time-elasped: 330.28min
-> berries picked: 67 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4563 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [239, 494, 480, 543, 576, 703, 730, 449, 349]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 4, 13, 13, 8, 23, 16, 13, 14]
	Time taken saving stuff: 0.00s

=== episode:202 Env-steps-taken:51744
 	picked: 11 |actions: {0: 201, 1: 291, 2: 177, 3: 178, 4: 249, 5: 225, 6: 886, 7: 255, 8: 391}
episode: 202/2000 -> reward: 17.427083333333336, steps:2853, time-taken: 0.99min, time-elasped: 331.28min
-> berries picked: 11 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4536 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [234, 489, 477, 539, 573, 700, 729, 448, 347]
	| approx positives in sample 512: 100
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 10, 14, 13, 13, 15, 18, 3, 11]
	Time taken saving stuff: 0.00s

=== episode:203 Env-steps-taken:74304
 	picked: 84 |actions: {0: 435, 1: 493, 2: 473, 3: 408, 4: 571, 5: 569, 6: 435, 7: 472, 8: 326}
episode: 203/2000 -> reward: 131.3020833333332, steps:4182, time-taken: 1.56min, time-elasped: 332.84min
-> berries picked: 84 of 800 | patches-visited: [0, 4, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4563 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [232, 494, 484, 537, 576, 703, 734, 454, 349]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 12, 7, 12, 13, 16, 19, 12, 11]
	Time taken saving stuff: 0.00s

=== episode:204 Env-steps-taken:72672
 	picked: 90 |actions: {0: 475, 1: 658, 2: 615, 3: 632, 4: 587, 5: 578, 6: 651, 7: 517, 8: 413}
episode: 204/2000 -> reward: 123.45833333333316, steps:5126, time-taken: 1.83min, time-elasped: 334.67min
-> berries picked: 90 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4586 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [236, 493, 486, 546, 579, 706, 734, 454, 352]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 12, 12, 13, 16, 16, 10, 9, 11]
	Time taken saving stuff: 0.00s

=== episode:205 Env-steps-taken:81984
 	picked: 117 |actions: {0: 864, 1: 960, 2: 752, 3: 819, 4: 737, 5: 687, 6: 916, 7: 671, 8: 557}
episode: 205/2000 -> reward: 168.9114583333335, steps:6963, time-taken: 2.38min, time-elasped: 337.05min
-> berries picked: 117 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4617 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [242, 501, 493, 554, 572, 712, 734, 456, 353]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 8, 12, 11, 12, 13, 17, 14, 15]
	Time taken saving stuff: 0.00s

=== episode:206 Env-steps-taken:74880
 	picked: 98 |actions: {0: 628, 1: 886, 2: 537, 3: 544, 4: 544, 5: 663, 6: 662, 7: 526, 8: 403}
episode: 206/2000 -> reward: 134.88541666666657, steps:5393, time-taken: 1.84min, time-elasped: 338.89min
-> berries picked: 98 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4652 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [244, 509, 503, 554, 573, 716, 737, 459, 357]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 15, 10, 10, 15, 14, 10, 11, 12]
	Time taken saving stuff: 0.00s

=== episode:207 Env-steps-taken:62400
 	picked: 51 |actions: {0: 282, 1: 241, 2: 225, 3: 366, 4: 453, 5: 297, 6: 290, 7: 212, 8: 305}
episode: 207/2000 -> reward: 70.6354166666667, steps:2671, time-taken: 1.04min, time-elasped: 339.93min
-> berries picked: 51 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4663 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [249, 509, 501, 552, 574, 719, 739, 461, 359]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 13, 10, 7, 8, 23, 12, 11, 12]
	Time taken saving stuff: 0.00s

=== episode:208 Env-steps-taken:65376
 	picked: 70 |actions: {0: 387, 1: 598, 2: 802, 3: 629, 4: 538, 5: 598, 6: 552, 7: 347, 8: 721}
episode: 208/2000 -> reward: 86.48958333333329, steps:5172, time-taken: 1.74min, time-elasped: 341.68min
-> berries picked: 70 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4662 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [246, 509, 506, 550, 576, 716, 740, 460, 359]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 16, 10, 7, 15, 15, 12, 10, 7]
	Time taken saving stuff: 0.00s

=== episode:209 Env-steps-taken:71040
 	picked: 86 |actions: {0: 629, 1: 672, 2: 625, 3: 651, 4: 602, 5: 667, 6: 759, 7: 585, 8: 548}
episode: 209/2000 -> reward: 115.5729166666665, steps:5738, time-taken: 1.93min, time-elasped: 343.61min
-> berries picked: 86 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4683 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [250, 511, 514, 548, 576, 716, 745, 462, 361]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 9, 9, 14, 13, 10, 18, 12, 15]
	Time taken saving stuff: 0.00s

=== episode:210 Env-steps-taken:61536
 	picked: 44 |actions: {0: 330, 1: 469, 2: 505, 3: 553, 4: 362, 5: 504, 6: 507, 7: 350, 8: 479}
episode: 210/2000 -> reward: 68.47916666666671, steps:4059, time-taken: 1.46min, time-elasped: 345.07min
-> berries picked: 44 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4672 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [244, 512, 519, 542, 575, 718, 735, 466, 361]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 15, 12, 8, 9, 13, 18, 14, 12]
	Time taken saving stuff: 0.05s

=== episode:21 Env-steps-taken:65760
 	picked: 66 |actions: {0: 177, 1: 1120, 2: 102, 3: 239, 4: 212, 5: 994, 6: 198, 7: 256, 8: 59}

==================================================
eval-episode: 210 -> reward: 89.21874999999996, steps: 3357.0, wall-time: 30.10s
-> berries picked: 66 of 800 | patches-visited: [0, 1] | juice left:-0.00
==================================================


=== episode:211 Env-steps-taken:70656
 	picked: 88 |actions: {0: 519, 1: 705, 2: 558, 3: 564, 4: 497, 5: 800, 6: 654, 7: 539, 8: 418}
episode: 211/2000 -> reward: 113.45833333333319, steps:5254, time-taken: 1.86min, time-elasped: 347.43min
-> berries picked: 88 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4681 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [246, 517, 523, 541, 572, 723, 735, 459, 365]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 15, 9, 17, 10, 18, 14, 14, 7]
	Time taken saving stuff: 0.00s

=== episode:212 Env-steps-taken:73824
 	picked: 100 |actions: {0: 631, 1: 788, 2: 596, 3: 782, 4: 613, 5: 786, 6: 694, 7: 533, 8: 450}
episode: 212/2000 -> reward: 129.2708333333332, steps:5873, time-taken: 2.00min, time-elasped: 349.44min
-> berries picked: 100 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4687 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [241, 518, 526, 549, 572, 726, 730, 458, 367]
	| approx positives in sample 512: 101
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 11, 14, 15, 9, 15, 11, 8, 12]
	Time taken saving stuff: 0.00s

=== episode:213 Env-steps-taken:72384
 	picked: 84 |actions: {0: 567, 1: 615, 2: 672, 3: 611, 4: 523, 5: 715, 6: 792, 7: 502, 8: 557}
episode: 213/2000 -> reward: 120.74479166666654, steps:5554, time-taken: 1.91min, time-elasped: 351.35min
-> berries picked: 84 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4686 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [241, 525, 528, 546, 570, 718, 731, 458, 369]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 11, 14, 8, 13, 25, 11, 13, 9]
	Time taken saving stuff: 0.00s

=== episode:214 Env-steps-taken:74016
 	picked: 100 |actions: {0: 594, 1: 654, 2: 646, 3: 696, 4: 866, 5: 832, 6: 750, 7: 637, 8: 466}
episode: 214/2000 -> reward: 130.27083333333317, steps:6141, time-taken: 2.11min, time-elasped: 353.47min
-> berries picked: 100 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4710 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [242, 526, 533, 548, 568, 723, 732, 466, 372]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 16, 12, 13, 17, 14, 18, 9, 12]
	Time taken saving stuff: 0.00s

=== episode:215 Env-steps-taken:76800
 	picked: 112 |actions: {0: 681, 1: 830, 2: 774, 3: 758, 4: 817, 5: 764, 6: 947, 7: 589, 8: 412}
episode: 215/2000 -> reward: 143.69791666666654, steps:6572, time-taken: 2.20min, time-elasped: 355.67min
-> berries picked: 112 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4743 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [242, 532, 541, 558, 568, 717, 736, 477, 372]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 14, 11, 18, 16, 12, 22, 10, 18]
	Time taken saving stuff: 0.00s

=== episode:216 Env-steps-taken:65760
 	picked: 62 |actions: {0: 394, 1: 476, 2: 582, 3: 372, 4: 474, 5: 428, 6: 502, 7: 364, 8: 475}
episode: 216/2000 -> reward: 89.44791666666664, steps:4067, time-taken: 1.47min, time-elasped: 357.14min
-> berries picked: 62 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4746 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [242, 534, 544, 564, 562, 717, 731, 476, 376]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 11, 20, 13, 7, 11, 17, 9, 13]
	Time taken saving stuff: 0.00s

=== episode:217 Env-steps-taken:77760
 	picked: 109 |actions: {0: 700, 1: 1007, 2: 682, 3: 664, 4: 631, 5: 866, 6: 769, 7: 542, 8: 461}
episode: 217/2000 -> reward: 149.25520833333331, steps:6322, time-taken: 2.17min, time-elasped: 359.32min
-> berries picked: 109 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4753 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [244, 542, 553, 555, 556, 703, 733, 487, 380]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 17, 8, 15, 5, 9, 14, 9, 12]
	Time taken saving stuff: 0.00s

=== episode:218 Env-steps-taken:68928
 	picked: 79 |actions: {0: 528, 1: 548, 2: 541, 3: 515, 4: 516, 5: 621, 6: 507, 7: 415, 8: 299}
episode: 218/2000 -> reward: 104.97395833333323, steps:4490, time-taken: 1.54min, time-elasped: 360.86min
-> berries picked: 79 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4766 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [251, 546, 558, 560, 553, 698, 730, 488, 382]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 12, 6, 7, 13, 13, 20, 11, 17]
	Time taken saving stuff: 0.01s

=== episode:219 Env-steps-taken:77184
 	picked: 103 |actions: {0: 659, 1: 804, 2: 815, 3: 744, 4: 752, 5: 871, 6: 678, 7: 611, 8: 524}
episode: 219/2000 -> reward: 146.5989583333333, steps:6458, time-taken: 2.16min, time-elasped: 363.02min
-> berries picked: 103 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4772 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [252, 544, 567, 561, 552, 689, 733, 490, 384]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 7, 11, 17, 10, 13, 14, 15, 12]
	Time taken saving stuff: 0.00s

=== episode:220 Env-steps-taken:76320
 	picked: 99 |actions: {0: 640, 1: 928, 2: 705, 3: 807, 4: 674, 5: 821, 6: 635, 7: 532, 8: 648}
episode: 220/2000 -> reward: 142.32812499999994, steps:6390, time-taken: 2.09min, time-elasped: 365.12min
-> berries picked: 99 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4777 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [247, 548, 573, 551, 557, 687, 738, 490, 386]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 11, 14, 18, 14, 10, 11, 10, 12]
	Time taken saving stuff: 0.05s

=== episode:22 Env-steps-taken:76224
 	picked: 107 |actions: {0: 212, 1: 330, 2: 945, 3: 124, 4: 709, 5: 157, 6: 451, 7: 233, 8: 843}

==================================================
eval-episode: 220 -> reward: 141.86979166666669, steps: 4004.0, wall-time: 31.77s
-> berries picked: 107 of 800 | patches-visited: [0, 1, 8] | juice left:-0.00
==================================================


=== episode:221 Env-steps-taken:73152
 	picked: 89 |actions: {0: 529, 1: 391, 2: 470, 3: 448, 4: 545, 5: 750, 6: 464, 7: 454, 8: 409}
episode: 221/2000 -> reward: 126.90104166666649, steps:4460, time-taken: 1.63min, time-elasped: 367.28min
-> berries picked: 89 of 800 | patches-visited: [0, 2, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4809 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [254, 545, 580, 552, 558, 695, 745, 491, 389]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 11, 21, 20, 12, 11, 12, 10, 13]
	Time taken saving stuff: 0.00s

=== episode:222 Env-steps-taken:80064
 	picked: 115 |actions: {0: 731, 1: 940, 2: 831, 3: 767, 4: 773, 5: 840, 6: 722, 7: 556, 8: 549}
episode: 222/2000 -> reward: 160.91145833333343, steps:6709, time-taken: 2.23min, time-elasped: 369.50min
-> berries picked: 115 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4832 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [253, 552, 579, 557, 567, 691, 750, 494, 389]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 13, 14, 9, 10, 16, 13, 6, 22]
	Time taken saving stuff: 0.00s

=== episode:223 Env-steps-taken:73440
 	picked: 89 |actions: {0: 463, 1: 574, 2: 583, 3: 511, 4: 527, 5: 641, 6: 564, 7: 481, 8: 324}
episode: 223/2000 -> reward: 127.01562499999986, steps:4668, time-taken: 1.59min, time-elasped: 371.10min
-> berries picked: 89 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4856 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [249, 548, 593, 558, 569, 687, 763, 497, 392]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 12, 8, 13, 9, 13, 24, 9, 15]
	Time taken saving stuff: 0.00s

=== episode:224 Env-steps-taken:74880
 	picked: 95 |actions: {0: 641, 1: 708, 2: 897, 3: 591, 4: 595, 5: 817, 6: 464, 7: 542, 8: 562}
episode: 224/2000 -> reward: 134.72916666666657, steps:5817, time-taken: 2.01min, time-elasped: 373.11min
-> berries picked: 95 of 800 | patches-visited: [0, 2, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4865 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [249, 550, 595, 560, 577, 679, 757, 502, 396]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 20, 9, 15, 13, 12, 18, 14, 14]
	Time taken saving stuff: 0.00s

=== episode:225 Env-steps-taken:73536
 	picked: 101 |actions: {0: 836, 1: 812, 2: 868, 3: 690, 4: 642, 5: 748, 6: 558, 7: 598, 8: 485}
episode: 225/2000 -> reward: 127.71354166666647, steps:6237, time-taken: 2.02min, time-elasped: 375.13min
-> berries picked: 101 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4895 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [254, 557, 600, 566, 573, 687, 757, 503, 398]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 13, 17, 14, 12, 13, 13, 11, 12]
	Time taken saving stuff: 0.00s

=== episode:226 Env-steps-taken:74784
 	picked: 104 |actions: {0: 661, 1: 791, 2: 774, 3: 726, 4: 694, 5: 802, 6: 591, 7: 582, 8: 568}
episode: 226/2000 -> reward: 134.04166666666654, steps:6189, time-taken: 2.16min, time-elasped: 377.29min
-> berries picked: 104 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4880 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [253, 555, 593, 565, 574, 686, 748, 505, 401]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 12, 8, 18, 18, 17, 14, 19, 12]
	Time taken saving stuff: 0.00s

=== episode:227 Env-steps-taken:69888
 	picked: 84 |actions: {0: 498, 1: 578, 2: 699, 3: 476, 4: 492, 5: 546, 6: 522, 7: 478, 8: 577}
episode: 227/2000 -> reward: 109.68749999999987, steps:4866, time-taken: 1.68min, time-elasped: 378.97min
-> berries picked: 84 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4874 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [254, 545, 598, 568, 565, 688, 743, 508, 405]
	| approx positives in sample 512: 94
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 6, 8, 6, 13, 13, 21, 11, 11]
	Time taken saving stuff: 0.00s

=== episode:228 Env-steps-taken:75456
 	picked: 100 |actions: {0: 709, 1: 863, 2: 667, 3: 582, 4: 822, 5: 862, 6: 773, 7: 761, 8: 590}
episode: 228/2000 -> reward: 137.77083333333326, steps:6629, time-taken: 2.21min, time-elasped: 381.17min
-> berries picked: 100 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4851 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [256, 535, 598, 555, 563, 686, 750, 502, 406]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [2, 5, 13, 12, 10, 15, 20, 15, 14]
	Time taken saving stuff: 0.00s

=== episode:229 Env-steps-taken:72000
 	picked: 89 |actions: {0: 533, 1: 542, 2: 615, 3: 598, 4: 662, 5: 698, 6: 592, 7: 484, 8: 429}
episode: 229/2000 -> reward: 120.40104166666649, steps:5153, time-taken: 1.83min, time-elasped: 383.00min
-> berries picked: 89 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4837 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [256, 527, 598, 556, 561, 681, 751, 499, 408]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 10, 11, 11, 13, 18, 21, 13, 17]
	Time taken saving stuff: 0.00s

=== episode:230 Env-steps-taken:68640
 	picked: 81 |actions: {0: 622, 1: 643, 2: 639, 3: 467, 4: 608, 5: 812, 6: 548, 7: 501, 8: 435}
episode: 230/2000 -> reward: 103.85937499999991, steps:5275, time-taken: 1.82min, time-elasped: 384.83min
-> berries picked: 81 of 800 | patches-visited: [0, 4, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4839 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [260, 520, 598, 562, 555, 684, 753, 499, 408]
	| approx positives in sample 512: 90
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 9, 10, 8, 10, 12, 13, 8, 13]
	Time taken saving stuff: 0.05s

=== episode:23 Env-steps-taken:85728
 	picked: 134 |actions: {0: 330, 1: 642, 2: 611, 3: 209, 4: 659, 5: 666, 6: 382, 7: 623, 8: 400}

==================================================
eval-episode: 230 -> reward: 189.8229166666669, steps: 4522.0, wall-time: 38.39s
-> berries picked: 134 of 800 | patches-visited: [0, 1, 3] | juice left:-0.00
==================================================


=== episode:231 Env-steps-taken:68544
 	picked: 79 |actions: {0: 430, 1: 684, 2: 609, 3: 518, 4: 761, 5: 731, 6: 587, 7: 394, 8: 439}
episode: 231/2000 -> reward: 102.47395833333321, steps:5153, time-taken: 1.76min, time-elasped: 387.23min
-> berries picked: 79 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4804 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [251, 521, 601, 547, 545, 684, 752, 495, 408]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 16, 17, 14, 12, 12, 11, 11, 12]
	Time taken saving stuff: 0.00s

=== episode:232 Env-steps-taken:69600
 	picked: 82 |actions: {0: 590, 1: 826, 2: 765, 3: 505, 4: 637, 5: 666, 6: 546, 7: 460, 8: 563}
episode: 232/2000 -> reward: 108.3020833333332, steps:5558, time-taken: 1.82min, time-elasped: 389.06min
-> berries picked: 82 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4783 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [249, 529, 604, 545, 532, 682, 749, 486, 407]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 16, 17, 12, 14, 15, 18, 3, 17]
	Time taken saving stuff: 0.00s

=== episode:233 Env-steps-taken:65280
 	picked: 69 |actions: {0: 696, 1: 669, 2: 794, 3: 508, 4: 614, 5: 594, 6: 523, 7: 404, 8: 601}
episode: 233/2000 -> reward: 86.04687499999997, steps:5403, time-taken: 1.82min, time-elasped: 390.88min
-> berries picked: 69 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4754 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [244, 528, 601, 547, 525, 679, 746, 478, 406]
	| approx positives in sample 512: 93
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [2, 9, 8, 8, 7, 17, 16, 16, 10]
	Time taken saving stuff: 0.00s

=== episode:234 Env-steps-taken:77376
 	picked: 109 |actions: {0: 701, 1: 698, 2: 849, 3: 767, 4: 877, 5: 856, 6: 664, 7: 567, 8: 528}
episode: 234/2000 -> reward: 147.25520833333331, steps:6507, time-taken: 2.16min, time-elasped: 393.04min
-> berries picked: 109 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4751 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [244, 517, 605, 551, 525, 675, 747, 476, 411]
	| approx positives in sample 512: 91
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 11, 11, 7, 5, 15, 11, 12, 11]
	Time taken saving stuff: 0.00s

=== episode:235 Env-steps-taken:74688
 	picked: 102 |actions: {0: 750, 1: 791, 2: 698, 3: 655, 4: 728, 5: 869, 6: 716, 7: 642, 8: 598}
episode: 235/2000 -> reward: 133.65624999999986, steps:6447, time-taken: 2.22min, time-elasped: 395.26min
-> berries picked: 102 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4754 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [255, 525, 601, 552, 528, 664, 747, 470, 412]
	| approx positives in sample 512: 100
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 6, 17, 11, 8, 10, 12, 11, 19]
	Time taken saving stuff: 0.00s

=== episode:236 Env-steps-taken:72000
 	picked: 88 |actions: {0: 791, 1: 881, 2: 621, 3: 516, 4: 538, 5: 751, 6: 540, 7: 491, 8: 521}
episode: 236/2000 -> reward: 120.45833333333317, steps:5650, time-taken: 2.05min, time-elasped: 397.32min
-> berries picked: 88 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4755 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [257, 531, 604, 550, 524, 659, 746, 468, 416]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 7, 11, 18, 9, 20, 18, 15, 12]
	Time taken saving stuff: 0.00s

=== episode:237 Env-steps-taken:79968
 	picked: 115 |actions: {0: 820, 1: 898, 2: 663, 3: 671, 4: 808, 5: 864, 6: 784, 7: 741, 8: 541}
episode: 237/2000 -> reward: 160.41145833333337, steps:6790, time-taken: 2.28min, time-elasped: 399.61min
-> berries picked: 115 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4775 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [259, 535, 608, 556, 521, 650, 748, 480, 418]
	| approx positives in sample 512: 94
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 14, 13, 11, 3, 12, 14, 12, 11]
	Time taken saving stuff: 0.00s

=== episode:238 Env-steps-taken:74016
 	picked: 95 |actions: {0: 856, 1: 846, 2: 652, 3: 572, 4: 835, 5: 930, 6: 524, 7: 630, 8: 511}
episode: 238/2000 -> reward: 130.5572916666665, steps:6356, time-taken: 2.12min, time-elasped: 401.72min
-> berries picked: 95 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4772 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [263, 540, 616, 548, 513, 652, 744, 476, 420]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 14, 14, 12, 15, 7, 11, 10, 11]
	Time taken saving stuff: 0.00s

=== episode:239 Env-steps-taken:60096
 	picked: 41 |actions: {0: 195, 1: 278, 2: 214, 3: 198, 4: 273, 5: 459, 6: 291, 7: 258, 8: 302}
episode: 239/2000 -> reward: 60.6510416666667, steps:2468, time-taken: 0.95min, time-elasped: 402.68min
-> berries picked: 41 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4777 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [263, 538, 619, 547, 514, 654, 747, 478, 417]
	| approx positives in sample 512: 100
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 4, 11, 11, 9, 21, 17, 10, 6]
	Time taken saving stuff: 0.00s

=== episode:240 Env-steps-taken:71232
 	picked: 85 |actions: {0: 705, 1: 653, 2: 594, 3: 509, 4: 553, 5: 642, 6: 479, 7: 463, 8: 491}
episode: 240/2000 -> reward: 116.6302083333332, steps:5089, time-taken: 1.70min, time-elasped: 404.38min
-> berries picked: 85 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4787 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [263, 545, 625, 549, 509, 653, 751, 472, 420]
	| approx positives in sample 512: 95
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 11, 7, 16, 5, 19, 11, 6, 15]
	Time taken saving stuff: 0.05s

=== episode:24 Env-steps-taken:79392
 	picked: 113 |actions: {0: 283, 1: 1854, 2: 223, 3: 364, 4: 293, 5: 1635, 6: 81, 7: 707, 8: 576}

==================================================
eval-episode: 240 -> reward: 158.0260416666667, steps: 6016.0, wall-time: 37.65s
-> berries picked: 113 of 800 | patches-visited: [1, 4, 6] | juice left:-0.00
==================================================


=== episode:241 Env-steps-taken:67488
 	picked: 74 |actions: {0: 823, 1: 842, 2: 608, 3: 561, 4: 700, 5: 563, 6: 573, 7: 519, 8: 459}
episode: 241/2000 -> reward: 97.76041666666656, steps:5648, time-taken: 1.94min, time-elasped: 406.95min
-> berries picked: 74 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4780 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [269, 543, 625, 554, 499, 643, 755, 474, 418]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 12, 14, 14, 11, 15, 17, 10, 7]
	Time taken saving stuff: 0.00s

=== episode:242 Env-steps-taken:72480
 	picked: 100 |actions: {0: 621, 1: 1019, 2: 673, 3: 592, 4: 649, 5: 723, 6: 596, 7: 685, 8: 463}
episode: 242/2000 -> reward: 122.27083333333316, steps:6021, time-taken: 2.02min, time-elasped: 408.98min
-> berries picked: 100 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4774 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [272, 553, 632, 554, 497, 624, 745, 480, 417]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 12, 13, 9, 11, 16, 15, 14, 9]
	Time taken saving stuff: 0.00s

=== episode:243 Env-steps-taken:55776
 	picked: 27 |actions: {0: 179, 1: 205, 2: 174, 3: 234, 4: 238, 5: 159, 6: 195, 7: 180, 8: 156}
episode: 243/2000 -> reward: 38.95312500000001, steps:1720, time-taken: 0.87min, time-elasped: 409.85min
-> berries picked: 27 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4777 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [271, 552, 630, 561, 495, 621, 750, 480, 417]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 14, 18, 10, 15, 8, 20, 9, 13]
	Time taken saving stuff: 0.00s

=== episode:244 Env-steps-taken:64512
 	picked: 67 |actions: {0: 520, 1: 549, 2: 627, 3: 513, 4: 661, 5: 493, 6: 382, 7: 367, 8: 520}
episode: 244/2000 -> reward: 82.16145833333333, steps:4632, time-taken: 1.59min, time-elasped: 411.44min
-> berries picked: 67 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4762 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [268, 540, 637, 565, 494, 619, 751, 473, 415]
	| approx positives in sample 512: 101
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 19, 11, 15, 10, 12, 7, 8, 12]
	Time taken saving stuff: 0.00s

=== episode:245 Env-steps-taken:68352
 	picked: 78 |actions: {0: 520, 1: 645, 2: 494, 3: 506, 4: 498, 5: 567, 6: 329, 7: 448, 8: 391}
episode: 245/2000 -> reward: 102.03124999999989, steps:4398, time-taken: 1.54min, time-elasped: 412.98min
-> berries picked: 78 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4779 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [263, 544, 642, 570, 498, 625, 747, 474, 416]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 11, 14, 12, 8, 17, 17, 14, 12]
	Time taken saving stuff: 0.00s

=== episode:246 Env-steps-taken:78816
 	picked: 115 |actions: {0: 738, 1: 817, 2: 668, 3: 699, 4: 663, 5: 984, 6: 760, 7: 671, 8: 618}
episode: 246/2000 -> reward: 154.91145833333337, steps:6618, time-taken: 2.24min, time-elasped: 415.23min
-> berries picked: 115 of 800 | patches-visited: [0, 3, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4799 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [261, 547, 654, 567, 496, 629, 751, 476, 418]
	| approx positives in sample 512: 100
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 12, 15, 9, 8, 13, 18, 4, 16]
	Time taken saving stuff: 0.00s

=== episode:247 Env-steps-taken:70368
 	picked: 89 |actions: {0: 627, 1: 631, 2: 623, 3: 496, 4: 581, 5: 661, 6: 582, 7: 685, 8: 699}
episode: 247/2000 -> reward: 111.90104166666649, steps:5585, time-taken: 1.93min, time-elasped: 417.16min
-> berries picked: 89 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4796 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [257, 549, 653, 570, 496, 621, 752, 477, 421]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 15, 14, 12, 12, 17, 18, 8, 7]
	Time taken saving stuff: 0.00s

=== episode:248 Env-steps-taken:71136
 	picked: 89 |actions: {0: 644, 1: 800, 2: 835, 3: 635, 4: 533, 5: 635, 6: 435, 7: 478, 8: 594}
episode: 248/2000 -> reward: 115.90104166666653, steps:5589, time-taken: 1.93min, time-elasped: 419.09min
-> berries picked: 89 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4809 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [258, 551, 663, 576, 495, 625, 747, 476, 418]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 16, 12, 15, 9, 10, 10, 13, 15]
	Time taken saving stuff: 0.00s

=== episode:249 Env-steps-taken:70080
 	picked: 85 |actions: {0: 538, 1: 575, 2: 561, 3: 478, 4: 656, 5: 692, 6: 646, 7: 476, 8: 375}
episode: 249/2000 -> reward: 110.63020833333319, steps:4997, time-taken: 1.66min, time-elasped: 420.75min
-> berries picked: 85 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4809 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [258, 545, 667, 580, 501, 623, 744, 473, 418]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 14, 16, 9, 11, 11, 12, 13, 10]
	Time taken saving stuff: 0.00s

=== episode:250 Env-steps-taken:79872
 	picked: 117 |actions: {0: 708, 1: 769, 2: 735, 3: 664, 4: 762, 5: 944, 6: 839, 7: 776, 8: 703}
episode: 250/2000 -> reward: 159.79687500000003, steps:6900, time-taken: 2.26min, time-elasped: 423.01min
-> berries picked: 117 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4826 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [259, 549, 676, 587, 502, 618, 741, 478, 416]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 9, 17, 13, 9, 13, 15, 18, 13]
	Time taken saving stuff: 0.05s

=== episode:25 Env-steps-taken:109056
 	picked: 226 |actions: {0: 523, 1: 889, 2: 987, 3: 1478, 4: 613, 5: 867, 6: 673, 7: 1524, 8: 579}

==================================================
eval-episode: 250 -> reward: 306.5520833333333, steps: 8133.0, wall-time: 51.41s
-> berries picked: 226 of 800 | patches-visited: [1, 4, 6, 7] | juice left:-0.00
==================================================


=== episode:251 Env-steps-taken:69120
 	picked: 85 |actions: {0: 623, 1: 510, 2: 467, 3: 454, 4: 439, 5: 661, 6: 595, 7: 527, 8: 457}
episode: 251/2000 -> reward: 105.63020833333324, steps:4733, time-taken: 1.69min, time-elasped: 425.56min
-> berries picked: 85 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4819 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [267, 545, 672, 576, 498, 621, 744, 478, 418]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 10, 12, 20, 10, 18, 17, 10, 15]
	Time taken saving stuff: 0.00s

=== episode:252 Env-steps-taken:65952
 	picked: 62 |actions: {0: 400, 1: 542, 2: 524, 3: 354, 4: 492, 5: 454, 6: 407, 7: 505, 8: 431}
episode: 252/2000 -> reward: 90.44791666666661, steps:4109, time-taken: 1.47min, time-elasped: 427.03min
-> berries picked: 62 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4821 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [267, 537, 674, 579, 499, 621, 744, 480, 420]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 11, 13, 12, 14, 14, 13, 10, 10]
	Time taken saving stuff: 0.00s

=== episode:253 Env-steps-taken:64896
 	picked: 56 |actions: {0: 255, 1: 406, 2: 330, 3: 430, 4: 400, 5: 347, 6: 348, 7: 243, 8: 291}
episode: 253/2000 -> reward: 85.29166666666663, steps:3050, time-taken: 1.17min, time-elasped: 428.20min
-> berries picked: 56 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4832 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [262, 538, 675, 584, 501, 616, 748, 485, 423]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 17, 13, 12, 13, 17, 13, 12, 17]
	Time taken saving stuff: 0.00s

=== episode:254 Env-steps-taken:67680
 	picked: 81 |actions: {0: 628, 1: 762, 2: 599, 3: 545, 4: 701, 5: 698, 6: 542, 7: 435, 8: 486}
episode: 254/2000 -> reward: 98.4166666666666, steps:5396, time-taken: 1.85min, time-elasped: 430.06min
-> berries picked: 81 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4823 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [261, 542, 673, 584, 495, 611, 753, 479, 425]
	| approx positives in sample 512: 95
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 9, 16, 9, 7, 16, 11, 8, 11]
	Time taken saving stuff: 0.00s

=== episode:255 Env-steps-taken:66144
 	picked: 71 |actions: {0: 702, 1: 701, 2: 549, 3: 474, 4: 665, 5: 504, 6: 516, 7: 433, 8: 591}
episode: 255/2000 -> reward: 90.43229166666657, steps:5135, time-taken: 1.76min, time-elasped: 431.82min
-> berries picked: 71 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4831 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [269, 548, 669, 589, 493, 609, 748, 481, 425]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 15, 8, 11, 14, 8, 14, 11, 19]
	Time taken saving stuff: 0.00s

=== episode:256 Env-steps-taken:70464
 	picked: 78 |actions: {0: 575, 1: 574, 2: 351, 3: 496, 4: 732, 5: 728, 6: 598, 7: 490, 8: 597}
episode: 256/2000 -> reward: 113.53124999999989, steps:5141, time-taken: 1.85min, time-elasped: 433.67min
-> berries picked: 78 of 800 | patches-visited: [0, 6, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4818 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [273, 542, 667, 586, 496, 609, 736, 481, 428]
	| approx positives in sample 512: 96
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 12, 11, 15, 12, 11, 14, 6, 10]
	Time taken saving stuff: 0.00s

=== episode:257 Env-steps-taken:70560
 	picked: 82 |actions: {0: 637, 1: 569, 2: 516, 3: 492, 4: 619, 5: 723, 6: 424, 7: 466, 8: 356}
episode: 257/2000 -> reward: 113.30208333333321, steps:4802, time-taken: 1.67min, time-elasped: 435.34min
-> berries picked: 82 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4816 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [272, 542, 673, 591, 491, 600, 734, 481, 432]
	| approx positives in sample 512: 91
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 15, 15, 12, 2, 11, 15, 4, 14]
	Time taken saving stuff: 0.00s

=== episode:258 Env-steps-taken:77664
 	picked: 108 |actions: {0: 624, 1: 663, 2: 688, 3: 731, 4: 752, 5: 791, 6: 628, 7: 578, 8: 563}
episode: 258/2000 -> reward: 149.31249999999994, steps:6018, time-taken: 2.09min, time-elasped: 437.44min
-> berries picked: 108 of 800 | patches-visited: [0, 4, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4836 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [276, 541, 676, 603, 499, 603, 729, 474, 435]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 12, 16, 11, 7, 17, 16, 10, 20]
	Time taken saving stuff: 0.00s

=== episode:259 Env-steps-taken:65088
 	picked: 63 |actions: {0: 654, 1: 972, 2: 513, 3: 418, 4: 597, 5: 698, 6: 580, 7: 419, 8: 460}
episode: 259/2000 -> reward: 85.89062499999999, steps:5311, time-taken: 1.81min, time-elasped: 439.25min
-> berries picked: 63 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4807 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [276, 535, 673, 600, 489, 608, 719, 474, 433]
	| approx positives in sample 512: 100
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 11, 14, 11, 12, 11, 10, 11, 11]
	Time taken saving stuff: 0.00s

=== episode:260 Env-steps-taken:56640
 	picked: 32 |actions: {0: 308, 1: 380, 2: 235, 3: 190, 4: 218, 5: 266, 6: 269, 7: 205, 8: 348}
episode: 260/2000 -> reward: 43.16666666666667, steps:2419, time-taken: 0.97min, time-elasped: 440.22min
-> berries picked: 32 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4805 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [272, 535, 673, 599, 488, 610, 719, 478, 431]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 19, 20, 11, 10, 18, 14, 9, 19]
	Time taken saving stuff: 0.05s

=== episode:26 Env-steps-taken:52896
 	picked: 18 |actions: {0: 95, 1: 1850, 2: 28, 3: 41, 4: 93, 5: 1867, 6: 21, 7: 37, 8: 83}

==================================================
eval-episode: 260 -> reward: 24.968749999999993, steps: 4115.0, wall-time: 29.23s
-> berries picked: 18 of 800 | patches-visited: [1, 3] | juice left:-0.00
==================================================


=== episode:261 Env-steps-taken:65856
 	picked: 64 |actions: {0: 389, 1: 482, 2: 462, 3: 358, 4: 582, 5: 446, 6: 368, 7: 321, 8: 439}
episode: 261/2000 -> reward: 89.33333333333329, steps:3847, time-taken: 1.33min, time-elasped: 442.05min
-> berries picked: 64 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4787 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [272, 538, 676, 594, 483, 609, 711, 475, 429]
	| approx positives in sample 512: 101
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 8, 20, 13, 4, 7, 11, 10, 16]
	Time taken saving stuff: 0.02s

=== episode:262 Env-steps-taken:70176
 	picked: 82 |actions: {0: 652, 1: 705, 2: 485, 3: 615, 4: 815, 5: 755, 6: 576, 7: 374, 8: 475}
episode: 262/2000 -> reward: 111.30208333333319, steps:5452, time-taken: 1.86min, time-elasped: 443.91min
-> berries picked: 82 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4771 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [278, 532, 682, 590, 475, 597, 710, 475, 432]
	| approx positives in sample 512: 88
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 12, 11, 9, 5, 11, 7, 8, 18]
	Time taken saving stuff: 0.02s

=== episode:263 Env-steps-taken:74400
 	picked: 98 |actions: {0: 701, 1: 763, 2: 631, 3: 608, 4: 684, 5: 667, 6: 529, 7: 432, 8: 639}
episode: 263/2000 -> reward: 132.8854166666665, steps:5654, time-taken: 1.94min, time-elasped: 445.85min
-> berries picked: 98 of 800 | patches-visited: [0, 1, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4755 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [278, 538, 690, 590, 470, 583, 705, 474, 427]
	| approx positives in sample 512: 99
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 8, 20, 9, 9, 9, 9, 15, 11]
	Time taken saving stuff: 0.04s

=== episode:264 Env-steps-taken:62112
 	picked: 49 |actions: {0: 338, 1: 364, 2: 315, 3: 351, 4: 461, 5: 427, 6: 276, 7: 228, 8: 457}
episode: 264/2000 -> reward: 69.25000000000003, steps:3217, time-taken: 1.29min, time-elasped: 447.14min
-> berries picked: 49 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4735 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [274, 534, 688, 585, 466, 588, 697, 476, 427]
	| approx positives in sample 512: 93
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 12, 5, 11, 10, 14, 10, 5, 16]
	Time taken saving stuff: 0.11s

=== episode:265 Env-steps-taken:64896
 	picked: 61 |actions: {0: 393, 1: 397, 2: 391, 3: 372, 4: 431, 5: 453, 6: 435, 7: 308, 8: 322}
episode: 265/2000 -> reward: 85.00520833333329, steps:3502, time-taken: 1.32min, time-elasped: 448.47min
-> berries picked: 61 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4738 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [278, 534, 687, 584, 460, 592, 703, 474, 426]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 12, 18, 12, 12, 9, 16, 5, 15]
	Time taken saving stuff: 0.09s

=== episode:266 Env-steps-taken:76608
 	picked: 104 |actions: {0: 693, 1: 912, 2: 639, 3: 663, 4: 875, 5: 795, 6: 552, 7: 567, 8: 526}
episode: 266/2000 -> reward: 142.15624999999997, steps:6222, time-taken: 2.15min, time-elasped: 450.61min
-> berries picked: 104 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4759 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [280, 537, 693, 589, 463, 591, 699, 477, 430]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 9, 17, 11, 10, 12, 17, 10, 11]
	Time taken saving stuff: 0.21s

=== episode:267 Env-steps-taken:76896
 	picked: 105 |actions: {0: 801, 1: 734, 2: 686, 3: 697, 4: 709, 5: 913, 6: 606, 7: 607, 8: 583}
episode: 267/2000 -> reward: 145.48437499999994, steps:6336, time-taken: 2.20min, time-elasped: 452.82min
-> berries picked: 105 of 800 | patches-visited: [0, 2, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4784 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [275, 538, 695, 595, 458, 597, 702, 491, 433]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 13, 19, 16, 17, 16, 14, 14, 14]
	Time taken saving stuff: 0.02s

=== episode:268 Env-steps-taken:65856
 	picked: 65 |actions: {0: 596, 1: 573, 2: 531, 3: 451, 4: 752, 5: 604, 6: 319, 7: 491, 8: 438}
episode: 268/2000 -> reward: 87.89062499999994, steps:4755, time-taken: 1.62min, time-elasped: 454.44min
-> berries picked: 65 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4782 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [270, 537, 694, 599, 457, 597, 698, 497, 433]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 14, 17, 11, 13, 16, 18, 10, 17]
	Time taken saving stuff: 0.03s

=== episode:269 Env-steps-taken:51840
 	picked: 12 |actions: {0: 33, 1: 173, 2: 76, 3: 104, 4: 53, 5: 72, 6: 62, 7: 87, 8: 100}
episode: 269/2000 -> reward: 19.312500000000004, steps:760, time-taken: 0.48min, time-elasped: 454.92min
-> berries picked: 12 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4780 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [269, 536, 696, 600, 457, 598, 697, 495, 432]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 16, 14, 11, 13, 16, 12, 17, 15]
	Time taken saving stuff: 0.10s

=== episode:270 Env-steps-taken:49920
 	picked: 8 |actions: {0: 46, 1: 64, 2: 38, 3: 41, 4: 28, 5: 61, 6: 30, 7: 67, 8: 66}
episode: 270/2000 -> reward: 9.541666666666671, steps:441, time-taken: 0.38min, time-elasped: 455.30min
-> berries picked: 8 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4780 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [270, 536, 697, 595, 456, 598, 699, 496, 433]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 9, 9, 16, 11, 5, 23, 7, 9]
	Time taken saving stuff: 0.16s

=== episode:27 Env-steps-taken:90816
 	picked: 158 |actions: {0: 1043, 1: 313, 2: 576, 3: 523, 4: 758, 5: 340, 6: 739, 7: 260, 8: 906}

==================================================
eval-episode: 270 -> reward: 215.44791666666706, steps: 5458.0, wall-time: 42.45s
-> berries picked: 158 of 800 | patches-visited: [0, 1, 6, 9] | juice left:-0.00
==================================================


=== episode:271 Env-steps-taken:74880
 	picked: 94 |actions: {0: 686, 1: 699, 2: 636, 3: 593, 4: 680, 5: 675, 6: 575, 7: 549, 8: 487}
episode: 271/2000 -> reward: 135.6145833333332, steps:5580, time-taken: 1.93min, time-elasped: 457.94min
-> berries picked: 94 of 800 | patches-visited: [0, 2, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4800 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [270, 545, 703, 600, 455, 593, 692, 507, 435]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 12, 9, 10, 10, 18, 15, 15, 12]
	Time taken saving stuff: 0.00s

=== episode:272 Env-steps-taken:63936
 	picked: 54 |actions: {0: 403, 1: 480, 2: 394, 3: 454, 4: 559, 5: 531, 6: 248, 7: 293, 8: 422}
episode: 272/2000 -> reward: 80.40625, steps:3784, time-taken: 1.38min, time-elasped: 459.32min
-> berries picked: 54 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4805 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [269, 546, 703, 603, 457, 591, 691, 509, 436]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 16, 9, 14, 9, 11, 15, 10, 7]
	Time taken saving stuff: 0.11s

=== episode:273 Env-steps-taken:70848
 	picked: 79 |actions: {0: 469, 1: 629, 2: 489, 3: 536, 4: 679, 5: 567, 6: 511, 7: 459, 8: 533}
episode: 273/2000 -> reward: 114.9739583333332, steps:4872, time-taken: 1.78min, time-elasped: 461.10min
-> berries picked: 79 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4801 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [268, 545, 696, 605, 461, 593, 691, 507, 435]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 13, 13, 16, 9, 11, 10, 12, 19]
	Time taken saving stuff: 0.00s

=== episode:274 Env-steps-taken:69984
 	picked: 81 |actions: {0: 396, 1: 634, 2: 418, 3: 437, 4: 555, 5: 470, 6: 575, 7: 506, 8: 428}
episode: 274/2000 -> reward: 110.85937499999986, steps:4419, time-taken: 1.61min, time-elasped: 462.71min
-> berries picked: 81 of 800 | patches-visited: [0, 1, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4811 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [272, 541, 693, 607, 463, 592, 697, 509, 437]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 9, 20, 12, 11, 10, 12, 12, 13]
	Time taken saving stuff: 0.09s

=== episode:275 Env-steps-taken:67776
 	picked: 72 |actions: {0: 468, 1: 551, 2: 475, 3: 475, 4: 537, 5: 550, 6: 439, 7: 428, 8: 373}
episode: 275/2000 -> reward: 99.87499999999993, steps:4296, time-taken: 1.60min, time-elasped: 464.31min
-> berries picked: 72 of 800 | patches-visited: [0, 4, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4830 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [278, 542, 697, 607, 464, 600, 700, 503, 439]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 17, 9, 9, 19, 7, 18, 16, 13]
	Time taken saving stuff: 0.01s

=== episode:276 Env-steps-taken:69888
 	picked: 72 |actions: {0: 490, 1: 533, 2: 465, 3: 502, 4: 469, 5: 480, 6: 407, 7: 481, 8: 517}
episode: 276/2000 -> reward: 110.37499999999991, steps:4344, time-taken: 1.55min, time-elasped: 465.86min
-> berries picked: 72 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4854 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [288, 543, 703, 610, 460, 596, 701, 512, 441]
	| approx positives in sample 512: 101
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [2, 13, 13, 16, 12, 10, 13, 10, 12]
	Time taken saving stuff: 0.10s

=== episode:277 Env-steps-taken:74688
 	picked: 97 |actions: {0: 484, 1: 637, 2: 597, 3: 594, 4: 573, 5: 751, 6: 491, 7: 549, 8: 440}
episode: 277/2000 -> reward: 134.44270833333323, steps:5116, time-taken: 1.79min, time-elasped: 467.66min
-> berries picked: 97 of 800 | patches-visited: [0, 2, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4870 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [291, 546, 701, 617, 453, 602, 703, 510, 447]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7, 8] [16, 15, 16, 7, 22, 12, 7, 19]
	Time taken saving stuff: 0.00s

=== episode:278 Env-steps-taken:59712
 	picked: 50 |actions: {0: 359, 1: 337, 2: 344, 3: 287, 4: 327, 5: 368, 6: 346, 7: 330, 8: 324}
episode: 278/2000 -> reward: 58.63541666666671, steps:3022, time-taken: 1.17min, time-elasped: 468.83min
-> berries picked: 50 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4882 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [293, 549, 708, 617, 450, 592, 710, 513, 450]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 11, 13, 13, 6, 9, 18, 12, 13]
	Time taken saving stuff: 0.03s

=== episode:279 Env-steps-taken:78240
 	picked: 116 |actions: {0: 713, 1: 825, 2: 692, 3: 741, 4: 749, 5: 892, 6: 705, 7: 608, 8: 594}
episode: 279/2000 -> reward: 151.85416666666669, steps:6519, time-taken: 2.18min, time-elasped: 471.02min
-> berries picked: 116 of 800 | patches-visited: [0, 4, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4901 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [293, 549, 712, 619, 453, 598, 709, 518, 450]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 10, 12, 15, 7, 13, 11, 11, 21]
	Time taken saving stuff: 0.00s

=== episode:280 Env-steps-taken:68256
 	picked: 74 |actions: {0: 470, 1: 641, 2: 490, 3: 549, 4: 693, 5: 510, 6: 507, 7: 523, 8: 476}
episode: 280/2000 -> reward: 102.26041666666659, steps:4859, time-taken: 1.69min, time-elasped: 472.70min
-> berries picked: 74 of 800 | patches-visited: [0, 1, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4922 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [293, 546, 719, 625, 457, 595, 713, 523, 451]
	| approx positives in sample 512: 94
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 15, 6, 16, 8, 11, 10, 12, 11]
	Time taken saving stuff: 0.14s

=== episode:28 Env-steps-taken:81120
 	picked: 126 |actions: {0: 235, 1: 987, 2: 248, 3: 650, 4: 638, 5: 325, 6: 165, 7: 414, 8: 565}

==================================================
eval-episode: 280 -> reward: 166.28125000000009, steps: 4227.0, wall-time: 34.30s
-> berries picked: 126 of 800 | patches-visited: [1, 3, 6] | juice left:-0.00
==================================================


=== episode:281 Env-steps-taken:70752
 	picked: 88 |actions: {0: 663, 1: 591, 2: 574, 3: 581, 4: 892, 5: 746, 6: 600, 7: 567, 8: 607}
episode: 281/2000 -> reward: 113.95833333333319, steps:5821, time-taken: 2.02min, time-elasped: 475.30min
-> berries picked: 88 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4912 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [292, 545, 726, 618, 451, 591, 714, 523, 452]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 12, 18, 11, 5, 8, 9, 14, 21]
	Time taken saving stuff: 0.04s

=== episode:282 Env-steps-taken:79200
 	picked: 113 |actions: {0: 582, 1: 700, 2: 758, 3: 635, 4: 748, 5: 756, 6: 807, 7: 546, 8: 686}
episode: 282/2000 -> reward: 157.02604166666677, steps:6218, time-taken: 2.13min, time-elasped: 477.44min
-> berries picked: 113 of 800 | patches-visited: [0, 3, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4948 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [289, 554, 733, 620, 453, 598, 720, 524, 457]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 11, 21, 18, 10, 12, 11, 11, 12]
	Time taken saving stuff: 0.10s

=== episode:283 Env-steps-taken:61056
 	picked: 50 |actions: {0: 335, 1: 420, 2: 384, 3: 316, 4: 465, 5: 344, 6: 276, 7: 315, 8: 290}
episode: 283/2000 -> reward: 65.1354166666667, steps:3145, time-taken: 1.14min, time-elasped: 478.58min
-> berries picked: 50 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4952 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [290, 556, 733, 621, 459, 597, 720, 522, 454]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 13, 18, 17, 6, 7, 11, 13, 12]
	Time taken saving stuff: 0.11s

=== episode:284 Env-steps-taken:62496
 	picked: 51 |actions: {0: 290, 1: 367, 2: 302, 3: 287, 4: 453, 5: 450, 6: 262, 7: 268, 8: 357}
episode: 284/2000 -> reward: 73.07812500000001, steps:3036, time-taken: 1.13min, time-elasped: 479.71min
-> berries picked: 51 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4949 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [287, 553, 736, 614, 463, 603, 720, 519, 454]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 9, 14, 16, 13, 9, 14, 16, 13]
	Time taken saving stuff: 0.03s

=== episode:285 Env-steps-taken:73632
 	picked: 93 |actions: {0: 505, 1: 611, 2: 580, 3: 687, 4: 688, 5: 582, 6: 620, 7: 538, 8: 555}
episode: 285/2000 -> reward: 128.67187499999983, steps:5366, time-taken: 1.85min, time-elasped: 481.57min
-> berries picked: 93 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4957 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [288, 555, 735, 613, 471, 599, 719, 521, 456]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 12, 10, 13, 10, 14, 13, 16, 19]
	Time taken saving stuff: 0.10s

=== episode:286 Env-steps-taken:70464
 	picked: 79 |actions: {0: 479, 1: 566, 2: 374, 3: 454, 4: 573, 5: 490, 6: 443, 7: 435, 8: 450}
episode: 286/2000 -> reward: 112.9739583333332, steps:4264, time-taken: 1.52min, time-elasped: 483.09min
-> berries picked: 79 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4940 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [293, 553, 737, 612, 471, 583, 713, 522, 456]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 13, 14, 23, 8, 19, 11, 10, 10]
	Time taken saving stuff: 0.11s

=== episode:287 Env-steps-taken:64512
 	picked: 66 |actions: {0: 500, 1: 463, 2: 381, 3: 485, 4: 606, 5: 472, 6: 455, 7: 512, 8: 584}
episode: 287/2000 -> reward: 82.21874999999997, steps:4458, time-taken: 1.52min, time-elasped: 484.62min
-> berries picked: 66 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4909 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [294, 548, 728, 609, 472, 576, 707, 518, 457]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 17, 15, 15, 8, 14, 13, 7, 13]
	Time taken saving stuff: 0.00s

=== episode:288 Env-steps-taken:76224
 	picked: 102 |actions: {0: 654, 1: 605, 2: 519, 3: 504, 4: 604, 5: 690, 6: 582, 7: 580, 8: 521}
episode: 288/2000 -> reward: 140.2135416666666, steps:5259, time-taken: 1.86min, time-elasped: 486.48min
-> berries picked: 102 of 800 | patches-visited: [0, 2, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4928 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [299, 554, 730, 610, 474, 570, 702, 528, 461]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 13, 17, 10, 8, 12, 8, 15, 22]
	Time taken saving stuff: 0.02s

=== episode:289 Env-steps-taken:69408
 	picked: 79 |actions: {0: 446, 1: 728, 2: 534, 3: 634, 4: 519, 5: 397, 6: 606, 7: 469, 8: 465}
episode: 289/2000 -> reward: 106.0885416666666, steps:4798, time-taken: 1.72min, time-elasped: 488.21min
-> berries picked: 79 of 800 | patches-visited: [0, 5, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4938 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [297, 556, 740, 613, 474, 565, 702, 530, 461]
	| approx positives in sample 512: 93
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 10, 12, 13, 4, 12, 11, 6, 19]
	Time taken saving stuff: 0.02s

=== episode:290 Env-steps-taken:68160
 	picked: 78 |actions: {0: 550, 1: 574, 2: 383, 3: 528, 4: 587, 5: 522, 6: 515, 7: 509, 8: 486}
episode: 290/2000 -> reward: 99.14583333333326, steps:4654, time-taken: 1.58min, time-elasped: 489.79min
-> berries picked: 78 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4938 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [294, 562, 738, 614, 469, 568, 700, 532, 461]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 12, 14, 17, 4, 19, 10, 17, 14]
	Time taken saving stuff: 0.16s

=== episode:29 Env-steps-taken:112896
 	picked: 242 |actions: {0: 423, 1: 1153, 2: 640, 3: 888, 4: 800, 5: 652, 6: 749, 7: 1058, 8: 516}

==================================================
eval-episode: 290 -> reward: 323.8072916666663, steps: 6879.0, wall-time: 49.74s
-> berries picked: 242 of 800 | patches-visited: [0, 1, 2, 3, 9] | juice left:-0.00
==================================================


=== episode:291 Env-steps-taken:67104
 	picked: 74 |actions: {0: 587, 1: 677, 2: 402, 3: 651, 4: 458, 5: 597, 6: 511, 7: 731, 8: 505}
episode: 291/2000 -> reward: 95.76041666666659, steps:5119, time-taken: 1.79min, time-elasped: 492.41min
-> berries picked: 74 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4934 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [291, 566, 732, 613, 468, 567, 695, 538, 464]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 19, 13, 8, 12, 11, 12, 12, 27]
	Time taken saving stuff: 0.10s

=== episode:292 Env-steps-taken:68640
 	picked: 76 |actions: {0: 495, 1: 561, 2: 414, 3: 457, 4: 550, 5: 544, 6: 426, 7: 422, 8: 411}
episode: 292/2000 -> reward: 103.64583333333326, steps:4280, time-taken: 1.57min, time-elasped: 493.99min
-> berries picked: 76 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4930 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [296, 566, 730, 614, 461, 571, 694, 534, 464]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 14, 16, 20, 9, 16, 12, 7, 11]
	Time taken saving stuff: 0.00s

=== episode:293 Env-steps-taken:72768
 	picked: 87 |actions: {0: 575, 1: 745, 2: 488, 3: 575, 4: 435, 5: 524, 6: 589, 7: 705, 8: 446}
episode: 293/2000 -> reward: 123.13020833333316, steps:5082, time-taken: 1.82min, time-elasped: 495.81min
-> berries picked: 87 of 800 | patches-visited: [0, 1, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4944 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [307, 570, 728, 617, 456, 565, 696, 540, 465]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 12, 19, 15, 18, 7, 15, 11, 11]
	Time taken saving stuff: 0.03s

=== episode:294 Env-steps-taken:69600
 	picked: 88 |actions: {0: 477, 1: 617, 2: 467, 3: 560, 4: 677, 5: 846, 6: 602, 7: 555, 8: 548}
episode: 294/2000 -> reward: 107.95833333333319, steps:5349, time-taken: 1.87min, time-elasped: 497.69min
-> berries picked: 88 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4972 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [307, 568, 728, 620, 467, 575, 695, 544, 468]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 13, 11, 14, 8, 17, 11, 11, 12]
	Time taken saving stuff: 0.00s

=== episode:295 Env-steps-taken:75648
 	picked: 98 |actions: {0: 537, 1: 638, 2: 552, 3: 617, 4: 829, 5: 776, 6: 553, 7: 676, 8: 591}
episode: 295/2000 -> reward: 138.88541666666663, steps:5769, time-taken: 1.96min, time-elasped: 499.65min
-> berries picked: 98 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4979 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [301, 574, 732, 618, 464, 579, 698, 543, 470]
	| approx positives in sample 512: 85
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 15, 7, 11, 7, 10, 8, 14, 8]
	Time taken saving stuff: 0.12s

=== episode:296 Env-steps-taken:70464
 	picked: 81 |actions: {0: 505, 1: 459, 2: 548, 3: 552, 4: 569, 5: 549, 6: 423, 7: 432, 8: 397}
episode: 296/2000 -> reward: 112.85937499999987, steps:4434, time-taken: 1.59min, time-elasped: 501.24min
-> berries picked: 81 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4993 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [305, 571, 733, 623, 466, 584, 698, 539, 474]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 10, 17, 17, 13, 11, 15, 20, 22]
	Time taken saving stuff: 0.00s

=== episode:297 Env-steps-taken:74496
 	picked: 101 |actions: {0: 650, 1: 661, 2: 561, 3: 708, 4: 628, 5: 666, 6: 695, 7: 765, 8: 622}
episode: 297/2000 -> reward: 132.3281249999999, steps:5956, time-taken: 1.96min, time-elasped: 503.21min
-> berries picked: 101 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5016 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [302, 576, 737, 633, 469, 587, 703, 534, 475]
	| approx positives in sample 512: 100
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 16, 9, 8, 12, 4, 12, 19, 13]
	Time taken saving stuff: 0.11s

=== episode:298 Env-steps-taken:70656
 	picked: 92 |actions: {0: 607, 1: 668, 2: 524, 3: 578, 4: 638, 5: 555, 6: 549, 7: 528, 8: 346}
episode: 298/2000 -> reward: 111.34374999999984, steps:4993, time-taken: 1.70min, time-elasped: 504.91min
-> berries picked: 92 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5032 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [298, 574, 743, 649, 465, 592, 706, 529, 476]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 10, 11, 15, 12, 8, 11, 10, 20]
	Time taken saving stuff: 0.00s

=== episode:299 Env-steps-taken:74976
 	picked: 108 |actions: {0: 761, 1: 846, 2: 746, 3: 668, 4: 717, 5: 673, 6: 590, 7: 682, 8: 427}
episode: 299/2000 -> reward: 134.8124999999999, steps:6110, time-taken: 2.12min, time-elasped: 507.03min
-> berries picked: 108 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5049 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [298, 575, 752, 649, 468, 586, 706, 536, 479]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 17, 14, 14, 9, 11, 13, 11, 11]
	Time taken saving stuff: 0.11s

=== episode:300 Env-steps-taken:76992
 	picked: 108 |actions: {0: 709, 1: 683, 2: 628, 3: 763, 4: 777, 5: 780, 6: 569, 7: 629, 8: 702}
episode: 300/2000 -> reward: 143.4270833333333, steps:6240, time-taken: 2.07min, time-elasped: 509.10min
-> berries picked: 108 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5069 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [304, 571, 754, 647, 467, 587, 717, 540, 482]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 11, 15, 13, 6, 17, 9, 10, 17]
	Time taken saving stuff: 0.05s

=== episode:30 Env-steps-taken:93504
 	picked: 164 |actions: {0: 998, 1: 508, 2: 417, 3: 869, 4: 298, 5: 1226, 6: 451, 7: 480, 8: 413}

==================================================
eval-episode: 300 -> reward: 228.7187500000005, steps: 5660.0, wall-time: 40.95s
-> berries picked: 164 of 800 | patches-visited: [0, 1, 3, 9] | juice left:-0.00
==================================================


=== episode:301 Env-steps-taken:73920
 	picked: 100 |actions: {0: 722, 1: 742, 2: 717, 3: 677, 4: 735, 5: 540, 6: 491, 7: 525, 8: 521}
episode: 301/2000 -> reward: 126.9999999999998, steps:5670, time-taken: 2.00min, time-elasped: 511.79min
-> berries picked: 100 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5104 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [312, 576, 762, 646, 468, 593, 718, 544, 485]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 15, 12, 10, 6, 15, 11, 13, 18]
	Time taken saving stuff: 0.02s

=== episode:302 Env-steps-taken:65856
 	picked: 72 |actions: {0: 871, 1: 551, 2: 473, 3: 484, 4: 639, 5: 541, 6: 489, 7: 601, 8: 394}
episode: 302/2000 -> reward: 88.87499999999996, steps:5043, time-taken: 1.75min, time-elasped: 513.54min
-> berries picked: 72 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5103 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [318, 577, 763, 645, 469, 589, 715, 544, 483]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 17, 12, 13, 9, 16, 13, 9, 26]
	Time taken saving stuff: 0.02s

=== episode:303 Env-steps-taken:73248
 	picked: 99 |actions: {0: 734, 1: 724, 2: 731, 3: 623, 4: 783, 5: 694, 6: 549, 7: 544, 8: 435}
episode: 303/2000 -> reward: 126.32812499999983, steps:5817, time-taken: 1.96min, time-elasped: 515.51min
-> berries picked: 99 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5134 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [321, 580, 769, 650, 478, 590, 718, 542, 486]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 15, 12, 14, 8, 14, 14, 21, 17]
	Time taken saving stuff: 0.10s

=== episode:304 Env-steps-taken:65088
 	picked: 62 |actions: {0: 547, 1: 594, 2: 592, 3: 346, 4: 555, 5: 436, 6: 403, 7: 536, 8: 356}
episode: 304/2000 -> reward: 85.44791666666663, steps:4365, time-taken: 1.51min, time-elasped: 517.02min
-> berries picked: 62 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5143 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [324, 582, 771, 646, 479, 591, 714, 547, 489]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 10, 19, 15, 5, 14, 14, 16, 20]
	Time taken saving stuff: 0.03s

=== episode:305 Env-steps-taken:74400
 	picked: 97 |actions: {0: 693, 1: 694, 2: 734, 3: 701, 4: 834, 5: 799, 6: 731, 7: 672, 8: 463}
episode: 305/2000 -> reward: 132.44270833333314, steps:6321, time-taken: 2.07min, time-elasped: 519.09min
-> berries picked: 97 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5166 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [322, 584, 771, 651, 485, 596, 716, 549, 492]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 11, 20, 14, 13, 13, 18, 12, 21]
	Time taken saving stuff: 0.11s

=== episode:306 Env-steps-taken:67200
 	picked: 78 |actions: {0: 687, 1: 607, 2: 446, 3: 619, 4: 836, 5: 667, 6: 437, 7: 587, 8: 391}
episode: 306/2000 -> reward: 95.53124999999991, steps:5277, time-taken: 1.88min, time-elasped: 520.98min
-> berries picked: 78 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5163 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [314, 583, 772, 657, 485, 592, 723, 545, 492]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 13, 16, 15, 17, 10, 13, 10, 13]
	Time taken saving stuff: 0.10s

=== episode:307 Env-steps-taken:70560
 	picked: 85 |actions: {0: 746, 1: 805, 2: 611, 3: 573, 4: 830, 5: 609, 6: 507, 7: 664, 8: 438}
episode: 307/2000 -> reward: 113.1302083333332, steps:5783, time-taken: 1.90min, time-elasped: 522.89min
-> berries picked: 85 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5156 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [322, 584, 774, 649, 487, 596, 712, 542, 490]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 12, 11, 20, 7, 14, 15, 8, 12]
	Time taken saving stuff: 0.04s

=== episode:308 Env-steps-taken:71040
 	picked: 88 |actions: {0: 679, 1: 590, 2: 548, 3: 503, 4: 643, 5: 619, 6: 438, 7: 570, 8: 383}
episode: 308/2000 -> reward: 115.9583333333332, steps:4973, time-taken: 1.75min, time-elasped: 524.64min
-> berries picked: 88 of 800 | patches-visited: [0, 5, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5185 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [330, 594, 778, 652, 493, 589, 715, 542, 492]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 14, 10, 11, 11, 12, 13, 10, 16]
	Time taken saving stuff: 0.11s

=== episode:309 Env-steps-taken:78144
 	picked: 112 |actions: {0: 662, 1: 712, 2: 575, 3: 646, 4: 769, 5: 782, 6: 600, 7: 631, 8: 357}
episode: 309/2000 -> reward: 151.58333333333334, steps:5734, time-taken: 2.03min, time-elasped: 526.67min
-> berries picked: 112 of 800 | patches-visited: [0, 3, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5192 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [330, 587, 778, 660, 500, 594, 709, 541, 493]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 13, 21, 11, 6, 14, 12, 11, 14]
	Time taken saving stuff: 0.12s

=== episode:310 Env-steps-taken:76224
 	picked: 110 |actions: {0: 704, 1: 772, 2: 493, 3: 578, 4: 779, 5: 807, 6: 632, 7: 686, 8: 439}
episode: 310/2000 -> reward: 141.19791666666654, steps:5890, time-taken: 2.00min, time-elasped: 528.68min
-> berries picked: 110 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5218 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [342, 588, 776, 660, 504, 598, 714, 540, 496]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 9, 21, 12, 13, 8, 12, 9, 11]
	Time taken saving stuff: 0.15s

=== episode:31 Env-steps-taken:90528
 	picked: 166 |actions: {0: 647, 1: 405, 2: 1490, 3: 355, 4: 756, 5: 450, 6: 1393, 7: 767, 8: 301}

==================================================
eval-episode: 310 -> reward: 212.98958333333383, steps: 6564.0, wall-time: 48.99s
-> berries picked: 166 of 800 | patches-visited: [0, 1, 3] | juice left:-0.00
==================================================


=== episode:311 Env-steps-taken:69312
 	picked: 76 |actions: {0: 401, 1: 565, 2: 592, 3: 536, 4: 673, 5: 571, 6: 584, 7: 514, 8: 402}
episode: 311/2000 -> reward: 107.14583333333324, steps:4838, time-taken: 1.76min, time-elasped: 531.26min
-> berries picked: 76 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5205 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [330, 594, 783, 663, 501, 591, 705, 543, 495]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 8, 11, 13, 12, 19, 18, 12, 19]
	Time taken saving stuff: 0.02s

=== episode:312 Env-steps-taken:69024
 	picked: 80 |actions: {0: 639, 1: 480, 2: 599, 3: 552, 4: 895, 5: 673, 6: 484, 7: 681, 8: 468}
episode: 312/2000 -> reward: 104.5312499999999, steps:5471, time-taken: 1.92min, time-elasped: 533.19min
-> berries picked: 80 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5185 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [327, 590, 786, 664, 500, 584, 702, 539, 493]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 9, 17, 18, 9, 10, 12, 9, 16]
	Time taken saving stuff: 0.00s

=== episode:313 Env-steps-taken:68160
 	picked: 74 |actions: {0: 430, 1: 489, 2: 434, 3: 370, 4: 576, 5: 619, 6: 456, 7: 579, 8: 342}
episode: 313/2000 -> reward: 101.26041666666657, steps:4295, time-taken: 1.56min, time-elasped: 534.75min
-> berries picked: 74 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5194 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [328, 592, 789, 663, 496, 587, 705, 540, 494]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 16, 11, 19, 8, 8, 13, 18, 13]
	Time taken saving stuff: 0.09s

=== episode:314 Env-steps-taken:75648
 	picked: 103 |actions: {0: 702, 1: 825, 2: 696, 3: 610, 4: 915, 5: 651, 6: 684, 7: 675, 8: 418}
episode: 314/2000 -> reward: 138.5989583333332, steps:6176, time-taken: 2.16min, time-elasped: 536.92min
-> berries picked: 103 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5202 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [330, 594, 791, 668, 492, 585, 707, 541, 494]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 13, 13, 21, 4, 11, 8, 9, 13]
	Time taken saving stuff: 0.00s

=== episode:315 Env-steps-taken:76608
 	picked: 104 |actions: {0: 699, 1: 794, 2: 810, 3: 683, 4: 893, 5: 650, 6: 568, 7: 661, 8: 556}
episode: 315/2000 -> reward: 143.54166666666663, steps:6314, time-taken: 2.14min, time-elasped: 539.06min
-> berries picked: 104 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5202 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [327, 594, 801, 671, 496, 583, 701, 535, 494]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 16, 15, 14, 11, 15, 12, 23, 7]
	Time taken saving stuff: 0.02s

=== episode:316 Env-steps-taken:79488
 	picked: 118 |actions: {0: 585, 1: 860, 2: 614, 3: 603, 4: 996, 5: 851, 6: 726, 7: 970, 8: 477}
episode: 316/2000 -> reward: 156.85416666666674, steps:6682, time-taken: 2.27min, time-elasped: 541.33min
-> berries picked: 118 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5233 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [330, 605, 796, 677, 498, 586, 706, 545, 490]
	| approx positives in sample 512: 95
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 12, 7, 21, 11, 13, 10, 7, 8]
	Time taken saving stuff: 0.00s

=== episode:317 Env-steps-taken:71424
 	picked: 89 |actions: {0: 622, 1: 726, 2: 533, 3: 594, 4: 651, 5: 619, 6: 554, 7: 647, 8: 390}
episode: 317/2000 -> reward: 117.40104166666653, steps:5336, time-taken: 1.94min, time-elasped: 543.27min
-> berries picked: 89 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5237 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [330, 605, 800, 678, 503, 580, 708, 541, 492]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 14, 13, 15, 12, 10, 13, 11, 10]
	Time taken saving stuff: 0.09s

=== episode:318 Env-steps-taken:72384
 	picked: 94 |actions: {0: 709, 1: 621, 2: 495, 3: 584, 4: 849, 5: 830, 6: 702, 7: 778, 8: 488}
episode: 318/2000 -> reward: 122.11458333333317, steps:6056, time-taken: 2.09min, time-elasped: 545.36min
-> berries picked: 94 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5230 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [332, 605, 799, 675, 497, 584, 700, 543, 495]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 26, 13, 14, 8, 17, 6, 17, 13]
	Time taken saving stuff: 0.00s

=== episode:319 Env-steps-taken:67392
 	picked: 72 |actions: {0: 500, 1: 456, 2: 430, 3: 451, 4: 575, 5: 564, 6: 452, 7: 349, 8: 262}
episode: 319/2000 -> reward: 96.8749999999999, steps:4039, time-taken: 1.44min, time-elasped: 546.80min
-> berries picked: 72 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5252 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [339, 611, 804, 678, 501, 584, 699, 540, 496]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 7, 24, 15, 15, 5, 14, 18, 7]
	Time taken saving stuff: 0.02s

=== episode:320 Env-steps-taken:78528
 	picked: 111 |actions: {0: 643, 1: 909, 2: 619, 3: 786, 4: 707, 5: 633, 6: 610, 7: 640, 8: 404}
episode: 320/2000 -> reward: 153.140625, steps:5951, time-taken: 2.08min, time-elasped: 548.88min
-> berries picked: 111 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5287 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [341, 614, 809, 686, 509, 585, 704, 542, 497]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 18, 9, 17, 7, 14, 12, 13, 13]
	Time taken saving stuff: 0.05s

=== episode:32 Env-steps-taken:100800
 	picked: 200 |actions: {0: 982, 1: 798, 2: 355, 3: 867, 4: 633, 5: 1022, 6: 308, 7: 862, 8: 476}

==================================================
eval-episode: 320 -> reward: 265.04166666666725, steps: 6303.0, wall-time: 49.47s
-> berries picked: 200 of 800 | patches-visited: [1, 2, 5, 7] | juice left:-0.00
==================================================


=== episode:321 Env-steps-taken:74688
 	picked: 95 |actions: {0: 858, 1: 590, 2: 479, 3: 621, 4: 627, 5: 777, 6: 619, 7: 936, 8: 465}
episode: 321/2000 -> reward: 134.05729166666652, steps:5972, time-taken: 2.04min, time-elasped: 551.75min
-> berries picked: 95 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5307 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [342, 617, 818, 686, 502, 583, 713, 547, 499]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 14, 16, 9, 11, 7, 17, 20, 16]
	Time taken saving stuff: 0.05s

=== episode:322 Env-steps-taken:76128
 	picked: 102 |actions: {0: 738, 1: 601, 2: 616, 3: 595, 4: 710, 5: 730, 6: 594, 7: 748, 8: 443}
episode: 322/2000 -> reward: 139.7708333333332, steps:5775, time-taken: 2.01min, time-elasped: 553.76min
-> berries picked: 102 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5340 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [350, 618, 825, 695, 503, 583, 718, 547, 501]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 17, 20, 10, 11, 15, 14, 13, 19]
	Time taken saving stuff: 0.11s

=== episode:323 Env-steps-taken:74688
 	picked: 101 |actions: {0: 735, 1: 691, 2: 500, 3: 640, 4: 821, 5: 720, 6: 755, 7: 597, 8: 520}
episode: 323/2000 -> reward: 133.71354166666657, steps:5979, time-taken: 2.13min, time-elasped: 555.90min
-> berries picked: 101 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5380 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [359, 622, 826, 694, 512, 590, 725, 550, 502]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 15, 25, 14, 10, 12, 13, 13, 16]
	Time taken saving stuff: 0.10s

=== episode:324 Env-steps-taken:85344
 	picked: 136 |actions: {0: 858, 1: 838, 2: 778, 3: 807, 4: 988, 5: 712, 6: 611, 7: 802, 8: 464}
episode: 324/2000 -> reward: 187.7656250000002, steps:6858, time-taken: 2.55min, time-elasped: 558.45min
-> berries picked: 136 of 800 | patches-visited: [0, 2, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5426 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [365, 631, 831, 712, 519, 593, 718, 554, 503]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 16, 15, 13, 13, 12, 10, 12, 14]
	Time taken saving stuff: 0.03s

=== episode:325 Env-steps-taken:73920
 	picked: 97 |actions: {0: 594, 1: 695, 2: 597, 3: 787, 4: 806, 5: 581, 6: 530, 7: 662, 8: 625}
episode: 325/2000 -> reward: 129.55729166666652, steps:5877, time-taken: 2.09min, time-elasped: 560.55min
-> berries picked: 97 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5455 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [363, 639, 838, 719, 521, 597, 715, 555, 508]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 19, 17, 12, 8, 11, 12, 10, 18]
	Time taken saving stuff: 0.09s

=== episode:326 Env-steps-taken:80448
 	picked: 121 |actions: {0: 728, 1: 714, 2: 711, 3: 695, 4: 706, 5: 833, 6: 697, 7: 942, 8: 570}
episode: 326/2000 -> reward: 162.56770833333346, steps:6596, time-taken: 2.30min, time-elasped: 562.84min
-> berries picked: 121 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5419 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [366, 626, 820, 719, 518, 596, 715, 553, 506]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 13, 17, 11, 8, 9, 9, 13, 14]
	Time taken saving stuff: 0.00s

=== episode:327 Env-steps-taken:51840
 	picked: 11 |actions: {0: 71, 1: 166, 2: 101, 3: 68, 4: 69, 5: 44, 6: 53, 7: 54, 8: 241}
episode: 327/2000 -> reward: 19.36979166666667, steps:867, time-taken: 0.57min, time-elasped: 563.42min
-> berries picked: 11 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5412 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [362, 627, 823, 719, 516, 595, 714, 551, 505]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 21, 10, 16, 13, 17, 12, 10, 20]
	Time taken saving stuff: 0.01s

=== episode:328 Env-steps-taken:69120
 	picked: 83 |actions: {0: 618, 1: 700, 2: 630, 3: 565, 4: 651, 5: 653, 6: 457, 7: 670, 8: 472}
episode: 328/2000 -> reward: 104.41666666666657, steps:5416, time-taken: 1.99min, time-elasped: 565.42min
-> berries picked: 83 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5412 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [365, 630, 827, 716, 517, 589, 715, 549, 504]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 12, 18, 11, 12, 12, 14, 11, 14]
	Time taken saving stuff: 0.08s

=== episode:329 Env-steps-taken:71520
 	picked: 89 |actions: {0: 626, 1: 581, 2: 678, 3: 656, 4: 735, 5: 628, 6: 562, 7: 627, 8: 560}
episode: 329/2000 -> reward: 117.9010416666665, steps:5653, time-taken: 2.02min, time-elasped: 567.44min
-> berries picked: 89 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5394 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [363, 624, 824, 715, 512, 585, 719, 546, 506]
	| approx positives in sample 512: 93
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 12, 18, 11, 5, 9, 15, 10, 9]
	Time taken saving stuff: 0.01s

=== episode:330 Env-steps-taken:64800
 	picked: 66 |actions: {0: 446, 1: 517, 2: 612, 3: 522, 4: 680, 5: 541, 6: 409, 7: 791, 8: 513}
episode: 330/2000 -> reward: 83.71874999999997, steps:5031, time-taken: 1.76min, time-elasped: 569.20min
-> berries picked: 66 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5381 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [361, 619, 819, 714, 513, 586, 714, 548, 507]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 15, 16, 11, 12, 11, 16, 14, 10]
	Time taken saving stuff: 0.13s

=== episode:33 Env-steps-taken:67776
 	picked: 74 |actions: {0: 295, 1: 395, 2: 154, 3: 479, 4: 152, 5: 265, 6: 61, 7: 316, 8: 699}

==================================================
eval-episode: 330 -> reward: 99.26041666666657, steps: 2816.0, wall-time: 30.02s
-> berries picked: 74 of 800 | patches-visited: [1, 6] | juice left:-0.00
==================================================


=== episode:331 Env-steps-taken:62592
 	picked: 56 |actions: {0: 449, 1: 402, 2: 671, 3: 495, 4: 609, 5: 467, 6: 300, 7: 467, 8: 561}
episode: 331/2000 -> reward: 72.79166666666669, steps:4421, time-taken: 1.54min, time-elasped: 571.25min
-> berries picked: 56 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5354 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [357, 611, 823, 719, 510, 581, 699, 547, 507]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 14, 15, 14, 5, 7, 18, 15, 9]
	Time taken saving stuff: 0.00s

=== episode:332 Env-steps-taken:66432
 	picked: 73 |actions: {0: 644, 1: 602, 2: 583, 3: 579, 4: 754, 5: 565, 6: 381, 7: 876, 8: 457}
episode: 332/2000 -> reward: 92.31770833333327, steps:5441, time-taken: 1.84min, time-elasped: 573.09min
-> berries picked: 73 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5363 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [355, 616, 829, 719, 508, 582, 700, 546, 508]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 13, 19, 18, 6, 16, 11, 11, 13]
	Time taken saving stuff: 0.02s

=== episode:333 Env-steps-taken:60480
 	picked: 47 |actions: {0: 457, 1: 461, 2: 496, 3: 410, 4: 975, 5: 504, 6: 392, 7: 427, 8: 739}
episode: 333/2000 -> reward: 62.80729166666671, steps:4861, time-taken: 1.76min, time-elasped: 574.86min
-> berries picked: 47 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5357 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [355, 619, 829, 715, 504, 581, 698, 546, 510]
	| approx positives in sample 512: 101
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 7, 15, 22, 9, 11, 14, 9, 10]
	Time taken saving stuff: 0.00s

=== episode:334 Env-steps-taken:56448
 	picked: 29 |actions: {0: 203, 1: 213, 2: 207, 3: 188, 4: 214, 5: 169, 6: 157, 7: 215, 8: 218}
episode: 334/2000 -> reward: 42.838541666666686, steps:1784, time-taken: 0.85min, time-elasped: 575.71min
-> berries picked: 29 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5358 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [354, 618, 833, 716, 498, 584, 696, 547, 512]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 14, 17, 13, 13, 11, 21, 11, 14]
	Time taken saving stuff: 0.01s

=== episode:335 Env-steps-taken:74784
 	picked: 102 |actions: {0: 711, 1: 677, 2: 690, 3: 591, 4: 678, 5: 467, 6: 482, 7: 893, 8: 469}
episode: 335/2000 -> reward: 134.65624999999983, steps:5658, time-taken: 2.06min, time-elasped: 577.77min
-> berries picked: 102 of 800 | patches-visited: [0, 2, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5378 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [351, 618, 838, 713, 501, 588, 696, 558, 515]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 14, 18, 10, 7, 16, 21, 12, 7]
	Time taken saving stuff: 0.00s

=== episode:336 Env-steps-taken:59424
 	picked: 45 |actions: {0: 421, 1: 317, 2: 449, 3: 299, 4: 282, 5: 223, 6: 222, 7: 370, 8: 298}
episode: 336/2000 -> reward: 57.42187500000004, steps:2881, time-taken: 1.16min, time-elasped: 578.93min
-> berries picked: 45 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5373 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [353, 614, 833, 709, 503, 585, 699, 559, 518]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 14, 8, 15, 16, 10, 16, 12, 19]
	Time taken saving stuff: 0.01s

=== episode:337 Env-steps-taken:66816
 	picked: 70 |actions: {0: 697, 1: 543, 2: 575, 3: 432, 4: 584, 5: 388, 6: 362, 7: 728, 8: 356}
episode: 337/2000 -> reward: 94.48958333333327, steps:4665, time-taken: 1.92min, time-elasped: 580.86min
-> berries picked: 70 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5382 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [354, 623, 832, 703, 500, 585, 700, 562, 523]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 14, 19, 14, 9, 13, 13, 12, 18]
	Time taken saving stuff: 0.00s

=== episode:338 Env-steps-taken:69024
 	picked: 73 |actions: {0: 736, 1: 690, 2: 676, 3: 541, 4: 672, 5: 549, 6: 372, 7: 606, 8: 544}
episode: 338/2000 -> reward: 106.31770833333321, steps:5386, time-taken: 2.09min, time-elasped: 582.96min
-> berries picked: 73 of 800 | patches-visited: [0, 3, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5375 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [354, 621, 826, 702, 498, 589, 701, 558, 526]
	| approx positives in sample 512: 99
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 7, 15, 11, 10, 9, 11, 11, 16]
	Time taken saving stuff: 0.01s

=== episode:339 Env-steps-taken:65568
 	picked: 69 |actions: {0: 617, 1: 696, 2: 662, 3: 405, 4: 613, 5: 387, 6: 409, 7: 659, 8: 429}
episode: 339/2000 -> reward: 87.54687499999996, steps:4877, time-taken: 1.75min, time-elasped: 584.71min
-> berries picked: 69 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5377 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [358, 623, 831, 692, 500, 580, 702, 565, 526]
	| approx positives in sample 512: 90
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 7, 13, 11, 12, 11, 11, 9, 11]
	Time taken saving stuff: 0.02s

=== episode:340 Env-steps-taken:65376
 	picked: 68 |actions: {0: 580, 1: 606, 2: 467, 3: 394, 4: 584, 5: 370, 6: 409, 7: 506, 8: 517}
episode: 340/2000 -> reward: 87.10416666666664, steps:4433, time-taken: 1.68min, time-elasped: 586.39min
-> berries picked: 68 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5387 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [353, 621, 834, 694, 505, 577, 708, 565, 530]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 13, 14, 17, 12, 11, 11, 16, 14]
	Time taken saving stuff: 0.06s

=== episode:34 Env-steps-taken:70368
 	picked: 84 |actions: {0: 509, 1: 394, 2: 290, 3: 321, 4: 278, 5: 115, 6: 234, 7: 218, 8: 637}

==================================================
eval-episode: 340 -> reward: 111.30208333333321, steps: 2996.0, wall-time: 30.91s
-> berries picked: 84 of 800 | patches-visited: [1, 4] | juice left:-0.00
==================================================


=== episode:341 Env-steps-taken:64032
 	picked: 66 |actions: {0: 736, 1: 727, 2: 642, 3: 617, 4: 504, 5: 469, 6: 392, 7: 470, 8: 656}
episode: 341/2000 -> reward: 79.71874999999996, steps:5213, time-taken: 1.89min, time-elasped: 588.80min
-> berries picked: 66 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5369 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [352, 624, 828, 701, 500, 572, 706, 559, 527]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 20, 13, 13, 11, 5, 12, 7, 20]
	Time taken saving stuff: 0.10s

=== episode:342 Env-steps-taken:64032
 	picked: 68 |actions: {0: 944, 1: 669, 2: 540, 3: 612, 4: 777, 5: 453, 6: 520, 7: 798, 8: 509}
episode: 342/2000 -> reward: 79.60416666666667, steps:5822, time-taken: 2.76min, time-elasped: 591.57min
-> berries picked: 68 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5354 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [351, 623, 826, 700, 497, 566, 706, 563, 522]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 13, 12, 14, 11, 11, 12, 13, 11]
	Time taken saving stuff: 0.00s

=== episode:343 Env-steps-taken:62784
 	picked: 57 |actions: {0: 592, 1: 571, 2: 399, 3: 432, 4: 670, 5: 458, 6: 418, 7: 632, 8: 348}
episode: 343/2000 -> reward: 74.234375, steps:4520, time-taken: 1.65min, time-elasped: 593.22min
-> berries picked: 57 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5350 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [351, 621, 828, 698, 497, 565, 706, 561, 523]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 19, 7, 18, 10, 14, 11, 13, 13]
	Time taken saving stuff: 0.00s

=== episode:344 Env-steps-taken:73152
 	picked: 92 |actions: {0: 700, 1: 684, 2: 547, 3: 675, 4: 872, 5: 557, 6: 545, 7: 530, 8: 440}
episode: 344/2000 -> reward: 126.22916666666649, steps:5550, time-taken: 1.98min, time-elasped: 595.20min
-> berries picked: 92 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5358 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [357, 621, 825, 692, 507, 565, 709, 558, 524]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 9, 24, 11, 10, 16, 16, 11, 13]
	Time taken saving stuff: 0.00s

=== episode:345 Env-steps-taken:67968
 	picked: 74 |actions: {0: 604, 1: 657, 2: 522, 3: 788, 4: 491, 5: 418, 6: 504, 7: 428, 8: 370}
episode: 345/2000 -> reward: 100.26041666666657, steps:4782, time-taken: 1.74min, time-elasped: 596.95min
-> berries picked: 74 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5358 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [355, 621, 825, 696, 512, 563, 706, 554, 526]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 19, 18, 12, 7, 11, 13, 10, 17]
	Time taken saving stuff: 0.00s

=== episode:346 Env-steps-taken:66528
 	picked: 73 |actions: {0: 677, 1: 744, 2: 844, 3: 447, 4: 660, 5: 446, 6: 518, 7: 556, 8: 578}
episode: 346/2000 -> reward: 92.31770833333326, steps:5470, time-taken: 2.66min, time-elasped: 599.61min
-> berries picked: 73 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5329 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [354, 620, 824, 685, 507, 555, 707, 550, 527]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 16, 9, 18, 8, 5, 18, 10, 10]
	Time taken saving stuff: 0.00s

=== episode:347 Env-steps-taken:62784
 	picked: 53 |actions: {0: 494, 1: 522, 2: 364, 3: 303, 4: 383, 5: 357, 6: 396, 7: 567, 8: 490}
episode: 347/2000 -> reward: 72.52083333333334, steps:3876, time-taken: 1.57min, time-elasped: 601.18min
-> berries picked: 53 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5315 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [359, 625, 815, 682, 501, 550, 708, 549, 526]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 7, 15, 8, 12, 16, 16, 10, 12]
	Time taken saving stuff: 0.00s

=== episode:348 Env-steps-taken:61248
 	picked: 53 |actions: {0: 555, 1: 514, 2: 515, 3: 505, 4: 659, 5: 329, 6: 351, 7: 567, 8: 417}
episode: 348/2000 -> reward: 65.96354166666671, steps:4412, time-taken: 1.70min, time-elasped: 602.88min
-> berries picked: 53 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5309 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [359, 625, 817, 682, 501, 544, 708, 548, 525]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 11, 16, 12, 10, 12, 10, 9, 19]
	Time taken saving stuff: 0.00s

=== episode:349 Env-steps-taken:70752
 	picked: 93 |actions: {0: 705, 1: 636, 2: 646, 3: 803, 4: 619, 5: 502, 6: 443, 7: 790, 8: 493}
episode: 349/2000 -> reward: 113.67187499999984, steps:5637, time-taken: 2.52min, time-elasped: 605.41min
-> berries picked: 93 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5311 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [363, 628, 811, 685, 500, 546, 705, 548, 525]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 6, 15, 16, 7, 13, 14, 15, 11]
	Time taken saving stuff: 0.01s

=== episode:350 Env-steps-taken:72096
 	picked: 90 |actions: {0: 640, 1: 786, 2: 570, 3: 527, 4: 597, 5: 481, 6: 455, 7: 728, 8: 695}
episode: 350/2000 -> reward: 119.45833333333314, steps:5479, time-taken: 2.00min, time-elasped: 607.41min
-> berries picked: 90 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5302 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [362, 633, 810, 678, 500, 541, 702, 549, 527]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 12, 13, 16, 11, 17, 12, 7, 15]
	Time taken saving stuff: 0.15s

=== episode:35 Env-steps-taken:48864
 	picked: 3 |actions: {0: 0, 1: 2, 2: 0, 3: 0, 4: 5, 5: 9, 6: 10, 7: 0, 8: 52}

==================================================
eval-episode: 350 -> reward: 4.328125, steps: 78.0, wall-time: 25.93s
-> berries picked: 3 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:351 Env-steps-taken:68928
 	picked: 74 |actions: {0: 694, 1: 734, 2: 777, 3: 579, 4: 702, 5: 535, 6: 473, 7: 739, 8: 558}
episode: 351/2000 -> reward: 103.87499999999989, steps:5791, time-taken: 2.17min, time-elasped: 610.02min
-> berries picked: 74 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5282 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [357, 627, 804, 676, 504, 542, 707, 539, 526]
	| approx positives in sample 512: 92
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 8, 12, 16, 10, 10, 6, 7, 12]
	Time taken saving stuff: 0.08s

=== episode:352 Env-steps-taken:71424
 	picked: 91 |actions: {0: 599, 1: 684, 2: 660, 3: 569, 4: 735, 5: 604, 6: 478, 7: 1105, 8: 594}
episode: 352/2000 -> reward: 117.28645833333316, steps:6028, time-taken: 2.15min, time-elasped: 612.17min
-> berries picked: 91 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5284 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [356, 635, 798, 683, 497, 539, 708, 539, 529]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 9, 19, 15, 17, 10, 15, 7, 13]
	Time taken saving stuff: 0.01s

=== episode:353 Env-steps-taken:66048
 	picked: 74 |actions: {0: 702, 1: 687, 2: 612, 3: 447, 4: 718, 5: 590, 6: 495, 7: 921, 8: 569}
episode: 353/2000 -> reward: 89.7604166666666, steps:5741, time-taken: 2.51min, time-elasped: 614.69min
-> berries picked: 74 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5267 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [357, 637, 797, 677, 493, 540, 698, 538, 530]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 7, 17, 12, 12, 7, 19, 10, 21]
	Time taken saving stuff: 0.01s

=== episode:354 Env-steps-taken:64896
 	picked: 61 |actions: {0: 583, 1: 625, 2: 508, 3: 440, 4: 699, 5: 472, 6: 390, 7: 894, 8: 593}
episode: 354/2000 -> reward: 85.00520833333331, steps:5204, time-taken: 2.59min, time-elasped: 617.28min
-> berries picked: 61 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5267 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [359, 641, 792, 672, 498, 542, 695, 539, 529]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 15, 13, 12, 9, 10, 17, 6, 17]
	Time taken saving stuff: 0.00s

=== episode:355 Env-steps-taken:59232
 	picked: 46 |actions: {0: 311, 1: 423, 2: 388, 3: 261, 4: 398, 5: 281, 6: 259, 7: 400, 8: 409}
episode: 355/2000 -> reward: 56.86458333333337, steps:3130, time-taken: 1.37min, time-elasped: 618.65min
-> berries picked: 46 of 800 | patches-visited: [0, 3, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5277 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [358, 646, 794, 676, 500, 540, 696, 539, 528]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 14, 12, 15, 17, 12, 16, 12, 16]
	Time taken saving stuff: 0.00s

=== episode:356 Env-steps-taken:57216
 	picked: 35 |actions: {0: 307, 1: 285, 2: 257, 3: 275, 4: 271, 5: 242, 6: 205, 7: 385, 8: 222}
episode: 356/2000 -> reward: 45.99479166666668, steps:2449, time-taken: 1.10min, time-elasped: 619.76min
-> berries picked: 35 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5267 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [363, 648, 790, 669, 503, 541, 691, 536, 526]
	| approx positives in sample 512: 101
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 8, 14, 13, 12, 13, 16, 7, 14]
	Time taken saving stuff: 0.00s

=== episode:357 Env-steps-taken:63168
 	picked: 56 |actions: {0: 353, 1: 395, 2: 312, 3: 219, 4: 537, 5: 281, 6: 246, 7: 475, 8: 258}
episode: 357/2000 -> reward: 76.29166666666669, steps:3076, time-taken: 1.31min, time-elasped: 621.07min
-> berries picked: 56 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5267 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [364, 646, 791, 669, 503, 541, 687, 536, 530]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 13, 17, 10, 14, 7, 16, 9, 17]
	Time taken saving stuff: 0.00s

=== episode:358 Env-steps-taken:48672
 	picked: 3 |actions: {0: 111, 1: 84, 2: 83, 3: 84, 4: 102, 5: 39, 6: 26, 7: 48, 8: 90}
episode: 358/2000 -> reward: 3.828124999999999, steps:667, time-taken: 0.57min, time-elasped: 621.64min
-> berries picked: 3 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5265 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [363, 646, 792, 668, 503, 541, 685, 536, 531]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 6, 21, 6, 9, 6, 14, 13, 15]
	Time taken saving stuff: 0.09s

=== episode:359 Env-steps-taken:74304
 	picked: 94 |actions: {0: 525, 1: 909, 2: 622, 3: 604, 4: 739, 5: 641, 6: 629, 7: 667, 8: 419}
episode: 359/2000 -> reward: 132.1145833333332, steps:5755, time-taken: 2.16min, time-elasped: 623.81min
-> berries picked: 94 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5262 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [360, 646, 797, 666, 502, 548, 686, 531, 526]
	| approx positives in sample 512: 100
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 12, 24, 10, 8, 4, 14, 8, 15]
	Time taken saving stuff: 0.05s

=== episode:360 Env-steps-taken:63456
 	picked: 56 |actions: {0: 424, 1: 501, 2: 490, 3: 632, 4: 630, 5: 374, 6: 544, 7: 611, 8: 524}
episode: 360/2000 -> reward: 77.79166666666664, steps:4730, time-taken: 1.71min, time-elasped: 625.52min
-> berries picked: 56 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5236 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [365, 651, 792, 664, 500, 537, 677, 525, 525]
	| approx positives in sample 512: 93
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 13, 16, 14, 11, 9, 7, 8, 10]
	Time taken saving stuff: 0.14s

=== episode:36 Env-steps-taken:69792
 	picked: 84 |actions: {0: 125, 1: 796, 2: 87, 3: 475, 4: 225, 5: 153, 6: 607, 7: 179, 8: 302}

==================================================
eval-episode: 360 -> reward: 109.6874999999999, steps: 2949.0, wall-time: 35.40s
-> berries picked: 84 of 800 | patches-visited: [0, 1, 8] | juice left:-0.00
==================================================


=== episode:361 Env-steps-taken:64800
 	picked: 67 |actions: {0: 648, 1: 637, 2: 653, 3: 613, 4: 626, 5: 511, 6: 484, 7: 598, 8: 617}
episode: 361/2000 -> reward: 84.1614583333333, steps:5387, time-taken: 1.95min, time-elasped: 628.07min
-> berries picked: 67 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5234 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [370, 658, 795, 661, 494, 534, 670, 527, 525]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 6, 9, 19, 8, 13, 18, 11, 22]
	Time taken saving stuff: 0.10s

=== episode:362 Env-steps-taken:65184
 	picked: 66 |actions: {0: 648, 1: 772, 2: 556, 3: 537, 4: 463, 5: 426, 6: 494, 7: 653, 8: 710}
episode: 362/2000 -> reward: 85.71874999999996, steps:5259, time-taken: 1.98min, time-elasped: 630.06min
-> berries picked: 66 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5218 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [370, 665, 788, 664, 492, 528, 664, 523, 524]
	| approx positives in sample 512: 96
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 9, 17, 13, 10, 12, 8, 8, 11]
	Time taken saving stuff: 0.01s

=== episode:363 Env-steps-taken:70464
 	picked: 81 |actions: {0: 584, 1: 537, 2: 451, 3: 451, 4: 575, 5: 363, 6: 380, 7: 484, 8: 454}
episode: 363/2000 -> reward: 111.41666666666656, steps:4279, time-taken: 1.66min, time-elasped: 631.72min
-> berries picked: 81 of 800 | patches-visited: [0, 4, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5241 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [382, 668, 787, 665, 493, 532, 661, 527, 526]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 15, 20, 10, 8, 11, 14, 8, 14]
	Time taken saving stuff: 0.01s

=== episode:364 Env-steps-taken:74496
 	picked: 107 |actions: {0: 640, 1: 740, 2: 723, 3: 675, 4: 711, 5: 577, 6: 572, 7: 823, 8: 420}
episode: 364/2000 -> reward: 132.36979166666657, steps:5881, time-taken: 2.24min, time-elasped: 633.96min
-> berries picked: 107 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5265 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [392, 677, 791, 664, 500, 530, 660, 523, 528]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 14, 17, 16, 13, 8, 11, 9, 13]
	Time taken saving stuff: 0.09s

=== episode:365 Env-steps-taken:57888
 	picked: 39 |actions: {0: 288, 1: 286, 2: 278, 3: 284, 4: 446, 5: 238, 6: 258, 7: 357, 8: 239}
episode: 365/2000 -> reward: 49.76562500000004, steps:2674, time-taken: 1.18min, time-elasped: 635.15min
-> berries picked: 39 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5271 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [395, 672, 794, 668, 502, 528, 661, 520, 531]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 7, 11, 15, 12, 4, 16, 11, 18]
	Time taken saving stuff: 0.02s

=== episode:366 Env-steps-taken:65952
 	picked: 75 |actions: {0: 511, 1: 578, 2: 470, 3: 462, 4: 484, 5: 486, 6: 338, 7: 582, 8: 415}
episode: 366/2000 -> reward: 89.70312499999993, steps:4326, time-taken: 1.58min, time-elasped: 636.73min
-> berries picked: 75 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5301 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [402, 678, 793, 672, 502, 531, 667, 524, 532]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 12, 18, 13, 7, 10, 9, 6, 7]
	Time taken saving stuff: 0.10s

=== episode:367 Env-steps-taken:71904
 	picked: 90 |actions: {0: 604, 1: 605, 2: 703, 3: 396, 4: 570, 5: 467, 6: 476, 7: 774, 8: 423}
episode: 367/2000 -> reward: 118.4010416666665, steps:5018, time-taken: 1.97min, time-elasped: 638.71min
-> berries picked: 90 of 800 | patches-visited: [0, 5, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5315 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [398, 677, 798, 676, 500, 532, 669, 531, 534]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 17, 14, 13, 7, 9, 13, 6, 16]
	Time taken saving stuff: 0.01s

=== episode:368 Env-steps-taken:62112
 	picked: 55 |actions: {0: 399, 1: 366, 2: 331, 3: 432, 4: 369, 5: 361, 6: 442, 7: 449, 8: 326}
episode: 368/2000 -> reward: 70.34895833333337, steps:3475, time-taken: 1.51min, time-elasped: 640.22min
-> berries picked: 55 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5319 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [393, 685, 794, 677, 500, 528, 679, 528, 535]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 13, 11, 11, 10, 7, 18, 9, 20]
	Time taken saving stuff: 0.09s

=== episode:369 Env-steps-taken:82368
 	picked: 126 |actions: {0: 736, 1: 764, 2: 725, 3: 597, 4: 746, 5: 693, 6: 676, 7: 933, 8: 463}
episode: 369/2000 -> reward: 172.78125000000017, steps:6333, time-taken: 2.43min, time-elasped: 642.66min
-> berries picked: 126 of 800 | patches-visited: [0, 1, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5360 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [403, 690, 796, 674, 503, 534, 685, 537, 538]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 12, 11, 16, 11, 13, 15, 7, 16]
	Time taken saving stuff: 0.10s

=== episode:370 Env-steps-taken:76992
 	picked: 106 |actions: {0: 859, 1: 724, 2: 767, 3: 699, 4: 705, 5: 620, 6: 673, 7: 822, 8: 548}
episode: 370/2000 -> reward: 145.42708333333334, steps:6417, time-taken: 2.55min, time-elasped: 645.22min
-> berries picked: 106 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5368 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [403, 696, 802, 666, 501, 529, 682, 549, 540]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 20, 20, 16, 9, 12, 14, 6, 17]
	Time taken saving stuff: 0.16s

=== episode:37 Env-steps-taken:74112
 	picked: 102 |actions: {0: 359, 1: 366, 2: 794, 3: 190, 4: 922, 5: 155, 6: 174, 7: 1033, 8: 501}

==================================================
eval-episode: 370 -> reward: 131.15624999999983, steps: 4494.0, wall-time: 49.31s
-> berries picked: 102 of 800 | patches-visited: [1, 2, 7] | juice left:-0.00
==================================================


=== episode:371 Env-steps-taken:70944
 	picked: 87 |actions: {0: 770, 1: 795, 2: 609, 3: 500, 4: 713, 5: 535, 6: 638, 7: 900, 8: 542}
episode: 371/2000 -> reward: 115.01562499999987, steps:6002, time-taken: 2.29min, time-elasped: 648.34min
-> berries picked: 87 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5372 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [407, 694, 805, 666, 497, 528, 690, 544, 541]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 10, 13, 8, 12, 19, 17, 16, 21]
	Time taken saving stuff: 0.00s

=== episode:372 Env-steps-taken:65472
 	picked: 67 |actions: {0: 687, 1: 886, 2: 705, 3: 769, 4: 753, 5: 460, 6: 494, 7: 563, 8: 635}
episode: 372/2000 -> reward: 87.16145833333329, steps:5952, time-taken: 2.24min, time-elasped: 650.58min
-> berries picked: 67 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5354 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [409, 688, 807, 661, 495, 524, 689, 539, 542]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 19, 17, 17, 10, 14, 15, 12, 9]
	Time taken saving stuff: 0.00s

=== episode:373 Env-steps-taken:62400
 	picked: 57 |actions: {0: 906, 1: 576, 2: 688, 3: 495, 4: 902, 5: 536, 6: 474, 7: 679, 8: 399}
episode: 373/2000 -> reward: 71.73437500000001, steps:5655, time-taken: 2.09min, time-elasped: 652.67min
-> berries picked: 57 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5336 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [406, 687, 808, 655, 491, 523, 688, 538, 540]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 8, 17, 6, 10, 14, 12, 14, 17]
	Time taken saving stuff: 0.01s

=== episode:374 Env-steps-taken:67776
 	picked: 78 |actions: {0: 671, 1: 678, 2: 712, 3: 606, 4: 688, 5: 461, 6: 452, 7: 514, 8: 560}
episode: 374/2000 -> reward: 99.0312499999999, steps:5342, time-taken: 1.92min, time-elasped: 654.58min
-> berries picked: 78 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5336 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [410, 683, 809, 654, 487, 522, 692, 539, 540]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 15, 14, 18, 8, 10, 10, 16, 12]
	Time taken saving stuff: 0.11s

=== episode:375 Env-steps-taken:67392
 	picked: 71 |actions: {0: 795, 1: 581, 2: 568, 3: 498, 4: 693, 5: 435, 6: 332, 7: 418, 8: 306}
episode: 375/2000 -> reward: 97.4322916666666, steps:4626, time-taken: 1.83min, time-elasped: 656.42min
-> berries picked: 71 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5350 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [421, 679, 816, 657, 488, 520, 690, 541, 538]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 15, 21, 20, 7, 13, 12, 8, 9]
	Time taken saving stuff: 0.02s

=== episode:376 Env-steps-taken:65472
 	picked: 64 |actions: {0: 347, 1: 473, 2: 316, 3: 394, 4: 355, 5: 366, 6: 276, 7: 351, 8: 252}
episode: 376/2000 -> reward: 87.83333333333327, steps:3130, time-taken: 1.30min, time-elasped: 657.72min
-> berries picked: 64 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5368 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [427, 673, 820, 660, 491, 522, 688, 547, 540]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 12, 9, 19, 12, 7, 15, 12, 12]
	Time taken saving stuff: 0.09s

=== episode:377 Env-steps-taken:73440
 	picked: 90 |actions: {0: 647, 1: 760, 2: 687, 3: 811, 4: 737, 5: 650, 6: 631, 7: 680, 8: 592}
episode: 377/2000 -> reward: 127.84374999999982, steps:6195, time-taken: 3.19min, time-elasped: 660.92min
-> berries picked: 90 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5366 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [429, 667, 820, 668, 481, 523, 688, 552, 538]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 11, 15, 13, 10, 12, 11, 9, 18]
	Time taken saving stuff: 0.07s

=== episode:378 Env-steps-taken:66528
 	picked: 71 |actions: {0: 588, 1: 732, 2: 471, 3: 483, 4: 585, 5: 395, 6: 427, 7: 495, 8: 434}
episode: 378/2000 -> reward: 92.93229166666661, steps:4610, time-taken: 2.45min, time-elasped: 663.38min
-> berries picked: 71 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5395 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [436, 675, 827, 668, 485, 527, 687, 551, 539]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 14, 16, 10, 6, 7, 12, 15, 12]
	Time taken saving stuff: 0.01s

=== episode:379 Env-steps-taken:64320
 	picked: 66 |actions: {0: 637, 1: 792, 2: 513, 3: 537, 4: 612, 5: 526, 6: 484, 7: 715, 8: 451}
episode: 379/2000 -> reward: 81.21874999999997, steps:5267, time-taken: 2.46min, time-elasped: 665.84min
-> berries picked: 66 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5384 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [445, 670, 816, 667, 479, 524, 692, 552, 539]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 8, 9, 13, 9, 17, 11, 12, 19]
	Time taken saving stuff: 0.02s

=== episode:380 Env-steps-taken:60672
 	picked: 44 |actions: {0: 460, 1: 347, 2: 391, 3: 416, 4: 475, 5: 411, 6: 364, 7: 325, 8: 366}
episode: 380/2000 -> reward: 63.97916666666672, steps:3555, time-taken: 1.90min, time-elasped: 667.74min
-> berries picked: 44 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5395 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [449, 667, 817, 669, 481, 528, 690, 555, 539]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 8, 19, 17, 9, 7, 12, 13, 14]
	Time taken saving stuff: 0.18s

=== episode:38 Env-steps-taken:65664
 	picked: 66 |actions: {0: 244, 1: 1073, 2: 141, 3: 151, 4: 499, 5: 148, 6: 166, 7: 754, 8: 1038}

==================================================
eval-episode: 380 -> reward: 88.71874999999997, steps: 4214.0, wall-time: 54.03s
-> berries picked: 66 of 800 | patches-visited: [1, 4] | juice left:-0.00
==================================================


=== episode:381 Env-steps-taken:64416
 	picked: 62 |actions: {0: 552, 1: 634, 2: 540, 3: 653, 4: 561, 5: 345, 6: 392, 7: 736, 8: 481}
episode: 381/2000 -> reward: 82.44791666666664, steps:4894, time-taken: 2.52min, time-elasped: 671.16min
-> berries picked: 62 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5395 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [450, 668, 820, 665, 481, 527, 687, 557, 540]
	| approx positives in sample 512: 96
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 5, 13, 13, 11, 5, 14, 9, 17]
	Time taken saving stuff: 0.08s

=== episode:382 Env-steps-taken:61728
 	picked: 54 |actions: {0: 746, 1: 1078, 2: 485, 3: 544, 4: 642, 5: 459, 6: 501, 7: 574, 8: 583}
episode: 382/2000 -> reward: 68.40625000000001, steps:5612, time-taken: 2.54min, time-elasped: 673.71min
-> berries picked: 54 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5386 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [455, 674, 819, 657, 474, 526, 684, 557, 540]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 18, 19, 16, 11, 13, 10, 13, 12]
	Time taken saving stuff: 0.11s

=== episode:383 Env-steps-taken:69984
 	picked: 80 |actions: {0: 637, 1: 655, 2: 418, 3: 525, 4: 511, 5: 542, 6: 401, 7: 593, 8: 499}
episode: 383/2000 -> reward: 110.91666666666656, steps:4781, time-taken: 2.22min, time-elasped: 675.93min
-> berries picked: 80 of 800 | patches-visited: [0, 3, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5414 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [455, 684, 818, 660, 473, 529, 688, 564, 543]
	| approx positives in sample 512: 95
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 10, 16, 11, 12, 11, 13, 10, 7]
	Time taken saving stuff: 0.11s

=== episode:384 Env-steps-taken:64608
 	picked: 58 |actions: {0: 434, 1: 578, 2: 459, 3: 473, 4: 347, 5: 389, 6: 283, 7: 510, 8: 396}
episode: 384/2000 -> reward: 83.6770833333333, steps:3869, time-taken: 2.02min, time-elasped: 677.95min
-> berries picked: 58 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5419 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [453, 692, 820, 657, 474, 526, 691, 561, 545]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 18, 16, 9, 10, 13, 11, 10, 13]
	Time taken saving stuff: 0.02s

=== episode:385 Env-steps-taken:70080
 	picked: 88 |actions: {0: 666, 1: 743, 2: 702, 3: 773, 4: 708, 5: 635, 6: 474, 7: 771, 8: 480}
episode: 385/2000 -> reward: 110.07291666666654, steps:5952, time-taken: 2.85min, time-elasped: 680.81min
-> berries picked: 88 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5437 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [453, 687, 825, 660, 480, 528, 693, 563, 548]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 16, 14, 14, 9, 11, 14, 15, 15]
	Time taken saving stuff: 0.00s

=== episode:386 Env-steps-taken:73248
 	picked: 93 |actions: {0: 890, 1: 866, 2: 694, 3: 715, 4: 642, 5: 670, 6: 553, 7: 740, 8: 518}
episode: 386/2000 -> reward: 126.67187499999984, steps:6288, time-taken: 3.11min, time-elasped: 683.92min
-> berries picked: 93 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5431 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [455, 691, 821, 659, 480, 522, 698, 558, 547]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 18, 20, 13, 7, 9, 10, 17, 18]
	Time taken saving stuff: 0.02s

=== episode:387 Env-steps-taken:72960
 	picked: 95 |actions: {0: 677, 1: 921, 2: 686, 3: 602, 4: 705, 5: 637, 6: 501, 7: 803, 8: 537}
episode: 387/2000 -> reward: 125.05729166666646, steps:6069, time-taken: 2.95min, time-elasped: 686.87min
-> berries picked: 95 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5432 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [462, 690, 828, 654, 484, 515, 697, 557, 545]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 16, 11, 8, 10, 10, 16, 14, 25]
	Time taken saving stuff: 0.08s

=== episode:388 Env-steps-taken:64224
 	picked: 57 |actions: {0: 565, 1: 453, 2: 384, 3: 379, 4: 499, 5: 317, 6: 306, 7: 530, 8: 497}
episode: 388/2000 -> reward: 81.73437499999997, steps:3930, time-taken: 2.08min, time-elasped: 688.96min
-> berries picked: 57 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5435 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [461, 688, 829, 660, 483, 519, 688, 561, 546]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 11, 15, 21, 3, 7, 13, 10, 15]
	Time taken saving stuff: 0.01s

=== episode:389 Env-steps-taken:70080
 	picked: 85 |actions: {0: 761, 1: 517, 2: 622, 3: 574, 4: 533, 5: 656, 6: 527, 7: 581, 8: 404}
episode: 389/2000 -> reward: 109.80208333333321, steps:5175, time-taken: 2.57min, time-elasped: 691.54min
-> berries picked: 85 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5442 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [468, 689, 827, 664, 488, 517, 688, 556, 545]
	| approx positives in sample 512: 93
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 9, 10, 14, 8, 9, 8, 16, 8]
	Time taken saving stuff: 0.01s

=== episode:390 Env-steps-taken:78624
 	picked: 112 |actions: {0: 829, 1: 772, 2: 595, 3: 738, 4: 742, 5: 512, 6: 721, 7: 752, 8: 600}
episode: 390/2000 -> reward: 151.69791666666666, steps:6261, time-taken: 3.11min, time-elasped: 694.66min
-> berries picked: 112 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5464 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [469, 696, 827, 661, 487, 522, 695, 559, 548]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 12, 20, 15, 14, 8, 8, 10, 13]
	Time taken saving stuff: 0.16s

=== episode:39 Env-steps-taken:75456
 	picked: 96 |actions: {0: 1398, 1: 114, 2: 618, 3: 237, 4: 225, 5: 376, 6: 157, 7: 785, 8: 1127}

==================================================
eval-episode: 390 -> reward: 138.99999999999991, steps: 5037.0, wall-time: 45.24s
-> berries picked: 96 of 800 | patches-visited: [1, 4, 5, 7] | juice left:-0.00
==================================================


=== episode:391 Env-steps-taken:65280
 	picked: 68 |actions: {0: 537, 1: 492, 2: 492, 3: 370, 4: 490, 5: 451, 6: 291, 7: 360, 8: 333}
episode: 391/2000 -> reward: 85.21874999999997, steps:3816, time-taken: 2.09min, time-elasped: 697.50min
-> berries picked: 68 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5470 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [474, 697, 825, 663, 489, 521, 696, 556, 549]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 13, 14, 13, 16, 16, 14, 12, 22]
	Time taken saving stuff: 0.09s

=== episode:392 Env-steps-taken:60000
 	picked: 48 |actions: {0: 516, 1: 435, 2: 769, 3: 468, 4: 397, 5: 302, 6: 269, 7: 328, 8: 488}
episode: 392/2000 -> reward: 60.25000000000005, steps:3972, time-taken: 2.04min, time-elasped: 699.54min
-> berries picked: 48 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5469 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [475, 696, 830, 661, 483, 523, 695, 555, 551]
	| approx positives in sample 512: 96
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 12, 15, 13, 8, 9, 6, 10, 13]
	Time taken saving stuff: 0.09s

=== episode:393 Env-steps-taken:59616
 	picked: 42 |actions: {0: 454, 1: 382, 2: 494, 3: 353, 4: 376, 5: 316, 6: 279, 7: 444, 8: 340}
episode: 393/2000 -> reward: 59.09375000000003, steps:3438, time-taken: 2.02min, time-elasped: 701.57min
-> berries picked: 42 of 800 | patches-visited: [0, 1, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5469 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [478, 695, 836, 660, 481, 519, 692, 555, 553]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 12, 24, 12, 7, 8, 13, 14, 22]
	Time taken saving stuff: 0.10s

=== episode:394 Env-steps-taken:67776
 	picked: 76 |actions: {0: 685, 1: 469, 2: 730, 3: 562, 4: 609, 5: 549, 6: 404, 7: 614, 8: 470}
episode: 394/2000 -> reward: 97.76041666666657, steps:5092, time-taken: 2.39min, time-elasped: 703.96min
-> berries picked: 76 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5486 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [470, 696, 843, 665, 483, 522, 694, 556, 557]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 9, 22, 10, 13, 10, 14, 16, 16]
	Time taken saving stuff: 0.04s

=== episode:395 Env-steps-taken:66912
 	picked: 64 |actions: {0: 464, 1: 455, 2: 326, 3: 310, 4: 332, 5: 489, 6: 281, 7: 329, 8: 338}
episode: 395/2000 -> reward: 93.44791666666661, steps:3324, time-taken: 1.83min, time-elasped: 705.80min
-> berries picked: 64 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5500 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [470, 701, 849, 666, 484, 520, 693, 556, 561]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 11, 12, 13, 11, 14, 16, 16, 15]
	Time taken saving stuff: 0.01s

=== episode:396 Env-steps-taken:57216
 	picked: 35 |actions: {0: 458, 1: 515, 2: 724, 3: 446, 4: 432, 5: 260, 6: 318, 7: 422, 8: 405}
episode: 396/2000 -> reward: 46.494791666666686, steps:3980, time-taken: 1.93min, time-elasped: 707.73min
-> berries picked: 35 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5482 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [474, 697, 848, 663, 479, 521, 683, 556, 561]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 10, 16, 12, 9, 12, 21, 13, 18]
	Time taken saving stuff: 0.01s

=== episode:397 Env-steps-taken:57792
 	picked: 37 |actions: {0: 420, 1: 265, 2: 361, 3: 310, 4: 427, 5: 227, 6: 216, 7: 262, 8: 188}
episode: 397/2000 -> reward: 49.380208333333364, steps:2676, time-taken: 1.53min, time-elasped: 709.27min
-> berries picked: 37 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5485 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [475, 702, 848, 662, 480, 522, 681, 552, 563]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 11, 20, 8, 7, 10, 17, 9, 17]
	Time taken saving stuff: 0.01s

=== episode:398 Env-steps-taken:66432
 	picked: 71 |actions: {0: 633, 1: 657, 2: 719, 3: 579, 4: 438, 5: 437, 6: 398, 7: 633, 8: 629}
episode: 398/2000 -> reward: 92.4322916666666, steps:5123, time-taken: 2.63min, time-elasped: 711.90min
-> berries picked: 71 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5488 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [477, 706, 846, 663, 479, 521, 684, 548, 564]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 20, 18, 17, 12, 12, 18, 18, 13]
	Time taken saving stuff: 0.00s

=== episode:399 Env-steps-taken:51840
 	picked: 15 |actions: {0: 122, 1: 139, 2: 168, 3: 128, 4: 88, 5: 76, 6: 52, 7: 64, 8: 93}
episode: 399/2000 -> reward: 19.140624999999996, steps:930, time-taken: 0.76min, time-elasped: 712.67min
-> berries picked: 15 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5491 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [479, 708, 846, 664, 480, 519, 685, 546, 564]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 14, 9, 6, 19, 13, 11, 7, 13]
	Time taken saving stuff: 0.03s

=== episode:400 Env-steps-taken:60000
 	picked: 46 |actions: {0: 420, 1: 320, 2: 379, 3: 384, 4: 298, 5: 281, 6: 270, 7: 261, 8: 217}
episode: 400/2000 -> reward: 60.36458333333337, steps:2830, time-taken: 1.81min, time-elasped: 714.48min
-> berries picked: 46 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5502 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [482, 709, 851, 666, 479, 518, 688, 545, 564]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 19, 11, 17, 8, 7, 18, 11, 12]
	Time taken saving stuff: 0.15s

=== episode:40 Env-steps-taken:55008
 	picked: 25 |actions: {0: 287, 1: 171, 2: 351, 3: 65, 4: 56, 5: 320, 6: 41, 7: 123, 8: 17}

==================================================
eval-episode: 400 -> reward: 35.56770833333334, steps: 1431.0, wall-time: 37.11s
-> berries picked: 25 of 800 | patches-visited: [0, 1] | juice left:-0.00
==================================================


=== episode:401 Env-steps-taken:50112
 	picked: 9 |actions: {0: 101, 1: 130, 2: 92, 3: 93, 4: 129, 5: 99, 6: 47, 7: 88, 8: 89}
episode: 401/2000 -> reward: 10.484375, steps:868, time-taken: 0.81min, time-elasped: 715.92min
-> berries picked: 9 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5500 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [481, 709, 853, 666, 479, 517, 686, 545, 564]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 11, 23, 13, 8, 9, 22, 7, 16]
	Time taken saving stuff: 0.02s

=== episode:402 Env-steps-taken:63552
 	picked: 67 |actions: {0: 943, 1: 661, 2: 703, 3: 516, 4: 725, 5: 595, 6: 425, 7: 651, 8: 507}
episode: 402/2000 -> reward: 77.16145833333333, steps:5726, time-taken: 2.78min, time-elasped: 718.70min
-> berries picked: 67 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5498 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [479, 706, 864, 661, 479, 513, 686, 545, 565]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 15, 21, 15, 11, 10, 11, 17, 20]
	Time taken saving stuff: 0.02s

=== episode:403 Env-steps-taken:63648
 	picked: 60 |actions: {0: 709, 1: 772, 2: 600, 3: 619, 4: 692, 5: 485, 6: 408, 7: 599, 8: 480}
episode: 403/2000 -> reward: 78.0625, steps:5364, time-taken: 2.42min, time-elasped: 721.12min
-> berries picked: 60 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5500 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [482, 709, 865, 665, 482, 511, 680, 543, 563]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 10, 18, 19, 13, 10, 16, 9, 20]
	Time taken saving stuff: 0.03s

=== episode:404 Env-steps-taken:62784
 	picked: 56 |actions: {0: 554, 1: 582, 2: 649, 3: 442, 4: 433, 5: 364, 6: 406, 7: 548, 8: 354}
episode: 404/2000 -> reward: 74.29166666666667, steps:4332, time-taken: 2.47min, time-elasped: 723.59min
-> berries picked: 56 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5503 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [483, 704, 869, 669, 477, 509, 679, 548, 565]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 17, 17, 16, 11, 13, 7, 8, 21]
	Time taken saving stuff: 0.00s

=== episode:405 Env-steps-taken:67584
 	picked: 70 |actions: {0: 570, 1: 539, 2: 541, 3: 409, 4: 605, 5: 436, 6: 354, 7: 460, 8: 371}
episode: 405/2000 -> reward: 98.48958333333326, steps:4285, time-taken: 2.35min, time-elasped: 725.95min
-> berries picked: 70 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5528 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [485, 709, 876, 666, 482, 512, 685, 548, 565]
	| approx positives in sample 512: 101
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 8, 16, 13, 6, 17, 7, 8, 16]
	Time taken saving stuff: 0.02s

=== episode:406 Env-steps-taken:63744
 	picked: 56 |actions: {0: 407, 1: 460, 2: 461, 3: 357, 4: 506, 5: 280, 6: 376, 7: 409, 8: 315}
episode: 406/2000 -> reward: 79.29166666666666, steps:3571, time-taken: 1.79min, time-elasped: 727.74min
-> berries picked: 56 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5552 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [484, 715, 885, 669, 479, 511, 689, 553, 567]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 15, 24, 14, 10, 9, 15, 12, 15]
	Time taken saving stuff: 0.09s

=== episode:407 Env-steps-taken:64320
 	picked: 62 |actions: {0: 799, 1: 730, 2: 550, 3: 662, 4: 863, 5: 592, 6: 443, 7: 601, 8: 485}
episode: 407/2000 -> reward: 81.44791666666666, steps:5725, time-taken: 2.66min, time-elasped: 730.40min
-> berries picked: 62 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5558 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [481, 713, 888, 674, 482, 510, 691, 551, 568]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 17, 17, 12, 8, 10, 20, 11, 20]
	Time taken saving stuff: 0.01s

=== episode:408 Env-steps-taken:62208
 	picked: 58 |actions: {0: 993, 1: 515, 2: 791, 3: 455, 4: 883, 5: 426, 6: 421, 7: 582, 8: 462}
episode: 408/2000 -> reward: 70.67708333333336, steps:5528, time-taken: 2.67min, time-elasped: 733.07min
-> berries picked: 58 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5566 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [479, 712, 892, 675, 490, 506, 693, 550, 569]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 11, 20, 14, 9, 11, 8, 14, 10]
	Time taken saving stuff: 0.01s

=== episode:409 Env-steps-taken:58560
 	picked: 34 |actions: {0: 178, 1: 201, 2: 372, 3: 254, 4: 265, 5: 172, 6: 122, 7: 101, 8: 97}
episode: 409/2000 -> reward: 53.55208333333338, steps:1762, time-taken: 1.15min, time-elasped: 734.23min
-> berries picked: 34 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5582 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [480, 715, 893, 676, 498, 511, 692, 546, 571]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 19, 19, 8, 7, 6, 12, 13, 22]
	Time taken saving stuff: 0.02s

=== episode:410 Env-steps-taken:63456
 	picked: 56 |actions: {0: 456, 1: 459, 2: 462, 3: 342, 4: 405, 5: 222, 6: 258, 7: 306, 8: 186}
episode: 410/2000 -> reward: 77.79166666666666, steps:3096, time-taken: 1.74min, time-elasped: 735.97min
-> berries picked: 56 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5591 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [481, 725, 896, 676, 496, 509, 689, 547, 572]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 10, 23, 9, 10, 6, 13, 2, 17]
	Time taken saving stuff: 0.16s

=== episode:41 Env-steps-taken:77568
 	picked: 110 |actions: {0: 1033, 1: 580, 2: 594, 3: 249, 4: 1544, 5: 191, 6: 221, 7: 603, 8: 12}

==================================================
eval-episode: 410 -> reward: 145.42708333333331, steps: 5027.0, wall-time: 53.22s
-> berries picked: 110 of 800 | patches-visited: [0, 1] | juice left:-0.00
==================================================


=== episode:411 Env-steps-taken:72192
 	picked: 85 |actions: {0: 707, 1: 691, 2: 751, 3: 567, 4: 688, 5: 491, 6: 404, 7: 515, 8: 497}
episode: 411/2000 -> reward: 122.13020833333319, steps:5311, time-taken: 2.75min, time-elasped: 739.61min
-> berries picked: 85 of 800 | patches-visited: [0, 5, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5604 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [483, 735, 894, 674, 497, 508, 691, 550, 572]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 20, 18, 7, 7, 16, 14, 16, 17]
	Time taken saving stuff: 0.02s

=== episode:412 Env-steps-taken:61344
 	picked: 55 |actions: {0: 406, 1: 562, 2: 470, 3: 413, 4: 618, 5: 360, 6: 363, 7: 434, 8: 345}
episode: 412/2000 -> reward: 66.84895833333337, steps:3971, time-taken: 2.12min, time-elasped: 741.73min
-> berries picked: 55 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5610 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [486, 742, 892, 672, 494, 509, 696, 547, 572]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 14, 16, 10, 6, 6, 18, 14, 19]
	Time taken saving stuff: 0.09s

=== episode:413 Env-steps-taken:70368
 	picked: 81 |actions: {0: 843, 1: 707, 2: 580, 3: 503, 4: 732, 5: 468, 6: 424, 7: 676, 8: 435}
episode: 413/2000 -> reward: 112.35937499999986, steps:5368, time-taken: 2.68min, time-elasped: 744.41min
-> berries picked: 81 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5616 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [488, 746, 893, 669, 498, 509, 694, 544, 575]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 11, 17, 16, 7, 9, 12, 13, 18]
	Time taken saving stuff: 0.09s

=== episode:414 Env-steps-taken:71040
 	picked: 94 |actions: {0: 632, 1: 666, 2: 619, 3: 461, 4: 603, 5: 592, 6: 428, 7: 718, 8: 410}
episode: 414/2000 -> reward: 114.7291666666665, steps:5129, time-taken: 2.97min, time-elasped: 747.39min
-> berries picked: 94 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5648 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [495, 747, 898, 671, 503, 518, 693, 551, 572]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 11, 16, 14, 14, 11, 15, 15, 15]
	Time taken saving stuff: 0.20s

=== episode:415 Env-steps-taken:64608
 	picked: 66 |actions: {0: 505, 1: 561, 2: 531, 3: 305, 4: 496, 5: 345, 6: 303, 7: 420, 8: 252}
episode: 415/2000 -> reward: 82.33333333333333, steps:3718, time-taken: 2.21min, time-elasped: 749.61min
-> berries picked: 66 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5648 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [499, 744, 895, 667, 500, 522, 698, 551, 572]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 14, 19, 14, 11, 10, 11, 11, 28]
	Time taken saving stuff: 0.05s

=== episode:416 Env-steps-taken:65472
 	picked: 69 |actions: {0: 417, 1: 457, 2: 653, 3: 516, 4: 606, 5: 337, 6: 369, 7: 396, 8: 346}
episode: 416/2000 -> reward: 87.54687499999997, steps:4097, time-taken: 3.27min, time-elasped: 752.88min
-> berries picked: 69 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5661 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [500, 745, 906, 668, 499, 521, 695, 555, 572]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 16, 18, 9, 12, 11, 13, 17, 13]
	Time taken saving stuff: 0.01s

=== episode:417 Env-steps-taken:75936
 	picked: 98 |actions: {0: 588, 1: 813, 2: 557, 3: 676, 4: 735, 5: 491, 6: 490, 7: 538, 8: 381}
episode: 417/2000 -> reward: 140.88541666666657, steps:5269, time-taken: 2.85min, time-elasped: 755.73min
-> berries picked: 98 of 800 | patches-visited: [0, 3, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5688 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [499, 753, 901, 668, 509, 526, 700, 558, 574]
	| approx positives in sample 512: 100
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 12, 12, 13, 9, 8, 16, 4, 16]
	Time taken saving stuff: 0.00s

=== episode:418 Env-steps-taken:59136
 	picked: 42 |actions: {0: 427, 1: 510, 2: 1020, 3: 250, 4: 341, 5: 283, 6: 282, 7: 393, 8: 265}
episode: 418/2000 -> reward: 55.593750000000036, steps:3771, time-taken: 1.98min, time-elasped: 757.72min
-> berries picked: 42 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5675 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [504, 751, 897, 658, 511, 526, 700, 554, 574]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 15, 13, 6, 11, 13, 10, 11, 17]
	Time taken saving stuff: 0.03s

=== episode:419 Env-steps-taken:58080
 	picked: 38 |actions: {0: 262, 1: 340, 2: 312, 3: 246, 4: 235, 5: 216, 6: 206, 7: 206, 8: 128}
episode: 419/2000 -> reward: 50.8229166666667, steps:2151, time-taken: 1.45min, time-elasped: 759.18min
-> berries picked: 38 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5692 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [505, 752, 897, 663, 513, 529, 703, 556, 574]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 22, 21, 13, 9, 13, 7, 16, 17]
	Time taken saving stuff: 0.09s

=== episode:420 Env-steps-taken:63840
 	picked: 58 |actions: {0: 453, 1: 432, 2: 507, 3: 426, 4: 569, 5: 310, 6: 286, 7: 352, 8: 274}
episode: 420/2000 -> reward: 79.67708333333333, steps:3609, time-taken: 2.23min, time-elasped: 761.41min
-> berries picked: 58 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5712 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [508, 755, 900, 660, 514, 535, 705, 559, 576]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 12, 11, 9, 9, 12, 12, 15, 13]
	Time taken saving stuff: 0.14s

=== episode:42 Env-steps-taken:84864
 	picked: 148 |actions: {0: 1280, 1: 1101, 2: 298, 3: 1041, 4: 224, 5: 1390, 6: 494, 7: 363, 8: 34}

==================================================
eval-episode: 420 -> reward: 183.13541666666694, steps: 6225.0, wall-time: 62.73s
-> berries picked: 148 of 800 | patches-visited: [1, 4] | juice left:-0.00
==================================================


=== episode:421 Env-steps-taken:69984
 	picked: 80 |actions: {0: 519, 1: 527, 2: 734, 3: 441, 4: 750, 5: 469, 6: 378, 7: 468, 8: 286}
episode: 421/2000 -> reward: 110.91666666666656, steps:4572, time-taken: 2.59min, time-elasped: 765.05min
-> berries picked: 80 of 800 | patches-visited: [0, 1, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5719 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [510, 757, 908, 660, 515, 535, 698, 559, 577]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 17, 15, 7, 12, 14, 16, 12, 16]
	Time taken saving stuff: 0.03s

=== episode:422 Env-steps-taken:64992
 	picked: 63 |actions: {0: 620, 1: 562, 2: 613, 3: 456, 4: 490, 5: 313, 6: 304, 7: 458, 8: 412}
episode: 422/2000 -> reward: 84.89062499999997, steps:4228, time-taken: 1.98min, time-elasped: 767.03min
-> berries picked: 63 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5713 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [513, 764, 911, 655, 507, 533, 693, 561, 576]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 12, 14, 11, 13, 9, 15, 9, 14]
	Time taken saving stuff: 0.01s

=== episode:423 Env-steps-taken:68928
 	picked: 77 |actions: {0: 643, 1: 642, 2: 713, 3: 439, 4: 500, 5: 484, 6: 370, 7: 615, 8: 463}
episode: 423/2000 -> reward: 104.70312499999993, steps:4869, time-taken: 2.42min, time-elasped: 769.46min
-> berries picked: 77 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5724 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [519, 764, 910, 657, 509, 537, 687, 563, 578]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 11, 19, 11, 8, 6, 9, 16, 12]
	Time taken saving stuff: 0.03s

=== episode:424 Env-steps-taken:61344
 	picked: 54 |actions: {0: 615, 1: 488, 2: 467, 3: 385, 4: 596, 5: 505, 6: 383, 7: 541, 8: 394}
episode: 424/2000 -> reward: 66.40625000000004, steps:4374, time-taken: 2.09min, time-elasped: 771.55min
-> berries picked: 54 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5720 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [524, 764, 904, 651, 511, 538, 686, 565, 577]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 17, 11, 10, 6, 6, 20, 9, 17]
	Time taken saving stuff: 0.00s

=== episode:425 Env-steps-taken:57408
 	picked: 38 |actions: {0: 259, 1: 284, 2: 343, 3: 295, 4: 296, 5: 260, 6: 199, 7: 254, 8: 178}
episode: 425/2000 -> reward: 47.3229166666667, steps:2368, time-taken: 1.36min, time-elasped: 772.91min
-> berries picked: 38 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5727 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [520, 765, 910, 651, 511, 537, 687, 568, 578]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 10, 13, 13, 8, 13, 10, 10, 16]
	Time taken saving stuff: 0.01s

=== episode:426 Env-steps-taken:63552
 	picked: 54 |actions: {0: 469, 1: 516, 2: 599, 3: 474, 4: 641, 5: 370, 6: 342, 7: 397, 8: 435}
episode: 426/2000 -> reward: 78.40624999999999, steps:4243, time-taken: 2.19min, time-elasped: 775.10min
-> berries picked: 54 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5713 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [519, 764, 907, 651, 511, 534, 687, 560, 580]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 19, 19, 11, 9, 10, 15, 13, 16]
	Time taken saving stuff: 0.01s

=== episode:427 Env-steps-taken:51840
 	picked: 13 |actions: {0: 98, 1: 80, 2: 75, 3: 48, 4: 104, 5: 68, 6: 39, 7: 113, 8: 81}
episode: 427/2000 -> reward: 19.25520833333333, steps:706, time-taken: 0.72min, time-elasped: 775.83min
-> berries picked: 13 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5715 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [520, 767, 906, 649, 511, 536, 685, 562, 579]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 14, 18, 10, 18, 8, 17, 9, 18]
	Time taken saving stuff: 0.11s

=== episode:428 Env-steps-taken:64608
 	picked: 60 |actions: {0: 509, 1: 537, 2: 605, 3: 374, 4: 550, 5: 390, 6: 282, 7: 376, 8: 506}
episode: 428/2000 -> reward: 83.56249999999997, steps:4129, time-taken: 2.19min, time-elasped: 778.02min
-> berries picked: 60 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5730 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [523, 771, 911, 647, 514, 532, 688, 567, 577]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 17, 15, 7, 9, 15, 11, 11, 17]
	Time taken saving stuff: 0.09s

=== episode:429 Env-steps-taken:64608
 	picked: 63 |actions: {0: 492, 1: 483, 2: 542, 3: 493, 4: 765, 5: 395, 6: 391, 7: 503, 8: 647}
episode: 429/2000 -> reward: 83.39062499999996, steps:4711, time-taken: 2.55min, time-elasped: 780.58min
-> berries picked: 63 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5730 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [521, 769, 909, 654, 517, 530, 687, 566, 577]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 16, 12, 16, 14, 14, 15, 14, 20]
	Time taken saving stuff: 0.10s

=== episode:430 Env-steps-taken:54336
 	picked: 20 |actions: {0: 144, 1: 184, 2: 201, 3: 127, 4: 141, 5: 116, 6: 90, 7: 154, 8: 95}
episode: 430/2000 -> reward: 31.85416666666666, steps:1252, time-taken: 1.11min, time-elasped: 781.70min
-> berries picked: 20 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5730 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [519, 765, 909, 657, 516, 533, 687, 567, 577]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 20, 13, 9, 9, 5, 15, 12, 14]
	Time taken saving stuff: 0.06s

=== episode:43 Env-steps-taken:83328
 	picked: 127 |actions: {0: 852, 1: 361, 2: 732, 3: 423, 4: 713, 5: 309, 6: 226, 7: 300, 8: 652}

==================================================
eval-episode: 430 -> reward: 177.7239583333335, steps: 4568.0, wall-time: 57.46s
-> berries picked: 127 of 800 | patches-visited: [1, 4, 7] | juice left:-0.00
==================================================


=== episode:431 Env-steps-taken:58944
 	picked: 41 |actions: {0: 347, 1: 306, 2: 452, 3: 217, 4: 343, 5: 307, 6: 237, 7: 240, 8: 163}
episode: 431/2000 -> reward: 55.1510416666667, steps:2612, time-taken: 1.59min, time-elasped: 784.25min
-> berries picked: 41 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5744 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [522, 766, 909, 653, 519, 538, 691, 567, 579]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 11, 20, 17, 11, 14, 18, 11, 13]
	Time taken saving stuff: 0.03s

=== episode:432 Env-steps-taken:79680
 	picked: 108 |actions: {0: 569, 1: 623, 2: 651, 3: 603, 4: 914, 5: 522, 6: 626, 7: 660, 8: 437}
episode: 432/2000 -> reward: 159.42708333333337, steps:5605, time-taken: 3.01min, time-elasped: 787.27min
-> berries picked: 108 of 800 | patches-visited: [0, 2, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5780 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [524, 770, 909, 662, 527, 543, 699, 567, 579]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 11, 18, 14, 9, 15, 15, 10, 14]
	Time taken saving stuff: 0.09s

=== episode:433 Env-steps-taken:57696
 	picked: 33 |actions: {0: 191, 1: 126, 2: 192, 3: 178, 4: 242, 5: 150, 6: 135, 7: 141, 8: 111}
episode: 433/2000 -> reward: 49.10937500000002, steps:1466, time-taken: 1.19min, time-elasped: 788.46min
-> berries picked: 33 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5793 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [525, 773, 907, 664, 529, 546, 701, 568, 580]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 18, 12, 13, 9, 5, 17, 13, 16]
	Time taken saving stuff: 0.00s

=== episode:434 Env-steps-taken:60480
 	picked: 48 |actions: {0: 544, 1: 406, 2: 327, 3: 343, 4: 356, 5: 287, 6: 219, 7: 594, 8: 410}
episode: 434/2000 -> reward: 62.750000000000064, steps:3486, time-taken: 2.03min, time-elasped: 790.49min
-> berries picked: 48 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5801 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [529, 772, 912, 663, 527, 545, 700, 572, 581]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 15, 15, 12, 12, 11, 10, 9, 17]
	Time taken saving stuff: 0.01s

=== episode:435 Env-steps-taken:71520
 	picked: 88 |actions: {0: 704, 1: 733, 2: 611, 3: 608, 4: 1032, 5: 562, 6: 554, 7: 538, 8: 652}
episode: 435/2000 -> reward: 117.95833333333317, steps:5994, time-taken: 2.86min, time-elasped: 793.35min
-> berries picked: 88 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5809 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [528, 768, 908, 666, 528, 551, 701, 573, 586]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 17, 6, 13, 9, 11, 17, 7, 18]
	Time taken saving stuff: 0.01s

=== episode:436 Env-steps-taken:72384
 	picked: 87 |actions: {0: 589, 1: 521, 2: 711, 3: 522, 4: 550, 5: 472, 6: 459, 7: 447, 8: 393}
episode: 436/2000 -> reward: 121.13020833333319, steps:4664, time-taken: 2.61min, time-elasped: 795.97min
-> berries picked: 87 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5837 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [526, 773, 905, 668, 538, 556, 704, 579, 588]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 21, 13, 21, 14, 14, 13, 14, 15]
	Time taken saving stuff: 0.01s

=== episode:437 Env-steps-taken:59040
 	picked: 44 |actions: {0: 359, 1: 324, 2: 487, 3: 500, 4: 308, 5: 205, 6: 197, 7: 194, 8: 247}
episode: 437/2000 -> reward: 54.97916666666671, steps:2821, time-taken: 1.50min, time-elasped: 797.47min
-> berries picked: 44 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5850 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [528, 776, 913, 667, 541, 556, 705, 577, 587]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 15, 20, 17, 8, 10, 18, 13, 15]
	Time taken saving stuff: 0.01s

=== episode:438 Env-steps-taken:68544
 	picked: 84 |actions: {0: 572, 1: 534, 2: 783, 3: 587, 4: 673, 5: 462, 6: 416, 7: 453, 8: 358}
episode: 438/2000 -> reward: 102.24479166666657, steps:4838, time-taken: 2.32min, time-elasped: 799.79min
-> berries picked: 84 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5865 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [523, 781, 910, 676, 542, 557, 703, 584, 589]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 18, 17, 8, 9, 10, 17, 18, 22]
	Time taken saving stuff: 0.01s

=== episode:439 Env-steps-taken:55680
 	picked: 27 |actions: {0: 233, 1: 176, 2: 267, 3: 173, 4: 208, 5: 145, 6: 121, 7: 146, 8: 99}
episode: 439/2000 -> reward: 38.45312500000001, steps:1568, time-taken: 1.13min, time-elasped: 800.92min
-> berries picked: 27 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5868 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [523, 781, 912, 677, 542, 555, 704, 583, 591]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 23, 12, 16, 9, 11, 10, 11, 10]
	Time taken saving stuff: 0.10s

=== episode:440 Env-steps-taken:53568
 	picked: 20 |actions: {0: 139, 1: 147, 2: 241, 3: 158, 4: 206, 5: 149, 6: 103, 7: 74, 8: 99}
episode: 440/2000 -> reward: 27.85416666666666, steps:1316, time-taken: 0.87min, time-elasped: 801.79min
-> berries picked: 20 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5869 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [522, 780, 911, 677, 546, 555, 706, 582, 590]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 7, 10, 17, 12, 13, 13, 15, 13]
	Time taken saving stuff: 0.05s

=== episode:44 Env-steps-taken:75360
 	picked: 104 |actions: {0: 322, 1: 419, 2: 663, 3: 487, 4: 224, 5: 469, 6: 397, 7: 105, 8: 91}

==================================================
eval-episode: 440 -> reward: 137.54166666666657, steps: 3177.0, wall-time: 47.45s
-> berries picked: 104 of 800 | patches-visited: [0, 1, 8] | juice left:-0.00
==================================================


=== episode:441 Env-steps-taken:64416
 	picked: 58 |actions: {0: 368, 1: 564, 2: 570, 3: 449, 4: 508, 5: 302, 6: 319, 7: 348, 8: 359}
episode: 441/2000 -> reward: 82.17708333333333, steps:3787, time-taken: 1.92min, time-elasped: 804.51min
-> berries picked: 58 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5857 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [522, 779, 918, 678, 540, 550, 703, 580, 587]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 13, 11, 17, 11, 8, 16, 8, 20]
	Time taken saving stuff: 0.10s

=== episode:442 Env-steps-taken:69600
 	picked: 82 |actions: {0: 626, 1: 580, 2: 636, 3: 502, 4: 832, 5: 449, 6: 528, 7: 440, 8: 335}
episode: 442/2000 -> reward: 108.30208333333323, steps:4928, time-taken: 2.43min, time-elasped: 806.94min
-> berries picked: 82 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5851 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [519, 778, 914, 677, 548, 547, 698, 581, 589]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 18, 10, 17, 8, 10, 6, 11, 21]
	Time taken saving stuff: 0.03s

=== episode:443 Env-steps-taken:63264
 	picked: 60 |actions: {0: 429, 1: 303, 2: 463, 3: 369, 4: 635, 5: 427, 6: 501, 7: 359, 8: 508}
episode: 443/2000 -> reward: 76.5625, steps:3994, time-taken: 2.01min, time-elasped: 808.96min
-> berries picked: 60 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5864 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [519, 782, 913, 678, 549, 551, 698, 581, 593]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 14, 21, 10, 11, 3, 9, 10, 13]
	Time taken saving stuff: 0.11s

=== episode:444 Env-steps-taken:65184
 	picked: 65 |actions: {0: 380, 1: 468, 2: 582, 3: 370, 4: 424, 5: 273, 6: 404, 7: 249, 8: 375}
episode: 444/2000 -> reward: 84.8333333333333, steps:3525, time-taken: 1.82min, time-elasped: 810.78min
-> berries picked: 65 of 800 | patches-visited: [0, 3, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5869 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [518, 781, 915, 674, 550, 552, 699, 582, 598]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 8, 11, 17, 6, 9, 15, 11, 18]
	Time taken saving stuff: 0.08s

=== episode:445 Env-steps-taken:67968
 	picked: 73 |actions: {0: 527, 1: 711, 2: 988, 3: 504, 4: 666, 5: 574, 6: 460, 7: 461, 8: 559}
episode: 445/2000 -> reward: 100.31770833333326, steps:5450, time-taken: 2.70min, time-elasped: 813.49min
-> berries picked: 73 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5862 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [524, 783, 916, 669, 545, 547, 699, 581, 598]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 15, 16, 8, 16, 11, 10, 11, 18]
	Time taken saving stuff: 0.11s

=== episode:446 Env-steps-taken:64800
 	picked: 65 |actions: {0: 581, 1: 433, 2: 561, 3: 424, 4: 558, 5: 411, 6: 360, 7: 505, 8: 428}
episode: 446/2000 -> reward: 83.77604166666663, steps:4261, time-taken: 2.11min, time-elasped: 815.60min
-> berries picked: 65 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5878 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [528, 784, 925, 660, 553, 549, 696, 584, 599]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 12, 17, 12, 14, 6, 12, 15, 19]
	Time taken saving stuff: 0.04s

=== episode:447 Env-steps-taken:73536
 	picked: 93 |actions: {0: 703, 1: 555, 2: 731, 3: 573, 4: 733, 5: 661, 6: 583, 7: 637, 8: 674}
episode: 447/2000 -> reward: 128.6718749999998, steps:5850, time-taken: 2.91min, time-elasped: 818.51min
-> berries picked: 93 of 800 | patches-visited: [0, 1, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5895 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [534, 784, 936, 654, 553, 545, 697, 589, 603]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 12, 22, 10, 7, 15, 15, 9, 13]
	Time taken saving stuff: 0.03s

=== episode:448 Env-steps-taken:49728
 	picked: 6 |actions: {0: 35, 1: 62, 2: 72, 3: 25, 4: 15, 5: 22, 6: 27, 7: 48, 8: 53}
episode: 448/2000 -> reward: 8.656250000000002, steps:359, time-taken: 0.58min, time-elasped: 819.09min
-> berries picked: 6 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5897 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [534, 787, 935, 653, 553, 544, 698, 590, 603]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 15, 20, 14, 9, 5, 12, 9, 17]
	Time taken saving stuff: 0.01s

=== episode:449 Env-steps-taken:66912
 	picked: 72 |actions: {0: 528, 1: 491, 2: 908, 3: 585, 4: 771, 5: 491, 6: 492, 7: 451, 8: 559}
episode: 449/2000 -> reward: 94.87499999999993, steps:5276, time-taken: 2.77min, time-elasped: 821.87min
-> berries picked: 72 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5894 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [532, 792, 936, 657, 550, 542, 697, 585, 603]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 16, 13, 10, 13, 10, 18, 15, 7]
	Time taken saving stuff: 0.00s

=== episode:450 Env-steps-taken:64896
 	picked: 70 |actions: {0: 462, 1: 444, 2: 623, 3: 540, 4: 518, 5: 440, 6: 439, 7: 601, 8: 419}
episode: 450/2000 -> reward: 84.9895833333333, steps:4486, time-taken: 2.22min, time-elasped: 824.10min
-> berries picked: 70 of 800 | patches-visited: [0, 6, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5917 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [534, 792, 939, 659, 557, 540, 700, 591, 605]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 21, 18, 12, 9, 5, 14, 8, 14]
	Time taken saving stuff: 0.07s

=== episode:45 Env-steps-taken:74976
 	picked: 97 |actions: {0: 1294, 1: 382, 2: 773, 3: 145, 4: 1194, 5: 241, 6: 322, 7: 122, 8: 899}

==================================================
eval-episode: 450 -> reward: 135.44270833333326, steps: 5372.0, wall-time: 57.87s
-> berries picked: 97 of 800 | patches-visited: [1, 3] | juice left:-0.00
==================================================


=== episode:451 Env-steps-taken:71808
 	picked: 85 |actions: {0: 558, 1: 592, 2: 814, 3: 630, 4: 641, 5: 554, 6: 446, 7: 816, 8: 468}
episode: 451/2000 -> reward: 120.13020833333317, steps:5519, time-taken: 2.97min, time-elasped: 828.03min
-> berries picked: 85 of 800 | patches-visited: [0, 1, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5925 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [539, 792, 943, 663, 556, 538, 701, 587, 606]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 21, 13, 11, 10, 11, 6, 16, 14]
	Time taken saving stuff: 0.02s

=== episode:452 Env-steps-taken:66432
 	picked: 66 |actions: {0: 407, 1: 474, 2: 582, 3: 407, 4: 411, 5: 333, 6: 268, 7: 321, 8: 542}
episode: 452/2000 -> reward: 93.21874999999996, steps:3745, time-taken: 2.03min, time-elasped: 830.06min
-> berries picked: 66 of 800 | patches-visited: [0, 1, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5939 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [539, 803, 949, 663, 556, 532, 705, 581, 611]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 17, 12, 10, 10, 7, 11, 9, 21]
	Time taken saving stuff: 0.00s

=== episode:453 Env-steps-taken:65760
 	picked: 68 |actions: {0: 591, 1: 518, 2: 599, 3: 422, 4: 533, 5: 397, 6: 396, 7: 463, 8: 336}
episode: 453/2000 -> reward: 89.10416666666661, steps:4255, time-taken: 2.18min, time-elasped: 832.25min
-> berries picked: 68 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5965 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [541, 809, 948, 663, 566, 533, 708, 584, 613]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 19, 14, 14, 15, 13, 18, 6, 21]
	Time taken saving stuff: 0.01s

=== episode:454 Env-steps-taken:70656
 	picked: 89 |actions: {0: 588, 1: 492, 2: 781, 3: 552, 4: 832, 5: 462, 6: 440, 7: 646, 8: 363}
episode: 454/2000 -> reward: 113.40104166666653, steps:5156, time-taken: 2.44min, time-elasped: 834.69min
-> berries picked: 89 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5984 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [547, 812, 954, 669, 566, 534, 710, 581, 611]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 15, 22, 11, 10, 9, 14, 13, 14]
	Time taken saving stuff: 0.01s

=== episode:455 Env-steps-taken:61152
 	picked: 47 |actions: {0: 317, 1: 332, 2: 541, 3: 302, 4: 562, 5: 262, 6: 294, 7: 432, 8: 372}
episode: 455/2000 -> reward: 66.8072916666667, steps:3414, time-taken: 1.86min, time-elasped: 836.55min
-> berries picked: 47 of 800 | patches-visited: [0, 2, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5988 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [541, 818, 955, 667, 566, 533, 710, 586, 612]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 22, 11, 12, 18, 11, 14, 11, 22]
	Time taken saving stuff: 0.00s

=== episode:456 Env-steps-taken:58272
 	picked: 41 |actions: {0: 299, 1: 301, 2: 652, 3: 253, 4: 494, 5: 411, 6: 351, 7: 431, 8: 281}
episode: 456/2000 -> reward: 51.6510416666667, steps:3473, time-taken: 1.81min, time-elasped: 838.36min
-> berries picked: 41 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5976 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [534, 817, 960, 662, 568, 535, 705, 583, 612]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 22, 19, 12, 10, 8, 13, 13, 19]
	Time taken saving stuff: 0.01s

=== episode:457 Env-steps-taken:62112
 	picked: 52 |actions: {0: 463, 1: 488, 2: 597, 3: 463, 4: 645, 5: 374, 6: 413, 7: 465, 8: 451}
episode: 457/2000 -> reward: 71.02083333333336, steps:4359, time-taken: 2.15min, time-elasped: 840.52min
-> berries picked: 52 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5973 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [532, 813, 960, 670, 565, 536, 701, 583, 613]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 18, 21, 12, 11, 9, 5, 8, 12]
	Time taken saving stuff: 0.10s

=== episode:458 Env-steps-taken:66720
 	picked: 67 |actions: {0: 428, 1: 506, 2: 632, 3: 441, 4: 580, 5: 363, 6: 320, 7: 460, 8: 358}
episode: 458/2000 -> reward: 94.16145833333329, steps:4088, time-taken: 2.10min, time-elasped: 842.62min
-> berries picked: 67 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5983 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [540, 822, 961, 672, 566, 530, 697, 582, 613]
	| approx positives in sample 512: 101
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 7, 24, 11, 10, 10, 11, 7, 11]
	Time taken saving stuff: 0.10s

=== episode:459 Env-steps-taken:74016
 	picked: 97 |actions: {0: 629, 1: 658, 2: 836, 3: 620, 4: 965, 5: 591, 6: 411, 7: 755, 8: 555}
episode: 459/2000 -> reward: 130.44270833333317, steps:6020, time-taken: 2.89min, time-elasped: 845.52min
-> berries picked: 97 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5990 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [539, 825, 959, 673, 569, 532, 692, 589, 612]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 21, 13, 13, 14, 9, 9, 16, 25]
	Time taken saving stuff: 0.09s

=== episode:460 Env-steps-taken:54432
 	picked: 22 |actions: {0: 150, 1: 162, 2: 94, 3: 92, 4: 78, 5: 94, 6: 72, 7: 114, 8: 109}
episode: 460/2000 -> reward: 32.239583333333336, steps:965, time-taken: 0.86min, time-elasped: 846.38min
-> berries picked: 22 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5994 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [539, 829, 957, 672, 571, 534, 690, 588, 614]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 16, 25, 16, 14, 5, 11, 4, 13]
	Time taken saving stuff: 0.08s

=== episode:46 Env-steps-taken:70272
 	picked: 94 |actions: {0: 484, 1: 808, 2: 299, 3: 512, 4: 524, 5: 418, 6: 586, 7: 72, 8: 624}

==================================================
eval-episode: 460 -> reward: 111.11458333333316, steps: 4327.0, wall-time: 50.13s
-> berries picked: 94 of 800 | patches-visited: [1, 2] | juice left:-0.00
==================================================


=== episode:461 Env-steps-taken:64320
 	picked: 69 |actions: {0: 683, 1: 634, 2: 482, 3: 404, 4: 692, 5: 487, 6: 586, 7: 533, 8: 437}
episode: 461/2000 -> reward: 81.54687499999997, steps:4938, time-taken: 2.65min, time-elasped: 849.88min
-> berries picked: 69 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5993 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [542, 830, 958, 671, 575, 533, 688, 581, 615]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 12, 16, 8, 21, 6, 13, 14, 18]
	Time taken saving stuff: 0.00s

=== episode:462 Env-steps-taken:66720
 	picked: 72 |actions: {0: 490, 1: 447, 2: 525, 3: 381, 4: 719, 5: 529, 6: 509, 7: 619, 8: 520}
episode: 462/2000 -> reward: 92.54687499999996, steps:4739, time-taken: 2.43min, time-elasped: 852.31min
-> berries picked: 72 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6006 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [541, 831, 960, 671, 577, 538, 693, 578, 617]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 9, 14, 10, 19, 13, 7, 15, 16]
	Time taken saving stuff: 0.01s

=== episode:463 Env-steps-taken:67200
 	picked: 68 |actions: {0: 356, 1: 514, 2: 668, 3: 399, 4: 453, 5: 429, 6: 494, 7: 531, 8: 399}
episode: 463/2000 -> reward: 94.66145833333327, steps:4243, time-taken: 2.16min, time-elasped: 854.47min
-> berries picked: 68 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6016 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [540, 832, 965, 670, 575, 542, 693, 580, 619]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 15, 13, 12, 10, 7, 13, 11, 21]
	Time taken saving stuff: 0.00s

=== episode:464 Env-steps-taken:70176
 	picked: 84 |actions: {0: 474, 1: 719, 2: 771, 3: 655, 4: 799, 5: 632, 6: 586, 7: 743, 8: 499}
episode: 464/2000 -> reward: 109.24479166666656, steps:5878, time-taken: 2.80min, time-elasped: 857.28min
-> berries picked: 84 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6023 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [535, 829, 967, 673, 574, 545, 701, 580, 619]
	| approx positives in sample 512: 92
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 10, 21, 6, 4, 15, 16, 4, 7]
	Time taken saving stuff: 0.00s

=== episode:465 Env-steps-taken:62688
 	picked: 54 |actions: {0: 374, 1: 386, 2: 492, 3: 425, 4: 497, 5: 373, 6: 436, 7: 403, 8: 371}
episode: 465/2000 -> reward: 73.40625000000001, steps:3757, time-taken: 1.95min, time-elasped: 859.23min
-> berries picked: 54 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6021 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [537, 829, 972, 671, 576, 543, 698, 577, 618]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 13, 15, 10, 11, 6, 14, 7, 17]
	Time taken saving stuff: 0.01s

=== episode:466 Env-steps-taken:63072
 	picked: 59 |actions: {0: 454, 1: 405, 2: 849, 3: 428, 4: 563, 5: 541, 6: 264, 7: 521, 8: 534}
episode: 466/2000 -> reward: 75.11979166666667, steps:4559, time-taken: 2.20min, time-elasped: 861.43min
-> berries picked: 59 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6015 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [533, 829, 977, 674, 573, 541, 694, 576, 618]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 17, 10, 9, 18, 11, 11, 20, 24]
	Time taken saving stuff: 0.01s

=== episode:467 Env-steps-taken:71232
 	picked: 87 |actions: {0: 509, 1: 848, 2: 897, 3: 533, 4: 555, 5: 507, 6: 467, 7: 667, 8: 409}
episode: 467/2000 -> reward: 116.51562499999983, steps:5392, time-taken: 2.62min, time-elasped: 864.05min
-> berries picked: 87 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6026 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [533, 833, 988, 674, 567, 544, 689, 579, 619]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 20, 10, 6, 7, 13, 11, 14, 23]
	Time taken saving stuff: 0.01s

=== episode:468 Env-steps-taken:62208
 	picked: 52 |actions: {0: 279, 1: 331, 2: 455, 3: 329, 4: 305, 5: 261, 6: 270, 7: 185, 8: 153}
episode: 468/2000 -> reward: 71.52083333333336, steps:2568, time-taken: 1.40min, time-elasped: 865.46min
-> berries picked: 52 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6046 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [533, 840, 995, 675, 573, 545, 690, 574, 621]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 15, 10, 14, 12, 12, 14, 8, 16]
	Time taken saving stuff: 0.16s

=== episode:469 Env-steps-taken:72576
 	picked: 94 |actions: {0: 693, 1: 636, 2: 678, 3: 554, 4: 750, 5: 602, 6: 455, 7: 627, 8: 492}
episode: 469/2000 -> reward: 123.11458333333316, steps:5487, time-taken: 2.70min, time-elasped: 868.16min
-> berries picked: 94 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6067 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [541, 843, 999, 673, 565, 548, 695, 579, 624]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 14, 18, 10, 9, 10, 12, 14, 21]
	Time taken saving stuff: 0.07s

=== episode:470 Env-steps-taken:63360
 	picked: 59 |actions: {0: 292, 1: 397, 2: 377, 3: 475, 4: 558, 5: 384, 6: 311, 7: 501, 8: 296}
episode: 470/2000 -> reward: 75.234375, steps:3591, time-taken: 1.83min, time-elasped: 870.00min
-> berries picked: 59 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6081 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [546, 847, 1004, 672, 570, 548, 692, 576, 626]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 16, 12, 19, 11, 9, 15, 9, 22]
	Time taken saving stuff: 0.05s

=== episode:47 Env-steps-taken:67872
 	picked: 77 |actions: {0: 317, 1: 217, 2: 477, 3: 780, 4: 554, 5: 164, 6: 333, 7: 444, 8: 449}

==================================================
eval-episode: 470 -> reward: 99.58854166666653, steps: 3735.0, wall-time: 40.57s
-> berries picked: 77 of 800 | patches-visited: [1, 8] | juice left:-0.00
==================================================


=== episode:471 Env-steps-taken:67872
 	picked: 71 |actions: {0: 511, 1: 724, 2: 748, 3: 449, 4: 588, 5: 581, 6: 455, 7: 586, 8: 633}
episode: 471/2000 -> reward: 100.43229166666659, steps:5275, time-taken: 2.83min, time-elasped: 873.51min
-> berries picked: 71 of 800 | patches-visited: [0, 2, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6082 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [544, 846, 1007, 674, 567, 546, 694, 579, 625]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 14, 17, 13, 9, 10, 12, 9, 19]
	Time taken saving stuff: 0.01s

=== episode:472 Env-steps-taken:64416
 	picked: 70 |actions: {0: 471, 1: 477, 2: 589, 3: 474, 4: 531, 5: 379, 6: 299, 7: 472, 8: 245}
episode: 472/2000 -> reward: 81.98958333333331, steps:3937, time-taken: 2.06min, time-elasped: 875.58min
-> berries picked: 70 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6112 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [549, 852, 1014, 676, 570, 550, 696, 578, 627]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 19, 11, 10, 10, 7, 13, 11, 22]
	Time taken saving stuff: 0.00s

=== episode:473 Env-steps-taken:64512
 	picked: 62 |actions: {0: 359, 1: 573, 2: 695, 3: 411, 4: 553, 5: 538, 6: 422, 7: 537, 8: 387}
episode: 473/2000 -> reward: 82.44791666666664, steps:4475, time-taken: 2.18min, time-elasped: 877.76min
-> berries picked: 62 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6115 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [547, 855, 1018, 672, 572, 548, 694, 580, 629]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 14, 18, 9, 10, 10, 16, 7, 18]
	Time taken saving stuff: 0.01s

=== episode:474 Env-steps-taken:61248
 	picked: 43 |actions: {0: 304, 1: 344, 2: 389, 3: 280, 4: 335, 5: 278, 6: 210, 7: 295, 8: 172}
episode: 474/2000 -> reward: 67.03645833333336, steps:2607, time-taken: 1.60min, time-elasped: 879.37min
-> berries picked: 43 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6121 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [543, 859, 1024, 670, 574, 549, 693, 582, 627]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 25, 21, 12, 7, 9, 11, 14, 17]
	Time taken saving stuff: 0.02s

=== episode:475 Env-steps-taken:72096
 	picked: 90 |actions: {0: 424, 1: 493, 2: 775, 3: 498, 4: 841, 5: 629, 6: 631, 7: 630, 8: 415}
episode: 475/2000 -> reward: 120.84374999999986, steps:5336, time-taken: 2.74min, time-elasped: 882.11min
-> berries picked: 90 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6135 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [542, 866, 1027, 673, 574, 546, 694, 585, 628]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 14, 14, 16, 7, 9, 13, 9, 21]
	Time taken saving stuff: 0.00s

=== episode:476 Env-steps-taken:62208
 	picked: 55 |actions: {0: 350, 1: 546, 2: 543, 3: 381, 4: 454, 5: 425, 6: 287, 7: 436, 8: 191}
episode: 476/2000 -> reward: 70.84895833333337, steps:3613, time-taken: 1.93min, time-elasped: 884.04min
-> berries picked: 55 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6100 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [542, 872, 1024, 671, 575, 541, 678, 572, 625]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 19, 17, 5, 13, 6, 15, 7, 19]
	Time taken saving stuff: 0.01s

=== episode:477 Env-steps-taken:70368
 	picked: 78 |actions: {0: 610, 1: 663, 2: 541, 3: 391, 4: 503, 5: 416, 6: 411, 7: 709, 8: 347}
episode: 477/2000 -> reward: 111.08854166666659, steps:4591, time-taken: 2.30min, time-elasped: 886.34min
-> berries picked: 78 of 800 | patches-visited: [0, 1, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6094 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [548, 872, 1025, 673, 570, 546, 674, 559, 627]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 20, 21, 8, 10, 6, 9, 10, 13]
	Time taken saving stuff: 0.11s

=== episode:478 Env-steps-taken:62304
 	picked: 46 |actions: {0: 230, 1: 263, 2: 387, 3: 274, 4: 327, 5: 223, 6: 195, 7: 335, 8: 183}
episode: 478/2000 -> reward: 71.86458333333334, steps:2417, time-taken: 1.53min, time-elasped: 887.87min
-> berries picked: 46 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6082 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [545, 869, 1025, 670, 568, 544, 677, 557, 627]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 16, 17, 11, 10, 7, 8, 13, 20]
	Time taken saving stuff: 0.01s

=== episode:479 Env-steps-taken:69984
 	picked: 82 |actions: {0: 447, 1: 474, 2: 501, 3: 379, 4: 528, 5: 659, 6: 530, 7: 753, 8: 302}
episode: 479/2000 -> reward: 110.8020833333332, steps:4573, time-taken: 2.49min, time-elasped: 890.37min
-> berries picked: 82 of 800 | patches-visited: [0, 3, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6107 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [545, 870, 1024, 674, 574, 548, 675, 567, 630]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 11, 12, 13, 7, 14, 12, 15, 19]
	Time taken saving stuff: 0.10s

=== episode:480 Env-steps-taken:68160
 	picked: 77 |actions: {0: 413, 1: 491, 2: 560, 3: 560, 4: 456, 5: 453, 6: 359, 7: 475, 8: 398}
episode: 480/2000 -> reward: 101.08854166666657, steps:4165, time-taken: 2.11min, time-elasped: 892.49min
-> berries picked: 77 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6103 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [545, 877, 1021, 675, 576, 545, 675, 558, 631]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 14, 16, 14, 11, 11, 14, 19, 18]
	Time taken saving stuff: 0.06s

=== episode:48 Env-steps-taken:73344
 	picked: 95 |actions: {0: 289, 1: 928, 2: 230, 3: 486, 4: 789, 5: 350, 6: 1085, 7: 239, 8: 125}

==================================================
eval-episode: 480 -> reward: 127.05729166666647, steps: 4521.0, wall-time: 54.40s
-> berries picked: 95 of 800 | patches-visited: [1, 4] | juice left:-0.00
==================================================


=== episode:481 Env-steps-taken:55968
 	picked: 27 |actions: {0: 118, 1: 202, 2: 253, 3: 146, 4: 204, 5: 171, 6: 188, 7: 170, 8: 193}
episode: 481/2000 -> reward: 39.95312500000002, steps:1645, time-taken: 1.17min, time-elasped: 894.57min
-> berries picked: 27 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6098 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [542, 879, 1023, 674, 576, 545, 676, 553, 630]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 24, 18, 13, 12, 10, 11, 10, 24]
	Time taken saving stuff: 0.10s

=== episode:482 Env-steps-taken:58080
 	picked: 39 |actions: {0: 254, 1: 337, 2: 537, 3: 282, 4: 354, 5: 249, 6: 209, 7: 333, 8: 331}
episode: 482/2000 -> reward: 50.26562500000002, steps:2886, time-taken: 1.71min, time-elasped: 896.28min
-> berries picked: 39 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6089 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [542, 874, 1023, 674, 572, 543, 676, 554, 631]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 22, 19, 8, 7, 7, 8, 9, 18]
	Time taken saving stuff: 0.02s

=== episode:483 Env-steps-taken:68448
 	picked: 73 |actions: {0: 301, 1: 377, 2: 616, 3: 509, 4: 542, 5: 468, 6: 389, 7: 513, 8: 413}
episode: 483/2000 -> reward: 101.93229166666659, steps:4128, time-taken: 2.35min, time-elasped: 898.64min
-> berries picked: 73 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6094 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [541, 876, 1027, 675, 570, 545, 675, 552, 633]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 17, 15, 16, 8, 9, 12, 9, 12]
	Time taken saving stuff: 0.10s

=== episode:484 Env-steps-taken:67104
 	picked: 62 |actions: {0: 405, 1: 455, 2: 524, 3: 434, 4: 453, 5: 510, 6: 365, 7: 487, 8: 349}
episode: 484/2000 -> reward: 95.94791666666661, steps:3982, time-taken: 2.15min, time-elasped: 900.79min
-> berries picked: 62 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6092 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [545, 878, 1025, 682, 566, 548, 671, 547, 630]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 9, 14, 4, 12, 12, 13, 12, 22]
	Time taken saving stuff: 0.05s

=== episode:485 Env-steps-taken:65760
 	picked: 70 |actions: {0: 445, 1: 446, 2: 568, 3: 442, 4: 811, 5: 516, 6: 419, 7: 494, 8: 374}
episode: 485/2000 -> reward: 88.98958333333326, steps:4515, time-taken: 2.34min, time-elasped: 903.13min
-> berries picked: 70 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6092 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [544, 878, 1032, 685, 567, 541, 663, 550, 632]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 19, 14, 19, 8, 11, 10, 3, 19]
	Time taken saving stuff: 0.03s

=== episode:486 Env-steps-taken:52320
 	picked: 16 |actions: {0: 123, 1: 129, 2: 237, 3: 104, 4: 116, 5: 57, 6: 90, 7: 127, 8: 68}
episode: 486/2000 -> reward: 21.583333333333332, steps:1051, time-taken: 0.83min, time-elasped: 903.97min
-> berries picked: 16 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6089 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [540, 882, 1029, 682, 570, 540, 663, 549, 634]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 12, 20, 17, 14, 10, 12, 10, 24]
	Time taken saving stuff: 0.08s

=== episode:487 Env-steps-taken:65376
 	picked: 67 |actions: {0: 424, 1: 342, 2: 504, 3: 528, 4: 680, 5: 529, 6: 347, 7: 573, 8: 418}
episode: 487/2000 -> reward: 84.77604166666666, steps:4345, time-taken: 2.22min, time-elasped: 906.19min
-> berries picked: 67 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6093 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [540, 884, 1024, 685, 570, 538, 671, 545, 636]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 15, 13, 16, 12, 12, 12, 10, 24]
	Time taken saving stuff: 0.09s

=== episode:488 Env-steps-taken:60768
 	picked: 50 |actions: {0: 360, 1: 454, 2: 512, 3: 344, 4: 446, 5: 364, 6: 292, 7: 459, 8: 243}
episode: 488/2000 -> reward: 63.63541666666672, steps:3474, time-taken: 1.96min, time-elasped: 908.16min
-> berries picked: 50 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6088 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [541, 885, 1031, 683, 565, 538, 667, 543, 635]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 18, 11, 14, 7, 6, 11, 17, 13]
	Time taken saving stuff: 0.10s

=== episode:489 Env-steps-taken:62304
 	picked: 51 |actions: {0: 378, 1: 377, 2: 436, 3: 339, 4: 614, 5: 400, 6: 410, 7: 441, 8: 345}
episode: 489/2000 -> reward: 72.07812500000001, steps:3740, time-taken: 1.96min, time-elasped: 910.12min
-> berries picked: 51 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6102 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [547, 885, 1028, 683, 569, 538, 673, 543, 636]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 18, 19, 5, 10, 11, 8, 19, 16]
	Time taken saving stuff: 0.09s

=== episode:490 Env-steps-taken:62304
 	picked: 55 |actions: {0: 445, 1: 491, 2: 386, 3: 392, 4: 568, 5: 534, 6: 414, 7: 570, 8: 332}
episode: 490/2000 -> reward: 71.84895833333337, steps:4132, time-taken: 2.26min, time-elasped: 912.39min
-> berries picked: 55 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6109 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [553, 889, 1025, 676, 573, 540, 672, 544, 637]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 15, 16, 14, 14, 5, 8, 10, 22]
	Time taken saving stuff: 0.08s

=== episode:49 Env-steps-taken:93696
 	picked: 170 |actions: {0: 875, 1: 255, 2: 1806, 3: 339, 4: 1375, 5: 395, 6: 1642, 7: 481, 8: 729}

==================================================
eval-episode: 490 -> reward: 228.8750000000005, steps: 7897.0, wall-time: 75.78s
-> berries picked: 170 of 800 | patches-visited: [1, 4, 6, 8] | juice left:-0.00
==================================================


=== episode:491 Env-steps-taken:73248
 	picked: 94 |actions: {0: 743, 1: 652, 2: 572, 3: 632, 4: 638, 5: 644, 6: 613, 7: 664, 8: 558}
episode: 491/2000 -> reward: 126.67187499999984, steps:5716, time-taken: 2.97min, time-elasped: 916.62min
-> berries picked: 94 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6105 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [563, 888, 1022, 680, 571, 534, 664, 545, 638]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 23, 9, 10, 13, 11, 18, 13, 22]
	Time taken saving stuff: 0.02s

=== episode:492 Env-steps-taken:68640
 	picked: 77 |actions: {0: 297, 1: 446, 2: 424, 3: 455, 4: 513, 5: 576, 6: 504, 7: 547, 8: 503}
episode: 492/2000 -> reward: 103.58854166666656, steps:4265, time-taken: 2.36min, time-elasped: 918.98min
-> berries picked: 77 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6106 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [555, 897, 1022, 678, 572, 533, 665, 545, 639]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 13, 16, 13, 9, 11, 11, 13, 15]
	Time taken saving stuff: 0.09s

=== episode:493 Env-steps-taken:68160
 	picked: 81 |actions: {0: 406, 1: 438, 2: 484, 3: 531, 4: 702, 5: 671, 6: 451, 7: 405, 8: 425}
episode: 493/2000 -> reward: 100.8593749999999, steps:4513, time-taken: 2.34min, time-elasped: 921.32min
-> berries picked: 81 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6086 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [553, 895, 1015, 674, 566, 540, 669, 532, 642]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 19, 22, 16, 8, 2, 11, 13, 23]
	Time taken saving stuff: 0.10s

=== episode:494 Env-steps-taken:66336
 	picked: 69 |actions: {0: 355, 1: 428, 2: 535, 3: 466, 4: 555, 5: 326, 6: 268, 7: 289, 8: 222}
episode: 494/2000 -> reward: 92.54687499999996, steps:3444, time-taken: 1.97min, time-elasped: 923.30min
-> berries picked: 69 of 800 | patches-visited: [0, 4, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6090 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [550, 899, 1024, 676, 567, 535, 666, 530, 643]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 23, 17, 16, 9, 8, 8, 16, 14]
	Time taken saving stuff: 0.00s

=== episode:495 Env-steps-taken:66624
 	picked: 67 |actions: {0: 345, 1: 431, 2: 400, 3: 437, 4: 552, 5: 429, 6: 343, 7: 397, 8: 285}
episode: 495/2000 -> reward: 93.66145833333326, steps:3619, time-taken: 1.93min, time-elasped: 925.24min
-> berries picked: 67 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6093 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [551, 902, 1020, 675, 565, 536, 664, 532, 648]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 18, 20, 11, 14, 6, 11, 13, 21]
	Time taken saving stuff: 0.01s

=== episode:496 Env-steps-taken:68352
 	picked: 77 |actions: {0: 689, 1: 511, 2: 569, 3: 562, 4: 720, 5: 744, 6: 427, 7: 609, 8: 674}
episode: 496/2000 -> reward: 102.08854166666656, steps:5505, time-taken: 2.69min, time-elasped: 927.93min
-> berries picked: 77 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6092 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [553, 903, 1017, 671, 569, 536, 660, 535, 648]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 12, 21, 14, 17, 10, 17, 6, 21]
	Time taken saving stuff: 0.10s

=== episode:497 Env-steps-taken:64608
 	picked: 60 |actions: {0: 403, 1: 441, 2: 570, 3: 522, 4: 698, 5: 528, 6: 413, 7: 393, 8: 527}
episode: 497/2000 -> reward: 83.06249999999999, steps:4495, time-taken: 2.18min, time-elasped: 930.12min
-> berries picked: 60 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6109 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [554, 903, 1022, 674, 570, 539, 659, 538, 650]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 18, 16, 14, 13, 10, 9, 9, 19]
	Time taken saving stuff: 0.10s

=== episode:498 Env-steps-taken:61536
 	picked: 63 |actions: {0: 545, 1: 539, 2: 603, 3: 623, 4: 874, 5: 498, 6: 483, 7: 597, 8: 636}
episode: 498/2000 -> reward: 66.5052083333334, steps:5398, time-taken: 2.65min, time-elasped: 932.77min
-> berries picked: 63 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6104 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [550, 902, 1020, 678, 568, 537, 661, 539, 649]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 20, 15, 11, 7, 15, 10, 8, 14]
	Time taken saving stuff: 0.10s

=== episode:499 Env-steps-taken:65856
 	picked: 75 |actions: {0: 521, 1: 578, 2: 742, 3: 636, 4: 666, 5: 670, 6: 461, 7: 469, 8: 517}
episode: 499/2000 -> reward: 89.20312499999994, steps:5260, time-taken: 2.68min, time-elasped: 935.46min
-> berries picked: 75 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6118 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [552, 906, 1031, 675, 567, 538, 656, 539, 654]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 24, 16, 11, 9, 8, 9, 7, 18]
	Time taken saving stuff: 0.00s

=== episode:500 Env-steps-taken:61536
 	picked: 50 |actions: {0: 265, 1: 384, 2: 417, 3: 352, 4: 263, 5: 215, 6: 257, 7: 389, 8: 231}
episode: 500/2000 -> reward: 68.6354166666667, steps:2773, time-taken: 1.62min, time-elasped: 937.08min
-> berries picked: 50 of 800 | patches-visited: [0, 7, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6141 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [556, 908, 1037, 680, 568, 535, 660, 542, 655]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 20, 15, 22, 15, 14, 10, 15, 7]
	Time taken saving stuff: 0.17s

=== episode:50 Env-steps-taken:73440
 	picked: 93 |actions: {0: 394, 1: 371, 2: 55, 3: 715, 4: 326, 5: 251, 6: 408, 7: 155, 8: 673}

==================================================
eval-episode: 500 -> reward: 126.28645833333319, steps: 3348.0, wall-time: 53.74s
-> berries picked: 93 of 800 | patches-visited: [0, 1, 2] | juice left:-0.00
==================================================


=== episode:501 Env-steps-taken:66048
 	picked: 72 |actions: {0: 385, 1: 505, 2: 723, 3: 476, 4: 663, 5: 487, 6: 526, 7: 439, 8: 398}
episode: 501/2000 -> reward: 90.37499999999997, steps:4602, time-taken: 2.38min, time-elasped: 940.36min
-> berries picked: 72 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6161 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [558, 909, 1045, 681, 577, 531, 658, 545, 657]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 18, 19, 14, 11, 14, 15, 7, 18]
	Time taken saving stuff: 0.00s

=== episode:502 Env-steps-taken:63840
 	picked: 62 |actions: {0: 374, 1: 326, 2: 407, 3: 380, 4: 423, 5: 430, 6: 297, 7: 423, 8: 355}
episode: 502/2000 -> reward: 79.44791666666666, steps:3415, time-taken: 1.91min, time-elasped: 942.28min
-> berries picked: 62 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6176 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [563, 912, 1045, 684, 576, 534, 659, 547, 656]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 18, 13, 14, 5, 12, 13, 12, 23]
	Time taken saving stuff: 0.00s

=== episode:503 Env-steps-taken:69312
 	picked: 77 |actions: {0: 593, 1: 607, 2: 566, 3: 434, 4: 578, 5: 363, 6: 520, 7: 567, 8: 402}
episode: 503/2000 -> reward: 107.08854166666657, steps:4630, time-taken: 2.53min, time-elasped: 944.81min
-> berries picked: 77 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6202 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [563, 918, 1050, 682, 580, 535, 664, 551, 659]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 11, 17, 13, 11, 13, 11, 13, 17]
	Time taken saving stuff: 0.01s

=== episode:504 Env-steps-taken:52800
 	picked: 15 |actions: {0: 69, 1: 74, 2: 171, 3: 100, 4: 166, 5: 57, 6: 45, 7: 56, 8: 66}
episode: 504/2000 -> reward: 24.140625, steps:804, time-taken: 0.73min, time-elasped: 945.54min
-> berries picked: 15 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6204 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [562, 920, 1054, 683, 579, 534, 661, 550, 661]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 18, 25, 13, 7, 8, 10, 9, 17]
	Time taken saving stuff: 0.10s

=== episode:505 Env-steps-taken:62688
 	picked: 56 |actions: {0: 426, 1: 390, 2: 502, 3: 349, 4: 402, 5: 277, 6: 313, 7: 448, 8: 363}
episode: 505/2000 -> reward: 73.79166666666667, steps:3470, time-taken: 1.96min, time-elasped: 947.51min
-> berries picked: 56 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6197 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [565, 917, 1051, 680, 575, 533, 663, 552, 661]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 11, 19, 12, 11, 9, 8, 20, 15]
	Time taken saving stuff: 0.10s

=== episode:506 Env-steps-taken:58080
 	picked: 36 |actions: {0: 239, 1: 611, 2: 354, 3: 291, 4: 266, 5: 235, 6: 290, 7: 286, 8: 532}
episode: 506/2000 -> reward: 50.93750000000003, steps:3104, time-taken: 1.67min, time-elasped: 949.18min
-> berries picked: 36 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6168 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [567, 914, 1036, 675, 568, 534, 663, 548, 663]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 11, 16, 16, 8, 9, 23, 9, 27]
	Time taken saving stuff: 0.03s

=== episode:507 Env-steps-taken:61440
 	picked: 47 |actions: {0: 286, 1: 297, 2: 245, 3: 220, 4: 214, 5: 187, 6: 283, 7: 280, 8: 341}
episode: 507/2000 -> reward: 66.86458333333337, steps:2353, time-taken: 1.38min, time-elasped: 950.57min
-> berries picked: 47 of 800 | patches-visited: [0, 1, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6164 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [563, 917, 1038, 667, 565, 533, 666, 548, 667]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 17, 18, 14, 10, 5, 8, 19, 20]
	Time taken saving stuff: 0.01s

=== episode:508 Env-steps-taken:63552
 	picked: 62 |actions: {0: 557, 1: 607, 2: 640, 3: 450, 4: 684, 5: 554, 6: 470, 7: 434, 8: 501}
episode: 508/2000 -> reward: 78.00520833333333, steps:4897, time-taken: 2.47min, time-elasped: 953.04min
-> berries picked: 62 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6142 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [563, 915, 1032, 659, 562, 526, 672, 546, 667]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 12, 12, 17, 10, 10, 19, 4, 22]
	Time taken saving stuff: 0.00s

=== episode:509 Env-steps-taken:71712
 	picked: 92 |actions: {0: 672, 1: 690, 2: 956, 3: 648, 4: 732, 5: 598, 6: 660, 7: 515, 8: 614}
episode: 509/2000 -> reward: 118.72916666666649, steps:6085, time-taken: 2.83min, time-elasped: 955.87min
-> berries picked: 92 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6153 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [570, 917, 1037, 651, 566, 523, 674, 549, 666]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 18, 14, 12, 6, 5, 12, 14, 15]
	Time taken saving stuff: 0.00s

=== episode:510 Env-steps-taken:62688
 	picked: 54 |actions: {0: 454, 1: 428, 2: 552, 3: 394, 4: 419, 5: 410, 6: 306, 7: 316, 8: 328}
episode: 510/2000 -> reward: 73.96354166666666, steps:3607, time-taken: 2.05min, time-elasped: 957.92min
-> berries picked: 54 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6152 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [570, 917, 1040, 656, 560, 517, 679, 546, 667]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 18, 19, 5, 8, 9, 9, 15, 16]
	Time taken saving stuff: 0.07s

=== episode:51 Env-steps-taken:55008
 	picked: 25 |actions: {0: 80, 1: 79, 2: 212, 3: 3, 4: 98, 5: 43, 6: 19, 7: 215, 8: 56}

==================================================
eval-episode: 510 -> reward: 35.567708333333336, steps: 805.0, wall-time: 36.63s
-> berries picked: 25 of 800 | patches-visited: [1, 2] | juice left:-0.00
==================================================


=== episode:511 Env-steps-taken:59328
 	picked: 43 |actions: {0: 290, 1: 319, 2: 331, 3: 258, 4: 392, 5: 224, 6: 199, 7: 302, 8: 333}
episode: 511/2000 -> reward: 57.03645833333337, steps:2648, time-taken: 1.58min, time-elasped: 960.12min
-> berries picked: 43 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6142 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [567, 922, 1037, 657, 552, 513, 679, 546, 669]
	| approx positives in sample 512: 93
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 16, 16, 12, 8, 8, 12, 7, 8]
	Time taken saving stuff: 0.14s

=== episode:512 Env-steps-taken:68352
 	picked: 72 |actions: {0: 458, 1: 462, 2: 443, 3: 403, 4: 447, 5: 386, 6: 378, 7: 326, 8: 324}
episode: 512/2000 -> reward: 102.37499999999991, steps:3627, time-taken: 1.99min, time-elasped: 962.11min
-> berries picked: 72 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6158 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [575, 925, 1040, 661, 545, 513, 678, 551, 670]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 14, 17, 14, 16, 6, 13, 10, 17]
	Time taken saving stuff: 0.11s

=== episode:513 Env-steps-taken:60288
 	picked: 51 |actions: {0: 382, 1: 415, 2: 623, 3: 406, 4: 559, 5: 369, 6: 288, 7: 384, 8: 406}
episode: 513/2000 -> reward: 61.07812500000007, steps:3832, time-taken: 1.98min, time-elasped: 964.09min
-> berries picked: 51 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6146 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [576, 929, 1038, 655, 547, 505, 680, 546, 670]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 18, 6, 8, 10, 5, 12, 14, 21]
	Time taken saving stuff: 0.10s

=== episode:514 Env-steps-taken:61440
 	picked: 52 |actions: {0: 360, 1: 449, 2: 539, 3: 393, 4: 481, 5: 399, 6: 280, 7: 509, 8: 344}
episode: 514/2000 -> reward: 68.02083333333339, steps:3754, time-taken: 2.00min, time-elasped: 966.10min
-> berries picked: 52 of 800 | patches-visited: [0, 5, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6147 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [577, 927, 1038, 650, 551, 509, 680, 543, 672]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 15, 17, 13, 8, 12, 13, 5, 22]
	Time taken saving stuff: 0.01s

=== episode:515 Env-steps-taken:72480
 	picked: 90 |actions: {0: 623, 1: 618, 2: 865, 3: 600, 4: 659, 5: 590, 6: 413, 7: 611, 8: 405}
episode: 515/2000 -> reward: 122.84374999999982, steps:5384, time-taken: 2.84min, time-elasped: 968.95min
-> berries picked: 90 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6145 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [577, 931, 1034, 649, 549, 511, 680, 545, 669]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 9, 16, 12, 8, 11, 10, 13, 12]
	Time taken saving stuff: 0.01s

=== episode:516 Env-steps-taken:77952
 	picked: 106 |actions: {0: 657, 1: 691, 2: 806, 3: 734, 4: 863, 5: 773, 6: 548, 7: 708, 8: 537}
episode: 516/2000 -> reward: 150.42708333333334, steps:6317, time-taken: 3.03min, time-elasped: 971.99min
-> berries picked: 106 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6178 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [585, 936, 1036, 656, 552, 512, 682, 545, 674]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 27, 13, 14, 11, 16, 15, 10, 18]
	Time taken saving stuff: 0.01s

=== episode:517 Env-steps-taken:63936
 	picked: 63 |actions: {0: 487, 1: 627, 2: 673, 3: 633, 4: 829, 5: 809, 6: 520, 7: 530, 8: 687}
episode: 517/2000 -> reward: 79.39062499999996, steps:5795, time-taken: 2.78min, time-elasped: 974.77min
-> berries picked: 63 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6173 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [590, 934, 1037, 659, 548, 502, 684, 544, 675]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 15, 10, 14, 11, 6, 11, 14, 17]
	Time taken saving stuff: 0.01s

=== episode:518 Env-steps-taken:72288
 	picked: 89 |actions: {0: 512, 1: 565, 2: 667, 3: 563, 4: 515, 5: 512, 6: 418, 7: 562, 8: 384}
episode: 518/2000 -> reward: 119.95833333333317, steps:4698, time-taken: 2.50min, time-elasped: 977.27min
-> berries picked: 89 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6200 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [597, 936, 1045, 667, 542, 506, 681, 548, 678]
	| approx positives in sample 512: 100
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 19, 7, 13, 2, 6, 12, 10, 19]
	Time taken saving stuff: 0.01s

=== episode:519 Env-steps-taken:62592
 	picked: 50 |actions: {0: 270, 1: 264, 2: 379, 3: 362, 4: 419, 5: 410, 6: 351, 7: 301, 8: 452}
episode: 519/2000 -> reward: 73.63541666666667, steps:3208, time-taken: 1.95min, time-elasped: 979.22min
-> berries picked: 50 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6205 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [588, 938, 1049, 665, 547, 508, 681, 553, 676]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 10, 20, 8, 12, 12, 16, 6, 19]
	Time taken saving stuff: 0.00s

=== episode:520 Env-steps-taken:63264
 	picked: 61 |actions: {0: 380, 1: 492, 2: 622, 3: 509, 4: 402, 5: 400, 6: 333, 7: 471, 8: 385}
episode: 520/2000 -> reward: 76.00520833333333, steps:3994, time-taken: 2.01min, time-elasped: 981.23min
-> berries picked: 61 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6207 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [589, 943, 1055, 666, 547, 503, 679, 550, 675]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 16, 16, 16, 4, 11, 12, 7, 12]
	Time taken saving stuff: 0.08s

=== episode:52 Env-steps-taken:79968
 	picked: 118 |actions: {0: 375, 1: 790, 2: 153, 3: 785, 4: 692, 5: 342, 6: 1286, 7: 224, 8: 695}

==================================================
eval-episode: 520 -> reward: 160.7395833333334, steps: 5342.0, wall-time: 53.27s
-> berries picked: 118 of 800 | patches-visited: [0, 1, 3] | juice left:-0.00
==================================================


=== episode:521 Env-steps-taken:70656
 	picked: 78 |actions: {0: 455, 1: 536, 2: 537, 3: 536, 4: 743, 5: 723, 6: 494, 7: 590, 8: 787}
episode: 521/2000 -> reward: 114.03124999999989, steps:5401, time-taken: 2.69min, time-elasped: 984.82min
-> berries picked: 78 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6200 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [589, 943, 1054, 668, 548, 499, 675, 547, 677]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [24, 13, 20, 16, 4, 11, 10, 6, 20]
	Time taken saving stuff: 0.01s

=== episode:522 Env-steps-taken:66816
 	picked: 70 |actions: {0: 336, 1: 396, 2: 546, 3: 425, 4: 584, 5: 466, 6: 387, 7: 573, 8: 537}
episode: 522/2000 -> reward: 94.48958333333329, steps:4250, time-taken: 2.25min, time-elasped: 987.08min
-> berries picked: 70 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6224 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [590, 942, 1055, 677, 555, 505, 675, 547, 678]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 15, 17, 19, 10, 13, 5, 13, 17]
	Time taken saving stuff: 0.01s

=== episode:523 Env-steps-taken:69312
 	picked: 77 |actions: {0: 459, 1: 650, 2: 678, 3: 559, 4: 593, 5: 561, 6: 370, 7: 525, 8: 470}
episode: 523/2000 -> reward: 106.64583333333323, steps:4865, time-taken: 2.50min, time-elasped: 989.58min
-> berries picked: 77 of 800 | patches-visited: [0, 5, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6244 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [586, 949, 1056, 680, 561, 508, 678, 544, 682]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 21, 24, 8, 11, 12, 12, 11, 8]
	Time taken saving stuff: 0.01s

=== episode:524 Env-steps-taken:67488
 	picked: 72 |actions: {0: 358, 1: 485, 2: 424, 3: 424, 4: 620, 5: 424, 6: 477, 7: 583, 8: 447}
episode: 524/2000 -> reward: 97.87499999999994, steps:4242, time-taken: 2.26min, time-elasped: 991.84min
-> berries picked: 72 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6252 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [590, 941, 1055, 680, 564, 507, 682, 547, 686]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 18, 16, 11, 10, 12, 18, 12, 17]
	Time taken saving stuff: 0.00s

=== episode:525 Env-steps-taken:72192
 	picked: 89 |actions: {0: 647, 1: 583, 2: 726, 3: 587, 4: 768, 5: 552, 6: 466, 7: 566, 8: 564}
episode: 525/2000 -> reward: 121.4010416666665, steps:5459, time-taken: 2.71min, time-elasped: 994.56min
-> berries picked: 89 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6269 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [597, 943, 1053, 686, 567, 508, 683, 545, 687]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 15, 18, 18, 9, 12, 11, 11, 18]
	Time taken saving stuff: 0.00s

=== episode:526 Env-steps-taken:62016
 	picked: 56 |actions: {0: 308, 1: 381, 2: 318, 3: 559, 4: 373, 5: 331, 6: 361, 7: 355, 8: 321}
episode: 526/2000 -> reward: 69.7916666666667, steps:3307, time-taken: 1.91min, time-elasped: 996.47min
-> berries picked: 56 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6276 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [592, 946, 1046, 691, 572, 510, 686, 548, 685]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 9, 15, 15, 13, 11, 9, 10, 15]
	Time taken saving stuff: 0.01s

=== episode:527 Env-steps-taken:69408
 	picked: 81 |actions: {0: 546, 1: 714, 2: 631, 3: 493, 4: 711, 5: 573, 6: 478, 7: 473, 8: 595}
episode: 527/2000 -> reward: 107.35937499999987, steps:5214, time-taken: 2.61min, time-elasped: 999.09min
-> berries picked: 81 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6279 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [595, 951, 1048, 693, 566, 513, 682, 547, 684]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 14, 15, 11, 16, 11, 13, 8, 24]
	Time taken saving stuff: 0.01s

=== episode:528 Env-steps-taken:71232
 	picked: 88 |actions: {0: 740, 1: 616, 2: 668, 3: 710, 4: 708, 5: 609, 6: 569, 7: 447, 8: 496}
episode: 528/2000 -> reward: 116.45833333333317, steps:5563, time-taken: 2.73min, time-elasped: 1001.83min
-> berries picked: 88 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6271 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [591, 951, 1050, 685, 564, 511, 685, 550, 684]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 9, 13, 14, 11, 10, 14, 7, 17]
	Time taken saving stuff: 0.00s

=== episode:529 Env-steps-taken:70176
 	picked: 81 |actions: {0: 509, 1: 605, 2: 561, 3: 561, 4: 623, 5: 671, 6: 522, 7: 556, 8: 538}
episode: 529/2000 -> reward: 111.85937499999986, steps:5146, time-taken: 2.67min, time-elasped: 1004.50min
-> berries picked: 81 of 800 | patches-visited: [0, 1, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6295 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [591, 950, 1057, 686, 566, 516, 688, 554, 687]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 18, 12, 7, 13, 16, 9, 8, 21]
	Time taken saving stuff: 0.00s

=== episode:530 Env-steps-taken:72000
 	picked: 94 |actions: {0: 511, 1: 675, 2: 712, 3: 441, 4: 650, 5: 461, 6: 452, 7: 418, 8: 389}
episode: 530/2000 -> reward: 120.11458333333317, steps:4709, time-taken: 2.58min, time-elasped: 1007.08min
-> berries picked: 94 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6318 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [603, 956, 1055, 685, 573, 519, 684, 554, 689]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 16, 17, 14, 10, 11, 21, 10, 21]
	Time taken saving stuff: 0.06s

=== episode:53 Env-steps-taken:72864
 	picked: 95 |actions: {0: 241, 1: 656, 2: 534, 3: 179, 4: 866, 5: 60, 6: 243, 7: 419, 8: 547}

==================================================
eval-episode: 530 -> reward: 123.61458333333313, steps: 3745.0, wall-time: 42.83s
-> berries picked: 95 of 800 | patches-visited: [0, 1, 8] | juice left:-0.00
==================================================


=== episode:531 Env-steps-taken:71424
 	picked: 85 |actions: {0: 683, 1: 810, 2: 959, 3: 485, 4: 557, 5: 703, 6: 496, 7: 671, 8: 816}
episode: 531/2000 -> reward: 117.63020833333317, steps:6180, time-taken: 3.00min, time-elasped: 1010.79min
-> berries picked: 85 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6315 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [607, 959, 1053, 679, 574, 522, 684, 549, 688]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 21, 21, 15, 8, 13, 18, 18, 15]
	Time taken saving stuff: 0.00s

=== episode:532 Env-steps-taken:78144
 	picked: 112 |actions: {0: 691, 1: 875, 2: 843, 3: 645, 4: 695, 5: 605, 6: 581, 7: 641, 8: 764}
episode: 532/2000 -> reward: 150.69791666666666, steps:6340, time-taken: 3.17min, time-elasped: 1013.97min
-> berries picked: 112 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6332 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [603, 972, 1057, 685, 569, 519, 684, 553, 690]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 15, 16, 12, 13, 12, 10, 5, 14]
	Time taken saving stuff: 0.00s

=== episode:533 Env-steps-taken:59424
 	picked: 46 |actions: {0: 280, 1: 435, 2: 588, 3: 398, 4: 394, 5: 342, 6: 321, 7: 258, 8: 530}
episode: 533/2000 -> reward: 56.864583333333385, steps:3546, time-taken: 1.79min, time-elasped: 1015.76min
-> berries picked: 46 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6327 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [604, 972, 1052, 680, 569, 520, 689, 553, 688]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 18, 11, 10, 7, 7, 13, 16, 18]
	Time taken saving stuff: 0.01s

=== episode:534 Env-steps-taken:65472
 	picked: 71 |actions: {0: 532, 1: 656, 2: 635, 3: 472, 4: 674, 5: 535, 6: 465, 7: 529, 8: 534}
episode: 534/2000 -> reward: 86.93229166666661, steps:5032, time-taken: 2.46min, time-elasped: 1018.22min
-> berries picked: 71 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6339 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [610, 977, 1062, 677, 569, 519, 683, 555, 687]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 25, 21, 16, 11, 11, 13, 9, 18]
	Time taken saving stuff: 0.01s

=== episode:535 Env-steps-taken:72576
 	picked: 88 |actions: {0: 516, 1: 752, 2: 735, 3: 602, 4: 736, 5: 685, 6: 579, 7: 493, 8: 698}
episode: 535/2000 -> reward: 123.45833333333317, steps:5796, time-taken: 2.88min, time-elasped: 1021.10min
-> berries picked: 88 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6369 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [609, 976, 1066, 676, 575, 529, 687, 560, 691]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 10, 12, 9, 9, 12, 13, 16, 20]
	Time taken saving stuff: 0.00s

=== episode:536 Env-steps-taken:68064
 	picked: 74 |actions: {0: 445, 1: 687, 2: 728, 3: 539, 4: 460, 5: 644, 6: 460, 7: 522, 8: 622}
episode: 536/2000 -> reward: 100.76041666666656, steps:5107, time-taken: 2.60min, time-elasped: 1023.70min
-> berries picked: 74 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6343 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [604, 975, 1061, 672, 571, 532, 687, 555, 686]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 14, 13, 17, 8, 14, 13, 16, 21]
	Time taken saving stuff: 0.01s

=== episode:537 Env-steps-taken:70176
 	picked: 79 |actions: {0: 339, 1: 538, 2: 514, 3: 404, 4: 503, 5: 432, 6: 495, 7: 503, 8: 533}
episode: 537/2000 -> reward: 111.08854166666657, steps:4261, time-taken: 2.22min, time-elasped: 1025.92min
-> berries picked: 79 of 800 | patches-visited: [0, 2, 5, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6348 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [612, 968, 1063, 674, 572, 529, 685, 556, 689]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 14, 18, 12, 7, 12, 12, 3, 26]
	Time taken saving stuff: 0.01s

=== episode:538 Env-steps-taken:66720
 	picked: 63 |actions: {0: 393, 1: 402, 2: 507, 3: 385, 4: 439, 5: 423, 6: 330, 7: 311, 8: 378}
episode: 538/2000 -> reward: 94.89062499999996, steps:3568, time-taken: 1.88min, time-elasped: 1027.81min
-> berries picked: 63 of 800 | patches-visited: [0, 5, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6357 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [612, 968, 1061, 680, 569, 532, 685, 556, 694]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 8, 17, 12, 7, 10, 13, 9, 8]
	Time taken saving stuff: 0.01s

=== episode:539 Env-steps-taken:70752
 	picked: 89 |actions: {0: 594, 1: 711, 2: 743, 3: 545, 4: 634, 5: 587, 6: 720, 7: 675, 8: 674}
episode: 539/2000 -> reward: 113.90104166666653, steps:5883, time-taken: 3.07min, time-elasped: 1030.88min
-> berries picked: 89 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6349 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [611, 968, 1056, 675, 576, 527, 681, 559, 696]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 14, 20, 14, 8, 8, 22, 9, 12]
	Time taken saving stuff: 0.01s

=== episode:540 Env-steps-taken:76704
 	picked: 105 |actions: {0: 832, 1: 722, 2: 688, 3: 489, 4: 531, 5: 580, 6: 627, 7: 729, 8: 534}
episode: 540/2000 -> reward: 142.59895833333326, steps:5732, time-taken: 2.94min, time-elasped: 1033.82min
-> berries picked: 105 of 800 | patches-visited: [0, 5, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6371 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [618, 973, 1054, 678, 567, 532, 686, 565, 698]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 16, 19, 15, 8, 16, 12, 20, 14]
	Time taken saving stuff: 0.05s

=== episode:54 Env-steps-taken:92640
 	picked: 176 |actions: {0: 454, 1: 662, 2: 1206, 3: 535, 4: 766, 5: 159, 6: 882, 7: 972, 8: 1208}

==================================================
eval-episode: 540 -> reward: 223.4166666666672, steps: 6844.0, wall-time: 62.30s
-> berries picked: 176 of 800 | patches-visited: [1, 5, 7] | juice left:-0.00
==================================================


=== episode:541 Env-steps-taken:72192
 	picked: 91 |actions: {0: 701, 1: 620, 2: 820, 3: 699, 4: 547, 5: 535, 6: 568, 7: 578, 8: 638}
episode: 541/2000 -> reward: 119.4010416666665, steps:5706, time-taken: 2.85min, time-elasped: 1037.71min
-> berries picked: 91 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6375 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [617, 977, 1057, 674, 569, 534, 684, 566, 697]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 16, 13, 20, 10, 8, 14, 7, 14]
	Time taken saving stuff: 0.00s

=== episode:542 Env-steps-taken:74400
 	picked: 103 |actions: {0: 600, 1: 674, 2: 764, 3: 692, 4: 651, 5: 591, 6: 564, 7: 540, 8: 419}
episode: 542/2000 -> reward: 132.59895833333317, steps:5495, time-taken: 2.75min, time-elasped: 1040.46min
-> berries picked: 103 of 800 | patches-visited: [0, 6, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6392 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [619, 978, 1047, 684, 579, 534, 684, 569, 698]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 15, 15, 16, 6, 8, 15, 6, 21]
	Time taken saving stuff: 0.01s

=== episode:543 Env-steps-taken:70176
 	picked: 74 |actions: {0: 481, 1: 542, 2: 555, 3: 440, 4: 433, 5: 418, 6: 425, 7: 401, 8: 498}
episode: 543/2000 -> reward: 110.8749999999999, steps:4193, time-taken: 2.27min, time-elasped: 1042.74min
-> berries picked: 74 of 800 | patches-visited: [0, 1, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6394 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [613, 977, 1042, 683, 581, 533, 685, 578, 702]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 10, 10, 15, 7, 14, 12, 8, 16]
	Time taken saving stuff: 0.00s

=== episode:544 Env-steps-taken:69408
 	picked: 84 |actions: {0: 671, 1: 506, 2: 733, 3: 540, 4: 749, 5: 525, 6: 709, 7: 495, 8: 542}
episode: 544/2000 -> reward: 107.18749999999986, steps:5470, time-taken: 2.70min, time-elasped: 1045.44min
-> berries picked: 84 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6409 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [614, 981, 1050, 683, 584, 527, 687, 579, 704]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 16, 18, 9, 11, 8, 11, 4, 16]
	Time taken saving stuff: 0.01s

=== episode:545 Env-steps-taken:65568
 	picked: 67 |actions: {0: 481, 1: 428, 2: 583, 3: 536, 4: 554, 5: 520, 6: 396, 7: 431, 8: 414}
episode: 545/2000 -> reward: 88.16145833333327, steps:4343, time-taken: 2.31min, time-elasped: 1047.75min
-> berries picked: 67 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6419 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [615, 988, 1047, 688, 591, 525, 685, 576, 704]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 18, 16, 11, 9, 14, 9, 10, 21]
	Time taken saving stuff: 0.01s

=== episode:546 Env-steps-taken:61056
 	picked: 47 |actions: {0: 295, 1: 288, 2: 397, 3: 274, 4: 330, 5: 287, 6: 323, 7: 303, 8: 314}
episode: 546/2000 -> reward: 65.8072916666667, steps:2811, time-taken: 1.73min, time-elasped: 1049.49min
-> berries picked: 47 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6407 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [619, 985, 1037, 687, 588, 524, 684, 578, 705]
	| approx positives in sample 512: 101
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 17, 20, 16, 8, 4, 8, 6, 12]
	Time taken saving stuff: 0.01s

=== episode:547 Env-steps-taken:61824
 	picked: 56 |actions: {0: 412, 1: 663, 2: 1093, 3: 528, 4: 556, 5: 503, 6: 412, 7: 340, 8: 652}
episode: 547/2000 -> reward: 68.79166666666669, steps:5159, time-taken: 2.52min, time-elasped: 1052.01min
-> berries picked: 56 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6379 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [616, 976, 1025, 691, 584, 522, 685, 576, 704]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 15, 22, 13, 7, 8, 12, 4, 16]
	Time taken saving stuff: 0.00s

=== episode:548 Env-steps-taken:78048
 	picked: 114 |actions: {0: 728, 1: 810, 2: 891, 3: 585, 4: 912, 5: 522, 6: 708, 7: 694, 8: 584}
episode: 548/2000 -> reward: 150.46874999999994, steps:6434, time-taken: 3.24min, time-elasped: 1055.26min
-> berries picked: 114 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6416 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [619, 978, 1026, 696, 589, 525, 688, 586, 709]
	| approx positives in sample 512: 100
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 14, 14, 10, 12, 11, 12, 8, 11]
	Time taken saving stuff: 0.01s

=== episode:549 Env-steps-taken:74592
 	picked: 96 |actions: {0: 579, 1: 755, 2: 647, 3: 597, 4: 599, 5: 555, 6: 577, 7: 516, 8: 442}
episode: 549/2000 -> reward: 133.4999999999999, steps:5267, time-taken: 2.70min, time-elasped: 1057.96min
-> berries picked: 96 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6431 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [624, 984, 1026, 698, 590, 525, 690, 583, 711]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 20, 9, 14, 9, 13, 9, 15, 13]
	Time taken saving stuff: 0.01s

=== episode:550 Env-steps-taken:72480
 	picked: 88 |actions: {0: 705, 1: 554, 2: 913, 3: 628, 4: 625, 5: 659, 6: 522, 7: 539, 8: 682}
episode: 550/2000 -> reward: 121.01562499999986, steps:5827, time-taken: 2.86min, time-elasped: 1060.82min
-> berries picked: 88 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6442 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [629, 985, 1022, 693, 591, 530, 694, 586, 712]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 14, 19, 12, 12, 13, 18, 8, 18]
	Time taken saving stuff: 0.06s

=== episode:55 Env-steps-taken:91296
 	picked: 159 |actions: {0: 809, 1: 444, 2: 569, 3: 1203, 4: 354, 5: 987, 6: 271, 7: 468, 8: 432}

==================================================
eval-episode: 550 -> reward: 217.00520833333383, steps: 5537.0, wall-time: 66.60s
-> berries picked: 159 of 800 | patches-visited: [0, 1, 2, 6] | juice left:-0.00
==================================================


=== episode:551 Env-steps-taken:71616
 	picked: 84 |actions: {0: 575, 1: 714, 2: 760, 3: 631, 4: 831, 5: 689, 6: 818, 7: 568, 8: 656}
episode: 551/2000 -> reward: 118.68749999999986, steps:6242, time-taken: 3.12min, time-elasped: 1065.06min
-> berries picked: 84 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6433 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [631, 983, 1015, 693, 593, 527, 690, 588, 713]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 14, 16, 15, 13, 9, 11, 14, 12]
	Time taken saving stuff: 0.01s

=== episode:552 Env-steps-taken:66240
 	picked: 76 |actions: {0: 600, 1: 455, 2: 608, 3: 524, 4: 655, 5: 560, 6: 604, 7: 555, 8: 556}
episode: 552/2000 -> reward: 89.20312499999991, steps:5117, time-taken: 2.46min, time-elasped: 1067.52min
-> berries picked: 76 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6448 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [636, 987, 1017, 688, 596, 531, 693, 585, 715]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 17, 11, 13, 11, 6, 17, 11, 19]
	Time taken saving stuff: 0.00s

=== episode:553 Env-steps-taken:70656
 	picked: 89 |actions: {0: 653, 1: 673, 2: 660, 3: 505, 4: 493, 5: 553, 6: 537, 7: 523, 8: 473}
episode: 553/2000 -> reward: 113.40104166666652, steps:5070, time-taken: 2.73min, time-elasped: 1070.25min
-> berries picked: 89 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6472 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [646, 989, 1028, 688, 602, 530, 691, 584, 714]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 10, 17, 18, 11, 8, 13, 10, 20]
	Time taken saving stuff: 0.01s

=== episode:554 Env-steps-taken:67008
 	picked: 75 |actions: {0: 623, 1: 550, 2: 764, 3: 641, 4: 632, 5: 424, 6: 444, 7: 492, 8: 476}
episode: 554/2000 -> reward: 95.20312499999994, steps:5046, time-taken: 2.55min, time-elasped: 1072.80min
-> berries picked: 75 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6459 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [646, 991, 1018, 691, 603, 527, 685, 586, 712]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 15, 20, 11, 12, 9, 15, 16, 23]
	Time taken saving stuff: 0.01s

=== episode:555 Env-steps-taken:73344
 	picked: 101 |actions: {0: 666, 1: 738, 2: 738, 3: 733, 4: 733, 5: 597, 6: 582, 7: 708, 8: 471}
episode: 555/2000 -> reward: 126.71354166666643, steps:5966, time-taken: 2.90min, time-elasped: 1075.70min
-> berries picked: 101 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6459 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [642, 986, 1021, 693, 597, 527, 688, 592, 713]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 16, 12, 12, 7, 8, 10, 7, 17]
	Time taken saving stuff: 0.01s

=== episode:556 Env-steps-taken:66240
 	picked: 67 |actions: {0: 565, 1: 494, 2: 441, 3: 311, 4: 428, 5: 349, 6: 438, 7: 396, 8: 387}
episode: 556/2000 -> reward: 91.66145833333329, steps:3809, time-taken: 1.97min, time-elasped: 1077.68min
-> berries picked: 67 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6488 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [647, 993, 1023, 688, 600, 533, 691, 597, 716]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 22, 14, 15, 11, 6, 8, 15, 14]
	Time taken saving stuff: 0.00s

=== episode:557 Env-steps-taken:76128
 	picked: 101 |actions: {0: 806, 1: 751, 2: 724, 3: 603, 4: 738, 5: 706, 6: 543, 7: 549, 8: 636}
episode: 557/2000 -> reward: 141.21354166666657, steps:6056, time-taken: 3.08min, time-elasped: 1080.76min
-> berries picked: 101 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6506 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [652, 998, 1023, 687, 607, 534, 692, 597, 716]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 16, 18, 10, 8, 11, 6, 8, 17]
	Time taken saving stuff: 0.01s

=== episode:558 Env-steps-taken:62976
 	picked: 51 |actions: {0: 323, 1: 276, 2: 293, 3: 325, 4: 193, 5: 287, 6: 204, 7: 218, 8: 271}
episode: 558/2000 -> reward: 76.07812500000001, steps:2390, time-taken: 1.40min, time-elasped: 1082.16min
-> berries picked: 51 of 800 | patches-visited: [0, 1, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6522 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [653, 1000, 1024, 693, 605, 532, 694, 602, 719]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 13, 17, 12, 7, 10, 10, 19, 12]
	Time taken saving stuff: 0.01s

=== episode:559 Env-steps-taken:58848
 	picked: 40 |actions: {0: 267, 1: 236, 2: 412, 3: 327, 4: 346, 5: 465, 6: 305, 7: 271, 8: 522}
episode: 559/2000 -> reward: 54.20833333333339, steps:3151, time-taken: 1.76min, time-elasped: 1083.92min
-> berries picked: 40 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6526 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [652, 999, 1025, 690, 609, 535, 696, 601, 719]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 12, 14, 11, 7, 13, 14, 11, 12]
	Time taken saving stuff: 0.00s

=== episode:560 Env-steps-taken:73920
 	picked: 101 |actions: {0: 609, 1: 642, 2: 763, 3: 722, 4: 717, 5: 585, 6: 538, 7: 480, 8: 483}
episode: 560/2000 -> reward: 129.7135416666665, steps:5539, time-taken: 2.96min, time-elasped: 1086.89min
-> berries picked: 101 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6538 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [650, 1006, 1024, 691, 613, 539, 691, 606, 718]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 13, 19, 18, 11, 10, 15, 4, 12]
	Time taken saving stuff: 0.09s

=== episode:56 Env-steps-taken:57024
 	picked: 32 |actions: {0: 164, 1: 167, 2: 119, 3: 58, 4: 67, 5: 48, 6: 56, 7: 70, 8: 108}

==================================================
eval-episode: 560 -> reward: 45.166666666666686, steps: 857.0, wall-time: 35.22s
-> berries picked: 32 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:561 Env-steps-taken:67488
 	picked: 78 |actions: {0: 502, 1: 639, 2: 641, 3: 497, 4: 578, 5: 368, 6: 454, 7: 508, 8: 605}
episode: 561/2000 -> reward: 97.53124999999993, steps:4792, time-taken: 2.35min, time-elasped: 1089.83min
-> berries picked: 78 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6546 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [656, 1001, 1035, 691, 610, 537, 690, 610, 716]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 13, 19, 13, 4, 13, 13, 13, 19]
	Time taken saving stuff: 0.02s

=== episode:562 Env-steps-taken:82080
 	picked: 127 |actions: {0: 722, 1: 823, 2: 913, 3: 760, 4: 853, 5: 833, 6: 855, 7: 689, 8: 618}
episode: 562/2000 -> reward: 170.72395833333348, steps:7066, time-taken: 3.53min, time-elasped: 1093.37min
-> berries picked: 127 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6578 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [663, 1008, 1032, 691, 617, 545, 691, 610, 721]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 16, 16, 13, 9, 10, 11, 16, 21]
	Time taken saving stuff: 0.01s

=== episode:563 Env-steps-taken:64896
 	picked: 60 |actions: {0: 451, 1: 379, 2: 376, 3: 296, 4: 447, 5: 429, 6: 472, 7: 373, 8: 371}
episode: 563/2000 -> reward: 85.56249999999997, steps:3594, time-taken: 1.97min, time-elasped: 1095.34min
-> berries picked: 60 of 800 | patches-visited: [0, 3, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6593 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [670, 1010, 1030, 693, 620, 542, 690, 615, 723]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 13, 18, 13, 10, 8, 12, 14, 27]
	Time taken saving stuff: 0.01s

=== episode:564 Env-steps-taken:63072
 	picked: 54 |actions: {0: 351, 1: 380, 2: 526, 3: 408, 4: 501, 5: 314, 6: 316, 7: 281, 8: 451}
episode: 564/2000 -> reward: 75.90624999999999, steps:3528, time-taken: 1.81min, time-elasped: 1097.15min
-> berries picked: 54 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6598 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [668, 1015, 1033, 697, 621, 539, 687, 613, 725]
	| approx positives in sample 512: 101
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 12, 10, 8, 10, 8, 10, 14, 15]
	Time taken saving stuff: 0.01s

=== episode:565 Env-steps-taken:65280
 	picked: 60 |actions: {0: 458, 1: 411, 2: 529, 3: 378, 4: 623, 5: 657, 6: 384, 7: 342, 8: 393}
episode: 565/2000 -> reward: 87.06249999999996, steps:4175, time-taken: 2.16min, time-elasped: 1099.31min
-> berries picked: 60 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6599 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [670, 1012, 1034, 698, 623, 537, 687, 613, 725]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 17, 16, 11, 10, 9, 11, 8, 18]
	Time taken saving stuff: 0.01s

=== episode:566 Env-steps-taken:70080
 	picked: 84 |actions: {0: 743, 1: 712, 2: 560, 3: 551, 4: 708, 5: 656, 6: 587, 7: 598, 8: 611}
episode: 566/2000 -> reward: 108.35937499999986, steps:5726, time-taken: 2.68min, time-elasped: 1101.99min
-> berries picked: 84 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6594 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [667, 1016, 1038, 700, 614, 535, 690, 609, 725]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 16, 19, 11, 12, 10, 14, 9, 22]
	Time taken saving stuff: 0.01s

=== episode:567 Env-steps-taken:64032
 	picked: 59 |actions: {0: 495, 1: 428, 2: 552, 3: 469, 4: 526, 5: 570, 6: 446, 7: 324, 8: 610}
episode: 567/2000 -> reward: 80.61979166666664, steps:4420, time-taken: 2.24min, time-elasped: 1104.24min
-> berries picked: 59 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6603 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [668, 1019, 1039, 704, 613, 536, 689, 610, 725]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 17, 16, 9, 8, 12, 11, 8, 26]
	Time taken saving stuff: 0.01s

=== episode:568 Env-steps-taken:72480
 	picked: 94 |actions: {0: 555, 1: 700, 2: 663, 3: 557, 4: 630, 5: 681, 6: 519, 7: 505, 8: 508}
episode: 568/2000 -> reward: 121.22916666666647, steps:5318, time-taken: 2.46min, time-elasped: 1106.70min
-> berries picked: 94 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6609 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [669, 1022, 1042, 703, 617, 539, 688, 606, 723]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 16, 19, 10, 15, 10, 8, 12, 18]
	Time taken saving stuff: 0.00s

=== episode:569 Env-steps-taken:77856
 	picked: 113 |actions: {0: 925, 1: 993, 2: 807, 3: 618, 4: 702, 5: 615, 6: 646, 7: 618, 8: 738}
episode: 569/2000 -> reward: 149.52604166666663, steps:6662, time-taken: 3.06min, time-elasped: 1109.77min
-> berries picked: 113 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6643 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [682, 1029, 1047, 707, 620, 538, 688, 611, 721]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 27, 22, 8, 11, 7, 15, 13, 18]
	Time taken saving stuff: 0.08s

=== episode:570 Env-steps-taken:71616
 	picked: 91 |actions: {0: 698, 1: 680, 2: 706, 3: 602, 4: 654, 5: 728, 6: 451, 7: 460, 8: 618}
episode: 570/2000 -> reward: 117.90104166666653, steps:5597, time-taken: 2.75min, time-elasped: 1112.52min
-> berries picked: 91 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6659 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [687, 1034, 1045, 707, 627, 536, 686, 612, 725]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 15, 17, 12, 10, 10, 9, 14, 12]
	Time taken saving stuff: 0.15s

=== episode:57 Env-steps-taken:96096
 	picked: 186 |actions: {0: 722, 1: 507, 2: 1223, 3: 313, 4: 744, 5: 1015, 6: 303, 7: 639, 8: 931}

==================================================
eval-episode: 570 -> reward: 240.84375000000065, steps: 6397.0, wall-time: 64.11s
-> berries picked: 186 of 800 | patches-visited: [1, 6, 7] | juice left:-0.00
==================================================


=== episode:571 Env-steps-taken:78048
 	picked: 110 |actions: {0: 817, 1: 723, 2: 657, 3: 657, 4: 676, 5: 677, 6: 592, 7: 510, 8: 391}
episode: 571/2000 -> reward: 150.6979166666666, steps:5700, time-taken: 2.83min, time-elasped: 1116.42min
-> berries picked: 110 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6644 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [683, 1026, 1044, 711, 619, 544, 682, 616, 719]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 20, 20, 9, 13, 9, 9, 7, 22]
	Time taken saving stuff: 0.03s

=== episode:572 Env-steps-taken:68832
 	picked: 79 |actions: {0: 633, 1: 580, 2: 569, 3: 580, 4: 885, 5: 662, 6: 621, 7: 567, 8: 592}
episode: 572/2000 -> reward: 104.47395833333321, steps:5689, time-taken: 2.81min, time-elasped: 1119.24min
-> berries picked: 79 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6634 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [682, 1019, 1043, 711, 623, 542, 683, 611, 720]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 15, 14, 9, 5, 8, 10, 14, 25]
	Time taken saving stuff: 0.02s

=== episode:573 Env-steps-taken:62400
 	picked: 52 |actions: {0: 291, 1: 310, 2: 553, 3: 317, 4: 541, 5: 457, 6: 301, 7: 333, 8: 485}
episode: 573/2000 -> reward: 72.52083333333336, steps:3588, time-taken: 1.95min, time-elasped: 1121.19min
-> berries picked: 52 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6633 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [680, 1021, 1044, 712, 623, 542, 686, 605, 720]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 10, 19, 14, 13, 21, 12, 13, 18]
	Time taken saving stuff: 0.03s

=== episode:574 Env-steps-taken:69120
 	picked: 78 |actions: {0: 526, 1: 620, 2: 654, 3: 442, 4: 637, 5: 545, 6: 362, 7: 424, 8: 477}
episode: 574/2000 -> reward: 106.0312499999999, steps:4687, time-taken: 2.18min, time-elasped: 1123.37min
-> berries picked: 78 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6638 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [684, 1024, 1051, 709, 629, 536, 683, 601, 721]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 15, 17, 9, 13, 18, 8, 5, 28]
	Time taken saving stuff: 0.08s

=== episode:575 Env-steps-taken:66432
 	picked: 71 |actions: {0: 480, 1: 683, 2: 613, 3: 533, 4: 740, 5: 585, 6: 433, 7: 436, 8: 481}
episode: 575/2000 -> reward: 92.43229166666659, steps:4984, time-taken: 2.35min, time-elasped: 1125.71min
-> berries picked: 71 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6644 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [680, 1022, 1049, 716, 632, 535, 686, 603, 721]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 16, 12, 7, 9, 10, 7, 13, 32]
	Time taken saving stuff: 0.03s

=== episode:576 Env-steps-taken:67008
 	picked: 72 |actions: {0: 440, 1: 447, 2: 554, 3: 444, 4: 597, 5: 401, 6: 492, 7: 478, 8: 404}
episode: 576/2000 -> reward: 95.37499999999993, steps:4257, time-taken: 2.15min, time-elasped: 1127.87min
-> berries picked: 72 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6653 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [676, 1023, 1052, 714, 631, 542, 687, 603, 725]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 11, 12, 13, 9, 10, 11, 11, 17]
	Time taken saving stuff: 0.05s

=== episode:577 Env-steps-taken:66144
 	picked: 72 |actions: {0: 483, 1: 756, 2: 775, 3: 573, 4: 733, 5: 489, 6: 484, 7: 499, 8: 581}
episode: 577/2000 -> reward: 90.37499999999996, steps:5373, time-taken: 2.58min, time-elasped: 1130.46min
-> berries picked: 72 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6641 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [679, 1016, 1046, 720, 632, 541, 685, 598, 724]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 13, 14, 13, 11, 8, 15, 5, 18]
	Time taken saving stuff: 0.01s

=== episode:578 Env-steps-taken:77952
 	picked: 111 |actions: {0: 788, 1: 641, 2: 822, 3: 533, 4: 645, 5: 603, 6: 603, 7: 586, 8: 537}
episode: 578/2000 -> reward: 148.25520833333337, steps:5758, time-taken: 2.73min, time-elasped: 1133.19min
-> berries picked: 111 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6651 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [678, 1016, 1040, 729, 635, 543, 686, 602, 722]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 14, 16, 12, 7, 16, 20, 15, 18]
	Time taken saving stuff: 0.01s

=== episode:579 Env-steps-taken:69216
 	picked: 94 |actions: {0: 630, 1: 621, 2: 855, 3: 692, 4: 802, 5: 494, 6: 513, 7: 513, 8: 587}
episode: 579/2000 -> reward: 104.17187499999993, steps:5707, time-taken: 2.86min, time-elasped: 1136.05min
-> berries picked: 94 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6638 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [670, 1015, 1043, 726, 638, 543, 684, 594, 725]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 17, 11, 18, 11, 8, 8, 8, 18]
	Time taken saving stuff: 0.02s

=== episode:580 Env-steps-taken:69984
 	picked: 84 |actions: {0: 516, 1: 574, 2: 686, 3: 474, 4: 733, 5: 609, 6: 599, 7: 510, 8: 406}
episode: 580/2000 -> reward: 107.35937499999987, steps:5107, time-taken: 2.56min, time-elasped: 1138.61min
-> berries picked: 84 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6647 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [672, 1015, 1048, 724, 641, 540, 683, 596, 728]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 17, 21, 9, 12, 20, 14, 9, 14]
	Time taken saving stuff: 0.13s

=== episode:58 Env-steps-taken:77760
 	picked: 118 |actions: {0: 464, 1: 808, 2: 157, 3: 719, 4: 1076, 5: 433, 6: 138, 7: 450, 8: 641}

==================================================
eval-episode: 580 -> reward: 147.85416666666663, steps: 4886.0, wall-time: 53.91s
-> berries picked: 118 of 800 | patches-visited: [1, 7] | juice left:-0.00
==================================================


=== episode:581 Env-steps-taken:67296
 	picked: 69 |actions: {0: 617, 1: 487, 2: 477, 3: 513, 4: 729, 5: 547, 6: 357, 7: 543, 8: 491}
episode: 581/2000 -> reward: 97.10416666666661, steps:4761, time-taken: 2.44min, time-elasped: 1141.96min
-> berries picked: 69 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6641 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [681, 1021, 1050, 720, 629, 538, 687, 586, 729]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 18, 13, 14, 12, 11, 13, 11, 15]
	Time taken saving stuff: 0.01s

=== episode:582 Env-steps-taken:75648
 	picked: 103 |actions: {0: 553, 1: 816, 2: 806, 3: 687, 4: 746, 5: 851, 6: 607, 7: 532, 8: 519}
episode: 582/2000 -> reward: 138.21354166666654, steps:6117, time-taken: 2.86min, time-elasped: 1144.82min
-> berries picked: 103 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6665 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [681, 1024, 1055, 716, 632, 552, 689, 584, 732]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 12, 13, 14, 12, 8, 12, 12, 22]
	Time taken saving stuff: 0.01s

=== episode:583 Env-steps-taken:69216
 	picked: 90 |actions: {0: 780, 1: 771, 2: 642, 3: 586, 4: 587, 5: 507, 6: 488, 7: 546, 8: 452}
episode: 583/2000 -> reward: 105.84374999999989, steps:5359, time-taken: 2.65min, time-elasped: 1147.47min
-> berries picked: 90 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6676 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [685, 1024, 1052, 720, 633, 550, 691, 587, 734]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 17, 14, 15, 16, 11, 10, 8, 18]
	Time taken saving stuff: 0.09s

=== episode:584 Env-steps-taken:75744
 	picked: 103 |actions: {0: 704, 1: 705, 2: 659, 3: 841, 4: 781, 5: 718, 6: 556, 7: 544, 8: 467}
episode: 584/2000 -> reward: 139.09895833333326, steps:5975, time-taken: 2.94min, time-elasped: 1150.41min
-> berries picked: 103 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6687 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [680, 1027, 1057, 723, 637, 546, 693, 587, 737]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 9, 16, 14, 9, 11, 11, 14, 19]
	Time taken saving stuff: 0.01s

=== episode:585 Env-steps-taken:66816
 	picked: 76 |actions: {0: 565, 1: 538, 2: 524, 3: 511, 4: 815, 5: 448, 6: 431, 7: 420, 8: 354}
episode: 585/2000 -> reward: 94.14583333333326, steps:4606, time-taken: 2.57min, time-elasped: 1152.98min
-> berries picked: 76 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6704 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [687, 1029, 1063, 724, 629, 547, 695, 589, 741]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 8, 21, 7, 17, 22, 14, 11, 22]
	Time taken saving stuff: 0.03s

=== episode:586 Env-steps-taken:72864
 	picked: 93 |actions: {0: 706, 1: 668, 2: 778, 3: 600, 4: 577, 5: 760, 6: 573, 7: 440, 8: 427}
episode: 586/2000 -> reward: 124.67187499999982, steps:5529, time-taken: 2.71min, time-elasped: 1155.69min
-> berries picked: 93 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6705 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [692, 1032, 1065, 726, 627, 545, 690, 585, 743]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 14, 10, 13, 12, 14, 9, 7, 15]
	Time taken saving stuff: 0.10s

=== episode:587 Env-steps-taken:69504
 	picked: 77 |actions: {0: 671, 1: 640, 2: 682, 3: 492, 4: 634, 5: 560, 6: 501, 7: 460, 8: 462}
episode: 587/2000 -> reward: 108.08854166666656, steps:5102, time-taken: 2.56min, time-elasped: 1158.26min
-> berries picked: 77 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6718 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [690, 1036, 1062, 725, 631, 545, 692, 591, 746]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 22, 18, 16, 7, 5, 10, 13, 26]
	Time taken saving stuff: 0.01s

=== episode:588 Env-steps-taken:67296
 	picked: 76 |actions: {0: 489, 1: 546, 2: 551, 3: 416, 4: 545, 5: 579, 6: 369, 7: 453, 8: 453}
episode: 588/2000 -> reward: 95.26041666666657, steps:4401, time-taken: 2.16min, time-elasped: 1160.42min
-> berries picked: 76 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6729 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [689, 1042, 1063, 725, 627, 547, 693, 595, 748]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 17, 25, 14, 6, 6, 18, 9, 17]
	Time taken saving stuff: 0.01s

=== episode:589 Env-steps-taken:75168
 	picked: 98 |actions: {0: 631, 1: 601, 2: 598, 3: 664, 4: 786, 5: 750, 6: 499, 7: 469, 8: 469}
episode: 589/2000 -> reward: 136.38541666666654, steps:5467, time-taken: 2.69min, time-elasped: 1163.11min
-> berries picked: 98 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6746 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [686, 1044, 1068, 739, 630, 549, 690, 589, 751]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 16, 14, 7, 16, 8, 11, 10, 20]
	Time taken saving stuff: 0.01s

=== episode:590 Env-steps-taken:70752
 	picked: 84 |actions: {0: 692, 1: 678, 2: 825, 3: 603, 4: 608, 5: 728, 6: 584, 7: 568, 8: 525}
episode: 590/2000 -> reward: 114.18749999999986, steps:5811, time-taken: 2.65min, time-elasped: 1165.77min
-> berries picked: 84 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6758 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [694, 1045, 1072, 741, 624, 549, 689, 593, 751]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 19, 13, 8, 14, 11, 11, 11, 11]
	Time taken saving stuff: 0.05s

=== episode:59 Env-steps-taken:79104
 	picked: 126 |actions: {0: 897, 1: 1466, 2: 326, 3: 228, 4: 513, 5: 1437, 6: 386, 7: 176, 8: 393}

==================================================
eval-episode: 590 -> reward: 155.28124999999994, steps: 5822.0, wall-time: 60.10s
-> berries picked: 126 of 800 | patches-visited: [1, 2] | juice left:-0.00
==================================================


=== episode:591 Env-steps-taken:68160
 	picked: 79 |actions: {0: 783, 1: 699, 2: 622, 3: 632, 4: 542, 5: 585, 6: 460, 7: 474, 8: 464}
episode: 591/2000 -> reward: 100.97395833333323, steps:5261, time-taken: 2.54min, time-elasped: 1169.31min
-> berries picked: 79 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6751 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [701, 1051, 1069, 741, 622, 543, 685, 587, 752]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 11, 23, 13, 8, 9, 9, 10, 18]
	Time taken saving stuff: 0.09s

=== episode:592 Env-steps-taken:66432
 	picked: 76 |actions: {0: 542, 1: 582, 2: 586, 3: 754, 4: 709, 5: 678, 6: 571, 7: 463, 8: 622}
episode: 592/2000 -> reward: 91.64583333333329, steps:5507, time-taken: 2.79min, time-elasped: 1172.11min
-> berries picked: 76 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6742 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [699, 1051, 1069, 738, 618, 543, 684, 589, 751]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 14, 19, 12, 19, 10, 8, 9, 22]
	Time taken saving stuff: 0.01s

=== episode:593 Env-steps-taken:65760
 	picked: 63 |actions: {0: 509, 1: 481, 2: 587, 3: 526, 4: 518, 5: 539, 6: 420, 7: 363, 8: 348}
episode: 593/2000 -> reward: 89.39062499999996, steps:4291, time-taken: 2.21min, time-elasped: 1174.33min
-> berries picked: 63 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6749 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [696, 1050, 1076, 739, 622, 545, 682, 589, 750]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 11, 20, 9, 16, 12, 10, 11, 25]
	Time taken saving stuff: 0.01s

=== episode:594 Env-steps-taken:69216
 	picked: 80 |actions: {0: 632, 1: 684, 2: 623, 3: 448, 4: 563, 5: 739, 6: 563, 7: 586, 8: 378}
episode: 594/2000 -> reward: 106.41666666666656, steps:5216, time-taken: 2.63min, time-elasped: 1176.96min
-> berries picked: 80 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6758 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [705, 1054, 1079, 741, 620, 545, 681, 583, 750]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 18, 16, 14, 13, 11, 11, 14, 14]
	Time taken saving stuff: 0.01s

=== episode:595 Env-steps-taken:71904
 	picked: 89 |actions: {0: 580, 1: 549, 2: 600, 3: 567, 4: 646, 5: 780, 6: 546, 7: 491, 8: 581}
episode: 595/2000 -> reward: 119.90104166666652, steps:5340, time-taken: 2.67min, time-elasped: 1179.64min
-> berries picked: 89 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6766 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [708, 1055, 1081, 739, 623, 547, 676, 583, 754]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 14, 22, 12, 9, 9, 11, 8, 15]
	Time taken saving stuff: 0.09s

=== episode:596 Env-steps-taken:73536
 	picked: 99 |actions: {0: 704, 1: 614, 2: 712, 3: 584, 4: 754, 5: 604, 6: 636, 7: 558, 8: 456}
episode: 596/2000 -> reward: 127.82812499999982, steps:5622, time-taken: 2.77min, time-elasped: 1182.42min
-> berries picked: 99 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6771 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [718, 1061, 1082, 740, 624, 543, 669, 579, 755]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 24, 11, 15, 8, 14, 12, 6, 16]
	Time taken saving stuff: 0.01s

=== episode:597 Env-steps-taken:75936
 	picked: 107 |actions: {0: 704, 1: 672, 2: 659, 3: 667, 4: 797, 5: 867, 6: 590, 7: 664, 8: 497}
episode: 597/2000 -> reward: 139.86979166666657, steps:6117, time-taken: 2.89min, time-elasped: 1185.31min
-> berries picked: 107 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6796 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [720, 1065, 1081, 745, 630, 547, 670, 581, 757]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 22, 13, 15, 8, 11, 10, 12, 16]
	Time taken saving stuff: 0.00s

=== episode:598 Env-steps-taken:64032
 	picked: 66 |actions: {0: 489, 1: 424, 2: 515, 3: 534, 4: 665, 5: 719, 6: 425, 7: 472, 8: 441}
episode: 598/2000 -> reward: 79.71874999999997, steps:4684, time-taken: 2.21min, time-elasped: 1187.52min
-> berries picked: 66 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6782 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [719, 1065, 1082, 739, 627, 546, 669, 578, 757]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 20, 14, 7, 9, 7, 12, 12, 14]
	Time taken saving stuff: 0.01s

=== episode:599 Env-steps-taken:71328
 	picked: 91 |actions: {0: 650, 1: 731, 2: 751, 3: 467, 4: 536, 5: 574, 6: 480, 7: 518, 8: 332}
episode: 599/2000 -> reward: 113.95833333333319, steps:5039, time-taken: 2.39min, time-elasped: 1189.91min
-> berries picked: 91 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6788 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [724, 1067, 1085, 738, 624, 541, 676, 577, 756]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 11, 20, 17, 8, 14, 10, 11, 19]
	Time taken saving stuff: 0.02s

=== episode:600 Env-steps-taken:72480
 	picked: 99 |actions: {0: 615, 1: 660, 2: 722, 3: 731, 4: 591, 5: 635, 6: 512, 7: 524, 8: 482}
episode: 600/2000 -> reward: 122.82812499999982, steps:5472, time-taken: 2.67min, time-elasped: 1192.58min
-> berries picked: 99 of 800 | patches-visited: [0, 3, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6806 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [724, 1067, 1093, 740, 628, 548, 671, 578, 757]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 18, 17, 10, 9, 8, 12, 9, 17]
	Time taken saving stuff: 0.16s

=== episode:60 Env-steps-taken:91008
 	picked: 163 |actions: {0: 599, 1: 749, 2: 609, 3: 1443, 4: 1955, 5: 810, 6: 938, 7: 110, 8: 170}

==================================================
eval-episode: 600 -> reward: 213.77604166666708, steps: 7383.0, wall-time: 63.97s
-> berries picked: 163 of 800 | patches-visited: [0, 1, 8] | juice left:-0.00
==================================================


=== episode:601 Env-steps-taken:72960
 	picked: 97 |actions: {0: 668, 1: 715, 2: 846, 3: 556, 4: 869, 5: 692, 6: 634, 7: 604, 8: 507}
episode: 601/2000 -> reward: 124.94270833333316, steps:6091, time-taken: 2.87min, time-elasped: 1196.53min
-> berries picked: 97 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6804 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [724, 1066, 1092, 741, 637, 543, 670, 578, 753]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 21, 21, 10, 13, 7, 9, 10, 10]
	Time taken saving stuff: 0.01s

=== episode:602 Env-steps-taken:72672
 	picked: 92 |actions: {0: 492, 1: 669, 2: 693, 3: 541, 4: 562, 5: 583, 6: 523, 7: 573, 8: 382}
episode: 602/2000 -> reward: 121.45833333333319, steps:5018, time-taken: 2.43min, time-elasped: 1198.96min
-> berries picked: 92 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6826 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [722, 1074, 1096, 743, 638, 546, 671, 582, 754]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 16, 17, 13, 14, 7, 14, 6, 12]
	Time taken saving stuff: 0.10s

=== episode:603 Env-steps-taken:70944
 	picked: 85 |actions: {0: 507, 1: 627, 2: 714, 3: 627, 4: 986, 5: 714, 6: 496, 7: 531, 8: 703}
episode: 603/2000 -> reward: 115.13020833333321, steps:5905, time-taken: 2.89min, time-elasped: 1201.86min
-> berries picked: 85 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6830 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [717, 1084, 1099, 745, 641, 546, 663, 581, 754]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 20, 13, 16, 9, 8, 13, 11, 20]
	Time taken saving stuff: 0.10s

=== episode:604 Env-steps-taken:67968
 	picked: 75 |actions: {0: 539, 1: 454, 2: 515, 3: 513, 4: 512, 5: 456, 6: 536, 7: 432, 8: 349}
episode: 604/2000 -> reward: 99.81770833333326, steps:4306, time-taken: 2.43min, time-elasped: 1204.29min
-> berries picked: 75 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6832 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [722, 1090, 1099, 745, 637, 543, 665, 576, 755]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 21, 15, 20, 7, 11, 12, 7, 20]
	Time taken saving stuff: 0.08s

=== episode:605 Env-steps-taken:71712
 	picked: 85 |actions: {0: 652, 1: 493, 2: 565, 3: 432, 4: 802, 5: 524, 6: 533, 7: 508, 8: 409}
episode: 605/2000 -> reward: 118.24479166666656, steps:4918, time-taken: 2.45min, time-elasped: 1206.74min
-> berries picked: 85 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6830 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [723, 1090, 1104, 744, 633, 544, 663, 575, 754]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 16, 18, 14, 13, 10, 15, 12, 27]
	Time taken saving stuff: 0.09s

=== episode:606 Env-steps-taken:76704
 	picked: 110 |actions: {0: 731, 1: 685, 2: 670, 3: 833, 4: 814, 5: 799, 6: 602, 7: 660, 8: 508}
episode: 606/2000 -> reward: 143.2552083333333, steps:6302, time-taken: 3.24min, time-elasped: 1209.98min
-> berries picked: 110 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6822 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [713, 1085, 1107, 751, 644, 544, 658, 570, 750]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 21, 18, 19, 10, 9, 9, 8, 20]
	Time taken saving stuff: 0.01s

=== episode:607 Env-steps-taken:77280
 	picked: 106 |actions: {0: 629, 1: 681, 2: 809, 3: 598, 4: 529, 5: 834, 6: 611, 7: 602, 8: 571}
episode: 607/2000 -> reward: 145.54166666666663, steps:5864, time-taken: 2.81min, time-elasped: 1212.79min
-> berries picked: 106 of 800 | patches-visited: [0, 7, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6817 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [702, 1084, 1115, 748, 641, 550, 657, 572, 748]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 15, 24, 11, 16, 5, 21, 7, 20]
	Time taken saving stuff: 0.01s

=== episode:608 Env-steps-taken:67584
 	picked: 78 |actions: {0: 518, 1: 515, 2: 608, 3: 669, 4: 442, 5: 410, 6: 383, 7: 501, 8: 447}
episode: 608/2000 -> reward: 96.58854166666659, steps:4493, time-taken: 2.20min, time-elasped: 1215.00min
-> berries picked: 78 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6791 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [699, 1086, 1113, 750, 636, 549, 642, 571, 745]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 17, 16, 12, 7, 9, 16, 5, 16]
	Time taken saving stuff: 0.01s

=== episode:609 Env-steps-taken:67968
 	picked: 88 |actions: {0: 508, 1: 751, 2: 787, 3: 611, 4: 681, 5: 521, 6: 508, 7: 571, 8: 563}
episode: 609/2000 -> reward: 99.45833333333323, steps:5501, time-taken: 2.67min, time-elasped: 1217.67min
-> berries picked: 88 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6806 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [706, 1086, 1118, 747, 633, 554, 645, 574, 743]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 23, 16, 14, 12, 15, 6, 10, 16]
	Time taken saving stuff: 0.09s

=== episode:610 Env-steps-taken:69984
 	picked: 82 |actions: {0: 645, 1: 595, 2: 509, 3: 468, 4: 560, 5: 593, 6: 446, 7: 513, 8: 514}
episode: 610/2000 -> reward: 110.30208333333324, steps:4843, time-taken: 2.28min, time-elasped: 1219.95min
-> berries picked: 82 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6811 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [713, 1082, 1118, 749, 628, 554, 646, 578, 743]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 17, 20, 8, 14, 6, 8, 13, 23]
	Time taken saving stuff: 0.05s

=== episode:61 Env-steps-taken:82752
 	picked: 137 |actions: {0: 351, 1: 624, 2: 567, 3: 755, 4: 553, 5: 1079, 6: 175, 7: 887, 8: 438}

==================================================
eval-episode: 610 -> reward: 173.65104166666688, steps: 5429.0, wall-time: 55.15s
-> berries picked: 137 of 800 | patches-visited: [0, 1] | juice left:-0.00
==================================================


=== episode:611 Env-steps-taken:64512
 	picked: 62 |actions: {0: 362, 1: 361, 2: 442, 3: 342, 4: 313, 5: 419, 6: 345, 7: 270, 8: 400}
episode: 611/2000 -> reward: 82.94791666666664, steps:3254, time-taken: 1.88min, time-elasped: 1222.76min
-> berries picked: 62 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6769 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [703, 1069, 1115, 747, 626, 553, 648, 564, 744]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 13, 16, 12, 10, 5, 18, 17, 25]
	Time taken saving stuff: 0.09s

=== episode:612 Env-steps-taken:76416
 	picked: 101 |actions: {0: 581, 1: 768, 2: 594, 3: 721, 4: 585, 5: 671, 6: 717, 7: 844, 8: 566}
episode: 612/2000 -> reward: 142.71354166666663, steps:6047, time-taken: 2.90min, time-elasped: 1225.67min
-> berries picked: 101 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6730 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [692, 1054, 1110, 748, 618, 553, 642, 568, 745]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 17, 14, 17, 9, 12, 8, 14, 21]
	Time taken saving stuff: 0.01s

=== episode:613 Env-steps-taken:72576
 	picked: 91 |actions: {0: 606, 1: 694, 2: 634, 3: 732, 4: 555, 5: 536, 6: 509, 7: 698, 8: 534}
episode: 613/2000 -> reward: 123.28645833333317, steps:5498, time-taken: 2.77min, time-elasped: 1228.45min
-> berries picked: 91 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6731 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [686, 1055, 1117, 748, 625, 546, 639, 572, 743]
	| approx positives in sample 512: 94
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 18, 13, 14, 5, 10, 6, 11, 13]
	Time taken saving stuff: 0.00s

=== episode:614 Env-steps-taken:75072
 	picked: 105 |actions: {0: 707, 1: 719, 2: 778, 3: 625, 4: 737, 5: 741, 6: 575, 7: 555, 8: 577}
episode: 614/2000 -> reward: 134.59895833333323, steps:6014, time-taken: 2.97min, time-elasped: 1231.42min
-> berries picked: 105 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6730 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [684, 1046, 1113, 756, 631, 543, 645, 570, 742]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 14, 18, 9, 16, 13, 11, 11, 18]
	Time taken saving stuff: 0.02s

=== episode:615 Env-steps-taken:63360
 	picked: 61 |actions: {0: 493, 1: 452, 2: 535, 3: 435, 4: 387, 5: 565, 6: 391, 7: 365, 8: 552}
episode: 615/2000 -> reward: 76.50520833333334, steps:4175, time-taken: 2.09min, time-elasped: 1233.51min
-> berries picked: 61 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6708 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [683, 1040, 1112, 751, 630, 542, 642, 566, 742]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 14, 18, 10, 5, 11, 8, 16, 23]
	Time taken saving stuff: 0.00s

=== episode:616 Env-steps-taken:59904
 	picked: 50 |actions: {0: 407, 1: 531, 2: 410, 3: 649, 4: 961, 5: 792, 6: 386, 7: 492, 8: 746}
episode: 616/2000 -> reward: 57.75000000000006, steps:5374, time-taken: 2.52min, time-elasped: 1236.03min
-> berries picked: 50 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6663 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [672, 1034, 1094, 748, 638, 545, 636, 554, 742]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 17, 17, 15, 7, 12, 13, 7, 17]
	Time taken saving stuff: 0.10s

=== episode:617 Env-steps-taken:69984
 	picked: 81 |actions: {0: 488, 1: 585, 2: 549, 3: 689, 4: 690, 5: 710, 6: 504, 7: 637, 8: 497}
episode: 617/2000 -> reward: 108.41666666666656, steps:5349, time-taken: 2.72min, time-elasped: 1238.76min
-> berries picked: 81 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6638 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [667, 1025, 1080, 746, 636, 549, 641, 553, 741]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 21, 14, 8, 9, 10, 9, 9, 13]
	Time taken saving stuff: 0.09s

=== episode:618 Env-steps-taken:64224
 	picked: 55 |actions: {0: 437, 1: 433, 2: 576, 3: 724, 4: 695, 5: 532, 6: 412, 7: 562, 8: 779}
episode: 618/2000 -> reward: 81.84895833333331, steps:5150, time-taken: 2.48min, time-elasped: 1241.24min
-> berries picked: 55 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6614 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [665, 1016, 1071, 747, 631, 550, 638, 557, 739]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 16, 18, 9, 12, 9, 13, 17, 13]
	Time taken saving stuff: 0.02s

=== episode:619 Env-steps-taken:63648
 	picked: 62 |actions: {0: 333, 1: 381, 2: 342, 3: 391, 4: 446, 5: 415, 6: 336, 7: 417, 8: 492}
episode: 619/2000 -> reward: 78.06250000000001, steps:3553, time-taken: 1.95min, time-elasped: 1243.19min
-> berries picked: 62 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6630 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [671, 1014, 1070, 748, 632, 557, 641, 559, 738]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 17, 12, 9, 7, 16, 7, 6, 22]
	Time taken saving stuff: 0.02s

=== episode:620 Env-steps-taken:64800
 	picked: 58 |actions: {0: 355, 1: 329, 2: 407, 3: 338, 4: 317, 5: 356, 6: 297, 7: 392, 8: 313}
episode: 620/2000 -> reward: 84.6770833333333, steps:3104, time-taken: 1.60min, time-elasped: 1244.79min
-> berries picked: 58 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6638 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [675, 1014, 1069, 752, 635, 553, 643, 559, 738]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 14, 11, 7, 11, 10, 9, 11, 16]
	Time taken saving stuff: 0.14s

=== episode:62 Env-steps-taken:71328
 	picked: 88 |actions: {0: 291, 1: 382, 2: 234, 3: 595, 4: 375, 5: 275, 6: 173, 7: 747, 8: 198}

==================================================
eval-episode: 620 -> reward: 116.0729166666665, steps: 3270.0, wall-time: 45.72s
-> berries picked: 88 of 800 | patches-visited: [0, 1] | juice left:-0.00
==================================================


=== episode:621 Env-steps-taken:73824
 	picked: 94 |actions: {0: 637, 1: 637, 2: 594, 3: 627, 4: 614, 5: 646, 6: 474, 7: 802, 8: 466}
episode: 621/2000 -> reward: 129.61458333333314, steps:5497, time-taken: 2.70min, time-elasped: 1248.26min
-> berries picked: 94 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6662 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [678, 1014, 1071, 759, 638, 554, 644, 566, 738]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 12, 19, 9, 10, 11, 15, 12, 13]
	Time taken saving stuff: 0.02s

=== episode:622 Env-steps-taken:67296
 	picked: 70 |actions: {0: 592, 1: 601, 2: 544, 3: 529, 4: 601, 5: 478, 6: 441, 7: 538, 8: 554}
episode: 622/2000 -> reward: 96.98958333333327, steps:4878, time-taken: 2.38min, time-elasped: 1250.64min
-> berries picked: 70 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6671 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [676, 1015, 1073, 762, 636, 557, 647, 567, 738]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 21, 17, 11, 9, 3, 14, 11, 11]
	Time taken saving stuff: 0.02s

=== episode:623 Env-steps-taken:77760
 	picked: 112 |actions: {0: 626, 1: 611, 2: 780, 3: 752, 4: 818, 5: 772, 6: 514, 7: 590, 8: 432}
episode: 623/2000 -> reward: 147.640625, steps:5895, time-taken: 2.83min, time-elasped: 1253.48min
-> berries picked: 112 of 800 | patches-visited: [0, 3, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6685 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [671, 1017, 1077, 762, 636, 563, 644, 576, 739]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 21, 16, 17, 6, 12, 11, 5, 18]
	Time taken saving stuff: 0.08s

=== episode:624 Env-steps-taken:72768
 	picked: 95 |actions: {0: 522, 1: 653, 2: 565, 3: 530, 4: 682, 5: 683, 6: 431, 7: 528, 8: 681}
episode: 624/2000 -> reward: 124.0572916666665, steps:5275, time-taken: 2.57min, time-elasped: 1256.06min
-> berries picked: 95 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6696 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [671, 1023, 1074, 761, 641, 564, 647, 576, 739]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 14, 15, 13, 10, 13, 6, 5, 19]
	Time taken saving stuff: 0.01s

=== episode:625 Env-steps-taken:75456
 	picked: 102 |actions: {0: 624, 1: 684, 2: 605, 3: 644, 4: 644, 5: 721, 6: 556, 7: 606, 8: 555}
episode: 625/2000 -> reward: 136.77083333333326, steps:5639, time-taken: 2.57min, time-elasped: 1258.63min
-> berries picked: 102 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6723 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [684, 1025, 1079, 759, 642, 565, 650, 576, 743]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 15, 16, 16, 10, 9, 9, 7, 14]
	Time taken saving stuff: 0.08s

=== episode:626 Env-steps-taken:76896
 	picked: 100 |actions: {0: 682, 1: 859, 2: 718, 3: 792, 4: 729, 5: 756, 6: 571, 7: 631, 8: 618}
episode: 626/2000 -> reward: 145.77083333333331, steps:6356, time-taken: 3.02min, time-elasped: 1261.65min
-> berries picked: 100 of 800 | patches-visited: [0, 2, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6709 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [673, 1023, 1086, 760, 644, 558, 648, 575, 742]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 24, 15, 13, 9, 9, 12, 6, 21]
	Time taken saving stuff: 0.01s

=== episode:627 Env-steps-taken:69600
 	picked: 88 |actions: {0: 587, 1: 569, 2: 803, 3: 650, 4: 476, 5: 415, 6: 440, 7: 555, 8: 439}
episode: 627/2000 -> reward: 107.9583333333332, steps:4934, time-taken: 2.46min, time-elasped: 1264.12min
-> berries picked: 88 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6716 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [673, 1021, 1091, 758, 645, 562, 647, 579, 740]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 12, 18, 18, 10, 12, 14, 11, 18]
	Time taken saving stuff: 0.01s

=== episode:628 Env-steps-taken:74400
 	picked: 94 |actions: {0: 564, 1: 644, 2: 704, 3: 693, 4: 649, 5: 565, 6: 524, 7: 513, 8: 407}
episode: 628/2000 -> reward: 132.6145833333332, steps:5263, time-taken: 2.61min, time-elasped: 1266.73min
-> berries picked: 94 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6726 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [668, 1023, 1094, 759, 644, 566, 653, 577, 742]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 17, 15, 18, 13, 5, 10, 13, 20]
	Time taken saving stuff: 0.02s

=== episode:629 Env-steps-taken:66816
 	picked: 70 |actions: {0: 514, 1: 528, 2: 574, 3: 421, 4: 560, 5: 577, 6: 347, 7: 501, 8: 311}
episode: 629/2000 -> reward: 92.21874999999996, steps:4333, time-taken: 2.45min, time-elasped: 1269.19min
-> berries picked: 70 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6727 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [661, 1026, 1094, 759, 645, 570, 653, 576, 743]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 22, 12, 13, 14, 6, 13, 17, 13]
	Time taken saving stuff: 0.08s

=== episode:630 Env-steps-taken:69120
 	picked: 77 |actions: {0: 606, 1: 529, 2: 509, 3: 634, 4: 577, 5: 581, 6: 494, 7: 529, 8: 500}
episode: 630/2000 -> reward: 104.14583333333324, steps:4959, time-taken: 2.13min, time-elasped: 1271.32min
-> berries picked: 77 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6735 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [661, 1028, 1090, 770, 649, 567, 648, 579, 743]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 13, 14, 17, 10, 11, 14, 5, 22]
	Time taken saving stuff: 0.05s

=== episode:63 Env-steps-taken:80352
 	picked: 120 |actions: {0: 309, 1: 380, 2: 868, 3: 837, 4: 188, 5: 1047, 6: 64, 7: 526, 8: 103}

==================================================
eval-episode: 630 -> reward: 162.6250000000002, steps: 4322.0, wall-time: 38.63s
-> berries picked: 120 of 800 | patches-visited: [1, 6, 8] | juice left:-0.00
==================================================


=== episode:631 Env-steps-taken:66336
 	picked: 72 |actions: {0: 529, 1: 594, 2: 652, 3: 715, 4: 944, 5: 887, 6: 395, 7: 660, 8: 480}
episode: 631/2000 -> reward: 91.37499999999994, steps:5856, time-taken: 2.02min, time-elasped: 1273.99min
-> berries picked: 72 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6716 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [649, 1026, 1088, 781, 648, 567, 644, 571, 742]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 23, 17, 16, 11, 9, 12, 7, 18]
	Time taken saving stuff: 0.00s

=== episode:632 Env-steps-taken:74784
 	picked: 101 |actions: {0: 604, 1: 616, 2: 815, 3: 497, 4: 615, 5: 602, 6: 555, 7: 536, 8: 448}
episode: 632/2000 -> reward: 134.21354166666657, steps:5288, time-taken: 1.82min, time-elasped: 1275.82min
-> berries picked: 101 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6745 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [658, 1023, 1098, 783, 650, 574, 647, 571, 741]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 19, 15, 19, 13, 10, 9, 13, 20]
	Time taken saving stuff: 0.02s

=== episode:633 Env-steps-taken:62016
 	picked: 51 |actions: {0: 393, 1: 410, 2: 519, 3: 386, 4: 386, 5: 414, 6: 327, 7: 423, 8: 380}
episode: 633/2000 -> reward: 70.078125, steps:3638, time-taken: 1.29min, time-elasped: 1277.11min
-> berries picked: 51 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6742 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [656, 1020, 1095, 785, 650, 574, 649, 572, 741]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 22, 19, 9, 5, 11, 16, 10, 13]
	Time taken saving stuff: 0.00s

=== episode:634 Env-steps-taken:68448
 	picked: 71 |actions: {0: 500, 1: 524, 2: 596, 3: 515, 4: 645, 5: 480, 6: 381, 7: 346, 8: 273}
episode: 634/2000 -> reward: 102.93229166666657, steps:4260, time-taken: 1.77min, time-elasped: 1278.88min
-> berries picked: 71 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6754 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [656, 1029, 1097, 787, 651, 573, 647, 571, 743]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 15, 14, 14, 7, 8, 13, 11, 24]
	Time taken saving stuff: 0.07s

=== episode:635 Env-steps-taken:69120
 	picked: 79 |actions: {0: 410, 1: 759, 2: 574, 3: 535, 4: 584, 5: 525, 6: 450, 7: 730, 8: 576}
episode: 635/2000 -> reward: 105.64583333333326, steps:5143, time-taken: 1.87min, time-elasped: 1280.75min
-> berries picked: 79 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6771 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [651, 1030, 1098, 795, 657, 572, 653, 572, 743]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 19, 16, 16, 11, 12, 8, 11, 14]
	Time taken saving stuff: 0.00s

=== episode:636 Env-steps-taken:65088
 	picked: 72 |actions: {0: 590, 1: 456, 2: 476, 3: 843, 4: 723, 5: 679, 6: 412, 7: 507, 8: 504}
episode: 636/2000 -> reward: 84.87499999999997, steps:5190, time-taken: 1.82min, time-elasped: 1282.57min
-> berries picked: 72 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6755 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [642, 1026, 1100, 796, 664, 574, 648, 563, 742]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 19, 16, 10, 10, 8, 16, 14, 17]
	Time taken saving stuff: 0.01s

=== episode:637 Env-steps-taken:61824
 	picked: 50 |actions: {0: 392, 1: 370, 2: 423, 3: 331, 4: 470, 5: 697, 6: 294, 7: 336, 8: 357}
episode: 637/2000 -> reward: 69.1354166666667, steps:3670, time-taken: 1.42min, time-elasped: 1283.99min
-> berries picked: 50 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6760 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [645, 1023, 1100, 797, 660, 577, 651, 564, 743]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 20, 16, 13, 16, 13, 8, 10, 19]
	Time taken saving stuff: 0.00s

=== episode:638 Env-steps-taken:64512
 	picked: 60 |actions: {0: 302, 1: 322, 2: 315, 3: 336, 4: 403, 5: 412, 6: 253, 7: 286, 8: 214}
episode: 638/2000 -> reward: 81.67708333333331, steps:2843, time-taken: 1.18min, time-elasped: 1285.18min
-> berries picked: 60 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6780 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [646, 1025, 1108, 802, 656, 584, 647, 565, 747]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 18, 19, 8, 6, 10, 11, 13, 22]
	Time taken saving stuff: 0.08s

=== episode:639 Env-steps-taken:70944
 	picked: 80 |actions: {0: 524, 1: 476, 2: 545, 3: 503, 4: 676, 5: 483, 6: 415, 7: 479, 8: 350}
episode: 639/2000 -> reward: 115.41666666666656, steps:4451, time-taken: 1.58min, time-elasped: 1286.76min
-> berries picked: 80 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6794 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [648, 1029, 1114, 796, 653, 587, 651, 565, 751]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 18, 16, 12, 10, 16, 11, 11, 23]
	Time taken saving stuff: 0.00s

=== episode:640 Env-steps-taken:68928
 	picked: 73 |actions: {0: 500, 1: 539, 2: 599, 3: 537, 4: 588, 5: 403, 6: 351, 7: 511, 8: 431}
episode: 640/2000 -> reward: 105.31770833333326, steps:4459, time-taken: 1.75min, time-elasped: 1288.52min
-> berries picked: 73 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6805 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [648, 1030, 1114, 803, 653, 592, 651, 563, 751]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 23, 13, 14, 14, 15, 9, 10, 24]
	Time taken saving stuff: 0.06s

=== episode:64 Env-steps-taken:94656
 	picked: 178 |actions: {0: 692, 1: 478, 2: 2367, 3: 788, 4: 665, 5: 774, 6: 237, 7: 561, 8: 445}

==================================================
eval-episode: 640 -> reward: 229.5885416666673, steps: 7007.0, wall-time: 48.25s
-> berries picked: 178 of 800 | patches-visited: [0, 1, 6] | juice left:-0.00
==================================================


=== episode:641 Env-steps-taken:70080
 	picked: 78 |actions: {0: 519, 1: 661, 2: 702, 3: 514, 4: 588, 5: 545, 6: 367, 7: 466, 8: 297}
episode: 641/2000 -> reward: 111.0312499999999, steps:4659, time-taken: 1.75min, time-elasped: 1291.07min
-> berries picked: 78 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6805 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [644, 1035, 1122, 802, 648, 591, 653, 561, 749]
	| approx positives in sample 512: 100
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 15, 9, 8, 13, 12, 9, 9, 18]
	Time taken saving stuff: 0.09s

=== episode:642 Env-steps-taken:80352
 	picked: 115 |actions: {0: 699, 1: 937, 2: 672, 3: 653, 4: 752, 5: 889, 6: 602, 7: 725, 8: 472}
episode: 642/2000 -> reward: 160.08333333333337, steps:6401, time-taken: 2.31min, time-elasped: 1293.38min
-> berries picked: 115 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6839 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [646, 1036, 1125, 810, 650, 594, 668, 561, 749]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 14, 19, 20, 12, 13, 13, 5, 18]
	Time taken saving stuff: 0.11s

=== episode:643 Env-steps-taken:59040
 	picked: 36 |actions: {0: 367, 1: 236, 2: 181, 3: 160, 4: 110, 5: 108, 6: 139, 7: 127, 8: 164}
episode: 643/2000 -> reward: 55.937500000000036, steps:1592, time-taken: 0.81min, time-elasped: 1294.20min
-> berries picked: 36 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6847 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [646, 1038, 1128, 813, 649, 595, 668, 560, 750]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 16, 18, 13, 7, 14, 12, 12, 21]
	Time taken saving stuff: 0.04s

=== episode:644 Env-steps-taken:73344
 	picked: 88 |actions: {0: 606, 1: 682, 2: 663, 3: 681, 4: 824, 5: 626, 6: 570, 7: 750, 8: 385}
episode: 644/2000 -> reward: 127.45833333333319, steps:5787, time-taken: 2.02min, time-elasped: 1296.22min
-> berries picked: 88 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6849 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [646, 1040, 1128, 806, 654, 594, 670, 560, 751]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 20, 19, 14, 14, 6, 8, 11, 21]
	Time taken saving stuff: 0.02s

=== episode:645 Env-steps-taken:65184
 	picked: 75 |actions: {0: 431, 1: 699, 2: 614, 3: 485, 4: 530, 5: 541, 6: 415, 7: 449, 8: 384}
episode: 645/2000 -> reward: 85.20312499999994, steps:4548, time-taken: 1.62min, time-elasped: 1297.84min
-> berries picked: 75 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6868 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [644, 1037, 1137, 811, 654, 596, 672, 567, 750]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 13, 19, 18, 20, 9, 11, 10, 12]
	Time taken saving stuff: 0.10s

=== episode:646 Env-steps-taken:75072
 	picked: 98 |actions: {0: 626, 1: 601, 2: 629, 3: 592, 4: 696, 5: 648, 6: 613, 7: 582, 8: 435}
episode: 646/2000 -> reward: 135.88541666666657, steps:5422, time-taken: 1.91min, time-elasped: 1299.75min
-> berries picked: 98 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6883 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [651, 1042, 1137, 806, 651, 600, 678, 565, 753]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 13, 16, 9, 15, 10, 8, 17, 19]
	Time taken saving stuff: 0.10s

=== episode:647 Env-steps-taken:65280
 	picked: 60 |actions: {0: 418, 1: 572, 2: 574, 3: 611, 4: 580, 5: 458, 6: 423, 7: 470, 8: 420}
episode: 647/2000 -> reward: 86.56249999999999, steps:4526, time-taken: 1.56min, time-elasped: 1301.32min
-> berries picked: 60 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6869 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [651, 1048, 1129, 798, 648, 600, 680, 564, 751]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 14, 14, 8, 10, 10, 21, 10, 22]
	Time taken saving stuff: 0.09s

=== episode:648 Env-steps-taken:60576
 	picked: 48 |actions: {0: 336, 1: 465, 2: 347, 3: 349, 4: 307, 5: 261, 6: 294, 7: 227, 8: 234}
episode: 648/2000 -> reward: 63.25000000000006, steps:2820, time-taken: 1.19min, time-elasped: 1302.51min
-> berries picked: 48 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6884 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [656, 1050, 1130, 800, 647, 602, 684, 565, 750]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 18, 13, 21, 11, 6, 14, 9, 22]
	Time taken saving stuff: 0.01s

=== episode:649 Env-steps-taken:61056
 	picked: 51 |actions: {0: 564, 1: 905, 2: 610, 3: 534, 4: 691, 5: 559, 6: 437, 7: 461, 8: 471}
episode: 649/2000 -> reward: 65.07812500000003, steps:5232, time-taken: 1.84min, time-elasped: 1304.36min
-> berries picked: 51 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6874 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [657, 1047, 1127, 795, 644, 600, 684, 569, 751]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 13, 12, 14, 3, 10, 9, 8, 24]
	Time taken saving stuff: 0.10s

=== episode:650 Env-steps-taken:65568
 	picked: 70 |actions: {0: 535, 1: 1048, 2: 708, 3: 659, 4: 582, 5: 719, 6: 421, 7: 495, 8: 552}
episode: 650/2000 -> reward: 87.04687499999994, steps:5719, time-taken: 1.92min, time-elasped: 1306.29min
-> berries picked: 70 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6888 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [657, 1047, 1126, 801, 653, 601, 685, 568, 750]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 12, 15, 20, 8, 16, 19, 13, 17]
	Time taken saving stuff: 0.07s

=== episode:65 Env-steps-taken:94848
 	picked: 183 |actions: {0: 482, 1: 1120, 2: 808, 3: 779, 4: 599, 5: 631, 6: 717, 7: 789, 8: 353}

==================================================
eval-episode: 650 -> reward: 234.51562500000065, steps: 6278.0, wall-time: 43.45s
-> berries picked: 183 of 800 | patches-visited: [1, 4, 7] | juice left:-0.00
==================================================


=== episode:651 Env-steps-taken:73152
 	picked: 95 |actions: {0: 615, 1: 861, 2: 627, 3: 624, 4: 510, 5: 653, 6: 485, 7: 680, 8: 518}
episode: 651/2000 -> reward: 126.05729166666647, steps:5573, time-taken: 1.99min, time-elasped: 1309.01min
-> berries picked: 95 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6892 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [659, 1047, 1122, 804, 649, 597, 694, 574, 746]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 16, 15, 11, 11, 8, 8, 13, 19]
	Time taken saving stuff: 0.09s

=== episode:652 Env-steps-taken:70272
 	picked: 83 |actions: {0: 621, 1: 616, 2: 562, 3: 644, 4: 487, 5: 631, 6: 491, 7: 562, 8: 426}
episode: 652/2000 -> reward: 111.74479166666656, steps:5040, time-taken: 1.83min, time-elasped: 1310.84min
-> berries picked: 83 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6900 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [657, 1047, 1124, 801, 650, 597, 696, 580, 748]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 16, 15, 17, 8, 9, 15, 9, 19]
	Time taken saving stuff: 0.00s

=== episode:653 Env-steps-taken:52320
 	picked: 16 |actions: {0: 214, 1: 315, 2: 305, 3: 225, 4: 191, 5: 156, 6: 145, 7: 89, 8: 215}
episode: 653/2000 -> reward: 21.583333333333332, steps:1855, time-taken: 0.91min, time-elasped: 1311.76min
-> berries picked: 16 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6894 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [652, 1048, 1127, 799, 650, 597, 695, 579, 747]
	| approx positives in sample 512: 139
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [25, 17, 16, 11, 16, 17, 10, 11, 16]
	Time taken saving stuff: 0.09s

=== episode:654 Env-steps-taken:68448
 	picked: 80 |actions: {0: 507, 1: 774, 2: 676, 3: 704, 4: 633, 5: 604, 6: 521, 7: 693, 8: 388}
episode: 654/2000 -> reward: 102.47395833333326, steps:5500, time-taken: 1.95min, time-elasped: 1313.72min
-> berries picked: 80 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6900 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [652, 1043, 1128, 804, 656, 599, 695, 575, 748]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 22, 13, 20, 13, 8, 7, 14, 18]
	Time taken saving stuff: 0.00s

=== episode:655 Env-steps-taken:58080
 	picked: 36 |actions: {0: 292, 1: 288, 2: 305, 3: 302, 4: 246, 5: 207, 6: 188, 7: 240, 8: 188}
episode: 655/2000 -> reward: 50.93750000000003, steps:2256, time-taken: 0.95min, time-elasped: 1314.67min
-> berries picked: 36 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6905 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [652, 1047, 1126, 804, 660, 597, 698, 572, 749]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 20, 20, 20, 11, 7, 9, 18, 16]
	Time taken saving stuff: 0.01s

=== episode:656 Env-steps-taken:69984
 	picked: 82 |actions: {0: 555, 1: 742, 2: 794, 3: 657, 4: 679, 5: 716, 6: 496, 7: 442, 8: 487}
episode: 656/2000 -> reward: 110.3020833333332, steps:5568, time-taken: 1.96min, time-elasped: 1316.63min
-> berries picked: 82 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6899 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [647, 1045, 1128, 806, 652, 602, 701, 569, 749]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 12, 19, 15, 12, 13, 14, 10, 18]
	Time taken saving stuff: 0.00s

=== episode:657 Env-steps-taken:65184
 	picked: 60 |actions: {0: 308, 1: 547, 2: 630, 3: 402, 4: 437, 5: 528, 6: 357, 7: 373, 8: 392}
episode: 657/2000 -> reward: 87.06249999999996, steps:3974, time-taken: 1.53min, time-elasped: 1318.16min
-> berries picked: 60 of 800 | patches-visited: [0, 3, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6909 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [649, 1043, 1129, 806, 653, 604, 704, 569, 752]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 17, 22, 6, 8, 9, 15, 7, 21]
	Time taken saving stuff: 0.02s

=== episode:658 Env-steps-taken:61536
 	picked: 51 |actions: {0: 427, 1: 507, 2: 611, 3: 460, 4: 354, 5: 379, 6: 303, 7: 315, 8: 315}
episode: 658/2000 -> reward: 68.07812500000006, steps:3671, time-taken: 1.45min, time-elasped: 1319.62min
-> berries picked: 51 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6902 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [646, 1050, 1129, 807, 650, 602, 702, 564, 752]
	| approx positives in sample 512: 100
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 15, 12, 11, 6, 6, 12, 12, 15]
	Time taken saving stuff: 0.00s

=== episode:659 Env-steps-taken:62496
 	picked: 55 |actions: {0: 513, 1: 559, 2: 801, 3: 630, 4: 576, 5: 617, 6: 482, 7: 440, 8: 342}
episode: 659/2000 -> reward: 71.46354166666669, steps:4960, time-taken: 1.69min, time-elasped: 1321.31min
-> berries picked: 55 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6887 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [640, 1044, 1125, 810, 645, 602, 703, 566, 752]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 19, 12, 19, 8, 6, 13, 6, 19]
	Time taken saving stuff: 0.11s

=== episode:660 Env-steps-taken:58560
 	picked: 41 |actions: {0: 272, 1: 421, 2: 490, 3: 357, 4: 333, 5: 279, 6: 240, 7: 338, 8: 229}
episode: 660/2000 -> reward: 53.1510416666667, steps:2959, time-taken: 1.21min, time-elasped: 1322.52min
-> berries picked: 41 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6893 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [641, 1041, 1128, 810, 643, 605, 708, 565, 752]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 22, 19, 14, 12, 9, 13, 7, 16]
	Time taken saving stuff: 0.05s

=== episode:66 Env-steps-taken:74592
 	picked: 94 |actions: {0: 145, 1: 747, 2: 905, 3: 890, 4: 291, 5: 451, 6: 537, 7: 815, 8: 394}

==================================================
eval-episode: 660 -> reward: 133.61458333333323, steps: 5175.0, wall-time: 37.80s
-> berries picked: 94 of 800 | patches-visited: [1, 8] | juice left:-0.00
==================================================


=== episode:661 Env-steps-taken:63456
 	picked: 63 |actions: {0: 538, 1: 817, 2: 719, 3: 763, 4: 750, 5: 581, 6: 387, 7: 453, 8: 739}
episode: 661/2000 -> reward: 76.890625, steps:5747, time-taken: 1.95min, time-elasped: 1325.11min
-> berries picked: 63 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6889 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [643, 1044, 1128, 803, 646, 606, 703, 564, 752]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 16, 19, 15, 16, 11, 3, 7, 18]
	Time taken saving stuff: 0.10s

=== episode:662 Env-steps-taken:52032
 	picked: 18 |actions: {0: 155, 1: 128, 2: 126, 3: 205, 4: 107, 5: 135, 6: 105, 7: 101, 8: 156}
episode: 662/2000 -> reward: 19.968749999999993, steps:1218, time-taken: 0.67min, time-elasped: 1325.78min
-> berries picked: 18 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6891 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [645, 1043, 1127, 804, 648, 603, 703, 565, 753]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 12, 20, 14, 14, 13, 13, 6, 17]
	Time taken saving stuff: 0.01s

=== episode:663 Env-steps-taken:63360
 	picked: 58 |actions: {0: 280, 1: 316, 2: 473, 3: 429, 4: 358, 5: 437, 6: 283, 7: 406, 8: 359}
episode: 663/2000 -> reward: 77.17708333333336, steps:3341, time-taken: 1.34min, time-elasped: 1327.13min
-> berries picked: 58 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6909 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [647, 1050, 1128, 800, 646, 608, 705, 570, 755]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 21, 15, 9, 9, 17, 19, 6, 18]
	Time taken saving stuff: 0.09s

=== episode:664 Env-steps-taken:60864
 	picked: 47 |actions: {0: 381, 1: 610, 2: 427, 3: 383, 4: 277, 5: 344, 6: 285, 7: 351, 8: 313}
episode: 664/2000 -> reward: 64.80729166666671, steps:3371, time-taken: 1.29min, time-elasped: 1328.42min
-> berries picked: 47 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6905 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [653, 1046, 1126, 798, 651, 605, 705, 565, 756]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 18, 12, 16, 9, 9, 15, 8, 16]
	Time taken saving stuff: 0.11s

=== episode:665 Env-steps-taken:49632
 	picked: 6 |actions: {0: 39, 1: 101, 2: 156, 3: 52, 4: 63, 5: 43, 6: 32, 7: 59, 8: 99}
episode: 665/2000 -> reward: 8.156250000000002, steps:644, time-taken: 0.51min, time-elasped: 1328.93min
-> berries picked: 6 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6906 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [653, 1046, 1128, 797, 652, 605, 704, 565, 756]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 9, 14, 15, 8, 15, 11, 8, 18]
	Time taken saving stuff: 0.08s

=== episode:666 Env-steps-taken:63072
 	picked: 61 |actions: {0: 438, 1: 495, 2: 516, 3: 381, 4: 335, 5: 362, 6: 280, 7: 406, 8: 317}
episode: 666/2000 -> reward: 75.50520833333333, steps:3530, time-taken: 1.35min, time-elasped: 1330.28min
-> berries picked: 61 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6922 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [654, 1048, 1130, 806, 652, 603, 704, 569, 756]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 8, 19, 21, 12, 13, 11, 11, 16]
	Time taken saving stuff: 0.02s

=== episode:667 Env-steps-taken:68640
 	picked: 73 |actions: {0: 579, 1: 508, 2: 635, 3: 597, 4: 747, 5: 700, 6: 376, 7: 482, 8: 510}
episode: 667/2000 -> reward: 104.31770833333324, steps:5134, time-taken: 1.89min, time-elasped: 1332.17min
-> berries picked: 73 of 800 | patches-visited: [0, 5, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6935 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [653, 1045, 1126, 811, 656, 613, 705, 570, 756]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 24, 15, 15, 15, 9, 17, 8, 20]
	Time taken saving stuff: 0.09s

=== episode:668 Env-steps-taken:67776
 	picked: 74 |actions: {0: 486, 1: 552, 2: 783, 3: 498, 4: 499, 5: 398, 6: 342, 7: 446, 8: 511}
episode: 668/2000 -> reward: 99.26041666666657, steps:4515, time-taken: 1.71min, time-elasped: 1333.89min
-> berries picked: 74 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6945 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [652, 1051, 1132, 802, 661, 610, 710, 569, 758]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 22, 19, 14, 15, 12, 18, 6, 10]
	Time taken saving stuff: 0.02s

=== episode:669 Env-steps-taken:62592
 	picked: 53 |actions: {0: 434, 1: 536, 2: 377, 3: 374, 4: 344, 5: 554, 6: 279, 7: 394, 8: 290}
episode: 669/2000 -> reward: 73.46354166666669, steps:3582, time-taken: 1.29min, time-elasped: 1335.18min
-> berries picked: 53 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6949 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [656, 1051, 1128, 803, 659, 612, 712, 569, 759]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 16, 20, 10, 1, 13, 14, 13, 16]
	Time taken saving stuff: 0.06s

=== episode:670 Env-steps-taken:63072
 	picked: 56 |actions: {0: 435, 1: 372, 2: 492, 3: 391, 4: 327, 5: 408, 6: 402, 7: 352, 8: 372}
episode: 670/2000 -> reward: 75.00520833333334, steps:3551, time-taken: 1.36min, time-elasped: 1336.54min
-> berries picked: 56 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6948 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [651, 1051, 1126, 807, 659, 613, 714, 567, 760]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 20, 11, 14, 12, 12, 15, 8, 18]
	Time taken saving stuff: 0.16s

=== episode:67 Env-steps-taken:56928
 	picked: 30 |actions: {0: 98, 1: 197, 2: 135, 3: 134, 4: 46, 5: 82, 6: 71, 7: 136, 8: 14}

==================================================
eval-episode: 670 -> reward: 44.781250000000014, steps: 913.0, wall-time: 23.34s
-> berries picked: 30 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:671 Env-steps-taken:60000
 	picked: 41 |actions: {0: 368, 1: 467, 2: 1454, 3: 435, 4: 457, 5: 396, 6: 390, 7: 316, 8: 431}
episode: 671/2000 -> reward: 60.65104166666671, steps:4714, time-taken: 1.71min, time-elasped: 1338.65min
-> berries picked: 41 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6907 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [647, 1044, 1120, 793, 655, 610, 712, 565, 761]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 18, 19, 16, 11, 8, 12, 14, 19]
	Time taken saving stuff: 0.00s

=== episode:672 Env-steps-taken:78144
 	picked: 114 |actions: {0: 678, 1: 746, 2: 1084, 3: 699, 4: 659, 5: 676, 6: 611, 7: 582, 8: 544}
episode: 672/2000 -> reward: 149.08333333333331, steps:6279, time-taken: 2.11min, time-elasped: 1340.77min
-> berries picked: 114 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6938 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [647, 1044, 1129, 803, 656, 618, 713, 567, 761]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 18, 18, 11, 15, 15, 12, 5, 12]
	Time taken saving stuff: 0.02s

=== episode:673 Env-steps-taken:68544
 	picked: 74 |actions: {0: 500, 1: 459, 2: 700, 3: 379, 4: 495, 5: 393, 6: 316, 7: 302, 8: 376}
episode: 673/2000 -> reward: 103.26041666666661, steps:3920, time-taken: 1.53min, time-elasped: 1342.30min
-> berries picked: 74 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6959 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [658, 1051, 1135, 801, 661, 620, 711, 560, 762]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 15, 17, 17, 13, 9, 4, 8, 26]
	Time taken saving stuff: 0.01s

=== episode:674 Env-steps-taken:73728
 	picked: 96 |actions: {0: 693, 1: 661, 2: 627, 3: 724, 4: 563, 5: 618, 6: 479, 7: 574, 8: 434}
episode: 674/2000 -> reward: 128.99999999999986, steps:5373, time-taken: 1.85min, time-elasped: 1344.15min
-> berries picked: 96 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6969 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [659, 1055, 1133, 798, 668, 615, 717, 560, 764]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 14, 17, 7, 5, 10, 10, 10, 15]
	Time taken saving stuff: 0.10s

=== episode:675 Env-steps-taken:64992
 	picked: 70 |actions: {0: 605, 1: 698, 2: 822, 3: 540, 4: 493, 5: 631, 6: 461, 7: 449, 8: 610}
episode: 675/2000 -> reward: 84.04687499999997, steps:5309, time-taken: 1.83min, time-elasped: 1345.98min
-> berries picked: 70 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6965 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [662, 1056, 1129, 797, 671, 613, 716, 561, 760]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 19, 23, 15, 9, 12, 11, 6, 17]
	Time taken saving stuff: 0.11s

=== episode:676 Env-steps-taken:74496
 	picked: 94 |actions: {0: 464, 1: 593, 2: 719, 3: 659, 4: 561, 5: 517, 6: 384, 7: 497, 8: 456}
episode: 676/2000 -> reward: 133.61458333333323, steps:4850, time-taken: 1.81min, time-elasped: 1347.80min
-> berries picked: 94 of 800 | patches-visited: [0, 1, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6994 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [659, 1060, 1134, 799, 680, 618, 716, 565, 763]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 11, 4, 14, 12, 10, 12, 9, 23]
	Time taken saving stuff: 0.10s

=== episode:677 Env-steps-taken:70848
 	picked: 87 |actions: {0: 534, 1: 507, 2: 769, 3: 669, 4: 564, 5: 661, 6: 421, 7: 407, 8: 605}
episode: 677/2000 -> reward: 114.13020833333321, steps:5137, time-taken: 1.90min, time-elasped: 1349.70min
-> berries picked: 87 of 800 | patches-visited: [0, 5, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7009 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [653, 1061, 1139, 802, 689, 617, 718, 565, 765]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 11, 23, 16, 11, 11, 9, 10, 17]
	Time taken saving stuff: 0.09s

=== episode:678 Env-steps-taken:60384
 	picked: 46 |actions: {0: 460, 1: 844, 2: 475, 3: 374, 4: 335, 5: 420, 6: 318, 7: 345, 8: 757}
episode: 678/2000 -> reward: 61.864583333333385, steps:4328, time-taken: 1.50min, time-elasped: 1351.21min
-> berries picked: 46 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6990 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [648, 1065, 1135, 795, 684, 617, 715, 565, 766]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 20, 14, 14, 16, 7, 19, 8, 22]
	Time taken saving stuff: 0.01s

=== episode:679 Env-steps-taken:67104
 	picked: 79 |actions: {0: 594, 1: 550, 2: 586, 3: 531, 4: 717, 5: 519, 6: 339, 7: 453, 8: 615}
episode: 679/2000 -> reward: 95.47395833333323, steps:4904, time-taken: 1.76min, time-elasped: 1352.97min
-> berries picked: 79 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7008 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [648, 1071, 1135, 796, 691, 619, 714, 565, 769]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 11, 17, 15, 15, 8, 8, 15, 20]
	Time taken saving stuff: 0.09s

=== episode:680 Env-steps-taken:69120
 	picked: 79 |actions: {0: 663, 1: 593, 2: 677, 3: 530, 4: 486, 5: 471, 6: 454, 7: 436, 8: 605}
episode: 680/2000 -> reward: 104.08854166666657, steps:4915, time-taken: 1.74min, time-elasped: 1354.71min
-> berries picked: 79 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7026 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [652, 1077, 1136, 797, 688, 622, 715, 570, 769]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 25, 15, 19, 8, 17, 12, 5, 15]
	Time taken saving stuff: 0.16s

=== episode:68 Env-steps-taken:74880
 	picked: 105 |actions: {0: 373, 1: 710, 2: 801, 3: 283, 4: 160, 5: 581, 6: 276, 7: 1480, 8: 1624}

==================================================
eval-episode: 680 -> reward: 134.48437499999983, steps: 6288.0, wall-time: 43.26s
-> berries picked: 105 of 800 | patches-visited: [1, 2] | juice left:-0.00
==================================================


=== episode:681 Env-steps-taken:52992
 	picked: 17 |actions: {0: 178, 1: 115, 2: 205, 3: 121, 4: 104, 5: 217, 6: 77, 7: 154, 8: 203}
episode: 681/2000 -> reward: 25.026041666666668, steps:1374, time-taken: 0.72min, time-elasped: 1356.16min
-> berries picked: 17 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7023 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [651, 1076, 1136, 797, 690, 620, 713, 571, 769]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 12, 17, 19, 12, 8, 10, 6, 21]
	Time taken saving stuff: 0.00s

=== episode:682 Env-steps-taken:67776
 	picked: 77 |actions: {0: 646, 1: 484, 2: 637, 3: 494, 4: 535, 5: 599, 6: 352, 7: 408, 8: 593}
episode: 682/2000 -> reward: 99.08854166666659, steps:4748, time-taken: 1.81min, time-elasped: 1357.97min
-> berries picked: 77 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7029 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [649, 1069, 1137, 805, 692, 621, 711, 577, 768]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 24, 12, 13, 12, 8, 14, 12, 15]
	Time taken saving stuff: 0.02s

=== episode:683 Env-steps-taken:66048
 	picked: 65 |actions: {0: 530, 1: 422, 2: 558, 3: 544, 4: 480, 5: 422, 6: 515, 7: 529, 8: 495}
episode: 683/2000 -> reward: 90.7760416666666, steps:4495, time-taken: 2.07min, time-elasped: 1360.04min
-> berries picked: 65 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7037 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [649, 1074, 1131, 799, 693, 624, 713, 583, 771]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 19, 13, 18, 11, 15, 10, 7, 14]
	Time taken saving stuff: 0.01s

=== episode:684 Env-steps-taken:64896
 	picked: 64 |actions: {0: 501, 1: 581, 2: 793, 3: 635, 4: 586, 5: 449, 6: 370, 7: 450, 8: 660}
episode: 684/2000 -> reward: 84.33333333333333, steps:5025, time-taken: 2.33min, time-elasped: 1362.37min
-> berries picked: 64 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7026 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [650, 1074, 1129, 802, 689, 625, 710, 577, 770]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 13, 16, 11, 13, 12, 12, 9, 26]
	Time taken saving stuff: 0.00s

=== episode:685 Env-steps-taken:63744
 	picked: 58 |actions: {0: 321, 1: 437, 2: 481, 3: 398, 4: 421, 5: 376, 6: 235, 7: 289, 8: 387}
episode: 685/2000 -> reward: 79.17708333333331, steps:3345, time-taken: 1.73min, time-elasped: 1364.10min
-> berries picked: 58 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7041 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [647, 1072, 1138, 800, 691, 631, 710, 580, 772]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 16, 17, 13, 17, 4, 13, 13, 14]
	Time taken saving stuff: 0.02s

=== episode:686 Env-steps-taken:65472
 	picked: 68 |actions: {0: 518, 1: 686, 2: 731, 3: 698, 4: 825, 5: 572, 6: 561, 7: 583, 8: 656}
episode: 686/2000 -> reward: 87.1041666666666, steps:5830, time-taken: 2.67min, time-elasped: 1366.78min
-> berries picked: 68 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7022 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [644, 1062, 1140, 799, 693, 633, 710, 571, 770]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 16, 17, 13, 14, 6, 9, 10, 14]
	Time taken saving stuff: 0.01s

=== episode:687 Env-steps-taken:74880
 	picked: 95 |actions: {0: 644, 1: 677, 2: 655, 3: 635, 4: 438, 5: 545, 6: 448, 7: 578, 8: 362}
episode: 687/2000 -> reward: 134.22916666666657, steps:4982, time-taken: 2.56min, time-elasped: 1369.34min
-> berries picked: 95 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7045 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [644, 1060, 1137, 804, 698, 639, 715, 578, 770]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 18, 15, 8, 12, 18, 11, 6, 15]
	Time taken saving stuff: 0.08s

=== episode:688 Env-steps-taken:68256
 	picked: 69 |actions: {0: 443, 1: 529, 2: 522, 3: 474, 4: 497, 5: 589, 6: 348, 7: 570, 8: 278}
episode: 688/2000 -> reward: 102.04687499999993, steps:4250, time-taken: 2.14min, time-elasped: 1371.48min
-> berries picked: 69 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7047 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [648, 1056, 1139, 802, 697, 639, 711, 582, 773]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 12, 20, 11, 13, 14, 15, 7, 27]
	Time taken saving stuff: 0.01s

=== episode:689 Env-steps-taken:67584
 	picked: 71 |actions: {0: 532, 1: 665, 2: 553, 3: 372, 4: 389, 5: 581, 6: 344, 7: 414, 8: 325}
episode: 689/2000 -> reward: 98.04687499999991, steps:4175, time-taken: 2.11min, time-elasped: 1373.60min
-> berries picked: 71 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7055 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [648, 1066, 1143, 798, 692, 644, 715, 575, 774]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 20, 11, 12, 11, 16, 13, 7, 13]
	Time taken saving stuff: 0.11s

=== episode:690 Env-steps-taken:64224
 	picked: 59 |actions: {0: 508, 1: 669, 2: 870, 3: 670, 4: 448, 5: 493, 6: 371, 7: 426, 8: 640}
episode: 690/2000 -> reward: 81.11979166666664, steps:5095, time-taken: 2.39min, time-elasped: 1375.99min
-> berries picked: 59 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7043 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [649, 1065, 1145, 800, 686, 641, 707, 576, 774]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 16, 22, 14, 8, 11, 10, 14, 16]
	Time taken saving stuff: 0.06s

=== episode:69 Env-steps-taken:70272
 	picked: 81 |actions: {0: 265, 1: 678, 2: 365, 3: 841, 4: 282, 5: 358, 6: 35, 7: 389, 8: 191}

==================================================
eval-episode: 690 -> reward: 111.85937499999989, steps: 3404.0, wall-time: 40.50s
-> berries picked: 81 of 800 | patches-visited: [1, 8] | juice left:-0.00
==================================================


=== episode:691 Env-steps-taken:63936
 	picked: 59 |actions: {0: 383, 1: 495, 2: 460, 3: 408, 4: 288, 5: 205, 6: 249, 7: 330, 8: 180}
episode: 691/2000 -> reward: 80.11979166666666, steps:2998, time-taken: 1.69min, time-elasped: 1378.36min
-> berries picked: 59 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7050 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [652, 1069, 1146, 798, 686, 638, 707, 579, 775]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 15, 15, 16, 11, 8, 12, 14, 17]
	Time taken saving stuff: 0.07s

=== episode:692 Env-steps-taken:70272
 	picked: 84 |actions: {0: 584, 1: 561, 2: 687, 3: 583, 4: 418, 5: 420, 6: 316, 7: 382, 8: 303}
episode: 692/2000 -> reward: 112.18749999999989, steps:4254, time-taken: 2.21min, time-elasped: 1380.58min
-> berries picked: 84 of 800 | patches-visited: [0, 5, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7057 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [648, 1074, 1144, 799, 689, 642, 703, 584, 774]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 22, 21, 10, 12, 12, 9, 12, 21]
	Time taken saving stuff: 0.01s

=== episode:693 Env-steps-taken:58944
 	picked: 40 |actions: {0: 201, 1: 372, 2: 276, 3: 384, 4: 360, 5: 280, 6: 208, 7: 219, 8: 180}
episode: 693/2000 -> reward: 55.208333333333364, steps:2480, time-taken: 1.44min, time-elasped: 1382.02min
-> berries picked: 40 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7055 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [642, 1074, 1146, 798, 690, 641, 702, 589, 773]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 13, 20, 11, 9, 7, 7, 7, 20]
	Time taken saving stuff: 0.01s

=== episode:694 Env-steps-taken:56448
 	picked: 35 |actions: {0: 195, 1: 217, 2: 286, 3: 343, 4: 287, 5: 259, 6: 174, 7: 201, 8: 175}
episode: 694/2000 -> reward: 42.49479166666668, steps:2137, time-taken: 1.24min, time-elasped: 1383.26min
-> berries picked: 35 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7061 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [641, 1072, 1146, 800, 696, 641, 703, 589, 773]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 24, 9, 18, 14, 13, 4, 8, 15]
	Time taken saving stuff: 0.01s

=== episode:695 Env-steps-taken:64320
 	picked: 63 |actions: {0: 535, 1: 549, 2: 574, 3: 502, 4: 548, 5: 404, 6: 412, 7: 516, 8: 355}
episode: 695/2000 -> reward: 81.89062499999997, steps:4395, time-taken: 2.21min, time-elasped: 1385.48min
-> berries picked: 63 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7054 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [645, 1062, 1149, 802, 689, 642, 701, 589, 775]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 14, 15, 14, 11, 9, 9, 7, 20]
	Time taken saving stuff: 0.02s

=== episode:696 Env-steps-taken:65760
 	picked: 63 |actions: {0: 489, 1: 760, 2: 784, 3: 506, 4: 567, 5: 472, 6: 374, 7: 528, 8: 607}
episode: 696/2000 -> reward: 89.39062499999997, steps:5087, time-taken: 2.58min, time-elasped: 1388.06min
-> berries picked: 63 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7046 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [645, 1065, 1148, 798, 689, 634, 703, 589, 775]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 19, 16, 11, 11, 13, 9, 13, 19]
	Time taken saving stuff: 0.01s

=== episode:697 Env-steps-taken:56736
 	picked: 35 |actions: {0: 353, 1: 456, 2: 355, 3: 231, 4: 182, 5: 259, 6: 255, 7: 299, 8: 258}
episode: 697/2000 -> reward: 43.494791666666686, steps:2648, time-taken: 1.47min, time-elasped: 1389.53min
-> berries picked: 35 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7052 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [647, 1068, 1147, 798, 688, 637, 703, 590, 774]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 18, 18, 22, 16, 9, 4, 4, 20]
	Time taken saving stuff: 0.01s

=== episode:698 Env-steps-taken:57024
 	picked: 35 |actions: {0: 199, 1: 263, 2: 214, 3: 201, 4: 212, 5: 133, 6: 180, 7: 221, 8: 141}
episode: 698/2000 -> reward: 45.49479166666669, steps:1764, time-taken: 1.06min, time-elasped: 1390.58min
-> berries picked: 35 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7066 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [648, 1072, 1149, 799, 687, 638, 704, 595, 774]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 19, 19, 11, 9, 8, 17, 5, 32]
	Time taken saving stuff: 0.01s

=== episode:699 Env-steps-taken:63072
 	picked: 54 |actions: {0: 431, 1: 450, 2: 418, 3: 330, 4: 367, 5: 439, 6: 338, 7: 443, 8: 282}
episode: 699/2000 -> reward: 75.90625000000001, steps:3498, time-taken: 1.74min, time-elasped: 1392.33min
-> berries picked: 54 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7060 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [642, 1067, 1149, 796, 689, 639, 705, 598, 775]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 17, 24, 11, 20, 10, 9, 8, 15]
	Time taken saving stuff: 0.08s

=== episode:700 Env-steps-taken:64320
 	picked: 66 |actions: {0: 515, 1: 706, 2: 530, 3: 590, 4: 594, 5: 513, 6: 349, 7: 463, 8: 325}
episode: 700/2000 -> reward: 81.71874999999994, steps:4585, time-taken: 2.28min, time-elasped: 1394.62min
-> berries picked: 66 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7056 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [638, 1069, 1148, 796, 687, 641, 706, 596, 775]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 22, 16, 16, 8, 10, 3, 11, 24]
	Time taken saving stuff: 0.10s

=== episode:70 Env-steps-taken:86496
 	picked: 144 |actions: {0: 600, 1: 933, 2: 253, 3: 789, 4: 394, 5: 218, 6: 461, 7: 607, 8: 105}

==================================================
eval-episode: 700 -> reward: 192.3645833333336, steps: 4360.0, wall-time: 52.68s
-> berries picked: 144 of 800 | patches-visited: [1, 2, 5] | juice left:-0.00
==================================================


=== episode:701 Env-steps-taken:65184
 	picked: 75 |actions: {0: 566, 1: 837, 2: 563, 3: 682, 4: 614, 5: 515, 6: 599, 7: 602, 8: 355}
episode: 701/2000 -> reward: 84.8177083333333, steps:5333, time-taken: 2.49min, time-elasped: 1397.99min
-> berries picked: 75 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7048 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [642, 1067, 1150, 796, 685, 639, 707, 591, 771]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 18, 16, 16, 13, 8, 17, 6, 16]
	Time taken saving stuff: 0.01s

=== episode:702 Env-steps-taken:60288
 	picked: 47 |actions: {0: 388, 1: 361, 2: 540, 3: 253, 4: 349, 5: 230, 6: 234, 7: 312, 8: 216}
episode: 702/2000 -> reward: 61.807291666666714, steps:2883, time-taken: 1.57min, time-elasped: 1399.57min
-> berries picked: 47 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7051 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [644, 1067, 1149, 797, 684, 643, 712, 584, 771]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 19, 13, 10, 14, 14, 15, 7, 13]
	Time taken saving stuff: 0.01s

=== episode:703 Env-steps-taken:70464
 	picked: 84 |actions: {0: 620, 1: 745, 2: 628, 3: 575, 4: 835, 5: 678, 6: 688, 7: 586, 8: 424}
episode: 703/2000 -> reward: 112.68749999999984, steps:5779, time-taken: 2.72min, time-elasped: 1402.29min
-> berries picked: 84 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7051 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [647, 1064, 1140, 797, 688, 649, 713, 581, 772]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 9, 16, 13, 16, 10, 9, 17, 23]
	Time taken saving stuff: 0.09s

=== episode:704 Env-steps-taken:64800
 	picked: 69 |actions: {0: 559, 1: 582, 2: 615, 3: 431, 4: 684, 5: 519, 6: 433, 7: 450, 8: 366}
episode: 704/2000 -> reward: 84.04687499999999, steps:4639, time-taken: 2.33min, time-elasped: 1404.62min
-> berries picked: 69 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7054 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [646, 1065, 1136, 799, 688, 651, 716, 582, 771]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 18, 15, 15, 13, 9, 11, 11, 19]
	Time taken saving stuff: 0.10s

=== episode:705 Env-steps-taken:71424
 	picked: 81 |actions: {0: 448, 1: 308, 2: 417, 3: 339, 4: 296, 5: 414, 6: 432, 7: 453, 8: 202}
episode: 705/2000 -> reward: 118.35937499999984, steps:3309, time-taken: 1.93min, time-elasped: 1406.55min
-> berries picked: 81 of 800 | patches-visited: [0, 4, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7086 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [649, 1064, 1141, 800, 688, 653, 728, 588, 775]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 14, 23, 12, 13, 12, 10, 3, 11]
	Time taken saving stuff: 0.08s

=== episode:706 Env-steps-taken:64992
 	picked: 73 |actions: {0: 491, 1: 963, 2: 793, 3: 574, 4: 631, 5: 674, 6: 475, 7: 809, 8: 499}
episode: 706/2000 -> reward: 84.31770833333329, steps:5909, time-taken: 2.75min, time-elasped: 1409.31min
-> berries picked: 73 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7073 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [651, 1062, 1137, 802, 687, 654, 725, 585, 770]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 21, 17, 14, 6, 9, 8, 13, 24]
	Time taken saving stuff: 0.10s

=== episode:707 Env-steps-taken:63744
 	picked: 60 |actions: {0: 498, 1: 905, 2: 614, 3: 577, 4: 563, 5: 685, 6: 456, 7: 747, 8: 389}
episode: 707/2000 -> reward: 78.17708333333333, steps:5434, time-taken: 2.73min, time-elasped: 1412.04min
-> berries picked: 60 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7053 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [649, 1061, 1135, 794, 689, 648, 723, 587, 767]
	| approx positives in sample 512: 143
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 19, 19, 15, 15, 9, 20, 9, 22]
	Time taken saving stuff: 0.09s

=== episode:708 Env-steps-taken:67968
 	picked: 76 |actions: {0: 484, 1: 437, 2: 377, 3: 475, 4: 333, 5: 498, 6: 417, 7: 516, 8: 266}
episode: 708/2000 -> reward: 100.14583333333321, steps:3803, time-taken: 2.09min, time-elasped: 1414.13min
-> berries picked: 76 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7068 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [649, 1060, 1140, 801, 684, 654, 726, 586, 768]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 22, 14, 11, 10, 12, 17, 5, 21]
	Time taken saving stuff: 0.09s

=== episode:709 Env-steps-taken:67200
 	picked: 77 |actions: {0: 512, 1: 768, 2: 863, 3: 627, 4: 505, 5: 632, 6: 422, 7: 476, 8: 352}
episode: 709/2000 -> reward: 96.08854166666654, steps:5157, time-taken: 2.65min, time-elasped: 1416.79min
-> berries picked: 77 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7088 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [653, 1059, 1140, 810, 691, 653, 727, 586, 769]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 23, 15, 17, 17, 14, 15, 12, 23]
	Time taken saving stuff: 0.08s

=== episode:710 Env-steps-taken:72288
 	picked: 99 |actions: {0: 635, 1: 665, 2: 731, 3: 855, 4: 695, 5: 787, 6: 484, 7: 605, 8: 393}
episode: 710/2000 -> reward: 121.32812499999983, steps:5850, time-taken: 2.91min, time-elasped: 1419.70min
-> berries picked: 99 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7102 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [647, 1067, 1139, 812, 694, 654, 730, 587, 772]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 9, 18, 10, 16, 9, 8, 6, 19]
	Time taken saving stuff: 0.07s

=== episode:71 Env-steps-taken:89376
 	picked: 158 |actions: {0: 441, 1: 789, 2: 552, 3: 415, 4: 971, 5: 613, 6: 307, 7: 625, 8: 186}

==================================================
eval-episode: 710 -> reward: 207.44791666666714, steps: 4899.0, wall-time: 50.69s
-> berries picked: 158 of 800 | patches-visited: [0, 1, 3] | juice left:-0.00
==================================================


=== episode:711 Env-steps-taken:69792
 	picked: 88 |actions: {0: 523, 1: 681, 2: 754, 3: 485, 4: 486, 5: 691, 6: 546, 7: 470, 8: 389}
episode: 711/2000 -> reward: 108.95833333333319, steps:5025, time-taken: 2.58min, time-elasped: 1423.13min
-> berries picked: 88 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7127 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [646, 1073, 1145, 820, 693, 656, 732, 589, 773]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 17, 15, 14, 10, 11, 14, 12, 14]
	Time taken saving stuff: 0.10s

=== episode:712 Env-steps-taken:67680
 	picked: 67 |actions: {0: 552, 1: 486, 2: 413, 3: 427, 4: 448, 5: 320, 6: 377, 7: 339, 8: 287}
episode: 712/2000 -> reward: 99.16145833333327, steps:3649, time-taken: 1.89min, time-elasped: 1425.03min
-> berries picked: 67 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7137 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [649, 1065, 1143, 833, 698, 657, 731, 587, 774]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 14, 14, 15, 12, 11, 18, 13, 15]
	Time taken saving stuff: 0.02s

=== episode:713 Env-steps-taken:76800
 	picked: 111 |actions: {0: 685, 1: 1029, 2: 746, 3: 695, 4: 647, 5: 646, 6: 639, 7: 648, 8: 570}
episode: 713/2000 -> reward: 141.31249999999991, steps:6305, time-taken: 3.10min, time-elasped: 1428.13min
-> berries picked: 111 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7158 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [654, 1069, 1143, 832, 694, 667, 733, 593, 773]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 14, 18, 19, 12, 11, 8, 8, 22]
	Time taken saving stuff: 0.11s

=== episode:714 Env-steps-taken:73920
 	picked: 101 |actions: {0: 811, 1: 718, 2: 864, 3: 586, 4: 592, 5: 687, 6: 571, 7: 753, 8: 394}
episode: 714/2000 -> reward: 129.7135416666665, steps:5976, time-taken: 2.89min, time-elasped: 1431.03min
-> berries picked: 101 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7170 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [666, 1076, 1146, 830, 695, 659, 731, 593, 774]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 20, 19, 9, 11, 5, 11, 13, 22]
	Time taken saving stuff: 0.01s

=== episode:715 Env-steps-taken:66048
 	picked: 64 |actions: {0: 485, 1: 552, 2: 651, 3: 456, 4: 398, 5: 387, 6: 405, 7: 420, 8: 296}
episode: 715/2000 -> reward: 90.44791666666659, steps:4050, time-taken: 2.04min, time-elasped: 1433.07min
-> berries picked: 64 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7171 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [662, 1078, 1146, 833, 692, 662, 731, 592, 775]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 13, 14, 13, 5, 12, 10, 7, 23]
	Time taken saving stuff: 0.02s

=== episode:716 Env-steps-taken:72192
 	picked: 85 |actions: {0: 560, 1: 651, 2: 490, 3: 551, 4: 509, 5: 587, 6: 489, 7: 540, 8: 334}
episode: 716/2000 -> reward: 121.63020833333321, steps:4711, time-taken: 2.28min, time-elasped: 1435.35min
-> berries picked: 85 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7177 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [662, 1085, 1141, 831, 690, 666, 726, 601, 775]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 23, 17, 13, 8, 5, 16, 14, 20]
	Time taken saving stuff: 0.11s

=== episode:717 Env-steps-taken:67296
 	picked: 73 |actions: {0: 471, 1: 700, 2: 596, 3: 511, 4: 412, 5: 439, 6: 463, 7: 472, 8: 430}
episode: 717/2000 -> reward: 97.31770833333327, steps:4494, time-taken: 2.24min, time-elasped: 1437.60min
-> berries picked: 73 of 800 | patches-visited: [0, 5, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7188 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [656, 1089, 1143, 834, 690, 664, 729, 604, 779]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 13, 16, 16, 16, 14, 7, 10, 20]
	Time taken saving stuff: 0.09s

=== episode:718 Env-steps-taken:62592
 	picked: 65 |actions: {0: 615, 1: 742, 2: 440, 3: 401, 4: 429, 5: 648, 6: 511, 7: 558, 8: 651}
episode: 718/2000 -> reward: 72.27604166666667, steps:4995, time-taken: 2.52min, time-elasped: 1440.13min
-> berries picked: 65 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7206 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [659, 1088, 1139, 839, 688, 668, 737, 609, 779]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 9, 19, 12, 9, 15, 19, 6, 16]
	Time taken saving stuff: 0.10s

=== episode:719 Env-steps-taken:62016
 	picked: 60 |actions: {0: 479, 1: 530, 2: 430, 3: 402, 4: 523, 5: 568, 6: 317, 7: 320, 8: 269}
episode: 719/2000 -> reward: 69.56250000000003, steps:3838, time-taken: 1.88min, time-elasped: 1442.01min
-> berries picked: 60 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7214 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [664, 1083, 1139, 841, 691, 668, 736, 612, 780]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 26, 15, 14, 11, 12, 6, 16, 16]
	Time taken saving stuff: 0.01s

=== episode:720 Env-steps-taken:61632
 	picked: 50 |actions: {0: 326, 1: 473, 2: 503, 3: 325, 4: 322, 5: 267, 6: 323, 7: 409, 8: 419}
episode: 720/2000 -> reward: 66.69270833333336, steps:3367, time-taken: 1.78min, time-elasped: 1443.79min
-> berries picked: 50 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7215 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [662, 1086, 1141, 841, 694, 666, 739, 607, 779]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 20, 15, 9, 15, 7, 12, 8, 13]
	Time taken saving stuff: 0.07s

=== episode:72 Env-steps-taken:98304
 	picked: 191 |actions: {0: 738, 1: 620, 2: 967, 3: 383, 4: 858, 5: 602, 6: 1457, 7: 402, 8: 82}

==================================================
eval-episode: 720 -> reward: 251.67187500000074, steps: 6109.0, wall-time: 67.60s
-> berries picked: 191 of 800 | patches-visited: [1, 3, 9] | juice left:-0.00
==================================================


=== episode:721 Env-steps-taken:74880
 	picked: 99 |actions: {0: 682, 1: 735, 2: 726, 3: 481, 4: 694, 5: 599, 6: 718, 7: 624, 8: 327}
episode: 721/2000 -> reward: 134.49999999999994, steps:5586, time-taken: 2.72min, time-elasped: 1447.64min
-> berries picked: 99 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7234 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [667, 1084, 1139, 838, 699, 671, 743, 612, 781]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 17, 17, 9, 8, 15, 10, 10, 30]
	Time taken saving stuff: 0.01s

=== episode:722 Env-steps-taken:62688
 	picked: 60 |actions: {0: 446, 1: 727, 2: 507, 3: 380, 4: 446, 5: 569, 6: 439, 7: 421, 8: 404}
episode: 722/2000 -> reward: 73.5625, steps:4339, time-taken: 2.15min, time-elasped: 1449.80min
-> berries picked: 60 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7240 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [667, 1084, 1147, 838, 697, 669, 745, 610, 783]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 20, 11, 11, 7, 14, 15, 9, 15]
	Time taken saving stuff: 0.09s

=== episode:723 Env-steps-taken:62784
 	picked: 50 |actions: {0: 504, 1: 657, 2: 629, 3: 543, 4: 709, 5: 717, 6: 521, 7: 562, 8: 520}
episode: 723/2000 -> reward: 74.63541666666667, steps:5362, time-taken: 2.55min, time-elasped: 1452.35min
-> berries picked: 50 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7238 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [665, 1088, 1147, 836, 698, 665, 749, 606, 784]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 18, 17, 13, 11, 9, 9, 16, 14]
	Time taken saving stuff: 0.08s

=== episode:724 Env-steps-taken:66624
 	picked: 75 |actions: {0: 628, 1: 675, 2: 721, 3: 532, 4: 463, 5: 521, 6: 491, 7: 392, 8: 340}
episode: 724/2000 -> reward: 92.70312499999991, steps:4763, time-taken: 3.45min, time-elasped: 1455.81min
-> berries picked: 75 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7239 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [657, 1088, 1155, 841, 695, 664, 750, 604, 785]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 16, 12, 17, 8, 14, 13, 12, 18]
	Time taken saving stuff: 0.01s

=== episode:725 Env-steps-taken:65280
 	picked: 68 |actions: {0: 526, 1: 700, 2: 617, 3: 526, 4: 514, 5: 558, 6: 434, 7: 622, 8: 481}
episode: 725/2000 -> reward: 86.10416666666663, steps:4978, time-taken: 2.40min, time-elasped: 1458.21min
-> berries picked: 68 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7253 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [656, 1088, 1154, 841, 700, 667, 750, 611, 786]
	| approx positives in sample 512: 154
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 19, 17, 21, 10, 18, 17, 15, 23]
	Time taken saving stuff: 0.00s

=== episode:726 Env-steps-taken:69600
 	picked: 81 |actions: {0: 644, 1: 605, 2: 640, 3: 502, 4: 579, 5: 548, 6: 495, 7: 519, 8: 310}
episode: 726/2000 -> reward: 108.35937499999986, steps:4842, time-taken: 2.27min, time-elasped: 1460.49min
-> berries picked: 81 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7247 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [661, 1081, 1141, 842, 704, 666, 746, 619, 787]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 14, 17, 9, 17, 11, 14, 8, 18]
	Time taken saving stuff: 0.00s

=== episode:727 Env-steps-taken:63360
 	picked: 60 |actions: {0: 444, 1: 379, 2: 500, 3: 435, 4: 483, 5: 437, 6: 340, 7: 489, 8: 390}
episode: 727/2000 -> reward: 77.06249999999996, steps:3897, time-taken: 2.22min, time-elasped: 1462.71min
-> berries picked: 60 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7236 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [657, 1074, 1139, 845, 704, 665, 746, 618, 788]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 25, 23, 20, 9, 7, 11, 7, 17]
	Time taken saving stuff: 0.00s

=== episode:728 Env-steps-taken:72864
 	picked: 91 |actions: {0: 679, 1: 687, 2: 633, 3: 545, 4: 468, 5: 513, 6: 515, 7: 609, 8: 421}
episode: 728/2000 -> reward: 123.34374999999984, steps:5070, time-taken: 2.55min, time-elasped: 1465.26min
-> berries picked: 91 of 800 | patches-visited: [0, 2, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7265 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [663, 1081, 1152, 846, 704, 665, 747, 616, 791]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 18, 11, 16, 10, 9, 9, 7, 12]
	Time taken saving stuff: 0.02s

=== episode:729 Env-steps-taken:61632
 	picked: 56 |actions: {0: 251, 1: 322, 2: 331, 3: 402, 4: 263, 5: 307, 6: 286, 7: 258, 8: 200}
episode: 729/2000 -> reward: 68.2916666666667, steps:2620, time-taken: 1.44min, time-elasped: 1466.71min
-> berries picked: 56 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7286 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [663, 1083, 1153, 851, 706, 671, 748, 615, 796]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 17, 19, 17, 17, 19, 8, 8, 21]
	Time taken saving stuff: 0.08s

=== episode:730 Env-steps-taken:72864
 	picked: 91 |actions: {0: 568, 1: 567, 2: 750, 3: 556, 4: 524, 5: 765, 6: 486, 7: 456, 8: 427}
episode: 730/2000 -> reward: 123.34374999999982, steps:5099, time-taken: 2.38min, time-elasped: 1469.09min
-> berries picked: 91 of 800 | patches-visited: [0, 4, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7297 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [669, 1085, 1153, 854, 708, 670, 746, 613, 799]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 18, 15, 13, 10, 16, 8, 8, 17]
	Time taken saving stuff: 0.17s

=== episode:73 Env-steps-taken:55872
 	picked: 28 |actions: {0: 509, 1: 141, 2: 79, 3: 190, 4: 235, 5: 11, 6: 45, 7: 62, 8: 102}

==================================================
eval-episode: 730 -> reward: 39.89583333333334, steps: 1374.0, wall-time: 34.13s
-> berries picked: 28 of 800 | patches-visited: [1, 8] | juice left:-0.00
==================================================


=== episode:731 Env-steps-taken:60768
 	picked: 52 |actions: {0: 507, 1: 515, 2: 430, 3: 425, 4: 485, 5: 652, 6: 356, 7: 513, 8: 424}
episode: 731/2000 -> reward: 62.078125000000064, steps:4307, time-taken: 2.23min, time-elasped: 1471.89min
-> berries picked: 52 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7289 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [666, 1081, 1150, 852, 710, 671, 743, 618, 798]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 23, 16, 23, 12, 8, 18, 14, 21]
	Time taken saving stuff: 0.02s

=== episode:732 Env-steps-taken:64800
 	picked: 67 |actions: {0: 445, 1: 708, 2: 773, 3: 551, 4: 544, 5: 492, 6: 384, 7: 540, 8: 462}
episode: 732/2000 -> reward: 83.71874999999999, steps:4899, time-taken: 3.34min, time-elasped: 1475.23min
-> berries picked: 67 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7300 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [668, 1078, 1152, 855, 714, 671, 746, 618, 798]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 23, 16, 15, 11, 12, 16, 9, 20]
	Time taken saving stuff: 0.00s

=== episode:733 Env-steps-taken:70464
 	picked: 92 |actions: {0: 654, 1: 509, 2: 606, 3: 502, 4: 502, 5: 639, 6: 506, 7: 433, 8: 393}
episode: 733/2000 -> reward: 112.22916666666654, steps:4744, time-taken: 2.30min, time-elasped: 1477.54min
-> berries picked: 92 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7329 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [669, 1077, 1154, 862, 711, 679, 755, 623, 799]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 17, 19, 20, 14, 12, 7, 8, 15]
	Time taken saving stuff: 0.01s

=== episode:734 Env-steps-taken:57504
 	picked: 35 |actions: {0: 177, 1: 364, 2: 429, 3: 315, 4: 440, 5: 234, 6: 185, 7: 157, 8: 278}
episode: 734/2000 -> reward: 47.994791666666686, steps:2579, time-taken: 1.32min, time-elasped: 1478.86min
-> berries picked: 35 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7329 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [668, 1074, 1153, 865, 714, 676, 753, 625, 801]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 15, 15, 16, 16, 14, 11, 14, 25]
	Time taken saving stuff: 0.01s

=== episode:735 Env-steps-taken:72384
 	picked: 87 |actions: {0: 566, 1: 785, 2: 770, 3: 482, 4: 570, 5: 690, 6: 558, 7: 626, 8: 431}
episode: 735/2000 -> reward: 122.51562499999984, steps:5478, time-taken: 2.46min, time-elasped: 1481.31min
-> berries picked: 87 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7334 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [667, 1082, 1158, 862, 711, 674, 751, 627, 802]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 13, 19, 9, 19, 13, 12, 9, 25]
	Time taken saving stuff: 0.01s

=== episode:736 Env-steps-taken:68352
 	picked: 73 |actions: {0: 574, 1: 474, 2: 699, 3: 354, 4: 391, 5: 395, 6: 286, 7: 267, 8: 340}
episode: 736/2000 -> reward: 102.31770833333324, steps:3780, time-taken: 2.00min, time-elasped: 1483.32min
-> berries picked: 73 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7364 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [673, 1084, 1159, 869, 719, 680, 748, 630, 802]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 24, 13, 19, 20, 15, 12, 7, 15]
	Time taken saving stuff: 0.00s

=== episode:737 Env-steps-taken:73440
 	picked: 94 |actions: {0: 548, 1: 584, 2: 707, 3: 564, 4: 606, 5: 586, 6: 522, 7: 515, 8: 354}
episode: 737/2000 -> reward: 125.72916666666649, steps:4986, time-taken: 2.30min, time-elasped: 1485.62min
-> berries picked: 94 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7378 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [679, 1081, 1163, 880, 719, 681, 739, 629, 807]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 18, 15, 12, 11, 5, 16, 13, 11]
	Time taken saving stuff: 0.01s

=== episode:738 Env-steps-taken:65952
 	picked: 63 |actions: {0: 477, 1: 535, 2: 762, 3: 417, 4: 530, 5: 461, 6: 340, 7: 399, 8: 376}
episode: 738/2000 -> reward: 90.39062499999996, steps:4297, time-taken: 2.04min, time-elasped: 1487.66min
-> berries picked: 63 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7388 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [680, 1081, 1168, 883, 724, 681, 738, 624, 809]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 23, 27, 10, 12, 17, 9, 6, 17]
	Time taken saving stuff: 0.01s

=== episode:739 Env-steps-taken:55104
 	picked: 25 |actions: {0: 236, 1: 254, 2: 461, 3: 201, 4: 203, 5: 181, 6: 123, 7: 154, 8: 188}
episode: 739/2000 -> reward: 35.56770833333333, steps:2001, time-taken: 1.11min, time-elasped: 1488.78min
-> berries picked: 25 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7389 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [679, 1083, 1170, 886, 724, 677, 736, 625, 809]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 13, 17, 11, 12, 15, 17, 13, 17]
	Time taken saving stuff: 0.01s

=== episode:740 Env-steps-taken:59904
 	picked: 48 |actions: {0: 459, 1: 408, 2: 588, 3: 197, 4: 332, 5: 320, 6: 241, 7: 233, 8: 198}
episode: 740/2000 -> reward: 57.80729166666671, steps:2976, time-taken: 1.46min, time-elasped: 1490.24min
-> berries picked: 48 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7386 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [679, 1078, 1167, 887, 726, 676, 736, 627, 810]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 16, 17, 16, 12, 14, 8, 10, 21]
	Time taken saving stuff: 0.16s

=== episode:74 Env-steps-taken:69312
 	picked: 74 |actions: {0: 1125, 1: 307, 2: 175, 3: 318, 4: 816, 5: 90, 6: 157, 7: 146, 8: 32}

==================================================
eval-episode: 740 -> reward: 105.31770833333324, steps: 3166.0, wall-time: 40.85s
-> berries picked: 74 of 800 | patches-visited: [1, 6] | juice left:-0.00
==================================================


=== episode:741 Env-steps-taken:61056
 	picked: 49 |actions: {0: 268, 1: 488, 2: 594, 3: 360, 4: 406, 5: 380, 6: 303, 7: 278, 8: 233}
episode: 741/2000 -> reward: 65.19270833333339, steps:3310, time-taken: 1.57min, time-elasped: 1492.49min
-> berries picked: 49 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7382 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [676, 1081, 1170, 890, 726, 670, 733, 628, 808]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 21, 19, 20, 14, 8, 5, 16, 18]
	Time taken saving stuff: 0.01s

=== episode:742 Env-steps-taken:68160
 	picked: 80 |actions: {0: 342, 1: 468, 2: 610, 3: 430, 4: 483, 5: 604, 6: 437, 7: 465, 8: 292}
episode: 742/2000 -> reward: 98.08854166666656, steps:4131, time-taken: 1.84min, time-elasped: 1494.33min
-> berries picked: 80 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7398 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [672, 1077, 1169, 893, 732, 671, 744, 630, 810]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 13, 17, 12, 8, 17, 12, 13, 19]
	Time taken saving stuff: 0.00s

=== episode:743 Env-steps-taken:56544
 	picked: 31 |actions: {0: 135, 1: 257, 2: 322, 3: 173, 4: 215, 5: 203, 6: 191, 7: 176, 8: 125}
episode: 743/2000 -> reward: 43.223958333333336, steps:1797, time-taken: 0.94min, time-elasped: 1495.27min
-> berries picked: 31 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7405 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [672, 1075, 1169, 893, 734, 675, 747, 631, 809]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 21, 10, 13, 11, 17, 10, 8, 14]
	Time taken saving stuff: 0.04s

=== episode:744 Env-steps-taken:62784
 	picked: 53 |actions: {0: 419, 1: 464, 2: 481, 3: 370, 4: 535, 5: 437, 6: 296, 7: 353, 8: 228}
episode: 744/2000 -> reward: 74.46354166666669, steps:3583, time-taken: 1.59min, time-elasped: 1496.86min
-> berries picked: 53 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7410 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [674, 1076, 1172, 898, 736, 670, 747, 630, 807]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 20, 22, 13, 10, 12, 14, 8, 20]
	Time taken saving stuff: 0.07s

=== episode:745 Env-steps-taken:55008
 	picked: 22 |actions: {0: 104, 1: 237, 2: 257, 3: 220, 4: 290, 5: 121, 6: 155, 7: 114, 8: 215}
episode: 745/2000 -> reward: 35.239583333333336, steps:1713, time-taken: 1.00min, time-elasped: 1497.86min
-> berries picked: 22 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7413 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [674, 1076, 1170, 904, 738, 666, 747, 632, 806]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 13, 18, 10, 13, 8, 9, 16, 20]
	Time taken saving stuff: 0.01s

=== episode:746 Env-steps-taken:65376
 	picked: 62 |actions: {0: 391, 1: 573, 2: 528, 3: 461, 4: 480, 5: 481, 6: 301, 7: 269, 8: 219}
episode: 746/2000 -> reward: 86.94791666666663, steps:3703, time-taken: 1.77min, time-elasped: 1499.63min
-> berries picked: 62 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7431 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [677, 1079, 1178, 907, 739, 668, 747, 629, 807]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 20, 18, 12, 15, 9, 13, 10, 23]
	Time taken saving stuff: 0.01s

=== episode:747 Env-steps-taken:62976
 	picked: 49 |actions: {0: 247, 1: 549, 2: 624, 3: 356, 4: 301, 5: 372, 6: 301, 7: 307, 8: 240}
episode: 747/2000 -> reward: 75.69270833333334, steps:3297, time-taken: 1.54min, time-elasped: 1501.18min
-> berries picked: 49 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7443 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [678, 1083, 1180, 912, 740, 663, 749, 631, 807]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 19, 18, 16, 10, 11, 11, 8, 21]
	Time taken saving stuff: 0.00s

=== episode:748 Env-steps-taken:65856
 	picked: 66 |actions: {0: 434, 1: 647, 2: 656, 3: 470, 4: 740, 5: 732, 6: 494, 7: 436, 8: 469}
episode: 748/2000 -> reward: 89.33333333333329, steps:5078, time-taken: 2.16min, time-elasped: 1503.34min
-> berries picked: 66 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7447 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [676, 1081, 1183, 911, 742, 663, 751, 632, 808]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 12, 12, 12, 8, 11, 14, 11, 16]
	Time taken saving stuff: 0.01s

=== episode:749 Env-steps-taken:60672
 	picked: 49 |actions: {0: 343, 1: 400, 2: 425, 3: 421, 4: 562, 5: 390, 6: 281, 7: 261, 8: 237}
episode: 749/2000 -> reward: 63.692708333333385, steps:3320, time-taken: 1.55min, time-elasped: 1504.89min
-> berries picked: 49 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7455 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [683, 1083, 1184, 915, 743, 660, 749, 630, 808]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 17, 24, 20, 11, 8, 16, 9, 22]
	Time taken saving stuff: 0.00s

=== episode:750 Env-steps-taken:59712
 	picked: 43 |actions: {0: 236, 1: 404, 2: 460, 3: 340, 4: 364, 5: 312, 6: 285, 7: 317, 8: 316}
episode: 750/2000 -> reward: 59.036458333333385, steps:3034, time-taken: 1.49min, time-elasped: 1506.38min
-> berries picked: 43 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7460 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [685, 1084, 1187, 915, 742, 660, 747, 632, 808]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 28, 23, 12, 9, 4, 15, 13, 23]
	Time taken saving stuff: 0.06s

=== episode:75 Env-steps-taken:77376
 	picked: 110 |actions: {0: 391, 1: 849, 2: 627, 3: 441, 4: 522, 5: 198, 6: 284, 7: 419, 8: 690}

==================================================
eval-episode: 750 -> reward: 146.31249999999997, steps: 4421.0, wall-time: 42.89s
-> berries picked: 110 of 800 | patches-visited: [1, 6] | juice left:-0.00
==================================================


=== episode:751 Env-steps-taken:50688
 	picked: 11 |actions: {0: 82, 1: 170, 2: 270, 3: 90, 4: 72, 5: 62, 6: 79, 7: 63, 8: 98}
episode: 751/2000 -> reward: 13.36979166666667, steps:986, time-taken: 0.67min, time-elasped: 1507.77min
-> berries picked: 11 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7460 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [684, 1084, 1189, 915, 742, 659, 745, 635, 807]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 20, 17, 15, 13, 14, 11, 12, 16]
	Time taken saving stuff: 0.01s

=== episode:752 Env-steps-taken:58656
 	picked: 35 |actions: {0: 214, 1: 216, 2: 329, 3: 301, 4: 178, 5: 124, 6: 110, 7: 159, 8: 133}
episode: 752/2000 -> reward: 53.994791666666714, steps:1764, time-taken: 1.08min, time-elasped: 1508.86min
-> berries picked: 35 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7465 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [688, 1084, 1192, 914, 736, 662, 745, 635, 809]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 17, 19, 15, 20, 14, 11, 9, 23]
	Time taken saving stuff: 0.00s

=== episode:753 Env-steps-taken:60288
 	picked: 40 |actions: {0: 225, 1: 410, 2: 394, 3: 220, 4: 299, 5: 205, 6: 241, 7: 195, 8: 212}
episode: 753/2000 -> reward: 62.20833333333337, steps:2401, time-taken: 1.36min, time-elasped: 1510.22min
-> berries picked: 40 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7463 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [687, 1094, 1196, 907, 734, 661, 741, 630, 813]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 18, 17, 13, 11, 9, 10, 16, 29]
	Time taken saving stuff: 0.10s

=== episode:754 Env-steps-taken:60384
 	picked: 44 |actions: {0: 282, 1: 330, 2: 526, 3: 356, 4: 449, 5: 236, 6: 198, 7: 278, 8: 166}
episode: 754/2000 -> reward: 62.47916666666672, steps:2821, time-taken: 1.39min, time-elasped: 1511.61min
-> berries picked: 44 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7472 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [689, 1097, 1198, 906, 737, 665, 736, 630, 814]
	| approx positives in sample 512: 154
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 26, 23, 17, 12, 23, 9, 13, 15]
	Time taken saving stuff: 0.10s

=== episode:755 Env-steps-taken:77280
 	picked: 96 |actions: {0: 545, 1: 860, 2: 959, 3: 575, 4: 831, 5: 687, 6: 556, 7: 549, 8: 368}
episode: 755/2000 -> reward: 148.00000000000003, steps:5930, time-taken: 2.62min, time-elasped: 1514.24min
-> berries picked: 96 of 800 | patches-visited: [0, 4, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7486 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [685, 1103, 1200, 908, 736, 665, 740, 632, 817]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 21, 15, 8, 9, 14, 9, 12, 22]
	Time taken saving stuff: 0.00s

=== episode:756 Env-steps-taken:66144
 	picked: 61 |actions: {0: 307, 1: 611, 2: 617, 3: 391, 4: 543, 5: 554, 6: 280, 7: 340, 8: 236}
episode: 756/2000 -> reward: 91.50520833333327, steps:3879, time-taken: 2.26min, time-elasped: 1516.50min
-> berries picked: 61 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7496 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [681, 1105, 1203, 910, 743, 670, 738, 629, 817]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 17, 15, 21, 16, 6, 11, 12, 20]
	Time taken saving stuff: 0.07s

=== episode:757 Env-steps-taken:59328
 	picked: 39 |actions: {0: 193, 1: 435, 2: 409, 3: 269, 4: 366, 5: 329, 6: 209, 7: 166, 8: 172}
episode: 757/2000 -> reward: 57.26562500000003, steps:2548, time-taken: 4.67min, time-elasped: 1521.18min
-> berries picked: 39 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7488 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [681, 1104, 1202, 915, 741, 669, 733, 625, 818]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 19, 18, 14, 10, 12, 10, 10, 19]
	Time taken saving stuff: 0.04s

=== episode:758 Env-steps-taken:77952
 	picked: 105 |actions: {0: 601, 1: 745, 2: 891, 3: 622, 4: 558, 5: 697, 6: 473, 7: 410, 8: 457}
episode: 758/2000 -> reward: 151.0416666666667, steps:5454, time-taken: 5.14min, time-elasped: 1526.33min
-> berries picked: 105 of 800 | patches-visited: [0, 7, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7513 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [682, 1108, 1210, 916, 741, 677, 733, 624, 822]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 15, 17, 21, 15, 13, 17, 11, 18]
	Time taken saving stuff: 0.00s

=== episode:759 Env-steps-taken:67872
 	picked: 74 |actions: {0: 449, 1: 695, 2: 614, 3: 498, 4: 439, 5: 615, 6: 409, 7: 487, 8: 291}
episode: 759/2000 -> reward: 100.2604166666666, steps:4497, time-taken: 1.76min, time-elasped: 1528.09min
-> berries picked: 74 of 800 | patches-visited: [0, 2, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7531 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [683, 1114, 1209, 920, 734, 684, 735, 628, 824]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 18, 10, 14, 14, 9, 10, 6, 14]
	Time taken saving stuff: 0.01s

=== episode:760 Env-steps-taken:58560
 	picked: 39 |actions: {0: 346, 1: 606, 2: 1132, 3: 573, 4: 405, 5: 385, 6: 338, 7: 362, 8: 319}
episode: 760/2000 -> reward: 53.265625000000036, steps:4466, time-taken: 1.86min, time-elasped: 1529.95min
-> berries picked: 39 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7516 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [685, 1106, 1210, 916, 735, 681, 730, 628, 825]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 16, 16, 15, 12, 12, 12, 7, 21]
	Time taken saving stuff: 0.07s

=== episode:76 Env-steps-taken:55584
 	picked: 27 |actions: {0: 161, 1: 1769, 2: 131, 3: 72, 4: 6, 5: 1732, 6: 4, 7: 103, 8: 16}

==================================================
eval-episode: 760 -> reward: 37.95312500000001, steps: 3994.0, wall-time: 47.42s
-> berries picked: 27 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:761 Env-steps-taken:64608
 	picked: 62 |actions: {0: 479, 1: 598, 2: 764, 3: 628, 4: 522, 5: 555, 6: 482, 7: 384, 8: 294}
episode: 761/2000 -> reward: 83.44791666666663, steps:4706, time-taken: 2.22min, time-elasped: 1532.97min
-> berries picked: 62 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7515 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [686, 1106, 1215, 915, 734, 679, 728, 626, 826]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 25, 22, 14, 13, 16, 10, 10, 13]
	Time taken saving stuff: 0.10s

=== episode:762 Env-steps-taken:66144
 	picked: 67 |actions: {0: 567, 1: 531, 2: 567, 3: 424, 4: 396, 5: 445, 6: 388, 7: 329, 8: 274}
episode: 762/2000 -> reward: 91.66145833333329, steps:3921, time-taken: 1.85min, time-elasped: 1534.82min
-> berries picked: 67 of 800 | patches-visited: [0, 1, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7518 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [690, 1112, 1206, 916, 731, 681, 728, 622, 832]
	| approx positives in sample 512: 147
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 14, 19, 23, 16, 15, 19, 9, 18]
	Time taken saving stuff: 0.11s

=== episode:763 Env-steps-taken:67584
 	picked: 65 |actions: {0: 280, 1: 471, 2: 667, 3: 395, 4: 537, 5: 409, 6: 377, 7: 317, 8: 278}
episode: 763/2000 -> reward: 98.7760416666666, steps:3731, time-taken: 1.74min, time-elasped: 1536.56min
-> berries picked: 65 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7534 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [689, 1117, 1207, 914, 736, 684, 730, 622, 835]
	| approx positives in sample 512: 95
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 10, 13, 11, 10, 8, 10, 12, 14]
	Time taken saving stuff: 0.02s

=== episode:764 Env-steps-taken:59616
 	picked: 43 |actions: {0: 307, 1: 302, 2: 501, 3: 301, 4: 326, 5: 290, 6: 269, 7: 242, 8: 166}
episode: 764/2000 -> reward: 58.03645833333338, steps:2704, time-taken: 1.39min, time-elasped: 1537.95min
-> berries picked: 43 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7551 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [693, 1120, 1208, 917, 739, 682, 732, 626, 834]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 25, 15, 22, 8, 11, 16, 11, 22]
	Time taken saving stuff: 0.02s

=== episode:765 Env-steps-taken:50016
 	picked: 6 |actions: {0: 22, 1: 52, 2: 81, 3: 32, 4: 48, 5: 39, 6: 38, 7: 24, 8: 29}
episode: 765/2000 -> reward: 10.156250000000002, steps:365, time-taken: 0.41min, time-elasped: 1538.37min
-> berries picked: 6 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7553 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [694, 1120, 1208, 915, 739, 683, 732, 628, 834]
	| approx positives in sample 512: 146
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 17, 26, 17, 12, 11, 10, 15, 27]
	Time taken saving stuff: 0.08s

=== episode:766 Env-steps-taken:61152
 	picked: 52 |actions: {0: 407, 1: 352, 2: 695, 3: 375, 4: 386, 5: 605, 6: 334, 7: 362, 8: 238}
episode: 766/2000 -> reward: 65.52083333333337, steps:3754, time-taken: 1.81min, time-elasped: 1540.18min
-> berries picked: 52 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7524 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [688, 1109, 1200, 918, 733, 682, 732, 630, 832]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 20, 16, 14, 15, 12, 13, 11, 17]
	Time taken saving stuff: 0.10s

=== episode:767 Env-steps-taken:75456
 	picked: 99 |actions: {0: 547, 1: 622, 2: 876, 3: 543, 4: 646, 5: 711, 6: 536, 7: 681, 8: 347}
episode: 767/2000 -> reward: 138.3281249999999, steps:5509, time-taken: 2.54min, time-elasped: 1542.72min
-> berries picked: 99 of 800 | patches-visited: [0, 1, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7557 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [692, 1111, 1204, 913, 744, 689, 736, 635, 833]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 21, 20, 15, 6, 11, 10, 7, 26]
	Time taken saving stuff: 0.11s

=== episode:768 Env-steps-taken:57408
 	picked: 36 |actions: {0: 250, 1: 537, 2: 711, 3: 335, 4: 241, 5: 229, 6: 243, 7: 250, 8: 325}
episode: 768/2000 -> reward: 45.99479166666669, steps:3121, time-taken: 1.49min, time-elasped: 1544.22min
-> berries picked: 36 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7533 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [686, 1110, 1201, 911, 739, 686, 730, 637, 833]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 20, 13, 15, 15, 9, 14, 20, 24]
	Time taken saving stuff: 0.02s

=== episode:769 Env-steps-taken:66816
 	picked: 70 |actions: {0: 311, 1: 435, 2: 672, 3: 381, 4: 416, 5: 303, 6: 398, 7: 354, 8: 202}
episode: 769/2000 -> reward: 93.10416666666659, steps:3472, time-taken: 1.65min, time-elasped: 1545.88min
-> berries picked: 70 of 800 | patches-visited: [0, 2, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7550 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [685, 1111, 1202, 920, 742, 692, 729, 633, 836]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 22, 17, 14, 20, 10, 16, 8, 18]
	Time taken saving stuff: 0.01s

=== episode:770 Env-steps-taken:65952
 	picked: 65 |actions: {0: 392, 1: 343, 2: 572, 3: 352, 4: 414, 5: 374, 6: 346, 7: 327, 8: 242}
episode: 770/2000 -> reward: 90.27604166666663, steps:3362, time-taken: 1.52min, time-elasped: 1547.40min
-> berries picked: 65 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7555 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [687, 1110, 1203, 921, 744, 690, 724, 637, 839]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 10, 16, 17, 7, 12, 8, 13, 19]
	Time taken saving stuff: 0.09s

=== episode:77 Env-steps-taken:55488
 	picked: 26 |actions: {0: 272, 1: 99, 2: 246, 3: 35, 4: 13, 5: 159, 6: 76, 7: 40, 8: 25}

==================================================
eval-episode: 770 -> reward: 37.510416666666664, steps: 965.0, wall-time: 32.96s
-> berries picked: 26 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:771 Env-steps-taken:57792
 	picked: 36 |actions: {0: 259, 1: 329, 2: 322, 3: 280, 4: 282, 5: 202, 6: 166, 7: 187, 8: 164}
episode: 771/2000 -> reward: 46.10937500000002, steps:2191, time-taken: 1.14min, time-elasped: 1549.09min
-> berries picked: 36 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7544 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [682, 1110, 1195, 924, 742, 686, 724, 640, 841]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 18, 9, 15, 11, 13, 14, 10, 17]
	Time taken saving stuff: 0.00s

=== episode:772 Env-steps-taken:63936
 	picked: 57 |actions: {0: 409, 1: 578, 2: 503, 3: 344, 4: 337, 5: 439, 6: 398, 7: 567, 8: 231}
episode: 772/2000 -> reward: 79.73437500000001, steps:3806, time-taken: 1.73min, time-elasped: 1550.82min
-> berries picked: 57 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7544 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [681, 1113, 1189, 920, 746, 681, 729, 646, 839]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 25, 9, 12, 8, 16, 7, 11, 29]
	Time taken saving stuff: 0.01s

=== episode:773 Env-steps-taken:65472
 	picked: 59 |actions: {0: 313, 1: 451, 2: 1214, 3: 507, 4: 460, 5: 486, 6: 412, 7: 310, 8: 282}
episode: 773/2000 -> reward: 87.23437499999996, steps:4435, time-taken: 1.92min, time-elasped: 1552.74min
-> berries picked: 59 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7536 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [679, 1112, 1187, 918, 748, 681, 731, 641, 839]
	| approx positives in sample 512: 154
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 20, 28, 20, 16, 5, 16, 11, 24]
	Time taken saving stuff: 0.01s

=== episode:774 Env-steps-taken:69504
 	picked: 82 |actions: {0: 443, 1: 696, 2: 931, 3: 464, 4: 652, 5: 590, 6: 438, 7: 605, 8: 533}
episode: 774/2000 -> reward: 106.41666666666654, steps:5352, time-taken: 2.43min, time-elasped: 1555.18min
-> berries picked: 82 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7542 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [666, 1115, 1194, 921, 747, 685, 734, 645, 835]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 11, 14, 18, 14, 16, 6, 13, 17]
	Time taken saving stuff: 0.00s

=== episode:775 Env-steps-taken:73440
 	picked: 93 |actions: {0: 545, 1: 507, 2: 836, 3: 575, 4: 579, 5: 653, 6: 513, 7: 595, 8: 364}
episode: 775/2000 -> reward: 127.67187499999982, steps:5167, time-taken: 2.39min, time-elasped: 1557.57min
-> berries picked: 93 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7556 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [663, 1117, 1195, 925, 746, 687, 739, 646, 838]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 19, 20, 10, 17, 21, 12, 12, 24]
	Time taken saving stuff: 0.01s

=== episode:776 Env-steps-taken:69888
 	picked: 84 |actions: {0: 562, 1: 435, 2: 665, 3: 417, 4: 553, 5: 481, 6: 439, 7: 398, 8: 309}
episode: 776/2000 -> reward: 109.68749999999987, steps:4259, time-taken: 2.09min, time-elasped: 1559.67min
-> berries picked: 84 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7573 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [666, 1120, 1199, 929, 744, 688, 739, 651, 837]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 11, 21, 25, 12, 9, 11, 11, 15]
	Time taken saving stuff: 0.00s

=== episode:777 Env-steps-taken:62592
 	picked: 56 |actions: {0: 400, 1: 517, 2: 457, 3: 308, 4: 468, 5: 457, 6: 272, 7: 349, 8: 210}
episode: 777/2000 -> reward: 73.29166666666667, steps:3438, time-taken: 1.62min, time-elasped: 1561.29min
-> berries picked: 56 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7576 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [669, 1123, 1200, 920, 744, 692, 743, 649, 836]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 17, 14, 10, 9, 7, 10, 11, 20]
	Time taken saving stuff: 0.00s

=== episode:778 Env-steps-taken:67296
 	picked: 69 |actions: {0: 473, 1: 712, 2: 842, 3: 433, 4: 581, 5: 564, 6: 611, 7: 422, 8: 377}
episode: 778/2000 -> reward: 97.54687499999994, steps:5015, time-taken: 2.33min, time-elasped: 1563.62min
-> berries picked: 69 of 800 | patches-visited: [0, 2, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7588 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [669, 1122, 1203, 922, 746, 696, 741, 650, 839]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 18, 13, 17, 14, 18, 8, 9, 17]
	Time taken saving stuff: 0.01s

=== episode:779 Env-steps-taken:66720
 	picked: 68 |actions: {0: 445, 1: 466, 2: 715, 3: 442, 4: 640, 5: 423, 6: 392, 7: 343, 8: 325}
episode: 779/2000 -> reward: 93.21874999999996, steps:4191, time-taken: 1.91min, time-elasped: 1565.53min
-> berries picked: 68 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7598 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [669, 1124, 1207, 926, 747, 695, 744, 644, 842]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 16, 14, 11, 17, 16, 8, 10, 19]
	Time taken saving stuff: 0.02s

=== episode:780 Env-steps-taken:60576
 	picked: 43 |actions: {0: 325, 1: 334, 2: 561, 3: 236, 4: 274, 5: 199, 6: 241, 7: 273, 8: 137}
episode: 780/2000 -> reward: 63.53645833333339, steps:2580, time-taken: 1.36min, time-elasped: 1566.90min
-> berries picked: 43 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7611 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [673, 1125, 1208, 929, 743, 695, 745, 650, 843]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 29, 21, 15, 12, 15, 12, 13, 19]
	Time taken saving stuff: 0.06s

=== episode:78 Env-steps-taken:62400
 	picked: 47 |actions: {0: 99, 1: 510, 2: 394, 3: 75, 4: 493, 5: 71, 6: 98, 7: 66, 8: 117}

==================================================
eval-episode: 780 -> reward: 73.30729166666667, steps: 1923.0, wall-time: 33.89s
-> berries picked: 47 of 800 | patches-visited: [0, 1, 8] | juice left:-0.00
==================================================


=== episode:781 Env-steps-taken:63264
 	picked: 61 |actions: {0: 446, 1: 597, 2: 943, 3: 396, 4: 659, 5: 545, 6: 389, 7: 456, 8: 451}
episode: 781/2000 -> reward: 76.50520833333331, steps:4882, time-taken: 2.24min, time-elasped: 1569.70min
-> berries picked: 61 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7586 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [671, 1125, 1208, 922, 741, 688, 744, 645, 842]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 13, 13, 10, 14, 11, 8, 10, 35]
	Time taken saving stuff: 0.01s

=== episode:782 Env-steps-taken:65280
 	picked: 72 |actions: {0: 595, 1: 728, 2: 1025, 3: 557, 4: 678, 5: 600, 6: 506, 7: 575, 8: 550}
episode: 782/2000 -> reward: 85.87499999999996, steps:5814, time-taken: 2.34min, time-elasped: 1572.04min
-> berries picked: 72 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7566 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [677, 1118, 1206, 919, 737, 682, 749, 642, 836]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 9, 13, 19, 13, 12, 10, 9, 18]
	Time taken saving stuff: 0.01s

=== episode:783 Env-steps-taken:72192
 	picked: 87 |actions: {0: 607, 1: 646, 2: 975, 3: 484, 4: 672, 5: 598, 6: 539, 7: 574, 8: 314}
episode: 783/2000 -> reward: 121.51562499999987, steps:5409, time-taken: 2.45min, time-elasped: 1574.50min
-> berries picked: 87 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7584 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [681, 1124, 1215, 917, 742, 681, 741, 646, 837]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 14, 22, 9, 10, 12, 9, 6, 17]
	Time taken saving stuff: 0.10s

=== episode:784 Env-steps-taken:57792
 	picked: 36 |actions: {0: 224, 1: 402, 2: 381, 3: 226, 4: 275, 5: 336, 6: 303, 7: 228, 8: 151}
episode: 784/2000 -> reward: 48.93750000000004, steps:2526, time-taken: 1.36min, time-elasped: 1575.86min
-> berries picked: 36 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7584 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [675, 1125, 1220, 918, 740, 682, 742, 645, 837]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 18, 19, 14, 11, 7, 15, 12, 11]
	Time taken saving stuff: 0.00s

=== episode:785 Env-steps-taken:61344
 	picked: 52 |actions: {0: 366, 1: 505, 2: 642, 3: 344, 4: 341, 5: 443, 6: 348, 7: 508, 8: 272}
episode: 785/2000 -> reward: 65.13541666666671, steps:3769, time-taken: 1.64min, time-elasped: 1577.50min
-> berries picked: 52 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7570 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [679, 1124, 1222, 913, 738, 677, 744, 638, 835]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 21, 15, 22, 10, 14, 10, 7, 29]
	Time taken saving stuff: 0.03s

=== episode:786 Env-steps-taken:76416
 	picked: 101 |actions: {0: 687, 1: 616, 2: 735, 3: 446, 4: 537, 5: 533, 6: 567, 7: 621, 8: 311}
episode: 786/2000 -> reward: 143.2135416666666, steps:5053, time-taken: 2.31min, time-elasped: 1579.82min
-> berries picked: 101 of 800 | patches-visited: [0, 2, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7566 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [686, 1119, 1226, 912, 736, 677, 742, 633, 835]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 13, 13, 23, 10, 14, 17, 7, 12]
	Time taken saving stuff: 0.08s

=== episode:787 Env-steps-taken:65568
 	picked: 65 |actions: {0: 497, 1: 362, 2: 525, 3: 331, 4: 412, 5: 448, 6: 346, 7: 349, 8: 251}
episode: 787/2000 -> reward: 88.27604166666663, steps:3521, time-taken: 1.72min, time-elasped: 1581.54min
-> berries picked: 65 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7581 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [690, 1119, 1234, 911, 740, 682, 735, 633, 837]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 15, 25, 14, 15, 9, 7, 8, 18]
	Time taken saving stuff: 0.01s

=== episode:788 Env-steps-taken:70368
 	picked: 80 |actions: {0: 429, 1: 825, 2: 990, 3: 531, 4: 706, 5: 653, 6: 604, 7: 459, 8: 424}
episode: 788/2000 -> reward: 111.03124999999989, steps:5621, time-taken: 2.45min, time-elasped: 1583.99min
-> berries picked: 80 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7582 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [689, 1118, 1232, 917, 742, 683, 738, 628, 835]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 17, 21, 19, 11, 18, 13, 7, 16]
	Time taken saving stuff: 0.09s

=== episode:789 Env-steps-taken:53184
 	picked: 15 |actions: {0: 130, 1: 168, 2: 297, 3: 99, 4: 96, 5: 77, 6: 101, 7: 151, 8: 132}
episode: 789/2000 -> reward: 26.140625, steps:1251, time-taken: 0.77min, time-elasped: 1584.77min
-> berries picked: 15 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7571 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [688, 1122, 1228, 915, 740, 683, 734, 626, 835]
	| approx positives in sample 512: 139
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 19, 14, 18, 19, 12, 15, 11, 21]
	Time taken saving stuff: 0.01s

=== episode:790 Env-steps-taken:59136
 	picked: 48 |actions: {0: 317, 1: 314, 2: 476, 3: 355, 4: 395, 5: 382, 6: 356, 7: 291, 8: 202}
episode: 790/2000 -> reward: 55.25000000000005, steps:3088, time-taken: 1.45min, time-elasped: 1586.23min
-> berries picked: 48 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7574 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [690, 1119, 1229, 914, 744, 681, 736, 627, 834]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 6, 17, 11, 12, 9, 18, 10, 19]
	Time taken saving stuff: 0.05s

=== episode:79 Env-steps-taken:65760
 	picked: 69 |actions: {0: 991, 1: 440, 2: 917, 3: 155, 4: 649, 5: 212, 6: 274, 7: 350, 8: 1058}

==================================================
eval-episode: 790 -> reward: 88.54687499999993, steps: 5046.0, wall-time: 50.65s
-> berries picked: 69 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:791 Env-steps-taken:64896
 	picked: 63 |actions: {0: 613, 1: 606, 2: 990, 3: 645, 4: 656, 5: 681, 6: 525, 7: 602, 8: 582}
episode: 791/2000 -> reward: 84.39062499999997, steps:5900, time-taken: 2.68min, time-elasped: 1589.76min
-> berries picked: 63 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7571 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [691, 1119, 1231, 914, 741, 681, 733, 626, 835]
	| approx positives in sample 512: 154
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 24, 21, 24, 19, 15, 11, 8, 25]
	Time taken saving stuff: 0.10s

=== episode:792 Env-steps-taken:57888
 	picked: 38 |actions: {0: 247, 1: 378, 2: 580, 3: 253, 4: 354, 5: 326, 6: 275, 7: 358, 8: 260}
episode: 792/2000 -> reward: 49.32291666666669, steps:3031, time-taken: 1.51min, time-elasped: 1591.27min
-> berries picked: 38 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7564 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [688, 1123, 1236, 909, 741, 676, 732, 628, 831]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 13, 14, 13, 9, 13, 11, 10, 20]
	Time taken saving stuff: 0.00s

=== episode:793 Env-steps-taken:68352
 	picked: 75 |actions: {0: 475, 1: 639, 2: 795, 3: 445, 4: 633, 5: 520, 6: 348, 7: 526, 8: 346}
episode: 793/2000 -> reward: 100.26041666666659, steps:4727, time-taken: 2.15min, time-elasped: 1593.43min
-> berries picked: 75 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7579 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [688, 1136, 1240, 911, 739, 677, 733, 622, 833]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 16, 16, 23, 17, 15, 9, 11, 15]
	Time taken saving stuff: 0.02s

=== episode:794 Env-steps-taken:70752
 	picked: 91 |actions: {0: 542, 1: 551, 2: 801, 3: 560, 4: 498, 5: 652, 6: 437, 7: 497, 8: 342}
episode: 794/2000 -> reward: 113.78645833333319, steps:4880, time-taken: 2.22min, time-elasped: 1595.65min
-> berries picked: 91 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7597 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [684, 1142, 1238, 916, 748, 677, 731, 627, 834]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 18, 16, 19, 13, 11, 11, 7, 15]
	Time taken saving stuff: 0.02s

=== episode:795 Env-steps-taken:70368
 	picked: 79 |actions: {0: 508, 1: 458, 2: 746, 3: 422, 4: 470, 5: 484, 6: 433, 7: 495, 8: 263}
episode: 795/2000 -> reward: 110.58854166666653, steps:4279, time-taken: 1.91min, time-elasped: 1597.57min
-> berries picked: 79 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7610 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [687, 1151, 1241, 914, 749, 676, 733, 625, 834]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 15, 22, 15, 10, 9, 19, 7, 16]
	Time taken saving stuff: 0.02s

=== episode:796 Env-steps-taken:53760
 	picked: 22 |actions: {0: 143, 1: 134, 2: 302, 3: 164, 4: 127, 5: 115, 6: 144, 7: 111, 8: 90}
episode: 796/2000 -> reward: 28.296875000000007, steps:1330, time-taken: 0.82min, time-elasped: 1598.39min
-> berries picked: 22 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7617 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [687, 1150, 1242, 918, 748, 677, 736, 625, 834]
	| approx positives in sample 512: 143
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 27, 14, 15, 17, 15, 10, 13, 20]
	Time taken saving stuff: 0.10s

=== episode:797 Env-steps-taken:62976
 	picked: 56 |actions: {0: 493, 1: 434, 2: 542, 3: 356, 4: 315, 5: 360, 6: 334, 7: 542, 8: 222}
episode: 797/2000 -> reward: 75.2916666666667, steps:3598, time-taken: 1.73min, time-elasped: 1600.13min
-> berries picked: 56 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7608 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [693, 1151, 1241, 912, 750, 675, 732, 621, 833]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 17, 17, 12, 11, 13, 11, 11, 15]
	Time taken saving stuff: 0.02s

=== episode:798 Env-steps-taken:64512
 	picked: 65 |actions: {0: 433, 1: 657, 2: 818, 3: 467, 4: 382, 5: 502, 6: 349, 7: 357, 8: 367}
episode: 798/2000 -> reward: 82.77604166666664, steps:4332, time-taken: 2.08min, time-elasped: 1602.21min
-> berries picked: 65 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7611 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [696, 1157, 1242, 912, 751, 672, 728, 620, 833]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 11, 17, 27, 9, 8, 14, 10, 20]
	Time taken saving stuff: 0.09s

=== episode:799 Env-steps-taken:59424
 	picked: 44 |actions: {0: 193, 1: 450, 2: 522, 3: 327, 4: 337, 5: 304, 6: 352, 7: 284, 8: 194}
episode: 799/2000 -> reward: 57.093750000000036, steps:2963, time-taken: 1.49min, time-elasped: 1603.71min
-> berries picked: 44 of 800 | patches-visited: [0, 1, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7620 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [693, 1158, 1244, 913, 747, 675, 730, 622, 838]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 17, 19, 13, 9, 10, 15, 6, 31]
	Time taken saving stuff: 0.02s

=== episode:800 Env-steps-taken:64992
 	picked: 72 |actions: {0: 620, 1: 690, 2: 862, 3: 553, 4: 608, 5: 508, 6: 500, 7: 555, 8: 446}
episode: 800/2000 -> reward: 84.87499999999999, steps:5342, time-taken: 2.28min, time-elasped: 1606.00min
-> berries picked: 72 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7632 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [692, 1164, 1247, 919, 741, 676, 727, 624, 842]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 20, 14, 9, 11, 18, 14, 13, 22]
	Time taken saving stuff: 0.15s

=== episode:80 Env-steps-taken:69504
 	picked: 79 |actions: {0: 412, 1: 589, 2: 635, 3: 321, 4: 124, 5: 284, 6: 158, 7: 225, 8: 775}

==================================================
eval-episode: 800 -> reward: 107.97395833333323, steps: 3523.0, wall-time: 43.50s
-> berries picked: 79 of 800 | patches-visited: [1, 7] | juice left:-0.00
==================================================


=== episode:801 Env-steps-taken:66720
 	picked: 66 |actions: {0: 439, 1: 508, 2: 756, 3: 344, 4: 502, 5: 493, 6: 400, 7: 478, 8: 247}
episode: 801/2000 -> reward: 94.21874999999994, steps:4167, time-taken: 2.03min, time-elasped: 1608.76min
-> berries picked: 66 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7629 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [695, 1161, 1247, 920, 745, 677, 727, 615, 842]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 11, 22, 9, 22, 16, 14, 8, 12]
	Time taken saving stuff: 0.10s

=== episode:802 Env-steps-taken:67200
 	picked: 78 |actions: {0: 502, 1: 682, 2: 648, 3: 430, 4: 484, 5: 429, 6: 461, 7: 485, 8: 302}
episode: 802/2000 -> reward: 92.70312499999991, steps:4423, time-taken: 2.02min, time-elasped: 1610.78min
-> berries picked: 78 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7626 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [693, 1154, 1254, 925, 743, 676, 723, 617, 841]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 19, 24, 20, 6, 8, 11, 12, 15]
	Time taken saving stuff: 0.03s

=== episode:803 Env-steps-taken:70656
 	picked: 87 |actions: {0: 541, 1: 562, 2: 799, 3: 454, 4: 494, 5: 641, 6: 519, 7: 591, 8: 304}
episode: 803/2000 -> reward: 113.51562499999987, steps:4905, time-taken: 2.33min, time-elasped: 1613.12min
-> berries picked: 87 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7643 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [704, 1153, 1259, 921, 746, 675, 719, 623, 843]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 16, 17, 15, 8, 9, 9, 5, 15]
	Time taken saving stuff: 0.09s

=== episode:804 Env-steps-taken:63744
 	picked: 57 |actions: {0: 372, 1: 510, 2: 433, 3: 287, 4: 379, 5: 324, 6: 261, 7: 338, 8: 200}
episode: 804/2000 -> reward: 77.29166666666666, steps:3104, time-taken: 1.51min, time-elasped: 1614.64min
-> berries picked: 57 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7653 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [708, 1155, 1256, 927, 746, 676, 718, 622, 845]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 18, 29, 21, 8, 9, 9, 7, 14]
	Time taken saving stuff: 0.09s

=== episode:805 Env-steps-taken:63648
 	picked: 63 |actions: {0: 405, 1: 379, 2: 549, 3: 310, 4: 477, 5: 420, 6: 249, 7: 346, 8: 232}
episode: 805/2000 -> reward: 78.4479166666667, steps:3367, time-taken: 1.61min, time-elasped: 1616.25min
-> berries picked: 63 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7665 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [710, 1156, 1260, 931, 747, 678, 716, 623, 844]
	| approx positives in sample 512: 145
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 21, 25, 20, 15, 12, 9, 4, 19]
	Time taken saving stuff: 0.10s

=== episode:806 Env-steps-taken:62784
 	picked: 57 |actions: {0: 419, 1: 518, 2: 618, 3: 447, 4: 327, 5: 409, 6: 408, 7: 316, 8: 186}
episode: 806/2000 -> reward: 72.29166666666669, steps:3648, time-taken: 1.80min, time-elasped: 1618.06min
-> berries picked: 57 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7646 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [710, 1151, 1260, 930, 738, 675, 718, 618, 846]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 21, 20, 13, 9, 10, 12, 13, 21]
	Time taken saving stuff: 0.01s

=== episode:807 Env-steps-taken:65376
 	picked: 61 |actions: {0: 397, 1: 539, 2: 500, 3: 494, 4: 346, 5: 428, 6: 356, 7: 411, 8: 224}
episode: 807/2000 -> reward: 88.00520833333329, steps:3695, time-taken: 1.72min, time-elasped: 1619.77min
-> berries picked: 61 of 800 | patches-visited: [0, 5, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7657 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [712, 1146, 1259, 930, 743, 680, 716, 623, 848]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 13, 20, 20, 10, 13, 11, 10, 18]
	Time taken saving stuff: 0.09s

=== episode:808 Env-steps-taken:68640
 	picked: 75 |actions: {0: 519, 1: 719, 2: 636, 3: 513, 4: 629, 5: 618, 6: 509, 7: 600, 8: 302}
episode: 808/2000 -> reward: 103.70312499999989, steps:5045, time-taken: 2.47min, time-elasped: 1622.25min
-> berries picked: 75 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7674 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [716, 1145, 1254, 928, 745, 685, 717, 630, 854]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 18, 23, 13, 18, 15, 14, 8, 17]
	Time taken saving stuff: 0.01s

=== episode:809 Env-steps-taken:69888
 	picked: 81 |actions: {0: 510, 1: 728, 2: 653, 3: 681, 4: 456, 5: 315, 6: 341, 7: 383, 8: 315}
episode: 809/2000 -> reward: 108.53124999999987, steps:4382, time-taken: 1.96min, time-elasped: 1624.21min
-> berries picked: 81 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7684 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [712, 1151, 1258, 934, 744, 683, 718, 629, 855]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 19, 15, 15, 17, 13, 14, 10, 15]
	Time taken saving stuff: 0.16s

=== episode:810 Env-steps-taken:57696
 	picked: 36 |actions: {0: 239, 1: 340, 2: 286, 3: 169, 4: 170, 5: 142, 6: 169, 7: 149, 8: 97}
episode: 810/2000 -> reward: 48.437500000000014, steps:1761, time-taken: 1.14min, time-elasped: 1625.35min
-> berries picked: 36 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7690 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [713, 1157, 1262, 930, 745, 683, 714, 631, 855]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 20, 17, 11, 9, 9, 15, 8, 27]
	Time taken saving stuff: 0.08s

=== episode:81 Env-steps-taken:57312
 	picked: 34 |actions: {0: 143, 1: 340, 2: 315, 3: 118, 4: 29, 5: 29, 6: 165, 7: 54, 8: 114}

==================================================
eval-episode: 810 -> reward: 47.05208333333335, steps: 1307.0, wall-time: 26.81s
-> berries picked: 34 of 800 | patches-visited: [1, 7] | juice left:-0.00
==================================================


=== episode:811 Env-steps-taken:55488
 	picked: 30 |actions: {0: 270, 1: 300, 2: 450, 3: 204, 4: 230, 5: 321, 6: 274, 7: 314, 8: 200}
episode: 811/2000 -> reward: 37.28125000000001, steps:2563, time-taken: 1.27min, time-elasped: 1627.07min
-> berries picked: 30 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7658 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [711, 1154, 1250, 923, 746, 680, 712, 627, 855]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 16, 12, 9, 13, 9, 15, 10, 16]
	Time taken saving stuff: 0.10s

=== episode:812 Env-steps-taken:65856
 	picked: 72 |actions: {0: 566, 1: 610, 2: 1102, 3: 509, 4: 672, 5: 628, 6: 542, 7: 561, 8: 374}
episode: 812/2000 -> reward: 88.87499999999993, steps:5564, time-taken: 2.41min, time-elasped: 1629.48min
-> berries picked: 72 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7629 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [706, 1150, 1243, 922, 748, 676, 711, 621, 852]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 24, 15, 12, 9, 12, 12, 8, 20]
	Time taken saving stuff: 0.10s

=== episode:813 Env-steps-taken:56352
 	picked: 34 |actions: {0: 204, 1: 261, 2: 494, 3: 279, 4: 213, 5: 184, 6: 167, 7: 194, 8: 150}
episode: 813/2000 -> reward: 42.05208333333335, steps:2146, time-taken: 1.25min, time-elasped: 1630.73min
-> berries picked: 34 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7630 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [707, 1150, 1243, 922, 746, 676, 710, 621, 855]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 15, 14, 13, 15, 10, 11, 13, 18]
	Time taken saving stuff: 0.02s

=== episode:814 Env-steps-taken:65088
 	picked: 70 |actions: {0: 663, 1: 554, 2: 920, 3: 696, 4: 692, 5: 516, 6: 523, 7: 571, 8: 446}
episode: 814/2000 -> reward: 84.98958333333329, steps:5581, time-taken: 2.39min, time-elasped: 1633.13min
-> berries picked: 70 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7603 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [707, 1141, 1236, 930, 741, 670, 707, 617, 854]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 16, 15, 18, 14, 13, 11, 9, 19]
	Time taken saving stuff: 0.10s

=== episode:815 Env-steps-taken:61248
 	picked: 48 |actions: {0: 320, 1: 423, 2: 407, 3: 321, 4: 335, 5: 346, 6: 390, 7: 402, 8: 365}
episode: 815/2000 -> reward: 66.25000000000004, steps:3309, time-taken: 1.62min, time-elasped: 1634.75min
-> berries picked: 48 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7609 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [705, 1147, 1234, 932, 741, 672, 707, 617, 854]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 18, 17, 14, 10, 7, 16, 8, 21]
	Time taken saving stuff: 0.02s

=== episode:816 Env-steps-taken:50784
 	picked: 12 |actions: {0: 92, 1: 104, 2: 155, 3: 86, 4: 129, 5: 87, 6: 67, 7: 162, 8: 63}
episode: 816/2000 -> reward: 13.812500000000004, steps:945, time-taken: 0.68min, time-elasped: 1635.43min
-> berries picked: 12 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7603 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [707, 1148, 1233, 929, 738, 671, 707, 617, 853]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 16, 18, 23, 9, 10, 15, 9, 19]
	Time taken saving stuff: 0.10s

=== episode:817 Env-steps-taken:66432
 	picked: 78 |actions: {0: 491, 1: 558, 2: 742, 3: 646, 4: 717, 5: 553, 6: 481, 7: 618, 8: 339}
episode: 817/2000 -> reward: 91.53124999999991, steps:5145, time-taken: 2.27min, time-elasped: 1637.70min
-> berries picked: 78 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7592 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [706, 1142, 1230, 929, 745, 673, 704, 611, 852]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 12, 19, 15, 10, 13, 16, 10, 19]
	Time taken saving stuff: 0.02s

=== episode:818 Env-steps-taken:62976
 	picked: 54 |actions: {0: 297, 1: 517, 2: 584, 3: 438, 4: 442, 5: 367, 6: 346, 7: 356, 8: 236}
episode: 818/2000 -> reward: 75.40625, steps:3583, time-taken: 1.83min, time-elasped: 1639.54min
-> berries picked: 54 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7595 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [700, 1145, 1236, 925, 744, 675, 707, 609, 854]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 19, 20, 13, 9, 10, 9, 9, 18]
	Time taken saving stuff: 0.09s

=== episode:819 Env-steps-taken:70176
 	picked: 74 |actions: {0: 405, 1: 461, 2: 564, 3: 529, 4: 618, 5: 461, 6: 422, 7: 383, 8: 247}
episode: 819/2000 -> reward: 111.76041666666656, steps:4090, time-taken: 2.07min, time-elasped: 1641.61min
-> berries picked: 74 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7598 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [698, 1144, 1239, 921, 749, 681, 705, 607, 854]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 20, 22, 11, 13, 13, 11, 10, 18]
	Time taken saving stuff: 0.01s

=== episode:820 Env-steps-taken:67104
 	picked: 68 |actions: {0: 448, 1: 532, 2: 612, 3: 521, 4: 571, 5: 457, 6: 357, 7: 466, 8: 295}
episode: 820/2000 -> reward: 96.10416666666659, steps:4259, time-taken: 2.06min, time-elasped: 1643.67min
-> berries picked: 68 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7614 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [697, 1149, 1243, 927, 754, 677, 704, 606, 857]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 14, 12, 18, 15, 10, 7, 6, 24]
	Time taken saving stuff: 0.18s

=== episode:82 Env-steps-taken:61152
 	picked: 46 |actions: {0: 198, 1: 362, 2: 253, 3: 104, 4: 443, 5: 113, 6: 58, 7: 173, 8: 211}

==================================================
eval-episode: 820 -> reward: 65.86458333333339, steps: 1915.0, wall-time: 44.15s
-> berries picked: 46 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:821 Env-steps-taken:77664
 	picked: 106 |actions: {0: 657, 1: 827, 2: 853, 3: 734, 4: 709, 5: 613, 6: 609, 7: 645, 8: 401}
episode: 821/2000 -> reward: 148.98437499999997, steps:6048, time-taken: 2.83min, time-elasped: 1647.25min
-> berries picked: 106 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7627 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [705, 1148, 1249, 925, 759, 672, 700, 608, 861]
	| approx positives in sample 512: 143
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 22, 24, 15, 14, 13, 13, 10, 20]
	Time taken saving stuff: 0.09s

=== episode:822 Env-steps-taken:75456
 	picked: 107 |actions: {0: 723, 1: 663, 2: 710, 3: 583, 4: 591, 5: 666, 6: 625, 7: 845, 8: 360}
episode: 822/2000 -> reward: 136.92708333333323, steps:5766, time-taken: 2.67min, time-elasped: 1649.92min
-> berries picked: 107 of 800 | patches-visited: [0, 4, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7632 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [709, 1151, 1249, 921, 762, 677, 697, 605, 861]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 18, 18, 15, 14, 8, 12, 8, 18]
	Time taken saving stuff: 0.02s

=== episode:823 Env-steps-taken:77376
 	picked: 107 |actions: {0: 760, 1: 617, 2: 900, 3: 680, 4: 650, 5: 702, 6: 773, 7: 804, 8: 383}
episode: 823/2000 -> reward: 147.36979166666663, steps:6269, time-taken: 2.82min, time-elasped: 1652.75min
-> berries picked: 107 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7654 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [713, 1156, 1251, 929, 759, 677, 700, 608, 861]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 19, 18, 11, 11, 8, 11, 10, 20]
	Time taken saving stuff: 0.02s

=== episode:824 Env-steps-taken:63072
 	picked: 53 |actions: {0: 404, 1: 490, 2: 441, 3: 341, 4: 368, 5: 413, 6: 346, 7: 609, 8: 252}
episode: 824/2000 -> reward: 75.96354166666666, steps:3664, time-taken: 1.72min, time-elasped: 1654.47min
-> berries picked: 53 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7667 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [715, 1158, 1253, 927, 757, 680, 701, 614, 862]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 13, 21, 16, 6, 10, 12, 5, 11]
	Time taken saving stuff: 0.09s

=== episode:825 Env-steps-taken:51648
 	picked: 13 |actions: {0: 70, 1: 81, 2: 108, 3: 66, 4: 95, 5: 125, 6: 137, 7: 151, 8: 82}
episode: 825/2000 -> reward: 18.75520833333333, steps:915, time-taken: 0.72min, time-elasped: 1655.19min
-> berries picked: 13 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7674 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [717, 1157, 1254, 927, 758, 683, 700, 614, 864]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 11, 18, 20, 8, 8, 7, 10, 15]
	Time taken saving stuff: 0.01s

=== episode:826 Env-steps-taken:77376
 	picked: 110 |actions: {0: 773, 1: 662, 2: 947, 3: 666, 4: 552, 5: 723, 6: 491, 7: 634, 8: 522}
episode: 826/2000 -> reward: 147.1979166666666, steps:5970, time-taken: 2.78min, time-elasped: 1657.97min
-> berries picked: 110 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7677 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [727, 1158, 1252, 930, 755, 675, 705, 615, 860]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 18, 19, 14, 16, 8, 7, 11, 20]
	Time taken saving stuff: 0.01s

=== episode:827 Env-steps-taken:65952
 	picked: 61 |actions: {0: 505, 1: 365, 2: 533, 3: 381, 4: 350, 5: 412, 6: 398, 7: 324, 8: 455}
episode: 827/2000 -> reward: 91.00520833333331, steps:3723, time-taken: 1.85min, time-elasped: 1659.83min
-> berries picked: 61 of 800 | patches-visited: [0, 1, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7666 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [729, 1156, 1244, 933, 754, 672, 705, 612, 861]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 11, 18, 11, 11, 12, 15, 7, 16]
	Time taken saving stuff: 0.08s

=== episode:828 Env-steps-taken:70944
 	picked: 84 |actions: {0: 545, 1: 501, 2: 675, 3: 639, 4: 576, 5: 716, 6: 482, 7: 583, 8: 372}
episode: 828/2000 -> reward: 113.74479166666656, steps:5089, time-taken: 2.36min, time-elasped: 1662.20min
-> berries picked: 84 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7681 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [736, 1154, 1247, 935, 755, 679, 701, 612, 862]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 19, 15, 15, 17, 15, 11, 8, 16]
	Time taken saving stuff: 0.10s

=== episode:829 Env-steps-taken:63936
 	picked: 64 |actions: {0: 718, 1: 523, 2: 711, 3: 399, 4: 538, 5: 566, 6: 614, 7: 793, 8: 464}
episode: 829/2000 -> reward: 79.3333333333333, steps:5326, time-taken: 2.45min, time-elasped: 1664.65min
-> berries picked: 64 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7664 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [732, 1160, 1243, 928, 757, 672, 698, 612, 862]
	| approx positives in sample 512: 147
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 23, 21, 16, 17, 16, 9, 7, 22]
	Time taken saving stuff: 0.02s

=== episode:830 Env-steps-taken:73536
 	picked: 90 |actions: {0: 623, 1: 520, 2: 732, 3: 417, 4: 592, 5: 474, 6: 630, 7: 553, 8: 359}
episode: 830/2000 -> reward: 128.34374999999983, steps:4900, time-taken: 2.30min, time-elasped: 1666.95min
-> berries picked: 90 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7678 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [739, 1160, 1247, 929, 759, 675, 701, 606, 862]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 14, 15, 12, 12, 10, 8, 9, 18]
	Time taken saving stuff: 0.14s

=== episode:83 Env-steps-taken:54144
 	picked: 22 |actions: {0: 198, 1: 73, 2: 163, 3: 38, 4: 21, 5: 10, 6: 37, 7: 40, 8: 68}

==================================================
eval-episode: 830 -> reward: 30.739583333333332, steps: 648.0, wall-time: 31.28s
-> berries picked: 22 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:831 Env-steps-taken:67872
 	picked: 79 |actions: {0: 621, 1: 582, 2: 875, 3: 501, 4: 446, 5: 824, 6: 450, 7: 665, 8: 364}
episode: 831/2000 -> reward: 99.47395833333324, steps:5328, time-taken: 2.38min, time-elasped: 1669.85min
-> berries picked: 79 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7694 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [740, 1159, 1260, 929, 757, 673, 696, 617, 863]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 17, 13, 19, 16, 12, 15, 4, 16]
	Time taken saving stuff: 0.10s

=== episode:832 Env-steps-taken:50208
 	picked: 8 |actions: {0: 126, 1: 135, 2: 204, 3: 90, 4: 113, 5: 71, 6: 53, 7: 53, 8: 128}
episode: 832/2000 -> reward: 11.041666666666664, steps:973, time-taken: 0.82min, time-elasped: 1670.67min
-> berries picked: 8 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7691 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [738, 1160, 1260, 929, 759, 671, 695, 616, 863]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 19, 21, 10, 7, 11, 14, 11, 20]
	Time taken saving stuff: 0.11s

=== episode:833 Env-steps-taken:63552
 	picked: 60 |actions: {0: 700, 1: 505, 2: 630, 3: 489, 4: 640, 5: 561, 6: 399, 7: 435, 8: 325}
episode: 833/2000 -> reward: 78.06249999999999, steps:4684, time-taken: 2.21min, time-elasped: 1672.88min
-> berries picked: 60 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7685 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [731, 1160, 1262, 926, 760, 677, 692, 613, 864]
	| approx positives in sample 512: 139
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 14, 12, 16, 12, 11, 19, 12, 30]
	Time taken saving stuff: 0.11s

=== episode:834 Env-steps-taken:69024
 	picked: 87 |actions: {0: 697, 1: 619, 2: 901, 3: 599, 4: 724, 5: 640, 6: 602, 7: 601, 8: 399}
episode: 834/2000 -> reward: 105.01562499999987, steps:5782, time-taken: 2.72min, time-elasped: 1675.60min
-> berries picked: 87 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7715 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [740, 1158, 1264, 935, 759, 684, 695, 614, 866]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 16, 17, 14, 11, 11, 14, 13, 15]
	Time taken saving stuff: 0.01s

=== episode:835 Env-steps-taken:69696
 	picked: 80 |actions: {0: 580, 1: 625, 2: 871, 3: 610, 4: 602, 5: 551, 6: 522, 7: 703, 8: 415}
episode: 835/2000 -> reward: 106.9739583333332, steps:5479, time-taken: 2.45min, time-elasped: 1678.05min
-> berries picked: 80 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7727 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [739, 1168, 1267, 933, 762, 681, 695, 615, 867]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 20, 14, 14, 11, 15, 7, 15, 22]
	Time taken saving stuff: 0.11s

=== episode:836 Env-steps-taken:73248
 	picked: 94 |actions: {0: 659, 1: 632, 2: 834, 3: 680, 4: 667, 5: 814, 6: 576, 7: 748, 8: 454}
episode: 836/2000 -> reward: 126.22916666666653, steps:6064, time-taken: 2.55min, time-elasped: 1680.60min
-> berries picked: 94 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7738 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [742, 1163, 1268, 933, 768, 688, 698, 609, 869]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 15, 16, 12, 12, 6, 7, 12, 17]
	Time taken saving stuff: 0.00s

=== episode:837 Env-steps-taken:63648
 	picked: 70 |actions: {0: 688, 1: 498, 2: 771, 3: 532, 4: 594, 5: 574, 6: 516, 7: 787, 8: 353}
episode: 837/2000 -> reward: 77.98958333333329, steps:5313, time-taken: 2.29min, time-elasped: 1682.90min
-> berries picked: 70 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7737 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [746, 1162, 1263, 929, 766, 689, 699, 610, 873]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 21, 17, 16, 16, 18, 6, 12, 19]
	Time taken saving stuff: 0.00s

=== episode:838 Env-steps-taken:70368
 	picked: 89 |actions: {0: 780, 1: 606, 2: 744, 3: 613, 4: 639, 5: 821, 6: 520, 7: 706, 8: 396}
episode: 838/2000 -> reward: 111.90104166666652, steps:5825, time-taken: 2.64min, time-elasped: 1685.55min
-> berries picked: 89 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7757 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [746, 1172, 1267, 932, 765, 692, 699, 612, 872]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 18, 13, 18, 11, 8, 9, 10, 14]
	Time taken saving stuff: 0.00s

=== episode:839 Env-steps-taken:66144
 	picked: 68 |actions: {0: 514, 1: 465, 2: 535, 3: 631, 4: 392, 5: 402, 6: 408, 7: 433, 8: 323}
episode: 839/2000 -> reward: 91.10416666666661, steps:4103, time-taken: 2.03min, time-elasped: 1687.58min
-> berries picked: 68 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7771 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [753, 1174, 1260, 939, 771, 693, 698, 611, 872]
	| approx positives in sample 512: 146
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 15, 20, 15, 22, 18, 10, 15, 17]
	Time taken saving stuff: 0.07s

=== episode:840 Env-steps-taken:58752
 	picked: 37 |actions: {0: 257, 1: 368, 2: 938, 3: 373, 4: 389, 5: 287, 6: 243, 7: 308, 8: 328}
episode: 840/2000 -> reward: 54.38020833333337, steps:3491, time-taken: 1.68min, time-elasped: 1689.27min
-> berries picked: 37 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7762 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [749, 1175, 1262, 938, 770, 691, 697, 607, 873]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 16, 17, 12, 10, 15, 10, 15, 18]
	Time taken saving stuff: 0.15s

=== episode:84 Env-steps-taken:62592
 	picked: 51 |actions: {0: 233, 1: 186, 2: 724, 3: 58, 4: 560, 5: 105, 6: 126, 7: 193, 8: 399}

==================================================
eval-episode: 840 -> reward: 72.69270833333336, steps: 2584.0, wall-time: 38.49s
-> berries picked: 51 of 800 | patches-visited: [1, 7] | juice left:-0.00
==================================================


=== episode:841 Env-steps-taken:63264
 	picked: 55 |actions: {0: 303, 1: 444, 2: 593, 3: 436, 4: 562, 5: 323, 6: 386, 7: 376, 8: 296}
episode: 841/2000 -> reward: 76.84895833333333, steps:3719, time-taken: 1.97min, time-elasped: 1691.88min
-> berries picked: 55 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7753 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [748, 1172, 1257, 940, 773, 683, 700, 607, 873]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 13, 19, 22, 12, 14, 7, 13, 17]
	Time taken saving stuff: 0.08s

=== episode:842 Env-steps-taken:64320
 	picked: 67 |actions: {0: 405, 1: 434, 2: 481, 3: 474, 4: 575, 5: 368, 6: 474, 7: 391, 8: 215}
episode: 842/2000 -> reward: 81.66145833333333, steps:3817, time-taken: 1.80min, time-elasped: 1693.69min
-> berries picked: 67 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7766 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [747, 1175, 1264, 943, 775, 679, 699, 610, 874]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 19, 13, 11, 15, 12, 12, 11, 26]
	Time taken saving stuff: 0.03s

=== episode:843 Env-steps-taken:67584
 	picked: 75 |actions: {0: 451, 1: 564, 2: 651, 3: 621, 4: 864, 5: 623, 6: 495, 7: 570, 8: 411}
episode: 843/2000 -> reward: 97.31770833333323, steps:5250, time-taken: 2.46min, time-elasped: 1696.15min
-> berries picked: 75 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7784 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [755, 1177, 1267, 943, 782, 682, 696, 608, 874]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 12, 19, 12, 19, 7, 4, 7, 17]
	Time taken saving stuff: 0.00s

=== episode:844 Env-steps-taken:64704
 	picked: 70 |actions: {0: 638, 1: 646, 2: 1063, 3: 515, 4: 578, 5: 518, 6: 511, 7: 761, 8: 421}
episode: 844/2000 -> reward: 82.98958333333331, steps:5651, time-taken: 2.46min, time-elasped: 1698.61min
-> berries picked: 70 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7782 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [755, 1181, 1267, 945, 780, 685, 695, 600, 874]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 18, 24, 17, 15, 7, 11, 6, 21]
	Time taken saving stuff: 0.01s

=== episode:845 Env-steps-taken:72288
 	picked: 92 |actions: {0: 605, 1: 712, 2: 917, 3: 656, 4: 637, 5: 569, 6: 526, 7: 551, 8: 351}
episode: 845/2000 -> reward: 121.34374999999987, steps:5524, time-taken: 2.55min, time-elasped: 1701.16min
-> berries picked: 92 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7806 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [756, 1185, 1272, 948, 788, 685, 693, 604, 875]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 17, 22, 13, 16, 10, 15, 14, 12]
	Time taken saving stuff: 0.01s

=== episode:846 Env-steps-taken:65568
 	picked: 65 |actions: {0: 463, 1: 603, 2: 677, 3: 462, 4: 577, 5: 574, 6: 497, 7: 517, 8: 413}
episode: 846/2000 -> reward: 88.27604166666663, steps:4783, time-taken: 2.14min, time-elasped: 1703.31min
-> berries picked: 65 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7801 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [755, 1181, 1272, 945, 789, 686, 692, 609, 872]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 16, 22, 16, 8, 12, 10, 7, 21]
	Time taken saving stuff: 0.09s

=== episode:847 Env-steps-taken:69984
 	picked: 79 |actions: {0: 449, 1: 673, 2: 779, 3: 556, 4: 473, 5: 469, 6: 366, 7: 489, 8: 407}
episode: 847/2000 -> reward: 110.47395833333321, steps:4661, time-taken: 2.17min, time-elasped: 1705.48min
-> berries picked: 79 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7816 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [753, 1189, 1268, 953, 788, 688, 691, 613, 873]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 21, 11, 16, 15, 10, 13, 9, 16]
	Time taken saving stuff: 0.00s

=== episode:848 Env-steps-taken:65184
 	picked: 63 |actions: {0: 505, 1: 705, 2: 626, 3: 422, 4: 500, 5: 463, 6: 403, 7: 478, 8: 359}
episode: 848/2000 -> reward: 86.39062499999997, steps:4461, time-taken: 2.00min, time-elasped: 1707.48min
-> berries picked: 63 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7828 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [750, 1192, 1277, 949, 788, 690, 689, 616, 877]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 11, 17, 20, 15, 13, 8, 9, 18]
	Time taken saving stuff: 0.00s

=== episode:849 Env-steps-taken:71904
 	picked: 92 |actions: {0: 540, 1: 560, 2: 803, 3: 699, 4: 908, 5: 690, 6: 520, 7: 745, 8: 440}
episode: 849/2000 -> reward: 119.72916666666647, steps:5905, time-taken: 2.61min, time-elasped: 1710.09min
-> berries picked: 92 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7838 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [753, 1189, 1281, 954, 789, 694, 683, 617, 878]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 22, 16, 14, 13, 12, 9, 8, 23]
	Time taken saving stuff: 0.09s

=== episode:850 Env-steps-taken:84960
 	picked: 129 |actions: {0: 919, 1: 693, 2: 831, 3: 700, 4: 628, 5: 527, 6: 682, 7: 753, 8: 453}
episode: 850/2000 -> reward: 183.28125000000017, steps:6186, time-taken: 2.86min, time-elasped: 1712.95min
-> berries picked: 129 of 800 | patches-visited: [0, 2, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7871 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [765, 1197, 1283, 957, 786, 690, 684, 629, 880]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 19, 19, 13, 10, 15, 14, 10, 13]
	Time taken saving stuff: 0.17s

=== episode:85 Env-steps-taken:86112
 	picked: 151 |actions: {0: 560, 1: 295, 2: 1318, 3: 263, 4: 1061, 5: 746, 6: 135, 7: 1296, 8: 443}

==================================================
eval-episode: 850 -> reward: 190.84895833333368, steps: 6117.0, wall-time: 51.35s
-> berries picked: 151 of 800 | patches-visited: [0, 1, 7] | juice left:-0.00
==================================================


=== episode:851 Env-steps-taken:71712
 	picked: 88 |actions: {0: 781, 1: 665, 2: 721, 3: 534, 4: 650, 5: 488, 6: 405, 7: 656, 8: 540}
episode: 851/2000 -> reward: 117.01562499999986, steps:5440, time-taken: 2.62min, time-elasped: 1716.43min
-> berries picked: 88 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7864 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [771, 1201, 1276, 956, 786, 690, 685, 622, 877]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 18, 17, 18, 12, 10, 15, 16, 18]
	Time taken saving stuff: 0.01s

=== episode:852 Env-steps-taken:69600
 	picked: 81 |actions: {0: 388, 1: 649, 2: 633, 3: 496, 4: 637, 5: 582, 6: 420, 7: 598, 8: 535}
episode: 852/2000 -> reward: 108.35937499999991, steps:4938, time-taken: 2.64min, time-elasped: 1719.07min
-> berries picked: 81 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7851 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [760, 1201, 1273, 959, 792, 689, 682, 620, 875]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 15, 14, 20, 10, 9, 7, 14, 22]
	Time taken saving stuff: 0.08s

=== episode:853 Env-steps-taken:70368
 	picked: 80 |actions: {0: 549, 1: 787, 2: 776, 3: 627, 4: 617, 5: 496, 6: 413, 7: 631, 8: 468}
episode: 853/2000 -> reward: 112.41666666666653, steps:5364, time-taken: 2.45min, time-elasped: 1721.52min
-> berries picked: 80 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7866 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [758, 1206, 1275, 968, 790, 688, 683, 621, 877]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 24, 15, 16, 16, 5, 9, 8, 20]
	Time taken saving stuff: 0.00s

=== episode:854 Env-steps-taken:66816
 	picked: 76 |actions: {0: 696, 1: 592, 2: 795, 3: 550, 4: 672, 5: 703, 6: 484, 7: 501, 8: 465}
episode: 854/2000 -> reward: 93.64583333333326, steps:5458, time-taken: 2.45min, time-elasped: 1723.97min
-> berries picked: 76 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7880 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [761, 1206, 1280, 973, 794, 683, 684, 622, 877]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 18, 13, 7, 13, 11, 9, 5, 29]
	Time taken saving stuff: 0.01s

=== episode:855 Env-steps-taken:65472
 	picked: 73 |actions: {0: 521, 1: 482, 2: 901, 3: 571, 4: 1003, 5: 644, 6: 509, 7: 629, 8: 577}
episode: 855/2000 -> reward: 86.8177083333333, steps:5837, time-taken: 2.55min, time-elasped: 1726.52min
-> berries picked: 73 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7897 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [760, 1212, 1283, 977, 796, 689, 686, 615, 879]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 12, 20, 16, 8, 9, 7, 9, 27]
	Time taken saving stuff: 0.02s

=== episode:856 Env-steps-taken:58272
 	picked: 36 |actions: {0: 253, 1: 252, 2: 397, 3: 281, 4: 255, 5: 263, 6: 235, 7: 191, 8: 309}
episode: 856/2000 -> reward: 52.43750000000002, steps:2436, time-taken: 1.25min, time-elasped: 1727.77min
-> berries picked: 36 of 800 | patches-visited: [0, 4, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7887 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [754, 1208, 1280, 978, 800, 690, 683, 612, 882]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 17, 17, 20, 12, 15, 8, 5, 28]
	Time taken saving stuff: 0.01s

=== episode:857 Env-steps-taken:72192
 	picked: 86 |actions: {0: 635, 1: 771, 2: 930, 3: 649, 4: 687, 5: 568, 6: 478, 7: 504, 8: 756}
episode: 857/2000 -> reward: 121.57291666666652, steps:5978, time-taken: 2.59min, time-elasped: 1730.37min
-> berries picked: 86 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7889 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [752, 1203, 1285, 975, 804, 686, 685, 614, 885]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 16, 18, 14, 8, 9, 10, 13, 18]
	Time taken saving stuff: 0.02s

=== episode:858 Env-steps-taken:75264
 	picked: 94 |actions: {0: 604, 1: 797, 2: 802, 3: 582, 4: 778, 5: 793, 6: 689, 7: 621, 8: 614}
episode: 858/2000 -> reward: 136.72916666666657, steps:6280, time-taken: 2.89min, time-elasped: 1733.27min
-> berries picked: 94 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7896 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [747, 1207, 1287, 975, 804, 686, 688, 616, 886]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 19, 23, 21, 13, 10, 2, 7, 15]
	Time taken saving stuff: 0.01s

=== episode:859 Env-steps-taken:63552
 	picked: 60 |actions: {0: 430, 1: 330, 2: 555, 3: 375, 4: 563, 5: 508, 6: 386, 7: 511, 8: 315}
episode: 859/2000 -> reward: 78.0625, steps:3973, time-taken: 1.80min, time-elasped: 1735.07min
-> berries picked: 60 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7907 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [746, 1208, 1286, 978, 807, 689, 686, 621, 886]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 20, 16, 12, 14, 9, 12, 16, 16]
	Time taken saving stuff: 0.08s

=== episode:860 Env-steps-taken:70752
 	picked: 87 |actions: {0: 614, 1: 648, 2: 628, 3: 453, 4: 496, 5: 502, 6: 533, 7: 631, 8: 414}
episode: 860/2000 -> reward: 114.01562499999986, steps:4919, time-taken: 2.29min, time-elasped: 1737.36min
-> berries picked: 87 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7923 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [755, 1209, 1288, 978, 807, 687, 691, 619, 889]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 11, 19, 21, 11, 10, 12, 13, 26]
	Time taken saving stuff: 0.07s

=== episode:86 Env-steps-taken:86688
 	picked: 153 |actions: {0: 459, 1: 602, 2: 636, 3: 264, 4: 986, 5: 307, 6: 748, 7: 762, 8: 262}

==================================================
eval-episode: 860 -> reward: 191.84895833333357, steps: 5026.0, wall-time: 56.92s
-> berries picked: 153 of 800 | patches-visited: [0, 1, 3] | juice left:-0.00
==================================================


=== episode:861 Env-steps-taken:60192
 	picked: 47 |actions: {0: 415, 1: 525, 2: 659, 3: 343, 4: 439, 5: 538, 6: 336, 7: 502, 8: 491}
episode: 861/2000 -> reward: 60.86458333333338, steps:4248, time-taken: 1.95min, time-elasped: 1740.26min
-> berries picked: 47 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7908 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [751, 1209, 1289, 975, 806, 685, 686, 615, 892]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 17, 14, 15, 14, 4, 7, 11, 24]
	Time taken saving stuff: 0.08s

=== episode:862 Env-steps-taken:74688
 	picked: 105 |actions: {0: 782, 1: 831, 2: 699, 3: 575, 4: 744, 5: 666, 6: 516, 7: 736, 8: 442}
episode: 862/2000 -> reward: 133.4843749999999, steps:5991, time-taken: 2.82min, time-elasped: 1743.08min
-> berries picked: 105 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7924 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [759, 1210, 1286, 977, 811, 688, 688, 612, 893]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 18, 20, 16, 12, 8, 15, 10, 18]
	Time taken saving stuff: 0.10s

=== episode:863 Env-steps-taken:69408
 	picked: 89 |actions: {0: 561, 1: 562, 2: 775, 3: 509, 4: 886, 5: 615, 6: 495, 7: 601, 8: 397}
episode: 863/2000 -> reward: 106.90104166666653, steps:5401, time-taken: 2.48min, time-elasped: 1745.56min
-> berries picked: 89 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7935 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [759, 1212, 1280, 982, 812, 694, 693, 609, 894]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 19, 26, 15, 16, 14, 9, 14, 18]
	Time taken saving stuff: 0.08s

=== episode:864 Env-steps-taken:65952
 	picked: 67 |actions: {0: 400, 1: 436, 2: 661, 3: 423, 4: 487, 5: 448, 6: 477, 7: 454, 8: 263}
episode: 864/2000 -> reward: 90.66145833333329, steps:4049, time-taken: 1.99min, time-elasped: 1747.56min
-> berries picked: 67 of 800 | patches-visited: [0, 3, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7950 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [762, 1215, 1284, 979, 815, 697, 695, 606, 897]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 12, 26, 17, 7, 11, 9, 11, 18]
	Time taken saving stuff: 0.02s

=== episode:865 Env-steps-taken:74208
 	picked: 100 |actions: {0: 673, 1: 653, 2: 851, 3: 613, 4: 896, 5: 598, 6: 550, 7: 648, 8: 382}
episode: 865/2000 -> reward: 131.27083333333317, steps:5864, time-taken: 2.55min, time-elasped: 1750.11min
-> berries picked: 100 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7972 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [760, 1215, 1293, 984, 816, 702, 698, 606, 898]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 20, 16, 21, 15, 10, 12, 14, 20]
	Time taken saving stuff: 0.01s

=== episode:866 Env-steps-taken:60000
 	picked: 46 |actions: {0: 317, 1: 345, 2: 431, 3: 298, 4: 461, 5: 380, 6: 310, 7: 377, 8: 219}
episode: 866/2000 -> reward: 59.86458333333339, steps:3138, time-taken: 1.53min, time-elasped: 1751.65min
-> berries picked: 46 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7979 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [757, 1219, 1296, 986, 814, 706, 698, 605, 898]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 18, 17, 13, 16, 9, 17, 6, 27]
	Time taken saving stuff: 0.01s

=== episode:867 Env-steps-taken:65568
 	picked: 60 |actions: {0: 370, 1: 462, 2: 432, 3: 328, 4: 439, 5: 204, 6: 240, 7: 383, 8: 246}
episode: 867/2000 -> reward: 85.29166666666664, steps:3104, time-taken: 1.61min, time-elasped: 1753.26min
-> berries picked: 60 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7992 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [760, 1225, 1298, 987, 812, 705, 696, 607, 902]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 21, 17, 15, 19, 11, 14, 14, 21]
	Time taken saving stuff: 0.01s

=== episode:868 Env-steps-taken:73536
 	picked: 88 |actions: {0: 696, 1: 708, 2: 659, 3: 511, 4: 650, 5: 488, 6: 647, 7: 773, 8: 359}
episode: 868/2000 -> reward: 127.01562499999986, steps:5491, time-taken: 2.48min, time-elasped: 1755.74min
-> berries picked: 88 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8015 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [768, 1236, 1299, 978, 814, 705, 700, 609, 906]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 22, 21, 10, 14, 10, 8, 9, 15]
	Time taken saving stuff: 0.09s

=== episode:869 Env-steps-taken:65376
 	picked: 62 |actions: {0: 532, 1: 612, 2: 664, 3: 541, 4: 588, 5: 473, 6: 430, 7: 530, 8: 355}
episode: 869/2000 -> reward: 86.94791666666664, steps:4725, time-taken: 2.14min, time-elasped: 1757.88min
-> berries picked: 62 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8007 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [766, 1235, 1302, 981, 815, 705, 692, 605, 906]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 17, 20, 10, 15, 9, 8, 7, 13]
	Time taken saving stuff: 0.10s

=== episode:870 Env-steps-taken:66816
 	picked: 73 |actions: {0: 743, 1: 732, 2: 610, 3: 632, 4: 777, 5: 559, 6: 511, 7: 826, 8: 349}
episode: 870/2000 -> reward: 94.31770833333324, steps:5739, time-taken: 2.55min, time-elasped: 1760.44min
-> berries picked: 73 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8004 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [777, 1232, 1296, 976, 810, 704, 690, 611, 908]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 22, 19, 17, 15, 9, 8, 11, 16]
	Time taken saving stuff: 0.08s

=== episode:87 Env-steps-taken:91680
 	picked: 169 |actions: {0: 246, 1: 767, 2: 703, 3: 569, 4: 982, 5: 1242, 6: 223, 7: 1021, 8: 167}

==================================================
eval-episode: 870 -> reward: 216.48958333333388, steps: 5920.0, wall-time: 59.57s
-> berries picked: 169 of 800 | patches-visited: [1, 2, 5, 9] | juice left:-0.00
==================================================


=== episode:871 Env-steps-taken:65088
 	picked: 63 |actions: {0: 486, 1: 374, 2: 659, 3: 460, 4: 676, 5: 467, 6: 491, 7: 483, 8: 303}
episode: 871/2000 -> reward: 85.89062499999994, steps:4399, time-taken: 2.05min, time-elasped: 1763.48min
-> berries picked: 63 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7978 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [763, 1226, 1296, 970, 810, 705, 687, 609, 912]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 12, 21, 26, 15, 11, 9, 8, 22]
	Time taken saving stuff: 0.02s

=== episode:872 Env-steps-taken:62304
 	picked: 50 |actions: {0: 285, 1: 357, 2: 420, 3: 322, 4: 376, 5: 274, 6: 259, 7: 348, 8: 173}
episode: 872/2000 -> reward: 72.1354166666667, steps:2814, time-taken: 1.53min, time-elasped: 1765.02min
-> berries picked: 50 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7988 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [760, 1227, 1300, 968, 811, 709, 687, 611, 915]
	| approx positives in sample 512: 145
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 27, 14, 19, 11, 14, 14, 17, 14]
	Time taken saving stuff: 0.07s

=== episode:873 Env-steps-taken:68160
 	picked: 76 |actions: {0: 657, 1: 651, 2: 972, 3: 617, 4: 869, 5: 586, 6: 407, 7: 764, 8: 449}
episode: 873/2000 -> reward: 100.64583333333324, steps:5972, time-taken: 2.55min, time-elasped: 1767.57min
-> berries picked: 76 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7984 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [757, 1228, 1306, 963, 805, 711, 689, 610, 915]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 23, 17, 13, 13, 13, 13, 8, 12]
	Time taken saving stuff: 0.09s

=== episode:874 Env-steps-taken:61920
 	picked: 52 |actions: {0: 302, 1: 520, 2: 367, 3: 410, 4: 449, 5: 331, 6: 353, 7: 375, 8: 283}
episode: 874/2000 -> reward: 69.52083333333334, steps:3390, time-taken: 1.64min, time-elasped: 1769.21min
-> berries picked: 52 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7984 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [756, 1231, 1305, 959, 798, 716, 694, 611, 914]
	| approx positives in sample 512: 151
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 25, 17, 16, 16, 7, 16, 10, 37]
	Time taken saving stuff: 0.01s

=== episode:875 Env-steps-taken:61632
 	picked: 47 |actions: {0: 320, 1: 343, 2: 392, 3: 372, 4: 466, 5: 351, 6: 268, 7: 302, 8: 215}
episode: 875/2000 -> reward: 66.86458333333337, steps:3029, time-taken: 1.57min, time-elasped: 1770.78min
-> berries picked: 47 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7996 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [757, 1232, 1306, 967, 803, 721, 690, 605, 915]
	| approx positives in sample 512: 147
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 21, 27, 16, 15, 16, 12, 10, 19]
	Time taken saving stuff: 0.09s

=== episode:876 Env-steps-taken:66816
 	picked: 67 |actions: {0: 599, 1: 569, 2: 473, 3: 367, 4: 506, 5: 533, 6: 365, 7: 468, 8: 278}
episode: 876/2000 -> reward: 94.66145833333327, steps:4158, time-taken: 2.01min, time-elasped: 1772.79min
-> berries picked: 67 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7989 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [756, 1226, 1306, 963, 805, 718, 692, 605, 918]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 19, 27, 12, 14, 13, 10, 18, 14]
	Time taken saving stuff: 0.10s

=== episode:877 Env-steps-taken:66912
 	picked: 77 |actions: {0: 803, 1: 677, 2: 755, 3: 477, 4: 665, 5: 525, 6: 619, 7: 622, 8: 329}
episode: 877/2000 -> reward: 94.08854166666657, steps:5472, time-taken: 2.32min, time-elasped: 1775.11min
-> berries picked: 77 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8000 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [762, 1232, 1310, 957, 811, 716, 691, 604, 917]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 13, 16, 15, 13, 16, 10, 14, 20]
	Time taken saving stuff: 0.01s

=== episode:878 Env-steps-taken:65664
 	picked: 74 |actions: {0: 595, 1: 564, 2: 879, 3: 570, 4: 1022, 5: 647, 6: 625, 7: 737, 8: 331}
episode: 878/2000 -> reward: 87.7604166666666, steps:5970, time-taken: 2.69min, time-elasped: 1777.80min
-> berries picked: 74 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8016 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [760, 1234, 1313, 960, 812, 719, 697, 603, 918]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 23, 15, 17, 9, 20, 15, 9, 26]
	Time taken saving stuff: 0.11s

=== episode:879 Env-steps-taken:54624
 	picked: 23 |actions: {0: 294, 1: 286, 2: 373, 3: 229, 4: 221, 5: 161, 6: 224, 7: 136, 8: 138}
episode: 879/2000 -> reward: 33.68229166666666, steps:2062, time-taken: 1.02min, time-elasped: 1778.83min
-> berries picked: 23 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8018 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [763, 1239, 1312, 959, 809, 716, 695, 605, 920]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 18, 18, 13, 15, 14, 10, 3, 16]
	Time taken saving stuff: 0.01s

=== episode:880 Env-steps-taken:63936
 	picked: 54 |actions: {0: 416, 1: 516, 2: 656, 3: 546, 4: 598, 5: 311, 6: 292, 7: 300, 8: 319}
episode: 880/2000 -> reward: 80.90625, steps:3954, time-taken: 1.97min, time-elasped: 1780.80min
-> berries picked: 54 of 800 | patches-visited: [0, 1, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8028 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [770, 1241, 1314, 963, 811, 715, 691, 601, 922]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 25, 22, 16, 14, 15, 10, 11, 17]
	Time taken saving stuff: 0.14s

=== episode:88 Env-steps-taken:83616
 	picked: 139 |actions: {0: 952, 1: 252, 2: 998, 3: 299, 4: 1630, 5: 302, 6: 891, 7: 66, 8: 280}

==================================================
eval-episode: 880 -> reward: 176.65104166666697, steps: 5670.0, wall-time: 51.80s
-> berries picked: 139 of 800 | patches-visited: [0, 1, 8] | juice left:-0.00
==================================================


=== episode:881 Env-steps-taken:70464
 	picked: 86 |actions: {0: 525, 1: 750, 2: 913, 3: 762, 4: 696, 5: 557, 6: 660, 7: 660, 8: 417}
episode: 881/2000 -> reward: 112.57291666666656, steps:5940, time-taken: 2.77min, time-elasped: 1784.45min
-> berries picked: 86 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8019 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [763, 1244, 1319, 968, 811, 711, 684, 596, 923]
	| approx positives in sample 512: 149
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 33, 30, 6, 15, 10, 12, 8, 21]
	Time taken saving stuff: 0.01s

=== episode:882 Env-steps-taken:65568
 	picked: 65 |actions: {0: 588, 1: 582, 2: 793, 3: 527, 4: 729, 5: 515, 6: 613, 7: 535, 8: 332}
episode: 882/2000 -> reward: 88.27604166666664, steps:5214, time-taken: 2.46min, time-elasped: 1786.90min
-> berries picked: 65 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8020 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [762, 1253, 1322, 963, 807, 716, 679, 595, 923]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 18, 21, 18, 17, 6, 16, 10, 21]
	Time taken saving stuff: 0.01s

=== episode:883 Env-steps-taken:67392
 	picked: 71 |actions: {0: 600, 1: 495, 2: 690, 3: 467, 4: 569, 5: 513, 6: 605, 7: 450, 8: 321}
episode: 883/2000 -> reward: 97.9322916666666, steps:4710, time-taken: 2.33min, time-elasped: 1789.24min
-> berries picked: 71 of 800 | patches-visited: [0, 3, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8034 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [763, 1254, 1326, 964, 811, 715, 679, 597, 925]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 15, 26, 16, 18, 8, 19, 9, 20]
	Time taken saving stuff: 0.01s

=== episode:884 Env-steps-taken:70752
 	picked: 86 |actions: {0: 429, 1: 475, 2: 582, 3: 516, 4: 603, 5: 510, 6: 501, 7: 575, 8: 324}
episode: 884/2000 -> reward: 114.57291666666653, steps:4515, time-taken: 2.18min, time-elasped: 1791.42min
-> berries picked: 86 of 800 | patches-visited: [0, 1, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8056 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [762, 1263, 1328, 965, 812, 720, 683, 597, 926]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 24, 20, 13, 17, 15, 7, 3, 18]
	Time taken saving stuff: 0.01s

=== episode:885 Env-steps-taken:65376
 	picked: 67 |actions: {0: 554, 1: 768, 2: 668, 3: 469, 4: 439, 5: 513, 6: 570, 7: 641, 8: 338}
episode: 885/2000 -> reward: 86.66145833333327, steps:4960, time-taken: 2.22min, time-elasped: 1793.64min
-> berries picked: 67 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8059 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [766, 1263, 1330, 963, 811, 716, 682, 601, 927]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 23, 16, 13, 13, 15, 11, 2, 16]
	Time taken saving stuff: 0.02s

=== episode:886 Env-steps-taken:71040
 	picked: 85 |actions: {0: 662, 1: 574, 2: 866, 3: 536, 4: 747, 5: 778, 6: 601, 7: 745, 8: 420}
episode: 886/2000 -> reward: 115.63020833333319, steps:5929, time-taken: 2.75min, time-elasped: 1796.40min
-> berries picked: 85 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8071 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [764, 1260, 1335, 962, 813, 725, 681, 601, 930]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 18, 19, 14, 11, 8, 14, 10, 19]
	Time taken saving stuff: 0.10s

=== episode:887 Env-steps-taken:53184
 	picked: 18 |actions: {0: 74, 1: 106, 2: 169, 3: 67, 4: 91, 5: 77, 6: 86, 7: 131, 8: 40}
episode: 887/2000 -> reward: 25.96875, steps:841, time-taken: 0.70min, time-elasped: 1797.10min
-> berries picked: 18 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8073 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [763, 1260, 1333, 962, 812, 726, 682, 603, 932]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 17, 22, 15, 8, 11, 12, 11, 27]
	Time taken saving stuff: 0.01s

=== episode:888 Env-steps-taken:65568
 	picked: 71 |actions: {0: 553, 1: 565, 2: 882, 3: 495, 4: 701, 5: 466, 6: 674, 7: 610, 8: 412}
episode: 888/2000 -> reward: 87.43229166666664, steps:5358, time-taken: 2.35min, time-elasped: 1799.45min
-> berries picked: 71 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8074 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [768, 1256, 1333, 969, 813, 715, 686, 603, 931]
	| approx positives in sample 512: 145
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 17, 19, 19, 16, 9, 11, 7, 31]
	Time taken saving stuff: 0.10s

=== episode:889 Env-steps-taken:68064
 	picked: 72 |actions: {0: 532, 1: 570, 2: 670, 3: 480, 4: 665, 5: 454, 6: 512, 7: 607, 8: 341}
episode: 889/2000 -> reward: 101.37499999999991, steps:4831, time-taken: 2.29min, time-elasped: 1801.75min
-> berries picked: 72 of 800 | patches-visited: [0, 2, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8070 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [771, 1261, 1332, 966, 811, 721, 678, 601, 929]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 15, 23, 18, 18, 10, 12, 11, 18]
	Time taken saving stuff: 0.00s

=== episode:890 Env-steps-taken:71424
 	picked: 86 |actions: {0: 584, 1: 577, 2: 675, 3: 484, 4: 671, 5: 666, 6: 693, 7: 570, 8: 300}
episode: 890/2000 -> reward: 117.57291666666652, steps:5220, time-taken: 2.51min, time-elasped: 1804.26min
-> berries picked: 86 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8093 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [773, 1267, 1338, 965, 811, 727, 675, 607, 930]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 14, 26, 9, 13, 7, 11, 10, 14]
	Time taken saving stuff: 0.06s

=== episode:89 Env-steps-taken:74688
 	picked: 105 |actions: {0: 341, 1: 301, 2: 1449, 3: 167, 4: 372, 5: 315, 6: 738, 7: 523, 8: 497}

==================================================
eval-episode: 890 -> reward: 132.59895833333317, steps: 4703.0, wall-time: 46.70s
-> berries picked: 105 of 800 | patches-visited: [1, 7] | juice left:-0.00
==================================================


=== episode:891 Env-steps-taken:73056
 	picked: 92 |actions: {0: 558, 1: 682, 2: 764, 3: 510, 4: 993, 5: 657, 6: 706, 7: 763, 8: 522}
episode: 891/2000 -> reward: 123.90104166666652, steps:6155, time-taken: 2.76min, time-elasped: 1807.81min
-> berries picked: 92 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8082 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [772, 1261, 1329, 964, 809, 724, 679, 612, 932]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 10, 15, 12, 10, 13, 10, 8, 21]
	Time taken saving stuff: 0.01s

=== episode:892 Env-steps-taken:59040
 	picked: 40 |actions: {0: 267, 1: 295, 2: 202, 3: 285, 4: 262, 5: 216, 6: 400, 7: 300, 8: 177}
episode: 892/2000 -> reward: 55.208333333333364, steps:2404, time-taken: 1.32min, time-elasped: 1809.13min
-> berries picked: 40 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8084 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [771, 1261, 1329, 962, 808, 728, 679, 613, 933]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 31, 16, 18, 13, 13, 6, 12, 23]
	Time taken saving stuff: 0.10s

=== episode:893 Env-steps-taken:64032
 	picked: 57 |actions: {0: 389, 1: 375, 2: 498, 3: 367, 4: 496, 5: 417, 6: 462, 7: 324, 8: 377}
episode: 893/2000 -> reward: 80.734375, steps:3705, time-taken: 1.80min, time-elasped: 1810.93min
-> berries picked: 57 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8084 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [768, 1265, 1326, 964, 809, 731, 679, 609, 933]
	| approx positives in sample 512: 155
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [23, 15, 18, 20, 18, 14, 13, 8, 26]
	Time taken saving stuff: 0.01s

=== episode:894 Env-steps-taken:66240
 	picked: 66 |actions: {0: 392, 1: 495, 2: 527, 3: 459, 4: 618, 5: 439, 6: 416, 7: 446, 8: 446}
episode: 894/2000 -> reward: 91.71874999999991, steps:4238, time-taken: 2.10min, time-elasped: 1813.04min
-> berries picked: 66 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8088 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [767, 1270, 1325, 961, 810, 733, 679, 607, 936]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 22, 13, 12, 8, 10, 14, 12, 19]
	Time taken saving stuff: 0.09s

=== episode:895 Env-steps-taken:66624
 	picked: 65 |actions: {0: 387, 1: 387, 2: 551, 3: 494, 4: 459, 5: 452, 6: 311, 7: 440, 8: 259}
episode: 895/2000 -> reward: 94.27604166666663, steps:3740, time-taken: 1.94min, time-elasped: 1814.99min
-> berries picked: 65 of 800 | patches-visited: [0, 3, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8096 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [767, 1272, 1326, 965, 808, 735, 675, 608, 940]
	| approx positives in sample 512: 139
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 19, 22, 16, 13, 7, 14, 10, 25]
	Time taken saving stuff: 0.01s

=== episode:896 Env-steps-taken:58272
 	picked: 37 |actions: {0: 241, 1: 295, 2: 388, 3: 230, 4: 285, 5: 343, 6: 312, 7: 291, 8: 199}
episode: 896/2000 -> reward: 50.49479166666669, steps:2584, time-taken: 1.30min, time-elasped: 1816.29min
-> berries picked: 37 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8101 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [770, 1271, 1325, 965, 810, 738, 675, 606, 941]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 13, 16, 16, 14, 10, 12, 9, 25]
	Time taken saving stuff: 0.08s

=== episode:897 Env-steps-taken:65472
 	picked: 57 |actions: {0: 368, 1: 291, 2: 494, 3: 304, 4: 344, 5: 390, 6: 370, 7: 328, 8: 197}
episode: 897/2000 -> reward: 88.23437499999997, steps:3086, time-taken: 1.57min, time-elasped: 1817.86min
-> berries picked: 57 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8108 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [766, 1275, 1332, 964, 811, 736, 674, 609, 941]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 14, 16, 17, 15, 11, 11, 7, 21]
	Time taken saving stuff: 0.09s

=== episode:898 Env-steps-taken:61632
 	picked: 55 |actions: {0: 425, 1: 378, 2: 407, 3: 291, 4: 517, 5: 404, 6: 427, 7: 462, 8: 296}
episode: 898/2000 -> reward: 67.84895833333339, steps:3607, time-taken: 1.66min, time-elasped: 1819.53min
-> berries picked: 55 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8122 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [768, 1276, 1333, 963, 813, 738, 676, 613, 942]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 21, 20, 13, 16, 6, 10, 9, 23]
	Time taken saving stuff: 0.01s

=== episode:899 Env-steps-taken:69888
 	picked: 79 |actions: {0: 536, 1: 489, 2: 802, 3: 452, 4: 651, 5: 620, 6: 582, 7: 515, 8: 316}
episode: 899/2000 -> reward: 109.97395833333323, steps:4963, time-taken: 2.23min, time-elasped: 1821.76min
-> berries picked: 79 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8136 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [772, 1281, 1342, 972, 805, 728, 676, 613, 947]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 18, 19, 11, 23, 11, 13, 8, 18]
	Time taken saving stuff: 0.02s

=== episode:900 Env-steps-taken:74400
 	picked: 96 |actions: {0: 702, 1: 651, 2: 933, 3: 604, 4: 935, 5: 714, 6: 576, 7: 921, 8: 395}
episode: 900/2000 -> reward: 132.49999999999986, steps:6431, time-taken: 2.86min, time-elasped: 1824.62min
-> berries picked: 96 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8143 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [775, 1283, 1347, 968, 802, 725, 677, 616, 950]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 29, 24, 13, 13, 9, 7, 11, 16]
	Time taken saving stuff: 0.06s

=== episode:90 Env-steps-taken:80352
 	picked: 125 |actions: {0: 430, 1: 414, 2: 1232, 3: 442, 4: 824, 5: 386, 6: 436, 7: 826, 8: 747}

==================================================
eval-episode: 900 -> reward: 160.39583333333343, steps: 5737.0, wall-time: 52.94s
-> berries picked: 125 of 800 | patches-visited: [0, 1, 3] | juice left:-0.00
==================================================


=== episode:901 Env-steps-taken:65664
 	picked: 63 |actions: {0: 557, 1: 419, 2: 575, 3: 600, 4: 867, 5: 559, 6: 646, 7: 619, 8: 446}
episode: 901/2000 -> reward: 88.39062499999994, steps:5288, time-taken: 2.35min, time-elasped: 1827.86min
-> berries picked: 63 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8138 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [773, 1281, 1345, 967, 802, 730, 677, 617, 946]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 16, 18, 20, 13, 9, 9, 6, 31]
	Time taken saving stuff: 0.10s

=== episode:902 Env-steps-taken:63936
 	picked: 66 |actions: {0: 542, 1: 538, 2: 670, 3: 435, 4: 642, 5: 500, 6: 559, 7: 686, 8: 373}
episode: 902/2000 -> reward: 77.27604166666664, steps:4945, time-taken: 2.25min, time-elasped: 1830.11min
-> berries picked: 66 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8123 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [772, 1285, 1341, 967, 799, 721, 678, 617, 943]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 16, 19, 14, 11, 16, 13, 10, 13]
	Time taken saving stuff: 0.02s

=== episode:903 Env-steps-taken:68640
 	picked: 83 |actions: {0: 596, 1: 630, 2: 754, 3: 509, 4: 657, 5: 469, 6: 630, 7: 569, 8: 336}
episode: 903/2000 -> reward: 103.24479166666656, steps:5150, time-taken: 2.30min, time-elasped: 1832.42min
-> berries picked: 83 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8151 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [778, 1282, 1346, 971, 803, 731, 677, 620, 943]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 11, 22, 13, 15, 9, 8, 11, 20]
	Time taken saving stuff: 0.11s

=== episode:904 Env-steps-taken:71520
 	picked: 83 |actions: {0: 563, 1: 536, 2: 699, 3: 556, 4: 575, 5: 536, 6: 660, 7: 575, 8: 268}
episode: 904/2000 -> reward: 118.24479166666654, steps:4968, time-taken: 2.34min, time-elasped: 1834.76min
-> berries picked: 83 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8175 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [787, 1287, 1344, 975, 807, 731, 676, 622, 946]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 23, 20, 15, 13, 11, 9, 12, 20]
	Time taken saving stuff: 0.10s

=== episode:905 Env-steps-taken:62112
 	picked: 50 |actions: {0: 352, 1: 263, 2: 316, 3: 183, 4: 256, 5: 259, 6: 258, 7: 342, 8: 161}
episode: 905/2000 -> reward: 71.19270833333334, steps:2390, time-taken: 1.33min, time-elasped: 1836.10min
-> berries picked: 50 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8202 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [788, 1290, 1347, 974, 811, 730, 679, 633, 950]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 17, 14, 13, 12, 17, 15, 5, 25]
	Time taken saving stuff: 0.03s

=== episode:906 Env-steps-taken:58272
 	picked: 38 |actions: {0: 491, 1: 293, 2: 485, 3: 379, 4: 715, 5: 319, 6: 363, 7: 340, 8: 345}
episode: 906/2000 -> reward: 49.38020833333335, steps:3730, time-taken: 1.85min, time-elasped: 1837.95min
-> berries picked: 38 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8173 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [788, 1285, 1342, 970, 805, 730, 674, 631, 948]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 21, 17, 20, 14, 14, 11, 15, 13]
	Time taken saving stuff: 0.09s

=== episode:907 Env-steps-taken:62208
 	picked: 54 |actions: {0: 362, 1: 303, 2: 434, 3: 302, 4: 377, 5: 267, 6: 376, 7: 323, 8: 285}
episode: 907/2000 -> reward: 70.90625000000003, steps:3029, time-taken: 1.44min, time-elasped: 1839.40min
-> berries picked: 54 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8184 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [790, 1278, 1347, 971, 806, 732, 674, 634, 952]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 15, 22, 10, 16, 8, 11, 9, 22]
	Time taken saving stuff: 0.09s

=== episode:908 Env-steps-taken:68736
 	picked: 81 |actions: {0: 559, 1: 499, 2: 555, 3: 457, 4: 516, 5: 445, 6: 564, 7: 500, 8: 326}
episode: 908/2000 -> reward: 103.85937499999993, steps:4421, time-taken: 2.11min, time-elasped: 1841.52min
-> berries picked: 81 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8202 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [797, 1276, 1347, 974, 807, 731, 674, 643, 953]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 17, 22, 15, 8, 9, 10, 9, 19]
	Time taken saving stuff: 0.08s

=== episode:909 Env-steps-taken:79776
 	picked: 112 |actions: {0: 838, 1: 951, 2: 867, 3: 644, 4: 818, 5: 837, 6: 684, 7: 650, 8: 565}
episode: 909/2000 -> reward: 159.58333333333343, steps:6854, time-taken: 3.05min, time-elasped: 1844.57min
-> berries picked: 112 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8212 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [793, 1295, 1345, 971, 810, 730, 677, 638, 953]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 21, 20, 14, 11, 9, 12, 9, 21]
	Time taken saving stuff: 0.11s

=== episode:910 Env-steps-taken:74688
 	picked: 105 |actions: {0: 789, 1: 728, 2: 772, 3: 705, 4: 628, 5: 834, 6: 691, 7: 797, 8: 448}
episode: 910/2000 -> reward: 133.48437499999983, steps:6392, time-taken: 2.85min, time-elasped: 1847.43min
-> berries picked: 105 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8222 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [803, 1295, 1346, 971, 803, 735, 678, 636, 955]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 18, 11, 20, 14, 10, 9, 11, 12]
	Time taken saving stuff: 0.10s

=== episode:91 Env-steps-taken:62880
 	picked: 53 |actions: {0: 590, 1: 102, 2: 230, 3: 373, 4: 99, 5: 650, 6: 127, 7: 79, 8: 132}

==================================================
eval-episode: 910 -> reward: 74.96354166666667, steps: 2382.0, wall-time: 30.94s
-> berries picked: 53 of 800 | patches-visited: [1, 4] | juice left:-0.00
==================================================


=== episode:911 Env-steps-taken:58752
 	picked: 34 |actions: {0: 249, 1: 310, 2: 293, 3: 220, 4: 290, 5: 266, 6: 199, 7: 163, 8: 214}
episode: 911/2000 -> reward: 52.60937500000003, steps:2204, time-taken: 1.35min, time-elasped: 1849.30min
-> berries picked: 34 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8218 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [802, 1295, 1346, 972, 806, 730, 683, 632, 952]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 11, 18, 11, 20, 9, 16, 8, 22]
	Time taken saving stuff: 0.10s

=== episode:912 Env-steps-taken:66816
 	picked: 74 |actions: {0: 778, 1: 557, 2: 751, 3: 647, 4: 629, 5: 542, 6: 753, 7: 593, 8: 421}
episode: 912/2000 -> reward: 93.37499999999996, steps:5671, time-taken: 2.46min, time-elasped: 1851.76min
-> berries picked: 74 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8211 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [799, 1295, 1345, 968, 807, 731, 681, 632, 953]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 11, 12, 10, 19, 11, 13, 10, 14]
	Time taken saving stuff: 0.00s

=== episode:913 Env-steps-taken:74496
 	picked: 100 |actions: {0: 702, 1: 666, 2: 878, 3: 722, 4: 789, 5: 564, 6: 595, 7: 629, 8: 348}
episode: 913/2000 -> reward: 131.88541666666657, steps:5893, time-taken: 2.77min, time-elasped: 1854.54min
-> berries picked: 100 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8227 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [805, 1294, 1350, 966, 805, 731, 686, 635, 955]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 16, 17, 16, 16, 13, 9, 4, 19]
	Time taken saving stuff: 0.01s

=== episode:914 Env-steps-taken:67584
 	picked: 82 |actions: {0: 721, 1: 578, 2: 654, 3: 452, 4: 479, 5: 688, 6: 658, 7: 820, 8: 511}
episode: 914/2000 -> reward: 97.80208333333321, steps:5561, time-taken: 2.42min, time-elasped: 1856.96min
-> berries picked: 82 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8223 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [803, 1298, 1347, 965, 805, 729, 686, 636, 954]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 19, 20, 10, 15, 13, 9, 7, 17]
	Time taken saving stuff: 0.01s

=== episode:915 Env-steps-taken:64320
 	picked: 59 |actions: {0: 427, 1: 350, 2: 407, 3: 349, 4: 421, 5: 350, 6: 440, 7: 281, 8: 214}
episode: 915/2000 -> reward: 81.61979166666666, steps:3239, time-taken: 1.54min, time-elasped: 1858.50min
-> berries picked: 59 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8242 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [806, 1299, 1352, 974, 806, 736, 681, 634, 954]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 17, 17, 16, 15, 17, 8, 10, 22]
	Time taken saving stuff: 0.00s

=== episode:916 Env-steps-taken:61920
 	picked: 57 |actions: {0: 345, 1: 510, 2: 753, 3: 397, 4: 682, 5: 501, 6: 463, 7: 572, 8: 293}
episode: 916/2000 -> reward: 69.73437500000007, steps:4516, time-taken: 2.02min, time-elasped: 1860.52min
-> berries picked: 57 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8249 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [807, 1297, 1358, 973, 808, 737, 679, 635, 955]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 12, 23, 14, 7, 9, 10, 10, 24]
	Time taken saving stuff: 0.02s

=== episode:917 Env-steps-taken:65760
 	picked: 65 |actions: {0: 619, 1: 477, 2: 597, 3: 488, 4: 477, 5: 650, 6: 460, 7: 639, 8: 293}
episode: 917/2000 -> reward: 89.2760416666666, steps:4700, time-taken: 2.16min, time-elasped: 1862.68min
-> berries picked: 65 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8272 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [812, 1303, 1358, 975, 808, 738, 683, 638, 957]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 18, 19, 13, 12, 14, 13, 6, 17]
	Time taken saving stuff: 0.09s

=== episode:918 Env-steps-taken:66816
 	picked: 68 |actions: {0: 461, 1: 478, 2: 566, 3: 488, 4: 687, 5: 662, 6: 506, 7: 594, 8: 312}
episode: 918/2000 -> reward: 95.10416666666661, steps:4754, time-taken: 2.23min, time-elasped: 1864.92min
-> berries picked: 68 of 800 | patches-visited: [0, 4, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8270 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [810, 1308, 1360, 977, 811, 734, 682, 629, 959]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 20, 18, 18, 12, 11, 15, 13, 21]
	Time taken saving stuff: 0.12s

=== episode:919 Env-steps-taken:78624
 	picked: 110 |actions: {0: 666, 1: 883, 2: 782, 3: 717, 4: 696, 5: 705, 6: 717, 7: 742, 8: 464}
episode: 919/2000 -> reward: 153.69791666666669, steps:6372, time-taken: 2.85min, time-elasped: 1867.77min
-> berries picked: 110 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8299 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [812, 1318, 1362, 977, 810, 737, 689, 633, 961]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 15, 12, 21, 11, 12, 14, 9, 25]
	Time taken saving stuff: 0.10s

=== episode:920 Env-steps-taken:69312
 	picked: 78 |actions: {0: 615, 1: 558, 2: 649, 3: 697, 4: 587, 5: 571, 6: 734, 7: 614, 8: 424}
episode: 920/2000 -> reward: 105.64583333333321, steps:5449, time-taken: 2.49min, time-elasped: 1870.26min
-> berries picked: 78 of 800 | patches-visited: [0, 1, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8307 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [811, 1317, 1371, 982, 812, 738, 681, 635, 960]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 21, 17, 11, 15, 15, 10, 10, 17]
	Time taken saving stuff: 0.06s

=== episode:92 Env-steps-taken:74976
 	picked: 106 |actions: {0: 655, 1: 222, 2: 864, 3: 135, 4: 315, 5: 358, 6: 308, 7: 419, 8: 548}

==================================================
eval-episode: 920 -> reward: 134.04166666666654, steps: 3824.0, wall-time: 45.07s
-> berries picked: 106 of 800 | patches-visited: [1, 7] | juice left:-0.00
==================================================


=== episode:921 Env-steps-taken:60192
 	picked: 41 |actions: {0: 313, 1: 449, 2: 381, 3: 866, 4: 388, 5: 234, 6: 231, 7: 274, 8: 216}
episode: 921/2000 -> reward: 61.65104166666671, steps:3352, time-taken: 1.77min, time-elasped: 1872.78min
-> berries picked: 41 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8299 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [808, 1320, 1379, 981, 811, 731, 675, 633, 961]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 18, 18, 8, 7, 9, 15, 9, 23]
	Time taken saving stuff: 0.02s

=== episode:922 Env-steps-taken:61248
 	picked: 49 |actions: {0: 291, 1: 298, 2: 316, 3: 301, 4: 330, 5: 301, 6: 337, 7: 266, 8: 246}
episode: 922/2000 -> reward: 66.69270833333337, steps:2686, time-taken: 1.37min, time-elasped: 1874.16min
-> berries picked: 49 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8300 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [807, 1327, 1377, 976, 813, 732, 674, 632, 962]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 21, 16, 17, 14, 11, 9, 6, 24]
	Time taken saving stuff: 0.08s

=== episode:923 Env-steps-taken:77760
 	picked: 113 |actions: {0: 733, 1: 675, 2: 687, 3: 870, 4: 746, 5: 775, 6: 898, 7: 614, 8: 402}
episode: 923/2000 -> reward: 149.0260416666667, steps:6400, time-taken: 2.87min, time-elasped: 1877.03min
-> berries picked: 113 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8319 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [811, 1333, 1379, 982, 813, 734, 668, 637, 962]
	| approx positives in sample 512: 139
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 19, 18, 21, 17, 12, 17, 8, 12]
	Time taken saving stuff: 0.07s

=== episode:924 Env-steps-taken:69120
 	picked: 76 |actions: {0: 504, 1: 403, 2: 522, 3: 609, 4: 617, 5: 627, 6: 684, 7: 561, 8: 473}
episode: 924/2000 -> reward: 106.14583333333321, steps:5000, time-taken: 4.99min, time-elasped: 1882.02min
-> berries picked: 76 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8313 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [812, 1332, 1382, 981, 815, 731, 661, 634, 965]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 18, 16, 21, 12, 13, 9, 10, 18]
	Time taken saving stuff: 1.69s

=== episode:925 Env-steps-taken:69408
 	picked: 77 |actions: {0: 448, 1: 472, 2: 455, 3: 433, 4: 517, 5: 535, 6: 416, 7: 529, 8: 337}
episode: 925/2000 -> reward: 107.58854166666659, steps:4142, time-taken: 3.65min, time-elasped: 1885.71min
-> berries picked: 77 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8327 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [809, 1337, 1383, 986, 818, 732, 668, 627, 967]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 15, 16, 17, 11, 14, 12, 8, 20]
	Time taken saving stuff: 0.01s

=== episode:926 Env-steps-taken:78624
 	picked: 108 |actions: {0: 755, 1: 798, 2: 737, 3: 514, 4: 785, 5: 624, 6: 646, 7: 631, 8: 434}
episode: 926/2000 -> reward: 154.31250000000006, steps:5924, time-taken: 2.31min, time-elasped: 1888.02min
-> berries picked: 108 of 800 | patches-visited: [0, 3, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8342 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [816, 1340, 1388, 991, 818, 732, 663, 625, 969]
	| approx positives in sample 512: 156
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 25, 30, 16, 11, 10, 14, 4, 27]
	Time taken saving stuff: 0.09s

=== episode:927 Env-steps-taken:64032
 	picked: 56 |actions: {0: 449, 1: 321, 2: 370, 3: 316, 4: 484, 5: 463, 6: 450, 7: 439, 8: 380}
episode: 927/2000 -> reward: 80.79166666666664, steps:3672, time-taken: 1.72min, time-elasped: 1889.74min
-> berries picked: 56 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8343 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [823, 1340, 1384, 986, 824, 726, 665, 622, 973]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 15, 31, 14, 13, 5, 10, 13, 25]
	Time taken saving stuff: 0.10s

=== episode:928 Env-steps-taken:67200
 	picked: 76 |actions: {0: 566, 1: 528, 2: 757, 3: 575, 4: 532, 5: 435, 6: 506, 7: 622, 8: 407}
episode: 928/2000 -> reward: 95.64583333333323, steps:4928, time-taken: 2.18min, time-elasped: 1891.92min
-> berries picked: 76 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8340 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [825, 1341, 1385, 988, 823, 721, 662, 622, 973]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 29, 17, 14, 12, 11, 8, 8, 20]
	Time taken saving stuff: 0.09s

=== episode:929 Env-steps-taken:71232
 	picked: 87 |actions: {0: 598, 1: 587, 2: 831, 3: 677, 4: 600, 5: 643, 6: 570, 7: 579, 8: 379}
episode: 929/2000 -> reward: 116.51562499999986, steps:5464, time-taken: 2.40min, time-elasped: 1894.32min
-> berries picked: 87 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8347 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [821, 1347, 1384, 990, 825, 724, 661, 622, 973]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 18, 18, 19, 15, 7, 15, 7, 20]
	Time taken saving stuff: 0.01s

=== episode:930 Env-steps-taken:75168
 	picked: 98 |actions: {0: 605, 1: 657, 2: 695, 3: 680, 4: 667, 5: 860, 6: 927, 7: 753, 8: 427}
episode: 930/2000 -> reward: 136.38541666666657, steps:6271, time-taken: 2.78min, time-elasped: 1897.10min
-> berries picked: 98 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8360 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [817, 1342, 1389, 990, 831, 732, 665, 621, 973]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 21, 24, 17, 15, 8, 9, 8, 23]
	Time taken saving stuff: 0.14s

=== episode:93 Env-steps-taken:65472
 	picked: 64 |actions: {0: 354, 1: 247, 2: 1928, 3: 139, 4: 596, 5: 183, 6: 1746, 7: 145, 8: 150}

==================================================
eval-episode: 930 -> reward: 87.8333333333333, steps: 5488.0, wall-time: 43.22s
-> berries picked: 64 of 800 | patches-visited: [1, 6] | juice left:-0.00
==================================================


=== episode:931 Env-steps-taken:71040
 	picked: 92 |actions: {0: 541, 1: 580, 2: 797, 3: 607, 4: 614, 5: 638, 6: 646, 7: 615, 8: 411}
episode: 931/2000 -> reward: 115.22916666666656, steps:5449, time-taken: 2.51min, time-elasped: 1900.33min
-> berries picked: 92 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8370 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [821, 1328, 1387, 996, 848, 734, 663, 619, 974]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 25, 12, 9, 16, 6, 4, 9, 27]
	Time taken saving stuff: 0.01s

=== episode:932 Env-steps-taken:74784
 	picked: 92 |actions: {0: 556, 1: 663, 2: 705, 3: 649, 4: 659, 5: 606, 6: 566, 7: 796, 8: 388}
episode: 932/2000 -> reward: 134.72916666666657, steps:5588, time-taken: 2.58min, time-elasped: 1902.92min
-> berries picked: 92 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8369 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [824, 1330, 1393, 994, 847, 733, 657, 615, 976]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 23, 20, 11, 16, 6, 17, 8, 18]
	Time taken saving stuff: 0.08s

=== episode:933 Env-steps-taken:75360
 	picked: 103 |actions: {0: 575, 1: 723, 2: 587, 3: 747, 4: 758, 5: 631, 6: 698, 7: 704, 8: 338}
episode: 933/2000 -> reward: 137.09895833333326, steps:5761, time-taken: 2.70min, time-elasped: 1905.62min
-> berries picked: 103 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8383 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [823, 1328, 1392, 999, 852, 737, 658, 614, 980]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 17, 17, 8, 18, 7, 9, 3, 17]
	Time taken saving stuff: 0.10s

=== episode:934 Env-steps-taken:63264
 	picked: 63 |actions: {0: 461, 1: 457, 2: 468, 3: 477, 4: 430, 5: 404, 6: 425, 7: 406, 8: 274}
episode: 934/2000 -> reward: 75.89062499999997, steps:3802, time-taken: 1.77min, time-elasped: 1907.40min
-> berries picked: 63 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8382 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [828, 1332, 1391, 998, 851, 732, 659, 611, 980]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 24, 14, 13, 14, 10, 7, 7, 32]
	Time taken saving stuff: 0.10s

=== episode:935 Env-steps-taken:66048
 	picked: 76 |actions: {0: 623, 1: 583, 2: 1053, 3: 601, 4: 509, 5: 618, 6: 543, 7: 632, 8: 378}
episode: 935/2000 -> reward: 89.20312499999993, steps:5540, time-taken: 2.54min, time-elasped: 1909.95min
-> berries picked: 76 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8378 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [829, 1330, 1395, 998, 849, 733, 656, 609, 979]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 30, 19, 16, 10, 12, 10, 10, 11]
	Time taken saving stuff: 0.02s

=== episode:936 Env-steps-taken:65088
 	picked: 72 |actions: {0: 646, 1: 678, 2: 801, 3: 489, 4: 538, 5: 521, 6: 704, 7: 653, 8: 410}
episode: 936/2000 -> reward: 85.37499999999994, steps:5440, time-taken: 2.45min, time-elasped: 1912.40min
-> berries picked: 72 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8344 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [831, 1334, 1384, 989, 838, 724, 657, 609, 978]
	| approx positives in sample 512: 139
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 21, 11, 21, 4, 14, 19, 11, 26]
	Time taken saving stuff: 0.09s

=== episode:937 Env-steps-taken:65568
 	picked: 69 |actions: {0: 555, 1: 481, 2: 640, 3: 671, 4: 672, 5: 764, 6: 528, 7: 605, 8: 415}
episode: 937/2000 -> reward: 87.54687499999991, steps:5331, time-taken: 2.51min, time-elasped: 1914.91min
-> berries picked: 69 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8340 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [828, 1327, 1383, 995, 837, 727, 656, 609, 978]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 21, 18, 16, 13, 16, 6, 8, 23]
	Time taken saving stuff: 0.10s

=== episode:938 Env-steps-taken:67488
 	picked: 68 |actions: {0: 599, 1: 655, 2: 576, 3: 772, 4: 618, 5: 593, 6: 599, 7: 744, 8: 347}
episode: 938/2000 -> reward: 98.10416666666659, steps:5503, time-taken: 2.42min, time-elasped: 1917.34min
-> berries picked: 68 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8323 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [830, 1320, 1373, 990, 836, 725, 662, 606, 981]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 14, 19, 9, 18, 16, 14, 9, 25]
	Time taken saving stuff: 0.01s

=== episode:939 Env-steps-taken:62976
 	picked: 57 |actions: {0: 398, 1: 254, 2: 293, 3: 290, 4: 384, 5: 296, 6: 421, 7: 341, 8: 198}
episode: 939/2000 -> reward: 75.234375, steps:2875, time-taken: 1.61min, time-elasped: 1918.95min
-> berries picked: 57 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8337 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [833, 1323, 1373, 993, 840, 724, 664, 607, 980]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 15, 15, 9, 15, 17, 11, 8, 17]
	Time taken saving stuff: 0.00s

=== episode:940 Env-steps-taken:68352
 	picked: 75 |actions: {0: 460, 1: 524, 2: 570, 3: 583, 4: 604, 5: 537, 6: 492, 7: 551, 8: 332}
episode: 940/2000 -> reward: 100.76041666666656, steps:4653, time-taken: 2.12min, time-elasped: 1921.07min
-> berries picked: 75 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8324 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [830, 1325, 1367, 995, 846, 725, 659, 600, 977]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 16, 16, 11, 11, 7, 7, 3, 16]
	Time taken saving stuff: 0.06s

=== episode:94 Env-steps-taken:66048
 	picked: 70 |actions: {0: 488, 1: 935, 2: 409, 3: 694, 4: 988, 5: 208, 6: 564, 7: 153, 8: 868}

==================================================
eval-episode: 940 -> reward: 89.98958333333326, steps: 5307.0, wall-time: 49.75s
-> berries picked: 70 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:941 Env-steps-taken:81792
 	picked: 115 |actions: {0: 542, 1: 810, 2: 952, 3: 827, 4: 748, 5: 709, 6: 623, 7: 729, 8: 416}
episode: 941/2000 -> reward: 170.41145833333343, steps:6356, time-taken: 2.92min, time-elasped: 1924.82min
-> berries picked: 115 of 800 | patches-visited: [0, 3, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8299 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [829, 1314, 1364, 976, 849, 731, 658, 600, 978]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 21, 22, 24, 14, 14, 6, 11, 19]
	Time taken saving stuff: 0.08s

=== episode:942 Env-steps-taken:59424
 	picked: 45 |actions: {0: 352, 1: 396, 2: 431, 3: 712, 4: 500, 5: 466, 6: 362, 7: 377, 8: 434}
episode: 942/2000 -> reward: 56.92187500000005, steps:4030, time-taken: 2.03min, time-elasped: 1926.85min
-> berries picked: 45 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8267 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [828, 1306, 1357, 973, 842, 724, 661, 599, 977]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 13, 20, 19, 15, 8, 8, 7, 19]
	Time taken saving stuff: 0.02s

=== episode:943 Env-steps-taken:72192
 	picked: 80 |actions: {0: 433, 1: 489, 2: 594, 3: 400, 4: 514, 5: 415, 6: 412, 7: 447, 8: 315}
episode: 943/2000 -> reward: 122.41666666666653, steps:4019, time-taken: 1.99min, time-elasped: 1928.84min
-> berries picked: 80 of 800 | patches-visited: [0, 1, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8280 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [832, 1309, 1351, 972, 848, 728, 658, 603, 979]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 14, 19, 15, 7, 8, 15, 11, 21]
	Time taken saving stuff: 0.09s

=== episode:944 Env-steps-taken:66528
 	picked: 76 |actions: {0: 635, 1: 909, 2: 866, 3: 507, 4: 572, 5: 557, 6: 461, 7: 795, 8: 480}
episode: 944/2000 -> reward: 92.14583333333327, steps:5782, time-taken: 2.62min, time-elasped: 1931.47min
-> berries picked: 76 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8259 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [834, 1316, 1345, 969, 836, 723, 657, 602, 977]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 20, 21, 14, 16, 12, 11, 8, 22]
	Time taken saving stuff: 0.11s

=== episode:945 Env-steps-taken:71040
 	picked: 83 |actions: {0: 497, 1: 616, 2: 741, 3: 598, 4: 538, 5: 528, 6: 467, 7: 520, 8: 319}
episode: 945/2000 -> reward: 115.74479166666653, steps:4824, time-taken: 2.30min, time-elasped: 1933.77min
-> berries picked: 83 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8250 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [829, 1310, 1340, 969, 841, 721, 657, 603, 980]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 18, 16, 17, 9, 16, 15, 9, 27]
	Time taken saving stuff: 0.09s

=== episode:946 Env-steps-taken:61152
 	picked: 44 |actions: {0: 277, 1: 398, 2: 456, 3: 277, 4: 368, 5: 266, 6: 320, 7: 275, 8: 197}
episode: 946/2000 -> reward: 64.53645833333339, steps:2834, time-taken: 1.61min, time-elasped: 1935.38min
-> berries picked: 44 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8243 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [832, 1305, 1344, 969, 840, 714, 659, 601, 979]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 16, 19, 15, 10, 10, 17, 11, 17]
	Time taken saving stuff: 0.01s

=== episode:947 Env-steps-taken:68352
 	picked: 75 |actions: {0: 506, 1: 494, 2: 577, 3: 585, 4: 525, 5: 460, 6: 472, 7: 564, 8: 385}
episode: 947/2000 -> reward: 102.20312499999991, steps:4568, time-taken: 2.21min, time-elasped: 1937.60min
-> berries picked: 75 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8236 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [836, 1306, 1341, 965, 841, 712, 658, 595, 982]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 14, 13, 14, 16, 16, 10, 14, 19]
	Time taken saving stuff: 0.05s

=== episode:948 Env-steps-taken:69504
 	picked: 76 |actions: {0: 560, 1: 641, 2: 721, 3: 658, 4: 607, 5: 563, 6: 575, 7: 495, 8: 444}
episode: 948/2000 -> reward: 108.14583333333323, steps:5264, time-taken: 2.57min, time-elasped: 1940.17min
-> berries picked: 76 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8239 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [837, 1305, 1337, 970, 846, 708, 660, 594, 982]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 19, 24, 11, 12, 13, 12, 8, 14]
	Time taken saving stuff: 0.04s

=== episode:949 Env-steps-taken:63072
 	picked: 53 |actions: {0: 346, 1: 419, 2: 668, 3: 464, 4: 466, 5: 341, 6: 298, 7: 348, 8: 313}
episode: 949/2000 -> reward: 75.96354166666667, steps:3663, time-taken: 1.96min, time-elasped: 1942.13min
-> berries picked: 53 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8228 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [829, 1303, 1335, 965, 850, 707, 663, 594, 982]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 21, 12, 13, 8, 14, 14, 7, 17]
	Time taken saving stuff: 0.00s

=== episode:950 Env-steps-taken:63168
 	picked: 58 |actions: {0: 444, 1: 516, 2: 655, 3: 477, 4: 608, 5: 428, 6: 539, 7: 461, 8: 368}
episode: 950/2000 -> reward: 75.67708333333334, steps:4496, time-taken: 2.09min, time-elasped: 1944.23min
-> berries picked: 58 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8219 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [826, 1302, 1337, 960, 853, 708, 661, 591, 981]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 17, 17, 21, 15, 10, 7, 4, 17]
	Time taken saving stuff: 0.06s

=== episode:95 Env-steps-taken:71712
 	picked: 92 |actions: {0: 111, 1: 574, 2: 41, 3: 474, 4: 236, 5: 430, 6: 124, 7: 842, 8: 420}

==================================================
eval-episode: 950 -> reward: 118.7291666666665, steps: 3252.0, wall-time: 47.07s
-> berries picked: 92 of 800 | patches-visited: [1, 7] | juice left:-0.00
==================================================


=== episode:951 Env-steps-taken:72864
 	picked: 95 |actions: {0: 628, 1: 631, 2: 691, 3: 610, 4: 819, 5: 716, 6: 608, 7: 707, 8: 464}
episode: 951/2000 -> reward: 123.67187499999984, steps:5874, time-taken: 2.76min, time-elasped: 1947.77min
-> berries picked: 95 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8223 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [824, 1302, 1334, 957, 854, 708, 668, 593, 983]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 13, 14, 22, 13, 9, 14, 5, 32]
	Time taken saving stuff: 0.01s

=== episode:952 Env-steps-taken:62400
 	picked: 48 |actions: {0: 361, 1: 461, 2: 493, 3: 591, 4: 497, 5: 677, 6: 327, 7: 381, 8: 502}
episode: 952/2000 -> reward: 72.75, steps:4290, time-taken: 2.18min, time-elasped: 1949.96min
-> berries picked: 48 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8217 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [825, 1307, 1335, 954, 853, 706, 662, 592, 983]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 24, 16, 14, 14, 8, 11, 10, 21]
	Time taken saving stuff: 0.09s

=== episode:953 Env-steps-taken:72576
 	picked: 88 |actions: {0: 597, 1: 500, 2: 635, 3: 570, 4: 612, 5: 587, 6: 527, 7: 556, 8: 313}
episode: 953/2000 -> reward: 121.51562499999984, steps:4897, time-taken: 2.34min, time-elasped: 1952.30min
-> berries picked: 88 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8233 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [822, 1302, 1339, 955, 851, 715, 669, 597, 983]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 17, 19, 8, 9, 12, 9, 9, 21]
	Time taken saving stuff: 0.03s

=== episode:954 Env-steps-taken:60096
 	picked: 49 |actions: {0: 364, 1: 362, 2: 357, 3: 451, 4: 335, 5: 367, 6: 299, 7: 304, 8: 164}
episode: 954/2000 -> reward: 60.69270833333338, steps:3003, time-taken: 1.59min, time-elasped: 1953.90min
-> berries picked: 49 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8233 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [821, 1303, 1339, 951, 853, 716, 668, 598, 984]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 17, 19, 14, 10, 10, 10, 9, 20]
	Time taken saving stuff: 0.09s

=== episode:955 Env-steps-taken:73344
 	picked: 87 |actions: {0: 581, 1: 694, 2: 653, 3: 546, 4: 478, 5: 583, 6: 425, 7: 514, 8: 292}
episode: 955/2000 -> reward: 127.13020833333319, steps:4766, time-taken: 2.37min, time-elasped: 1956.27min
-> berries picked: 87 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8260 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [822, 1316, 1352, 952, 853, 721, 667, 593, 984]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 14, 14, 19, 8, 5, 14, 10, 23]
	Time taken saving stuff: 0.00s

=== episode:956 Env-steps-taken:67104
 	picked: 71 |actions: {0: 515, 1: 592, 2: 813, 3: 783, 4: 624, 5: 488, 6: 575, 7: 496, 8: 311}
episode: 956/2000 -> reward: 95.9322916666666, steps:5197, time-taken: 2.31min, time-elasped: 1958.58min
-> berries picked: 71 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8262 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [823, 1317, 1350, 957, 853, 725, 659, 591, 987]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 12, 19, 18, 14, 8, 10, 9, 22]
	Time taken saving stuff: 0.00s

=== episode:957 Env-steps-taken:71328
 	picked: 86 |actions: {0: 572, 1: 624, 2: 616, 3: 761, 4: 708, 5: 704, 6: 575, 7: 593, 8: 526}
episode: 957/2000 -> reward: 117.07291666666652, steps:5679, time-taken: 2.76min, time-elasped: 1961.35min
-> berries picked: 86 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8263 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [818, 1325, 1351, 958, 857, 724, 648, 591, 991]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 27, 17, 19, 17, 15, 11, 8, 11]
	Time taken saving stuff: 0.00s

=== episode:958 Env-steps-taken:68736
 	picked: 80 |actions: {0: 718, 1: 544, 2: 575, 3: 603, 4: 525, 5: 710, 6: 546, 7: 661, 8: 330}
episode: 958/2000 -> reward: 103.91666666666656, steps:5212, time-taken: 2.28min, time-elasped: 1963.63min
-> berries picked: 80 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8273 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [823, 1330, 1353, 958, 861, 719, 647, 595, 987]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 15, 16, 17, 17, 14, 10, 10, 19]
	Time taken saving stuff: 0.00s

=== episode:959 Env-steps-taken:71808
 	picked: 91 |actions: {0: 711, 1: 571, 2: 649, 3: 741, 4: 671, 5: 723, 6: 656, 7: 843, 8: 480}
episode: 959/2000 -> reward: 119.28645833333319, steps:6045, time-taken: 2.70min, time-elasped: 1966.33min
-> berries picked: 91 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8282 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [822, 1331, 1350, 956, 862, 725, 655, 594, 987]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 12, 24, 13, 18, 11, 8, 15, 21]
	Time taken saving stuff: 0.04s

=== episode:960 Env-steps-taken:74496
 	picked: 100 |actions: {0: 730, 1: 735, 2: 656, 3: 753, 4: 848, 5: 654, 6: 856, 7: 654, 8: 422}
episode: 960/2000 -> reward: 132.7708333333332, steps:6308, time-taken: 2.78min, time-elasped: 1969.11min
-> berries picked: 100 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8278 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [821, 1334, 1349, 956, 868, 720, 653, 591, 986]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 20, 18, 12, 11, 7, 10, 9, 14]
	Time taken saving stuff: 0.07s

=== episode:96 Env-steps-taken:75072
 	picked: 103 |actions: {0: 253, 1: 998, 2: 119, 3: 202, 4: 569, 5: 359, 6: 317, 7: 399, 8: 504}

==================================================
eval-episode: 960 -> reward: 135.59895833333323, steps: 3720.0, wall-time: 47.14s
-> berries picked: 103 of 800 | patches-visited: [1, 2] | juice left:-0.00
==================================================


=== episode:961 Env-steps-taken:67296
 	picked: 71 |actions: {0: 482, 1: 802, 2: 722, 3: 698, 4: 533, 5: 517, 6: 389, 7: 470, 8: 405}
episode: 961/2000 -> reward: 96.43229166666659, steps:5018, time-taken: 2.28min, time-elasped: 1972.18min
-> berries picked: 71 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8266 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [816, 1337, 1355, 948, 867, 715, 647, 595, 986]
	| approx positives in sample 512: 151
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 24, 18, 21, 14, 15, 13, 11, 22]
	Time taken saving stuff: 0.00s

=== episode:962 Env-steps-taken:62112
 	picked: 53 |actions: {0: 365, 1: 587, 2: 592, 3: 663, 4: 430, 5: 426, 6: 422, 7: 368, 8: 288}
episode: 962/2000 -> reward: 70.46354166666669, steps:4141, time-taken: 2.10min, time-elasped: 1974.29min
-> berries picked: 53 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8263 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [814, 1341, 1357, 954, 864, 718, 643, 587, 985]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 24, 21, 13, 16, 6, 7, 11, 21]
	Time taken saving stuff: 0.10s

=== episode:963 Env-steps-taken:75264
 	picked: 104 |actions: {0: 807, 1: 874, 2: 592, 3: 623, 4: 827, 5: 686, 6: 638, 7: 644, 8: 348}
episode: 963/2000 -> reward: 136.54166666666654, steps:6039, time-taken: 2.84min, time-elasped: 1977.13min
-> berries picked: 104 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8275 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [815, 1345, 1358, 956, 867, 725, 638, 587, 984]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 17, 16, 14, 16, 14, 12, 8, 21]
	Time taken saving stuff: 0.02s

=== episode:964 Env-steps-taken:72384
 	picked: 94 |actions: {0: 722, 1: 611, 2: 611, 3: 626, 4: 933, 5: 744, 6: 706, 7: 663, 8: 452}
episode: 964/2000 -> reward: 122.11458333333316, steps:6068, time-taken: 2.81min, time-elasped: 1979.95min
-> berries picked: 94 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8297 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [811, 1345, 1360, 960, 875, 721, 648, 593, 984]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 24, 17, 12, 13, 7, 8, 9, 22]
	Time taken saving stuff: 0.01s

=== episode:965 Env-steps-taken:69120
 	picked: 73 |actions: {0: 552, 1: 645, 2: 667, 3: 480, 4: 540, 5: 524, 6: 643, 7: 645, 8: 362}
episode: 965/2000 -> reward: 104.3749999999999, steps:5058, time-taken: 2.50min, time-elasped: 1982.45min
-> berries picked: 73 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8302 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [817, 1356, 1364, 952, 870, 721, 645, 590, 987]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 18, 15, 16, 12, 10, 16, 11, 19]
	Time taken saving stuff: 0.01s

=== episode:966 Env-steps-taken:59808
 	picked: 45 |actions: {0: 274, 1: 343, 2: 289, 3: 386, 4: 396, 5: 275, 6: 350, 7: 403, 8: 204}
episode: 966/2000 -> reward: 59.42187500000005, steps:2920, time-taken: 1.64min, time-elasped: 1984.09min
-> berries picked: 45 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8307 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [817, 1351, 1361, 958, 873, 722, 649, 590, 986]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 28, 20, 16, 12, 9, 7, 13, 18]
	Time taken saving stuff: 0.00s

=== episode:967 Env-steps-taken:66336
 	picked: 68 |actions: {0: 611, 1: 521, 2: 567, 3: 664, 4: 781, 5: 481, 6: 496, 7: 452, 8: 361}
episode: 967/2000 -> reward: 91.6041666666666, steps:4934, time-taken: 2.33min, time-elasped: 1986.42min
-> berries picked: 68 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8315 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [818, 1347, 1367, 964, 877, 723, 652, 585, 982]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 15, 20, 16, 13, 15, 12, 8, 11]
	Time taken saving stuff: 0.01s

=== episode:968 Env-steps-taken:75936
 	picked: 95 |actions: {0: 664, 1: 727, 2: 665, 3: 736, 4: 630, 5: 605, 6: 724, 7: 620, 8: 401}
episode: 968/2000 -> reward: 140.55729166666663, steps:5772, time-taken: 2.75min, time-elasped: 1989.18min
-> berries picked: 95 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8337 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [811, 1355, 1373, 970, 880, 723, 652, 590, 983]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 13, 14, 11, 12, 10, 11, 10, 23]
	Time taken saving stuff: 0.03s

=== episode:969 Env-steps-taken:64800
 	picked: 57 |actions: {0: 522, 1: 443, 2: 583, 3: 482, 4: 441, 5: 574, 6: 624, 7: 555, 8: 287}
episode: 969/2000 -> reward: 84.23437499999996, steps:4511, time-taken: 2.14min, time-elasped: 1991.32min
-> berries picked: 57 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8353 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [814, 1355, 1370, 970, 882, 725, 657, 596, 984]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 15, 19, 13, 16, 7, 15, 8, 25]
	Time taken saving stuff: 0.09s

=== episode:970 Env-steps-taken:66624
 	picked: 66 |actions: {0: 456, 1: 570, 2: 628, 3: 607, 4: 825, 5: 541, 6: 603, 7: 589, 8: 432}
episode: 970/2000 -> reward: 93.71874999999993, steps:5251, time-taken: 2.50min, time-elasped: 1993.82min
-> berries picked: 66 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8366 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [814, 1358, 1369, 978, 880, 727, 660, 596, 984]
	| approx positives in sample 512: 143
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 17, 25, 11, 16, 17, 11, 12, 22]
	Time taken saving stuff: 0.05s

=== episode:97 Env-steps-taken:65088
 	picked: 64 |actions: {0: 329, 1: 190, 2: 707, 3: 74, 4: 395, 5: 485, 6: 230, 7: 393, 8: 829}

==================================================
eval-episode: 970 -> reward: 84.94791666666661, steps: 3632.0, wall-time: 40.62s
-> berries picked: 64 of 800 | patches-visited: [1, 5] | juice left:-0.00
==================================================


=== episode:971 Env-steps-taken:62784
 	picked: 52 |actions: {0: 289, 1: 310, 2: 412, 3: 231, 4: 339, 5: 339, 6: 337, 7: 333, 8: 165}
episode: 971/2000 -> reward: 73.13541666666669, steps:2755, time-taken: 1.53min, time-elasped: 1996.03min
-> berries picked: 52 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8369 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [815, 1359, 1369, 972, 878, 730, 661, 601, 984]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 14, 14, 15, 13, 11, 10, 11, 28]
	Time taken saving stuff: 0.10s

=== episode:972 Env-steps-taken:58080
 	picked: 39 |actions: {0: 458, 1: 331, 2: 539, 3: 424, 4: 626, 5: 374, 6: 383, 7: 681, 8: 212}
episode: 972/2000 -> reward: 50.26562500000004, steps:4028, time-taken: 2.99min, time-elasped: 1999.02min
-> berries picked: 39 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8354 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [816, 1355, 1367, 968, 878, 729, 660, 598, 983]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 27, 14, 15, 12, 11, 9, 6, 14]
	Time taken saving stuff: 0.00s

=== episode:973 Env-steps-taken:67104
 	picked: 68 |actions: {0: 413, 1: 438, 2: 567, 3: 552, 4: 865, 5: 550, 6: 547, 7: 381, 8: 475}
episode: 973/2000 -> reward: 96.1041666666666, steps:4788, time-taken: 2.31min, time-elasped: 2001.33min
-> berries picked: 68 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8348 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [811, 1357, 1368, 973, 873, 730, 656, 595, 985]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 17, 12, 19, 8, 7, 10, 15, 28]
	Time taken saving stuff: 0.01s

=== episode:974 Env-steps-taken:56544
 	picked: 28 |actions: {0: 280, 1: 247, 2: 251, 3: 319, 4: 329, 5: 237, 6: 216, 7: 190, 8: 334}
episode: 974/2000 -> reward: 43.39583333333334, steps:2403, time-taken: 1.54min, time-elasped: 2002.88min
-> berries picked: 28 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8347 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [812, 1357, 1371, 974, 869, 731, 657, 590, 986]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 22, 20, 19, 8, 9, 19, 4, 12]
	Time taken saving stuff: 0.01s

=== episode:975 Env-steps-taken:70656
 	picked: 88 |actions: {0: 673, 1: 548, 2: 702, 3: 567, 4: 784, 5: 562, 6: 765, 7: 832, 8: 425}
episode: 975/2000 -> reward: 112.57291666666653, steps:5858, time-taken: 3.35min, time-elasped: 2006.24min
-> berries picked: 88 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8357 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [815, 1361, 1374, 969, 869, 729, 661, 592, 987]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 24, 16, 16, 16, 7, 16, 10, 21]
	Time taken saving stuff: 0.01s

=== episode:976 Env-steps-taken:69216
 	picked: 82 |actions: {0: 681, 1: 523, 2: 663, 3: 521, 4: 671, 5: 551, 6: 678, 7: 552, 8: 373}
episode: 976/2000 -> reward: 104.35937499999987, steps:5213, time-taken: 2.62min, time-elasped: 2008.86min
-> berries picked: 82 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8344 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [819, 1360, 1373, 967, 864, 728, 657, 591, 985]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 16, 14, 8, 18, 14, 16, 10, 21]
	Time taken saving stuff: 0.01s

=== episode:977 Env-steps-taken:64128
 	picked: 56 |actions: {0: 472, 1: 540, 2: 558, 3: 561, 4: 504, 5: 388, 6: 460, 7: 520, 8: 326}
episode: 977/2000 -> reward: 81.29166666666667, steps:4329, time-taken: 2.25min, time-elasped: 2011.12min
-> berries picked: 56 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8334 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [824, 1360, 1367, 966, 867, 721, 656, 585, 988]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 14, 19, 20, 11, 12, 12, 8, 14]
	Time taken saving stuff: 0.02s

=== episode:978 Env-steps-taken:70848
 	picked: 83 |actions: {0: 470, 1: 487, 2: 608, 3: 518, 4: 716, 5: 619, 6: 489, 7: 607, 8: 466}
episode: 978/2000 -> reward: 115.24479166666656, steps:4980, time-taken: 2.52min, time-elasped: 2013.64min
-> berries picked: 83 of 800 | patches-visited: [0, 4, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8354 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [826, 1359, 1370, 966, 873, 719, 661, 590, 990]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 23, 17, 15, 23, 9, 8, 9, 22]
	Time taken saving stuff: 0.03s

=== episode:979 Env-steps-taken:72000
 	picked: 83 |actions: {0: 651, 1: 675, 2: 632, 3: 612, 4: 643, 5: 647, 6: 857, 7: 461, 8: 377}
episode: 979/2000 -> reward: 120.74479166666652, steps:5555, time-taken: 2.65min, time-elasped: 2016.29min
-> berries picked: 83 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8350 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [824, 1359, 1360, 970, 878, 726, 660, 583, 990]
	| approx positives in sample 512: 145
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 15, 32, 14, 18, 13, 8, 9, 21]
	Time taken saving stuff: 0.08s

=== episode:980 Env-steps-taken:60576
 	picked: 49 |actions: {0: 283, 1: 399, 2: 377, 3: 464, 4: 368, 5: 325, 6: 378, 7: 294, 8: 214}
episode: 980/2000 -> reward: 63.19270833333339, steps:3102, time-taken: 1.68min, time-elasped: 2017.98min
-> berries picked: 49 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8346 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [820, 1359, 1358, 969, 881, 724, 659, 584, 992]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 12, 12, 21, 8, 15, 9, 9, 23]
	Time taken saving stuff: 0.14s

=== episode:98 Env-steps-taken:58368
 	picked: 41 |actions: {0: 174, 1: 107, 2: 1043, 3: 511, 4: 407, 5: 183, 6: 750, 7: 49, 8: 1083}

==================================================
eval-episode: 980 -> reward: 51.65104166666671, steps: 4307.0, wall-time: 45.67s
-> berries picked: 41 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:981 Env-steps-taken:70944
 	picked: 85 |actions: {0: 467, 1: 642, 2: 654, 3: 640, 4: 984, 5: 635, 6: 676, 7: 572, 8: 402}
episode: 981/2000 -> reward: 115.1302083333332, steps:5672, time-taken: 2.74min, time-elasped: 2021.48min
-> berries picked: 85 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8335 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [819, 1363, 1354, 969, 878, 729, 654, 576, 993]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 19, 14, 12, 4, 11, 13, 6, 26]
	Time taken saving stuff: 0.01s

=== episode:982 Env-steps-taken:64608
 	picked: 67 |actions: {0: 493, 1: 654, 2: 644, 3: 817, 4: 845, 5: 708, 6: 597, 7: 464, 8: 465}
episode: 982/2000 -> reward: 82.6614583333333, steps:5687, time-taken: 2.60min, time-elasped: 2024.08min
-> berries picked: 67 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8303 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [816, 1363, 1345, 969, 871, 727, 647, 573, 992]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 23, 19, 14, 13, 11, 7, 8, 21]
	Time taken saving stuff: 0.10s

=== episode:983 Env-steps-taken:68160
 	picked: 83 |actions: {0: 524, 1: 815, 2: 427, 3: 482, 4: 680, 5: 504, 6: 538, 7: 478, 8: 391}
episode: 983/2000 -> reward: 100.74479166666659, steps:4839, time-taken: 2.76min, time-elasped: 2026.85min
-> berries picked: 83 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8308 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [816, 1367, 1347, 965, 874, 728, 652, 567, 992]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 14, 19, 12, 20, 12, 11, 12, 27]
	Time taken saving stuff: 0.10s

=== episode:984 Env-steps-taken:76512
 	picked: 108 |actions: {0: 732, 1: 870, 2: 680, 3: 520, 4: 869, 5: 750, 6: 773, 7: 637, 8: 430}
episode: 984/2000 -> reward: 141.4270833333333, steps:6261, time-taken: 3.25min, time-elasped: 2030.10min
-> berries picked: 108 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8313 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [820, 1374, 1346, 965, 875, 728, 647, 565, 993]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 20, 17, 19, 8, 14, 6, 11, 17]
	Time taken saving stuff: 0.09s

=== episode:985 Env-steps-taken:61248
 	picked: 49 |actions: {0: 286, 1: 468, 2: 484, 3: 369, 4: 444, 5: 285, 6: 369, 7: 475, 8: 291}
episode: 985/2000 -> reward: 66.69270833333337, steps:3471, time-taken: 1.86min, time-elasped: 2031.96min
-> berries picked: 49 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8305 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [818, 1380, 1344, 961, 877, 723, 644, 563, 995]
	| approx positives in sample 512: 143
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 22, 21, 21, 20, 10, 10, 4, 19]
	Time taken saving stuff: 0.09s

=== episode:986 Env-steps-taken:58560
 	picked: 39 |actions: {0: 301, 1: 368, 2: 487, 3: 377, 4: 584, 5: 425, 6: 522, 7: 455, 8: 406}
episode: 986/2000 -> reward: 52.76562500000003, steps:3925, time-taken: 1.85min, time-elasped: 2033.82min
-> berries picked: 39 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8296 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [820, 1381, 1342, 965, 873, 715, 642, 563, 995]
	| approx positives in sample 512: 163
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 31, 21, 21, 13, 13, 11, 11, 26]
	Time taken saving stuff: 0.02s

=== episode:987 Env-steps-taken:60576
 	picked: 45 |actions: {0: 417, 1: 422, 2: 458, 3: 596, 4: 641, 5: 566, 6: 561, 7: 552, 8: 424}
episode: 987/2000 -> reward: 62.92187500000006, steps:4637, time-taken: 2.32min, time-elasped: 2036.14min
-> berries picked: 45 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8281 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [814, 1381, 1343, 963, 877, 711, 634, 564, 994]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 18, 13, 22, 10, 14, 8, 7, 16]
	Time taken saving stuff: 0.00s

=== episode:988 Env-steps-taken:71808
 	picked: 93 |actions: {0: 581, 1: 734, 2: 773, 3: 685, 4: 851, 5: 557, 6: 607, 7: 552, 8: 418}
episode: 988/2000 -> reward: 119.22916666666652, steps:5758, time-taken: 2.60min, time-elasped: 2038.75min
-> berries picked: 93 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8296 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [814, 1387, 1343, 962, 881, 715, 631, 567, 996]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 22, 15, 12, 24, 15, 17, 9, 20]
	Time taken saving stuff: 0.01s

=== episode:989 Env-steps-taken:70656
 	picked: 85 |actions: {0: 583, 1: 675, 2: 732, 3: 501, 4: 696, 5: 428, 6: 650, 7: 528, 8: 396}
episode: 989/2000 -> reward: 113.63020833333319, steps:5189, time-taken: 2.55min, time-elasped: 2041.31min
-> berries picked: 85 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8321 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [813, 1393, 1352, 960, 884, 719, 631, 572, 997]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 14, 8, 12, 16, 10, 5, 7, 23]
	Time taken saving stuff: 0.00s

=== episode:990 Env-steps-taken:66240
 	picked: 80 |actions: {0: 551, 1: 714, 2: 773, 3: 555, 4: 672, 5: 584, 6: 523, 7: 504, 8: 498}
episode: 990/2000 -> reward: 90.41666666666656, steps:5374, time-taken: 2.39min, time-elasped: 2043.70min
-> berries picked: 80 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8322 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [815, 1391, 1352, 968, 885, 718, 629, 567, 997]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 16, 12, 14, 13, 15, 10, 7, 18]
	Time taken saving stuff: 0.08s

=== episode:99 Env-steps-taken:90816
 	picked: 162 |actions: {0: 825, 1: 514, 2: 902, 3: 558, 4: 801, 5: 450, 6: 675, 7: 248, 8: 488}

==================================================
eval-episode: 990 -> reward: 214.71875000000048, steps: 5461.0, wall-time: 49.92s
-> berries picked: 162 of 800 | patches-visited: [1, 2, 3] | juice left:-0.00
==================================================


=== episode:991 Env-steps-taken:69888
 	picked: 82 |actions: {0: 471, 1: 608, 2: 509, 3: 528, 4: 559, 5: 475, 6: 505, 7: 360, 8: 286}
episode: 991/2000 -> reward: 107.85937499999987, steps:4301, time-taken: 2.19min, time-elasped: 2046.72min
-> berries picked: 82 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8324 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [813, 1392, 1352, 973, 886, 718, 630, 563, 997]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 16, 24, 21, 17, 8, 12, 5, 29]
	Time taken saving stuff: 0.03s

=== episode:992 Env-steps-taken:73536
 	picked: 90 |actions: {0: 490, 1: 601, 2: 488, 3: 565, 4: 597, 5: 811, 6: 548, 7: 352, 8: 273}
episode: 992/2000 -> reward: 126.9010416666665, steps:4725, time-taken: 2.47min, time-elasped: 2049.19min
-> berries picked: 90 of 800 | patches-visited: [0, 1, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8330 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [813, 1382, 1353, 979, 886, 723, 633, 562, 999]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 22, 10, 12, 18, 10, 11, 11, 23]
	Time taken saving stuff: 0.02s

=== episode:993 Env-steps-taken:69024
 	picked: 83 |actions: {0: 548, 1: 501, 2: 547, 3: 400, 4: 632, 5: 598, 6: 571, 7: 454, 8: 344}
episode: 993/2000 -> reward: 105.24479166666654, steps:4595, time-taken: 2.21min, time-elasped: 2051.41min
-> berries picked: 83 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8337 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [813, 1381, 1350, 978, 890, 725, 638, 560, 1002]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 21, 18, 8, 18, 9, 13, 9, 19]
	Time taken saving stuff: 0.01s

=== episode:994 Env-steps-taken:68160
 	picked: 74 |actions: {0: 593, 1: 649, 2: 678, 3: 534, 4: 718, 5: 561, 6: 703, 7: 551, 8: 465}
episode: 994/2000 -> reward: 100.87499999999993, steps:5452, time-taken: 2.65min, time-elasped: 2054.07min
-> berries picked: 74 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8325 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [805, 1384, 1347, 980, 893, 721, 635, 559, 1001]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 21, 25, 16, 10, 13, 10, 6, 20]
	Time taken saving stuff: 0.01s

=== episode:995 Env-steps-taken:69024
 	picked: 76 |actions: {0: 480, 1: 665, 2: 670, 3: 444, 4: 708, 5: 593, 6: 693, 7: 702, 8: 380}
episode: 995/2000 -> reward: 105.64583333333321, steps:5335, time-taken: 2.50min, time-elasped: 2056.57min
-> berries picked: 76 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8325 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [803, 1392, 1338, 980, 893, 725, 638, 555, 1001]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 22, 16, 22, 16, 18, 8, 8, 21]
	Time taken saving stuff: 0.01s

=== episode:996 Env-steps-taken:69984
 	picked: 82 |actions: {0: 470, 1: 674, 2: 600, 3: 573, 4: 1066, 5: 494, 6: 530, 7: 391, 8: 568}
episode: 996/2000 -> reward: 109.41666666666654, steps:5366, time-taken: 2.53min, time-elasped: 2059.11min
-> berries picked: 82 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8310 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [805, 1389, 1342, 974, 901, 722, 631, 546, 1000]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 23, 15, 10, 10, 9, 12, 7, 24]
	Time taken saving stuff: 0.00s

=== episode:997 Env-steps-taken:62016
 	picked: 53 |actions: {0: 426, 1: 359, 2: 394, 3: 284, 4: 401, 5: 358, 6: 522, 7: 395, 8: 242}
episode: 997/2000 -> reward: 70.4635416666667, steps:3381, time-taken: 1.74min, time-elasped: 2060.85min
-> berries picked: 53 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8313 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [810, 1387, 1343, 970, 901, 725, 632, 546, 999]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 16, 16, 21, 12, 9, 6, 6, 17]
	Time taken saving stuff: 0.04s

=== episode:998 Env-steps-taken:73824
 	picked: 87 |actions: {0: 541, 1: 591, 2: 647, 3: 517, 4: 655, 5: 549, 6: 590, 7: 502, 8: 307}
episode: 998/2000 -> reward: 130.01562499999986, steps:4899, time-taken: 2.58min, time-elasped: 2063.43min
-> berries picked: 87 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8314 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [809, 1396, 1340, 968, 902, 724, 626, 548, 1001]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 27, 17, 21, 11, 4, 7, 6, 16]
	Time taken saving stuff: 0.10s

=== episode:999 Env-steps-taken:74400
 	picked: 94 |actions: {0: 798, 1: 883, 2: 911, 3: 525, 4: 894, 5: 632, 6: 563, 7: 578, 8: 466}
episode: 999/2000 -> reward: 132.61458333333317, steps:6250, time-taken: 2.87min, time-elasped: 2066.30min
-> berries picked: 94 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8309 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [810, 1392, 1348, 968, 902, 722, 624, 542, 1001]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 19, 15, 15, 14, 10, 15, 8, 27]
	Time taken saving stuff: 0.03s

=== episode:1000 Env-steps-taken:76416
 	picked: 103 |actions: {0: 754, 1: 838, 2: 684, 3: 601, 4: 748, 5: 610, 6: 728, 7: 554, 8: 403}
episode: 1000/2000 -> reward: 142.65624999999991, steps:5920, time-taken: 2.71min, time-elasped: 2069.01min
-> berries picked: 103 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8321 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [811, 1389, 1344, 979, 903, 718, 627, 548, 1002]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 25, 13, 17, 11, 16, 10, 7, 25]
	Time taken saving stuff: 0.16s

=== episode:100 Env-steps-taken:90048
 	picked: 157 |actions: {0: 1363, 1: 473, 2: 834, 3: 279, 4: 1395, 5: 571, 6: 552, 7: 251, 8: 799}

==================================================
eval-episode: 1000 -> reward: 208.1770833333338, steps: 6517.0, wall-time: 60.03s
-> berries picked: 157 of 800 | patches-visited: [1, 2, 9] | juice left:-0.00
==================================================


=== episode:1001 Env-steps-taken:76032
 	picked: 102 |actions: {0: 622, 1: 653, 2: 720, 3: 742, 4: 916, 5: 711, 6: 861, 7: 688, 8: 551}
episode: 1001/2000 -> reward: 140.65624999999994, steps:6464, time-taken: 3.00min, time-elasped: 2073.02min
-> berries picked: 102 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8317 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [811, 1390, 1338, 986, 894, 721, 632, 544, 1001]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 18, 16, 19, 18, 6, 5, 9, 14]
	Time taken saving stuff: 0.00s

=== episode:1002 Env-steps-taken:77472
 	picked: 107 |actions: {0: 704, 1: 795, 2: 854, 3: 755, 4: 897, 5: 686, 6: 754, 7: 747, 8: 416}
episode: 1002/2000 -> reward: 147.86979166666666, steps:6608, time-taken: 3.05min, time-elasped: 2076.07min
-> berries picked: 107 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8339 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [811, 1396, 1343, 985, 901, 725, 634, 542, 1002]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 17, 12, 16, 12, 12, 6, 13, 15]
	Time taken saving stuff: 0.09s

=== episode:1003 Env-steps-taken:71424
 	picked: 83 |actions: {0: 497, 1: 483, 2: 607, 3: 470, 4: 626, 5: 451, 6: 590, 7: 477, 8: 355}
episode: 1003/2000 -> reward: 118.24479166666652, steps:4556, time-taken: 2.39min, time-elasped: 2078.47min
-> berries picked: 83 of 800 | patches-visited: [0, 2, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8340 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [811, 1394, 1339, 983, 903, 730, 634, 543, 1003]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 24, 21, 12, 11, 15, 9, 6, 14]
	Time taken saving stuff: 0.08s

=== episode:1004 Env-steps-taken:63072
 	picked: 64 |actions: {0: 612, 1: 472, 2: 460, 3: 381, 4: 745, 5: 596, 6: 746, 7: 533, 8: 468}
episode: 1004/2000 -> reward: 74.83333333333333, steps:5013, time-taken: 2.29min, time-elasped: 2080.77min
-> berries picked: 64 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8334 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [806, 1391, 1338, 981, 897, 734, 639, 545, 1003]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 23, 22, 10, 15, 14, 9, 6, 21]
	Time taken saving stuff: 0.00s

=== episode:1005 Env-steps-taken:58272
 	picked: 37 |actions: {0: 287, 1: 319, 2: 353, 3: 284, 4: 382, 5: 320, 6: 309, 7: 177, 8: 223}
episode: 1005/2000 -> reward: 51.88020833333337, steps:2654, time-taken: 1.56min, time-elasped: 2082.33min
-> berries picked: 37 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8338 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [806, 1390, 1337, 981, 901, 735, 642, 543, 1003]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 12, 15, 19, 8, 7, 6, 7, 19]
	Time taken saving stuff: 0.01s

=== episode:1006 Env-steps-taken:70752
 	picked: 84 |actions: {0: 597, 1: 730, 2: 463, 3: 550, 4: 697, 5: 459, 6: 530, 7: 512, 8: 363}
episode: 1006/2000 -> reward: 114.68749999999989, steps:4901, time-taken: 2.34min, time-elasped: 2084.67min
-> berries picked: 84 of 800 | patches-visited: [0, 3, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8336 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [799, 1396, 1341, 979, 901, 741, 638, 537, 1004]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 20, 16, 16, 10, 11, 10, 11, 24]
	Time taken saving stuff: 0.01s

=== episode:1007 Env-steps-taken:66048
 	picked: 68 |actions: {0: 410, 1: 542, 2: 450, 3: 534, 4: 727, 5: 631, 6: 600, 7: 462, 8: 358}
episode: 1007/2000 -> reward: 90.66145833333326, steps:4714, time-taken: 2.37min, time-elasped: 2087.05min
-> berries picked: 68 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8339 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [795, 1389, 1342, 981, 908, 743, 641, 536, 1004]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 18, 15, 18, 16, 9, 13, 5, 18]
	Time taken saving stuff: 0.00s

=== episode:1008 Env-steps-taken:65856
 	picked: 70 |actions: {0: 505, 1: 784, 2: 613, 3: 445, 4: 544, 5: 506, 6: 613, 7: 379, 8: 347}
episode: 1008/2000 -> reward: 89.48958333333327, steps:4736, time-taken: 2.15min, time-elasped: 2089.21min
-> berries picked: 70 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8337 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [799, 1384, 1348, 981, 904, 743, 639, 536, 1003]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 18, 22, 15, 18, 6, 8, 10, 21]
	Time taken saving stuff: 0.01s

=== episode:1009 Env-steps-taken:77184
 	picked: 108 |actions: {0: 673, 1: 787, 2: 865, 3: 702, 4: 947, 5: 660, 6: 649, 7: 696, 8: 408}
episode: 1009/2000 -> reward: 146.31249999999997, steps:6387, time-taken: 3.01min, time-elasped: 2092.22min
-> berries picked: 108 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8337 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [802, 1385, 1346, 983, 899, 740, 638, 539, 1005]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 18, 20, 14, 11, 13, 8, 6, 20]
	Time taken saving stuff: 0.01s

=== episode:1010 Env-steps-taken:79008
 	picked: 111 |actions: {0: 704, 1: 854, 2: 861, 3: 682, 4: 950, 5: 781, 6: 781, 7: 609, 8: 418}
episode: 1010/2000 -> reward: 155.64062500000003, steps:6640, time-taken: 3.16min, time-elasped: 2095.40min
-> berries picked: 111 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8352 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [807, 1385, 1344, 987, 901, 748, 632, 541, 1007]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 22, 15, 16, 18, 14, 6, 6, 16]
	Time taken saving stuff: 0.16s

=== episode:101 Env-steps-taken:72672
 	picked: 98 |actions: {0: 668, 1: 586, 2: 143, 3: 216, 4: 415, 5: 218, 6: 717, 7: 192, 8: 535}

==================================================
eval-episode: 1010 -> reward: 123.38541666666647, steps: 3690.0, wall-time: 45.32s
-> berries picked: 98 of 800 | patches-visited: [1, 7] | juice left:-0.00
==================================================


=== episode:1011 Env-steps-taken:69408
 	picked: 78 |actions: {0: 567, 1: 671, 2: 569, 3: 654, 4: 776, 5: 724, 6: 681, 7: 573, 8: 375}
episode: 1011/2000 -> reward: 107.53124999999989, steps:5590, time-taken: 2.57min, time-elasped: 2098.73min
-> berries picked: 78 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8320 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [796, 1370, 1340, 982, 900, 750, 635, 541, 1006]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 15, 22, 11, 8, 10, 6, 8, 13]
	Time taken saving stuff: 0.01s

=== episode:1012 Env-steps-taken:56640
 	picked: 29 |actions: {0: 129, 1: 188, 2: 133, 3: 222, 4: 255, 5: 158, 6: 197, 7: 119, 8: 142}
episode: 1012/2000 -> reward: 41.89583333333336, steps:1543, time-taken: 1.03min, time-elasped: 2099.76min
-> berries picked: 29 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8315 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [794, 1369, 1340, 985, 903, 748, 634, 536, 1006]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 22, 20, 14, 12, 11, 8, 4, 17]
	Time taken saving stuff: 0.01s

=== episode:1013 Env-steps-taken:68928
 	picked: 80 |actions: {0: 568, 1: 471, 2: 447, 3: 457, 4: 495, 5: 464, 6: 495, 7: 471, 8: 295}
episode: 1013/2000 -> reward: 104.91666666666656, steps:4163, time-taken: 2.15min, time-elasped: 2101.92min
-> berries picked: 80 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8323 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [801, 1364, 1337, 979, 908, 751, 634, 541, 1008]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 19, 18, 9, 8, 16, 4, 12, 22]
	Time taken saving stuff: 0.02s

=== episode:1014 Env-steps-taken:63264
 	picked: 71 |actions: {0: 559, 1: 565, 2: 624, 3: 507, 4: 534, 5: 634, 6: 473, 7: 432, 8: 442}
episode: 1014/2000 -> reward: 73.10416666666666, steps:4770, time-taken: 2.34min, time-elasped: 2104.26min
-> berries picked: 71 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8320 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [800, 1362, 1337, 979, 909, 753, 631, 536, 1013]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 14, 16, 17, 12, 11, 17, 8, 23]
	Time taken saving stuff: 0.00s

=== episode:1015 Env-steps-taken:56160
 	picked: 30 |actions: {0: 118, 1: 206, 2: 252, 3: 217, 4: 232, 5: 206, 6: 207, 7: 230, 8: 141}
episode: 1015/2000 -> reward: 40.78125, steps:1809, time-taken: 1.15min, time-elasped: 2105.41min
-> berries picked: 30 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8322 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [799, 1357, 1340, 982, 910, 754, 632, 535, 1013]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 20, 18, 18, 5, 17, 6, 4, 9]
	Time taken saving stuff: 0.03s

=== episode:1016 Env-steps-taken:63552
 	picked: 50 |actions: {0: 309, 1: 288, 2: 358, 3: 281, 4: 285, 5: 292, 6: 286, 7: 212, 8: 151}
episode: 1016/2000 -> reward: 78.63541666666667, steps:2462, time-taken: 1.51min, time-elasped: 2106.93min
-> berries picked: 50 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8339 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [799, 1363, 1346, 984, 913, 752, 635, 531, 1016]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 20, 11, 16, 11, 17, 12, 5, 15]
	Time taken saving stuff: 0.09s

=== episode:1017 Env-steps-taken:65376
 	picked: 67 |actions: {0: 594, 1: 575, 2: 662, 3: 480, 4: 457, 5: 454, 6: 493, 7: 418, 8: 328}
episode: 1017/2000 -> reward: 84.77604166666661, steps:4461, time-taken: 2.20min, time-elasped: 2109.14min
-> berries picked: 67 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8349 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [806, 1366, 1351, 988, 913, 744, 634, 531, 1016]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 21, 19, 9, 14, 10, 13, 8, 22]
	Time taken saving stuff: 0.09s

=== episode:1018 Env-steps-taken:80064
 	picked: 117 |actions: {0: 714, 1: 788, 2: 733, 3: 857, 4: 710, 5: 846, 6: 706, 7: 722, 8: 388}
episode: 1018/2000 -> reward: 158.8541666666667, steps:6464, time-taken: 3.34min, time-elasped: 2112.49min
-> berries picked: 117 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8370 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [807, 1366, 1354, 1000, 913, 746, 634, 535, 1015]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 23, 16, 11, 12, 16, 6, 12, 17]
	Time taken saving stuff: 0.10s

=== episode:1019 Env-steps-taken:76320
 	picked: 102 |actions: {0: 594, 1: 619, 2: 882, 3: 626, 4: 736, 5: 527, 6: 540, 7: 580, 8: 383}
episode: 1019/2000 -> reward: 142.15624999999994, steps:5487, time-taken: 2.62min, time-elasped: 2115.11min
-> berries picked: 102 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8407 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [814, 1384, 1357, 1005, 917, 743, 631, 539, 1017]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 25, 20, 20, 13, 12, 8, 11, 16]
	Time taken saving stuff: 0.10s

=== episode:1020 Env-steps-taken:63072
 	picked: 55 |actions: {0: 349, 1: 359, 2: 445, 3: 373, 4: 516, 5: 374, 6: 402, 7: 339, 8: 290}
episode: 1020/2000 -> reward: 75.84895833333334, steps:3447, time-taken: 1.88min, time-elasped: 2116.99min
-> berries picked: 55 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8413 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [812, 1384, 1359, 1003, 917, 746, 634, 540, 1018]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 25, 16, 15, 8, 11, 16, 8, 17]
	Time taken saving stuff: 0.05s

=== episode:102 Env-steps-taken:62400
 	picked: 53 |actions: {0: 405, 1: 395, 2: 247, 3: 516, 4: 686, 5: 104, 6: 175, 7: 41, 8: 931}

==================================================
eval-episode: 1020 -> reward: 71.07812500000001, steps: 3500.0, wall-time: 46.46s
-> berries picked: 53 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:1021 Env-steps-taken:66336
 	picked: 72 |actions: {0: 580, 1: 473, 2: 769, 3: 451, 4: 557, 5: 455, 6: 666, 7: 508, 8: 359}
episode: 1021/2000 -> reward: 91.87499999999994, steps:4818, time-taken: 2.41min, time-elasped: 2120.18min
-> berries picked: 72 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8398 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [807, 1381, 1364, 1002, 912, 746, 631, 536, 1019]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 17, 20, 13, 13, 10, 8, 9, 18]
	Time taken saving stuff: 0.03s

=== episode:1022 Env-steps-taken:69696
 	picked: 86 |actions: {0: 497, 1: 426, 2: 633, 3: 433, 4: 456, 5: 505, 6: 634, 7: 501, 8: 286}
episode: 1022/2000 -> reward: 105.80208333333324, steps:4371, time-taken: 2.14min, time-elasped: 2122.33min
-> berries picked: 86 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8420 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [813, 1380, 1369, 996, 916, 749, 639, 537, 1021]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 20, 18, 9, 13, 10, 8, 12, 20]
	Time taken saving stuff: 0.09s

=== episode:1023 Env-steps-taken:67392
 	picked: 70 |actions: {0: 505, 1: 603, 2: 499, 3: 425, 4: 663, 5: 552, 6: 489, 7: 593, 8: 385}
episode: 1023/2000 -> reward: 97.48958333333326, steps:4714, time-taken: 2.38min, time-elasped: 2124.71min
-> berries picked: 70 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8422 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [814, 1379, 1370, 992, 915, 748, 642, 537, 1025]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 17, 22, 5, 17, 18, 8, 5, 28]
	Time taken saving stuff: 0.10s

=== episode:1024 Env-steps-taken:64224
 	picked: 56 |actions: {0: 310, 1: 400, 2: 451, 3: 442, 4: 367, 5: 353, 6: 270, 7: 412, 8: 235}
episode: 1024/2000 -> reward: 81.79166666666666, steps:3240, time-taken: 1.77min, time-elasped: 2126.49min
-> berries picked: 56 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8418 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [812, 1379, 1371, 992, 913, 746, 642, 537, 1026]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 21, 28, 21, 9, 9, 10, 10, 24]
	Time taken saving stuff: 0.00s

=== episode:1025 Env-steps-taken:73824
 	picked: 100 |actions: {0: 749, 1: 847, 2: 710, 3: 651, 4: 656, 5: 676, 6: 737, 7: 586, 8: 367}
episode: 1025/2000 -> reward: 129.2708333333332, steps:5979, time-taken: 3.09min, time-elasped: 2129.58min
-> berries picked: 100 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8436 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [813, 1387, 1376, 994, 906, 752, 644, 539, 1025]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 17, 13, 16, 17, 8, 14, 10, 21]
	Time taken saving stuff: 0.03s

=== episode:1026 Env-steps-taken:68352
 	picked: 69 |actions: {0: 285, 1: 325, 2: 409, 3: 352, 4: 355, 5: 297, 6: 383, 7: 375, 8: 202}
episode: 1026/2000 -> reward: 101.10416666666661, steps:2983, time-taken: 1.69min, time-elasped: 2131.28min
-> berries picked: 69 of 800 | patches-visited: [0, 2, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8428 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [808, 1372, 1382, 997, 905, 751, 645, 544, 1024]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 21, 27, 9, 12, 11, 11, 8, 22]
	Time taken saving stuff: 0.01s

=== episode:1027 Env-steps-taken:71232
 	picked: 80 |actions: {0: 392, 1: 495, 2: 614, 3: 536, 4: 595, 5: 531, 6: 546, 7: 631, 8: 296}
episode: 1027/2000 -> reward: 114.53124999999989, steps:4636, time-taken: 2.23min, time-elasped: 2133.51min
-> berries picked: 80 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8420 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [805, 1364, 1379, 999, 908, 758, 647, 539, 1021]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 17, 18, 15, 15, 10, 12, 6, 15]
	Time taken saving stuff: 0.09s

=== episode:1028 Env-steps-taken:75552
 	picked: 101 |actions: {0: 565, 1: 782, 2: 692, 3: 621, 4: 731, 5: 631, 6: 569, 7: 536, 8: 404}
episode: 1028/2000 -> reward: 137.32812499999991, steps:5531, time-taken: 2.83min, time-elasped: 2136.35min
-> berries picked: 101 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8429 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [808, 1352, 1386, 1005, 904, 763, 647, 540, 1024]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 26, 19, 21, 10, 14, 16, 7, 12]
	Time taken saving stuff: 0.11s

=== episode:1029 Env-steps-taken:65088
 	picked: 68 |actions: {0: 515, 1: 471, 2: 527, 3: 762, 4: 877, 5: 521, 6: 542, 7: 484, 8: 597}
episode: 1029/2000 -> reward: 85.60416666666664, steps:5296, time-taken: 2.76min, time-elasped: 2139.11min
-> berries picked: 68 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8410 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [808, 1346, 1386, 1002, 910, 751, 645, 539, 1023]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 19, 10, 17, 16, 10, 8, 5, 25]
	Time taken saving stuff: 0.02s

=== episode:1030 Env-steps-taken:70656
 	picked: 81 |actions: {0: 527, 1: 591, 2: 628, 3: 421, 4: 641, 5: 443, 6: 468, 7: 582, 8: 389}
episode: 1030/2000 -> reward: 112.47395833333321, steps:4690, time-taken: 2.57min, time-elasped: 2141.68min
-> berries picked: 81 of 800 | patches-visited: [0, 4, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8445 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [813, 1350, 1391, 1005, 915, 754, 644, 544, 1029]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 20, 16, 12, 14, 7, 11, 9, 18]
	Time taken saving stuff: 0.06s

=== episode:103 Env-steps-taken:86592
 	picked: 146 |actions: {0: 569, 1: 486, 2: 1138, 3: 230, 4: 739, 5: 822, 6: 273, 7: 645, 8: 277}

==================================================
eval-episode: 1030 -> reward: 193.635416666667, steps: 5179.0, wall-time: 65.45s
-> berries picked: 146 of 800 | patches-visited: [1, 4, 7] | juice left:-0.00
==================================================


=== episode:1031 Env-steps-taken:68832
 	picked: 77 |actions: {0: 678, 1: 657, 2: 630, 3: 608, 4: 869, 5: 624, 6: 499, 7: 594, 8: 391}
episode: 1031/2000 -> reward: 104.58854166666657, steps:5550, time-taken: 2.51min, time-elasped: 2145.29min
-> berries picked: 77 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8437 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [816, 1341, 1383, 1010, 918, 756, 643, 541, 1029]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 18, 16, 11, 17, 13, 11, 6, 18]
	Time taken saving stuff: 0.01s

=== episode:1032 Env-steps-taken:80160
 	picked: 119 |actions: {0: 819, 1: 691, 2: 748, 3: 622, 4: 853, 5: 727, 6: 685, 7: 684, 8: 496}
episode: 1032/2000 -> reward: 161.1822916666667, steps:6325, time-taken: 3.00min, time-elasped: 2148.29min
-> berries picked: 119 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8438 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [809, 1340, 1378, 1008, 923, 758, 647, 546, 1029]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 22, 21, 16, 19, 14, 5, 6, 15]
	Time taken saving stuff: 0.03s

=== episode:1033 Env-steps-taken:70368
 	picked: 78 |actions: {0: 477, 1: 393, 2: 567, 3: 416, 4: 474, 5: 522, 6: 556, 7: 464, 8: 319}
episode: 1033/2000 -> reward: 113.03124999999987, steps:4188, time-taken: 2.06min, time-elasped: 2150.35min
-> berries picked: 78 of 800 | patches-visited: [0, 1, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8430 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [804, 1326, 1376, 1004, 921, 762, 656, 549, 1032]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 14, 16, 10, 11, 11, 9, 5, 25]
	Time taken saving stuff: 0.07s

=== episode:1034 Env-steps-taken:76320
 	picked: 102 |actions: {0: 626, 1: 652, 2: 814, 3: 580, 4: 949, 5: 702, 6: 670, 7: 730, 8: 428}
episode: 1034/2000 -> reward: 142.15624999999997, steps:6151, time-taken: 2.82min, time-elasped: 2153.17min
-> berries picked: 102 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8435 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [805, 1325, 1382, 1006, 924, 765, 653, 545, 1030]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 13, 18, 14, 11, 12, 9, 9, 16]
	Time taken saving stuff: 0.03s

=== episode:1035 Env-steps-taken:75264
 	picked: 102 |actions: {0: 582, 1: 646, 2: 608, 3: 598, 4: 780, 5: 639, 6: 572, 7: 632, 8: 357}
episode: 1035/2000 -> reward: 137.15624999999994, steps:5414, time-taken: 2.68min, time-elasped: 2155.86min
-> berries picked: 102 of 800 | patches-visited: [0, 4, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8448 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [805, 1325, 1383, 1005, 930, 775, 655, 541, 1029]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 18, 17, 12, 13, 8, 12, 7, 21]
	Time taken saving stuff: 0.04s

=== episode:1036 Env-steps-taken:73344
 	picked: 95 |actions: {0: 546, 1: 509, 2: 735, 3: 552, 4: 868, 5: 651, 6: 658, 7: 446, 8: 359}
episode: 1036/2000 -> reward: 127.05729166666646, steps:5324, time-taken: 2.80min, time-elasped: 2158.66min
-> berries picked: 95 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8456 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [804, 1323, 1380, 1007, 931, 776, 656, 547, 1032]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 16, 15, 13, 10, 11, 11, 11, 27]
	Time taken saving stuff: 0.01s

=== episode:1037 Env-steps-taken:76320
 	picked: 101 |actions: {0: 652, 1: 560, 2: 845, 3: 526, 4: 727, 5: 791, 6: 697, 7: 683, 8: 361}
episode: 1037/2000 -> reward: 142.21354166666663, steps:5842, time-taken: 3.42min, time-elasped: 2162.08min
-> berries picked: 101 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8475 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [808, 1325, 1383, 1006, 936, 776, 656, 551, 1034]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 21, 23, 20, 20, 11, 10, 9, 17]
	Time taken saving stuff: 0.03s

=== episode:1038 Env-steps-taken:72960
 	picked: 94 |actions: {0: 713, 1: 701, 2: 663, 3: 564, 4: 781, 5: 533, 6: 461, 7: 635, 8: 482}
episode: 1038/2000 -> reward: 124.22916666666649, steps:5533, time-taken: 4.03min, time-elasped: 2166.11min
-> berries picked: 94 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8487 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [815, 1327, 1380, 1009, 939, 781, 655, 546, 1035]
	| approx positives in sample 512: 139
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 22, 9, 17, 19, 14, 14, 16, 18]
	Time taken saving stuff: 0.04s

=== episode:1039 Env-steps-taken:68352
 	picked: 74 |actions: {0: 630, 1: 577, 2: 727, 3: 486, 4: 631, 5: 550, 6: 525, 7: 473, 8: 373}
episode: 1039/2000 -> reward: 101.76041666666657, steps:4972, time-taken: 2.99min, time-elasped: 2169.11min
-> berries picked: 74 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8497 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [818, 1328, 1379, 1009, 939, 783, 658, 550, 1033]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 16, 16, 16, 27, 10, 11, 6, 19]
	Time taken saving stuff: 0.02s

=== episode:1040 Env-steps-taken:64416
 	picked: 69 |actions: {0: 508, 1: 446, 2: 697, 3: 570, 4: 1014, 5: 562, 6: 536, 7: 425, 8: 337}
episode: 1040/2000 -> reward: 81.54687499999996, steps:5095, time-taken: 3.14min, time-elasped: 2172.26min
-> berries picked: 69 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8497 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [816, 1326, 1377, 1006, 946, 784, 656, 553, 1033]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 18, 16, 14, 11, 12, 9, 8, 20]
	Time taken saving stuff: 0.12s

=== episode:104 Env-steps-taken:77664
 	picked: 109 |actions: {0: 532, 1: 609, 2: 1011, 3: 147, 4: 532, 5: 273, 6: 532, 7: 228, 8: 470}

==================================================
eval-episode: 1040 -> reward: 148.3697916666667, steps: 4334.0, wall-time: 60.60s
-> berries picked: 109 of 800 | patches-visited: [1, 2, 4] | juice left:-0.00
==================================================


=== episode:1041 Env-steps-taken:65760
 	picked: 69 |actions: {0: 424, 1: 398, 2: 443, 3: 677, 4: 581, 5: 401, 6: 641, 7: 566, 8: 397}
episode: 1041/2000 -> reward: 89.04687499999997, steps:4528, time-taken: 2.87min, time-elasped: 2176.14min
-> berries picked: 69 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8510 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [815, 1324, 1375, 1009, 951, 783, 661, 557, 1035]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 16, 13, 12, 13, 11, 13, 10, 23]
	Time taken saving stuff: 0.01s

=== episode:1042 Env-steps-taken:64992
 	picked: 66 |actions: {0: 464, 1: 485, 2: 503, 3: 393, 4: 511, 5: 444, 6: 530, 7: 382, 8: 245}
episode: 1042/2000 -> reward: 85.21874999999994, steps:3957, time-taken: 2.70min, time-elasped: 2178.85min
-> berries picked: 66 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8510 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [818, 1321, 1375, 1010, 949, 779, 660, 561, 1037]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 27, 15, 13, 11, 14, 11, 8, 22]
	Time taken saving stuff: 0.12s

=== episode:1043 Env-steps-taken:61536
 	picked: 53 |actions: {0: 473, 1: 374, 2: 598, 3: 469, 4: 497, 5: 474, 6: 473, 7: 547, 8: 414}
episode: 1043/2000 -> reward: 65.52083333333339, steps:4319, time-taken: 2.73min, time-elasped: 2181.58min
-> berries picked: 53 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8514 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [824, 1319, 1379, 1009, 951, 779, 658, 561, 1034]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 22, 21, 15, 6, 13, 5, 6, 20]
	Time taken saving stuff: 0.01s

=== episode:1044 Env-steps-taken:69216
 	picked: 76 |actions: {0: 593, 1: 396, 2: 553, 3: 363, 4: 496, 5: 434, 6: 438, 7: 426, 8: 237}
episode: 1044/2000 -> reward: 106.64583333333326, steps:3936, time-taken: 2.84min, time-elasped: 2184.43min
-> berries picked: 76 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8526 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [826, 1322, 1381, 1013, 951, 781, 661, 558, 1033]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 16, 17, 19, 24, 4, 16, 7, 21]
	Time taken saving stuff: 0.10s

=== episode:1045 Env-steps-taken:77664
 	picked: 105 |actions: {0: 708, 1: 593, 2: 740, 3: 762, 4: 695, 5: 685, 6: 613, 7: 598, 8: 353}
episode: 1045/2000 -> reward: 148.98437499999997, steps:5747, time-taken: 4.13min, time-elasped: 2188.56min
-> berries picked: 105 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8537 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [829, 1326, 1377, 1020, 945, 787, 661, 558, 1034]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 24, 14, 14, 6, 11, 15, 9, 18]
	Time taken saving stuff: 0.07s

=== episode:1046 Env-steps-taken:52704
 	picked: 15 |actions: {0: 85, 1: 114, 2: 157, 3: 197, 4: 133, 5: 153, 6: 80, 7: 114, 8: 98}
episode: 1046/2000 -> reward: 23.640624999999996, steps:1131, time-taken: 1.07min, time-elasped: 2189.64min
-> berries picked: 15 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8535 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [824, 1324, 1380, 1020, 946, 791, 660, 557, 1033]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 10, 24, 18, 13, 12, 13, 10, 19]
	Time taken saving stuff: 0.03s

=== episode:1047 Env-steps-taken:69792
 	picked: 81 |actions: {0: 514, 1: 547, 2: 654, 3: 863, 4: 704, 5: 730, 6: 554, 7: 670, 8: 343}
episode: 1047/2000 -> reward: 109.35937499999987, steps:5579, time-taken: 3.59min, time-elasped: 2193.24min
-> berries picked: 81 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8529 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [817, 1323, 1382, 1016, 952, 793, 659, 556, 1031]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 16, 19, 14, 16, 17, 11, 6, 20]
	Time taken saving stuff: 0.05s

=== episode:1048 Env-steps-taken:78144
 	picked: 109 |actions: {0: 713, 1: 609, 2: 751, 3: 810, 4: 762, 5: 730, 6: 557, 7: 664, 8: 470}
episode: 1048/2000 -> reward: 148.4270833333333, steps:6066, time-taken: 3.54min, time-elasped: 2196.79min
-> berries picked: 109 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8538 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [819, 1329, 1384, 1018, 956, 784, 658, 559, 1031]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 20, 11, 12, 16, 7, 13, 10, 24]
	Time taken saving stuff: 0.09s

=== episode:1049 Env-steps-taken:69216
 	picked: 74 |actions: {0: 466, 1: 455, 2: 428, 3: 584, 4: 599, 5: 476, 6: 422, 7: 358, 8: 272}
episode: 1049/2000 -> reward: 106.76041666666656, steps:4060, time-taken: 2.81min, time-elasped: 2199.60min
-> berries picked: 74 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8542 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [816, 1335, 1385, 1021, 954, 783, 655, 560, 1033]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 15, 12, 16, 16, 9, 8, 8, 24]
	Time taken saving stuff: 0.02s

=== episode:1050 Env-steps-taken:68928
 	picked: 78 |actions: {0: 515, 1: 430, 2: 568, 3: 646, 4: 571, 5: 473, 6: 614, 7: 544, 8: 282}
episode: 1050/2000 -> reward: 104.14583333333324, steps:4643, time-taken: 2.92min, time-elasped: 2202.53min
-> berries picked: 78 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8553 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [818, 1330, 1385, 1028, 956, 780, 660, 560, 1036]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 24, 22, 20, 12, 9, 10, 10, 23]
	Time taken saving stuff: 0.13s

=== episode:105 Env-steps-taken:81120
 	picked: 129 |actions: {0: 234, 1: 977, 2: 129, 3: 757, 4: 440, 5: 291, 6: 815, 7: 234, 8: 286}

==================================================
eval-episode: 1050 -> reward: 165.60937500000017, steps: 4163.0, wall-time: 63.42s
-> berries picked: 129 of 800 | patches-visited: [1, 8] | juice left:-0.00
==================================================


=== episode:1051 Env-steps-taken:68736
 	picked: 78 |actions: {0: 487, 1: 470, 2: 513, 3: 586, 4: 627, 5: 595, 6: 398, 7: 625, 8: 328}
episode: 1051/2000 -> reward: 102.08854166666656, steps:4629, time-taken: 3.05min, time-elasped: 2206.64min
-> berries picked: 78 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8549 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [816, 1323, 1385, 1028, 956, 783, 655, 564, 1039]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 27, 13, 10, 14, 11, 9, 11, 21]
	Time taken saving stuff: 0.00s

=== episode:1052 Env-steps-taken:64224
 	picked: 59 |actions: {0: 499, 1: 426, 2: 483, 3: 783, 4: 518, 5: 456, 6: 316, 7: 464, 8: 291}
episode: 1052/2000 -> reward: 79.84895833333333, steps:4236, time-taken: 2.57min, time-elasped: 2209.22min
-> berries picked: 59 of 800 | patches-visited: [0, 6, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8556 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [823, 1323, 1384, 1029, 955, 785, 652, 566, 1039]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 16, 22, 20, 16, 5, 6, 4, 18]
	Time taken saving stuff: 0.01s

=== episode:1053 Env-steps-taken:79776
 	picked: 113 |actions: {0: 910, 1: 676, 2: 763, 3: 864, 4: 832, 5: 730, 6: 657, 7: 730, 8: 409}
episode: 1053/2000 -> reward: 159.52604166666674, steps:6571, time-taken: 4.05min, time-elasped: 2213.27min
-> berries picked: 113 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8586 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [823, 1333, 1391, 1031, 964, 784, 653, 568, 1039]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 14, 16, 18, 16, 9, 9, 9, 22]
	Time taken saving stuff: 0.01s

=== episode:1054 Env-steps-taken:67968
 	picked: 82 |actions: {0: 442, 1: 570, 2: 708, 3: 632, 4: 510, 5: 565, 6: 505, 7: 566, 8: 388}
episode: 1054/2000 -> reward: 98.41666666666654, steps:4886, time-taken: 3.17min, time-elasped: 2216.44min
-> berries picked: 82 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8600 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [825, 1337, 1389, 1031, 961, 788, 656, 571, 1042]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 23, 19, 23, 18, 7, 10, 10, 20]
	Time taken saving stuff: 0.02s

=== episode:1055 Env-steps-taken:66144
 	picked: 68 |actions: {0: 614, 1: 598, 2: 527, 3: 660, 4: 601, 5: 542, 6: 523, 7: 631, 8: 309}
episode: 1055/2000 -> reward: 91.10416666666664, steps:5005, time-taken: 3.31min, time-elasped: 2219.75min
-> berries picked: 68 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8594 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [829, 1335, 1388, 1031, 958, 785, 656, 571, 1041]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 17, 24, 13, 11, 9, 7, 12, 19]
	Time taken saving stuff: 0.01s

=== episode:1056 Env-steps-taken:70080
 	picked: 84 |actions: {0: 537, 1: 560, 2: 415, 3: 575, 4: 536, 5: 605, 6: 674, 7: 550, 8: 492}
episode: 1056/2000 -> reward: 110.68749999999987, steps:4944, time-taken: 3.24min, time-elasped: 2223.00min
-> berries picked: 84 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8568 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [829, 1339, 1383, 1027, 949, 784, 654, 565, 1038]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 27, 9, 14, 12, 13, 12, 12, 18]
	Time taken saving stuff: 0.00s

=== episode:1057 Env-steps-taken:74784
 	picked: 107 |actions: {0: 652, 1: 690, 2: 684, 3: 647, 4: 595, 5: 572, 6: 639, 7: 613, 8: 273}
episode: 1057/2000 -> reward: 133.86979166666657, steps:5365, time-taken: 3.43min, time-elasped: 2226.43min
-> berries picked: 107 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8586 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [834, 1345, 1385, 1027, 945, 789, 654, 566, 1041]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 20, 14, 17, 15, 18, 15, 8, 17]
	Time taken saving stuff: 0.01s

=== episode:1058 Env-steps-taken:77472
 	picked: 114 |actions: {0: 852, 1: 816, 2: 784, 3: 760, 4: 834, 5: 748, 6: 657, 7: 719, 8: 356}
episode: 1058/2000 -> reward: 147.46874999999994, steps:6526, time-taken: 4.02min, time-elasped: 2230.46min
-> berries picked: 114 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8602 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [835, 1348, 1385, 1033, 946, 799, 648, 565, 1043]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 18, 20, 14, 5, 21, 8, 8, 15]
	Time taken saving stuff: 0.09s

=== episode:1059 Env-steps-taken:69504
 	picked: 78 |actions: {0: 579, 1: 567, 2: 898, 3: 728, 4: 541, 5: 485, 6: 393, 7: 497, 8: 593}
episode: 1059/2000 -> reward: 104.76041666666656, steps:5281, time-taken: 3.45min, time-elasped: 2233.92min
-> berries picked: 78 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8595 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [834, 1351, 1388, 1026, 949, 798, 646, 559, 1044]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 21, 25, 9, 12, 14, 8, 8, 23]
	Time taken saving stuff: 0.01s

=== episode:1060 Env-steps-taken:69984
 	picked: 75 |actions: {0: 535, 1: 434, 2: 343, 3: 383, 4: 437, 5: 506, 6: 515, 7: 768, 8: 477}
episode: 1060/2000 -> reward: 110.81770833333323, steps:4398, time-taken: 3.02min, time-elasped: 2236.94min
-> berries picked: 75 of 800 | patches-visited: [0, 6, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8605 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [838, 1348, 1391, 1022, 944, 804, 652, 560, 1046]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 16, 17, 14, 12, 10, 14, 4, 11]
	Time taken saving stuff: 0.07s

=== episode:106 Env-steps-taken:61824
 	picked: 54 |actions: {0: 495, 1: 247, 2: 1646, 3: 39, 4: 1063, 5: 345, 6: 664, 7: 345, 8: 270}

==================================================
eval-episode: 1060 -> reward: 68.02083333333336, steps: 5114.0, wall-time: 64.11s
-> berries picked: 54 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:1061 Env-steps-taken:69408
 	picked: 74 |actions: {0: 535, 1: 524, 2: 439, 3: 435, 4: 495, 5: 441, 6: 408, 7: 404, 8: 307}
episode: 1061/2000 -> reward: 107.76041666666657, steps:3988, time-taken: 2.69min, time-elasped: 2240.70min
-> berries picked: 74 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8605 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [844, 1349, 1389, 1023, 943, 799, 648, 564, 1046]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 23, 12, 12, 15, 9, 14, 7, 23]
	Time taken saving stuff: 0.09s

=== episode:1062 Env-steps-taken:73728
 	picked: 94 |actions: {0: 647, 1: 577, 2: 695, 3: 714, 4: 525, 5: 663, 6: 568, 7: 602, 8: 382}
episode: 1062/2000 -> reward: 129.11458333333317, steps:5373, time-taken: 3.43min, time-elasped: 2244.14min
-> berries picked: 94 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8601 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [831, 1355, 1396, 1018, 941, 801, 653, 565, 1041]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 20, 20, 16, 13, 10, 11, 7, 23]
	Time taken saving stuff: 0.10s

=== episode:1063 Env-steps-taken:67488
 	picked: 71 |actions: {0: 614, 1: 435, 2: 396, 3: 551, 4: 509, 5: 616, 6: 543, 7: 523, 8: 388}
episode: 1063/2000 -> reward: 98.4322916666666, steps:4575, time-taken: 2.92min, time-elasped: 2247.06min
-> berries picked: 71 of 800 | patches-visited: [0, 1, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8615 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [830, 1358, 1391, 1021, 944, 807, 658, 562, 1044]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 25, 15, 14, 16, 6, 14, 8, 16]
	Time taken saving stuff: 0.09s

=== episode:1064 Env-steps-taken:67776
 	picked: 77 |actions: {0: 550, 1: 502, 2: 511, 3: 567, 4: 592, 5: 621, 6: 533, 7: 522, 8: 257}
episode: 1064/2000 -> reward: 99.08854166666659, steps:4655, time-taken: 3.02min, time-elasped: 2250.09min
-> berries picked: 77 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8641 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [831, 1362, 1391, 1033, 947, 815, 660, 560, 1042]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 20, 28, 10, 19, 10, 11, 7, 23]
	Time taken saving stuff: 0.10s

=== episode:1065 Env-steps-taken:70464
 	picked: 85 |actions: {0: 574, 1: 545, 2: 539, 3: 917, 4: 531, 5: 806, 6: 527, 7: 682, 8: 443}
episode: 1065/2000 -> reward: 112.63020833333319, steps:5564, time-taken: 3.68min, time-elasped: 2253.77min
-> berries picked: 85 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8640 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [834, 1371, 1390, 1038, 943, 809, 654, 560, 1041]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 18, 16, 20, 18, 4, 13, 10, 23]
	Time taken saving stuff: 0.10s

=== episode:1066 Env-steps-taken:73728
 	picked: 93 |actions: {0: 607, 1: 566, 2: 898, 3: 648, 4: 842, 5: 726, 6: 771, 7: 590, 8: 340}
episode: 1066/2000 -> reward: 126.34374999999983, steps:5988, time-taken: 3.76min, time-elasped: 2257.53min
-> berries picked: 93 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8667 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [831, 1369, 1392, 1039, 945, 823, 658, 564, 1046]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 25, 17, 18, 17, 18, 15, 9, 17]
	Time taken saving stuff: 0.03s

=== episode:1067 Env-steps-taken:62688
 	picked: 63 |actions: {0: 425, 1: 783, 2: 578, 3: 488, 4: 553, 5: 494, 6: 457, 7: 476, 8: 404}
episode: 1067/2000 -> reward: 72.89062500000001, steps:4658, time-taken: 3.14min, time-elasped: 2260.68min
-> berries picked: 63 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8670 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [830, 1376, 1394, 1035, 946, 825, 658, 562, 1044]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 12, 21, 15, 16, 13, 10, 16, 20]
	Time taken saving stuff: 0.03s

=== episode:1068 Env-steps-taken:70368
 	picked: 76 |actions: {0: 454, 1: 485, 2: 416, 3: 469, 4: 569, 5: 505, 6: 533, 7: 515, 8: 279}
episode: 1068/2000 -> reward: 112.64583333333321, steps:4225, time-taken: 2.79min, time-elasped: 2263.47min
-> berries picked: 76 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8694 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [839, 1378, 1399, 1036, 946, 825, 662, 565, 1044]
	| approx positives in sample 512: 145
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 18, 20, 21, 16, 9, 11, 6, 28]
	Time taken saving stuff: 0.08s

=== episode:1069 Env-steps-taken:62976
 	picked: 55 |actions: {0: 598, 1: 436, 2: 541, 3: 442, 4: 493, 5: 530, 6: 529, 7: 544, 8: 281}
episode: 1069/2000 -> reward: 72.52083333333336, steps:4394, time-taken: 2.98min, time-elasped: 2266.46min
-> berries picked: 55 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8699 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [839, 1382, 1395, 1037, 944, 823, 665, 567, 1047]
	| approx positives in sample 512: 139
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 20, 22, 12, 14, 14, 7, 11, 19]
	Time taken saving stuff: 0.09s

=== episode:1070 Env-steps-taken:71616
 	picked: 90 |actions: {0: 707, 1: 594, 2: 677, 3: 628, 4: 577, 5: 707, 6: 698, 7: 687, 8: 387}
episode: 1070/2000 -> reward: 118.34374999999986, steps:5662, time-taken: 3.68min, time-elasped: 2270.14min
-> berries picked: 90 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8725 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [844, 1386, 1407, 1032, 949, 826, 666, 569, 1046]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 21, 25, 15, 20, 10, 10, 10, 13]
	Time taken saving stuff: 0.16s

=== episode:107 Env-steps-taken:80640
 	picked: 129 |actions: {0: 1218, 1: 150, 2: 710, 3: 1342, 4: 239, 5: 825, 6: 843, 7: 134, 8: 82}

==================================================
eval-episode: 1070 -> reward: 163.1093750000002, steps: 5543.0, wall-time: 71.98s
-> berries picked: 129 of 800 | patches-visited: [1, 4] | juice left:-0.00
==================================================


=== episode:1071 Env-steps-taken:67584
 	picked: 72 |actions: {0: 569, 1: 459, 2: 461, 3: 628, 4: 581, 5: 655, 6: 402, 7: 684, 8: 290}
episode: 1071/2000 -> reward: 97.8749999999999, steps:4729, time-taken: 3.26min, time-elasped: 2274.60min
-> berries picked: 72 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8743 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [843, 1388, 1410, 1040, 947, 828, 668, 571, 1048]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 25, 18, 16, 9, 13, 11, 12, 18]
	Time taken saving stuff: 0.01s

=== episode:1072 Env-steps-taken:72768
 	picked: 88 |actions: {0: 677, 1: 811, 2: 650, 3: 587, 4: 581, 5: 558, 6: 572, 7: 677, 8: 512}
episode: 1072/2000 -> reward: 122.51562499999986, steps:5625, time-taken: 3.48min, time-elasped: 2278.09min
-> berries picked: 88 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8754 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [849, 1394, 1417, 1037, 944, 828, 668, 569, 1048]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 21, 9, 19, 18, 6, 9, 8, 25]
	Time taken saving stuff: 0.03s

=== episode:1073 Env-steps-taken:73440
 	picked: 97 |actions: {0: 783, 1: 773, 2: 744, 3: 750, 4: 652, 5: 818, 6: 712, 7: 731, 8: 342}
episode: 1073/2000 -> reward: 127.44270833333316, steps:6305, time-taken: 3.90min, time-elasped: 2281.99min
-> berries picked: 97 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8778 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [847, 1400, 1421, 1044, 949, 825, 670, 573, 1049]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 19, 17, 20, 17, 10, 12, 4, 27]
	Time taken saving stuff: 0.10s

=== episode:1074 Env-steps-taken:64224
 	picked: 65 |actions: {0: 610, 1: 820, 2: 624, 3: 851, 4: 717, 5: 708, 6: 661, 7: 520, 8: 328}
episode: 1074/2000 -> reward: 80.77604166666664, steps:5839, time-taken: 3.54min, time-elasped: 2285.53min
-> berries picked: 65 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8787 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [852, 1403, 1421, 1043, 951, 825, 671, 573, 1048]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 13, 20, 21, 14, 9, 11, 12, 18]
	Time taken saving stuff: 0.01s

=== episode:1075 Env-steps-taken:71040
 	picked: 87 |actions: {0: 649, 1: 629, 2: 858, 3: 708, 4: 677, 5: 647, 6: 757, 7: 578, 8: 368}
episode: 1075/2000 -> reward: 115.51562499999984, steps:5871, time-taken: 3.62min, time-elasped: 2289.16min
-> berries picked: 87 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8799 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [852, 1416, 1424, 1040, 949, 822, 668, 573, 1055]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 25, 15, 11, 20, 11, 10, 14, 20]
	Time taken saving stuff: 0.10s

=== episode:1076 Env-steps-taken:65472
 	picked: 72 |actions: {0: 521, 1: 606, 2: 424, 3: 437, 4: 544, 5: 557, 6: 531, 7: 620, 8: 290}
episode: 1076/2000 -> reward: 86.87499999999994, steps:4530, time-taken: 3.05min, time-elasped: 2292.21min
-> berries picked: 72 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8805 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [854, 1414, 1419, 1034, 952, 832, 673, 571, 1056]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 20, 14, 17, 12, 25, 9, 9, 25]
	Time taken saving stuff: 0.02s

=== episode:1077 Env-steps-taken:66432
 	picked: 65 |actions: {0: 439, 1: 457, 2: 486, 3: 446, 4: 463, 5: 536, 6: 449, 7: 402, 8: 280}
episode: 1077/2000 -> reward: 92.77604166666663, steps:3958, time-taken: 2.68min, time-elasped: 2294.90min
-> berries picked: 65 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8818 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [854, 1417, 1419, 1033, 953, 838, 675, 570, 1059]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 26, 16, 17, 19, 10, 9, 8, 15]
	Time taken saving stuff: 0.09s

=== episode:1078 Env-steps-taken:60864
 	picked: 52 |actions: {0: 631, 1: 382, 2: 400, 3: 412, 4: 530, 5: 417, 6: 426, 7: 417, 8: 367}
episode: 1078/2000 -> reward: 64.5208333333334, steps:3982, time-taken: 2.64min, time-elasped: 2297.54min
-> berries picked: 52 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8816 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [852, 1412, 1418, 1032, 955, 838, 676, 572, 1061]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 15, 19, 19, 9, 12, 5, 7, 19]
	Time taken saving stuff: 0.10s

=== episode:1079 Env-steps-taken:63552
 	picked: 64 |actions: {0: 568, 1: 438, 2: 651, 3: 481, 4: 663, 5: 800, 6: 679, 7: 628, 8: 437}
episode: 1079/2000 -> reward: 77.33333333333334, steps:5345, time-taken: 3.39min, time-elasped: 2300.93min
-> berries picked: 64 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8816 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [851, 1414, 1418, 1026, 956, 837, 679, 574, 1061]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 14, 17, 12, 20, 13, 10, 10, 19]
	Time taken saving stuff: 0.09s

=== episode:1080 Env-steps-taken:67104
 	picked: 78 |actions: {0: 732, 1: 654, 2: 496, 3: 567, 4: 564, 5: 577, 6: 591, 7: 587, 8: 327}
episode: 1080/2000 -> reward: 95.03124999999994, steps:5095, time-taken: 3.46min, time-elasped: 2304.40min
-> berries picked: 78 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8821 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [861, 1419, 1408, 1027, 956, 838, 678, 575, 1059]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 22, 16, 12, 21, 9, 10, 10, 20]
	Time taken saving stuff: 0.11s

=== episode:108 Env-steps-taken:70656
 	picked: 82 |actions: {0: 443, 1: 241, 2: 409, 3: 1353, 4: 182, 5: 222, 6: 74, 7: 1531, 8: 314}

==================================================
eval-episode: 1080 -> reward: 113.80208333333319, steps: 4769.0, wall-time: 61.84s
-> berries picked: 82 of 800 | patches-visited: [1, 7] | juice left:-0.00
==================================================


=== episode:1081 Env-steps-taken:65664
 	picked: 72 |actions: {0: 893, 1: 428, 2: 672, 3: 662, 4: 595, 5: 628, 6: 735, 7: 760, 8: 597}
episode: 1081/2000 -> reward: 87.87499999999996, steps:5970, time-taken: 3.69min, time-elasped: 2309.12min
-> berries picked: 72 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8800 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [862, 1414, 1402, 1030, 951, 835, 678, 574, 1054]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 22, 19, 15, 12, 14, 13, 3, 24]
	Time taken saving stuff: 0.01s

=== episode:1082 Env-steps-taken:73536
 	picked: 89 |actions: {0: 655, 1: 630, 2: 645, 3: 653, 4: 548, 5: 782, 6: 712, 7: 637, 8: 339}
episode: 1082/2000 -> reward: 128.40104166666652, steps:5601, time-taken: 3.44min, time-elasped: 2312.56min
-> berries picked: 89 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8811 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [865, 1408, 1397, 1031, 961, 835, 682, 576, 1056]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [23, 16, 18, 10, 23, 10, 9, 6, 25]
	Time taken saving stuff: 0.08s

=== episode:1083 Env-steps-taken:81120
 	picked: 116 |actions: {0: 611, 1: 792, 2: 818, 3: 689, 4: 691, 5: 811, 6: 767, 7: 819, 8: 372}
episode: 1083/2000 -> reward: 166.35416666666674, steps:6370, time-taken: 3.72min, time-elasped: 2316.29min
-> berries picked: 116 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8835 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [869, 1414, 1398, 1034, 963, 839, 684, 576, 1058]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 22, 14, 10, 16, 14, 10, 9, 18]
	Time taken saving stuff: 0.00s

=== episode:1084 Env-steps-taken:74592
 	picked: 93 |actions: {0: 624, 1: 595, 2: 564, 3: 514, 4: 601, 5: 788, 6: 809, 7: 709, 8: 396}
episode: 1084/2000 -> reward: 133.67187499999986, steps:5600, time-taken: 3.59min, time-elasped: 2319.88min
-> berries picked: 93 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8837 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [866, 1415, 1389, 1033, 965, 845, 684, 580, 1060]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 15, 18, 22, 16, 13, 7, 11, 15]
	Time taken saving stuff: 0.03s

=== episode:1085 Env-steps-taken:74784
 	picked: 96 |actions: {0: 874, 1: 696, 2: 771, 3: 601, 4: 682, 5: 797, 6: 689, 7: 738, 8: 419}
episode: 1085/2000 -> reward: 134.11458333333323, steps:6267, time-taken: 3.86min, time-elasped: 2323.75min
-> berries picked: 96 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8830 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [867, 1419, 1383, 1024, 959, 840, 688, 591, 1059]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 21, 14, 19, 22, 16, 10, 7, 21]
	Time taken saving stuff: 0.02s

=== episode:1086 Env-steps-taken:69216
 	picked: 75 |actions: {0: 380, 1: 506, 2: 550, 3: 547, 4: 520, 5: 582, 6: 580, 7: 535, 8: 321}
episode: 1086/2000 -> reward: 105.8177083333332, steps:4521, time-taken: 3.12min, time-elasped: 2326.88min
-> berries picked: 75 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8852 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [873, 1421, 1386, 1024, 963, 846, 684, 591, 1064]
	| approx positives in sample 512: 145
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 24, 19, 16, 17, 13, 7, 7, 21]
	Time taken saving stuff: 0.11s

=== episode:1087 Env-steps-taken:66528
 	picked: 73 |actions: {0: 615, 1: 685, 2: 722, 3: 678, 4: 629, 5: 795, 6: 704, 7: 773, 8: 416}
episode: 1087/2000 -> reward: 92.31770833333326, steps:6017, time-taken: 3.79min, time-elasped: 2330.67min
-> berries picked: 73 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8836 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [874, 1421, 1381, 1019, 963, 846, 680, 587, 1065]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 26, 23, 14, 14, 10, 9, 13, 16]
	Time taken saving stuff: 0.05s

=== episode:1088 Env-steps-taken:65760
 	picked: 69 |actions: {0: 565, 1: 525, 2: 547, 3: 728, 4: 628, 5: 755, 6: 632, 7: 653, 8: 352}
episode: 1088/2000 -> reward: 87.66145833333329, steps:5385, time-taken: 3.48min, time-elasped: 2334.16min
-> berries picked: 69 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8845 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [872, 1421, 1386, 1021, 961, 853, 682, 587, 1062]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 18, 16, 18, 13, 7, 11, 9, 22]
	Time taken saving stuff: 0.02s

=== episode:1089 Env-steps-taken:75648
 	picked: 101 |actions: {0: 621, 1: 740, 2: 674, 3: 657, 4: 730, 5: 560, 6: 830, 7: 725, 8: 396}
episode: 1089/2000 -> reward: 139.21354166666657, steps:5933, time-taken: 3.77min, time-elasped: 2337.93min
-> berries picked: 101 of 800 | patches-visited: [0, 4, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8884 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [870, 1431, 1395, 1029, 965, 856, 687, 589, 1062]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 17, 17, 15, 18, 16, 9, 8, 18]
	Time taken saving stuff: 0.03s

=== episode:1090 Env-steps-taken:67584
 	picked: 73 |actions: {0: 545, 1: 445, 2: 422, 3: 419, 4: 453, 5: 447, 6: 485, 7: 417, 8: 328}
episode: 1090/2000 -> reward: 98.31770833333326, steps:3961, time-taken: 2.67min, time-elasped: 2340.61min
-> berries picked: 73 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8908 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [881, 1430, 1397, 1033, 966, 858, 686, 594, 1063]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 12, 18, 14, 15, 14, 13, 9, 20]
	Time taken saving stuff: 0.07s

=== episode:109 Env-steps-taken:54144
 	picked: 24 |actions: {0: 1972, 1: 203, 2: 82, 3: 80, 4: 1304, 5: 742, 6: 90, 7: 57, 8: 393}

==================================================
eval-episode: 1090 -> reward: 30.62499999999999, steps: 4923.0, wall-time: 49.51s
-> berries picked: 24 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:1091 Env-steps-taken:72768
 	picked: 93 |actions: {0: 669, 1: 519, 2: 569, 3: 478, 4: 646, 5: 718, 6: 626, 7: 721, 8: 361}
episode: 1091/2000 -> reward: 124.17187499999987, steps:5307, time-taken: 3.50min, time-elasped: 2344.95min
-> berries picked: 93 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8904 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [881, 1428, 1392, 1030, 974, 855, 686, 595, 1063]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 16, 17, 7, 19, 14, 6, 8, 28]
	Time taken saving stuff: 0.03s

=== episode:1092 Env-steps-taken:75072
 	picked: 102 |actions: {0: 733, 1: 558, 2: 759, 3: 666, 4: 679, 5: 718, 6: 731, 7: 743, 8: 415}
episode: 1092/2000 -> reward: 135.6562499999999, steps:6002, time-taken: 3.77min, time-elasped: 2348.72min
-> berries picked: 102 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8917 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [885, 1424, 1396, 1029, 980, 855, 692, 593, 1063]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 18, 13, 13, 18, 14, 11, 5, 26]
	Time taken saving stuff: 0.07s

=== episode:1093 Env-steps-taken:72480
 	picked: 90 |actions: {0: 686, 1: 489, 2: 516, 3: 598, 4: 466, 5: 557, 6: 765, 7: 540, 8: 347}
episode: 1093/2000 -> reward: 121.01562499999983, steps:4964, time-taken: 3.26min, time-elasped: 2351.98min
-> berries picked: 90 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8915 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [883, 1424, 1394, 1025, 979, 851, 690, 599, 1070]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 22, 18, 16, 12, 13, 9, 4, 29]
	Time taken saving stuff: 0.08s

=== episode:1094 Env-steps-taken:70272
 	picked: 81 |actions: {0: 529, 1: 470, 2: 534, 3: 590, 4: 512, 5: 596, 6: 664, 7: 659, 8: 360}
episode: 1094/2000 -> reward: 111.85937499999989, steps:4914, time-taken: 3.20min, time-elasped: 2355.18min
-> berries picked: 81 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8919 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [878, 1424, 1396, 1023, 983, 854, 696, 596, 1069]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 16, 23, 14, 11, 14, 16, 6, 18]
	Time taken saving stuff: 0.11s

=== episode:1095 Env-steps-taken:57312
 	picked: 32 |actions: {0: 321, 1: 234, 2: 342, 3: 205, 4: 161, 5: 133, 6: 251, 7: 224, 8: 294}
episode: 1095/2000 -> reward: 47.16666666666668, steps:2165, time-taken: 1.73min, time-elasped: 2356.91min
-> berries picked: 32 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8922 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [882, 1425, 1397, 1024, 980, 852, 696, 597, 1069]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 26, 13, 18, 13, 14, 9, 5, 17]
	Time taken saving stuff: 0.08s

=== episode:1096 Env-steps-taken:60768
 	picked: 49 |actions: {0: 297, 1: 259, 2: 392, 3: 260, 4: 434, 5: 449, 6: 359, 7: 393, 8: 170}
episode: 1096/2000 -> reward: 63.69270833333339, steps:3013, time-taken: 2.09min, time-elasped: 2359.01min
-> berries picked: 49 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8926 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [881, 1424, 1399, 1022, 979, 854, 698, 602, 1067]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 20, 20, 13, 11, 7, 13, 6, 21]
	Time taken saving stuff: 0.03s

=== episode:1097 Env-steps-taken:60384
 	picked: 49 |actions: {0: 293, 1: 315, 2: 317, 3: 200, 4: 264, 5: 310, 6: 329, 7: 430, 8: 256}
episode: 1097/2000 -> reward: 62.192708333333385, steps:2714, time-taken: 1.98min, time-elasped: 2361.00min
-> berries picked: 49 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8940 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [884, 1425, 1400, 1022, 981, 855, 701, 603, 1069]
	| approx positives in sample 512: 153
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 21, 26, 14, 18, 13, 18, 10, 21]
	Time taken saving stuff: 0.08s

=== episode:1098 Env-steps-taken:66528
 	picked: 72 |actions: {0: 467, 1: 518, 2: 580, 3: 463, 4: 662, 5: 455, 6: 451, 7: 503, 8: 252}
episode: 1098/2000 -> reward: 91.9322916666666, steps:4351, time-taken: 3.01min, time-elasped: 2364.01min
-> berries picked: 72 of 800 | patches-visited: [0, 5, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8945 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [884, 1429, 1405, 1027, 980, 850, 693, 603, 1074]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 14, 11, 18, 13, 11, 5, 7, 23]
	Time taken saving stuff: 0.00s

=== episode:1099 Env-steps-taken:63072
 	picked: 63 |actions: {0: 440, 1: 429, 2: 452, 3: 422, 4: 502, 5: 404, 6: 498, 7: 513, 8: 265}
episode: 1099/2000 -> reward: 74.890625, steps:3925, time-taken: 2.56min, time-elasped: 2366.57min
-> berries picked: 63 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8952 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [887, 1434, 1405, 1028, 979, 848, 693, 602, 1076]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 13, 18, 13, 9, 17, 17, 18, 27]
	Time taken saving stuff: 0.01s

=== episode:1100 Env-steps-taken:73248
 	picked: 95 |actions: {0: 547, 1: 655, 2: 713, 3: 734, 4: 693, 5: 606, 6: 726, 7: 646, 8: 355}
episode: 1100/2000 -> reward: 126.17187499999983, steps:5675, time-taken: 45.43min, time-elasped: 2412.01min
-> berries picked: 95 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8960 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [886, 1435, 1405, 1031, 981, 844, 691, 609, 1078]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 20, 20, 19, 15, 12, 6, 5, 21]
	Time taken saving stuff: 0.05s

=== episode:110 Env-steps-taken:83040
 	picked: 134 |actions: {0: 807, 1: 358, 2: 1476, 3: 1192, 4: 240, 5: 1308, 6: 481, 7: 497, 8: 188}

==================================================
eval-episode: 1100 -> reward: 175.82291666666683, steps: 6547.0, wall-time: 44.95s
-> berries picked: 134 of 800 | patches-visited: [1, 6, 8] | juice left:-0.00
==================================================


=== episode:1101 Env-steps-taken:74016
 	picked: 97 |actions: {0: 611, 1: 771, 2: 653, 3: 675, 4: 698, 5: 675, 6: 586, 7: 761, 8: 462}
episode: 1101/2000 -> reward: 130.4427083333332, steps:5892, time-taken: 2.66min, time-elasped: 2415.42min
-> berries picked: 97 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8952 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [878, 1439, 1411, 1023, 980, 843, 686, 614, 1078]
	| approx positives in sample 512: 139
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 21, 25, 12, 13, 15, 13, 11, 20]
	Time taken saving stuff: 0.11s

=== episode:1102 Env-steps-taken:60192
 	picked: 45 |actions: {0: 408, 1: 387, 2: 480, 3: 402, 4: 471, 5: 472, 6: 434, 7: 465, 8: 360}
episode: 1102/2000 -> reward: 60.92187500000006, steps:3879, time-taken: 2.41min, time-elasped: 2417.83min
-> berries picked: 45 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8935 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [874, 1444, 1414, 1013, 974, 844, 682, 612, 1078]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 17, 16, 13, 11, 9, 11, 8, 17]
	Time taken saving stuff: 0.01s

=== episode:1103 Env-steps-taken:67296
 	picked: 72 |actions: {0: 670, 1: 529, 2: 674, 3: 490, 4: 836, 5: 583, 6: 763, 7: 739, 8: 446}
episode: 1103/2000 -> reward: 96.37499999999993, steps:5730, time-taken: 3.38min, time-elasped: 2421.22min
-> berries picked: 72 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8928 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [871, 1441, 1417, 1013, 975, 839, 682, 613, 1077]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 19, 14, 21, 20, 17, 6, 8, 10]
	Time taken saving stuff: 0.01s

=== episode:1104 Env-steps-taken:68736
 	picked: 79 |actions: {0: 461, 1: 692, 2: 670, 3: 528, 4: 673, 5: 734, 6: 648, 7: 650, 8: 448}
episode: 1104/2000 -> reward: 103.97395833333323, steps:5504, time-taken: 3.44min, time-elasped: 2424.67min
-> berries picked: 79 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8946 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [871, 1449, 1419, 1018, 979, 838, 679, 614, 1079]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 28, 22, 16, 14, 14, 7, 6, 14]
	Time taken saving stuff: 0.09s

=== episode:1105 Env-steps-taken:61056
 	picked: 52 |actions: {0: 318, 1: 346, 2: 370, 3: 311, 4: 416, 5: 443, 6: 436, 7: 308, 8: 257}
episode: 1105/2000 -> reward: 65.02083333333339, steps:3205, time-taken: 2.59min, time-elasped: 2427.26min
-> berries picked: 52 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8946 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [869, 1449, 1417, 1018, 982, 840, 677, 615, 1079]
	| approx positives in sample 512: 146
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 23, 19, 17, 17, 12, 8, 8, 20]
	Time taken saving stuff: 0.00s

=== episode:1106 Env-steps-taken:66816
 	picked: 74 |actions: {0: 615, 1: 500, 2: 486, 3: 502, 4: 659, 5: 648, 6: 655, 7: 537, 8: 423}
episode: 1106/2000 -> reward: 93.76041666666659, steps:5025, time-taken: 3.41min, time-elasped: 2430.67min
-> berries picked: 74 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8908 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [865, 1451, 1405, 1012, 980, 841, 667, 614, 1073]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 20, 12, 19, 12, 9, 15, 6, 25]
	Time taken saving stuff: 0.10s

=== episode:1107 Env-steps-taken:64512
 	picked: 57 |actions: {0: 305, 1: 398, 2: 386, 3: 265, 4: 432, 5: 405, 6: 431, 7: 387, 8: 205}
episode: 1107/2000 -> reward: 82.73437499999999, steps:3214, time-taken: 2.41min, time-elasped: 2433.08min
-> berries picked: 57 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8896 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [867, 1444, 1401, 1012, 980, 843, 670, 610, 1069]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 18, 16, 9, 18, 15, 8, 11, 23]
	Time taken saving stuff: 0.10s

=== episode:1108 Env-steps-taken:72000
 	picked: 86 |actions: {0: 648, 1: 784, 2: 606, 3: 625, 4: 715, 5: 695, 6: 646, 7: 710, 8: 418}
episode: 1108/2000 -> reward: 120.57291666666652, steps:5847, time-taken: 3.43min, time-elasped: 2436.52min
-> berries picked: 86 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8902 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [875, 1443, 1403, 1011, 982, 839, 667, 610, 1072]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 20, 12, 12, 16, 11, 10, 10, 20]
	Time taken saving stuff: 0.01s

=== episode:1109 Env-steps-taken:58752
 	picked: 35 |actions: {0: 404, 1: 339, 2: 416, 3: 459, 4: 449, 5: 282, 6: 422, 7: 560, 8: 243}
episode: 1109/2000 -> reward: 53.99479166666669, steps:3574, time-taken: 2.48min, time-elasped: 2439.01min
-> berries picked: 35 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8881 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [875, 1440, 1400, 1013, 975, 840, 659, 608, 1071]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 20, 21, 11, 9, 12, 6, 12, 14]
	Time taken saving stuff: 0.03s

=== episode:1110 Env-steps-taken:69984
 	picked: 76 |actions: {0: 432, 1: 441, 2: 503, 3: 576, 4: 631, 5: 595, 6: 642, 7: 565, 8: 500}
episode: 1110/2000 -> reward: 110.64583333333321, steps:4885, time-taken: 3.10min, time-elasped: 2442.11min
-> berries picked: 76 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8869 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [870, 1437, 1397, 1008, 982, 843, 659, 605, 1068]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 18, 19, 16, 17, 13, 8, 11, 18]
	Time taken saving stuff: 0.07s

=== episode:111 Env-steps-taken:94848
 	picked: 184 |actions: {0: 832, 1: 390, 2: 1234, 3: 702, 4: 635, 5: 683, 6: 559, 7: 1061, 8: 453}

==================================================
eval-episode: 1110 -> reward: 233.63020833333402, steps: 6549.0, wall-time: 75.15s
-> berries picked: 184 of 800 | patches-visited: [1, 4, 7] | juice left:-0.00
==================================================


=== episode:1111 Env-steps-taken:54432
 	picked: 24 |actions: {0: 139, 1: 213, 2: 229, 3: 471, 4: 228, 5: 202, 6: 207, 7: 193, 8: 285}
episode: 1111/2000 -> reward: 32.12499999999999, steps:2167, time-taken: 1.74min, time-elasped: 2445.11min
-> berries picked: 24 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8841 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [871, 1422, 1383, 1006, 985, 845, 658, 605, 1066]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 16, 26, 29, 12, 16, 12, 11, 15]
	Time taken saving stuff: 0.01s

=== episode:1112 Env-steps-taken:63264
 	picked: 59 |actions: {0: 470, 1: 403, 2: 334, 3: 465, 4: 591, 5: 658, 6: 511, 7: 547, 8: 259}
episode: 1112/2000 -> reward: 76.61979166666666, steps:4238, time-taken: 2.62min, time-elasped: 2447.73min
-> berries picked: 59 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8829 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [876, 1420, 1372, 1009, 983, 844, 654, 608, 1063]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 18, 19, 12, 17, 9, 10, 10, 25]
	Time taken saving stuff: 0.01s

=== episode:1113 Env-steps-taken:57216
 	picked: 30 |actions: {0: 124, 1: 289, 2: 178, 3: 152, 4: 179, 5: 261, 6: 226, 7: 328, 8: 240}
episode: 1113/2000 -> reward: 46.781250000000036, steps:1977, time-taken: 1.65min, time-elasped: 2449.39min
-> berries picked: 30 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8821 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [879, 1413, 1365, 1006, 982, 845, 657, 610, 1064]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 12, 12, 18, 17, 11, 17, 10, 20]
	Time taken saving stuff: 0.03s

=== episode:1114 Env-steps-taken:63360
 	picked: 59 |actions: {0: 433, 1: 420, 2: 475, 3: 380, 4: 295, 5: 332, 6: 472, 7: 520, 8: 258}
episode: 1114/2000 -> reward: 77.11979166666666, steps:3585, time-taken: 2.29min, time-elasped: 2451.69min
-> berries picked: 59 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8819 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [885, 1411, 1365, 1004, 976, 844, 656, 611, 1067]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 17, 17, 13, 10, 12, 9, 4, 20]
	Time taken saving stuff: 0.03s

=== episode:1115 Env-steps-taken:72480
 	picked: 96 |actions: {0: 560, 1: 563, 2: 516, 3: 615, 4: 567, 5: 782, 6: 912, 7: 700, 8: 373}
episode: 1115/2000 -> reward: 122.49999999999984, steps:5588, time-taken: 3.41min, time-elasped: 2455.10min
-> berries picked: 96 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8808 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [881, 1408, 1358, 995, 974, 851, 663, 616, 1062]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 13, 17, 11, 19, 19, 3, 13, 14]
	Time taken saving stuff: 0.09s

=== episode:1116 Env-steps-taken:69120
 	picked: 81 |actions: {0: 549, 1: 600, 2: 482, 3: 799, 4: 794, 5: 614, 6: 689, 7: 741, 8: 370}
episode: 1116/2000 -> reward: 105.8593749999999, steps:5638, time-taken: 3.60min, time-elasped: 2458.70min
-> berries picked: 81 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8792 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [875, 1406, 1346, 988, 978, 854, 670, 614, 1061]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 17, 16, 13, 16, 11, 13, 11, 26]
	Time taken saving stuff: 0.01s

=== episode:1117 Env-steps-taken:75936
 	picked: 104 |actions: {0: 668, 1: 752, 2: 610, 3: 699, 4: 533, 5: 605, 6: 772, 7: 749, 8: 407}
episode: 1117/2000 -> reward: 140.0989583333333, steps:5795, time-taken: 3.51min, time-elasped: 2462.21min
-> berries picked: 104 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8812 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [878, 1410, 1337, 988, 984, 853, 676, 624, 1062]
	| approx positives in sample 512: 146
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 19, 23, 16, 18, 8, 11, 14, 22]
	Time taken saving stuff: 0.03s

=== episode:1118 Env-steps-taken:66336
 	picked: 71 |actions: {0: 420, 1: 516, 2: 468, 3: 479, 4: 475, 5: 422, 6: 472, 7: 399, 8: 219}
episode: 1118/2000 -> reward: 91.93229166666661, steps:3870, time-taken: 2.60min, time-elasped: 2464.81min
-> berries picked: 71 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8829 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [884, 1415, 1337, 989, 988, 853, 679, 622, 1062]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 17, 9, 16, 15, 15, 4, 9, 26]
	Time taken saving stuff: 0.04s

=== episode:1119 Env-steps-taken:64320
 	picked: 59 |actions: {0: 302, 1: 528, 2: 525, 3: 401, 4: 511, 5: 465, 6: 415, 7: 395, 8: 292}
episode: 1119/2000 -> reward: 82.11979166666669, steps:3834, time-taken: 2.53min, time-elasped: 2467.35min
-> berries picked: 59 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8831 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [880, 1413, 1339, 985, 989, 861, 678, 620, 1066]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 19, 22, 18, 14, 19, 8, 10, 17]
	Time taken saving stuff: 0.04s

=== episode:1120 Env-steps-taken:68736
 	picked: 83 |actions: {0: 564, 1: 558, 2: 610, 3: 623, 4: 582, 5: 500, 6: 639, 7: 608, 8: 291}
episode: 1120/2000 -> reward: 103.74479166666656, steps:4975, time-taken: 3.20min, time-elasped: 2470.56min
-> berries picked: 83 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8841 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [885, 1414, 1339, 984, 988, 866, 677, 622, 1066]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 15, 19, 12, 17, 11, 6, 5, 18]
	Time taken saving stuff: 0.18s

=== episode:112 Env-steps-taken:99648
 	picked: 195 |actions: {0: 1186, 1: 759, 2: 289, 3: 1794, 4: 330, 5: 600, 6: 1119, 7: 214, 8: 204}

==================================================
eval-episode: 1120 -> reward: 257.942708333334, steps: 6495.0, wall-time: 83.53s
-> berries picked: 195 of 800 | patches-visited: [0, 1, 6] | juice left:-0.00
==================================================


=== episode:1121 Env-steps-taken:66528
 	picked: 79 |actions: {0: 627, 1: 691, 2: 676, 3: 563, 4: 781, 5: 627, 6: 906, 7: 769, 8: 391}
episode: 1121/2000 -> reward: 91.97395833333324, steps:6031, time-taken: 3.55min, time-elasped: 2475.51min
-> berries picked: 79 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8826 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [879, 1411, 1338, 982, 990, 865, 677, 621, 1063]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 23, 13, 16, 8, 17, 9, 10, 28]
	Time taken saving stuff: 0.00s

=== episode:1122 Env-steps-taken:68832
 	picked: 85 |actions: {0: 524, 1: 538, 2: 592, 3: 499, 4: 686, 5: 555, 6: 733, 7: 634, 8: 326}
episode: 1122/2000 -> reward: 104.13020833333324, steps:5087, time-taken: 3.23min, time-elasped: 2478.75min
-> berries picked: 85 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8850 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [879, 1411, 1341, 985, 989, 866, 681, 630, 1068]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 23, 27, 19, 15, 11, 14, 7, 14]
	Time taken saving stuff: 0.09s

=== episode:1123 Env-steps-taken:73440
 	picked: 91 |actions: {0: 464, 1: 714, 2: 679, 3: 626, 4: 675, 5: 461, 6: 607, 7: 524, 8: 354}
episode: 1123/2000 -> reward: 127.78645833333316, steps:5104, time-taken: 3.13min, time-elasped: 2481.88min
-> berries picked: 91 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8872 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [882, 1415, 1350, 988, 992, 864, 679, 634, 1068]
	| approx positives in sample 512: 167
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 28, 17, 17, 18, 14, 14, 14, 25]
	Time taken saving stuff: 0.01s

=== episode:1124 Env-steps-taken:53856
 	picked: 20 |actions: {0: 108, 1: 175, 2: 128, 3: 94, 4: 104, 5: 121, 6: 175, 7: 138, 8: 120}
episode: 1124/2000 -> reward: 29.354166666666664, steps:1163, time-taken: 1.25min, time-elasped: 2483.14min
-> berries picked: 20 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8879 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [884, 1415, 1354, 987, 993, 864, 680, 634, 1068]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 19, 16, 15, 15, 15, 8, 9, 20]
	Time taken saving stuff: 0.01s

=== episode:1125 Env-steps-taken:65760
 	picked: 75 |actions: {0: 504, 1: 561, 2: 679, 3: 565, 4: 1002, 5: 551, 6: 740, 7: 853, 8: 372}
episode: 1125/2000 -> reward: 88.20312499999993, steps:5827, time-taken: 3.60min, time-elasped: 2486.74min
-> berries picked: 75 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8879 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [881, 1418, 1358, 983, 992, 863, 684, 633, 1067]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 17, 22, 16, 11, 14, 18, 12, 17]
	Time taken saving stuff: 0.12s

=== episode:1126 Env-steps-taken:52512
 	picked: 15 |actions: {0: 138, 1: 104, 2: 100, 3: 34, 4: 54, 5: 40, 6: 70, 7: 76, 8: 65}
episode: 1126/2000 -> reward: 22.640624999999996, steps:681, time-taken: 0.93min, time-elasped: 2487.68min
-> berries picked: 15 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8874 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [883, 1417, 1355, 982, 991, 864, 684, 632, 1066]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 29, 16, 11, 8, 12, 16, 7, 19]
	Time taken saving stuff: 0.00s

=== episode:1127 Env-steps-taken:63264
 	picked: 67 |actions: {0: 907, 1: 566, 2: 644, 3: 525, 4: 748, 5: 594, 6: 793, 7: 596, 8: 379}
episode: 1127/2000 -> reward: 75.66145833333337, steps:5752, time-taken: 3.48min, time-elasped: 2491.16min
-> berries picked: 67 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8860 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [882, 1409, 1353, 981, 991, 868, 679, 631, 1066]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 16, 21, 8, 15, 14, 6, 5, 23]
	Time taken saving stuff: 0.08s

=== episode:1128 Env-steps-taken:70464
 	picked: 84 |actions: {0: 544, 1: 683, 2: 638, 3: 469, 4: 746, 5: 484, 6: 659, 7: 548, 8: 336}
episode: 1128/2000 -> reward: 112.68749999999987, steps:5107, time-taken: 3.19min, time-elasped: 2494.36min
-> berries picked: 84 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8877 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [890, 1409, 1356, 981, 997, 867, 679, 632, 1066]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 27, 15, 13, 23, 15, 9, 8, 20]
	Time taken saving stuff: 0.01s

=== episode:1129 Env-steps-taken:67104
 	picked: 75 |actions: {0: 457, 1: 726, 2: 885, 3: 550, 4: 761, 5: 647, 6: 527, 7: 653, 8: 440}
episode: 1129/2000 -> reward: 95.20312499999991, steps:5646, time-taken: 3.34min, time-elasped: 2497.70min
-> berries picked: 75 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8870 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [882, 1407, 1363, 981, 992, 865, 681, 636, 1063]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 26, 15, 17, 14, 8, 17, 11, 20]
	Time taken saving stuff: 0.00s

=== episode:1130 Env-steps-taken:69888
 	picked: 83 |actions: {0: 654, 1: 578, 2: 713, 3: 518, 4: 855, 5: 629, 6: 747, 7: 625, 8: 454}
episode: 1130/2000 -> reward: 109.74479166666654, steps:5773, time-taken: 3.49min, time-elasped: 2501.20min
-> berries picked: 83 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8874 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [876, 1408, 1361, 976, 997, 868, 686, 637, 1065]
	| approx positives in sample 512: 139
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 23, 12, 13, 21, 16, 9, 7, 19]
	Time taken saving stuff: 0.11s

=== episode:113 Env-steps-taken:78432
 	picked: 117 |actions: {0: 233, 1: 971, 2: 139, 3: 1380, 4: 348, 5: 900, 6: 125, 7: 864, 8: 22}

==================================================
eval-episode: 1130 -> reward: 152.796875, steps: 4982.0, wall-time: 62.11s
-> berries picked: 117 of 800 | patches-visited: [1, 4, 7] | juice left:-0.00
==================================================


=== episode:1131 Env-steps-taken:52896
 	picked: 15 |actions: {0: 52, 1: 103, 2: 55, 3: 71, 4: 44, 5: 35, 6: 98, 7: 102, 8: 91}
episode: 1131/2000 -> reward: 24.640625000000004, steps:651, time-taken: 0.89min, time-elasped: 2503.13min
-> berries picked: 15 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8877 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [877, 1409, 1361, 977, 995, 867, 689, 637, 1065]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 18, 20, 14, 16, 12, 9, 13, 31]
	Time taken saving stuff: 0.09s

=== episode:1132 Env-steps-taken:78528
 	picked: 117 |actions: {0: 794, 1: 684, 2: 818, 3: 708, 4: 850, 5: 620, 6: 788, 7: 790, 8: 496}
episode: 1132/2000 -> reward: 152.79687500000003, steps:6548, time-taken: 4.31min, time-elasped: 2507.45min
-> berries picked: 117 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8884 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [878, 1415, 1366, 971, 995, 858, 696, 638, 1067]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 14, 19, 11, 13, 13, 12, 7, 21]
	Time taken saving stuff: 0.01s

=== episode:1133 Env-steps-taken:74016
 	picked: 105 |actions: {0: 649, 1: 661, 2: 852, 3: 609, 4: 667, 5: 729, 6: 782, 7: 769, 8: 332}
episode: 1133/2000 -> reward: 128.59895833333312, steps:6050, time-taken: 3.75min, time-elasped: 2511.20min
-> berries picked: 105 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8902 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [880, 1424, 1365, 978, 997, 861, 695, 636, 1066]
	| approx positives in sample 512: 153
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 22, 22, 21, 16, 10, 11, 19, 21]
	Time taken saving stuff: 0.01s

=== episode:1134 Env-steps-taken:85056
 	picked: 129 |actions: {0: 524, 1: 828, 2: 821, 3: 673, 4: 817, 5: 687, 6: 773, 7: 633, 8: 392}
episode: 1134/2000 -> reward: 186.60937500000023, steps:6148, time-taken: 3.88min, time-elasped: 2515.09min
-> berries picked: 129 of 800 | patches-visited: [0, 6, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8935 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [886, 1426, 1367, 986, 1004, 867, 697, 633, 1069]
	| approx positives in sample 512: 153
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 17, 25, 15, 14, 21, 14, 9, 27]
	Time taken saving stuff: 0.09s

=== episode:1135 Env-steps-taken:76800
 	picked: 106 |actions: {0: 638, 1: 786, 2: 802, 3: 630, 4: 775, 5: 515, 6: 800, 7: 831, 8: 480}
episode: 1135/2000 -> reward: 144.42708333333326, steps:6257, time-taken: 3.78min, time-elasped: 2518.87min
-> berries picked: 106 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8956 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [894, 1423, 1366, 993, 1006, 866, 693, 644, 1071]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 19, 19, 11, 14, 16, 9, 13, 27]
	Time taken saving stuff: 0.01s

=== episode:1136 Env-steps-taken:58176
 	picked: 34 |actions: {0: 154, 1: 264, 2: 234, 3: 150, 4: 314, 5: 221, 6: 206, 7: 154, 8: 112}
episode: 1136/2000 -> reward: 51.052083333333364, steps:1809, time-taken: 1.54min, time-elasped: 2520.42min
-> berries picked: 34 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8959 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [894, 1429, 1365, 991, 1007, 869, 690, 643, 1071]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 19, 15, 13, 13, 14, 6, 7, 33]
	Time taken saving stuff: 0.01s

=== episode:1137 Env-steps-taken:73344
 	picked: 92 |actions: {0: 635, 1: 588, 2: 789, 3: 350, 4: 580, 5: 542, 6: 609, 7: 690, 8: 356}
episode: 1137/2000 -> reward: 127.2291666666665, steps:5139, time-taken: 3.16min, time-elasped: 2523.58min
-> berries picked: 92 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8966 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [894, 1425, 1359, 991, 1007, 869, 692, 653, 1076]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 17, 21, 22, 14, 7, 10, 9, 28]
	Time taken saving stuff: 0.01s

=== episode:1138 Env-steps-taken:67200
 	picked: 66 |actions: {0: 462, 1: 504, 2: 564, 3: 431, 4: 575, 5: 387, 6: 603, 7: 426, 8: 269}
episode: 1138/2000 -> reward: 96.71874999999993, steps:4221, time-taken: 2.79min, time-elasped: 2526.38min
-> berries picked: 66 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8973 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [896, 1423, 1364, 991, 1008, 869, 691, 650, 1081]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 19, 14, 14, 24, 13, 10, 9, 22]
	Time taken saving stuff: 0.09s

=== episode:1139 Env-steps-taken:66336
 	picked: 68 |actions: {0: 545, 1: 493, 2: 624, 3: 441, 4: 675, 5: 556, 6: 564, 7: 612, 8: 330}
episode: 1139/2000 -> reward: 91.60416666666661, steps:4840, time-taken: 2.88min, time-elasped: 2529.26min
-> berries picked: 68 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8964 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [894, 1422, 1361, 990, 1007, 877, 690, 643, 1080]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 22, 14, 11, 18, 12, 17, 9, 27]
	Time taken saving stuff: 0.01s

=== episode:1140 Env-steps-taken:67680
 	picked: 69 |actions: {0: 327, 1: 455, 2: 342, 3: 404, 4: 600, 5: 431, 6: 570, 7: 643, 8: 330}
episode: 1140/2000 -> reward: 99.54687499999993, steps:4102, time-taken: 2.77min, time-elasped: 2532.03min
-> berries picked: 69 of 800 | patches-visited: [0, 2, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8971 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [890, 1420, 1365, 992, 1014, 877, 687, 647, 1079]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 26, 22, 10, 8, 14, 4, 11, 26]
	Time taken saving stuff: 0.11s

=== episode:114 Env-steps-taken:80352
 	picked: 124 |actions: {0: 555, 1: 526, 2: 278, 3: 859, 4: 455, 5: 230, 6: 913, 7: 414, 8: 254}

==================================================
eval-episode: 1140 -> reward: 162.01041666666674, steps: 4484.0, wall-time: 68.36s
-> berries picked: 124 of 800 | patches-visited: [0, 1, 3] | juice left:-0.00
==================================================


=== episode:1141 Env-steps-taken:72672
 	picked: 96 |actions: {0: 620, 1: 580, 2: 562, 3: 829, 4: 1108, 5: 597, 6: 849, 7: 694, 8: 413}
episode: 1141/2000 -> reward: 123.49999999999983, steps:6252, time-taken: 3.63min, time-elasped: 2536.81min
-> berries picked: 96 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8978 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [886, 1416, 1360, 997, 1021, 878, 691, 650, 1079]
	| approx positives in sample 512: 139
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 24, 15, 14, 21, 13, 15, 5, 17]
	Time taken saving stuff: 0.10s

=== episode:1142 Env-steps-taken:68256
 	picked: 76 |actions: {0: 402, 1: 484, 2: 388, 3: 374, 4: 416, 5: 437, 6: 653, 7: 564, 8: 235}
episode: 1142/2000 -> reward: 100.76041666666659, steps:3953, time-taken: 2.60min, time-elasped: 2539.41min
-> berries picked: 76 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8989 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [890, 1422, 1360, 994, 1017, 880, 691, 655, 1080]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 20, 12, 19, 15, 14, 12, 11, 19]
	Time taken saving stuff: 0.03s

=== episode:1143 Env-steps-taken:77184
 	picked: 107 |actions: {0: 612, 1: 663, 2: 560, 3: 631, 4: 786, 5: 706, 6: 843, 7: 751, 8: 545}
episode: 1143/2000 -> reward: 146.3697916666666, steps:6097, time-taken: 3.57min, time-elasped: 2542.98min
-> berries picked: 107 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8991 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [893, 1420, 1360, 992, 1020, 875, 696, 656, 1079]
	| approx positives in sample 512: 151
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 29, 18, 14, 13, 14, 8, 10, 24]
	Time taken saving stuff: 0.11s

=== episode:1144 Env-steps-taken:69504
 	picked: 80 |actions: {0: 626, 1: 621, 2: 652, 3: 657, 4: 707, 5: 457, 6: 601, 7: 486, 8: 395}
episode: 1144/2000 -> reward: 107.91666666666652, steps:5202, time-taken: 3.21min, time-elasped: 2546.19min
-> berries picked: 80 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8995 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [898, 1424, 1363, 992, 1018, 870, 692, 658, 1080]
	| approx positives in sample 512: 149
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 17, 23, 18, 15, 21, 9, 10, 26]
	Time taken saving stuff: 0.12s

=== episode:1145 Env-steps-taken:66048
 	picked: 71 |actions: {0: 606, 1: 654, 2: 707, 3: 597, 4: 529, 5: 441, 6: 664, 7: 525, 8: 433}
episode: 1145/2000 -> reward: 89.93229166666657, steps:5156, time-taken: 3.35min, time-elasped: 2549.55min
-> berries picked: 71 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8995 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [900, 1422, 1363, 994, 1013, 871, 695, 658, 1079]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 18, 12, 20, 17, 12, 13, 6, 16]
	Time taken saving stuff: 0.12s

=== episode:1146 Env-steps-taken:69984
 	picked: 86 |actions: {0: 450, 1: 530, 2: 698, 3: 489, 4: 669, 5: 601, 6: 592, 7: 648, 8: 295}
episode: 1146/2000 -> reward: 110.07291666666653, steps:4972, time-taken: 3.06min, time-elasped: 2552.61min
-> berries picked: 86 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8989 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [898, 1426, 1368, 995, 1010, 867, 695, 651, 1079]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 14, 9, 17, 13, 8, 8, 10, 29]
	Time taken saving stuff: 0.01s

=== episode:1147 Env-steps-taken:64416
 	picked: 69 |actions: {0: 457, 1: 542, 2: 541, 3: 423, 4: 597, 5: 329, 6: 575, 7: 536, 8: 329}
episode: 1147/2000 -> reward: 82.04687499999997, steps:4329, time-taken: 2.86min, time-elasped: 2555.48min
-> berries picked: 69 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8979 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [899, 1433, 1363, 990, 1009, 860, 691, 654, 1080]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 18, 24, 10, 19, 11, 9, 6, 15]
	Time taken saving stuff: 0.09s

=== episode:1148 Env-steps-taken:70176
 	picked: 75 |actions: {0: 479, 1: 529, 2: 634, 3: 511, 4: 727, 5: 539, 6: 650, 7: 453, 8: 337}
episode: 1148/2000 -> reward: 110.31770833333323, steps:4859, time-taken: 3.32min, time-elasped: 2558.81min
-> berries picked: 75 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8980 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [897, 1430, 1360, 992, 1013, 859, 694, 652, 1083]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 15, 13, 17, 13, 11, 13, 6, 26]
	Time taken saving stuff: 0.11s

=== episode:1149 Env-steps-taken:64512
 	picked: 63 |actions: {0: 370, 1: 401, 2: 598, 3: 345, 4: 691, 5: 390, 6: 469, 7: 529, 8: 344}
episode: 1149/2000 -> reward: 80.06249999999997, steps:4137, time-taken: 2.73min, time-elasped: 2561.54min
-> berries picked: 63 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8994 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [900, 1431, 1363, 992, 1017, 860, 692, 659, 1080]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 21, 29, 17, 15, 8, 7, 10, 23]
	Time taken saving stuff: 0.11s

=== episode:1150 Env-steps-taken:68928
 	picked: 80 |actions: {0: 551, 1: 510, 2: 645, 3: 463, 4: 569, 5: 630, 6: 764, 7: 617, 8: 395}
episode: 1150/2000 -> reward: 104.91666666666657, steps:5144, time-taken: 3.27min, time-elasped: 2564.82min
-> berries picked: 80 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9007 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [900, 1432, 1362, 993, 1018, 864, 696, 661, 1081]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 14, 15, 19, 16, 10, 10, 18, 17]
	Time taken saving stuff: 0.15s

=== episode:115 Env-steps-taken:73632
 	picked: 101 |actions: {0: 617, 1: 354, 2: 671, 3: 72, 4: 871, 5: 180, 6: 1063, 7: 77, 8: 259}

==================================================
eval-episode: 1150 -> reward: 128.2135416666665, steps: 4164.0, wall-time: 67.31s
-> berries picked: 101 of 800 | patches-visited: [0, 1] | juice left:-0.00
==================================================


=== episode:1151 Env-steps-taken:70848
 	picked: 85 |actions: {0: 573, 1: 406, 2: 562, 3: 484, 4: 758, 5: 542, 6: 653, 7: 529, 8: 402}
episode: 1151/2000 -> reward: 114.18749999999989, steps:4909, time-taken: 3.33min, time-elasped: 2569.28min
-> berries picked: 85 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9009 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [899, 1429, 1364, 988, 1017, 869, 699, 662, 1082]
	| approx positives in sample 512: 160
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 28, 19, 12, 16, 20, 16, 13, 21]
	Time taken saving stuff: 0.01s

=== episode:1152 Env-steps-taken:69888
 	picked: 78 |actions: {0: 445, 1: 560, 2: 460, 3: 380, 4: 552, 5: 474, 6: 700, 7: 523, 8: 344}
episode: 1152/2000 -> reward: 110.53124999999989, steps:4438, time-taken: 2.89min, time-elasped: 2572.17min
-> berries picked: 78 of 800 | patches-visited: [0, 5, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9017 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [901, 1429, 1365, 992, 1017, 867, 701, 661, 1084]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 17, 19, 12, 14, 6, 12, 10, 19]
	Time taken saving stuff: 0.10s

=== episode:1153 Env-steps-taken:63936
 	picked: 58 |actions: {0: 361, 1: 442, 2: 484, 3: 398, 4: 441, 5: 436, 6: 515, 7: 342, 8: 323}
episode: 1153/2000 -> reward: 79.67708333333334, steps:3742, time-taken: 2.67min, time-elasped: 2574.85min
-> berries picked: 58 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9018 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [903, 1429, 1362, 993, 1018, 867, 701, 663, 1082]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [23, 23, 7, 13, 16, 17, 12, 7, 22]
	Time taken saving stuff: 0.03s

=== episode:1154 Env-steps-taken:68928
 	picked: 78 |actions: {0: 397, 1: 667, 2: 488, 3: 514, 4: 672, 5: 550, 6: 922, 7: 617, 8: 327}
episode: 1154/2000 -> reward: 105.03124999999993, steps:5154, time-taken: 3.28min, time-elasped: 2578.13min
-> berries picked: 78 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9026 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [907, 1425, 1364, 992, 1017, 862, 705, 671, 1083]
	| approx positives in sample 512: 159
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 23, 30, 11, 18, 12, 9, 12, 25]
	Time taken saving stuff: 0.01s

=== episode:1155 Env-steps-taken:77280
 	picked: 117 |actions: {0: 731, 1: 758, 2: 874, 3: 675, 4: 821, 5: 650, 6: 772, 7: 897, 8: 455}
episode: 1155/2000 -> reward: 146.29687499999997, steps:6633, time-taken: 4.21min, time-elasped: 2582.35min
-> berries picked: 117 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9047 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [909, 1432, 1377, 999, 1013, 865, 703, 666, 1083]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 21, 30, 17, 17, 11, 5, 13, 22]
	Time taken saving stuff: 0.09s

=== episode:1156 Env-steps-taken:68832
 	picked: 78 |actions: {0: 490, 1: 519, 2: 648, 3: 519, 4: 588, 5: 453, 6: 664, 7: 544, 8: 316}
episode: 1156/2000 -> reward: 104.5312499999999, steps:4741, time-taken: 3.01min, time-elasped: 2585.37min
-> berries picked: 78 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9048 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [905, 1427, 1381, 1002, 1012, 864, 701, 672, 1084]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 18, 14, 17, 12, 20, 7, 12, 26]
	Time taken saving stuff: 0.02s

=== episode:1157 Env-steps-taken:67200
 	picked: 70 |actions: {0: 561, 1: 519, 2: 565, 3: 466, 4: 450, 5: 385, 6: 525, 7: 484, 8: 361}
episode: 1157/2000 -> reward: 95.98958333333326, steps:4316, time-taken: 2.64min, time-elasped: 2588.01min
-> berries picked: 70 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9050 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [901, 1434, 1382, 1006, 1006, 859, 702, 675, 1085]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 20, 15, 20, 21, 10, 10, 7, 24]
	Time taken saving stuff: 0.01s

=== episode:1158 Env-steps-taken:74592
 	picked: 92 |actions: {0: 514, 1: 540, 2: 578, 3: 528, 4: 790, 5: 480, 6: 634, 7: 490, 8: 314}
episode: 1158/2000 -> reward: 134.22916666666657, steps:4868, time-taken: 3.45min, time-elasped: 2591.47min
-> berries picked: 92 of 800 | patches-visited: [0, 1, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9054 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [899, 1431, 1389, 1010, 1004, 862, 699, 670, 1090]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 19, 19, 12, 10, 16, 11, 11, 25]
	Time taken saving stuff: 0.02s

=== episode:1159 Env-steps-taken:73248
 	picked: 99 |actions: {0: 740, 1: 710, 2: 804, 3: 670, 4: 739, 5: 570, 6: 754, 7: 793, 8: 433}
episode: 1159/2000 -> reward: 126.32812499999982, steps:6213, time-taken: 3.90min, time-elasped: 2595.38min
-> berries picked: 99 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9056 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [903, 1433, 1382, 1007, 1004, 863, 700, 673, 1091]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 16, 19, 14, 15, 21, 8, 9, 16]
	Time taken saving stuff: 0.00s

=== episode:1160 Env-steps-taken:75456
 	picked: 103 |actions: {0: 574, 1: 668, 2: 747, 3: 699, 4: 767, 5: 600, 6: 690, 7: 685, 8: 324}
episode: 1160/2000 -> reward: 138.0989583333333, steps:5754, time-taken: 3.79min, time-elasped: 2599.18min
-> berries picked: 103 of 800 | patches-visited: [0, 2, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9071 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [910, 1430, 1389, 1013, 1005, 860, 706, 666, 1092]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 24, 17, 24, 11, 14, 8, 10, 18]
	Time taken saving stuff: 0.09s

=== episode:116 Env-steps-taken:95232
 	picked: 172 |actions: {0: 571, 1: 1335, 2: 206, 3: 511, 4: 1848, 5: 224, 6: 1005, 7: 381, 8: 159}

==================================================
eval-episode: 1160 -> reward: 236.2604166666672, steps: 6240.0, wall-time: 76.56s
-> berries picked: 172 of 800 | patches-visited: [1, 4, 6, 8] | juice left:-0.00
==================================================


=== episode:1161 Env-steps-taken:71616
 	picked: 94 |actions: {0: 898, 1: 491, 2: 926, 3: 617, 4: 636, 5: 535, 6: 785, 7: 714, 8: 490}
episode: 1161/2000 -> reward: 118.1145833333332, steps:6092, time-taken: 3.91min, time-elasped: 2604.36min
-> berries picked: 94 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8997 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [906, 1383, 1378, 1016, 1004, 863, 697, 663, 1087]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 21, 15, 17, 10, 16, 10, 10, 21]
	Time taken saving stuff: 0.00s

=== episode:1162 Env-steps-taken:61632
 	picked: 56 |actions: {0: 385, 1: 461, 2: 426, 3: 324, 4: 356, 5: 322, 6: 672, 7: 390, 8: 344}
episode: 1162/2000 -> reward: 67.79166666666669, steps:3680, time-taken: 2.51min, time-elasped: 2606.87min
-> berries picked: 56 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8974 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [906, 1373, 1367, 1012, 1003, 859, 702, 661, 1091]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 21, 23, 16, 15, 18, 10, 10, 23]
	Time taken saving stuff: 0.19s

=== episode:1163 Env-steps-taken:68832
 	picked: 82 |actions: {0: 496, 1: 450, 2: 597, 3: 468, 4: 433, 5: 422, 6: 776, 7: 482, 8: 391}
episode: 1163/2000 -> reward: 103.41666666666656, steps:4515, time-taken: 3.04min, time-elasped: 2609.92min
-> berries picked: 82 of 800 | patches-visited: [0, 5, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8982 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [901, 1375, 1365, 1014, 1000, 864, 710, 660, 1093]
	| approx positives in sample 512: 150
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 17, 20, 23, 11, 16, 7, 14, 28]
	Time taken saving stuff: 0.11s

=== episode:1164 Env-steps-taken:65664
 	picked: 73 |actions: {0: 540, 1: 673, 2: 888, 3: 588, 4: 549, 5: 536, 6: 858, 7: 836, 8: 469}
episode: 1164/2000 -> reward: 87.8177083333333, steps:5937, time-taken: 3.62min, time-elasped: 2613.54min
-> berries picked: 73 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8951 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [900, 1370, 1354, 1017, 996, 864, 700, 660, 1090]
	| approx positives in sample 512: 150
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 20, 25, 14, 14, 13, 13, 15, 17]
	Time taken saving stuff: 0.01s

=== episode:1165 Env-steps-taken:65280
 	picked: 66 |actions: {0: 554, 1: 438, 2: 490, 3: 479, 4: 486, 5: 428, 6: 694, 7: 553, 8: 445}
episode: 1165/2000 -> reward: 86.21874999999997, steps:4567, time-taken: 3.06min, time-elasped: 2616.60min
-> berries picked: 66 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8960 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [906, 1365, 1354, 1019, 997, 863, 703, 664, 1089]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 19, 14, 17, 12, 14, 13, 12, 18]
	Time taken saving stuff: 0.02s

=== episode:1166 Env-steps-taken:75168
 	picked: 94 |actions: {0: 471, 1: 614, 2: 636, 3: 635, 4: 753, 5: 584, 6: 672, 7: 595, 8: 391}
episode: 1166/2000 -> reward: 136.61458333333326, steps:5351, time-taken: 3.59min, time-elasped: 2620.20min
-> berries picked: 94 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8967 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [910, 1370, 1349, 1023, 1000, 862, 703, 660, 1090]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 21, 22, 12, 15, 10, 12, 14, 23]
	Time taken saving stuff: 0.02s

=== episode:1167 Env-steps-taken:65184
 	picked: 61 |actions: {0: 432, 1: 355, 2: 391, 3: 464, 4: 422, 5: 294, 6: 558, 7: 380, 8: 270}
episode: 1167/2000 -> reward: 86.50520833333327, steps:3566, time-taken: 2.39min, time-elasped: 2622.59min
-> berries picked: 61 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8969 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [913, 1366, 1350, 1026, 1001, 864, 699, 658, 1092]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 26, 17, 17, 13, 14, 12, 8, 22]
	Time taken saving stuff: 0.09s

=== episode:1168 Env-steps-taken:69312
 	picked: 82 |actions: {0: 482, 1: 543, 2: 744, 3: 653, 4: 547, 5: 458, 6: 744, 7: 500, 8: 368}
episode: 1168/2000 -> reward: 107.30208333333323, steps:5039, time-taken: 3.42min, time-elasped: 2626.02min
-> berries picked: 82 of 800 | patches-visited: [0, 4, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8965 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [909, 1360, 1350, 1024, 1008, 864, 698, 658, 1094]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 20, 17, 15, 12, 19, 10, 7, 19]
	Time taken saving stuff: 0.03s

=== episode:1169 Env-steps-taken:68736
 	picked: 75 |actions: {0: 451, 1: 538, 2: 588, 3: 735, 4: 517, 5: 431, 6: 619, 7: 521, 8: 320}
episode: 1169/2000 -> reward: 104.20312499999993, steps:4720, time-taken: 3.19min, time-elasped: 2629.22min
-> berries picked: 75 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8963 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [908, 1364, 1354, 1029, 1006, 865, 695, 649, 1093]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 20, 19, 13, 15, 16, 8, 16, 28]
	Time taken saving stuff: 0.00s

=== episode:1170 Env-steps-taken:67008
 	picked: 67 |actions: {0: 446, 1: 475, 2: 668, 3: 418, 4: 494, 5: 386, 6: 440, 7: 519, 8: 359}
episode: 1170/2000 -> reward: 96.16145833333329, steps:4205, time-taken: 2.80min, time-elasped: 2632.01min
-> berries picked: 67 of 800 | patches-visited: [0, 1, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8966 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [908, 1362, 1359, 1032, 1004, 866, 694, 648, 1093]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 23, 19, 12, 15, 12, 10, 11, 20]
	Time taken saving stuff: 0.10s

=== episode:117 Env-steps-taken:78432
 	picked: 118 |actions: {0: 258, 1: 350, 2: 779, 3: 1502, 4: 594, 5: 316, 6: 88, 7: 1948, 8: 225}

==================================================
eval-episode: 1170 -> reward: 151.35416666666669, steps: 6060.0, wall-time: 75.96s
-> berries picked: 118 of 800 | patches-visited: [1, 3] | juice left:-0.00
==================================================


=== episode:1171 Env-steps-taken:66912
 	picked: 75 |actions: {0: 612, 1: 635, 2: 707, 3: 676, 4: 607, 5: 458, 6: 509, 7: 611, 8: 441}
episode: 1171/2000 -> reward: 94.20312499999993, steps:5256, time-taken: 3.30min, time-elasped: 2636.59min
-> berries picked: 75 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8956 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [906, 1362, 1365, 1026, 1004, 860, 695, 645, 1093]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 21, 19, 15, 12, 11, 9, 10, 20]
	Time taken saving stuff: 0.09s

=== episode:1172 Env-steps-taken:64320
 	picked: 66 |actions: {0: 376, 1: 468, 2: 617, 3: 449, 4: 457, 5: 399, 6: 668, 7: 474, 8: 401}
episode: 1172/2000 -> reward: 81.21875000000001, steps:4309, time-taken: 2.87min, time-elasped: 2639.46min
-> berries picked: 66 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8966 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [908, 1362, 1370, 1030, 1004, 858, 698, 646, 1090]
	| approx positives in sample 512: 143
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 18, 20, 14, 14, 13, 9, 15, 23]
	Time taken saving stuff: 0.00s

=== episode:1173 Env-steps-taken:59328
 	picked: 40 |actions: {0: 258, 1: 325, 2: 354, 3: 278, 4: 471, 5: 293, 6: 610, 7: 327, 8: 273}
episode: 1173/2000 -> reward: 57.20833333333337, steps:3189, time-taken: 2.32min, time-elasped: 2641.79min
-> berries picked: 40 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8963 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [909, 1362, 1363, 1032, 1003, 855, 699, 649, 1091]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 19, 11, 15, 14, 12, 17, 13, 21]
	Time taken saving stuff: 0.01s

=== episode:1174 Env-steps-taken:69984
 	picked: 74 |actions: {0: 412, 1: 372, 2: 706, 3: 390, 4: 567, 5: 426, 6: 506, 7: 378, 8: 254}
episode: 1174/2000 -> reward: 109.31770833333323, steps:4011, time-taken: 2.95min, time-elasped: 2644.74min
-> berries picked: 74 of 800 | patches-visited: [0, 7, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8993 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [913, 1367, 1368, 1035, 1007, 857, 702, 651, 1093]
	| approx positives in sample 512: 146
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 19, 21, 14, 18, 12, 10, 5, 32]
	Time taken saving stuff: 0.10s

=== episode:1175 Env-steps-taken:76512
 	picked: 110 |actions: {0: 657, 1: 620, 2: 720, 3: 644, 4: 825, 5: 669, 6: 1055, 7: 720, 8: 548}
episode: 1175/2000 -> reward: 142.69791666666657, steps:6458, time-taken: 4.10min, time-elasped: 2648.85min
-> berries picked: 110 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9005 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [913, 1364, 1364, 1036, 1006, 863, 703, 661, 1095]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 24, 24, 16, 6, 15, 7, 10, 25]
	Time taken saving stuff: 0.10s

=== episode:1176 Env-steps-taken:66816
 	picked: 73 |actions: {0: 391, 1: 401, 2: 648, 3: 367, 4: 493, 5: 509, 6: 729, 7: 690, 8: 401}
episode: 1176/2000 -> reward: 94.31770833333324, steps:4629, time-taken: 3.42min, time-elasped: 2652.27min
-> berries picked: 73 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9003 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [912, 1363, 1360, 1036, 1007, 869, 701, 658, 1097]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 24, 9, 19, 11, 11, 13, 7, 25]
	Time taken saving stuff: 0.10s

=== episode:1177 Env-steps-taken:72000
 	picked: 94 |actions: {0: 683, 1: 525, 2: 983, 3: 492, 4: 923, 5: 645, 6: 773, 7: 854, 8: 371}
episode: 1177/2000 -> reward: 120.11458333333317, steps:6249, time-taken: 3.85min, time-elasped: 2656.12min
-> berries picked: 94 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9008 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [912, 1367, 1361, 1036, 1004, 870, 695, 664, 1099]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 15, 15, 16, 18, 11, 6, 9, 28]
	Time taken saving stuff: 0.09s

=== episode:1178 Env-steps-taken:65472
 	picked: 59 |actions: {0: 385, 1: 387, 2: 404, 3: 300, 4: 430, 5: 363, 6: 425, 7: 395, 8: 239}
episode: 1178/2000 -> reward: 88.11979166666663, steps:3328, time-taken: 2.46min, time-elasped: 2658.58min
-> berries picked: 59 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9030 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [911, 1371, 1365, 1039, 1005, 871, 700, 669, 1099]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 15, 14, 18, 20, 13, 6, 7, 22]
	Time taken saving stuff: 0.01s

=== episode:1179 Env-steps-taken:66336
 	picked: 66 |actions: {0: 494, 1: 704, 2: 567, 3: 445, 4: 647, 5: 433, 6: 486, 7: 645, 8: 333}
episode: 1179/2000 -> reward: 92.21874999999993, steps:4754, time-taken: 3.08min, time-elasped: 2661.66min
-> berries picked: 66 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9037 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [914, 1376, 1365, 1037, 1011, 872, 700, 664, 1098]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 24, 20, 16, 16, 18, 9, 4, 16]
	Time taken saving stuff: 0.10s

=== episode:1180 Env-steps-taken:71040
 	picked: 89 |actions: {0: 558, 1: 541, 2: 639, 3: 441, 4: 588, 5: 463, 6: 791, 7: 599, 8: 352}
episode: 1180/2000 -> reward: 114.51562499999989, steps:4972, time-taken: 3.13min, time-elasped: 2664.80min
-> berries picked: 89 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9039 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [910, 1376, 1360, 1037, 1010, 874, 705, 667, 1100]
	| approx positives in sample 512: 147
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 19, 18, 17, 21, 16, 12, 9, 24]
	Time taken saving stuff: 0.06s

=== episode:118 Env-steps-taken:79392
 	picked: 120 |actions: {0: 272, 1: 700, 2: 846, 3: 224, 4: 957, 5: 196, 6: 537, 7: 439, 8: 152}

==================================================
eval-episode: 1180 -> reward: 157.12500000000003, steps: 4323.0, wall-time: 73.07s
-> berries picked: 120 of 800 | patches-visited: [1, 5] | juice left:-0.00
==================================================


=== episode:1181 Env-steps-taken:76608
 	picked: 105 |actions: {0: 664, 1: 719, 2: 659, 3: 629, 4: 932, 5: 520, 6: 1086, 7: 828, 8: 443}
episode: 1181/2000 -> reward: 143.48437499999997, steps:6480, time-taken: 3.86min, time-elasped: 2669.89min
-> berries picked: 105 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9027 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [906, 1370, 1358, 1039, 1013, 865, 708, 673, 1095]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 15, 15, 22, 17, 17, 11, 11, 22]
	Time taken saving stuff: 0.02s

=== episode:1182 Env-steps-taken:70560
 	picked: 85 |actions: {0: 646, 1: 733, 2: 668, 3: 586, 4: 871, 5: 521, 6: 917, 7: 738, 8: 418}
episode: 1182/2000 -> reward: 113.1302083333332, steps:6098, time-taken: 3.89min, time-elasped: 2673.78min
-> berries picked: 85 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9034 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [914, 1370, 1358, 1038, 1001, 865, 718, 674, 1096]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 16, 13, 11, 18, 17, 13, 15, 20]
	Time taken saving stuff: 0.06s

=== episode:1183 Env-steps-taken:58080
 	picked: 36 |actions: {0: 265, 1: 245, 2: 243, 3: 227, 4: 405, 5: 289, 6: 378, 7: 291, 8: 235}
episode: 1183/2000 -> reward: 49.05208333333336, steps:2578, time-taken: 1.92min, time-elasped: 2675.71min
-> berries picked: 36 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9039 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [913, 1370, 1357, 1037, 1007, 864, 720, 673, 1098]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 19, 26, 19, 19, 7, 11, 5, 21]
	Time taken saving stuff: 0.08s

=== episode:1184 Env-steps-taken:70752
 	picked: 79 |actions: {0: 416, 1: 659, 2: 771, 3: 620, 4: 849, 5: 606, 6: 702, 7: 592, 8: 405}
episode: 1184/2000 -> reward: 114.97395833333321, steps:5620, time-taken: 3.50min, time-elasped: 2679.22min
-> berries picked: 79 of 800 | patches-visited: [0, 4, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9040 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [912, 1369, 1355, 1033, 1006, 873, 718, 674, 1100]
	| approx positives in sample 512: 147
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 25, 20, 15, 15, 15, 16, 5, 20]
	Time taken saving stuff: 0.03s

=== episode:1185 Env-steps-taken:70944
 	picked: 84 |actions: {0: 541, 1: 553, 2: 594, 3: 541, 4: 635, 5: 515, 6: 715, 7: 690, 8: 442}
episode: 1185/2000 -> reward: 115.18749999999989, steps:5226, time-taken: 3.50min, time-elasped: 2682.72min
-> berries picked: 84 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9051 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [923, 1368, 1355, 1030, 1007, 873, 718, 673, 1104]
	| approx positives in sample 512: 156
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 23, 20, 18, 17, 20, 11, 11, 21]
	Time taken saving stuff: 0.01s

=== episode:1186 Env-steps-taken:75168
 	picked: 100 |actions: {0: 553, 1: 582, 2: 928, 3: 629, 4: 606, 5: 596, 6: 765, 7: 651, 8: 407}
episode: 1186/2000 -> reward: 134.88541666666663, steps:5717, time-taken: 3.90min, time-elasped: 2686.63min
-> berries picked: 100 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9055 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [924, 1369, 1362, 1036, 1001, 876, 710, 674, 1103]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 19, 13, 11, 19, 10, 13, 12, 17]
	Time taken saving stuff: 0.09s

=== episode:1187 Env-steps-taken:74016
 	picked: 97 |actions: {0: 606, 1: 639, 2: 814, 3: 675, 4: 618, 5: 549, 6: 799, 7: 567, 8: 390}
episode: 1187/2000 -> reward: 130.4427083333332, steps:5657, time-taken: 3.68min, time-elasped: 2690.31min
-> berries picked: 97 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9078 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [930, 1380, 1357, 1044, 999, 880, 711, 675, 1102]
	| approx positives in sample 512: 147
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 19, 14, 18, 12, 9, 12, 13, 29]
	Time taken saving stuff: 0.09s

=== episode:1188 Env-steps-taken:65760
 	picked: 69 |actions: {0: 440, 1: 573, 2: 625, 3: 694, 4: 622, 5: 458, 6: 696, 7: 513, 8: 407}
episode: 1188/2000 -> reward: 89.04687499999994, steps:5028, time-taken: 3.58min, time-elasped: 2693.90min
-> berries picked: 69 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9088 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [935, 1378, 1364, 1040, 1003, 875, 716, 675, 1102]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 20, 12, 12, 14, 14, 15, 10, 19]
	Time taken saving stuff: 0.02s

=== episode:1189 Env-steps-taken:67968
 	picked: 74 |actions: {0: 484, 1: 459, 2: 427, 3: 534, 4: 438, 5: 346, 6: 580, 7: 456, 8: 325}
episode: 1189/2000 -> reward: 100.76041666666659, steps:4049, time-taken: 2.65min, time-elasped: 2696.57min
-> berries picked: 74 of 800 | patches-visited: [0, 4, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9106 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [935, 1382, 1370, 1044, 1005, 874, 716, 675, 1105]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 22, 26, 11, 14, 10, 14, 16, 12]
	Time taken saving stuff: 0.00s

=== episode:1190 Env-steps-taken:72864
 	picked: 95 |actions: {0: 584, 1: 709, 2: 618, 3: 582, 4: 594, 5: 537, 6: 718, 7: 705, 8: 485}
episode: 1190/2000 -> reward: 124.55729166666652, steps:5532, time-taken: 3.65min, time-elasped: 2700.22min
-> berries picked: 95 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9118 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [948, 1378, 1375, 1047, 998, 876, 712, 680, 1104]
	| approx positives in sample 512: 172
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 19, 27, 24, 12, 26, 5, 18, 24]
	Time taken saving stuff: 0.16s

=== episode:119 Env-steps-taken:87360
 	picked: 151 |actions: {0: 976, 1: 373, 2: 512, 3: 1136, 4: 121, 5: 1280, 6: 208, 7: 458, 8: 178}

==================================================
eval-episode: 1190 -> reward: 196.463541666667, steps: 5242.0, wall-time: 78.62s
-> berries picked: 151 of 800 | patches-visited: [0, 1, 8] | juice left:-0.00
==================================================


=== episode:1191 Env-steps-taken:68544
 	picked: 76 |actions: {0: 425, 1: 509, 2: 736, 3: 542, 4: 742, 5: 483, 6: 613, 7: 329, 8: 328}
episode: 1191/2000 -> reward: 103.14583333333326, steps:4707, time-taken: 3.16min, time-elasped: 2704.69min
-> berries picked: 76 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9111 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [952, 1377, 1372, 1052, 996, 869, 712, 677, 1104]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 14, 24, 10, 17, 12, 14, 13, 24]
	Time taken saving stuff: 0.10s

=== episode:1192 Env-steps-taken:69792
 	picked: 84 |actions: {0: 730, 1: 717, 2: 885, 3: 549, 4: 695, 5: 523, 6: 453, 7: 540, 8: 330}
episode: 1192/2000 -> reward: 109.18749999999989, steps:5422, time-taken: 3.74min, time-elasped: 2708.44min
-> berries picked: 84 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9139 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [954, 1384, 1382, 1052, 997, 871, 712, 679, 1108]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 21, 20, 10, 15, 8, 10, 9, 17]
	Time taken saving stuff: 0.01s

=== episode:1193 Env-steps-taken:66144
 	picked: 64 |actions: {0: 489, 1: 448, 2: 677, 3: 388, 4: 450, 5: 376, 6: 416, 7: 424, 8: 273}
episode: 1193/2000 -> reward: 89.39062499999997, steps:3941, time-taken: 2.50min, time-elasped: 2710.95min
-> berries picked: 64 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9134 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [957, 1383, 1382, 1052, 999, 867, 713, 673, 1108]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 15, 17, 17, 13, 17, 13, 12, 25]
	Time taken saving stuff: 0.09s

=== episode:1194 Env-steps-taken:66720
 	picked: 71 |actions: {0: 410, 1: 450, 2: 369, 3: 438, 4: 469, 5: 441, 6: 406, 7: 414, 8: 253}
episode: 1194/2000 -> reward: 93.93229166666661, steps:3650, time-taken: 2.66min, time-elasped: 2713.62min
-> berries picked: 71 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9147 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [956, 1384, 1385, 1050, 995, 876, 721, 673, 1107]
	| approx positives in sample 512: 163
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 23, 17, 16, 18, 19, 16, 8, 25]
	Time taken saving stuff: 0.01s

=== episode:1195 Env-steps-taken:70080
 	picked: 85 |actions: {0: 533, 1: 538, 2: 677, 3: 533, 4: 480, 5: 528, 6: 865, 7: 465, 8: 272}
episode: 1195/2000 -> reward: 110.6302083333332, steps:4891, time-taken: 3.27min, time-elasped: 2716.89min
-> berries picked: 85 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9171 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [957, 1389, 1387, 1055, 1000, 877, 724, 671, 1111]
	| approx positives in sample 512: 159
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [25, 18, 13, 17, 20, 16, 14, 11, 25]
	Time taken saving stuff: 0.07s

=== episode:1196 Env-steps-taken:76704
 	picked: 104 |actions: {0: 738, 1: 535, 2: 642, 3: 617, 4: 703, 5: 616, 6: 803, 7: 657, 8: 336}
episode: 1196/2000 -> reward: 144.04166666666666, steps:5647, time-taken: 3.72min, time-elasped: 2720.62min
-> berries picked: 104 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9180 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [963, 1387, 1382, 1050, 1006, 877, 730, 672, 1113]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 18, 16, 13, 15, 16, 13, 11, 15]
	Time taken saving stuff: 0.02s

=== episode:1197 Env-steps-taken:63744
 	picked: 57 |actions: {0: 398, 1: 402, 2: 366, 3: 310, 4: 423, 5: 445, 6: 384, 7: 353, 8: 316}
episode: 1197/2000 -> reward: 78.734375, steps:3397, time-taken: 2.16min, time-elasped: 2722.78min
-> berries picked: 57 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9183 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [958, 1393, 1384, 1050, 1002, 876, 736, 672, 1112]
	| approx positives in sample 512: 150
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 16, 25, 18, 17, 11, 14, 13, 27]
	Time taken saving stuff: 0.08s

=== episode:1198 Env-steps-taken:73248
 	picked: 99 |actions: {0: 709, 1: 638, 2: 762, 3: 760, 4: 865, 5: 410, 6: 826, 7: 494, 8: 420}
episode: 1198/2000 -> reward: 125.44270833333317, steps:5884, time-taken: 3.78min, time-elasped: 2726.57min
-> berries picked: 99 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9195 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [967, 1389, 1389, 1056, 1007, 880, 728, 666, 1113]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 22, 10, 13, 17, 15, 11, 13, 20]
	Time taken saving stuff: 0.02s

=== episode:1199 Env-steps-taken:66240
 	picked: 74 |actions: {0: 728, 1: 647, 2: 732, 3: 534, 4: 521, 5: 362, 6: 656, 7: 519, 8: 427}
episode: 1199/2000 -> reward: 90.76041666666661, steps:5126, time-taken: 3.23min, time-elasped: 2729.80min
-> berries picked: 74 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9198 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [972, 1399, 1387, 1055, 1004, 879, 725, 665, 1112]
	| approx positives in sample 512: 149
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 19, 21, 18, 10, 18, 8, 8, 33]
	Time taken saving stuff: 0.11s

=== episode:1200 Env-steps-taken:70944
 	picked: 88 |actions: {0: 621, 1: 515, 2: 579, 3: 480, 4: 670, 5: 461, 6: 616, 7: 582, 8: 350}
episode: 1200/2000 -> reward: 113.57291666666653, steps:4874, time-taken: 3.27min, time-elasped: 2733.08min
-> berries picked: 88 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9227 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [972, 1404, 1392, 1058, 1006, 881, 727, 670, 1117]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 19, 14, 15, 17, 18, 10, 9, 21]
	Time taken saving stuff: 0.17s

=== episode:120 Env-steps-taken:86976
 	picked: 145 |actions: {0: 766, 1: 414, 2: 739, 3: 726, 4: 919, 5: 333, 6: 362, 7: 911, 8: 124}

==================================================
eval-episode: 1200 -> reward: 194.25000000000028, steps: 5294.0, wall-time: 77.12s
-> berries picked: 145 of 800 | patches-visited: [1, 2, 3] | juice left:-0.00
==================================================


=== episode:1201 Env-steps-taken:61440
 	picked: 54 |actions: {0: 287, 1: 348, 2: 300, 3: 394, 4: 278, 5: 343, 6: 319, 7: 310, 8: 168}
episode: 1201/2000 -> reward: 66.90625000000004, steps:2747, time-taken: 2.26min, time-elasped: 2736.63min
-> berries picked: 54 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9229 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [973, 1402, 1395, 1060, 1004, 879, 726, 672, 1118]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 14, 25, 16, 11, 6, 15, 10, 15]
	Time taken saving stuff: 0.01s

=== episode:1202 Env-steps-taken:74976
 	picked: 108 |actions: {0: 708, 1: 755, 2: 721, 3: 870, 4: 771, 5: 731, 6: 780, 7: 588, 8: 377}
episode: 1202/2000 -> reward: 134.8124999999999, steps:6301, time-taken: 3.72min, time-elasped: 2740.35min
-> berries picked: 108 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9244 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [965, 1406, 1398, 1064, 1004, 887, 726, 677, 1117]
	| approx positives in sample 512: 150
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 20, 19, 17, 21, 14, 11, 8, 20]
	Time taken saving stuff: 0.11s

=== episode:1203 Env-steps-taken:73344
 	picked: 95 |actions: {0: 511, 1: 493, 2: 664, 3: 588, 4: 555, 5: 724, 6: 632, 7: 665, 8: 366}
episode: 1203/2000 -> reward: 125.11458333333317, steps:5198, time-taken: 3.26min, time-elasped: 2743.62min
-> berries picked: 95 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9263 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [966, 1404, 1394, 1066, 1007, 893, 731, 685, 1117]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 18, 21, 13, 12, 12, 15, 13, 21]
	Time taken saving stuff: 0.09s

=== episode:1204 Env-steps-taken:66144
 	picked: 75 |actions: {0: 561, 1: 482, 2: 525, 3: 529, 4: 511, 5: 684, 6: 630, 7: 770, 8: 466}
episode: 1204/2000 -> reward: 90.70312499999993, steps:5158, time-taken: 3.35min, time-elasped: 2746.98min
-> berries picked: 75 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9255 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [957, 1402, 1392, 1064, 1006, 893, 737, 686, 1118]
	| approx positives in sample 512: 161
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 23, 15, 15, 15, 22, 13, 11, 28]
	Time taken saving stuff: 0.01s

=== episode:1205 Env-steps-taken:69792
 	picked: 84 |actions: {0: 579, 1: 588, 2: 793, 3: 544, 4: 667, 5: 420, 6: 644, 7: 395, 8: 444}
episode: 1205/2000 -> reward: 109.18749999999989, steps:5074, time-taken: 3.25min, time-elasped: 2750.24min
-> berries picked: 84 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9264 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [958, 1405, 1393, 1069, 1006, 891, 739, 681, 1122]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 18, 19, 17, 13, 8, 14, 12, 19]
	Time taken saving stuff: 0.03s

=== episode:1206 Env-steps-taken:64608
 	picked: 69 |actions: {0: 414, 1: 393, 2: 458, 3: 440, 4: 481, 5: 391, 6: 532, 7: 448, 8: 216}
episode: 1206/2000 -> reward: 83.04687499999996, steps:3773, time-taken: 2.43min, time-elasped: 2752.68min
-> berries picked: 69 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9283 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [961, 1409, 1390, 1077, 1007, 894, 739, 682, 1124]
	| approx positives in sample 512: 165
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 22, 23, 16, 19, 17, 16, 8, 25]
	Time taken saving stuff: 0.10s

=== episode:1207 Env-steps-taken:69888
 	picked: 85 |actions: {0: 566, 1: 725, 2: 653, 3: 545, 4: 601, 5: 578, 6: 736, 7: 519, 8: 344}
episode: 1207/2000 -> reward: 109.63020833333319, steps:5267, time-taken: 3.46min, time-elasped: 2756.14min
-> berries picked: 85 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9288 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [961, 1412, 1383, 1083, 1003, 899, 740, 680, 1127]
	| approx positives in sample 512: 147
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 15, 15, 16, 18, 16, 13, 9, 28]
	Time taken saving stuff: 0.01s

=== episode:1208 Env-steps-taken:72576
 	picked: 92 |actions: {0: 664, 1: 655, 2: 595, 3: 769, 4: 597, 5: 599, 6: 629, 7: 480, 8: 391}
episode: 1208/2000 -> reward: 123.22916666666649, steps:5379, time-taken: 3.42min, time-elasped: 2759.57min
-> berries picked: 92 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9307 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [961, 1418, 1389, 1083, 1007, 899, 739, 682, 1129]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 21, 19, 18, 10, 6, 8, 6, 22]
	Time taken saving stuff: 0.12s

=== episode:1209 Env-steps-taken:66432
 	picked: 75 |actions: {0: 670, 1: 716, 2: 862, 3: 649, 4: 732, 5: 592, 6: 768, 7: 649, 8: 402}
episode: 1209/2000 -> reward: 91.70312499999991, steps:6040, time-taken: 3.66min, time-elasped: 2763.24min
-> berries picked: 75 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9317 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [966, 1424, 1385, 1089, 1008, 896, 742, 679, 1128]
	| approx positives in sample 512: 146
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 31, 11, 13, 16, 15, 13, 10, 23]
	Time taken saving stuff: 0.11s

=== episode:1210 Env-steps-taken:72672
 	picked: 89 |actions: {0: 592, 1: 714, 2: 661, 3: 627, 4: 655, 5: 613, 6: 656, 7: 648, 8: 358}
episode: 1210/2000 -> reward: 123.9010416666665, steps:5524, time-taken: 3.57min, time-elasped: 2766.81min
-> berries picked: 89 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9328 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [965, 1424, 1387, 1090, 1008, 902, 742, 682, 1128]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 18, 20, 22, 16, 7, 6, 11, 28]
	Time taken saving stuff: 0.10s

=== episode:121 Env-steps-taken:98400
 	picked: 199 |actions: {0: 996, 1: 594, 2: 993, 3: 967, 4: 405, 5: 967, 6: 547, 7: 724, 8: 478}

==================================================
eval-episode: 1210 -> reward: 250.32812500000082, steps: 6671.0, wall-time: 80.32s
-> berries picked: 199 of 800 | patches-visited: [1, 2, 5] | juice left:-0.00
==================================================


=== episode:1211 Env-steps-taken:67776
 	picked: 78 |actions: {0: 572, 1: 503, 2: 666, 3: 534, 4: 555, 5: 528, 6: 492, 7: 560, 8: 320}
episode: 1211/2000 -> reward: 99.0312499999999, steps:4730, time-taken: 3.09min, time-elasped: 2771.24min
-> berries picked: 78 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9337 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [968, 1420, 1394, 1095, 1007, 897, 741, 685, 1130]
	| approx positives in sample 512: 152
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 20, 19, 16, 19, 11, 16, 10, 29]
	Time taken saving stuff: 0.01s

=== episode:1212 Env-steps-taken:66624
 	picked: 79 |actions: {0: 884, 1: 752, 2: 774, 3: 597, 4: 784, 5: 442, 6: 698, 7: 621, 8: 440}
episode: 1212/2000 -> reward: 92.47395833333326, steps:5992, time-taken: 3.48min, time-elasped: 2774.72min
-> berries picked: 79 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9338 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [972, 1421, 1392, 1096, 1011, 897, 732, 686, 1131]
	| approx positives in sample 512: 146
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 19, 23, 15, 18, 15, 9, 15, 19]
	Time taken saving stuff: 0.11s

=== episode:1213 Env-steps-taken:64896
 	picked: 72 |actions: {0: 469, 1: 393, 2: 577, 3: 416, 4: 459, 5: 296, 6: 367, 7: 284, 8: 287}
episode: 1213/2000 -> reward: 84.37499999999997, steps:3548, time-taken: 2.26min, time-elasped: 2776.99min
-> berries picked: 72 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9373 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [973, 1436, 1393, 1100, 1015, 899, 734, 690, 1133]
	| approx positives in sample 512: 149
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 20, 25, 9, 18, 9, 15, 12, 26]
	Time taken saving stuff: 0.01s

=== episode:1214 Env-steps-taken:65280
 	picked: 62 |actions: {0: 421, 1: 404, 2: 409, 3: 389, 4: 457, 5: 492, 6: 479, 7: 609, 8: 272}
episode: 1214/2000 -> reward: 86.94791666666663, steps:3932, time-taken: 2.84min, time-elasped: 2779.83min
-> berries picked: 62 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9367 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [970, 1437, 1390, 1093, 1016, 898, 737, 694, 1132]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 19, 21, 20, 17, 17, 7, 9, 21]
	Time taken saving stuff: 0.01s

=== episode:1215 Env-steps-taken:80160
 	picked: 115 |actions: {0: 651, 1: 786, 2: 866, 3: 839, 4: 744, 5: 595, 6: 682, 7: 707, 8: 403}
episode: 1215/2000 -> reward: 161.91145833333346, steps:6273, time-taken: 4.21min, time-elasped: 2784.04min
-> berries picked: 115 of 800 | patches-visited: [0, 4, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9389 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [970, 1440, 1397, 1097, 1023, 897, 737, 694, 1134]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 18, 16, 14, 14, 11, 11, 16, 19]
	Time taken saving stuff: 0.01s

=== episode:1216 Env-steps-taken:65472
 	picked: 65 |actions: {0: 398, 1: 506, 2: 602, 3: 331, 4: 439, 5: 396, 6: 412, 7: 320, 8: 295}
episode: 1216/2000 -> reward: 87.27604166666663, steps:3699, time-taken: 2.42min, time-elasped: 2786.47min
-> berries picked: 65 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9396 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [967, 1449, 1399, 1095, 1032, 895, 734, 691, 1134]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 21, 25, 12, 8, 8, 19, 11, 25]
	Time taken saving stuff: 0.01s

=== episode:1217 Env-steps-taken:68352
 	picked: 77 |actions: {0: 825, 1: 670, 2: 674, 3: 491, 4: 654, 5: 448, 6: 744, 7: 630, 8: 378}
episode: 1217/2000 -> reward: 101.58854166666657, steps:5514, time-taken: 3.49min, time-elasped: 2789.96min
-> berries picked: 77 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9397 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [970, 1450, 1400, 1089, 1027, 901, 737, 691, 1132]
	| approx positives in sample 512: 150
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 23, 22, 23, 19, 9, 12, 7, 15]
	Time taken saving stuff: 0.01s

=== episode:1218 Env-steps-taken:75552
 	picked: 103 |actions: {0: 667, 1: 823, 2: 722, 3: 655, 4: 756, 5: 800, 6: 793, 7: 748, 8: 424}
episode: 1218/2000 -> reward: 138.0989583333332, steps:6388, time-taken: 4.19min, time-elasped: 2794.15min
-> berries picked: 103 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9421 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [972, 1461, 1398, 1088, 1027, 905, 741, 694, 1135]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 19, 17, 11, 17, 16, 10, 8, 20]
	Time taken saving stuff: 0.01s

=== episode:1219 Env-steps-taken:63840
 	picked: 71 |actions: {0: 669, 1: 580, 2: 629, 3: 557, 4: 645, 5: 431, 6: 700, 7: 384, 8: 333}
episode: 1219/2000 -> reward: 78.43229166666664, steps:4928, time-taken: 3.06min, time-elasped: 2797.22min
-> berries picked: 71 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9409 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [969, 1459, 1394, 1090, 1024, 912, 738, 689, 1134]
	| approx positives in sample 512: 149
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 24, 17, 16, 21, 20, 12, 9, 20]
	Time taken saving stuff: 0.01s

=== episode:1220 Env-steps-taken:75744
 	picked: 108 |actions: {0: 711, 1: 818, 2: 765, 3: 696, 4: 930, 5: 714, 6: 738, 7: 680, 8: 421}
episode: 1220/2000 -> reward: 138.81249999999994, steps:6473, time-taken: 3.98min, time-elasped: 2801.20min
-> berries picked: 108 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9421 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [967, 1465, 1394, 1087, 1029, 915, 741, 685, 1138]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 16, 20, 18, 9, 13, 6, 13, 24]
	Time taken saving stuff: 0.08s

=== episode:122 Env-steps-taken:77184
 	picked: 109 |actions: {0: 484, 1: 221, 2: 656, 3: 81, 4: 464, 5: 217, 6: 3200, 7: 419, 8: 188}

==================================================
eval-episode: 1220 -> reward: 145.8697916666666, steps: 5930.0, wall-time: 66.01s
-> berries picked: 109 of 800 | patches-visited: [1, 2, 9] | juice left:-0.00
==================================================


=== episode:1221 Env-steps-taken:62688
 	picked: 56 |actions: {0: 428, 1: 453, 2: 335, 3: 409, 4: 486, 5: 562, 6: 419, 7: 390, 8: 288}
episode: 1221/2000 -> reward: 73.29166666666667, steps:3770, time-taken: 2.52min, time-elasped: 2804.83min
-> berries picked: 56 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9412 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [963, 1458, 1397, 1089, 1031, 920, 739, 676, 1139]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 21, 19, 13, 17, 17, 11, 7, 18]
	Time taken saving stuff: 0.09s

=== episode:1222 Env-steps-taken:66816
 	picked: 72 |actions: {0: 771, 1: 639, 2: 590, 3: 613, 4: 845, 5: 651, 6: 769, 7: 847, 8: 350}
episode: 1222/2000 -> reward: 93.87499999999994, steps:6075, time-taken: 3.47min, time-elasped: 2808.30min
-> berries picked: 72 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9377 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [955, 1456, 1396, 1084, 1032, 908, 734, 677, 1135]
	| approx positives in sample 512: 146
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 17, 21, 17, 11, 17, 11, 9, 31]
	Time taken saving stuff: 0.08s

=== episode:1223 Env-steps-taken:73920
 	picked: 94 |actions: {0: 571, 1: 663, 2: 668, 3: 521, 4: 690, 5: 739, 6: 717, 7: 785, 8: 390}
episode: 1223/2000 -> reward: 130.11458333333314, steps:5744, time-taken: 3.38min, time-elasped: 2811.69min
-> berries picked: 94 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9389 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [968, 1458, 1395, 1084, 1032, 912, 731, 671, 1138]
	| approx positives in sample 512: 150
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 18, 22, 23, 11, 10, 12, 12, 29]
	Time taken saving stuff: 0.00s

=== episode:1224 Env-steps-taken:77568
 	picked: 106 |actions: {0: 731, 1: 742, 2: 722, 3: 778, 4: 884, 5: 679, 6: 626, 7: 720, 8: 420}
episode: 1224/2000 -> reward: 148.4270833333333, steps:6302, time-taken: 3.74min, time-elasped: 2815.44min
-> berries picked: 106 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9389 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [959, 1460, 1407, 1086, 1031, 907, 731, 670, 1138]
	| approx positives in sample 512: 145
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 16, 27, 20, 14, 14, 9, 12, 25]
	Time taken saving stuff: 0.03s

=== episode:1225 Env-steps-taken:69408
 	picked: 86 |actions: {0: 702, 1: 574, 2: 670, 3: 520, 4: 588, 5: 645, 6: 603, 7: 594, 8: 539}
episode: 1225/2000 -> reward: 107.07291666666657, steps:5435, time-taken: 3.10min, time-elasped: 2818.54min
-> berries picked: 86 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9400 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [957, 1461, 1405, 1089, 1034, 913, 733, 669, 1139]
	| approx positives in sample 512: 154
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 23, 13, 17, 20, 16, 19, 12, 23]
	Time taken saving stuff: 0.02s

=== episode:1226 Env-steps-taken:67008
 	picked: 72 |actions: {0: 579, 1: 516, 2: 665, 3: 519, 4: 653, 5: 416, 6: 610, 7: 652, 8: 399}
episode: 1226/2000 -> reward: 95.37499999999991, steps:5009, time-taken: 2.63min, time-elasped: 2821.17min
-> berries picked: 72 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9395 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [955, 1457, 1403, 1093, 1040, 909, 734, 664, 1140]
	| approx positives in sample 512: 162
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 27, 16, 8, 19, 18, 11, 16, 26]
	Time taken saving stuff: 0.12s

=== episode:1227 Env-steps-taken:70176
 	picked: 80 |actions: {0: 641, 1: 527, 2: 603, 3: 549, 4: 622, 5: 527, 6: 527, 7: 528, 8: 325}
episode: 1227/2000 -> reward: 111.41666666666653, steps:4849, time-taken: 2.90min, time-elasped: 2824.07min
-> berries picked: 80 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9424 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [952, 1457, 1412, 1098, 1048, 912, 738, 668, 1139]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 25, 20, 15, 14, 13, 11, 5, 23]
	Time taken saving stuff: 0.09s

=== episode:1228 Env-steps-taken:72768
 	picked: 91 |actions: {0: 540, 1: 655, 2: 512, 3: 474, 4: 730, 5: 553, 6: 592, 7: 473, 8: 309}
episode: 1228/2000 -> reward: 124.28645833333319, steps:4838, time-taken: 2.71min, time-elasped: 2826.78min
-> berries picked: 91 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9452 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [957, 1463, 1407, 1101, 1053, 912, 746, 673, 1140]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 15, 22, 17, 12, 14, 18, 4, 18]
	Time taken saving stuff: 0.02s

=== episode:1229 Env-steps-taken:66624
 	picked: 79 |actions: {0: 882, 1: 695, 2: 613, 3: 455, 4: 621, 5: 583, 6: 669, 7: 615, 8: 381}
episode: 1229/2000 -> reward: 92.47395833333324, steps:5514, time-taken: 3.14min, time-elasped: 2829.92min
-> berries picked: 79 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9459 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [961, 1466, 1410, 1095, 1047, 915, 750, 673, 1142]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 25, 22, 9, 19, 10, 12, 13, 17]
	Time taken saving stuff: 0.10s

=== episode:1230 Env-steps-taken:70176
 	picked: 79 |actions: {0: 463, 1: 407, 2: 570, 3: 518, 4: 509, 5: 435, 6: 599, 7: 454, 8: 303}
episode: 1230/2000 -> reward: 110.03124999999989, steps:4258, time-taken: 3.79min, time-elasped: 2833.72min
-> berries picked: 79 of 800 | patches-visited: [0, 3, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9476 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [960, 1468, 1411, 1098, 1052, 915, 746, 680, 1146]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 20, 11, 15, 13, 15, 13, 10, 21]
	Time taken saving stuff: 0.06s

=== episode:123 Env-steps-taken:83712
 	picked: 143 |actions: {0: 870, 1: 599, 2: 634, 3: 718, 4: 1189, 5: 284, 6: 739, 7: 444, 8: 200}

==================================================
eval-episode: 1230 -> reward: 178.3072916666669, steps: 5677.0, wall-time: 70.18s
-> berries picked: 143 of 800 | patches-visited: [1, 7] | juice left:-0.00
==================================================


=== episode:1231 Env-steps-taken:76224
 	picked: 110 |actions: {0: 550, 1: 827, 2: 654, 3: 606, 4: 737, 5: 719, 6: 880, 7: 890, 8: 418}
episode: 1231/2000 -> reward: 141.19791666666657, steps:6281, time-taken: 7.35min, time-elasped: 2842.25min
-> berries picked: 110 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9506 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [965, 1473, 1422, 1096, 1058, 916, 747, 682, 1147]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 16, 15, 23, 18, 11, 7, 8, 25]
	Time taken saving stuff: 0.06s

=== episode:1232 Env-steps-taken:77952
 	picked: 109 |actions: {0: 581, 1: 810, 2: 645, 3: 672, 4: 791, 5: 660, 6: 788, 7: 760, 8: 402}
episode: 1232/2000 -> reward: 150.2552083333333, steps:6109, time-taken: 2085.18min, time-elasped: 4927.44min
-> berries picked: 109 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9533 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [973, 1478, 1418, 1101, 1064, 921, 749, 683, 1146]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 26, 20, 12, 7, 11, 15, 10, 21]
	Time taken saving stuff: 0.00s

=== episode:1233 Env-steps-taken:76320
 	picked: 114 |actions: {0: 712, 1: 812, 2: 784, 3: 722, 4: 679, 5: 630, 6: 909, 7: 794, 8: 453}
episode: 1233/2000 -> reward: 141.46874999999991, steps:6495, time-taken: 3.47min, time-elasped: 4930.91min
-> berries picked: 114 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9569 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [978, 1483, 1428, 1097, 1067, 926, 754, 689, 1147]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 13, 15, 13, 15, 12, 9, 12, 15]
	Time taken saving stuff: 0.01s

=== episode:1234 Env-steps-taken:66624
 	picked: 75 |actions: {0: 589, 1: 975, 2: 808, 3: 668, 4: 584, 5: 550, 6: 605, 7: 582, 8: 348}
episode: 1234/2000 -> reward: 92.70312499999994, steps:5709, time-taken: 3.23min, time-elasped: 4934.14min
-> berries picked: 75 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9579 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [978, 1484, 1430, 1100, 1065, 932, 752, 689, 1149]
	| approx positives in sample 512: 150
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 28, 17, 20, 19, 12, 10, 9, 25]
	Time taken saving stuff: 0.08s

=== episode:1235 Env-steps-taken:77664
 	picked: 113 |actions: {0: 678, 1: 830, 2: 864, 3: 598, 4: 756, 5: 628, 6: 701, 7: 751, 8: 399}
episode: 1235/2000 -> reward: 148.52604166666663, steps:6205, time-taken: 5.54min, time-elasped: 4939.69min
-> berries picked: 113 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9578 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [971, 1486, 1435, 1100, 1064, 926, 752, 690, 1154]
	| approx positives in sample 512: 158
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 27, 24, 19, 9, 15, 10, 16, 24]
	Time taken saving stuff: 0.01s

=== episode:1236 Env-steps-taken:76992
 	picked: 110 |actions: {0: 625, 1: 688, 2: 791, 3: 925, 4: 676, 5: 667, 6: 740, 7: 701, 8: 447}
episode: 1236/2000 -> reward: 145.19791666666666, steps:6260, time-taken: 4.98min, time-elasped: 4944.67min
-> berries picked: 110 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9566 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [966, 1494, 1413, 1100, 1063, 929, 760, 692, 1149]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 21, 15, 20, 17, 13, 6, 9, 25]
	Time taken saving stuff: 0.03s

=== episode:1237 Env-steps-taken:76416
 	picked: 113 |actions: {0: 742, 1: 813, 2: 651, 3: 861, 4: 773, 5: 798, 6: 675, 7: 674, 8: 414}
episode: 1237/2000 -> reward: 142.02604166666657, steps:6401, time-taken: 4.54min, time-elasped: 4949.22min
-> berries picked: 113 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9564 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [968, 1487, 1401, 1101, 1069, 929, 768, 693, 1148]
	| approx positives in sample 512: 155
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 26, 17, 15, 12, 15, 13, 10, 29]
	Time taken saving stuff: 0.00s

=== episode:1238 Env-steps-taken:58848
 	picked: 37 |actions: {0: 297, 1: 471, 2: 332, 3: 235, 4: 233, 5: 214, 6: 213, 7: 442, 8: 397}
episode: 1238/2000 -> reward: 54.88020833333337, steps:2834, time-taken: 2.27min, time-elasped: 4951.49min
-> berries picked: 37 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9563 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [971, 1492, 1400, 1095, 1066, 930, 766, 694, 1149]
	| approx positives in sample 512: 139
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 19, 21, 16, 14, 19, 11, 8, 21]
	Time taken saving stuff: 0.01s

=== episode:1239 Env-steps-taken:75552
 	picked: 100 |actions: {0: 574, 1: 647, 2: 783, 3: 607, 4: 625, 5: 684, 6: 464, 7: 700, 8: 346}
episode: 1239/2000 -> reward: 138.27083333333323, steps:5430, time-taken: 3.75min, time-elasped: 4955.25min
-> berries picked: 100 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9568 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [969, 1490, 1402, 1095, 1066, 926, 770, 699, 1151]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 14, 21, 14, 7, 12, 8, 14, 21]
	Time taken saving stuff: 0.01s

=== episode:1240 Env-steps-taken:67488
 	picked: 80 |actions: {0: 562, 1: 620, 2: 760, 3: 582, 4: 568, 5: 474, 6: 755, 7: 600, 8: 414}
episode: 1240/2000 -> reward: 96.91666666666654, steps:5335, time-taken: 4.22min, time-elasped: 4959.48min
-> berries picked: 80 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9570 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [976, 1486, 1405, 1094, 1059, 927, 771, 702, 1150]
	| approx positives in sample 512: 145
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 26, 17, 23, 16, 17, 7, 11, 18]
	Time taken saving stuff: 0.12s

=== episode:124 Env-steps-taken:100128
 	picked: 205 |actions: {0: 1340, 1: 820, 2: 442, 3: 1562, 4: 795, 5: 962, 6: 735, 7: 496, 8: 324}

==================================================
eval-episode: 1240 -> reward: 259.8697916666674, steps: 7476.0, wall-time: 106.95s
-> berries picked: 205 of 800 | patches-visited: [0, 1, 8] | juice left:-0.00
==================================================


=== episode:1241 Env-steps-taken:63552
 	picked: 52 |actions: {0: 307, 1: 396, 2: 325, 3: 430, 4: 381, 5: 357, 6: 362, 7: 326, 8: 239}
episode: 1241/2000 -> reward: 78.52083333333333, steps:3123, time-taken: 2.35min, time-elasped: 4963.61min
-> berries picked: 52 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9524 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [969, 1487, 1403, 1096, 1055, 912, 762, 696, 1144]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 18, 23, 23, 13, 14, 10, 5, 14]
	Time taken saving stuff: 0.02s

=== episode:1242 Env-steps-taken:72672
 	picked: 94 |actions: {0: 645, 1: 685, 2: 606, 3: 589, 4: 534, 5: 468, 6: 811, 7: 710, 8: 405}
episode: 1242/2000 -> reward: 123.61458333333314, steps:5453, time-taken: 3.48min, time-elasped: 4967.10min
-> berries picked: 94 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9510 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [975, 1496, 1397, 1089, 1046, 908, 769, 690, 1140]
	| approx positives in sample 512: 153
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 19, 20, 21, 17, 14, 14, 10, 26]
	Time taken saving stuff: 0.01s

=== episode:1243 Env-steps-taken:69024
 	picked: 73 |actions: {0: 414, 1: 509, 2: 552, 3: 669, 4: 468, 5: 414, 6: 670, 7: 438, 8: 352}
episode: 1243/2000 -> reward: 106.31770833333321, steps:4486, time-taken: 3.12min, time-elasped: 4970.22min
-> berries picked: 73 of 800 | patches-visited: [0, 2, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9498 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [974, 1494, 1403, 1086, 1046, 911, 761, 686, 1137]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 20, 21, 21, 15, 16, 8, 13, 14]
	Time taken saving stuff: 0.03s

=== episode:1244 Env-steps-taken:64608
 	picked: 63 |actions: {0: 385, 1: 418, 2: 488, 3: 373, 4: 513, 5: 371, 6: 649, 7: 446, 8: 261}
episode: 1244/2000 -> reward: 82.94791666666663, steps:3904, time-taken: 2.97min, time-elasped: 4973.19min
-> berries picked: 63 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9489 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [973, 1490, 1402, 1084, 1044, 909, 766, 686, 1135]
	| approx positives in sample 512: 146
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 23, 18, 16, 13, 12, 20, 8, 26]
	Time taken saving stuff: 0.03s

=== episode:1245 Env-steps-taken:76512
 	picked: 107 |actions: {0: 552, 1: 665, 2: 766, 3: 755, 4: 604, 5: 557, 6: 777, 7: 625, 8: 332}
episode: 1245/2000 -> reward: 143.36979166666657, steps:5633, time-taken: 3.62min, time-elasped: 4976.82min
-> berries picked: 107 of 800 | patches-visited: [0, 2, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9503 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [969, 1494, 1401, 1081, 1049, 918, 762, 689, 1140]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [24, 12, 22, 12, 9, 7, 14, 9, 27]
	Time taken saving stuff: 0.04s

=== episode:1246 Env-steps-taken:69408
 	picked: 82 |actions: {0: 507, 1: 483, 2: 547, 3: 608, 4: 565, 5: 421, 6: 634, 7: 555, 8: 286}
episode: 1246/2000 -> reward: 107.01562499999987, steps:4606, time-taken: 3.23min, time-elasped: 4980.05min
-> berries picked: 82 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9445 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [962, 1484, 1382, 1074, 1048, 915, 762, 680, 1138]
	| approx positives in sample 512: 143
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 26, 19, 16, 14, 14, 14, 10, 21]
	Time taken saving stuff: 0.10s

=== episode:1247 Env-steps-taken:74112
 	picked: 102 |actions: {0: 694, 1: 746, 2: 696, 3: 638, 4: 756, 5: 614, 6: 618, 7: 645, 8: 422}
episode: 1247/2000 -> reward: 130.65624999999983, steps:5829, time-taken: 4.54min, time-elasped: 4984.60min
-> berries picked: 102 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9430 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [962, 1482, 1370, 1071, 1049, 919, 758, 681, 1138]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 20, 19, 19, 18, 15, 14, 10, 20]
	Time taken saving stuff: 0.03s

=== episode:1248 Env-steps-taken:77376
 	picked: 106 |actions: {0: 608, 1: 917, 2: 732, 3: 535, 4: 629, 5: 715, 6: 815, 7: 784, 8: 354}
episode: 1248/2000 -> reward: 147.42708333333326, steps:6089, time-taken: 4.77min, time-elasped: 4989.37min
-> berries picked: 106 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9416 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [959, 1485, 1361, 1067, 1046, 915, 762, 686, 1135]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 18, 14, 13, 12, 6, 8, 5, 23]
	Time taken saving stuff: 0.01s

=== episode:1249 Env-steps-taken:72000
 	picked: 91 |actions: {0: 538, 1: 686, 2: 660, 3: 732, 4: 677, 5: 605, 6: 596, 7: 516, 8: 327}
episode: 1249/2000 -> reward: 118.84374999999987, steps:5337, time-taken: 5.62min, time-elasped: 4995.00min
-> berries picked: 91 of 800 | patches-visited: [0, 3, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9416 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [960, 1485, 1358, 1063, 1052, 919, 764, 680, 1135]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 24, 15, 11, 17, 10, 15, 11, 18]
	Time taken saving stuff: 0.01s

=== episode:1250 Env-steps-taken:75840
 	picked: 104 |actions: {0: 583, 1: 652, 2: 749, 3: 664, 4: 629, 5: 533, 6: 641, 7: 550, 8: 391}
episode: 1250/2000 -> reward: 140.04166666666657, steps:5392, time-taken: 4.13min, time-elasped: 4999.14min
-> berries picked: 104 of 800 | patches-visited: [0, 7, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9426 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [961, 1477, 1361, 1069, 1054, 921, 768, 679, 1136]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 20, 16, 10, 16, 15, 8, 8, 16]
	Time taken saving stuff: 0.14s

=== episode:125 Env-steps-taken:91392
 	picked: 169 |actions: {0: 855, 1: 713, 2: 1185, 3: 298, 4: 859, 5: 339, 6: 1158, 7: 263, 8: 341}

==================================================
eval-episode: 1250 -> reward: 217.31770833333383, steps: 6011.0, wall-time: 91.22s
-> berries picked: 169 of 800 | patches-visited: [1, 4, 5] | juice left:-0.00
==================================================


=== episode:1251 Env-steps-taken:62016
 	picked: 53 |actions: {0: 242, 1: 338, 2: 397, 3: 312, 4: 386, 5: 359, 6: 539, 7: 393, 8: 234}
episode: 1251/2000 -> reward: 69.96354166666671, steps:3200, time-taken: 2.72min, time-elasped: 5003.38min
-> berries picked: 53 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9415 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [956, 1474, 1360, 1066, 1054, 920, 766, 683, 1136]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 15, 12, 14, 12, 16, 8, 8, 23]
	Time taken saving stuff: 0.02s

=== episode:1252 Env-steps-taken:74112
 	picked: 92 |actions: {0: 555, 1: 723, 2: 795, 3: 635, 4: 720, 5: 689, 6: 520, 7: 667, 8: 407}
episode: 1252/2000 -> reward: 130.34374999999986, steps:5711, time-taken: 4.24min, time-elasped: 5007.62min
-> berries picked: 92 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9404 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [953, 1475, 1362, 1066, 1054, 918, 761, 682, 1133]
	| approx positives in sample 512: 155
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 20, 22, 18, 16, 16, 9, 6, 34]
	Time taken saving stuff: 0.01s

=== episode:1253 Env-steps-taken:77376
 	picked: 108 |actions: {0: 571, 1: 842, 2: 859, 3: 797, 4: 760, 5: 580, 6: 754, 7: 705, 8: 438}
episode: 1253/2000 -> reward: 147.31249999999994, steps:6306, time-taken: 4.25min, time-elasped: 5011.88min
-> berries picked: 108 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9413 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [958, 1474, 1361, 1072, 1054, 916, 762, 686, 1130]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 18, 15, 25, 14, 10, 14, 13, 16]
	Time taken saving stuff: 0.00s

=== episode:1254 Env-steps-taken:72096
 	picked: 98 |actions: {0: 754, 1: 723, 2: 734, 3: 698, 4: 607, 5: 560, 6: 811, 7: 753, 8: 453}
episode: 1254/2000 -> reward: 120.3854166666665, steps:6093, time-taken: 3.96min, time-elasped: 5015.84min
-> berries picked: 98 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9417 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [959, 1472, 1362, 1066, 1052, 917, 766, 690, 1133]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 19, 15, 18, 9, 10, 15, 11, 20]
	Time taken saving stuff: 0.01s

=== episode:1255 Env-steps-taken:79296
 	picked: 118 |actions: {0: 782, 1: 847, 2: 728, 3: 760, 4: 803, 5: 577, 6: 942, 7: 887, 8: 451}
episode: 1255/2000 -> reward: 156.7395833333334, steps:6777, time-taken: 4.57min, time-elasped: 5020.41min
-> berries picked: 118 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9438 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [962, 1471, 1368, 1066, 1048, 919, 774, 696, 1134]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 22, 20, 11, 13, 10, 13, 15, 17]
	Time taken saving stuff: 0.01s

=== episode:1256 Env-steps-taken:64992
 	picked: 71 |actions: {0: 413, 1: 631, 2: 462, 3: 386, 4: 427, 5: 431, 6: 522, 7: 538, 8: 253}
episode: 1256/2000 -> reward: 83.54687499999999, steps:4063, time-taken: 2.63min, time-elasped: 5023.05min
-> berries picked: 71 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9440 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [963, 1475, 1366, 1066, 1049, 913, 778, 697, 1133]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 22, 22, 11, 19, 14, 16, 7, 22]
	Time taken saving stuff: 0.01s

=== episode:1257 Env-steps-taken:67872
 	picked: 80 |actions: {0: 521, 1: 611, 2: 576, 3: 530, 4: 847, 5: 581, 6: 792, 7: 784, 8: 475}
episode: 1257/2000 -> reward: 99.41666666666657, steps:5717, time-taken: 3.69min, time-elasped: 5026.74min
-> berries picked: 80 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9438 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [963, 1477, 1356, 1064, 1055, 914, 776, 699, 1134]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 15, 17, 20, 12, 14, 12, 12, 15]
	Time taken saving stuff: 0.03s

=== episode:1258 Env-steps-taken:65280
 	picked: 69 |actions: {0: 343, 1: 381, 2: 346, 3: 339, 4: 321, 5: 390, 6: 378, 7: 440, 8: 359}
episode: 1258/2000 -> reward: 86.54687499999999, steps:3297, time-taken: 2.27min, time-elasped: 5029.01min
-> berries picked: 69 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9450 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [968, 1480, 1348, 1062, 1059, 917, 777, 704, 1135]
	| approx positives in sample 512: 154
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 23, 22, 13, 10, 12, 14, 11, 28]
	Time taken saving stuff: 0.03s

=== episode:1259 Env-steps-taken:83520
 	picked: 120 |actions: {0: 715, 1: 850, 2: 954, 3: 641, 4: 853, 5: 669, 6: 603, 7: 780, 8: 443}
episode: 1259/2000 -> reward: 177.73958333333348, steps:6508, time-taken: 4.64min, time-elasped: 5033.66min
-> berries picked: 120 of 800 | patches-visited: [0, 2, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9465 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [974, 1468, 1357, 1069, 1065, 916, 773, 707, 1136]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 15, 19, 22, 17, 9, 10, 15, 25]
	Time taken saving stuff: 0.01s

=== episode:1260 Env-steps-taken:64224
 	picked: 60 |actions: {0: 421, 1: 400, 2: 485, 3: 304, 4: 363, 5: 376, 6: 436, 7: 674, 8: 279}
episode: 1260/2000 -> reward: 81.67708333333331, steps:3738, time-taken: 2.72min, time-elasped: 5036.39min
-> berries picked: 60 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9471 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [976, 1464, 1356, 1071, 1061, 913, 779, 715, 1136]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 23, 16, 15, 18, 6, 10, 10, 19]
	Time taken saving stuff: 0.12s

=== episode:126 Env-steps-taken:98400
 	picked: 192 |actions: {0: 281, 1: 1143, 2: 410, 3: 1979, 4: 606, 5: 277, 6: 892, 7: 1184, 8: 277}

==================================================
eval-episode: 1260 -> reward: 251.61458333333408, steps: 7049.0, wall-time: 88.57s
-> berries picked: 192 of 800 | patches-visited: [1, 5, 6] | juice left:-0.00
==================================================


=== episode:1261 Env-steps-taken:78912
 	picked: 115 |actions: {0: 664, 1: 608, 2: 806, 3: 754, 4: 696, 5: 814, 6: 664, 7: 741, 8: 435}
episode: 1261/2000 -> reward: 155.41145833333343, steps:6182, time-taken: 4.13min, time-elasped: 5041.99min
-> berries picked: 115 of 800 | patches-visited: [0, 4, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9430 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [968, 1453, 1330, 1075, 1065, 912, 780, 717, 1130]
	| approx positives in sample 512: 139
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 21, 9, 21, 21, 11, 15, 12, 13]
	Time taken saving stuff: 0.00s

=== episode:1262 Env-steps-taken:74688
 	picked: 100 |actions: {0: 697, 1: 662, 2: 705, 3: 719, 4: 762, 5: 562, 6: 605, 7: 578, 8: 437}
episode: 1262/2000 -> reward: 133.7708333333332, steps:5727, time-taken: 4.12min, time-elasped: 5046.12min
-> berries picked: 100 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9410 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [967, 1445, 1328, 1078, 1063, 905, 775, 720, 1129]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 25, 12, 12, 13, 10, 8, 9, 27]
	Time taken saving stuff: 0.06s

=== episode:1263 Env-steps-taken:71136
 	picked: 91 |actions: {0: 472, 1: 594, 2: 591, 3: 589, 4: 565, 5: 461, 6: 566, 7: 622, 8: 435}
episode: 1263/2000 -> reward: 112.57291666666652, steps:4895, time-taken: 3.63min, time-elasped: 5049.75min
-> berries picked: 91 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9425 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [966, 1442, 1333, 1089, 1062, 909, 774, 723, 1127]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 27, 15, 19, 18, 9, 11, 9, 23]
	Time taken saving stuff: 0.06s

=== episode:1264 Env-steps-taken:66048
 	picked: 68 |actions: {0: 496, 1: 541, 2: 523, 3: 386, 4: 491, 5: 398, 6: 370, 7: 412, 8: 280}
episode: 1264/2000 -> reward: 90.60416666666661, steps:3897, time-taken: 3.05min, time-elasped: 5052.81min
-> berries picked: 68 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9420 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [973, 1439, 1328, 1088, 1059, 907, 774, 725, 1127]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 18, 21, 13, 10, 14, 17, 13, 15]
	Time taken saving stuff: 0.09s

=== episode:1265 Env-steps-taken:65376
 	picked: 69 |actions: {0: 499, 1: 480, 2: 535, 3: 540, 4: 645, 5: 487, 6: 574, 7: 578, 8: 379}
episode: 1265/2000 -> reward: 86.16145833333329, steps:4717, time-taken: 3.54min, time-elasped: 5056.35min
-> berries picked: 69 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9402 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [970, 1437, 1316, 1085, 1061, 909, 778, 722, 1124]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 14, 22, 15, 16, 16, 8, 7, 33]
	Time taken saving stuff: 0.01s

=== episode:1266 Env-steps-taken:73536
 	picked: 96 |actions: {0: 654, 1: 725, 2: 683, 3: 779, 4: 643, 5: 632, 6: 719, 7: 580, 8: 400}
episode: 1266/2000 -> reward: 127.9999999999998, steps:5815, time-taken: 4.14min, time-elasped: 5060.50min
-> berries picked: 96 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9378 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [971, 1435, 1310, 1081, 1058, 907, 771, 726, 1119]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 17, 12, 15, 18, 17, 7, 6, 21]
	Time taken saving stuff: 0.11s

=== episode:1267 Env-steps-taken:77088
 	picked: 105 |actions: {0: 620, 1: 730, 2: 799, 3: 675, 4: 677, 5: 640, 6: 817, 7: 735, 8: 464}
episode: 1267/2000 -> reward: 146.0416666666666, steps:6157, time-taken: 3.87min, time-elasped: 5064.38min
-> berries picked: 105 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9372 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [970, 1435, 1314, 1082, 1039, 911, 777, 727, 1117]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 13, 13, 14, 8, 13, 8, 7, 17]
	Time taken saving stuff: 0.10s

=== episode:1268 Env-steps-taken:68832
 	picked: 80 |actions: {0: 603, 1: 579, 2: 594, 3: 571, 4: 633, 5: 405, 6: 624, 7: 538, 8: 444}
episode: 1268/2000 -> reward: 104.41666666666659, steps:4991, time-taken: 3.46min, time-elasped: 5067.84min
-> berries picked: 80 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9388 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [975, 1435, 1315, 1085, 1039, 911, 780, 723, 1125]
	| approx positives in sample 512: 167
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 24, 23, 15, 11, 20, 11, 16, 29]
	Time taken saving stuff: 0.03s

=== episode:1269 Env-steps-taken:79488
 	picked: 113 |actions: {0: 665, 1: 804, 2: 634, 3: 636, 4: 641, 5: 734, 6: 615, 7: 570, 8: 500}
episode: 1269/2000 -> reward: 158.52604166666669, steps:5799, time-taken: 3.96min, time-elasped: 5071.81min
-> berries picked: 113 of 800 | patches-visited: [0, 4, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9411 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [977, 1439, 1324, 1093, 1041, 911, 778, 724, 1124]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 23, 15, 24, 13, 11, 11, 7, 21]
	Time taken saving stuff: 0.11s

=== episode:1270 Env-steps-taken:65280
 	picked: 79 |actions: {0: 705, 1: 692, 2: 659, 3: 607, 4: 524, 5: 571, 6: 620, 7: 513, 8: 512}
episode: 1270/2000 -> reward: 85.47395833333324, steps:5403, time-taken: 3.49min, time-elasped: 5075.30min
-> berries picked: 79 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9408 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [973, 1441, 1328, 1092, 1043, 907, 773, 729, 1122]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 30, 13, 14, 18, 13, 12, 7, 28]
	Time taken saving stuff: 0.20s

=== episode:127 Env-steps-taken:93600
 	picked: 168 |actions: {0: 653, 1: 545, 2: 622, 3: 1261, 4: 267, 5: 1039, 6: 336, 7: 682, 8: 532}

==================================================
eval-episode: 1270 -> reward: 228.87500000000057, steps: 5937.0, wall-time: 85.76s
-> berries picked: 168 of 800 | patches-visited: [1, 4, 6] | juice left:-0.00
==================================================


=== episode:1271 Env-steps-taken:73344
 	picked: 86 |actions: {0: 459, 1: 594, 2: 602, 3: 508, 4: 598, 5: 528, 6: 514, 7: 530, 8: 339}
episode: 1271/2000 -> reward: 127.57291666666649, steps:4672, time-taken: 3.38min, time-elasped: 5080.11min
-> berries picked: 86 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9411 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [969, 1445, 1328, 1095, 1046, 906, 775, 721, 1126]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 16, 19, 18, 15, 14, 12, 6, 20]
	Time taken saving stuff: 0.02s

=== episode:1272 Env-steps-taken:73344
 	picked: 96 |actions: {0: 631, 1: 619, 2: 760, 3: 592, 4: 717, 5: 635, 6: 673, 7: 668, 8: 415}
episode: 1272/2000 -> reward: 125.61458333333317, steps:5710, time-taken: 3.82min, time-elasped: 5083.93min
-> berries picked: 96 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9423 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [971, 1443, 1324, 1102, 1045, 909, 777, 724, 1128]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 20, 11, 18, 17, 15, 12, 7, 19]
	Time taken saving stuff: 0.03s

=== episode:1273 Env-steps-taken:67968
 	picked: 80 |actions: {0: 549, 1: 775, 2: 670, 3: 473, 4: 619, 5: 466, 6: 670, 7: 641, 8: 379}
episode: 1273/2000 -> reward: 99.41666666666654, steps:5242, time-taken: 3.51min, time-elasped: 5087.45min
-> berries picked: 80 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9442 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [972, 1448, 1330, 1107, 1044, 909, 778, 727, 1127]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 23, 24, 12, 14, 10, 15, 14, 21]
	Time taken saving stuff: 0.09s

=== episode:1274 Env-steps-taken:73344
 	picked: 106 |actions: {0: 681, 1: 561, 2: 710, 3: 728, 4: 607, 5: 847, 6: 697, 7: 661, 8: 377}
episode: 1274/2000 -> reward: 126.42708333333312, steps:5869, time-taken: 4.07min, time-elasped: 5091.53min
-> berries picked: 106 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9459 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [973, 1450, 1332, 1109, 1043, 914, 784, 728, 1126]
	| approx positives in sample 512: 147
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 24, 16, 9, 23, 15, 8, 11, 28]
	Time taken saving stuff: 0.01s

=== episode:1275 Env-steps-taken:61536
 	picked: 54 |actions: {0: 391, 1: 496, 2: 429, 3: 366, 4: 288, 5: 414, 6: 461, 7: 377, 8: 237}
episode: 1275/2000 -> reward: 67.52083333333337, steps:3459, time-taken: 2.68min, time-elasped: 5094.21min
-> berries picked: 54 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9463 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [975, 1451, 1326, 1110, 1042, 913, 789, 728, 1129]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 7, 20, 14, 7, 14, 16, 12, 25]
	Time taken saving stuff: 0.10s

=== episode:1276 Env-steps-taken:60480
 	picked: 43 |actions: {0: 295, 1: 246, 2: 190, 3: 268, 4: 288, 5: 179, 6: 347, 7: 310, 8: 137}
episode: 1276/2000 -> reward: 63.03645833333338, steps:2260, time-taken: 1.75min, time-elasped: 5095.96min
-> berries picked: 43 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9465 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [974, 1449, 1326, 1112, 1042, 913, 792, 727, 1130]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 16, 9, 12, 16, 14, 14, 12, 26]
	Time taken saving stuff: 0.09s

=== episode:1277 Env-steps-taken:76128
 	picked: 113 |actions: {0: 670, 1: 680, 2: 607, 3: 686, 4: 686, 5: 816, 6: 782, 7: 692, 8: 414}
episode: 1277/2000 -> reward: 140.52604166666657, steps:6033, time-taken: 3.98min, time-elasped: 5099.95min
-> berries picked: 113 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9477 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [975, 1446, 1327, 1112, 1049, 917, 791, 730, 1130]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 21, 19, 18, 14, 10, 8, 13, 26]
	Time taken saving stuff: 0.01s

=== episode:1278 Env-steps-taken:76992
 	picked: 115 |actions: {0: 793, 1: 730, 2: 779, 3: 700, 4: 652, 5: 754, 6: 689, 7: 725, 8: 411}
episode: 1278/2000 -> reward: 144.91145833333331, steps:6233, time-taken: 4.10min, time-elasped: 5104.06min
-> berries picked: 115 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9498 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [974, 1451, 1329, 1114, 1054, 917, 798, 729, 1132]
	| approx positives in sample 512: 146
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 21, 24, 10, 23, 13, 12, 12, 22]
	Time taken saving stuff: 0.01s

=== episode:1279 Env-steps-taken:68160
 	picked: 79 |actions: {0: 558, 1: 437, 2: 483, 3: 455, 4: 638, 5: 416, 6: 716, 7: 636, 8: 445}
episode: 1279/2000 -> reward: 100.47395833333323, steps:4784, time-taken: 3.30min, time-elasped: 5107.36min
-> berries picked: 79 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9501 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [970, 1445, 1334, 1116, 1059, 915, 802, 730, 1130]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 22, 14, 13, 17, 9, 12, 7, 21]
	Time taken saving stuff: 0.11s

=== episode:1280 Env-steps-taken:80160
 	picked: 118 |actions: {0: 720, 1: 723, 2: 749, 3: 856, 4: 646, 5: 579, 6: 773, 7: 745, 8: 436}
episode: 1280/2000 -> reward: 161.23958333333343, steps:6227, time-taken: 4.55min, time-elasped: 5111.92min
-> berries picked: 118 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9554 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [972, 1453, 1333, 1120, 1067, 924, 807, 746, 1132]
	| approx positives in sample 512: 152
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 19, 12, 22, 15, 13, 12, 12, 27]
	Time taken saving stuff: 0.09s

=== episode:128 Env-steps-taken:66144
 	picked: 62 |actions: {0: 102, 1: 244, 2: 115, 3: 447, 4: 1322, 5: 125, 6: 460, 7: 2324, 8: 75}

==================================================
eval-episode: 1280 -> reward: 90.56249999999994, steps: 5214.0, wall-time: 55.38s
-> berries picked: 62 of 800 | patches-visited: [1, 9] | juice left:-0.00
==================================================


=== episode:1281 Env-steps-taken:70944
 	picked: 97 |actions: {0: 663, 1: 716, 2: 547, 3: 668, 4: 538, 5: 415, 6: 784, 7: 630, 8: 415}
episode: 1281/2000 -> reward: 112.49999999999984, steps:5376, time-taken: 3.71min, time-elasped: 5116.56min
-> berries picked: 97 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9558 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [972, 1460, 1333, 1120, 1067, 918, 799, 755, 1134]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 21, 16, 12, 11, 11, 6, 9, 29]
	Time taken saving stuff: 0.06s

=== episode:1282 Env-steps-taken:70752
 	picked: 86 |actions: {0: 606, 1: 417, 2: 555, 3: 619, 4: 538, 5: 470, 6: 489, 7: 535, 8: 372}
episode: 1282/2000 -> reward: 114.07291666666653, steps:4601, time-taken: 3.56min, time-elasped: 5120.12min
-> berries picked: 86 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9565 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [977, 1461, 1331, 1118, 1067, 921, 800, 757, 1133]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 18, 17, 27, 16, 14, 8, 13, 16]
	Time taken saving stuff: 0.03s

=== episode:1283 Env-steps-taken:68736
 	picked: 76 |actions: {0: 464, 1: 565, 2: 533, 3: 496, 4: 443, 5: 391, 6: 520, 7: 503, 8: 394}
episode: 1283/2000 -> reward: 104.14583333333323, steps:4309, time-taken: 3.13min, time-elasped: 5123.26min
-> berries picked: 76 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9568 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [981, 1465, 1334, 1119, 1066, 916, 795, 756, 1136]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 13, 19, 17, 12, 13, 9, 9, 19]
	Time taken saving stuff: 0.03s

=== episode:1284 Env-steps-taken:64896
 	picked: 59 |actions: {0: 523, 1: 513, 2: 764, 3: 774, 4: 759, 5: 433, 6: 576, 7: 538, 8: 436}
episode: 1284/2000 -> reward: 84.61979166666663, steps:5316, time-taken: 3.77min, time-elasped: 5127.03min
-> berries picked: 59 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9552 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [975, 1465, 1333, 1119, 1062, 917, 791, 754, 1136]
	| approx positives in sample 512: 159
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 21, 20, 18, 18, 15, 11, 13, 25]
	Time taken saving stuff: 0.09s

=== episode:1285 Env-steps-taken:74400
 	picked: 99 |actions: {0: 565, 1: 682, 2: 563, 3: 573, 4: 615, 5: 606, 6: 671, 7: 569, 8: 486}
episode: 1285/2000 -> reward: 132.32812499999986, steps:5330, time-taken: 3.78min, time-elasped: 5130.82min
-> berries picked: 99 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9576 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [980, 1475, 1330, 1122, 1071, 917, 791, 754, 1136]
	| approx positives in sample 512: 165
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 19, 20, 13, 17, 12, 13, 15, 34]
	Time taken saving stuff: 0.10s

=== episode:1286 Env-steps-taken:72480
 	picked: 86 |actions: {0: 566, 1: 617, 2: 653, 3: 537, 4: 557, 5: 581, 6: 693, 7: 835, 8: 449}
episode: 1286/2000 -> reward: 123.07291666666653, steps:5488, time-taken: 3.49min, time-elasped: 5134.32min
-> berries picked: 86 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9577 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [980, 1478, 1333, 1122, 1065, 914, 792, 756, 1137]
	| approx positives in sample 512: 151
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 20, 12, 21, 14, 12, 15, 12, 24]
	Time taken saving stuff: 0.02s

=== episode:1287 Env-steps-taken:70656
 	picked: 84 |actions: {0: 529, 1: 473, 2: 530, 3: 563, 4: 764, 5: 588, 6: 711, 7: 597, 8: 459}
episode: 1287/2000 -> reward: 113.68749999999989, steps:5214, time-taken: 3.59min, time-elasped: 5137.91min
-> berries picked: 84 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9584 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [973, 1472, 1335, 1124, 1068, 915, 799, 763, 1135]
	| approx positives in sample 512: 152
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 19, 19, 10, 24, 21, 4, 12, 28]
	Time taken saving stuff: 0.01s

=== episode:1288 Env-steps-taken:61632
 	picked: 52 |actions: {0: 371, 1: 263, 2: 269, 3: 309, 4: 327, 5: 333, 6: 282, 7: 387, 8: 352}
episode: 1288/2000 -> reward: 68.52083333333337, steps:2893, time-taken: 2.27min, time-elasped: 5140.18min
-> berries picked: 52 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9590 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [973, 1474, 1336, 1129, 1069, 914, 798, 765, 1132]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [23, 13, 14, 20, 18, 8, 10, 18, 20]
	Time taken saving stuff: 0.03s

=== episode:1289 Env-steps-taken:66336
 	picked: 65 |actions: {0: 502, 1: 482, 2: 665, 3: 809, 4: 809, 5: 721, 6: 722, 7: 801, 8: 415}
episode: 1289/2000 -> reward: 91.77604166666659, steps:5926, time-taken: 3.80min, time-elasped: 5143.99min
-> berries picked: 65 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9570 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [963, 1465, 1340, 1125, 1062, 919, 799, 766, 1131]
	| approx positives in sample 512: 145
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 26, 17, 23, 14, 14, 10, 16, 16]
	Time taken saving stuff: 0.03s

=== episode:1290 Env-steps-taken:79104
 	picked: 119 |actions: {0: 665, 1: 738, 2: 688, 3: 764, 4: 971, 5: 638, 6: 752, 7: 761, 8: 440}
episode: 1290/2000 -> reward: 155.6822916666667, steps:6417, time-taken: 4.29min, time-elasped: 5148.29min
-> berries picked: 119 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9598 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [961, 1473, 1339, 1135, 1068, 925, 799, 769, 1129]
	| approx positives in sample 512: 139
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 17, 18, 16, 12, 12, 16, 9, 22]
	Time taken saving stuff: 0.06s

=== episode:129 Env-steps-taken:78048
 	picked: 113 |actions: {0: 339, 1: 380, 2: 277, 3: 603, 4: 362, 5: 318, 6: 528, 7: 338, 8: 548}

==================================================
eval-episode: 1290 -> reward: 149.64062500000003, steps: 3693.0, wall-time: 60.39s
-> berries picked: 113 of 800 | patches-visited: [1, 8] | juice left:-0.00
==================================================


=== episode:1291 Env-steps-taken:78720
 	picked: 115 |actions: {0: 636, 1: 744, 2: 668, 3: 819, 4: 821, 5: 822, 6: 976, 7: 835, 8: 509}
episode: 1291/2000 -> reward: 153.91145833333337, steps:6830, time-taken: 4.26min, time-elasped: 5153.56min
-> berries picked: 115 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9604 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [954, 1467, 1340, 1136, 1065, 941, 799, 773, 1129]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 24, 16, 18, 17, 13, 15, 11, 25]
	Time taken saving stuff: 0.01s

=== episode:1292 Env-steps-taken:65952
 	picked: 69 |actions: {0: 486, 1: 425, 2: 440, 3: 485, 4: 434, 5: 480, 6: 610, 7: 478, 8: 384}
episode: 1292/2000 -> reward: 90.04687499999996, steps:4222, time-taken: 2.87min, time-elasped: 5156.44min
-> berries picked: 69 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9616 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [956, 1466, 1338, 1134, 1068, 947, 800, 777, 1130]
	| approx positives in sample 512: 157
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 23, 20, 19, 14, 13, 18, 13, 19]
	Time taken saving stuff: 0.10s

=== episode:1293 Env-steps-taken:68832
 	picked: 85 |actions: {0: 522, 1: 526, 2: 685, 3: 665, 4: 717, 5: 649, 6: 814, 7: 799, 8: 406}
episode: 1293/2000 -> reward: 104.1302083333332, steps:5783, time-taken: 3.55min, time-elasped: 5159.99min
-> berries picked: 85 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9628 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [953, 1469, 1342, 1138, 1071, 947, 803, 773, 1132]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 19, 21, 11, 16, 12, 15, 7, 19]
	Time taken saving stuff: 0.02s

=== episode:1294 Env-steps-taken:75456
 	picked: 114 |actions: {0: 595, 1: 760, 2: 797, 3: 731, 4: 693, 5: 613, 6: 809, 7: 778, 8: 344}
episode: 1294/2000 -> reward: 136.64062499999991, steps:6120, time-taken: 4.23min, time-elasped: 5164.23min
-> berries picked: 114 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9651 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [955, 1475, 1345, 1138, 1070, 948, 809, 781, 1130]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 19, 16, 22, 11, 13, 10, 9, 22]
	Time taken saving stuff: 0.10s

=== episode:1295 Env-steps-taken:64128
 	picked: 59 |actions: {0: 409, 1: 523, 2: 482, 3: 538, 4: 347, 5: 385, 6: 396, 7: 343, 8: 256}
episode: 1295/2000 -> reward: 81.11979166666664, steps:3679, time-taken: 2.92min, time-elasped: 5167.15min
-> berries picked: 59 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9661 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [957, 1479, 1349, 1138, 1071, 952, 803, 780, 1132]
	| approx positives in sample 512: 150
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 19, 17, 20, 9, 21, 9, 12, 21]
	Time taken saving stuff: 0.09s

=== episode:1296 Env-steps-taken:66912
 	picked: 70 |actions: {0: 526, 1: 379, 2: 595, 3: 644, 4: 629, 5: 530, 6: 518, 7: 536, 8: 452}
episode: 1296/2000 -> reward: 94.48958333333324, steps:4809, time-taken: 3.39min, time-elasped: 5170.55min
-> berries picked: 70 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9654 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [961, 1477, 1349, 1140, 1062, 954, 805, 777, 1129]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 17, 20, 19, 13, 15, 11, 12, 26]
	Time taken saving stuff: 0.03s

=== episode:1297 Env-steps-taken:61632
 	picked: 47 |actions: {0: 180, 1: 242, 2: 249, 3: 380, 4: 517, 5: 315, 6: 414, 7: 304, 8: 206}
episode: 1297/2000 -> reward: 68.30729166666669, steps:2807, time-taken: 2.35min, time-elasped: 5172.90min
-> berries picked: 47 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9654 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [960, 1475, 1349, 1145, 1063, 954, 805, 774, 1129]
	| approx positives in sample 512: 157
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 10, 26, 25, 22, 15, 14, 12, 20]
	Time taken saving stuff: 0.04s

=== episode:1298 Env-steps-taken:74496
 	picked: 101 |actions: {0: 590, 1: 656, 2: 646, 3: 631, 4: 589, 5: 572, 6: 752, 7: 721, 8: 326}
episode: 1298/2000 -> reward: 132.71354166666652, steps:5483, time-taken: 3.72min, time-elasped: 5176.62min
-> berries picked: 101 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9670 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [960, 1480, 1347, 1140, 1070, 956, 811, 778, 1128]
	| approx positives in sample 512: 139
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 22, 20, 19, 13, 11, 10, 8, 22]
	Time taken saving stuff: 0.01s

=== episode:1299 Env-steps-taken:66240
 	picked: 68 |actions: {0: 481, 1: 740, 2: 669, 3: 593, 4: 979, 5: 533, 6: 676, 7: 597, 8: 472}
episode: 1299/2000 -> reward: 91.10416666666661, steps:5740, time-taken: 3.75min, time-elasped: 5180.37min
-> berries picked: 68 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9658 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [958, 1485, 1356, 1135, 1061, 947, 814, 774, 1128]
	| approx positives in sample 512: 158
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [26, 31, 10, 17, 17, 16, 14, 10, 17]
	Time taken saving stuff: 0.01s

=== episode:1300 Env-steps-taken:68832
 	picked: 80 |actions: {0: 460, 1: 689, 2: 464, 3: 715, 4: 597, 5: 480, 6: 523, 7: 674, 8: 337}
episode: 1300/2000 -> reward: 104.41666666666657, steps:4939, time-taken: 3.90min, time-elasped: 5184.27min
-> berries picked: 80 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9650 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [958, 1482, 1354, 1131, 1062, 948, 812, 774, 1129]
	| approx positives in sample 512: 145
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 26, 14, 17, 18, 17, 11, 9, 22]
	Time taken saving stuff: 0.11s

=== episode:130 Env-steps-taken:59712
 	picked: 46 |actions: {0: 47, 1: 147, 2: 73, 3: 202, 4: 169, 5: 135, 6: 283, 7: 359, 8: 143}

==================================================
eval-episode: 1300 -> reward: 58.86458333333337, steps: 1558.0, wall-time: 47.22s
-> berries picked: 46 of 800 | patches-visited: [1, 4] | juice left:-0.00
==================================================


=== episode:1301 Env-steps-taken:68352
 	picked: 73 |actions: {0: 479, 1: 483, 2: 609, 3: 447, 4: 555, 5: 434, 6: 570, 7: 543, 8: 400}
episode: 1301/2000 -> reward: 102.81770833333324, steps:4520, time-taken: 3.62min, time-elasped: 5188.69min
-> berries picked: 73 of 800 | patches-visited: [0, 1, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9663 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [964, 1480, 1354, 1132, 1065, 947, 814, 777, 1130]
	| approx positives in sample 512: 150
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 21, 12, 22, 20, 19, 8, 15, 25]
	Time taken saving stuff: 0.01s

=== episode:1302 Env-steps-taken:69792
 	picked: 76 |actions: {0: 434, 1: 590, 2: 447, 3: 570, 4: 518, 5: 409, 6: 619, 7: 660, 8: 280}
episode: 1302/2000 -> reward: 109.64583333333324, steps:4527, time-taken: 3.38min, time-elasped: 5192.08min
-> berries picked: 76 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9689 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [967, 1489, 1358, 1134, 1075, 947, 809, 779, 1131]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 18, 19, 15, 16, 13, 13, 5, 16]
	Time taken saving stuff: 0.01s

=== episode:1303 Env-steps-taken:72384
 	picked: 86 |actions: {0: 383, 1: 544, 2: 720, 3: 731, 4: 639, 5: 601, 6: 537, 7: 675, 8: 307}
episode: 1303/2000 -> reward: 122.5729166666665, steps:5137, time-taken: 4.18min, time-elasped: 5196.26min
-> berries picked: 86 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9707 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [962, 1490, 1365, 1146, 1073, 956, 809, 775, 1131]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 16, 21, 13, 14, 14, 11, 12, 28]
	Time taken saving stuff: 0.01s

=== episode:1304 Env-steps-taken:67200
 	picked: 79 |actions: {0: 617, 1: 751, 2: 824, 3: 728, 4: 681, 5: 497, 6: 718, 7: 655, 8: 397}
episode: 1304/2000 -> reward: 95.53124999999989, steps:5868, time-taken: 4.21min, time-elasped: 5200.47min
-> berries picked: 79 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9703 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [966, 1492, 1365, 1142, 1072, 958, 806, 772, 1130]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 16, 16, 15, 17, 15, 14, 6, 26]
	Time taken saving stuff: 0.02s

=== episode:1305 Env-steps-taken:71424
 	picked: 82 |actions: {0: 399, 1: 612, 2: 449, 3: 500, 4: 468, 5: 524, 6: 518, 7: 503, 8: 260}
episode: 1305/2000 -> reward: 115.85937499999986, steps:4233, time-taken: 3.57min, time-elasped: 5204.05min
-> berries picked: 82 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9716 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [968, 1496, 1364, 1149, 1073, 960, 806, 772, 1128]
	| approx positives in sample 512: 155
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 22, 22, 22, 12, 16, 15, 14, 16]
	Time taken saving stuff: 0.01s

=== episode:1306 Env-steps-taken:75456
 	picked: 101 |actions: {0: 523, 1: 695, 2: 570, 3: 674, 4: 783, 5: 595, 6: 771, 7: 649, 8: 417}
episode: 1306/2000 -> reward: 135.82812499999994, steps:5677, time-taken: 4.14min, time-elasped: 5208.19min
-> berries picked: 101 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9713 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [962, 1503, 1363, 1139, 1080, 954, 813, 770, 1129]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 25, 16, 24, 8, 9, 13, 10, 19]
	Time taken saving stuff: 0.08s

=== episode:1307 Env-steps-taken:62784
 	picked: 53 |actions: {0: 233, 1: 329, 2: 307, 3: 357, 4: 337, 5: 296, 6: 304, 7: 355, 8: 174}
episode: 1307/2000 -> reward: 73.96354166666669, steps:2692, time-taken: 2.45min, time-elasped: 5210.65min
-> berries picked: 53 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9724 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [964, 1501, 1363, 1141, 1081, 956, 816, 773, 1129]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 21, 15, 12, 11, 11, 11, 13, 29]
	Time taken saving stuff: 0.01s

=== episode:1308 Env-steps-taken:79872
 	picked: 120 |actions: {0: 721, 1: 790, 2: 959, 3: 823, 4: 698, 5: 626, 6: 793, 7: 936, 8: 409}
episode: 1308/2000 -> reward: 159.62500000000009, steps:6755, time-taken: 5.06min, time-elasped: 5215.71min
-> berries picked: 120 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9747 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [968, 1507, 1371, 1140, 1082, 947, 818, 783, 1131]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 14, 14, 15, 15, 15, 13, 15, 26]
	Time taken saving stuff: 0.01s

=== episode:1309 Env-steps-taken:75168
 	picked: 97 |actions: {0: 397, 1: 724, 2: 615, 3: 679, 4: 725, 5: 551, 6: 533, 7: 740, 8: 326}
episode: 1309/2000 -> reward: 136.4427083333332, steps:5290, time-taken: 4.11min, time-elasped: 5219.82min
-> berries picked: 97 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9752 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [969, 1511, 1375, 1141, 1082, 948, 813, 781, 1132]
	| approx positives in sample 512: 160
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 28, 19, 13, 15, 11, 10, 15, 32]
	Time taken saving stuff: 0.09s

=== episode:1310 Env-steps-taken:66240
 	picked: 73 |actions: {0: 468, 1: 490, 2: 672, 3: 716, 4: 590, 5: 478, 6: 563, 7: 669, 8: 293}
episode: 1310/2000 -> reward: 90.81770833333329, steps:4939, time-taken: 3.58min, time-elasped: 5223.41min
-> berries picked: 73 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9755 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [969, 1511, 1384, 1134, 1083, 953, 811, 778, 1132]
	| approx positives in sample 512: 152
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 31, 13, 21, 10, 17, 13, 12, 22]
	Time taken saving stuff: 0.07s

=== episode:131 Env-steps-taken:98880
 	picked: 198 |actions: {0: 655, 1: 857, 2: 335, 3: 975, 4: 693, 5: 660, 6: 812, 7: 1094, 8: 374}

==================================================
eval-episode: 1310 -> reward: 253.77083333333417, steps: 6455.0, wall-time: 96.58s
-> berries picked: 198 of 800 | patches-visited: [1, 2, 5] | juice left:-0.00
==================================================


=== episode:1311 Env-steps-taken:81216
 	picked: 125 |actions: {0: 764, 1: 778, 2: 1027, 3: 851, 4: 806, 5: 605, 6: 760, 7: 822, 8: 369}
episode: 1311/2000 -> reward: 166.3385416666668, steps:6782, time-taken: 4.95min, time-elasped: 5229.98min
-> berries picked: 125 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9763 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [973, 1512, 1388, 1130, 1080, 953, 816, 775, 1136]
	| approx positives in sample 512: 143
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 19, 28, 13, 18, 12, 11, 10, 19]
	Time taken saving stuff: 0.01s

=== episode:1312 Env-steps-taken:77472
 	picked: 108 |actions: {0: 588, 1: 700, 2: 731, 3: 590, 4: 726, 5: 531, 6: 733, 7: 696, 8: 371}
episode: 1312/2000 -> reward: 145.92708333333326, steps:5666, time-taken: 4.50min, time-elasped: 5234.49min
-> berries picked: 108 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9772 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [980, 1511, 1386, 1133, 1084, 945, 818, 776, 1139]
	| approx positives in sample 512: 150
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 19, 26, 22, 12, 17, 7, 13, 23]
	Time taken saving stuff: 0.04s

=== episode:1313 Env-steps-taken:65856
 	picked: 71 |actions: {0: 594, 1: 569, 2: 518, 3: 604, 4: 758, 5: 571, 6: 820, 7: 714, 8: 292}
episode: 1313/2000 -> reward: 88.93229166666659, steps:5440, time-taken: 3.95min, time-elasped: 5238.44min
-> berries picked: 71 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9773 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [986, 1507, 1382, 1136, 1082, 945, 820, 776, 1139]
	| approx positives in sample 512: 155
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 28, 15, 21, 19, 13, 14, 8, 23]
	Time taken saving stuff: 0.03s

=== episode:1314 Env-steps-taken:65856
 	picked: 76 |actions: {0: 440, 1: 476, 2: 525, 3: 592, 4: 575, 5: 466, 6: 691, 7: 556, 8: 309}
episode: 1314/2000 -> reward: 89.14583333333327, steps:4630, time-taken: 3.71min, time-elasped: 5242.15min
-> berries picked: 76 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9785 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [990, 1503, 1384, 1140, 1083, 946, 817, 781, 1141]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 27, 13, 14, 18, 14, 6, 12, 23]
	Time taken saving stuff: 0.03s

=== episode:1315 Env-steps-taken:65088
 	picked: 65 |actions: {0: 313, 1: 418, 2: 501, 3: 555, 4: 542, 5: 410, 6: 488, 7: 402, 8: 248}
episode: 1315/2000 -> reward: 85.77604166666663, steps:3877, time-taken: 3.27min, time-elasped: 5245.43min
-> berries picked: 65 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9793 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [988, 1499, 1393, 1141, 1088, 946, 814, 783, 1141]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 32, 15, 21, 18, 11, 7, 9, 17]
	Time taken saving stuff: 0.03s

=== episode:1316 Env-steps-taken:68928
 	picked: 77 |actions: {0: 514, 1: 572, 2: 586, 3: 801, 4: 525, 5: 522, 6: 740, 7: 644, 8: 435}
episode: 1316/2000 -> reward: 104.2031249999999, steps:5339, time-taken: 4.40min, time-elasped: 5249.84min
-> berries picked: 77 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9769 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [982, 1489, 1391, 1133, 1088, 947, 818, 779, 1142]
	| approx positives in sample 512: 149
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 26, 16, 18, 13, 11, 13, 14, 26]
	Time taken saving stuff: 0.01s

=== episode:1317 Env-steps-taken:79200
 	picked: 111 |actions: {0: 633, 1: 692, 2: 738, 3: 805, 4: 792, 5: 794, 6: 929, 7: 779, 8: 434}
episode: 1317/2000 -> reward: 156.640625, steps:6596, time-taken: 5.04min, time-elasped: 5254.88min
-> berries picked: 111 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9771 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [984, 1488, 1391, 1126, 1080, 952, 826, 782, 1142]
	| approx positives in sample 512: 150
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 20, 15, 19, 15, 12, 10, 13, 25]
	Time taken saving stuff: 0.03s

=== episode:1318 Env-steps-taken:70752
 	picked: 89 |actions: {0: 550, 1: 705, 2: 689, 3: 756, 4: 673, 5: 477, 6: 674, 7: 604, 8: 294}
episode: 1318/2000 -> reward: 113.51562499999986, steps:5422, time-taken: 4.30min, time-elasped: 5259.18min
-> berries picked: 89 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9765 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [988, 1483, 1394, 1118, 1077, 956, 825, 781, 1143]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 12, 23, 10, 19, 15, 11, 13, 20]
	Time taken saving stuff: 0.03s

=== episode:1319 Env-steps-taken:75168
 	picked: 111 |actions: {0: 643, 1: 776, 2: 584, 3: 718, 4: 685, 5: 667, 6: 859, 7: 655, 8: 422}
episode: 1319/2000 -> reward: 135.6406249999999, steps:6009, time-taken: 5.24min, time-elasped: 5264.43min
-> berries picked: 111 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9770 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [987, 1485, 1390, 1119, 1076, 965, 827, 779, 1142]
	| approx positives in sample 512: 146
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 17, 17, 25, 15, 14, 17, 12, 17]
	Time taken saving stuff: 0.07s

=== episode:1320 Env-steps-taken:70560
 	picked: 80 |actions: {0: 604, 1: 540, 2: 569, 3: 749, 4: 780, 5: 509, 6: 690, 7: 550, 8: 356}
episode: 1320/2000 -> reward: 113.41666666666654, steps:5347, time-taken: 3.74min, time-elasped: 5268.17min
-> berries picked: 80 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9768 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [992, 1478, 1393, 1118, 1072, 967, 824, 782, 1142]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 22, 21, 20, 12, 13, 16, 14, 17]
	Time taken saving stuff: 0.14s

=== episode:132 Env-steps-taken:64992
 	picked: 63 |actions: {0: 186, 1: 645, 2: 260, 3: 75, 4: 505, 5: 306, 6: 340, 7: 316, 8: 153}

==================================================
eval-episode: 1320 -> reward: 84.89062499999996, steps: 2786.0, wall-time: 54.37s
-> berries picked: 63 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:1321 Env-steps-taken:73440
 	picked: 90 |actions: {0: 728, 1: 567, 2: 733, 3: 438, 4: 613, 5: 673, 6: 670, 7: 637, 8: 300}
episode: 1321/2000 -> reward: 127.84374999999987, steps:5359, time-taken: 3.82min, time-elasped: 5272.90min
-> berries picked: 90 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9747 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [989, 1472, 1392, 1116, 1063, 974, 822, 781, 1138]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 15, 20, 11, 9, 9, 12, 11, 28]
	Time taken saving stuff: 0.00s

=== episode:1322 Env-steps-taken:75360
 	picked: 96 |actions: {0: 700, 1: 588, 2: 915, 3: 654, 4: 719, 5: 658, 6: 773, 7: 746, 8: 430}
episode: 1322/2000 -> reward: 137.49999999999997, steps:6183, time-taken: 3.87min, time-elasped: 5276.78min
-> berries picked: 96 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9739 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [991, 1473, 1390, 1110, 1066, 973, 821, 780, 1135]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 14, 15, 12, 9, 16, 13, 9, 24]
	Time taken saving stuff: 0.01s

=== episode:1323 Env-steps-taken:71616
 	picked: 86 |actions: {0: 530, 1: 638, 2: 734, 3: 518, 4: 489, 5: 460, 6: 726, 7: 526, 8: 299}
episode: 1323/2000 -> reward: 116.6302083333332, steps:4920, time-taken: 3.30min, time-elasped: 5280.08min
-> berries picked: 86 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9737 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [997, 1476, 1394, 1107, 1061, 967, 820, 779, 1136]
	| approx positives in sample 512: 150
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 18, 12, 15, 19, 15, 15, 12, 27]
	Time taken saving stuff: 0.01s

=== episode:1324 Env-steps-taken:64032
 	picked: 73 |actions: {0: 476, 1: 432, 2: 608, 3: 505, 4: 666, 5: 525, 6: 957, 7: 676, 8: 375}
episode: 1324/2000 -> reward: 79.31770833333331, steps:5220, time-taken: 3.26min, time-elasped: 5283.34min
-> berries picked: 73 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9743 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [997, 1480, 1392, 1107, 1060, 970, 825, 779, 1133]
	| approx positives in sample 512: 151
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 19, 19, 11, 23, 14, 16, 9, 23]
	Time taken saving stuff: 0.08s

=== episode:1325 Env-steps-taken:67872
 	picked: 76 |actions: {0: 422, 1: 468, 2: 571, 3: 480, 4: 506, 5: 572, 6: 513, 7: 513, 8: 339}
episode: 1325/2000 -> reward: 99.64583333333324, steps:4384, time-taken: 3.11min, time-elasped: 5286.46min
-> berries picked: 76 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9757 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1001, 1478, 1390, 1113, 1062, 969, 828, 779, 1137]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 23, 11, 25, 11, 7, 12, 12, 18]
	Time taken saving stuff: 0.10s

=== episode:1326 Env-steps-taken:69600
 	picked: 88 |actions: {0: 664, 1: 573, 2: 837, 3: 729, 4: 635, 5: 552, 6: 821, 7: 578, 8: 317}
episode: 1326/2000 -> reward: 107.57291666666656, steps:5706, time-taken: 3.67min, time-elasped: 5290.14min
-> berries picked: 88 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9759 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [995, 1477, 1394, 1113, 1067, 968, 826, 781, 1138]
	| approx positives in sample 512: 155
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 22, 27, 14, 20, 20, 11, 4, 20]
	Time taken saving stuff: 0.00s

=== episode:1327 Env-steps-taken:71424
 	picked: 85 |actions: {0: 706, 1: 611, 2: 704, 3: 514, 4: 756, 5: 499, 6: 687, 7: 579, 8: 373}
episode: 1327/2000 -> reward: 117.63020833333317, steps:5429, time-taken: 3.70min, time-elasped: 5293.84min
-> berries picked: 85 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9769 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [997, 1475, 1394, 1114, 1072, 962, 832, 782, 1141]
	| approx positives in sample 512: 151
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 24, 15, 12, 14, 22, 9, 12, 25]
	Time taken saving stuff: 0.08s

=== episode:1328 Env-steps-taken:72384
 	picked: 96 |actions: {0: 722, 1: 637, 2: 781, 3: 553, 4: 794, 5: 582, 6: 748, 7: 593, 8: 394}
episode: 1328/2000 -> reward: 121.99999999999982, steps:5804, time-taken: 4.14min, time-elasped: 5297.98min
-> berries picked: 96 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9782 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [998, 1483, 1396, 1118, 1066, 962, 830, 786, 1143]
	| approx positives in sample 512: 156
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [24, 27, 14, 15, 21, 11, 10, 8, 26]
	Time taken saving stuff: 0.02s

=== episode:1329 Env-steps-taken:63648
 	picked: 60 |actions: {0: 725, 1: 642, 2: 781, 3: 574, 4: 714, 5: 439, 6: 702, 7: 698, 8: 468}
episode: 1329/2000 -> reward: 78.0625, steps:5743, time-taken: 4.03min, time-elasped: 5302.01min
-> berries picked: 60 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9770 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [997, 1480, 1396, 1116, 1071, 959, 827, 783, 1141]
	| approx positives in sample 512: 156
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 18, 28, 19, 18, 14, 9, 15, 20]
	Time taken saving stuff: 0.01s

=== episode:1330 Env-steps-taken:65376
 	picked: 68 |actions: {0: 610, 1: 482, 2: 488, 3: 529, 4: 664, 5: 535, 6: 604, 7: 461, 8: 361}
episode: 1330/2000 -> reward: 86.60416666666661, steps:4734, time-taken: 3.58min, time-elasped: 5305.60min
-> berries picked: 68 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9786 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1003, 1482, 1397, 1117, 1075, 955, 828, 788, 1141]
	| approx positives in sample 512: 149
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 16, 20, 15, 16, 13, 11, 14, 28]
	Time taken saving stuff: 0.09s

=== episode:133 Env-steps-taken:67488
 	picked: 69 |actions: {0: 853, 1: 244, 2: 240, 3: 423, 4: 260, 5: 62, 6: 254, 7: 115, 8: 276}

==================================================
eval-episode: 1330 -> reward: 98.54687499999991, steps: 2727.0, wall-time: 61.85s
-> berries picked: 69 of 800 | patches-visited: [1, 4, 6] | juice left:-0.00
==================================================


=== episode:1331 Env-steps-taken:64512
 	picked: 62 |actions: {0: 388, 1: 330, 2: 371, 3: 339, 4: 508, 5: 377, 6: 572, 7: 435, 8: 236}
episode: 1331/2000 -> reward: 82.94791666666666, steps:3556, time-taken: 2.51min, time-elasped: 5309.14min
-> berries picked: 62 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9806 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1005, 1483, 1398, 1122, 1074, 958, 831, 792, 1143]
	| approx positives in sample 512: 151
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 23, 21, 13, 18, 12, 16, 9, 22]
	Time taken saving stuff: 0.00s

=== episode:1332 Env-steps-taken:67104
 	picked: 72 |actions: {0: 744, 1: 537, 2: 683, 3: 584, 4: 533, 5: 567, 6: 695, 7: 852, 8: 387}
episode: 1332/2000 -> reward: 95.87499999999991, steps:5582, time-taken: 3.62min, time-elasped: 5312.77min
-> berries picked: 72 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9811 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1008, 1486, 1399, 1124, 1072, 956, 834, 789, 1143]
	| approx positives in sample 512: 157
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 31, 24, 12, 17, 12, 12, 12, 18]
	Time taken saving stuff: 0.09s

=== episode:1333 Env-steps-taken:70080
 	picked: 84 |actions: {0: 712, 1: 620, 2: 684, 3: 583, 4: 534, 5: 453, 6: 639, 7: 765, 8: 392}
episode: 1333/2000 -> reward: 110.68749999999986, steps:5382, time-taken: 4.05min, time-elasped: 5316.82min
-> berries picked: 84 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9819 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1015, 1495, 1396, 1123, 1070, 956, 834, 789, 1141]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 21, 13, 14, 14, 15, 15, 9, 27]
	Time taken saving stuff: 0.01s

=== episode:1334 Env-steps-taken:66432
 	picked: 69 |actions: {0: 543, 1: 447, 2: 425, 3: 391, 4: 389, 5: 340, 6: 637, 7: 621, 8: 252}
episode: 1334/2000 -> reward: 92.54687499999996, steps:4045, time-taken: 2.82min, time-elasped: 5319.64min
-> berries picked: 69 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9836 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1022, 1495, 1401, 1122, 1068, 958, 836, 791, 1143]
	| approx positives in sample 512: 162
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 13, 21, 16, 18, 15, 17, 17, 25]
	Time taken saving stuff: 0.09s

=== episode:1335 Env-steps-taken:65376
 	picked: 68 |actions: {0: 627, 1: 500, 2: 684, 3: 469, 4: 773, 5: 563, 6: 661, 7: 684, 8: 381}
episode: 1335/2000 -> reward: 87.10416666666663, steps:5342, time-taken: 3.65min, time-elasped: 5323.29min
-> berries picked: 68 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9828 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1009, 1493, 1405, 1123, 1068, 961, 836, 791, 1142]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 18, 20, 18, 14, 17, 12, 10, 11]
	Time taken saving stuff: 0.11s

=== episode:1336 Env-steps-taken:67776
 	picked: 67 |actions: {0: 436, 1: 449, 2: 281, 3: 467, 4: 396, 5: 293, 6: 343, 7: 415, 8: 269}
episode: 1336/2000 -> reward: 98.2760416666666, steps:3349, time-taken: 2.68min, time-elasped: 5325.97min
-> berries picked: 67 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9837 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1014, 1490, 1403, 1124, 1075, 955, 837, 794, 1145]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 21, 21, 14, 13, 13, 15, 7, 18]
	Time taken saving stuff: 0.10s

=== episode:1337 Env-steps-taken:72864
 	picked: 91 |actions: {0: 575, 1: 694, 2: 628, 3: 579, 4: 582, 5: 521, 6: 998, 7: 677, 8: 394}
episode: 1337/2000 -> reward: 124.78645833333314, steps:5648, time-taken: 4.03min, time-elasped: 5330.01min
-> berries picked: 91 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9858 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1013, 1496, 1407, 1121, 1080, 960, 842, 792, 1147]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 16, 18, 15, 19, 10, 14, 11, 18]
	Time taken saving stuff: 0.02s

=== episode:1338 Env-steps-taken:66144
 	picked: 69 |actions: {0: 506, 1: 653, 2: 661, 3: 779, 4: 888, 5: 625, 6: 713, 7: 602, 8: 371}
episode: 1338/2000 -> reward: 90.54687499999993, steps:5798, time-taken: 3.99min, time-elasped: 5334.01min
-> berries picked: 69 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9847 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1007, 1495, 1410, 1122, 1079, 948, 846, 792, 1148]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 19, 27, 10, 13, 12, 8, 8, 26]
	Time taken saving stuff: 0.10s

=== episode:1339 Env-steps-taken:64224
 	picked: 71 |actions: {0: 482, 1: 458, 2: 466, 3: 540, 4: 563, 5: 727, 6: 601, 7: 687, 8: 407}
episode: 1339/2000 -> reward: 80.43229166666667, steps:4931, time-taken: 3.34min, time-elasped: 5337.36min
-> berries picked: 71 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9865 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1007, 1493, 1413, 1125, 1083, 951, 853, 791, 1149]
	| approx positives in sample 512: 154
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 25, 22, 9, 21, 18, 15, 9, 19]
	Time taken saving stuff: 0.09s

=== episode:1340 Env-steps-taken:65184
 	picked: 59 |actions: {0: 462, 1: 443, 2: 466, 3: 493, 4: 441, 5: 466, 6: 381, 7: 554, 8: 309}
episode: 1340/2000 -> reward: 86.61979166666663, steps:4015, time-taken: 2.92min, time-elasped: 5340.28min
-> berries picked: 59 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9883 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1011, 1494, 1414, 1125, 1089, 955, 851, 797, 1147]
	| approx positives in sample 512: 162
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 33, 13, 22, 18, 19, 14, 8, 19]
	Time taken saving stuff: 0.17s

=== episode:134 Env-steps-taken:91488
 	picked: 167 |actions: {0: 665, 1: 1227, 2: 204, 3: 890, 4: 338, 5: 919, 6: 641, 7: 1081, 8: 444}

==================================================
eval-episode: 1340 -> reward: 217.93229166666717, steps: 6409.0, wall-time: 82.65s
-> berries picked: 167 of 800 | patches-visited: [1, 2, 5] | juice left:-0.00
==================================================


=== episode:1341 Env-steps-taken:69888
 	picked: 82 |actions: {0: 581, 1: 426, 2: 701, 3: 609, 4: 677, 5: 598, 6: 648, 7: 686, 8: 386}
episode: 1341/2000 -> reward: 108.53124999999987, steps:5312, time-taken: 3.90min, time-elasped: 5345.57min
-> berries picked: 82 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9876 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1011, 1493, 1411, 1117, 1089, 953, 854, 798, 1150]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 26, 19, 14, 14, 17, 13, 10, 17]
	Time taken saving stuff: 0.01s

=== episode:1342 Env-steps-taken:65856
 	picked: 62 |actions: {0: 379, 1: 346, 2: 484, 3: 427, 4: 539, 5: 422, 6: 593, 7: 454, 8: 270}
episode: 1342/2000 -> reward: 87.50520833333329, steps:3914, time-taken: 2.88min, time-elasped: 5348.45min
-> berries picked: 62 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9889 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1011, 1492, 1413, 1115, 1099, 957, 851, 801, 1150]
	| approx positives in sample 512: 149
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 27, 21, 11, 23, 11, 16, 12, 18]
	Time taken saving stuff: 0.01s

=== episode:1343 Env-steps-taken:65664
 	picked: 67 |actions: {0: 449, 1: 451, 2: 715, 3: 611, 4: 579, 5: 352, 6: 493, 7: 722, 8: 329}
episode: 1343/2000 -> reward: 88.66145833333327, steps:4701, time-taken: 3.16min, time-elasped: 5351.62min
-> berries picked: 67 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9889 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1015, 1492, 1417, 1114, 1098, 956, 847, 802, 1148]
	| approx positives in sample 512: 156
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 22, 17, 13, 21, 18, 13, 14, 25]
	Time taken saving stuff: 0.03s

=== episode:1344 Env-steps-taken:71136
 	picked: 85 |actions: {0: 562, 1: 695, 2: 760, 3: 639, 4: 775, 5: 509, 6: 880, 7: 722, 8: 376}
episode: 1344/2000 -> reward: 115.24479166666653, steps:5918, time-taken: 4.13min, time-elasped: 5355.76min
-> berries picked: 85 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9905 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1020, 1490, 1420, 1120, 1102, 957, 850, 799, 1147]
	| approx positives in sample 512: 143
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 22, 15, 19, 16, 14, 9, 13, 21]
	Time taken saving stuff: 0.01s

=== episode:1345 Env-steps-taken:63552
 	picked: 53 |actions: {0: 574, 1: 518, 2: 653, 3: 526, 4: 781, 5: 516, 6: 729, 7: 727, 8: 346}
episode: 1345/2000 -> reward: 77.96354166666666, steps:5370, time-taken: 3.71min, time-elasped: 5359.47min
-> berries picked: 53 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9893 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1018, 1488, 1422, 1111, 1104, 955, 848, 798, 1149]
	| approx positives in sample 512: 160
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 23, 22, 14, 14, 12, 17, 13, 28]
	Time taken saving stuff: 0.01s

=== episode:1346 Env-steps-taken:67200
 	picked: 65 |actions: {0: 524, 1: 406, 2: 588, 3: 585, 4: 628, 5: 404, 6: 662, 7: 611, 8: 290}
episode: 1346/2000 -> reward: 97.27604166666661, steps:4698, time-taken: 2.91min, time-elasped: 5362.38min
-> berries picked: 65 of 800 | patches-visited: [0, 2, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9880 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1015, 1489, 1417, 1115, 1104, 951, 836, 803, 1150]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 21, 16, 24, 17, 12, 10, 10, 18]
	Time taken saving stuff: 0.00s

=== episode:1347 Env-steps-taken:65760
 	picked: 74 |actions: {0: 591, 1: 698, 2: 565, 3: 651, 4: 710, 5: 462, 6: 799, 7: 731, 8: 343}
episode: 1347/2000 -> reward: 88.26041666666656, steps:5550, time-taken: 3.27min, time-elasped: 5365.65min
-> berries picked: 74 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9879 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1020, 1487, 1421, 1115, 1104, 947, 833, 802, 1150]
	| approx positives in sample 512: 151
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 25, 14, 13, 20, 13, 16, 11, 23]
	Time taken saving stuff: 0.03s

=== episode:1348 Env-steps-taken:68832
 	picked: 83 |actions: {0: 499, 1: 561, 2: 510, 3: 508, 4: 559, 5: 475, 6: 726, 7: 727, 8: 419}
episode: 1348/2000 -> reward: 104.24479166666653, steps:4984, time-taken: 3.36min, time-elasped: 5369.01min
-> berries picked: 83 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9907 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1026, 1488, 1422, 1121, 1101, 949, 838, 810, 1152]
	| approx positives in sample 512: 169
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 21, 23, 19, 23, 19, 14, 11, 19]
	Time taken saving stuff: 0.01s

=== episode:1349 Env-steps-taken:68832
 	picked: 74 |actions: {0: 459, 1: 489, 2: 513, 3: 491, 4: 540, 5: 542, 6: 480, 7: 673, 8: 231}
episode: 1349/2000 -> reward: 104.76041666666659, steps:4418, time-taken: 3.53min, time-elasped: 5372.55min
-> berries picked: 74 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9905 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1024, 1486, 1421, 1119, 1101, 950, 840, 812, 1152]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 20, 18, 14, 20, 13, 10, 9, 18]
	Time taken saving stuff: 0.01s

=== episode:1350 Env-steps-taken:75648
 	picked: 95 |actions: {0: 664, 1: 675, 2: 629, 3: 608, 4: 874, 5: 585, 6: 671, 7: 886, 8: 488}
episode: 1350/2000 -> reward: 139.5572916666666, steps:6080, time-taken: 4.14min, time-elasped: 5376.69min
-> berries picked: 95 of 800 | patches-visited: [0, 3, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9925 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1024, 1488, 1425, 1117, 1110, 954, 842, 812, 1153]
	| approx positives in sample 512: 168
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 25, 19, 24, 18, 17, 16, 11, 25]
	Time taken saving stuff: 0.11s

=== episode:135 Env-steps-taken:85920
 	picked: 138 |actions: {0: 701, 1: 1145, 2: 232, 3: 728, 4: 476, 5: 289, 6: 619, 7: 724, 8: 297}

==================================================
eval-episode: 1350 -> reward: 188.32291666666694, steps: 5211.0, wall-time: 88.15s
-> berries picked: 138 of 800 | patches-visited: [0, 1, 2, 7] | juice left:-0.00
==================================================


=== episode:1351 Env-steps-taken:69504
 	picked: 76 |actions: {0: 548, 1: 478, 2: 593, 3: 520, 4: 614, 5: 487, 6: 685, 7: 700, 8: 280}
episode: 1351/2000 -> reward: 106.26041666666657, steps:4905, time-taken: 3.28min, time-elasped: 5381.45min
-> berries picked: 76 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9906 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1015, 1487, 1424, 1116, 1108, 951, 841, 813, 1151]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 21, 24, 13, 13, 19, 10, 13, 19]
	Time taken saving stuff: 0.02s

=== episode:1352 Env-steps-taken:65760
 	picked: 61 |actions: {0: 661, 1: 511, 2: 603, 3: 722, 4: 461, 5: 515, 6: 593, 7: 739, 8: 455}
episode: 1352/2000 -> reward: 89.5052083333333, steps:5260, time-taken: 3.59min, time-elasped: 5385.04min
-> berries picked: 61 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9884 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1016, 1489, 1417, 1121, 1102, 948, 835, 808, 1148]
	| approx positives in sample 512: 147
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 18, 15, 19, 22, 15, 9, 15, 22]
	Time taken saving stuff: 0.04s

=== episode:1353 Env-steps-taken:69696
 	picked: 81 |actions: {0: 669, 1: 462, 2: 747, 3: 619, 4: 487, 5: 554, 6: 758, 7: 572, 8: 382}
episode: 1353/2000 -> reward: 108.85937499999986, steps:5250, time-taken: 3.58min, time-elasped: 5388.63min
-> berries picked: 81 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9900 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1013, 1491, 1420, 1125, 1104, 947, 839, 811, 1150]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 15, 13, 13, 14, 11, 17, 12, 23]
	Time taken saving stuff: 0.02s

=== episode:1354 Env-steps-taken:65568
 	picked: 62 |actions: {0: 483, 1: 536, 2: 689, 3: 744, 4: 1001, 5: 604, 6: 652, 7: 657, 8: 515}
episode: 1354/2000 -> reward: 87.94791666666663, steps:5881, time-taken: 3.98min, time-elasped: 5392.61min
-> berries picked: 62 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9870 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1012, 1492, 1422, 1121, 1092, 946, 835, 801, 1149]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 19, 24, 14, 16, 12, 12, 6, 23]
	Time taken saving stuff: 0.10s

=== episode:1355 Env-steps-taken:65952
 	picked: 67 |actions: {0: 440, 1: 632, 2: 766, 3: 476, 4: 602, 5: 404, 6: 636, 7: 594, 8: 383}
episode: 1355/2000 -> reward: 90.16145833333326, steps:4933, time-taken: 3.67min, time-elasped: 5396.29min
-> berries picked: 67 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9864 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1013, 1491, 1422, 1121, 1098, 941, 830, 799, 1149]
	| approx positives in sample 512: 149
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 22, 21, 18, 17, 15, 9, 14, 20]
	Time taken saving stuff: 0.01s

=== episode:1356 Env-steps-taken:62880
 	picked: 54 |actions: {0: 523, 1: 347, 2: 396, 3: 309, 4: 399, 5: 912, 6: 707, 7: 802, 8: 328}
episode: 1356/2000 -> reward: 74.90625000000001, steps:4723, time-taken: 3.51min, time-elasped: 5399.80min
-> berries picked: 54 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9831 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1006, 1485, 1421, 1114, 1094, 937, 828, 799, 1147]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 14, 14, 14, 16, 9, 7, 9, 21]
	Time taken saving stuff: 0.02s

=== episode:1357 Env-steps-taken:69600
 	picked: 89 |actions: {0: 592, 1: 491, 2: 586, 3: 636, 4: 672, 5: 489, 6: 511, 7: 776, 8: 271}
episode: 1357/2000 -> reward: 107.90104166666654, steps:5024, time-taken: 3.61min, time-elasped: 5403.42min
-> berries picked: 89 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9844 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1008, 1484, 1421, 1118, 1093, 946, 830, 798, 1146]
	| approx positives in sample 512: 151
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 24, 22, 11, 17, 20, 14, 10, 19]
	Time taken saving stuff: 0.10s

=== episode:1358 Env-steps-taken:70752
 	picked: 85 |actions: {0: 549, 1: 604, 2: 648, 3: 623, 4: 511, 5: 447, 6: 772, 7: 597, 8: 282}
episode: 1358/2000 -> reward: 114.13020833333319, steps:5033, time-taken: 3.41min, time-elasped: 5406.84min
-> berries picked: 85 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9831 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1006, 1479, 1422, 1115, 1087, 947, 832, 798, 1145]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 29, 18, 15, 12, 17, 6, 9, 18]
	Time taken saving stuff: 0.10s

=== episode:1359 Env-steps-taken:77088
 	picked: 106 |actions: {0: 804, 1: 691, 2: 743, 3: 629, 4: 576, 5: 466, 6: 767, 7: 662, 8: 363}
episode: 1359/2000 -> reward: 146.42708333333326, steps:5701, time-taken: 4.27min, time-elasped: 5411.12min
-> berries picked: 106 of 800 | patches-visited: [0, 5, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9854 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1008, 1484, 1424, 1116, 1094, 952, 829, 802, 1145]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 11, 28, 15, 13, 12, 18, 15, 18]
	Time taken saving stuff: 0.03s

=== episode:1360 Env-steps-taken:68736
 	picked: 74 |actions: {0: 458, 1: 680, 2: 614, 3: 310, 4: 610, 5: 464, 6: 633, 7: 603, 8: 244}
episode: 1360/2000 -> reward: 104.26041666666659, steps:4616, time-taken: 3.29min, time-elasped: 5414.41min
-> berries picked: 74 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9860 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1009, 1483, 1426, 1116, 1092, 960, 830, 799, 1145]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 18, 19, 18, 20, 10, 12, 11, 17]
	Time taken saving stuff: 0.09s

=== episode:136 Env-steps-taken:99360
 	picked: 190 |actions: {0: 902, 1: 1777, 2: 626, 3: 652, 4: 788, 5: 514, 6: 1069, 7: 503, 8: 217}

==================================================
eval-episode: 1360 -> reward: 256.2291666666674, steps: 7048.0, wall-time: 91.22s
-> berries picked: 190 of 800 | patches-visited: [0, 1, 6, 8] | juice left:-0.00
==================================================


=== episode:1361 Env-steps-taken:64416
 	picked: 64 |actions: {0: 404, 1: 427, 2: 578, 3: 388, 4: 574, 5: 341, 6: 298, 7: 318, 8: 308}
episode: 1361/2000 -> reward: 81.83333333333331, steps:3636, time-taken: 2.78min, time-elasped: 5418.71min
-> berries picked: 64 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9851 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1008, 1469, 1429, 1122, 1089, 963, 828, 799, 1144]
	| approx positives in sample 512: 167
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 20, 23, 19, 17, 17, 13, 10, 29]
	Time taken saving stuff: 0.01s

=== episode:1362 Env-steps-taken:69600
 	picked: 75 |actions: {0: 614, 1: 549, 2: 477, 3: 464, 4: 579, 5: 354, 6: 351, 7: 538, 8: 371}
episode: 1362/2000 -> reward: 108.7031249999999, steps:4297, time-taken: 3.34min, time-elasped: 5422.06min
-> berries picked: 75 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9845 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [994, 1475, 1431, 1123, 1089, 963, 829, 797, 1144]
	| approx positives in sample 512: 150
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 20, 14, 20, 15, 16, 14, 9, 26]
	Time taken saving stuff: 0.07s

=== episode:1363 Env-steps-taken:72288
 	picked: 85 |actions: {0: 525, 1: 755, 2: 593, 3: 755, 4: 611, 5: 501, 6: 420, 7: 591, 8: 333}
episode: 1363/2000 -> reward: 122.13020833333317, steps:5084, time-taken: 3.74min, time-elasped: 5425.80min
-> berries picked: 85 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9840 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [995, 1467, 1428, 1125, 1087, 961, 833, 799, 1145]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 22, 17, 13, 9, 13, 9, 8, 16]
	Time taken saving stuff: 0.10s

=== episode:1364 Env-steps-taken:71232
 	picked: 87 |actions: {0: 715, 1: 715, 2: 728, 3: 685, 4: 790, 5: 557, 6: 596, 7: 744, 8: 405}
episode: 1364/2000 -> reward: 116.51562499999983, steps:5935, time-taken: 3.24min, time-elasped: 5429.05min
-> berries picked: 87 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9860 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [997, 1467, 1428, 1131, 1084, 964, 842, 801, 1146]
	| approx positives in sample 512: 157
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 17, 18, 21, 11, 12, 17, 13, 27]
	Time taken saving stuff: 0.11s

=== episode:1365 Env-steps-taken:74880
 	picked: 101 |actions: {0: 727, 1: 702, 2: 654, 3: 845, 4: 773, 5: 576, 6: 575, 7: 807, 8: 342}
episode: 1365/2000 -> reward: 134.71354166666663, steps:6001, time-taken: 3.38min, time-elasped: 5432.44min
-> berries picked: 101 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9873 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [992, 1472, 1436, 1141, 1082, 964, 840, 800, 1146]
	| approx positives in sample 512: 147
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 13, 32, 15, 13, 12, 15, 9, 25]
	Time taken saving stuff: 0.11s

=== episode:1366 Env-steps-taken:56448
 	picked: 34 |actions: {0: 488, 1: 755, 2: 696, 3: 532, 4: 798, 5: 460, 6: 414, 7: 389, 8: 441}
episode: 1366/2000 -> reward: 42.05208333333335, steps:4973, time-taken: 2.73min, time-elasped: 5435.17min
-> berries picked: 34 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9834 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [991, 1462, 1428, 1138, 1079, 960, 832, 797, 1147]
	| approx positives in sample 512: 149
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 20, 12, 17, 19, 15, 13, 13, 22]
	Time taken saving stuff: 0.10s

=== episode:1367 Env-steps-taken:67680
 	picked: 73 |actions: {0: 774, 1: 608, 2: 653, 3: 473, 4: 676, 5: 573, 6: 659, 7: 664, 8: 503}
episode: 1367/2000 -> reward: 98.81770833333324, steps:5583, time-taken: 3.67min, time-elasped: 5438.84min
-> berries picked: 73 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9823 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [989, 1460, 1427, 1128, 1072, 963, 835, 799, 1150]
	| approx positives in sample 512: 150
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 21, 17, 13, 16, 13, 15, 10, 26]
	Time taken saving stuff: 0.09s

=== episode:1368 Env-steps-taken:74304
 	picked: 97 |actions: {0: 796, 1: 717, 2: 606, 3: 630, 4: 619, 5: 543, 6: 660, 7: 658, 8: 344}
episode: 1368/2000 -> reward: 132.44270833333317, steps:5573, time-taken: 4.01min, time-elasped: 5442.86min
-> berries picked: 97 of 800 | patches-visited: [0, 8, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9836 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [991, 1454, 1428, 1129, 1080, 965, 835, 803, 1151]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 13, 17, 13, 15, 20, 19, 12, 18]
	Time taken saving stuff: 0.02s

=== episode:1369 Env-steps-taken:67488
 	picked: 72 |actions: {0: 470, 1: 622, 2: 809, 3: 544, 4: 660, 5: 457, 6: 486, 7: 688, 8: 297}
episode: 1369/2000 -> reward: 95.98958333333329, steps:5033, time-taken: 3.27min, time-elasped: 5446.13min
-> berries picked: 72 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9841 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [991, 1449, 1430, 1135, 1088, 962, 833, 800, 1153]
	| approx positives in sample 512: 143
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 17, 16, 14, 11, 10, 21, 13, 27]
	Time taken saving stuff: 0.09s

=== episode:1370 Env-steps-taken:61440
 	picked: 48 |actions: {0: 318, 1: 396, 2: 353, 3: 188, 4: 182, 5: 183, 6: 356, 7: 339, 8: 252}
episode: 1370/2000 -> reward: 66.36458333333339, steps:2567, time-taken: 1.69min, time-elasped: 5447.82min
-> berries picked: 48 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9852 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [992, 1454, 1434, 1131, 1090, 961, 833, 802, 1155]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 20, 19, 9, 18, 14, 10, 11, 20]
	Time taken saving stuff: 0.07s

=== episode:137 Env-steps-taken:78624
 	picked: 120 |actions: {0: 260, 1: 794, 2: 858, 3: 213, 4: 970, 5: 124, 6: 688, 7: 1055, 8: 494}

==================================================
eval-episode: 1370 -> reward: 152.73958333333331, steps: 5456.0, wall-time: 55.08s
-> berries picked: 120 of 800 | patches-visited: [1, 5, 7] | juice left:-0.00
==================================================


=== episode:1371 Env-steps-taken:62784
 	picked: 53 |actions: {0: 246, 1: 427, 2: 369, 3: 348, 4: 364, 5: 352, 6: 330, 7: 441, 8: 231}
episode: 1371/2000 -> reward: 74.46354166666667, steps:3108, time-taken: 2.07min, time-elasped: 5450.81min
-> berries picked: 53 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9843 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [994, 1455, 1433, 1133, 1090, 961, 831, 789, 1157]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 24, 18, 13, 8, 11, 18, 9, 16]
	Time taken saving stuff: 0.07s

=== episode:1372 Env-steps-taken:70752
 	picked: 89 |actions: {0: 490, 1: 476, 2: 593, 3: 526, 4: 604, 5: 451, 6: 455, 7: 452, 8: 306}
episode: 1372/2000 -> reward: 113.90104166666653, steps:4353, time-taken: 2.40min, time-elasped: 5453.22min
-> berries picked: 89 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9861 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [998, 1447, 1440, 1139, 1091, 964, 833, 790, 1159]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 17, 13, 23, 10, 14, 14, 9, 20]
	Time taken saving stuff: 0.02s

=== episode:1373 Env-steps-taken:64032
 	picked: 68 |actions: {0: 629, 1: 761, 2: 685, 3: 573, 4: 615, 5: 542, 6: 458, 7: 481, 8: 401}
episode: 1373/2000 -> reward: 78.33333333333329, steps:5145, time-taken: 2.79min, time-elasped: 5456.01min
-> berries picked: 68 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9841 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [991, 1448, 1434, 1139, 1086, 965, 831, 787, 1160]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 22, 12, 10, 12, 19, 8, 15, 20]
	Time taken saving stuff: 0.03s

=== episode:1374 Env-steps-taken:66816
 	picked: 72 |actions: {0: 616, 1: 735, 2: 600, 3: 571, 4: 577, 5: 481, 6: 604, 7: 513, 8: 327}
episode: 1374/2000 -> reward: 94.37499999999991, steps:5024, time-taken: 2.98min, time-elasped: 5459.00min
-> berries picked: 72 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9833 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [984, 1441, 1435, 1143, 1086, 967, 829, 786, 1162]
	| approx positives in sample 512: 152
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 23, 16, 17, 13, 15, 12, 9, 25]
	Time taken saving stuff: 0.03s

=== episode:1375 Env-steps-taken:72576
 	picked: 86 |actions: {0: 412, 1: 574, 2: 517, 3: 518, 4: 666, 5: 403, 6: 484, 7: 502, 8: 282}
episode: 1375/2000 -> reward: 123.57291666666652, steps:4358, time-taken: 2.52min, time-elasped: 5461.52min
-> berries picked: 86 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9856 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [987, 1444, 1437, 1150, 1093, 967, 830, 784, 1164]
	| approx positives in sample 512: 145
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 17, 15, 22, 21, 16, 8, 11, 21]
	Time taken saving stuff: 0.09s

=== episode:1376 Env-steps-taken:69984
 	picked: 77 |actions: {0: 536, 1: 607, 2: 633, 3: 489, 4: 609, 5: 402, 6: 385, 7: 588, 8: 315}
episode: 1376/2000 -> reward: 110.58854166666657, steps:4564, time-taken: 291.40min, time-elasped: 5752.93min
-> berries picked: 77 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9855 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [984, 1440, 1444, 1141, 1099, 965, 833, 787, 1162]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 24, 23, 19, 15, 12, 12, 12, 24]
	Time taken saving stuff: 0.03s

=== episode:1377 Env-steps-taken:65952
 	picked: 72 |actions: {0: 635, 1: 765, 2: 750, 3: 838, 4: 672, 5: 588, 6: 533, 7: 569, 8: 295}
episode: 1377/2000 -> reward: 89.37499999999994, steps:5645, time-taken: 8.69min, time-elasped: 5761.64min
-> berries picked: 72 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9839 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [977, 1438, 1445, 1137, 1099, 966, 829, 785, 1163]
	| approx positives in sample 512: 157
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 16, 18, 19, 15, 17, 20, 13, 24]
	Time taken saving stuff: 0.04s

=== episode:1378 Env-steps-taken:70272
 	picked: 83 |actions: {0: 654, 1: 656, 2: 599, 3: 681, 4: 640, 5: 663, 6: 779, 7: 661, 8: 349}
episode: 1378/2000 -> reward: 111.74479166666654, steps:5682, time-taken: 8.21min, time-elasped: 5769.85min
-> berries picked: 83 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9854 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [980, 1443, 1442, 1138, 1101, 970, 830, 787, 1163]
	| approx positives in sample 512: 149
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 19, 25, 16, 20, 17, 10, 5, 28]
	Time taken saving stuff: 0.01s

=== episode:1379 Env-steps-taken:64608
 	picked: 64 |actions: {0: 640, 1: 710, 2: 764, 3: 703, 4: 699, 5: 473, 6: 569, 7: 765, 8: 505}
episode: 1379/2000 -> reward: 82.8333333333333, steps:5828, time-taken: 1299.00min, time-elasped: 7068.86min
-> berries picked: 64 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9856 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [980, 1446, 1436, 1142, 1104, 969, 836, 782, 1161]
	| approx positives in sample 512: 156
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 28, 15, 16, 11, 19, 11, 14, 27]
	Time taken saving stuff: 0.10s

=== episode:1380 Env-steps-taken:67392
 	picked: 71 |actions: {0: 612, 1: 719, 2: 549, 3: 757, 4: 544, 5: 461, 6: 567, 7: 508, 8: 474}
episode: 1380/2000 -> reward: 97.4322916666666, steps:5191, time-taken: 1.91min, time-elasped: 7070.77min
-> berries picked: 71 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9862 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [975, 1445, 1445, 1140, 1105, 971, 838, 782, 1161]
	| approx positives in sample 512: 145
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 24, 15, 18, 15, 10, 8, 11, 27]
	Time taken saving stuff: 0.06s

=== episode:138 Env-steps-taken:86112
 	picked: 145 |actions: {0: 2148, 1: 255, 2: 546, 3: 988, 4: 419, 5: 338, 6: 556, 7: 368, 8: 530}

==================================================
eval-episode: 1380 -> reward: 191.19270833333366, steps: 6148.0, wall-time: 41.14s
-> berries picked: 145 of 800 | patches-visited: [1, 4, 7] | juice left:-0.00
==================================================


=== episode:1381 Env-steps-taken:65472
 	picked: 61 |actions: {0: 830, 1: 642, 2: 572, 3: 538, 4: 612, 5: 457, 6: 450, 7: 789, 8: 462}
episode: 1381/2000 -> reward: 87.50520833333329, steps:5352, time-taken: 2.08min, time-elasped: 7073.54min
-> berries picked: 61 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9833 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [973, 1434, 1443, 1135, 1099, 968, 836, 784, 1161]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 16, 19, 13, 8, 16, 8, 13, 30]
	Time taken saving stuff: 0.02s

=== episode:1382 Env-steps-taken:63072
 	picked: 58 |actions: {0: 615, 1: 560, 2: 614, 3: 395, 4: 505, 5: 410, 6: 722, 7: 577, 8: 418}
episode: 1382/2000 -> reward: 75.17708333333333, steps:4816, time-taken: 2.23min, time-elasped: 7075.77min
-> berries picked: 58 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9836 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [975, 1439, 1438, 1134, 1100, 963, 839, 788, 1160]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 18, 14, 16, 15, 14, 8, 13, 19]
	Time taken saving stuff: 0.10s

=== episode:1383 Env-steps-taken:66240
 	picked: 68 |actions: {0: 701, 1: 700, 2: 627, 3: 509, 4: 717, 5: 503, 6: 809, 7: 632, 8: 514}
episode: 1383/2000 -> reward: 89.71874999999996, steps:5712, time-taken: 2.49min, time-elasped: 7078.26min
-> berries picked: 68 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9821 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [967, 1443, 1439, 1130, 1096, 959, 838, 785, 1164]
	| approx positives in sample 512: 143
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 15, 16, 23, 14, 18, 12, 8, 24]
	Time taken saving stuff: 0.10s

=== episode:1384 Env-steps-taken:75264
 	picked: 99 |actions: {0: 707, 1: 845, 2: 683, 3: 645, 4: 694, 5: 670, 6: 674, 7: 677, 8: 406}
episode: 1384/2000 -> reward: 136.8281249999999, steps:6001, time-taken: 2.99min, time-elasped: 7081.25min
-> berries picked: 99 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9838 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [976, 1441, 1448, 1129, 1089, 961, 839, 790, 1165]
	| approx positives in sample 512: 166
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 24, 17, 16, 17, 16, 13, 12, 37]
	Time taken saving stuff: 0.04s

=== episode:1385 Env-steps-taken:64416
 	picked: 58 |actions: {0: 421, 1: 577, 2: 481, 3: 571, 4: 574, 5: 507, 6: 552, 7: 581, 8: 380}
episode: 1385/2000 -> reward: 82.6770833333333, steps:4644, time-taken: 2.36min, time-elasped: 7083.62min
-> berries picked: 58 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9840 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [970, 1445, 1447, 1126, 1087, 964, 846, 789, 1166]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 19, 15, 12, 18, 17, 9, 10, 24]
	Time taken saving stuff: 0.09s

=== episode:1386 Env-steps-taken:75648
 	picked: 106 |actions: {0: 773, 1: 866, 2: 933, 3: 784, 4: 650, 5: 682, 6: 742, 7: 728, 8: 469}
episode: 1386/2000 -> reward: 138.4270833333333, steps:6627, time-taken: 3.40min, time-elasped: 7087.03min
-> berries picked: 106 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9834 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [966, 1446, 1454, 1125, 1078, 961, 847, 792, 1165]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 22, 16, 20, 15, 16, 10, 10, 22]
	Time taken saving stuff: 0.04s

=== episode:1387 Env-steps-taken:63360
 	picked: 64 |actions: {0: 443, 1: 594, 2: 489, 3: 566, 4: 382, 5: 443, 6: 499, 7: 382, 8: 381}
episode: 1387/2000 -> reward: 76.3333333333333, steps:4179, time-taken: 2.45min, time-elasped: 7089.48min
-> berries picked: 64 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9843 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [964, 1453, 1456, 1128, 1080, 956, 850, 792, 1164]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 12, 16, 17, 12, 16, 11, 11, 26]
	Time taken saving stuff: 0.01s

=== episode:1388 Env-steps-taken:66720
 	picked: 68 |actions: {0: 504, 1: 565, 2: 446, 3: 558, 4: 453, 5: 591, 6: 582, 7: 465, 8: 302}
episode: 1388/2000 -> reward: 93.6041666666666, steps:4466, time-taken: 2.22min, time-elasped: 7091.70min
-> berries picked: 68 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9839 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [961, 1450, 1457, 1131, 1081, 955, 853, 788, 1163]
	| approx positives in sample 512: 149
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 24, 22, 11, 19, 18, 10, 8, 25]
	Time taken saving stuff: 0.02s

=== episode:1389 Env-steps-taken:70560
 	picked: 82 |actions: {0: 451, 1: 535, 2: 536, 3: 737, 4: 578, 5: 466, 6: 456, 7: 748, 8: 366}
episode: 1389/2000 -> reward: 113.30208333333321, steps:4873, time-taken: 3.03min, time-elasped: 7094.73min
-> berries picked: 82 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9865 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [966, 1452, 1464, 1135, 1084, 963, 850, 788, 1163]
	| approx positives in sample 512: 155
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 20, 17, 15, 11, 23, 11, 12, 26]
	Time taken saving stuff: 0.02s

=== episode:1390 Env-steps-taken:67968
 	picked: 76 |actions: {0: 451, 1: 519, 2: 413, 3: 488, 4: 504, 5: 485, 6: 519, 7: 681, 8: 285}
episode: 1390/2000 -> reward: 100.14583333333324, steps:4345, time-taken: 2.35min, time-elasped: 7097.09min
-> berries picked: 76 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9863 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [968, 1447, 1464, 1129, 1086, 960, 854, 791, 1164]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 19, 18, 8, 17, 12, 13, 15, 21]
	Time taken saving stuff: 0.08s

=== episode:139 Env-steps-taken:75072
 	picked: 107 |actions: {0: 405, 1: 376, 2: 514, 3: 2004, 4: 135, 5: 466, 6: 117, 7: 2228, 8: 145}

==================================================
eval-episode: 1390 -> reward: 134.48437499999986, steps: 6390.0, wall-time: 68.80s
-> berries picked: 107 of 800 | patches-visited: [1, 4] | juice left:-0.00
==================================================


=== episode:1391 Env-steps-taken:71616
 	picked: 89 |actions: {0: 676, 1: 620, 2: 563, 3: 801, 4: 712, 5: 572, 6: 688, 7: 867, 8: 422}
episode: 1391/2000 -> reward: 116.45833333333319, steps:5921, time-taken: 3.44min, time-elasped: 7101.68min
-> berries picked: 89 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9863 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [970, 1442, 1463, 1126, 1084, 958, 850, 804, 1166]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 20, 17, 16, 20, 10, 13, 10, 19]
	Time taken saving stuff: 0.12s

=== episode:1392 Env-steps-taken:66528
 	picked: 74 |actions: {0: 590, 1: 448, 2: 613, 3: 692, 4: 742, 5: 434, 6: 557, 7: 540, 8: 284}
episode: 1392/2000 -> reward: 92.26041666666657, steps:4900, time-taken: 2.85min, time-elasped: 7104.54min
-> berries picked: 74 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9853 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [964, 1445, 1461, 1129, 1084, 955, 850, 800, 1165]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 18, 18, 15, 10, 11, 12, 9, 32]
	Time taken saving stuff: 0.02s

=== episode:1393 Env-steps-taken:72576
 	picked: 88 |actions: {0: 565, 1: 535, 2: 694, 3: 776, 4: 700, 5: 519, 6: 639, 7: 670, 8: 315}
episode: 1393/2000 -> reward: 123.45833333333317, steps:5413, time-taken: 3.06min, time-elasped: 7107.59min
-> berries picked: 88 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9875 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [963, 1447, 1469, 1136, 1087, 953, 852, 800, 1168]
	| approx positives in sample 512: 156
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 22, 21, 18, 17, 12, 12, 10, 28]
	Time taken saving stuff: 0.01s

=== episode:1394 Env-steps-taken:63360
 	picked: 66 |actions: {0: 472, 1: 510, 2: 735, 3: 578, 4: 431, 5: 461, 6: 493, 7: 548, 8: 315}
episode: 1394/2000 -> reward: 76.21875, steps:4543, time-taken: 2.34min, time-elasped: 7109.93min
-> berries picked: 66 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9862 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [965, 1447, 1463, 1138, 1079, 950, 853, 800, 1167]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 19, 23, 18, 14, 12, 11, 14, 20]
	Time taken saving stuff: 0.10s

=== episode:1395 Env-steps-taken:69120
 	picked: 82 |actions: {0: 523, 1: 721, 2: 647, 3: 847, 4: 589, 5: 491, 6: 629, 7: 760, 8: 393}
episode: 1395/2000 -> reward: 105.80208333333321, steps:5600, time-taken: 2.87min, time-elasped: 7112.81min
-> berries picked: 82 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9869 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [968, 1453, 1466, 1135, 1082, 952, 846, 798, 1169]
	| approx positives in sample 512: 160
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 20, 29, 20, 19, 11, 16, 13, 22]
	Time taken saving stuff: 0.01s

=== episode:1396 Env-steps-taken:61440
 	picked: 48 |actions: {0: 302, 1: 340, 2: 243, 3: 319, 4: 276, 5: 271, 6: 426, 7: 364, 8: 185}
episode: 1396/2000 -> reward: 67.36458333333336, steps:2726, time-taken: 1.83min, time-elasped: 7114.65min
-> berries picked: 48 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9864 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [970, 1458, 1461, 1138, 1084, 948, 836, 801, 1168]
	| approx positives in sample 512: 151
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 26, 14, 14, 17, 14, 19, 11, 24]
	Time taken saving stuff: 0.01s

=== episode:1397 Env-steps-taken:69600
 	picked: 73 |actions: {0: 591, 1: 761, 2: 571, 3: 569, 4: 619, 5: 627, 6: 801, 7: 720, 8: 352}
episode: 1397/2000 -> reward: 106.87499999999991, steps:5611, time-taken: 2.96min, time-elasped: 7117.61min
-> berries picked: 73 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9851 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [971, 1458, 1463, 1129, 1080, 951, 835, 794, 1170]
	| approx positives in sample 512: 152
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 19, 18, 17, 16, 19, 13, 10, 19]
	Time taken saving stuff: 0.01s

=== episode:1398 Env-steps-taken:75648
 	picked: 107 |actions: {0: 622, 1: 774, 2: 692, 3: 688, 4: 560, 5: 521, 6: 509, 7: 683, 8: 327}
episode: 1398/2000 -> reward: 138.86979166666657, steps:5376, time-taken: 2.93min, time-elasped: 7120.53min
-> berries picked: 107 of 800 | patches-visited: [0, 4, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9872 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [977, 1470, 1458, 1130, 1079, 953, 838, 798, 1169]
	| approx positives in sample 512: 162
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 21, 26, 19, 12, 8, 17, 14, 29]
	Time taken saving stuff: 0.10s

=== episode:1399 Env-steps-taken:71136
 	picked: 86 |actions: {0: 697, 1: 763, 2: 691, 3: 812, 4: 535, 5: 636, 6: 605, 7: 578, 8: 381}
episode: 1399/2000 -> reward: 114.6302083333332, steps:5698, time-taken: 3.14min, time-elasped: 7123.68min
-> berries picked: 86 of 800 | patches-visited: [0, 6, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9866 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [979, 1476, 1458, 1129, 1075, 949, 834, 796, 1170]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 16, 14, 15, 19, 11, 15, 11, 22]
	Time taken saving stuff: 0.04s

=== episode:1400 Env-steps-taken:68640
 	picked: 82 |actions: {0: 511, 1: 784, 2: 561, 3: 720, 4: 572, 5: 506, 6: 774, 7: 885, 8: 413}
episode: 1400/2000 -> reward: 103.30208333333323, steps:5726, time-taken: 3.90min, time-elasped: 7127.58min
-> berries picked: 82 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9875 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [976, 1477, 1457, 1130, 1079, 944, 841, 799, 1172]
	| approx positives in sample 512: 149
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 20, 25, 13, 13, 12, 12, 13, 23]
	Time taken saving stuff: 0.16s

=== episode:140 Env-steps-taken:69792
 	picked: 78 |actions: {0: 255, 1: 242, 2: 201, 3: 393, 4: 1825, 5: 555, 6: 1400, 7: 503, 8: 195}

==================================================
eval-episode: 1400 -> reward: 109.14583333333321, steps: 5569.0, wall-time: 62.76s
-> berries picked: 78 of 800 | patches-visited: [1, 3, 9] | juice left:-0.00
==================================================


=== episode:1401 Env-steps-taken:63936
 	picked: 67 |actions: {0: 381, 1: 415, 2: 703, 3: 561, 4: 607, 5: 473, 6: 495, 7: 501, 8: 294}
episode: 1401/2000 -> reward: 79.1614583333333, steps:4430, time-taken: 3.09min, time-elasped: 7131.73min
-> berries picked: 67 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9876 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [974, 1475, 1456, 1131, 1080, 950, 837, 800, 1173]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 21, 20, 26, 11, 13, 12, 10, 19]
	Time taken saving stuff: 0.01s

=== episode:1402 Env-steps-taken:70656
 	picked: 81 |actions: {0: 563, 1: 667, 2: 567, 3: 680, 4: 518, 5: 418, 6: 575, 7: 567, 8: 339}
episode: 1402/2000 -> reward: 111.58854166666659, steps:4894, time-taken: 3.25min, time-elasped: 7134.99min
-> berries picked: 81 of 800 | patches-visited: [0, 1, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9884 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [976, 1475, 1465, 1127, 1083, 950, 832, 800, 1176]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 19, 19, 7, 16, 22, 12, 7, 27]
	Time taken saving stuff: 0.00s

=== episode:1403 Env-steps-taken:67104
 	picked: 70 |actions: {0: 570, 1: 618, 2: 792, 3: 808, 4: 551, 5: 419, 6: 607, 7: 676, 8: 323}
episode: 1403/2000 -> reward: 94.60416666666657, steps:5364, time-taken: 3.25min, time-elasped: 7138.24min
-> berries picked: 70 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9889 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [979, 1476, 1465, 1133, 1086, 948, 834, 793, 1175]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 20, 21, 17, 14, 14, 8, 11, 20]
	Time taken saving stuff: 0.01s

=== episode:1404 Env-steps-taken:63360
 	picked: 56 |actions: {0: 338, 1: 528, 2: 653, 3: 430, 4: 416, 5: 301, 6: 396, 7: 456, 8: 261}
episode: 1404/2000 -> reward: 77.29166666666664, steps:3779, time-taken: 2.67min, time-elasped: 7140.92min
-> berries picked: 56 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9894 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [980, 1476, 1466, 1132, 1084, 946, 836, 798, 1176]
	| approx positives in sample 512: 168
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 17, 26, 22, 15, 18, 13, 8, 27]
	Time taken saving stuff: 0.02s

=== episode:1405 Env-steps-taken:73920
 	picked: 95 |actions: {0: 491, 1: 675, 2: 755, 3: 735, 4: 535, 5: 476, 6: 783, 7: 561, 8: 367}
episode: 1405/2000 -> reward: 129.11458333333314, steps:5378, time-taken: 3.75min, time-elasped: 7144.66min
-> berries picked: 95 of 800 | patches-visited: [0, 1, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9910 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [984, 1472, 1474, 1130, 1084, 950, 835, 805, 1176]
	| approx positives in sample 512: 151
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 23, 10, 26, 18, 17, 10, 11, 22]
	Time taken saving stuff: 0.01s

=== episode:1406 Env-steps-taken:62496
 	picked: 50 |actions: {0: 385, 1: 364, 2: 344, 3: 344, 4: 339, 5: 367, 6: 468, 7: 324, 8: 250}
episode: 1406/2000 -> reward: 73.13541666666669, steps:3185, time-taken: 2.36min, time-elasped: 7147.03min
-> berries picked: 50 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9915 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [986, 1472, 1475, 1131, 1086, 950, 838, 799, 1178]
	| approx positives in sample 512: 151
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 20, 22, 16, 15, 10, 21, 9, 24]
	Time taken saving stuff: 0.03s

=== episode:1407 Env-steps-taken:56544
 	picked: 30 |actions: {0: 517, 1: 554, 2: 429, 3: 665, 4: 382, 5: 244, 6: 267, 7: 313, 8: 433}
episode: 1407/2000 -> reward: 42.781250000000014, steps:3804, time-taken: 2.65min, time-elasped: 7149.68min
-> berries picked: 30 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9890 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [985, 1477, 1470, 1127, 1080, 947, 832, 794, 1178]
	| approx positives in sample 512: 150
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [24, 21, 18, 17, 11, 5, 16, 11, 27]
	Time taken saving stuff: 0.09s

=== episode:1408 Env-steps-taken:65568
 	picked: 72 |actions: {0: 601, 1: 578, 2: 654, 3: 547, 4: 456, 5: 508, 6: 508, 7: 613, 8: 315}
episode: 1408/2000 -> reward: 87.87499999999996, steps:4780, time-taken: 3.12min, time-elasped: 7152.81min
-> berries picked: 72 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9894 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [987, 1480, 1469, 1129, 1073, 944, 832, 799, 1181]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 19, 20, 17, 13, 17, 15, 8, 19]
	Time taken saving stuff: 0.00s

=== episode:1409 Env-steps-taken:70464
 	picked: 83 |actions: {0: 478, 1: 617, 2: 688, 3: 913, 4: 682, 5: 660, 6: 450, 7: 656, 8: 293}
episode: 1409/2000 -> reward: 112.74479166666656, steps:5437, time-taken: 3.36min, time-elasped: 7156.17min
-> berries picked: 83 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9909 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [985, 1481, 1468, 1136, 1076, 944, 834, 803, 1182]
	| approx positives in sample 512: 150
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 25, 12, 26, 15, 14, 8, 12, 22]
	Time taken saving stuff: 0.11s

=== episode:1410 Env-steps-taken:69408
 	picked: 72 |actions: {0: 439, 1: 600, 2: 509, 3: 534, 4: 539, 5: 535, 6: 462, 7: 485, 8: 275}
episode: 1410/2000 -> reward: 107.8749999999999, steps:4378, time-taken: 2.85min, time-elasped: 7159.02min
-> berries picked: 72 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9928 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [988, 1483, 1472, 1134, 1083, 946, 839, 801, 1182]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 24, 19, 19, 16, 11, 10, 13, 17]
	Time taken saving stuff: 0.08s

=== episode:141 Env-steps-taken:74880
 	picked: 104 |actions: {0: 1089, 1: 1263, 2: 801, 3: 193, 4: 522, 5: 626, 6: 50, 7: 853, 8: 288}

==================================================
eval-episode: 1410 -> reward: 133.65624999999986, steps: 5685.0, wall-time: 58.88s
-> berries picked: 104 of 800 | patches-visited: [1, 6] | juice left:-0.00
==================================================


=== episode:1411 Env-steps-taken:75360
 	picked: 92 |actions: {0: 467, 1: 553, 2: 717, 3: 722, 4: 590, 5: 469, 6: 631, 7: 485, 8: 335}
episode: 1411/2000 -> reward: 138.22916666666657, steps:4969, time-taken: 3.08min, time-elasped: 7163.09min
-> berries picked: 92 of 800 | patches-visited: [0, 3, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9934 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [994, 1477, 1470, 1144, 1084, 948, 836, 796, 1185]
	| approx positives in sample 512: 154
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 20, 21, 24, 14, 13, 9, 13, 29]
	Time taken saving stuff: 0.01s

=== episode:1412 Env-steps-taken:68256
 	picked: 81 |actions: {0: 507, 1: 670, 2: 616, 3: 662, 4: 520, 5: 429, 6: 520, 7: 568, 8: 374}
episode: 1412/2000 -> reward: 101.35937499999994, steps:4866, time-taken: 3.07min, time-elasped: 7166.17min
-> berries picked: 81 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9947 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [993, 1479, 1478, 1148, 1085, 946, 839, 796, 1183]
	| approx positives in sample 512: 157
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 16, 24, 21, 18, 10, 19, 11, 23]
	Time taken saving stuff: 0.00s

=== episode:1413 Env-steps-taken:67008
 	picked: 73 |actions: {0: 556, 1: 619, 2: 762, 3: 692, 4: 584, 5: 472, 6: 491, 7: 630, 8: 362}
episode: 1413/2000 -> reward: 94.81770833333326, steps:5168, time-taken: 2.92min, time-elasped: 7169.09min
-> berries picked: 73 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9936 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [993, 1483, 1477, 1142, 1085, 944, 839, 795, 1178]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 26, 9, 10, 16, 16, 9, 9, 23]
	Time taken saving stuff: 0.03s

=== episode:1414 Env-steps-taken:78144
 	picked: 116 |actions: {0: 640, 1: 642, 2: 822, 3: 824, 4: 658, 5: 662, 6: 696, 7: 773, 8: 328}
episode: 1414/2000 -> reward: 149.41145833333331, steps:6045, time-taken: 3.47min, time-elasped: 7172.56min
-> berries picked: 116 of 800 | patches-visited: [0, 3, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9960 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [993, 1487, 1479, 1140, 1082, 947, 847, 801, 1184]
	| approx positives in sample 512: 156
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 15, 23, 17, 15, 15, 12, 13, 28]
	Time taken saving stuff: 0.00s

=== episode:1415 Env-steps-taken:65184
 	picked: 61 |actions: {0: 312, 1: 437, 2: 516, 3: 455, 4: 463, 5: 312, 6: 310, 7: 441, 8: 263}
episode: 1415/2000 -> reward: 86.5052083333333, steps:3509, time-taken: 2.21min, time-elasped: 7174.77min
-> berries picked: 61 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9969 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [992, 1487, 1486, 1138, 1080, 954, 846, 801, 1185]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 26, 25, 10, 14, 7, 11, 14, 20]
	Time taken saving stuff: 0.01s

=== episode:1416 Env-steps-taken:78624
 	picked: 112 |actions: {0: 710, 1: 729, 2: 747, 3: 885, 4: 811, 5: 595, 6: 710, 7: 793, 8: 406}
episode: 1416/2000 -> reward: 153.58333333333334, steps:6386, time-taken: 3.73min, time-elasped: 7178.51min
-> berries picked: 112 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9969 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [996, 1481, 1485, 1139, 1080, 951, 847, 805, 1185]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 22, 14, 11, 18, 13, 11, 12, 25]
	Time taken saving stuff: 0.11s

=== episode:1417 Env-steps-taken:63936
 	picked: 58 |actions: {0: 472, 1: 391, 2: 621, 3: 525, 4: 576, 5: 360, 6: 375, 7: 413, 8: 270}
episode: 1417/2000 -> reward: 79.67708333333333, steps:4003, time-taken: 2.50min, time-elasped: 7181.01min
-> berries picked: 58 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9963 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [994, 1480, 1478, 1142, 1085, 949, 847, 802, 1186]
	| approx positives in sample 512: 151
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 21, 21, 14, 13, 15, 14, 15, 23]
	Time taken saving stuff: 0.10s

=== episode:1418 Env-steps-taken:80448
 	picked: 115 |actions: {0: 638, 1: 825, 2: 812, 3: 872, 4: 788, 5: 662, 6: 623, 7: 692, 8: 357}
episode: 1418/2000 -> reward: 162.91145833333346, steps:6269, time-taken: 3.30min, time-elasped: 7184.31min
-> berries picked: 115 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9992 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [994, 1489, 1482, 1144, 1091, 956, 844, 804, 1188]
	| approx positives in sample 512: 153
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 16, 23, 16, 25, 20, 12, 11, 13]
	Time taken saving stuff: 0.03s

=== episode:1419 Env-steps-taken:70272
 	picked: 75 |actions: {0: 577, 1: 661, 2: 630, 3: 699, 4: 611, 5: 488, 6: 458, 7: 621, 8: 398}
episode: 1419/2000 -> reward: 112.20312499999989, steps:5143, time-taken: 2.97min, time-elasped: 7187.28min
-> berries picked: 75 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10014 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [998, 1492, 1487, 1153, 1096, 956, 840, 804, 1188]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 27, 13, 20, 8, 12, 13, 11, 27]
	Time taken saving stuff: 0.02s

=== episode:1420 Env-steps-taken:62592
 	picked: 53 |actions: {0: 494, 1: 437, 2: 498, 3: 441, 4: 414, 5: 284, 6: 265, 7: 419, 8: 331}
episode: 1420/2000 -> reward: 73.46354166666667, steps:3583, time-taken: 2.26min, time-elasped: 7189.55min
-> berries picked: 53 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10017 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [998, 1492, 1490, 1154, 1099, 948, 840, 807, 1189]
	| approx positives in sample 512: 160
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 22, 20, 17, 13, 22, 14, 11, 19]
	Time taken saving stuff: 0.19s

=== episode:142 Env-steps-taken:83616
 	picked: 133 |actions: {0: 1300, 1: 860, 2: 532, 3: 719, 4: 636, 5: 637, 6: 234, 7: 452, 8: 385}

==================================================
eval-episode: 1420 -> reward: 178.88020833333354, steps: 5755.0, wall-time: 66.36s
-> berries picked: 133 of 800 | patches-visited: [1, 6, 8] | juice left:-0.00
==================================================


=== episode:1421 Env-steps-taken:69600
 	picked: 84 |actions: {0: 527, 1: 626, 2: 773, 3: 462, 4: 635, 5: 497, 6: 531, 7: 614, 8: 310}
episode: 1421/2000 -> reward: 106.74479166666653, steps:4975, time-taken: 3.05min, time-elasped: 7193.71min
-> berries picked: 84 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10015 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [998, 1493, 1482, 1155, 1098, 948, 844, 805, 1192]
	| approx positives in sample 512: 149
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 29, 17, 10, 16, 23, 7, 7, 25]
	Time taken saving stuff: 0.02s

=== episode:1422 Env-steps-taken:55680
 	picked: 32 |actions: {0: 151, 1: 241, 2: 280, 3: 386, 4: 303, 5: 222, 6: 194, 7: 193, 8: 195}
episode: 1422/2000 -> reward: 38.16666666666667, steps:2165, time-taken: 1.58min, time-elasped: 7195.30min
-> berries picked: 32 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10019 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [997, 1494, 1482, 1157, 1097, 951, 843, 806, 1192]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 21, 21, 15, 16, 12, 21, 7, 13]
	Time taken saving stuff: 0.10s

=== episode:1423 Env-steps-taken:63840
 	picked: 67 |actions: {0: 573, 1: 443, 2: 832, 3: 761, 4: 549, 5: 546, 6: 690, 7: 516, 8: 305}
episode: 1423/2000 -> reward: 78.66145833333329, steps:5215, time-taken: 2.93min, time-elasped: 7198.23min
-> berries picked: 67 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10013 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [992, 1499, 1481, 1152, 1102, 950, 846, 801, 1190]
	| approx positives in sample 512: 146
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 23, 23, 19, 14, 10, 9, 10, 22]
	Time taken saving stuff: 0.11s

=== episode:1424 Env-steps-taken:72864
 	picked: 91 |actions: {0: 543, 1: 729, 2: 807, 3: 825, 4: 606, 5: 510, 6: 682, 7: 713, 8: 403}
episode: 1424/2000 -> reward: 125.28645833333316, steps:5818, time-taken: 3.56min, time-elasped: 7201.80min
-> berries picked: 91 of 800 | patches-visited: [0, 3, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10023 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [996, 1507, 1486, 1158, 1097, 950, 841, 795, 1193]
	| approx positives in sample 512: 149
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 14, 22, 16, 23, 13, 8, 10, 30]
	Time taken saving stuff: 0.00s

=== episode:1425 Env-steps-taken:70368
 	picked: 80 |actions: {0: 508, 1: 485, 2: 532, 3: 658, 4: 476, 5: 477, 6: 475, 7: 452, 8: 286}
episode: 1425/2000 -> reward: 112.91666666666656, steps:4349, time-taken: 561.30min, time-elasped: 7763.10min
-> berries picked: 80 of 800 | patches-visited: [0, 2, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10033 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [990, 1508, 1484, 1164, 1103, 955, 838, 795, 1196]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 20, 20, 12, 11, 8, 18, 6, 17]
	Time taken saving stuff: 0.00s

=== episode:1426 Env-steps-taken:65376
 	picked: 64 |actions: {0: 586, 1: 610, 2: 511, 3: 671, 4: 421, 5: 380, 6: 714, 7: 579, 8: 377}
episode: 1426/2000 -> reward: 86.83333333333329, steps:4849, time-taken: 1.96min, time-elasped: 7765.06min
-> berries picked: 64 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10021 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [990, 1501, 1480, 1159, 1103, 951, 841, 801, 1195]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 27, 15, 15, 16, 19, 13, 8, 19]
	Time taken saving stuff: 0.09s

=== episode:1427 Env-steps-taken:70272
 	picked: 85 |actions: {0: 606, 1: 618, 2: 675, 3: 795, 4: 627, 5: 512, 6: 715, 7: 592, 8: 386}
episode: 1427/2000 -> reward: 111.6302083333332, steps:5526, time-taken: 2.86min, time-elasped: 7767.93min
-> berries picked: 85 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10016 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [990, 1499, 1480, 1153, 1108, 953, 841, 796, 1196]
	| approx positives in sample 512: 156
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 13, 20, 18, 17, 13, 19, 11, 32]
	Time taken saving stuff: 0.10s

=== episode:1428 Env-steps-taken:76608
 	picked: 103 |actions: {0: 725, 1: 760, 2: 757, 3: 761, 4: 661, 5: 545, 6: 934, 7: 771, 8: 458}
episode: 1428/2000 -> reward: 143.5989583333333, steps:6372, time-taken: 2.99min, time-elasped: 7770.92min
-> berries picked: 103 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10013 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [993, 1497, 1478, 1153, 1106, 951, 841, 795, 1199]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 25, 16, 11, 14, 11, 12, 13, 17]
	Time taken saving stuff: 0.09s

=== episode:1429 Env-steps-taken:69408
 	picked: 83 |actions: {0: 646, 1: 556, 2: 572, 3: 709, 4: 622, 5: 527, 6: 908, 7: 659, 8: 317}
episode: 1429/2000 -> reward: 107.24479166666656, steps:5516, time-taken: 2.87min, time-elasped: 7773.80min
-> berries picked: 83 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10007 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [986, 1493, 1477, 1150, 1110, 957, 844, 794, 1196]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [25, 14, 20, 13, 22, 17, 7, 6, 14]
	Time taken saving stuff: 0.01s

=== episode:1430 Env-steps-taken:78528
 	picked: 104 |actions: {0: 689, 1: 741, 2: 704, 3: 894, 4: 628, 5: 743, 6: 729, 7: 781, 8: 386}
episode: 1430/2000 -> reward: 153.59895833333337, steps:6295, time-taken: 3.80min, time-elasped: 7777.60min
-> berries picked: 104 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10016 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [993, 1493, 1477, 1145, 1116, 959, 845, 794, 1194]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 17, 23, 13, 19, 8, 7, 7, 22]
	Time taken saving stuff: 0.15s

=== episode:143 Env-steps-taken:59328
 	picked: 42 |actions: {0: 896, 1: 440, 2: 456, 3: 601, 4: 60, 5: 68, 6: 16, 7: 289, 8: 216}

==================================================
eval-episode: 1430 -> reward: 56.593750000000036, steps: 3042.0, wall-time: 41.11s
-> berries picked: 42 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:1431 Env-steps-taken:67680
 	picked: 71 |actions: {0: 689, 1: 467, 2: 675, 3: 553, 4: 433, 5: 548, 6: 646, 7: 562, 8: 356}
episode: 1431/2000 -> reward: 98.9322916666666, steps:4929, time-taken: 2.81min, time-elasped: 7781.10min
-> berries picked: 71 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10032 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1002, 1499, 1484, 1140, 1117, 955, 841, 799, 1195]
	| approx positives in sample 512: 143
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 24, 13, 17, 16, 11, 16, 11, 21]
	Time taken saving stuff: 0.11s

=== episode:1432 Env-steps-taken:65088
 	picked: 63 |actions: {0: 808, 1: 592, 2: 644, 3: 1037, 4: 498, 5: 545, 6: 380, 7: 617, 8: 518}
episode: 1432/2000 -> reward: 85.39062499999996, steps:5639, time-taken: 2.83min, time-elasped: 7783.93min
-> berries picked: 63 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10022 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [998, 1500, 1482, 1136, 1118, 954, 838, 800, 1196]
	| approx positives in sample 512: 147
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 13, 30, 12, 13, 19, 16, 9, 20]
	Time taken saving stuff: 0.03s

=== episode:1433 Env-steps-taken:65664
 	picked: 67 |actions: {0: 682, 1: 674, 2: 687, 3: 847, 4: 606, 5: 458, 6: 710, 7: 968, 8: 338}
episode: 1433/2000 -> reward: 88.16145833333327, steps:5970, time-taken: 3.24min, time-elasped: 7787.18min
-> berries picked: 67 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10012 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [999, 1495, 1486, 1132, 1115, 951, 840, 802, 1192]
	| approx positives in sample 512: 161
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 21, 15, 18, 20, 22, 14, 10, 24]
	Time taken saving stuff: 0.03s

=== episode:1434 Env-steps-taken:65376
 	picked: 68 |actions: {0: 723, 1: 525, 2: 441, 3: 557, 4: 520, 5: 377, 6: 570, 7: 478, 8: 238}
episode: 1434/2000 -> reward: 86.60416666666663, steps:4429, time-taken: 2.16min, time-elasped: 7789.34min
-> berries picked: 68 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10029 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1007, 1499, 1485, 1136, 1114, 954, 842, 800, 1192]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 8, 27, 13, 17, 13, 12, 11, 22]
	Time taken saving stuff: 0.03s

=== episode:1435 Env-steps-taken:65184
 	picked: 76 |actions: {0: 855, 1: 649, 2: 554, 3: 836, 4: 616, 5: 497, 6: 748, 7: 703, 8: 406}
episode: 1435/2000 -> reward: 85.14583333333327, steps:5864, time-taken: 2.91min, time-elasped: 7792.25min
-> berries picked: 76 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10053 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1007, 1509, 1488, 1139, 1116, 956, 843, 803, 1192]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 22, 15, 12, 14, 16, 7, 17, 21]
	Time taken saving stuff: 0.01s

=== episode:1436 Env-steps-taken:65376
 	picked: 68 |actions: {0: 588, 1: 472, 2: 734, 3: 569, 4: 655, 5: 393, 6: 434, 7: 577, 8: 282}
episode: 1436/2000 -> reward: 86.60416666666663, steps:4704, time-taken: 2.78min, time-elasped: 7795.04min
-> berries picked: 68 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10053 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1008, 1508, 1489, 1134, 1118, 963, 845, 794, 1194]
	| approx positives in sample 512: 157
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 18, 25, 6, 18, 19, 17, 16, 30]
	Time taken saving stuff: 0.04s

=== episode:1437 Env-steps-taken:63360
 	picked: 56 |actions: {0: 276, 1: 526, 2: 499, 3: 498, 4: 483, 5: 329, 6: 321, 7: 359, 8: 181}
episode: 1437/2000 -> reward: 77.29166666666667, steps:3472, time-taken: 2.26min, time-elasped: 7797.30min
-> berries picked: 56 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10057 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1001, 1507, 1488, 1138, 1123, 971, 845, 789, 1195]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 20, 15, 16, 9, 16, 8, 12, 18]
	Time taken saving stuff: 0.04s

=== episode:1438 Env-steps-taken:72960
 	picked: 92 |actions: {0: 542, 1: 706, 2: 642, 3: 938, 4: 706, 5: 587, 6: 686, 7: 733, 8: 361}
episode: 1438/2000 -> reward: 123.78645833333317, steps:5901, time-taken: 2.95min, time-elasped: 7800.25min
-> berries picked: 92 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10058 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1005, 1500, 1485, 1138, 1129, 968, 847, 789, 1197]
	| approx positives in sample 512: 146
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 21, 23, 17, 15, 9, 10, 13, 19]
	Time taken saving stuff: 0.03s

=== episode:1439 Env-steps-taken:62880
 	picked: 56 |actions: {0: 485, 1: 493, 2: 456, 3: 675, 4: 454, 5: 418, 6: 529, 7: 744, 8: 258}
episode: 1439/2000 -> reward: 72.40625000000001, steps:4512, time-taken: 2.37min, time-elasped: 7802.62min
-> berries picked: 56 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10057 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1005, 1500, 1485, 1134, 1129, 969, 850, 787, 1198]
	| approx positives in sample 512: 146
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 22, 20, 12, 9, 10, 13, 20, 24]
	Time taken saving stuff: 0.09s

=== episode:1440 Env-steps-taken:74496
 	picked: 97 |actions: {0: 844, 1: 659, 2: 690, 3: 710, 4: 766, 5: 475, 6: 746, 7: 742, 8: 441}
episode: 1440/2000 -> reward: 132.9427083333332, steps:6073, time-taken: 3.19min, time-elasped: 7805.81min
-> berries picked: 97 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10069 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1007, 1503, 1488, 1133, 1132, 960, 849, 798, 1199]
	| approx positives in sample 512: 139
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 21, 18, 15, 17, 16, 12, 7, 18]
	Time taken saving stuff: 0.08s

=== episode:144 Env-steps-taken:64128
 	picked: 57 |actions: {0: 813, 1: 207, 2: 174, 3: 228, 4: 124, 5: 193, 6: 186, 7: 239, 8: 178}

==================================================
eval-episode: 1440 -> reward: 81.23437499999999, steps: 2342.0, wall-time: 39.61s
-> berries picked: 57 of 800 | patches-visited: [1, 9] | juice left:-0.00
==================================================


=== episode:1441 Env-steps-taken:64320
 	picked: 64 |actions: {0: 666, 1: 359, 2: 588, 3: 554, 4: 538, 5: 334, 6: 269, 7: 314, 8: 289}
episode: 1441/2000 -> reward: 80.39062499999996, steps:3911, time-taken: 2.33min, time-elasped: 7808.80min
-> berries picked: 64 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10074 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1005, 1509, 1490, 1135, 1130, 959, 849, 798, 1199]
	| approx positives in sample 512: 150
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 13, 23, 28, 15, 10, 7, 18, 21]
	Time taken saving stuff: 0.11s

=== episode:1442 Env-steps-taken:76608
 	picked: 102 |actions: {0: 678, 1: 724, 2: 803, 3: 667, 4: 705, 5: 642, 6: 687, 7: 666, 8: 325}
episode: 1442/2000 -> reward: 143.65624999999991, steps:5897, time-taken: 3.40min, time-elasped: 7812.21min
-> berries picked: 102 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10082 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1004, 1514, 1496, 1135, 1128, 957, 851, 799, 1198]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 21, 20, 8, 11, 15, 15, 9, 32]
	Time taken saving stuff: 0.10s

=== episode:1443 Env-steps-taken:52224
 	picked: 14 |actions: {0: 85, 1: 65, 2: 110, 3: 95, 4: 128, 5: 120, 6: 50, 7: 69, 8: 87}
episode: 1443/2000 -> reward: 21.197916666666664, steps:809, time-taken: 1.00min, time-elasped: 7813.21min
-> berries picked: 14 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10082 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1003, 1512, 1496, 1139, 1128, 957, 851, 798, 1198]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 22, 15, 19, 13, 16, 9, 10, 23]
	Time taken saving stuff: 0.01s

=== episode:1444 Env-steps-taken:61344
 	picked: 49 |actions: {0: 409, 1: 453, 2: 451, 3: 359, 4: 447, 5: 294, 6: 401, 7: 322, 8: 270}
episode: 1444/2000 -> reward: 66.69270833333336, steps:3406, time-taken: 2.16min, time-elasped: 7815.38min
-> berries picked: 49 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10077 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1000, 1511, 1495, 1136, 1127, 956, 856, 798, 1198]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 20, 28, 13, 11, 13, 9, 9, 18]
	Time taken saving stuff: 0.11s

=== episode:1445 Env-steps-taken:61440
 	picked: 54 |actions: {0: 459, 1: 379, 2: 512, 3: 571, 4: 337, 5: 350, 6: 382, 7: 454, 8: 218}
episode: 1445/2000 -> reward: 66.90625000000004, steps:3662, time-taken: 2.84min, time-elasped: 7818.22min
-> berries picked: 54 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10075 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [999, 1506, 1494, 1140, 1129, 953, 860, 796, 1198]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 24, 18, 14, 19, 17, 9, 4, 19]
	Time taken saving stuff: 0.22s

=== episode:1446 Env-steps-taken:56448
 	picked: 32 |actions: {0: 274, 1: 316, 2: 169, 3: 350, 4: 182, 5: 214, 6: 255, 7: 233, 8: 169}
episode: 1446/2000 -> reward: 42.16666666666667, steps:2162, time-taken: 1.70min, time-elasped: 7819.93min
-> berries picked: 32 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10056 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [999, 1501, 1492, 1140, 1123, 946, 860, 798, 1197]
	| approx positives in sample 512: 154
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 20, 28, 16, 18, 10, 11, 4, 34]
	Time taken saving stuff: 0.08s

=== episode:1447 Env-steps-taken:54912
 	picked: 28 |actions: {0: 209, 1: 247, 2: 240, 3: 449, 4: 241, 5: 150, 6: 163, 7: 179, 8: 247}
episode: 1447/2000 -> reward: 34.39583333333332, steps:2125, time-taken: 1.43min, time-elasped: 7821.37min
-> berries picked: 28 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10035 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [998, 1500, 1491, 1136, 1119, 940, 858, 797, 1196]
	| approx positives in sample 512: 145
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 16, 23, 17, 24, 16, 9, 6, 23]
	Time taken saving stuff: 0.02s

=== episode:1448 Env-steps-taken:70368
 	picked: 83 |actions: {0: 754, 1: 666, 2: 552, 3: 922, 4: 643, 5: 488, 6: 485, 7: 718, 8: 352}
episode: 1448/2000 -> reward: 112.8020833333332, steps:5580, time-taken: 3.02min, time-elasped: 7824.39min
-> berries picked: 83 of 800 | patches-visited: [0, 5, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10026 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1002, 1501, 1479, 1134, 1116, 940, 858, 800, 1196]
	| approx positives in sample 512: 152
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 11, 29, 17, 19, 18, 5, 15, 23]
	Time taken saving stuff: 0.08s

=== episode:1449 Env-steps-taken:70176
 	picked: 83 |actions: {0: 674, 1: 469, 2: 506, 3: 636, 4: 631, 5: 448, 6: 505, 7: 545, 8: 353}
episode: 1449/2000 -> reward: 110.35937499999989, steps:4767, time-taken: 2.56min, time-elasped: 7826.96min
-> berries picked: 83 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10015 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [995, 1497, 1486, 1133, 1120, 934, 858, 797, 1195]
	| approx positives in sample 512: 147
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 22, 19, 12, 17, 13, 9, 9, 28]
	Time taken saving stuff: 0.02s

=== episode:1450 Env-steps-taken:64512
 	picked: 56 |actions: {0: 556, 1: 503, 2: 322, 3: 436, 4: 305, 5: 271, 6: 334, 7: 399, 8: 319}
episode: 1450/2000 -> reward: 83.40624999999999, steps:3445, time-taken: 1.97min, time-elasped: 7828.93min
-> berries picked: 56 of 800 | patches-visited: [0, 2, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10014 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [996, 1498, 1482, 1134, 1118, 929, 860, 799, 1198]
	| approx positives in sample 512: 164
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 23, 22, 15, 16, 17, 17, 11, 31]
	Time taken saving stuff: 0.06s

=== episode:145 Env-steps-taken:86400
 	picked: 140 |actions: {0: 1199, 1: 803, 2: 463, 3: 1084, 4: 457, 5: 183, 6: 1143, 7: 548, 8: 232}

==================================================
eval-episode: 1450 -> reward: 192.9791666666669, steps: 6112.0, wall-time: 56.58s
-> berries picked: 140 of 800 | patches-visited: [1, 4, 7] | juice left:-0.00
==================================================


=== episode:1451 Env-steps-taken:55776
 	picked: 28 |actions: {0: 118, 1: 184, 2: 150, 3: 161, 4: 111, 5: 100, 6: 89, 7: 262, 8: 130}
episode: 1451/2000 -> reward: 38.89583333333334, steps:1305, time-taken: 1.07min, time-elasped: 7830.95min
-> berries picked: 28 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9997 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [996, 1492, 1484, 1134, 1117, 924, 852, 801, 1197]
	| approx positives in sample 512: 154
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 23, 21, 12, 12, 20, 13, 13, 25]
	Time taken saving stuff: 0.11s

=== episode:1452 Env-steps-taken:62880
 	picked: 60 |actions: {0: 488, 1: 403, 2: 531, 3: 553, 4: 428, 5: 475, 6: 382, 7: 439, 8: 258}
episode: 1452/2000 -> reward: 74.0625, steps:3957, time-taken: 2.08min, time-elasped: 7833.04min
-> berries picked: 60 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9952 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [987, 1481, 1474, 1132, 1114, 919, 854, 797, 1194]
	| approx positives in sample 512: 162
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 22, 14, 22, 22, 9, 12, 13, 30]
	Time taken saving stuff: 0.10s

=== episode:1453 Env-steps-taken:64416
 	picked: 62 |actions: {0: 639, 1: 607, 2: 646, 3: 607, 4: 482, 5: 362, 6: 412, 7: 536, 8: 378}
episode: 1453/2000 -> reward: 81.94791666666664, steps:4669, time-taken: 2.36min, time-elasped: 7835.40min
-> berries picked: 62 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9919 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [983, 1471, 1469, 1129, 1106, 914, 852, 801, 1194]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 11, 27, 18, 15, 13, 10, 11, 20]
	Time taken saving stuff: 0.10s

=== episode:1454 Env-steps-taken:57600
 	picked: 37 |actions: {0: 293, 1: 525, 2: 609, 3: 692, 4: 388, 5: 241, 6: 242, 7: 419, 8: 364}
episode: 1454/2000 -> reward: 48.38020833333336, steps:3773, time-taken: 2.18min, time-elasped: 7837.59min
-> berries picked: 37 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9897 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [981, 1468, 1468, 1131, 1103, 915, 846, 794, 1191]
	| approx positives in sample 512: 159
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 16, 16, 20, 12, 20, 13, 12, 31]
	Time taken saving stuff: 0.03s

=== episode:1455 Env-steps-taken:75360
 	picked: 96 |actions: {0: 652, 1: 721, 2: 797, 3: 1000, 4: 665, 5: 490, 6: 488, 7: 861, 8: 378}
episode: 1455/2000 -> reward: 137.99999999999994, steps:6052, time-taken: 3.39min, time-elasped: 7840.98min
-> berries picked: 96 of 800 | patches-visited: [0, 2, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9891 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [974, 1461, 1474, 1125, 1110, 913, 839, 801, 1194]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 15, 21, 11, 24, 13, 9, 11, 21]
	Time taken saving stuff: 0.02s

=== episode:1456 Env-steps-taken:66144
 	picked: 59 |actions: {0: 773, 1: 586, 2: 502, 3: 805, 4: 459, 5: 367, 6: 339, 7: 558, 8: 376}
episode: 1456/2000 -> reward: 90.17708333333327, steps:4765, time-taken: 2.68min, time-elasped: 7843.67min
-> berries picked: 59 of 800 | patches-visited: [0, 7, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9852 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [965, 1461, 1471, 1127, 1108, 914, 825, 792, 1189]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 15, 25, 14, 19, 10, 11, 7, 23]
	Time taken saving stuff: 0.06s

=== episode:1457 Env-steps-taken:51552
 	picked: 13 |actions: {0: 72, 1: 164, 2: 105, 3: 54, 4: 76, 5: 62, 6: 55, 7: 116, 8: 87}
episode: 1457/2000 -> reward: 17.755208333333336, steps:791, time-taken: 0.83min, time-elasped: 7844.50min
-> berries picked: 13 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9845 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [965, 1461, 1472, 1125, 1107, 912, 825, 791, 1187]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 16, 20, 13, 13, 13, 8, 11, 20]
	Time taken saving stuff: 0.09s

=== episode:1458 Env-steps-taken:70080
 	picked: 81 |actions: {0: 497, 1: 793, 2: 825, 3: 554, 4: 586, 5: 610, 6: 552, 7: 774, 8: 400}
episode: 1458/2000 -> reward: 110.85937499999987, steps:5591, time-taken: 3.16min, time-elasped: 7847.67min
-> berries picked: 81 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9829 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [969, 1454, 1469, 1127, 1101, 914, 827, 786, 1182]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 20, 13, 14, 12, 9, 18, 12, 25]
	Time taken saving stuff: 0.02s

=== episode:1459 Env-steps-taken:62304
 	picked: 58 |actions: {0: 444, 1: 458, 2: 513, 3: 355, 4: 414, 5: 335, 6: 275, 7: 425, 8: 265}
episode: 1459/2000 -> reward: 71.67708333333336, steps:3484, time-taken: 2.18min, time-elasped: 7849.85min
-> berries picked: 58 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9837 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [974, 1455, 1469, 1124, 1101, 915, 827, 789, 1183]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 17, 15, 15, 18, 13, 15, 12, 22]
	Time taken saving stuff: 0.11s

=== episode:1460 Env-steps-taken:61824
 	picked: 52 |actions: {0: 468, 1: 476, 2: 595, 3: 539, 4: 469, 5: 448, 6: 282, 7: 626, 8: 393}
episode: 1460/2000 -> reward: 69.52083333333336, steps:4296, time-taken: 2.58min, time-elasped: 7852.44min
-> berries picked: 52 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9829 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [975, 1452, 1468, 1124, 1105, 912, 822, 786, 1185]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 20, 13, 15, 16, 18, 6, 11, 23]
	Time taken saving stuff: 0.08s

=== episode:146 Env-steps-taken:71328
 	picked: 78 |actions: {0: 121, 1: 505, 2: 261, 3: 569, 4: 174, 5: 199, 6: 81, 7: 421, 8: 151}

==================================================
eval-episode: 1460 -> reward: 117.53124999999987, steps: 2482.0, wall-time: 49.11s
-> berries picked: 78 of 800 | patches-visited: [1, 8] | juice left:-0.00
==================================================


=== episode:1461 Env-steps-taken:61152
 	picked: 47 |actions: {0: 354, 1: 490, 2: 625, 3: 312, 4: 380, 5: 276, 6: 311, 7: 447, 8: 332}
episode: 1461/2000 -> reward: 65.8072916666667, steps:3527, time-taken: 2.36min, time-elasped: 7855.62min
-> berries picked: 47 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9828 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [980, 1453, 1471, 1124, 1104, 907, 819, 783, 1187]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 22, 17, 15, 18, 13, 17, 7, 24]
	Time taken saving stuff: 0.02s

=== episode:1462 Env-steps-taken:58176
 	picked: 34 |actions: {0: 271, 1: 334, 2: 400, 3: 215, 4: 221, 5: 197, 6: 176, 7: 292, 8: 165}
episode: 1462/2000 -> reward: 51.55208333333336, steps:2271, time-taken: 1.70min, time-elasped: 7857.33min
-> berries picked: 34 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9840 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [982, 1454, 1472, 1125, 1106, 908, 821, 786, 1186]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 11, 18, 17, 20, 11, 12, 13, 25]
	Time taken saving stuff: 0.10s

=== episode:1463 Env-steps-taken:56544
 	picked: 29 |actions: {0: 219, 1: 203, 2: 229, 3: 125, 4: 126, 5: 107, 6: 187, 7: 176, 8: 151}
episode: 1463/2000 -> reward: 42.838541666666686, steps:1523, time-taken: 1.29min, time-elasped: 7858.62min
-> berries picked: 29 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9841 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [985, 1458, 1470, 1124, 1103, 909, 820, 787, 1185]
	| approx positives in sample 512: 154
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 14, 21, 22, 25, 20, 7, 13, 19]
	Time taken saving stuff: 0.03s

=== episode:1464 Env-steps-taken:58464
 	picked: 34 |actions: {0: 142, 1: 227, 2: 142, 3: 189, 4: 212, 5: 188, 6: 204, 7: 259, 8: 104}
episode: 1464/2000 -> reward: 52.55208333333337, steps:1667, time-taken: 1.47min, time-elasped: 7860.10min
-> berries picked: 34 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9846 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [988, 1457, 1469, 1126, 1103, 911, 823, 783, 1186]
	| approx positives in sample 512: 153
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 11, 23, 11, 23, 14, 13, 15, 31]
	Time taken saving stuff: 0.10s

=== episode:1465 Env-steps-taken:73056
 	picked: 85 |actions: {0: 566, 1: 588, 2: 632, 3: 603, 4: 406, 5: 280, 6: 443, 7: 494, 8: 419}
episode: 1465/2000 -> reward: 126.63020833333319, steps:4431, time-taken: 2.79min, time-elasped: 7862.90min
-> berries picked: 85 of 800 | patches-visited: [0, 1, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9863 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [995, 1458, 1471, 1128, 1104, 907, 826, 786, 1188]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 16, 8, 18, 20, 10, 15, 11, 26]
	Time taken saving stuff: 0.00s

=== episode:1466 Env-steps-taken:59808
 	picked: 44 |actions: {0: 228, 1: 423, 2: 384, 3: 342, 4: 371, 5: 193, 6: 274, 7: 266, 8: 153}
episode: 1466/2000 -> reward: 59.97916666666671, steps:2634, time-taken: 1.71min, time-elasped: 7864.60min
-> berries picked: 44 of 800 | patches-visited: [0, 5, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9876 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [993, 1457, 1475, 1130, 1103, 907, 830, 790, 1191]
	| approx positives in sample 512: 157
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 26, 19, 13, 22, 12, 13, 12, 26]
	Time taken saving stuff: 0.09s

=== episode:1467 Env-steps-taken:64224
 	picked: 60 |actions: {0: 510, 1: 555, 2: 463, 3: 417, 4: 362, 5: 215, 6: 290, 7: 375, 8: 335}
episode: 1467/2000 -> reward: 82.0625, steps:3522, time-taken: 2.32min, time-elasped: 7866.93min
-> berries picked: 60 of 800 | patches-visited: [0, 2, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9879 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [992, 1464, 1475, 1133, 1100, 904, 826, 791, 1194]
	| approx positives in sample 512: 160
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 22, 23, 23, 16, 21, 8, 10, 21]
	Time taken saving stuff: 0.09s

=== episode:1468 Env-steps-taken:74496
 	picked: 98 |actions: {0: 697, 1: 812, 2: 691, 3: 811, 4: 695, 5: 486, 6: 642, 7: 882, 8: 422}
episode: 1468/2000 -> reward: 133.38541666666652, steps:6138, time-taken: 3.56min, time-elasped: 7870.50min
-> berries picked: 98 of 800 | patches-visited: [0, 3, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9897 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [996, 1470, 1478, 1135, 1099, 903, 832, 792, 1192]
	| approx positives in sample 512: 155
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 18, 21, 19, 15, 14, 14, 19, 21]
	Time taken saving stuff: 0.02s

=== episode:1469 Env-steps-taken:65856
 	picked: 63 |actions: {0: 480, 1: 600, 2: 528, 3: 444, 4: 479, 5: 315, 6: 457, 7: 524, 8: 258}
episode: 1469/2000 -> reward: 89.89062499999994, steps:4085, time-taken: 2.47min, time-elasped: 7872.98min
-> berries picked: 63 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9907 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [999, 1477, 1485, 1132, 1097, 902, 836, 786, 1193]
	| approx positives in sample 512: 143
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 21, 20, 10, 22, 10, 13, 14, 18]
	Time taken saving stuff: 0.02s

=== episode:1470 Env-steps-taken:65472
 	picked: 66 |actions: {0: 687, 1: 575, 2: 703, 3: 594, 4: 644, 5: 411, 6: 516, 7: 576, 8: 431}
episode: 1470/2000 -> reward: 87.71874999999996, steps:5137, time-taken: 3.09min, time-elasped: 7876.07min
-> berries picked: 66 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9892 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [995, 1481, 1481, 1123, 1095, 902, 835, 785, 1195]
	| approx positives in sample 512: 151
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 18, 18, 21, 14, 13, 18, 9, 29]
	Time taken saving stuff: 0.09s

=== episode:147 Env-steps-taken:75072
 	picked: 99 |actions: {0: 234, 1: 371, 2: 249, 3: 243, 4: 594, 5: 224, 6: 2433, 7: 613, 8: 179}

==================================================
eval-episode: 1470 -> reward: 136.32812499999986, steps: 5140.0, wall-time: 51.07s
-> berries picked: 99 of 800 | patches-visited: [1, 5, 9] | juice left:-0.00
==================================================


=== episode:1471 Env-steps-taken:64416
 	picked: 64 |actions: {0: 493, 1: 493, 2: 367, 3: 488, 4: 430, 5: 365, 6: 383, 7: 491, 8: 253}
episode: 1471/2000 -> reward: 81.83333333333333, steps:3763, time-taken: 2.41min, time-elasped: 7879.33min
-> berries picked: 64 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9875 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [987, 1478, 1475, 1121, 1093, 904, 834, 789, 1194]
	| approx positives in sample 512: 168
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 25, 27, 23, 15, 11, 19, 12, 23]
	Time taken saving stuff: 0.10s

=== episode:1472 Env-steps-taken:68160
 	picked: 70 |actions: {0: 447, 1: 596, 2: 560, 3: 520, 4: 452, 5: 402, 6: 307, 7: 619, 8: 247}
episode: 1472/2000 -> reward: 101.48958333333327, steps:4150, time-taken: 2.68min, time-elasped: 7882.02min
-> berries picked: 70 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9880 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [986, 1481, 1477, 1122, 1096, 901, 830, 790, 1197]
	| approx positives in sample 512: 159
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 16, 30, 12, 13, 13, 14, 15, 30]
	Time taken saving stuff: 0.03s

=== episode:1473 Env-steps-taken:70656
 	picked: 79 |actions: {0: 594, 1: 519, 2: 440, 3: 478, 4: 458, 5: 396, 6: 515, 7: 656, 8: 317}
episode: 1473/2000 -> reward: 112.53124999999987, steps:4373, time-taken: 2.64min, time-elasped: 7884.66min
-> berries picked: 79 of 800 | patches-visited: [0, 2, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9884 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [992, 1485, 1472, 1120, 1091, 905, 832, 787, 1200]
	| approx positives in sample 512: 146
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [23, 16, 17, 15, 18, 18, 13, 8, 18]
	Time taken saving stuff: 0.04s

=== episode:1474 Env-steps-taken:53088
 	picked: 17 |actions: {0: 145, 1: 193, 2: 203, 3: 104, 4: 77, 5: 67, 6: 79, 7: 110, 8: 81}
episode: 1474/2000 -> reward: 25.52604166666666, steps:1059, time-taken: 1.19min, time-elasped: 7885.85min
-> berries picked: 17 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9888 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [993, 1490, 1470, 1116, 1092, 906, 831, 789, 1201]
	| approx positives in sample 512: 145
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 22, 23, 12, 14, 9, 10, 15, 20]
	Time taken saving stuff: 0.10s

=== episode:1475 Env-steps-taken:64704
 	picked: 62 |actions: {0: 415, 1: 548, 2: 693, 3: 674, 4: 522, 5: 367, 6: 400, 7: 723, 8: 258}
episode: 1475/2000 -> reward: 83.44791666666663, steps:4600, time-taken: 2.65min, time-elasped: 7888.50min
-> berries picked: 62 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9878 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [988, 1494, 1473, 1114, 1096, 898, 828, 784, 1203]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 18, 22, 18, 13, 19, 11, 17, 12]
	Time taken saving stuff: 0.10s

=== episode:1476 Env-steps-taken:71136
 	picked: 82 |actions: {0: 692, 1: 567, 2: 512, 3: 564, 4: 784, 5: 582, 6: 530, 7: 742, 8: 447}
episode: 1476/2000 -> reward: 116.35937499999987, steps:5420, time-taken: 3.12min, time-elasped: 7891.63min
-> berries picked: 82 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9884 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [986, 1494, 1469, 1109, 1103, 900, 831, 790, 1202]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 21, 15, 19, 14, 16, 9, 8, 24]
	Time taken saving stuff: 0.02s

=== episode:1477 Env-steps-taken:66912
 	picked: 66 |actions: {0: 355, 1: 493, 2: 428, 3: 461, 4: 546, 5: 423, 6: 339, 7: 413, 8: 375}
episode: 1477/2000 -> reward: 95.21874999999993, steps:3833, time-taken: 2.55min, time-elasped: 7894.18min
-> berries picked: 66 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9887 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [986, 1498, 1473, 1102, 1106, 901, 830, 787, 1204]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 12, 16, 13, 22, 13, 8, 12, 26]
	Time taken saving stuff: 0.01s

=== episode:1478 Env-steps-taken:70752
 	picked: 87 |actions: {0: 662, 1: 513, 2: 507, 3: 549, 4: 588, 5: 533, 6: 683, 7: 737, 8: 401}
episode: 1478/2000 -> reward: 114.01562499999989, steps:5173, time-taken: 2.75min, time-elasped: 7896.94min
-> berries picked: 87 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9898 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [994, 1497, 1472, 1102, 1105, 906, 831, 784, 1207]
	| approx positives in sample 512: 150
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 22, 20, 15, 18, 14, 14, 7, 22]
	Time taken saving stuff: 0.11s

=== episode:1479 Env-steps-taken:66528
 	picked: 67 |actions: {0: 687, 1: 637, 2: 775, 3: 578, 4: 685, 5: 457, 6: 547, 7: 756, 8: 323}
episode: 1479/2000 -> reward: 93.16145833333327, steps:5445, time-taken: 2.77min, time-elasped: 7899.71min
-> berries picked: 67 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9914 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [991, 1507, 1474, 1105, 1106, 904, 836, 784, 1207]
	| approx positives in sample 512: 170
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 23, 20, 31, 12, 14, 14, 9, 32]
	Time taken saving stuff: 0.02s

=== episode:1480 Env-steps-taken:71040
 	picked: 78 |actions: {0: 584, 1: 684, 2: 716, 3: 737, 4: 552, 5: 432, 6: 567, 7: 618, 8: 302}
episode: 1480/2000 -> reward: 115.1458333333332, steps:5192, time-taken: 2.61min, time-elasped: 7902.33min
-> berries picked: 78 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9937 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [995, 1509, 1484, 1107, 1106, 903, 839, 785, 1209]
	| approx positives in sample 512: 162
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 18, 22, 23, 13, 14, 19, 17, 25]
	Time taken saving stuff: 0.10s

=== episode:148 Env-steps-taken:70176
 	picked: 77 |actions: {0: 1239, 1: 734, 2: 454, 3: 413, 4: 368, 5: 214, 6: 176, 7: 127, 8: 757}

==================================================
eval-episode: 1480 -> reward: 109.64583333333324, steps: 4482.0, wall-time: 61.50s
-> berries picked: 77 of 800 | patches-visited: [0, 1] | juice left:-0.00
==================================================


=== episode:1481 Env-steps-taken:71328
 	picked: 83 |actions: {0: 833, 1: 784, 2: 644, 3: 646, 4: 611, 5: 508, 6: 537, 7: 602, 8: 413}
episode: 1481/2000 -> reward: 117.24479166666654, steps:5578, time-taken: 2.94min, time-elasped: 7906.30min
-> berries picked: 83 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9948 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1003, 1511, 1484, 1105, 1106, 902, 840, 787, 1210]
	| approx positives in sample 512: 143
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 20, 13, 16, 16, 9, 10, 12, 26]
	Time taken saving stuff: 0.00s

=== episode:1482 Env-steps-taken:57120
 	picked: 29 |actions: {0: 346, 1: 324, 2: 279, 3: 209, 4: 220, 5: 137, 6: 169, 7: 183, 8: 221}
episode: 1482/2000 -> reward: 45.838541666666686, steps:2088, time-taken: 1.48min, time-elasped: 7907.78min
-> berries picked: 29 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9951 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1006, 1511, 1486, 1105, 1102, 903, 839, 788, 1211]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 15, 16, 13, 14, 10, 11, 6, 20]
	Time taken saving stuff: 0.01s

=== episode:1483 Env-steps-taken:67200
 	picked: 71 |actions: {0: 616, 1: 556, 2: 663, 3: 461, 4: 563, 5: 530, 6: 481, 7: 565, 8: 347}
episode: 1483/2000 -> reward: 96.43229166666659, steps:4782, time-taken: 2.75min, time-elasped: 7910.53min
-> berries picked: 71 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9954 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1005, 1512, 1483, 1111, 1101, 904, 840, 787, 1211]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 10, 29, 20, 14, 10, 14, 14, 18]
	Time taken saving stuff: 0.02s

=== episode:1484 Env-steps-taken:60288
 	picked: 45 |actions: {0: 243, 1: 231, 2: 313, 3: 237, 4: 233, 5: 267, 6: 222, 7: 298, 8: 182}
episode: 1484/2000 -> reward: 61.42187500000005, steps:2226, time-taken: 1.51min, time-elasped: 7912.05min
-> berries picked: 45 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9966 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1011, 1510, 1484, 1111, 1097, 908, 843, 793, 1209]
	| approx positives in sample 512: 171
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 23, 24, 16, 20, 21, 20, 10, 21]
	Time taken saving stuff: 0.09s

=== episode:1485 Env-steps-taken:73632
 	picked: 95 |actions: {0: 582, 1: 546, 2: 700, 3: 689, 4: 710, 5: 509, 6: 493, 7: 638, 8: 448}
episode: 1485/2000 -> reward: 128.5572916666665, steps:5315, time-taken: 2.94min, time-elasped: 7914.99min
-> berries picked: 95 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9968 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1011, 1510, 1486, 1113, 1103, 908, 842, 791, 1204]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 20, 21, 10, 13, 21, 3, 7, 23]
	Time taken saving stuff: 0.09s

=== episode:1486 Env-steps-taken:65760
 	picked: 61 |actions: {0: 443, 1: 609, 2: 518, 3: 440, 4: 368, 5: 269, 6: 240, 7: 287, 8: 251}
episode: 1486/2000 -> reward: 90.00520833333329, steps:3425, time-taken: 2.07min, time-elasped: 7917.07min
-> berries picked: 61 of 800 | patches-visited: [0, 8, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9975 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1011, 1520, 1488, 1112, 1103, 903, 843, 791, 1204]
	| approx positives in sample 512: 156
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 29, 21, 21, 20, 10, 9, 10, 19]
	Time taken saving stuff: 0.03s

=== episode:1487 Env-steps-taken:68064
 	picked: 78 |actions: {0: 599, 1: 673, 2: 663, 3: 568, 4: 702, 5: 633, 6: 596, 7: 697, 8: 341}
episode: 1487/2000 -> reward: 100.5312499999999, steps:5472, time-taken: 2.98min, time-elasped: 7920.05min
-> berries picked: 78 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9990 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1014, 1522, 1489, 1107, 1102, 904, 851, 797, 1204]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 19, 18, 16, 10, 13, 9, 7, 23]
	Time taken saving stuff: 0.02s

=== episode:1488 Env-steps-taken:69408
 	picked: 78 |actions: {0: 531, 1: 478, 2: 496, 3: 511, 4: 696, 5: 519, 6: 569, 7: 718, 8: 328}
episode: 1488/2000 -> reward: 107.53124999999989, steps:4846, time-taken: 2.65min, time-elasped: 7922.71min
-> berries picked: 78 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10001 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1016, 1521, 1490, 1105, 1103, 905, 857, 799, 1205]
	| approx positives in sample 512: 171
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 27, 19, 21, 17, 15, 17, 13, 24]
	Time taken saving stuff: 0.02s

=== episode:1489 Env-steps-taken:63552
 	picked: 53 |actions: {0: 479, 1: 375, 2: 363, 3: 305, 4: 241, 5: 233, 6: 374, 7: 369, 8: 236}
episode: 1489/2000 -> reward: 78.46354166666664, steps:2975, time-taken: 1.90min, time-elasped: 7924.62min
-> berries picked: 53 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10014 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1019, 1519, 1496, 1107, 1104, 904, 857, 804, 1204]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 15, 24, 14, 14, 14, 9, 16, 21]
	Time taken saving stuff: 0.02s

=== episode:1490 Env-steps-taken:58944
 	picked: 35 |actions: {0: 574, 1: 443, 2: 499, 3: 407, 4: 338, 5: 286, 6: 273, 7: 331, 8: 336}
episode: 1490/2000 -> reward: 55.4947916666667, steps:3487, time-taken: 2.04min, time-elasped: 7926.66min
-> berries picked: 35 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10006 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1023, 1519, 1494, 1104, 1103, 904, 853, 803, 1203]
	| approx positives in sample 512: 152
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 25, 16, 20, 18, 12, 20, 9, 23]
	Time taken saving stuff: 0.06s

=== episode:149 Env-steps-taken:54912
 	picked: 24 |actions: {0: 489, 1: 160, 2: 259, 3: 35, 4: 98, 5: 17, 6: 78, 7: 48, 8: 318}

==================================================
eval-episode: 1490 -> reward: 34.625, steps: 1502.0, wall-time: 41.83s
-> berries picked: 24 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:1491 Env-steps-taken:57984
 	picked: 35 |actions: {0: 397, 1: 187, 2: 151, 3: 128, 4: 155, 5: 156, 6: 214, 7: 183, 8: 94}
episode: 1491/2000 -> reward: 50.49479166666669, steps:1665, time-taken: 1.31min, time-elasped: 7928.68min
-> berries picked: 35 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10018 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1027, 1520, 1494, 1101, 1101, 906, 861, 805, 1203]
	| approx positives in sample 512: 165
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 24, 26, 11, 19, 19, 14, 18, 24]
	Time taken saving stuff: 0.10s

=== episode:1492 Env-steps-taken:71712
 	picked: 89 |actions: {0: 664, 1: 744, 2: 696, 3: 694, 4: 550, 5: 562, 6: 495, 7: 502, 8: 321}
episode: 1492/2000 -> reward: 118.9010416666665, steps:5228, time-taken: 2.91min, time-elasped: 7931.60min
-> berries picked: 89 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10024 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1033, 1519, 1494, 1103, 1094, 908, 861, 806, 1206]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 14, 24, 16, 15, 9, 10, 15, 24]
	Time taken saving stuff: 0.09s

=== episode:1493 Env-steps-taken:73152
 	picked: 91 |actions: {0: 775, 1: 503, 2: 844, 3: 574, 4: 802, 5: 737, 6: 560, 7: 871, 8: 513}
episode: 1493/2000 -> reward: 126.28645833333314, steps:6179, time-taken: 3.35min, time-elasped: 7934.95min
-> berries picked: 91 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10017 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1028, 1521, 1489, 1093, 1099, 908, 863, 810, 1206]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 20, 20, 10, 26, 12, 9, 10, 17]
	Time taken saving stuff: 0.00s

=== episode:1494 Env-steps-taken:67392
 	picked: 72 |actions: {0: 655, 1: 684, 2: 698, 3: 712, 4: 410, 5: 523, 6: 447, 7: 454, 8: 291}
episode: 1494/2000 -> reward: 97.37499999999991, steps:4874, time-taken: 2.52min, time-elasped: 7937.48min
-> berries picked: 72 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10008 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1028, 1522, 1488, 1090, 1095, 906, 856, 814, 1209]
	| approx positives in sample 512: 151
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 18, 14, 21, 22, 15, 17, 7, 22]
	Time taken saving stuff: 0.04s

=== episode:1495 Env-steps-taken:74496
 	picked: 100 |actions: {0: 781, 1: 729, 2: 712, 3: 744, 4: 667, 5: 584, 6: 619, 7: 737, 8: 364}
episode: 1495/2000 -> reward: 132.77083333333317, steps:5937, time-taken: 3.17min, time-elasped: 7940.65min
-> berries picked: 100 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10021 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1035, 1523, 1489, 1086, 1091, 912, 859, 816, 1210]
	| approx positives in sample 512: 146
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 24, 22, 17, 20, 11, 12, 11, 20]
	Time taken saving stuff: 0.03s

=== episode:1496 Env-steps-taken:68160
 	picked: 74 |actions: {0: 622, 1: 565, 2: 667, 3: 644, 4: 529, 5: 491, 6: 435, 7: 538, 8: 310}
episode: 1496/2000 -> reward: 101.26041666666654, steps:4801, time-taken: 2.71min, time-elasped: 7943.37min
-> berries picked: 74 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10011 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1031, 1521, 1490, 1089, 1091, 909, 855, 817, 1208]
	| approx positives in sample 512: 157
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 21, 25, 17, 15, 16, 11, 10, 26]
	Time taken saving stuff: 0.10s

=== episode:1497 Env-steps-taken:55104
 	picked: 24 |actions: {0: 218, 1: 162, 2: 154, 3: 197, 4: 151, 5: 190, 6: 174, 7: 139, 8: 134}
episode: 1497/2000 -> reward: 35.625, steps:1519, time-taken: 1.15min, time-elasped: 7944.52min
-> berries picked: 24 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10018 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1031, 1521, 1489, 1093, 1092, 907, 862, 816, 1207]
	| approx positives in sample 512: 178
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 25, 20, 13, 17, 24, 10, 25, 26]
	Time taken saving stuff: 0.03s

=== episode:1498 Env-steps-taken:72096
 	picked: 84 |actions: {0: 723, 1: 703, 2: 727, 3: 795, 4: 797, 5: 629, 6: 429, 7: 860, 8: 444}
episode: 1498/2000 -> reward: 121.18749999999986, steps:6107, time-taken: 3.38min, time-elasped: 7947.90min
-> berries picked: 84 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10031 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1037, 1517, 1492, 1095, 1095, 907, 862, 817, 1209]
	| approx positives in sample 512: 158
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 22, 17, 20, 14, 11, 17, 15, 24]
	Time taken saving stuff: 0.10s

=== episode:1499 Env-steps-taken:66144
 	picked: 66 |actions: {0: 526, 1: 545, 2: 416, 3: 449, 4: 439, 5: 350, 6: 318, 7: 501, 8: 221}
episode: 1499/2000 -> reward: 91.71874999999997, steps:3765, time-taken: 2.20min, time-elasped: 7950.10min
-> berries picked: 66 of 800 | patches-visited: [0, 4, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10047 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1042, 1517, 1492, 1094, 1094, 909, 865, 824, 1210]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 16, 20, 12, 15, 21, 10, 13, 23]
	Time taken saving stuff: 0.04s

=== episode:1500 Env-steps-taken:67776
 	picked: 73 |actions: {0: 704, 1: 782, 2: 590, 3: 643, 4: 613, 5: 557, 6: 462, 7: 627, 8: 277}
episode: 1500/2000 -> reward: 99.31770833333324, steps:5255, time-taken: 2.93min, time-elasped: 7953.04min
-> berries picked: 73 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10039 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1041, 1515, 1494, 1095, 1089, 905, 866, 823, 1211]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 13, 18, 18, 19, 14, 10, 6, 28]
	Time taken saving stuff: 0.16s

=== episode:150 Env-steps-taken:61920
 	picked: 49 |actions: {0: 305, 1: 568, 2: 249, 3: 332, 4: 125, 5: 154, 6: 118, 7: 130, 8: 502}

==================================================
eval-episode: 1500 -> reward: 68.8072916666667, steps: 2483.0, wall-time: 48.13s
-> berries picked: 49 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:1501 Env-steps-taken:75264
 	picked: 96 |actions: {0: 844, 1: 613, 2: 729, 3: 846, 4: 713, 5: 614, 6: 495, 7: 692, 8: 354}
episode: 1501/2000 -> reward: 136.61458333333323, steps:5900, time-taken: 3.62min, time-elasped: 7957.47min
-> berries picked: 96 of 800 | patches-visited: [0, 3, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10057 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1046, 1520, 1495, 1095, 1085, 908, 868, 826, 1214]
	| approx positives in sample 512: 146
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 13, 17, 16, 19, 13, 18, 10, 25]
	Time taken saving stuff: 0.11s

=== episode:1502 Env-steps-taken:64608
 	picked: 68 |actions: {0: 362, 1: 389, 2: 604, 3: 469, 4: 533, 5: 388, 6: 374, 7: 446, 8: 236}
episode: 1502/2000 -> reward: 82.60416666666664, steps:3801, time-taken: 2.51min, time-elasped: 7959.98min
-> berries picked: 68 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10056 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1048, 1520, 1492, 1101, 1086, 906, 867, 825, 1211]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 20, 17, 13, 15, 8, 10, 20, 24]
	Time taken saving stuff: 0.10s

=== episode:1503 Env-steps-taken:73152
 	picked: 100 |actions: {0: 743, 1: 736, 2: 770, 3: 747, 4: 780, 5: 535, 6: 662, 7: 914, 8: 386}
episode: 1503/2000 -> reward: 123.82812499999983, steps:6273, time-taken: 3.25min, time-elasped: 7963.23min
-> berries picked: 100 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10072 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1050, 1526, 1493, 1100, 1091, 913, 862, 828, 1209]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 11, 24, 18, 12, 14, 19, 10, 21]
	Time taken saving stuff: 0.10s

=== episode:1504 Env-steps-taken:71232
 	picked: 88 |actions: {0: 748, 1: 586, 2: 484, 3: 665, 4: 708, 5: 575, 6: 638, 7: 593, 8: 327}
episode: 1504/2000 -> reward: 116.45833333333317, steps:5324, time-taken: 3.03min, time-elasped: 7966.27min
-> berries picked: 88 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10084 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1053, 1525, 1487, 1094, 1095, 921, 867, 835, 1207]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 25, 15, 14, 21, 16, 15, 4, 23]
	Time taken saving stuff: 0.07s

=== episode:1505 Env-steps-taken:67392
 	picked: 77 |actions: {0: 650, 1: 442, 2: 632, 3: 563, 4: 491, 5: 451, 6: 395, 7: 534, 8: 321}
episode: 1505/2000 -> reward: 93.31770833333327, steps:4479, time-taken: 2.84min, time-elasped: 7969.11min
-> berries picked: 77 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10090 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1056, 1525, 1482, 1093, 1093, 930, 870, 832, 1209]
	| approx positives in sample 512: 146
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 15, 20, 24, 21, 9, 10, 14, 19]
	Time taken saving stuff: 0.10s

=== episode:1506 Env-steps-taken:73440
 	picked: 92 |actions: {0: 799, 1: 546, 2: 606, 3: 816, 4: 606, 5: 765, 6: 596, 7: 706, 8: 356}
episode: 1506/2000 -> reward: 127.72916666666649, steps:5796, time-taken: 3.07min, time-elasped: 7972.18min
-> berries picked: 92 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10086 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1056, 1521, 1482, 1102, 1092, 919, 870, 836, 1208]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 24, 14, 14, 15, 9, 9, 6, 18]
	Time taken saving stuff: 0.10s

=== episode:1507 Env-steps-taken:74688
 	picked: 101 |actions: {0: 756, 1: 650, 2: 803, 3: 657, 4: 711, 5: 498, 6: 529, 7: 713, 8: 332}
episode: 1507/2000 -> reward: 133.71354166666652, steps:5649, time-taken: 3.38min, time-elasped: 7975.57min
-> berries picked: 101 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10109 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1057, 1526, 1488, 1106, 1096, 915, 876, 835, 1210]
	| approx positives in sample 512: 154
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 24, 20, 22, 16, 9, 18, 8, 26]
	Time taken saving stuff: 0.09s

=== episode:1508 Env-steps-taken:70944
 	picked: 88 |actions: {0: 631, 1: 554, 2: 556, 3: 676, 4: 565, 5: 644, 6: 450, 7: 532, 8: 310}
episode: 1508/2000 -> reward: 112.63020833333321, steps:4918, time-taken: 2.66min, time-elasped: 7978.23min
-> berries picked: 88 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10127 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1060, 1533, 1486, 1110, 1097, 914, 878, 840, 1209]
	| approx positives in sample 512: 162
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 28, 24, 17, 10, 13, 20, 10, 25]
	Time taken saving stuff: 0.11s

=== episode:1509 Env-steps-taken:74016
 	picked: 96 |actions: {0: 827, 1: 611, 2: 632, 3: 982, 4: 752, 5: 648, 6: 607, 7: 925, 8: 409}
episode: 1509/2000 -> reward: 130.49999999999983, steps:6393, time-taken: 3.13min, time-elasped: 7981.37min
-> berries picked: 96 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10138 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1061, 1531, 1494, 1108, 1098, 912, 882, 841, 1211]
	| approx positives in sample 512: 147
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 13, 23, 13, 14, 17, 20, 11, 20]
	Time taken saving stuff: 0.04s

=== episode:1510 Env-steps-taken:61440
 	picked: 47 |actions: {0: 428, 1: 612, 2: 535, 3: 412, 4: 389, 5: 313, 6: 212, 7: 235, 8: 245}
episode: 1510/2000 -> reward: 67.8072916666667, steps:3381, time-taken: 1.96min, time-elasped: 7983.33min
-> berries picked: 47 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10141 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1059, 1534, 1500, 1107, 1098, 913, 878, 839, 1213]
	| approx positives in sample 512: 160
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 19, 15, 14, 19, 16, 22, 12, 25]
	Time taken saving stuff: 0.08s

=== episode:151 Env-steps-taken:64416
 	picked: 58 |actions: {0: 601, 1: 232, 2: 158, 3: 280, 4: 46, 5: 95, 6: 164, 7: 138, 8: 81}

==================================================
eval-episode: 1510 -> reward: 82.67708333333331, steps: 1795.0, wall-time: 43.72s
-> berries picked: 58 of 800 | patches-visited: [1, 5] | juice left:-0.00
==================================================


=== episode:1511 Env-steps-taken:64416
 	picked: 63 |actions: {0: 492, 1: 376, 2: 509, 3: 559, 4: 360, 5: 455, 6: 361, 7: 480, 8: 196}
episode: 1511/2000 -> reward: 81.89062499999996, steps:3788, time-taken: 2.07min, time-elasped: 7986.13min
-> berries picked: 63 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10151 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1061, 1533, 1502, 1110, 1098, 917, 874, 843, 1213]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 16, 20, 11, 17, 11, 11, 14, 16]
	Time taken saving stuff: 0.02s

=== episode:1512 Env-steps-taken:62208
 	picked: 53 |actions: {0: 799, 1: 529, 2: 511, 3: 768, 4: 484, 5: 479, 6: 470, 7: 735, 8: 299}
episode: 1512/2000 -> reward: 70.96354166666669, steps:5074, time-taken: 3.50min, time-elasped: 7989.63min
-> berries picked: 53 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10145 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1058, 1535, 1501, 1103, 1093, 923, 877, 840, 1215]
	| approx positives in sample 512: 156
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 19, 14, 20, 19, 11, 16, 14, 24]
	Time taken saving stuff: 0.02s

=== episode:1513 Env-steps-taken:72864
 	picked: 84 |actions: {0: 677, 1: 669, 2: 620, 3: 684, 4: 450, 5: 453, 6: 426, 7: 586, 8: 307}
episode: 1513/2000 -> reward: 125.18749999999983, steps:4872, time-taken: 2.56min, time-elasped: 7992.20min
-> berries picked: 84 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10148 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1054, 1533, 1502, 1106, 1095, 922, 881, 840, 1215]
	| approx positives in sample 512: 157
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 22, 16, 15, 22, 15, 18, 11, 24]
	Time taken saving stuff: 0.03s

=== episode:1514 Env-steps-taken:72096
 	picked: 85 |actions: {0: 970, 1: 705, 2: 603, 3: 852, 4: 609, 5: 570, 6: 553, 7: 776, 8: 372}
episode: 1514/2000 -> reward: 121.13020833333316, steps:6010, time-taken: 3.18min, time-elasped: 7995.38min
-> berries picked: 85 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10136 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1053, 1539, 1498, 1104, 1087, 920, 878, 843, 1214]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 18, 20, 14, 21, 16, 10, 8, 19]
	Time taken saving stuff: 0.10s

=== episode:1515 Env-steps-taken:72864
 	picked: 93 |actions: {0: 776, 1: 606, 2: 688, 3: 766, 4: 908, 5: 604, 6: 542, 7: 822, 8: 345}
episode: 1515/2000 -> reward: 124.67187499999983, steps:6057, time-taken: 3.34min, time-elasped: 7998.73min
-> berries picked: 93 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10160 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1057, 1538, 1506, 1107, 1089, 926, 872, 850, 1215]
	| approx positives in sample 512: 152
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 24, 25, 12, 14, 16, 17, 7, 26]
	Time taken saving stuff: 0.03s

=== episode:1516 Env-steps-taken:73152
 	picked: 88 |actions: {0: 568, 1: 586, 2: 623, 3: 777, 4: 657, 5: 498, 6: 516, 7: 727, 8: 354}
episode: 1516/2000 -> reward: 126.45833333333317, steps:5306, time-taken: 2.86min, time-elasped: 8001.59min
-> berries picked: 88 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10158 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1065, 1534, 1510, 1112, 1086, 916, 869, 850, 1216]
	| approx positives in sample 512: 156
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 21, 19, 12, 17, 19, 13, 15, 25]
	Time taken saving stuff: 0.02s

=== episode:1517 Env-steps-taken:69888
 	picked: 85 |actions: {0: 797, 1: 705, 2: 612, 3: 708, 4: 439, 5: 471, 6: 437, 7: 562, 8: 302}
episode: 1517/2000 -> reward: 109.63020833333321, steps:5033, time-taken: 2.86min, time-elasped: 8004.46min
-> berries picked: 85 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10165 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1065, 1539, 1516, 1107, 1086, 913, 869, 853, 1217]
	| approx positives in sample 512: 151
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 22, 16, 13, 18, 12, 12, 9, 31]
	Time taken saving stuff: 0.10s

=== episode:1518 Env-steps-taken:74496
 	picked: 94 |actions: {0: 744, 1: 566, 2: 557, 3: 724, 4: 484, 5: 540, 6: 477, 7: 726, 8: 285}
episode: 1518/2000 -> reward: 133.61458333333317, steps:5103, time-taken: 3.30min, time-elasped: 8007.77min
-> berries picked: 94 of 800 | patches-visited: [0, 5, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10183 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1059, 1538, 1524, 1107, 1084, 922, 875, 852, 1222]
	| approx positives in sample 512: 155
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 27, 33, 14, 15, 15, 8, 11, 18]
	Time taken saving stuff: 0.03s

=== episode:1519 Env-steps-taken:65472
 	picked: 66 |actions: {0: 653, 1: 523, 2: 552, 3: 816, 4: 523, 5: 453, 6: 468, 7: 887, 8: 283}
episode: 1519/2000 -> reward: 87.77604166666663, steps:5158, time-taken: 3.14min, time-elasped: 8010.92min
-> berries picked: 66 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10186 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1062, 1538, 1521, 1112, 1081, 921, 877, 855, 1219]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 23, 19, 14, 18, 5, 10, 11, 22]
	Time taken saving stuff: 0.02s

=== episode:1520 Env-steps-taken:74688
 	picked: 101 |actions: {0: 880, 1: 725, 2: 726, 3: 937, 4: 784, 5: 605, 6: 601, 7: 643, 8: 368}
episode: 1520/2000 -> reward: 133.71354166666654, steps:6269, time-taken: 3.70min, time-elasped: 8014.61min
-> berries picked: 101 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10202 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1062, 1540, 1519, 1113, 1086, 928, 881, 852, 1221]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 26, 17, 10, 15, 14, 15, 13, 18]
	Time taken saving stuff: 0.11s

=== episode:152 Env-steps-taken:62976
 	picked: 54 |actions: {0: 246, 1: 539, 2: 161, 3: 1616, 4: 109, 5: 90, 6: 33, 7: 1670, 8: 149}

==================================================
eval-episode: 1520 -> reward: 75.40625000000001, steps: 4613.0, wall-time: 54.87s
-> berries picked: 54 of 800 | patches-visited: [1, 6] | juice left:-0.00
==================================================


=== episode:1521 Env-steps-taken:71424
 	picked: 87 |actions: {0: 690, 1: 524, 2: 684, 3: 536, 4: 568, 5: 522, 6: 545, 7: 591, 8: 314}
episode: 1521/2000 -> reward: 117.51562499999986, steps:4974, time-taken: 2.98min, time-elasped: 8018.51min
-> berries picked: 87 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10218 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1065, 1545, 1523, 1119, 1083, 928, 884, 849, 1222]
	| approx positives in sample 512: 156
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 20, 22, 21, 18, 16, 12, 13, 22]
	Time taken saving stuff: 0.09s

=== episode:1522 Env-steps-taken:68928
 	picked: 80 |actions: {0: 811, 1: 554, 2: 542, 3: 655, 4: 413, 5: 409, 6: 445, 7: 604, 8: 263}
episode: 1522/2000 -> reward: 105.41666666666656, steps:4696, time-taken: 3.30min, time-elasped: 8021.82min
-> berries picked: 80 of 800 | patches-visited: [0, 3, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10232 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1068, 1550, 1532, 1119, 1075, 926, 886, 850, 1226]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 21, 22, 12, 24, 13, 10, 6, 13]
	Time taken saving stuff: 0.01s

=== episode:1523 Env-steps-taken:67008
 	picked: 69 |actions: {0: 883, 1: 677, 2: 690, 3: 747, 4: 556, 5: 626, 6: 534, 7: 874, 8: 368}
episode: 1523/2000 -> reward: 95.04687499999994, steps:5955, time-taken: 3.37min, time-elasped: 8025.19min
-> berries picked: 69 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10231 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1064, 1547, 1537, 1118, 1072, 927, 887, 850, 1229]
	| approx positives in sample 512: 143
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 17, 18, 13, 17, 15, 10, 10, 27]
	Time taken saving stuff: 0.07s

=== episode:1524 Env-steps-taken:59328
 	picked: 41 |actions: {0: 349, 1: 394, 2: 338, 3: 419, 4: 341, 5: 293, 6: 266, 7: 480, 8: 237}
episode: 1524/2000 -> reward: 56.65104166666671, steps:3117, time-taken: 1.85min, time-elasped: 8027.06min
-> berries picked: 41 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10240 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1064, 1550, 1542, 1116, 1070, 926, 886, 857, 1229]
	| approx positives in sample 512: 139
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 10, 11, 10, 17, 22, 13, 15, 25]
	Time taken saving stuff: 0.08s

=== episode:1525 Env-steps-taken:67104
 	picked: 72 |actions: {0: 708, 1: 521, 2: 543, 3: 545, 4: 543, 5: 508, 6: 434, 7: 635, 8: 354}
episode: 1525/2000 -> reward: 95.8749999999999, steps:4791, time-taken: 2.68min, time-elasped: 8029.74min
-> berries picked: 72 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10261 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1067, 1553, 1546, 1117, 1071, 929, 888, 861, 1229]
	| approx positives in sample 512: 145
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 14, 21, 16, 14, 15, 7, 16, 20]
	Time taken saving stuff: 0.09s

=== episode:1526 Env-steps-taken:65088
 	picked: 71 |actions: {0: 658, 1: 573, 2: 613, 3: 608, 4: 496, 5: 568, 6: 656, 7: 734, 8: 342}
episode: 1526/2000 -> reward: 84.93229166666661, steps:5248, time-taken: 2.92min, time-elasped: 8032.67min
-> berries picked: 71 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10240 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1069, 1560, 1535, 1117, 1067, 929, 883, 853, 1227]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 16, 24, 16, 19, 12, 13, 11, 16]
	Time taken saving stuff: 0.02s

=== episode:1527 Env-steps-taken:67296
 	picked: 66 |actions: {0: 491, 1: 512, 2: 505, 3: 565, 4: 417, 5: 463, 6: 367, 7: 617, 8: 224}
episode: 1527/2000 -> reward: 97.21874999999994, steps:4161, time-taken: 2.51min, time-elasped: 8035.18min
-> berries picked: 66 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10240 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1069, 1559, 1536, 1122, 1063, 928, 883, 852, 1228]
	| approx positives in sample 512: 158
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 19, 21, 7, 23, 16, 15, 16, 26]
	Time taken saving stuff: 0.03s

=== episode:1528 Env-steps-taken:64896
 	picked: 71 |actions: {0: 634, 1: 368, 2: 413, 3: 805, 4: 518, 5: 571, 6: 522, 7: 685, 8: 288}
episode: 1528/2000 -> reward: 83.54687499999996, steps:4804, time-taken: 2.46min, time-elasped: 8037.65min
-> berries picked: 71 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10235 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1068, 1567, 1533, 1116, 1068, 930, 874, 852, 1227]
	| approx positives in sample 512: 155
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 26, 11, 13, 21, 20, 9, 12, 22]
	Time taken saving stuff: 0.11s

=== episode:1529 Env-steps-taken:66336
 	picked: 76 |actions: {0: 1071, 1: 587, 2: 757, 3: 635, 4: 549, 5: 638, 6: 438, 7: 627, 8: 325}
episode: 1529/2000 -> reward: 89.7604166666666, steps:5627, time-taken: 2.97min, time-elasped: 8040.62min
-> berries picked: 76 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10231 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1065, 1568, 1533, 1113, 1068, 933, 872, 849, 1230]
	| approx positives in sample 512: 139
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 18, 13, 14, 20, 14, 13, 9, 26]
	Time taken saving stuff: 0.09s

=== episode:1530 Env-steps-taken:63552
 	picked: 59 |actions: {0: 482, 1: 351, 2: 276, 3: 289, 4: 316, 5: 312, 6: 316, 7: 303, 8: 147}
episode: 1530/2000 -> reward: 78.11979166666666, steps:2792, time-taken: 1.74min, time-elasped: 8042.37min
-> berries picked: 59 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10244 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1066, 1572, 1534, 1112, 1069, 931, 877, 853, 1230]
	| approx positives in sample 512: 149
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 22, 20, 13, 10, 14, 12, 14, 24]
	Time taken saving stuff: 0.15s

=== episode:153 Env-steps-taken:71712
 	picked: 89 |actions: {0: 2892, 1: 235, 2: 501, 3: 199, 4: 233, 5: 385, 6: 175, 7: 776, 8: 11}

==================================================
eval-episode: 1530 -> reward: 118.90104166666652, steps: 5407.0, wall-time: 50.04s
-> berries picked: 89 of 800 | patches-visited: [1, 7] | juice left:-0.00
==================================================


=== episode:1531 Env-steps-taken:64992
 	picked: 61 |actions: {0: 776, 1: 448, 2: 466, 3: 463, 4: 405, 5: 437, 6: 502, 7: 532, 8: 251}
episode: 1531/2000 -> reward: 85.50520833333331, steps:4280, time-taken: 2.31min, time-elasped: 8045.52min
-> berries picked: 61 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10235 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1071, 1574, 1532, 1110, 1065, 932, 876, 845, 1230]
	| approx positives in sample 512: 145
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 18, 23, 17, 14, 13, 9, 7, 25]
	Time taken saving stuff: 0.03s

=== episode:1532 Env-steps-taken:72960
 	picked: 90 |actions: {0: 846, 1: 626, 2: 721, 3: 701, 4: 717, 5: 712, 6: 537, 7: 606, 8: 305}
episode: 1532/2000 -> reward: 125.34374999999986, steps:5771, time-taken: 3.13min, time-elasped: 8048.66min
-> berries picked: 90 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10235 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1069, 1576, 1532, 1111, 1074, 927, 880, 839, 1227]
	| approx positives in sample 512: 156
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 27, 21, 14, 18, 14, 11, 13, 23]
	Time taken saving stuff: 0.03s

=== episode:1533 Env-steps-taken:58944
 	picked: 45 |actions: {0: 441, 1: 388, 2: 313, 3: 427, 4: 409, 5: 473, 6: 214, 7: 353, 8: 195}
episode: 1533/2000 -> reward: 53.53645833333337, steps:3213, time-taken: 1.80min, time-elasped: 8050.46min
-> berries picked: 45 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10230 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1068, 1576, 1532, 1109, 1077, 927, 874, 838, 1229]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 19, 17, 13, 18, 7, 10, 17, 16]
	Time taken saving stuff: 0.01s

=== episode:1534 Env-steps-taken:69504
 	picked: 78 |actions: {0: 666, 1: 606, 2: 472, 3: 476, 4: 560, 5: 496, 6: 440, 7: 490, 8: 266}
episode: 1534/2000 -> reward: 108.0312499999999, steps:4472, time-taken: 2.49min, time-elasped: 8052.95min
-> berries picked: 78 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10262 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1069, 1581, 1538, 1113, 1087, 930, 875, 841, 1228]
	| approx positives in sample 512: 159
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 19, 24, 12, 16, 16, 12, 13, 31]
	Time taken saving stuff: 0.02s

=== episode:1535 Env-steps-taken:56832
 	picked: 36 |actions: {0: 297, 1: 450, 2: 193, 3: 252, 4: 205, 5: 270, 6: 345, 7: 352, 8: 160}
episode: 1535/2000 -> reward: 44.43750000000002, steps:2524, time-taken: 1.64min, time-elasped: 8054.60min
-> berries picked: 36 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10274 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1075, 1582, 1538, 1110, 1089, 931, 874, 844, 1231]
	| approx positives in sample 512: 163
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 24, 22, 23, 19, 14, 18, 8, 22]
	Time taken saving stuff: 0.11s

=== episode:1536 Env-steps-taken:69408
 	picked: 84 |actions: {0: 465, 1: 423, 2: 473, 3: 646, 4: 637, 5: 698, 6: 485, 7: 773, 8: 324}
episode: 1536/2000 -> reward: 107.18749999999989, steps:4924, time-taken: 2.79min, time-elasped: 8057.39min
-> berries picked: 84 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10265 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1069, 1581, 1532, 1114, 1090, 929, 878, 840, 1232]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 25, 18, 17, 16, 6, 7, 8, 25]
	Time taken saving stuff: 0.01s

=== episode:1537 Env-steps-taken:74592
 	picked: 97 |actions: {0: 732, 1: 793, 2: 676, 3: 800, 4: 735, 5: 931, 6: 536, 7: 797, 8: 437}
episode: 1537/2000 -> reward: 133.4427083333332, steps:6437, time-taken: 3.34min, time-elasped: 8060.73min
-> berries picked: 97 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10256 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1071, 1578, 1529, 1117, 1083, 929, 878, 840, 1231]
	| approx positives in sample 512: 157
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 14, 18, 27, 14, 10, 22, 11, 24]
	Time taken saving stuff: 0.08s

=== episode:1538 Env-steps-taken:78048
 	picked: 117 |actions: {0: 622, 1: 843, 2: 852, 3: 852, 4: 812, 5: 923, 6: 729, 7: 716, 8: 366}
episode: 1538/2000 -> reward: 149.41145833333331, steps:6715, time-taken: 3.72min, time-elasped: 8064.45min
-> berries picked: 117 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10263 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1067, 1578, 1526, 1117, 1087, 932, 884, 842, 1230]
	| approx positives in sample 512: 158
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 19, 28, 14, 17, 12, 10, 18, 27]
	Time taken saving stuff: 0.09s

=== episode:1539 Env-steps-taken:75936
 	picked: 103 |actions: {0: 808, 1: 787, 2: 795, 3: 662, 4: 701, 5: 752, 6: 623, 7: 822, 8: 427}
episode: 1539/2000 -> reward: 140.09895833333326, steps:6377, time-taken: 3.89min, time-elasped: 8068.35min
-> berries picked: 103 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10261 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1072, 1579, 1526, 1113, 1088, 932, 882, 840, 1229]
	| approx positives in sample 512: 143
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 16, 17, 24, 12, 13, 11, 12, 19]
	Time taken saving stuff: 0.09s

=== episode:1540 Env-steps-taken:65088
 	picked: 63 |actions: {0: 640, 1: 688, 2: 492, 3: 442, 4: 596, 5: 504, 6: 407, 7: 483, 8: 280}
episode: 1540/2000 -> reward: 86.39062499999996, steps:4532, time-taken: 3.32min, time-elasped: 8071.67min
-> berries picked: 63 of 800 | patches-visited: [0, 6, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10257 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1074, 1581, 1525, 1107, 1084, 928, 888, 839, 1231]
	| approx positives in sample 512: 155
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 19, 10, 19, 18, 10, 17, 15, 30]
	Time taken saving stuff: 0.09s

=== episode:154 Env-steps-taken:76320
 	picked: 105 |actions: {0: 216, 1: 2457, 2: 255, 3: 483, 4: 344, 5: 1611, 6: 115, 7: 822, 8: 242}

==================================================
eval-episode: 1540 -> reward: 141.98437499999997, steps: 6545.0, wall-time: 76.42s
-> berries picked: 105 of 800 | patches-visited: [1, 4] | juice left:-0.00
==================================================


=== episode:1541 Env-steps-taken:64224
 	picked: 62 |actions: {0: 491, 1: 485, 2: 593, 3: 636, 4: 392, 5: 439, 6: 404, 7: 523, 8: 238}
episode: 1541/2000 -> reward: 80.56249999999999, steps:4201, time-taken: 3.11min, time-elasped: 8076.05min
-> berries picked: 62 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10224 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1076, 1581, 1522, 1110, 1069, 919, 883, 833, 1231]
	| approx positives in sample 512: 182
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 23, 27, 13, 26, 18, 15, 15, 33]
	Time taken saving stuff: 0.01s

=== episode:1542 Env-steps-taken:60960
 	picked: 48 |actions: {0: 475, 1: 428, 2: 576, 3: 430, 4: 394, 5: 432, 6: 405, 7: 378, 8: 224}
episode: 1542/2000 -> reward: 64.75000000000006, steps:3742, time-taken: 2.91min, time-elasped: 8078.97min
-> berries picked: 48 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10221 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1069, 1583, 1526, 1113, 1066, 922, 879, 834, 1229]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 20, 20, 12, 21, 11, 12, 14, 21]
	Time taken saving stuff: 0.01s

=== episode:1543 Env-steps-taken:66144
 	picked: 64 |actions: {0: 498, 1: 462, 2: 498, 3: 661, 4: 475, 5: 515, 6: 439, 7: 399, 8: 258}
episode: 1543/2000 -> reward: 91.33333333333331, steps:4205, time-taken: 3.17min, time-elasped: 8082.15min
-> berries picked: 64 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10229 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1068, 1585, 1527, 1115, 1072, 922, 875, 836, 1229]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 17, 18, 15, 12, 13, 12, 19, 23]
	Time taken saving stuff: 0.01s

=== episode:1544 Env-steps-taken:65472
 	picked: 66 |actions: {0: 821, 1: 592, 2: 747, 3: 870, 4: 564, 5: 566, 6: 492, 7: 842, 8: 381}
episode: 1544/2000 -> reward: 87.21874999999996, steps:5875, time-taken: 3.62min, time-elasped: 8085.77min
-> berries picked: 66 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10196 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1070, 1589, 1519, 1115, 1068, 914, 863, 834, 1224]
	| approx positives in sample 512: 145
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 22, 15, 10, 23, 13, 13, 11, 29]
	Time taken saving stuff: 0.01s

=== episode:1545 Env-steps-taken:63648
 	picked: 58 |actions: {0: 631, 1: 493, 2: 486, 3: 717, 4: 448, 5: 384, 6: 457, 7: 358, 8: 244}
episode: 1545/2000 -> reward: 78.17708333333333, steps:4218, time-taken: 2.95min, time-elasped: 8088.73min
-> berries picked: 58 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10196 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1068, 1586, 1519, 1119, 1071, 913, 865, 831, 1224]
	| approx positives in sample 512: 149
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 20, 22, 16, 10, 17, 19, 11, 23]
	Time taken saving stuff: 0.00s

=== episode:1546 Env-steps-taken:67392
 	picked: 77 |actions: {0: 630, 1: 738, 2: 695, 3: 755, 4: 622, 5: 629, 6: 482, 7: 674, 8: 371}
episode: 1546/2000 -> reward: 97.08854166666661, steps:5596, time-taken: 3.53min, time-elasped: 8092.27min
-> berries picked: 77 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10202 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1074, 1594, 1520, 1121, 1063, 904, 869, 832, 1225]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 25, 16, 11, 10, 6, 11, 10, 21]
	Time taken saving stuff: 0.01s

=== episode:1547 Env-steps-taken:66144
 	picked: 60 |actions: {0: 405, 1: 524, 2: 427, 3: 464, 4: 342, 5: 404, 6: 363, 7: 312, 8: 222}
episode: 1547/2000 -> reward: 91.56249999999996, steps:3463, time-taken: 2.18min, time-elasped: 8094.44min
-> berries picked: 60 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10213 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1076, 1595, 1517, 1123, 1064, 910, 870, 831, 1227]
	| approx positives in sample 512: 152
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [23, 20, 16, 12, 17, 12, 14, 15, 23]
	Time taken saving stuff: 0.00s

=== episode:1548 Env-steps-taken:74208
 	picked: 96 |actions: {0: 763, 1: 556, 2: 673, 3: 654, 4: 823, 5: 553, 6: 614, 7: 561, 8: 344}
episode: 1548/2000 -> reward: 131.49999999999983, steps:5541, time-taken: 3.45min, time-elasped: 8097.90min
-> berries picked: 96 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10215 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1076, 1597, 1520, 1117, 1066, 913, 871, 826, 1229]
	| approx positives in sample 512: 152
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 12, 19, 19, 20, 12, 11, 18, 22]
	Time taken saving stuff: 0.01s

=== episode:1549 Env-steps-taken:64416
 	picked: 61 |actions: {0: 434, 1: 504, 2: 495, 3: 490, 4: 580, 5: 286, 6: 485, 7: 501, 8: 229}
episode: 1549/2000 -> reward: 82.50520833333331, steps:4004, time-taken: 2.71min, time-elasped: 8100.61min
-> berries picked: 61 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10228 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1076, 1598, 1523, 1117, 1069, 914, 870, 830, 1231]
	| approx positives in sample 512: 152
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 20, 26, 14, 13, 13, 14, 10, 24]
	Time taken saving stuff: 0.01s

=== episode:1550 Env-steps-taken:70848
 	picked: 84 |actions: {0: 657, 1: 665, 2: 652, 3: 709, 4: 634, 5: 569, 6: 633, 7: 842, 8: 385}
episode: 1550/2000 -> reward: 114.68749999999986, steps:5746, time-taken: 3.57min, time-elasped: 8104.19min
-> berries picked: 84 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10239 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1075, 1605, 1529, 1124, 1062, 918, 867, 829, 1230]
	| approx positives in sample 512: 143
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 19, 19, 13, 18, 10, 13, 9, 28]
	Time taken saving stuff: 0.09s

=== episode:155 Env-steps-taken:74592
 	picked: 101 |actions: {0: 1916, 1: 280, 2: 782, 3: 935, 4: 527, 5: 875, 6: 122, 7: 1004, 8: 341}

==================================================
eval-episode: 1550 -> reward: 132.3281249999998, steps: 6782.0, wall-time: 70.18s
-> berries picked: 101 of 800 | patches-visited: [1, 7] | juice left:-0.00
==================================================


=== episode:1551 Env-steps-taken:68640
 	picked: 75 |actions: {0: 434, 1: 425, 2: 408, 3: 716, 4: 448, 5: 350, 6: 438, 7: 400, 8: 189}
episode: 1551/2000 -> reward: 103.31770833333324, steps:3808, time-taken: 2.40min, time-elasped: 8107.76min
-> berries picked: 75 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10258 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1070, 1611, 1533, 1123, 1069, 919, 870, 831, 1232]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 13, 18, 21, 15, 13, 11, 9, 22]
	Time taken saving stuff: 0.01s

=== episode:1552 Env-steps-taken:63456
 	picked: 55 |actions: {0: 320, 1: 381, 2: 394, 3: 395, 4: 515, 5: 406, 6: 369, 7: 438, 8: 301}
episode: 1552/2000 -> reward: 77.84895833333331, steps:3519, time-taken: 2.62min, time-elasped: 8110.39min
-> berries picked: 55 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10268 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1071, 1609, 1532, 1124, 1070, 921, 872, 837, 1232]
	| approx positives in sample 512: 164
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 21, 16, 19, 21, 17, 14, 9, 26]
	Time taken saving stuff: 0.01s

=== episode:1553 Env-steps-taken:72480
 	picked: 90 |actions: {0: 849, 1: 669, 2: 668, 3: 572, 4: 642, 5: 525, 6: 501, 7: 870, 8: 298}
episode: 1553/2000 -> reward: 122.84374999999983, steps:5594, time-taken: 3.22min, time-elasped: 8113.62min
-> berries picked: 90 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10278 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1075, 1615, 1530, 1127, 1069, 917, 874, 838, 1233]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 16, 16, 11, 10, 11, 11, 7, 23]
	Time taken saving stuff: 0.01s

=== episode:1554 Env-steps-taken:56928
 	picked: 32 |actions: {0: 166, 1: 152, 2: 263, 3: 217, 4: 157, 5: 218, 6: 218, 7: 121, 8: 140}
episode: 1554/2000 -> reward: 44.66666666666669, steps:1652, time-taken: 1.24min, time-elasped: 8114.87min
-> berries picked: 32 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10287 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1077, 1617, 1533, 1130, 1070, 916, 876, 835, 1233]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 21, 19, 13, 16, 14, 11, 11, 26]
	Time taken saving stuff: 0.01s

=== episode:1555 Env-steps-taken:64416
 	picked: 63 |actions: {0: 549, 1: 598, 2: 664, 3: 607, 4: 505, 5: 370, 6: 489, 7: 527, 8: 379}
episode: 1555/2000 -> reward: 81.89062499999997, steps:4688, time-taken: 2.70min, time-elasped: 8117.57min
-> berries picked: 63 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10293 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1079, 1619, 1539, 1128, 1068, 916, 875, 836, 1233]
	| approx positives in sample 512: 166
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 13, 21, 19, 21, 17, 14, 19, 24]
	Time taken saving stuff: 0.01s

=== episode:1556 Env-steps-taken:62304
 	picked: 48 |actions: {0: 484, 1: 695, 2: 461, 3: 584, 4: 641, 5: 386, 6: 378, 7: 738, 8: 361}
episode: 1556/2000 -> reward: 72.25000000000001, steps:4728, time-taken: 2.68min, time-elasped: 8120.26min
-> berries picked: 48 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10286 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1078, 1622, 1543, 1125, 1066, 910, 873, 834, 1235]
	| approx positives in sample 512: 143
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 21, 12, 21, 20, 9, 10, 11, 30]
	Time taken saving stuff: 0.01s

=== episode:1557 Env-steps-taken:69120
 	picked: 83 |actions: {0: 427, 1: 647, 2: 542, 3: 561, 4: 501, 5: 557, 6: 590, 7: 731, 8: 346}
episode: 1557/2000 -> reward: 105.74479166666653, steps:4902, time-taken: 2.88min, time-elasped: 8123.14min
-> berries picked: 83 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10314 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1085, 1620, 1545, 1125, 1061, 921, 883, 835, 1239]
	| approx positives in sample 512: 161
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 20, 19, 21, 16, 11, 14, 18, 27]
	Time taken saving stuff: 0.01s

=== episode:1558 Env-steps-taken:60000
 	picked: 47 |actions: {0: 613, 1: 512, 2: 502, 3: 543, 4: 455, 5: 491, 6: 321, 7: 567, 8: 303}
episode: 1558/2000 -> reward: 59.80729166666672, steps:4307, time-taken: 2.51min, time-elasped: 8125.65min
-> berries picked: 47 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10314 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1087, 1622, 1544, 1127, 1061, 917, 883, 833, 1240]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 23, 14, 14, 15, 16, 14, 8, 25]
	Time taken saving stuff: 0.01s

=== episode:1559 Env-steps-taken:58560
 	picked: 38 |actions: {0: 253, 1: 396, 2: 334, 3: 389, 4: 208, 5: 183, 6: 230, 7: 313, 8: 158}
episode: 1559/2000 -> reward: 53.3229166666667, steps:2464, time-taken: 1.80min, time-elasped: 8127.45min
-> berries picked: 38 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10331 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1085, 1626, 1549, 1126, 1062, 917, 883, 840, 1243]
	| approx positives in sample 512: 147
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 17, 24, 11, 16, 14, 16, 15, 21]
	Time taken saving stuff: 0.01s

=== episode:1560 Env-steps-taken:62304
 	picked: 52 |actions: {0: 523, 1: 568, 2: 556, 3: 480, 4: 466, 5: 378, 6: 395, 7: 625, 8: 271}
episode: 1560/2000 -> reward: 72.02083333333336, steps:4262, time-taken: 2.46min, time-elasped: 8129.92min
-> berries picked: 52 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10335 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1087, 1628, 1551, 1122, 1061, 918, 886, 839, 1243]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 19, 16, 18, 13, 11, 10, 12, 23]
	Time taken saving stuff: 0.07s

=== episode:156 Env-steps-taken:60768
 	picked: 45 |actions: {0: 216, 1: 122, 2: 215, 3: 228, 4: 96, 5: 223, 6: 128, 7: 348, 8: 70}

==================================================
eval-episode: 1560 -> reward: 64.42187500000006, steps: 1646.0, wall-time: 44.68s
-> berries picked: 45 of 800 | patches-visited: [1, 5] | juice left:-0.00
==================================================


=== episode:1561 Env-steps-taken:66528
 	picked: 72 |actions: {0: 755, 1: 736, 2: 573, 3: 842, 4: 754, 5: 418, 6: 405, 7: 659, 8: 292}
episode: 1561/2000 -> reward: 92.3749999999999, steps:5434, time-taken: 2.69min, time-elasped: 8133.35min
-> berries picked: 72 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10313 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1079, 1623, 1549, 1124, 1064, 912, 885, 835, 1242]
	| approx positives in sample 512: 150
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 19, 22, 17, 16, 14, 14, 10, 25]
	Time taken saving stuff: 0.01s

=== episode:1562 Env-steps-taken:62880
 	picked: 52 |actions: {0: 411, 1: 530, 2: 342, 3: 355, 4: 295, 5: 201, 6: 319, 7: 232, 8: 228}
episode: 1562/2000 -> reward: 75.19270833333333, steps:2913, time-taken: 1.76min, time-elasped: 8135.12min
-> berries picked: 52 of 800 | patches-visited: [0, 6, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10323 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1083, 1623, 1549, 1125, 1066, 913, 887, 836, 1241]
	| approx positives in sample 512: 154
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 22, 18, 15, 19, 10, 13, 6, 32]
	Time taken saving stuff: 0.01s

=== episode:1563 Env-steps-taken:64608
 	picked: 55 |actions: {0: 423, 1: 370, 2: 416, 3: 323, 4: 444, 5: 287, 6: 354, 7: 402, 8: 234}
episode: 1563/2000 -> reward: 84.34895833333331, steps:3253, time-taken: 1.90min, time-elasped: 8137.02min
-> berries picked: 55 of 800 | patches-visited: [0, 2, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10323 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1082, 1623, 1546, 1129, 1064, 911, 892, 835, 1241]
	| approx positives in sample 512: 143
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 19, 14, 19, 15, 16, 9, 7, 30]
	Time taken saving stuff: 0.01s

=== episode:1564 Env-steps-taken:53472
 	picked: 23 |actions: {0: 249, 1: 292, 2: 224, 3: 402, 4: 225, 5: 126, 6: 213, 7: 258, 8: 156}
episode: 1564/2000 -> reward: 27.182291666666657, steps:2145, time-taken: 1.24min, time-elasped: 8138.27min
-> berries picked: 23 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10316 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1078, 1623, 1547, 1131, 1063, 911, 889, 833, 1241]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 12, 20, 12, 14, 7, 15, 14, 32]
	Time taken saving stuff: 0.62s

=== episode:1565 Env-steps-taken:70560
 	picked: 81 |actions: {0: 575, 1: 606, 2: 504, 3: 377, 4: 363, 5: 313, 6: 355, 7: 494, 8: 277}
episode: 1565/2000 -> reward: 112.97395833333319, steps:3864, time-taken: 2.31min, time-elasped: 8140.59min
-> berries picked: 81 of 800 | patches-visited: [0, 6, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10314 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1083, 1629, 1541, 1131, 1059, 911, 890, 829, 1241]
	| approx positives in sample 512: 149
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 22, 16, 14, 16, 17, 15, 12, 24]
	Time taken saving stuff: 0.00s

=== episode:1566 Env-steps-taken:66816
 	picked: 69 |actions: {0: 676, 1: 446, 2: 443, 3: 600, 4: 543, 5: 567, 6: 401, 7: 529, 8: 333}
episode: 1566/2000 -> reward: 93.10416666666659, steps:4538, time-taken: 2.53min, time-elasped: 8143.13min
-> berries picked: 69 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10282 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1078, 1599, 1539, 1142, 1062, 908, 891, 822, 1241]
	| approx positives in sample 512: 150
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 18, 21, 19, 21, 14, 13, 8, 24]
	Time taken saving stuff: 0.01s

=== episode:1567 Env-steps-taken:73248
 	picked: 93 |actions: {0: 862, 1: 607, 2: 755, 3: 733, 4: 759, 5: 720, 6: 576, 7: 738, 8: 332}
episode: 1567/2000 -> reward: 124.72916666666652, steps:6082, time-taken: 3.11min, time-elasped: 8146.24min
-> berries picked: 93 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10278 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1081, 1594, 1540, 1147, 1056, 913, 889, 820, 1238]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 29, 16, 16, 9, 8, 9, 7, 22]
	Time taken saving stuff: 0.01s

=== episode:1568 Env-steps-taken:59040
 	picked: 43 |actions: {0: 257, 1: 253, 2: 269, 3: 303, 4: 307, 5: 259, 6: 305, 7: 388, 8: 179}
episode: 1568/2000 -> reward: 55.03645833333337, steps:2520, time-taken: 1.82min, time-elasped: 8148.06min
-> berries picked: 43 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10264 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1070, 1593, 1541, 1146, 1053, 916, 884, 822, 1239]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 24, 18, 20, 13, 7, 8, 10, 26]
	Time taken saving stuff: 0.00s

=== episode:1569 Env-steps-taken:65280
 	picked: 65 |actions: {0: 509, 1: 688, 2: 472, 3: 447, 4: 440, 5: 378, 6: 464, 7: 629, 8: 305}
episode: 1569/2000 -> reward: 86.27604166666663, steps:4332, time-taken: 2.29min, time-elasped: 8150.36min
-> berries picked: 65 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10263 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1070, 1595, 1539, 1146, 1055, 912, 884, 826, 1236]
	| approx positives in sample 512: 153
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 22, 19, 15, 14, 15, 18, 13, 29]
	Time taken saving stuff: 0.00s

=== episode:1570 Env-steps-taken:66048
 	picked: 67 |actions: {0: 566, 1: 624, 2: 462, 3: 527, 4: 376, 5: 303, 6: 465, 7: 688, 8: 235}
episode: 1570/2000 -> reward: 90.66145833333329, steps:4246, time-taken: 2.38min, time-elasped: 8152.74min
-> berries picked: 67 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10256 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1066, 1585, 1540, 1142, 1054, 921, 885, 826, 1237]
	| approx positives in sample 512: 168
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 26, 27, 23, 9, 9, 14, 13, 34]
	Time taken saving stuff: 0.08s

=== episode:157 Env-steps-taken:64128
 	picked: 58 |actions: {0: 390, 1: 617, 2: 143, 3: 904, 4: 226, 5: 135, 6: 63, 7: 1774, 8: 41}

==================================================
eval-episode: 1570 -> reward: 80.29166666666664, steps: 4293.0, wall-time: 59.86s
-> berries picked: 58 of 800 | patches-visited: [1, 5] | juice left:-0.00
==================================================


=== episode:1571 Env-steps-taken:62592
 	picked: 65 |actions: {0: 596, 1: 569, 2: 487, 3: 569, 4: 770, 5: 408, 6: 543, 7: 644, 8: 283}
episode: 1571/2000 -> reward: 72.27604166666667, steps:4869, time-taken: 2.79min, time-elasped: 8156.53min
-> berries picked: 65 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10239 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1065, 1584, 1538, 1143, 1046, 919, 885, 821, 1238]
	| approx positives in sample 512: 146
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 20, 13, 13, 17, 16, 18, 13, 23]
	Time taken saving stuff: 0.01s

=== episode:1572 Env-steps-taken:71904
 	picked: 89 |actions: {0: 712, 1: 590, 2: 764, 3: 746, 4: 787, 5: 481, 6: 536, 7: 746, 8: 312}
episode: 1572/2000 -> reward: 119.90104166666652, steps:5674, time-taken: 3.50min, time-elasped: 8160.03min
-> berries picked: 89 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10232 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1062, 1586, 1540, 1140, 1043, 911, 891, 822, 1237]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 19, 19, 14, 18, 13, 16, 8, 27]
	Time taken saving stuff: 0.01s

=== episode:1573 Env-steps-taken:62784
 	picked: 64 |actions: {0: 665, 1: 577, 2: 442, 3: 502, 4: 670, 5: 367, 6: 587, 7: 515, 8: 240}
episode: 1573/2000 -> reward: 72.94791666666667, steps:4565, time-taken: 2.72min, time-elasped: 8162.76min
-> berries picked: 64 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10230 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1061, 1588, 1539, 1143, 1041, 909, 886, 826, 1237]
	| approx positives in sample 512: 147
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 24, 14, 16, 13, 16, 19, 14, 20]
	Time taken saving stuff: 0.01s

=== episode:1574 Env-steps-taken:65280
 	picked: 69 |actions: {0: 670, 1: 673, 2: 694, 3: 639, 4: 539, 5: 418, 6: 465, 7: 685, 8: 288}
episode: 1574/2000 -> reward: 86.04687499999996, steps:5071, time-taken: 2.94min, time-elasped: 8165.71min
-> berries picked: 69 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10239 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1063, 1586, 1545, 1145, 1046, 907, 887, 823, 1237]
	| approx positives in sample 512: 151
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 19, 16, 22, 21, 20, 12, 5, 23]
	Time taken saving stuff: 0.01s

=== episode:1575 Env-steps-taken:65760
 	picked: 74 |actions: {0: 641, 1: 578, 2: 640, 3: 698, 4: 718, 5: 492, 6: 499, 7: 565, 8: 319}
episode: 1575/2000 -> reward: 88.26041666666663, steps:5150, time-taken: 3.02min, time-elasped: 8168.73min
-> berries picked: 74 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10251 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1063, 1592, 1544, 1152, 1046, 906, 883, 827, 1238]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 17, 25, 16, 10, 17, 14, 8, 22]
	Time taken saving stuff: 0.01s

=== episode:1576 Env-steps-taken:67584
 	picked: 72 |actions: {0: 531, 1: 773, 2: 860, 3: 887, 4: 820, 5: 432, 6: 580, 7: 751, 8: 455}
episode: 1576/2000 -> reward: 97.87499999999993, steps:6089, time-taken: 3.12min, time-elasped: 8171.86min
-> berries picked: 72 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10238 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1059, 1598, 1547, 1155, 1044, 903, 878, 817, 1237]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 27, 18, 15, 11, 12, 11, 12, 24]
	Time taken saving stuff: 0.01s

=== episode:1577 Env-steps-taken:66720
 	picked: 72 |actions: {0: 624, 1: 604, 2: 634, 3: 519, 4: 609, 5: 408, 6: 489, 7: 661, 8: 361}
episode: 1577/2000 -> reward: 92.04687499999994, steps:4909, time-taken: 2.61min, time-elasped: 8174.47min
-> berries picked: 72 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10251 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1069, 1601, 1548, 1155, 1044, 904, 877, 816, 1237]
	| approx positives in sample 512: 160
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 24, 24, 19, 22, 14, 18, 13, 15]
	Time taken saving stuff: 0.01s

=== episode:1578 Env-steps-taken:65568
 	picked: 73 |actions: {0: 598, 1: 562, 2: 407, 3: 705, 4: 447, 5: 509, 6: 627, 7: 692, 8: 344}
episode: 1578/2000 -> reward: 86.4322916666666, steps:4891, time-taken: 2.45min, time-elasped: 8176.92min
-> berries picked: 73 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10256 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1064, 1601, 1544, 1152, 1043, 904, 881, 830, 1237]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 22, 15, 16, 19, 10, 11, 8, 20]
	Time taken saving stuff: 0.01s

=== episode:1579 Env-steps-taken:68448
 	picked: 73 |actions: {0: 560, 1: 470, 2: 501, 3: 445, 4: 478, 5: 407, 6: 567, 7: 677, 8: 283}
episode: 1579/2000 -> reward: 102.81770833333323, steps:4388, time-taken: 2.68min, time-elasped: 8179.61min
-> berries picked: 73 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10253 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1061, 1600, 1544, 1148, 1044, 907, 882, 830, 1237]
	| approx positives in sample 512: 155
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 24, 19, 17, 11, 11, 20, 11, 28]
	Time taken saving stuff: 0.01s

=== episode:1580 Env-steps-taken:68736
 	picked: 80 |actions: {0: 676, 1: 785, 2: 519, 3: 579, 4: 796, 5: 541, 6: 757, 7: 821, 8: 381}
episode: 1580/2000 -> reward: 103.41666666666656, steps:5855, time-taken: 3.29min, time-elasped: 8182.90min
-> berries picked: 80 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10250 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1064, 1591, 1548, 1148, 1035, 911, 888, 827, 1238]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 11, 17, 16, 18, 9, 9, 9, 36]
	Time taken saving stuff: 0.06s

=== episode:158 Env-steps-taken:76512
 	picked: 113 |actions: {0: 185, 1: 726, 2: 447, 3: 153, 4: 831, 5: 133, 6: 190, 7: 2063, 8: 199}

==================================================
eval-episode: 1580 -> reward: 142.52604166666663, steps: 4927.0, wall-time: 54.50s
-> berries picked: 113 of 800 | patches-visited: [1, 7] | juice left:-0.00
==================================================


=== episode:1581 Env-steps-taken:66144
 	picked: 69 |actions: {0: 623, 1: 761, 2: 664, 3: 621, 4: 739, 5: 424, 6: 472, 7: 807, 8: 374}
episode: 1581/2000 -> reward: 91.04687499999997, steps:5485, time-taken: 3.57min, time-elasped: 8187.39min
-> berries picked: 69 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10211 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1067, 1586, 1542, 1142, 1034, 910, 872, 822, 1236]
	| approx positives in sample 512: 155
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 22, 22, 22, 19, 20, 13, 16, 14]
	Time taken saving stuff: 0.01s

=== episode:1582 Env-steps-taken:64128
 	picked: 63 |actions: {0: 549, 1: 522, 2: 653, 3: 604, 4: 480, 5: 484, 6: 513, 7: 781, 8: 292}
episode: 1582/2000 -> reward: 80.89062499999999, steps:4878, time-taken: 3.28min, time-elasped: 8190.67min
-> berries picked: 63 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10201 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1062, 1589, 1542, 1146, 1025, 911, 872, 819, 1235]
	| approx positives in sample 512: 173
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [27, 20, 23, 18, 28, 16, 11, 11, 19]
	Time taken saving stuff: 0.01s

=== episode:1583 Env-steps-taken:72288
 	picked: 92 |actions: {0: 689, 1: 775, 2: 816, 3: 752, 4: 500, 5: 460, 6: 565, 7: 801, 8: 401}
episode: 1583/2000 -> reward: 121.72916666666647, steps:5759, time-taken: 3.88min, time-elasped: 8194.56min
-> berries picked: 92 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10208 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1067, 1593, 1544, 1146, 1027, 909, 870, 819, 1233]
	| approx positives in sample 512: 143
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 23, 18, 18, 19, 8, 17, 15, 16]
	Time taken saving stuff: 0.00s

=== episode:1584 Env-steps-taken:64416
 	picked: 65 |actions: {0: 539, 1: 531, 2: 695, 3: 433, 4: 493, 5: 363, 6: 453, 7: 598, 8: 271}
episode: 1584/2000 -> reward: 82.33333333333329, steps:4376, time-taken: 3.19min, time-elasped: 8197.75min
-> berries picked: 65 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10196 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1059, 1589, 1543, 1145, 1028, 911, 865, 820, 1236]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 19, 18, 20, 14, 5, 12, 12, 23]
	Time taken saving stuff: 0.01s

=== episode:1585 Env-steps-taken:66816
 	picked: 76 |actions: {0: 647, 1: 630, 2: 567, 3: 748, 4: 580, 5: 480, 6: 565, 7: 966, 8: 336}
episode: 1585/2000 -> reward: 93.64583333333324, steps:5519, time-taken: 3.44min, time-elasped: 8201.20min
-> berries picked: 76 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10200 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1062, 1590, 1543, 1141, 1030, 910, 866, 822, 1236]
	| approx positives in sample 512: 152
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 18, 18, 15, 20, 6, 11, 18, 32]
	Time taken saving stuff: 0.01s

=== episode:1586 Env-steps-taken:74304
 	picked: 102 |actions: {0: 573, 1: 742, 2: 743, 3: 734, 4: 667, 5: 517, 6: 828, 7: 959, 8: 344}
episode: 1586/2000 -> reward: 131.6562499999999, steps:6107, time-taken: 3.65min, time-elasped: 8204.85min
-> berries picked: 102 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10203 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1067, 1578, 1543, 1141, 1028, 918, 869, 820, 1239]
	| approx positives in sample 512: 143
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 23, 29, 19, 16, 14, 8, 4, 16]
	Time taken saving stuff: 0.01s

=== episode:1587 Env-steps-taken:71328
 	picked: 86 |actions: {0: 475, 1: 593, 2: 588, 3: 610, 4: 448, 5: 448, 6: 513, 7: 746, 8: 273}
episode: 1587/2000 -> reward: 117.57291666666653, steps:4694, time-taken: 3.05min, time-elasped: 8207.90min
-> berries picked: 86 of 800 | patches-visited: [0, 2, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10217 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1066, 1581, 1546, 1142, 1027, 920, 873, 822, 1240]
	| approx positives in sample 512: 150
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 23, 13, 13, 19, 15, 17, 10, 26]
	Time taken saving stuff: 0.00s

=== episode:1588 Env-steps-taken:61536
 	picked: 46 |actions: {0: 277, 1: 247, 2: 302, 3: 289, 4: 257, 5: 221, 6: 310, 7: 490, 8: 188}
episode: 1588/2000 -> reward: 68.47916666666671, steps:2581, time-taken: 1.84min, time-elasped: 8209.75min
-> berries picked: 46 of 800 | patches-visited: [0, 2, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10224 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1070, 1581, 1546, 1139, 1027, 921, 873, 825, 1242]
	| approx positives in sample 512: 150
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 18, 25, 17, 12, 14, 18, 13, 24]
	Time taken saving stuff: 0.01s

=== episode:1589 Env-steps-taken:67104
 	picked: 80 |actions: {0: 647, 1: 753, 2: 645, 3: 547, 4: 747, 5: 508, 6: 504, 7: 735, 8: 311}
episode: 1589/2000 -> reward: 94.91666666666659, steps:5397, time-taken: 3.13min, time-elasped: 8212.88min
-> berries picked: 80 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10245 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1067, 1586, 1549, 1143, 1030, 922, 873, 835, 1240]
	| approx positives in sample 512: 164
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 23, 25, 17, 15, 19, 14, 13, 21]
	Time taken saving stuff: 0.00s

=== episode:1590 Env-steps-taken:67872
 	picked: 76 |actions: {0: 597, 1: 637, 2: 602, 3: 481, 4: 771, 5: 556, 6: 503, 7: 940, 8: 312}
episode: 1590/2000 -> reward: 99.14583333333324, steps:5399, time-taken: 3.24min, time-elasped: 8216.13min
-> berries picked: 76 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10255 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1066, 1587, 1547, 1146, 1029, 925, 876, 841, 1238]
	| approx positives in sample 512: 151
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 25, 12, 29, 15, 13, 12, 9, 25]
	Time taken saving stuff: 0.06s

=== episode:159 Env-steps-taken:83328
 	picked: 136 |actions: {0: 726, 1: 491, 2: 482, 3: 1462, 4: 141, 5: 556, 6: 310, 7: 1075, 8: 352}

==================================================
eval-episode: 1590 -> reward: 177.20833333333346, steps: 5595.0, wall-time: 67.44s
-> berries picked: 136 of 800 | patches-visited: [1, 5, 7] | juice left:-0.00
==================================================


=== episode:1591 Env-steps-taken:64320
 	picked: 69 |actions: {0: 651, 1: 582, 2: 634, 3: 570, 4: 836, 5: 524, 6: 623, 7: 1072, 8: 356}
episode: 1591/2000 -> reward: 81.04687499999996, steps:5848, time-taken: 3.58min, time-elasped: 8220.83min
-> berries picked: 69 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10234 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1069, 1589, 1549, 1136, 1027, 917, 866, 847, 1234]
	| approx positives in sample 512: 145
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 15, 27, 17, 12, 9, 16, 12, 20]
	Time taken saving stuff: 0.01s

=== episode:1592 Env-steps-taken:62976
 	picked: 55 |actions: {0: 478, 1: 415, 2: 369, 3: 269, 4: 387, 5: 273, 6: 338, 7: 623, 8: 220}
episode: 1592/2000 -> reward: 74.84895833333333, steps:3372, time-taken: 2.24min, time-elasped: 8223.08min
-> berries picked: 55 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10224 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1071, 1591, 1547, 1133, 1024, 918, 863, 845, 1232]
	| approx positives in sample 512: 157
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 21, 19, 23, 21, 11, 11, 14, 22]
	Time taken saving stuff: 0.00s

=== episode:1593 Env-steps-taken:66336
 	picked: 76 |actions: {0: 653, 1: 607, 2: 928, 3: 609, 4: 849, 5: 620, 6: 598, 7: 786, 8: 286}
episode: 1593/2000 -> reward: 91.14583333333324, steps:5936, time-taken: 3.40min, time-elasped: 8226.48min
-> berries picked: 76 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10222 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1076, 1587, 1545, 1130, 1023, 922, 865, 842, 1232]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 20, 19, 12, 17, 14, 7, 20, 19]
	Time taken saving stuff: 0.01s

=== episode:1594 Env-steps-taken:60384
 	picked: 48 |actions: {0: 553, 1: 484, 2: 619, 3: 704, 4: 516, 5: 436, 6: 412, 7: 836, 8: 289}
episode: 1594/2000 -> reward: 61.75000000000004, steps:4849, time-taken: 2.98min, time-elasped: 8229.46min
-> berries picked: 48 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10210 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1079, 1589, 1546, 1126, 1022, 916, 861, 838, 1233]
	| approx positives in sample 512: 150
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 22, 16, 19, 14, 13, 14, 15, 28]
	Time taken saving stuff: 0.01s

=== episode:1595 Env-steps-taken:65856
 	picked: 70 |actions: {0: 674, 1: 706, 2: 725, 3: 712, 4: 892, 5: 464, 6: 617, 7: 851, 8: 346}
episode: 1595/2000 -> reward: 88.98958333333326, steps:5987, time-taken: 3.39min, time-elasped: 8232.85min
-> berries picked: 70 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10219 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1081, 1587, 1547, 1133, 1022, 916, 862, 840, 1231]
	| approx positives in sample 512: 149
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 28, 15, 14, 15, 14, 18, 7, 26]
	Time taken saving stuff: 0.01s

=== episode:1596 Env-steps-taken:80256
 	picked: 113 |actions: {0: 743, 1: 715, 2: 739, 3: 944, 4: 790, 5: 608, 6: 759, 7: 701, 8: 452}
episode: 1596/2000 -> reward: 160.64062500000006, steps:6451, time-taken: 3.87min, time-elasped: 8236.73min
-> berries picked: 113 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10236 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1077, 1585, 1552, 1132, 1025, 922, 872, 840, 1231]
	| approx positives in sample 512: 147
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 31, 19, 13, 12, 15, 5, 11, 22]
	Time taken saving stuff: 0.01s

=== episode:1597 Env-steps-taken:70272
 	picked: 81 |actions: {0: 509, 1: 703, 2: 531, 3: 592, 4: 598, 5: 481, 6: 593, 7: 658, 8: 250}
episode: 1597/2000 -> reward: 111.85937499999989, steps:4915, time-taken: 3.27min, time-elasped: 8240.00min
-> berries picked: 81 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10260 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1085, 1591, 1554, 1134, 1027, 925, 873, 841, 1230]
	| approx positives in sample 512: 146
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 20, 23, 16, 15, 16, 11, 11, 19]
	Time taken saving stuff: 0.01s

=== episode:1598 Env-steps-taken:72288
 	picked: 88 |actions: {0: 487, 1: 630, 2: 808, 3: 560, 4: 577, 5: 576, 6: 548, 7: 696, 8: 320}
episode: 1598/2000 -> reward: 121.07291666666653, steps:5202, time-taken: 3.40min, time-elasped: 8243.41min
-> berries picked: 88 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10290 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1082, 1592, 1559, 1137, 1035, 933, 882, 841, 1229]
	| approx positives in sample 512: 143
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 24, 21, 16, 17, 12, 13, 9, 20]
	Time taken saving stuff: 0.01s

=== episode:1599 Env-steps-taken:69984
 	picked: 76 |actions: {0: 606, 1: 596, 2: 631, 3: 540, 4: 688, 5: 410, 6: 510, 7: 810, 8: 305}
episode: 1599/2000 -> reward: 110.64583333333321, steps:5096, time-taken: 3.14min, time-elasped: 8246.55min
-> berries picked: 76 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10309 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1089, 1595, 1555, 1136, 1038, 933, 884, 848, 1231]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 18, 20, 11, 18, 13, 14, 12, 18]
	Time taken saving stuff: 0.01s

=== episode:1600 Env-steps-taken:59712
 	picked: 43 |actions: {0: 228, 1: 362, 2: 301, 3: 310, 4: 355, 5: 215, 6: 337, 7: 447, 8: 173}
episode: 1600/2000 -> reward: 59.03645833333338, steps:2728, time-taken: 1.94min, time-elasped: 8248.50min
-> berries picked: 43 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10318 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1088, 1601, 1554, 1136, 1038, 934, 886, 850, 1231]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 9, 18, 16, 13, 10, 18, 14, 23]
	Time taken saving stuff: 0.08s

=== episode:160 Env-steps-taken:58080
 	picked: 36 |actions: {0: 613, 1: 196, 2: 239, 3: 441, 4: 141, 5: 80, 6: 40, 7: 58, 8: 255}

==================================================
eval-episode: 1600 -> reward: 50.937500000000036, steps: 2063.0, wall-time: 47.52s
-> berries picked: 36 of 800 | patches-visited: [1, 7] | juice left:-0.00
==================================================


=== episode:1601 Env-steps-taken:62592
 	picked: 60 |actions: {0: 860, 1: 490, 2: 598, 3: 837, 4: 705, 5: 439, 6: 581, 7: 857, 8: 324}
episode: 1601/2000 -> reward: 72.56250000000004, steps:5691, time-taken: 3.45min, time-elasped: 8252.75min
-> berries picked: 60 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10273 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1080, 1599, 1549, 1134, 1038, 929, 876, 839, 1229]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 10, 22, 12, 11, 15, 18, 13, 25]
	Time taken saving stuff: 0.01s

=== episode:1602 Env-steps-taken:67200
 	picked: 76 |actions: {0: 661, 1: 704, 2: 585, 3: 682, 4: 517, 5: 480, 6: 622, 7: 654, 8: 266}
episode: 1602/2000 -> reward: 95.64583333333324, steps:5171, time-taken: 2.79min, time-elasped: 8255.54min
-> berries picked: 76 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10280 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1085, 1599, 1548, 1130, 1040, 931, 876, 843, 1228]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 19, 17, 20, 14, 12, 8, 11, 26]
	Time taken saving stuff: 0.01s

=== episode:1603 Env-steps-taken:65184
 	picked: 71 |actions: {0: 604, 1: 456, 2: 558, 3: 542, 4: 641, 5: 414, 6: 650, 7: 749, 8: 325}
episode: 1603/2000 -> reward: 85.9322916666666, steps:4939, time-taken: 3.00min, time-elasped: 8258.54min
-> berries picked: 71 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10286 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1087, 1599, 1551, 1128, 1040, 934, 879, 840, 1228]
	| approx positives in sample 512: 163
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [23, 17, 19, 13, 22, 19, 17, 13, 20]
	Time taken saving stuff: 0.01s

=== episode:1604 Env-steps-taken:66144
 	picked: 76 |actions: {0: 584, 1: 567, 2: 589, 3: 653, 4: 710, 5: 490, 6: 718, 7: 1152, 8: 309}
episode: 1604/2000 -> reward: 88.76041666666666, steps:5772, time-taken: 3.00min, time-elasped: 8261.54min
-> berries picked: 76 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10297 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1087, 1600, 1548, 1128, 1044, 934, 882, 844, 1230]
	| approx positives in sample 512: 152
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 20, 21, 24, 15, 10, 9, 13, 23]
	Time taken saving stuff: 0.00s

=== episode:1605 Env-steps-taken:73248
 	picked: 101 |actions: {0: 757, 1: 673, 2: 685, 3: 888, 4: 729, 5: 542, 6: 639, 7: 1044, 8: 367}
episode: 1605/2000 -> reward: 126.21354166666649, steps:6324, time-taken: 3.67min, time-elasped: 8265.22min
-> berries picked: 101 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10311 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1091, 1602, 1546, 1140, 1046, 933, 881, 843, 1229]
	| approx positives in sample 512: 143
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 25, 17, 13, 10, 19, 11, 12, 20]
	Time taken saving stuff: 0.01s

=== episode:1606 Env-steps-taken:55680
 	picked: 28 |actions: {0: 185, 1: 319, 2: 328, 3: 301, 4: 329, 5: 174, 6: 172, 7: 277, 8: 174}
episode: 1606/2000 -> reward: 38.39583333333334, steps:2259, time-taken: 1.41min, time-elasped: 8266.63min
-> berries picked: 28 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10314 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1090, 1608, 1548, 1139, 1045, 933, 881, 842, 1228]
	| approx positives in sample 512: 152
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 16, 18, 17, 14, 15, 15, 17, 22]
	Time taken saving stuff: 0.01s

=== episode:1607 Env-steps-taken:63840
 	picked: 55 |actions: {0: 382, 1: 429, 2: 306, 3: 302, 4: 363, 5: 280, 6: 388, 7: 535, 8: 193}
episode: 1607/2000 -> reward: 79.34895833333333, steps:3178, time-taken: 2.11min, time-elasped: 8268.74min
-> berries picked: 55 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10317 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1092, 1614, 1546, 1141, 1042, 938, 877, 841, 1226]
	| approx positives in sample 512: 146
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 18, 16, 17, 12, 20, 16, 6, 23]
	Time taken saving stuff: 0.01s

=== episode:1608 Env-steps-taken:60768
 	picked: 44 |actions: {0: 375, 1: 390, 2: 533, 3: 412, 4: 349, 5: 307, 6: 442, 7: 447, 8: 221}
episode: 1608/2000 -> reward: 64.4791666666667, steps:3476, time-taken: 2.19min, time-elasped: 8270.94min
-> berries picked: 44 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10316 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1097, 1612, 1545, 1140, 1043, 936, 878, 838, 1227]
	| approx positives in sample 512: 175
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 26, 16, 25, 12, 21, 14, 13, 27]
	Time taken saving stuff: 0.00s

=== episode:1609 Env-steps-taken:67776
 	picked: 72 |actions: {0: 557, 1: 640, 2: 613, 3: 592, 4: 587, 5: 511, 6: 559, 7: 860, 8: 325}
episode: 1609/2000 -> reward: 99.37499999999991, steps:5244, time-taken: 3.22min, time-elasped: 8274.16min
-> berries picked: 72 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10331 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1099, 1618, 1542, 1146, 1040, 938, 887, 833, 1228]
	| approx positives in sample 512: 156
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 19, 21, 19, 13, 14, 15, 9, 30]
	Time taken saving stuff: 0.01s

=== episode:1610 Env-steps-taken:69888
 	picked: 82 |actions: {0: 566, 1: 562, 2: 624, 3: 574, 4: 608, 5: 520, 6: 467, 7: 751, 8: 291}
episode: 1610/2000 -> reward: 109.80208333333323, steps:4963, time-taken: 2.95min, time-elasped: 8277.12min
-> berries picked: 82 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10345 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1098, 1621, 1545, 1151, 1040, 942, 883, 836, 1229]
	| approx positives in sample 512: 152
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 22, 25, 24, 12, 17, 7, 13, 20]
	Time taken saving stuff: 0.07s

=== episode:161 Env-steps-taken:75168
 	picked: 97 |actions: {0: 958, 1: 333, 2: 543, 3: 658, 4: 321, 5: 608, 6: 138, 7: 1891, 8: 56}

==================================================
eval-episode: 1610 -> reward: 136.05729166666657, steps: 5506.0, wall-time: 57.31s
-> berries picked: 97 of 800 | patches-visited: [1, 2, 5] | juice left:-0.00
==================================================


=== episode:1611 Env-steps-taken:61056
 	picked: 53 |actions: {0: 470, 1: 472, 2: 513, 3: 638, 4: 505, 5: 290, 6: 344, 7: 655, 8: 307}
episode: 1611/2000 -> reward: 64.9635416666667, steps:4194, time-taken: 2.54min, time-elasped: 8280.62min
-> berries picked: 53 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10365 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1104, 1626, 1545, 1153, 1039, 941, 891, 838, 1228]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 22, 19, 8, 15, 7, 11, 9, 25]
	Time taken saving stuff: 0.00s

=== episode:1612 Env-steps-taken:66720
 	picked: 74 |actions: {0: 546, 1: 554, 2: 718, 3: 632, 4: 579, 5: 374, 6: 578, 7: 631, 8: 259}
episode: 1612/2000 -> reward: 93.26041666666656, steps:4871, time-taken: 2.66min, time-elasped: 8283.29min
-> berries picked: 74 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10379 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1109, 1631, 1546, 1157, 1041, 941, 890, 838, 1226]
	| approx positives in sample 512: 153
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 21, 14, 24, 10, 11, 15, 11, 30]
	Time taken saving stuff: 0.00s

=== episode:1613 Env-steps-taken:64800
 	picked: 69 |actions: {0: 638, 1: 529, 2: 652, 3: 696, 4: 555, 5: 422, 6: 455, 7: 483, 8: 263}
episode: 1613/2000 -> reward: 83.54687499999999, steps:4693, time-taken: 2.69min, time-elasped: 8285.98min
-> berries picked: 69 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10385 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1107, 1629, 1548, 1162, 1040, 943, 893, 839, 1224]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 18, 16, 27, 7, 19, 9, 13, 24]
	Time taken saving stuff: 0.01s

=== episode:1614 Env-steps-taken:64512
 	picked: 65 |actions: {0: 631, 1: 487, 2: 679, 3: 939, 4: 789, 5: 435, 6: 692, 7: 897, 8: 316}
episode: 1614/2000 -> reward: 82.27604166666664, steps:5865, time-taken: 3.38min, time-elasped: 8289.37min
-> berries picked: 65 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10387 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1109, 1632, 1544, 1166, 1046, 939, 890, 835, 1226]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 23, 22, 16, 9, 9, 13, 13, 23]
	Time taken saving stuff: 0.01s

=== episode:1615 Env-steps-taken:67968
 	picked: 75 |actions: {0: 607, 1: 601, 2: 875, 3: 616, 4: 639, 5: 451, 6: 517, 7: 721, 8: 299}
episode: 1615/2000 -> reward: 99.70312499999994, steps:5326, time-taken: 3.00min, time-elasped: 8292.37min
-> berries picked: 75 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10408 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1113, 1633, 1556, 1166, 1048, 940, 888, 835, 1229]
	| approx positives in sample 512: 171
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 27, 28, 14, 24, 11, 10, 15, 24]
	Time taken saving stuff: 0.00s

=== episode:1616 Env-steps-taken:69984
 	picked: 81 |actions: {0: 685, 1: 612, 2: 915, 3: 740, 4: 400, 5: 494, 6: 728, 7: 670, 8: 351}
episode: 1616/2000 -> reward: 110.3593749999999, steps:5595, time-taken: 3.13min, time-elasped: 8295.50min
-> berries picked: 81 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10383 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1106, 1617, 1554, 1172, 1046, 938, 886, 834, 1230]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 20, 14, 16, 17, 12, 7, 14, 32]
	Time taken saving stuff: 0.01s

=== episode:1617 Env-steps-taken:61632
 	picked: 57 |actions: {0: 305, 1: 541, 2: 672, 3: 603, 4: 304, 5: 362, 6: 368, 7: 601, 8: 312}
episode: 1617/2000 -> reward: 68.23437500000001, steps:4068, time-taken: 2.45min, time-elasped: 8297.96min
-> berries picked: 57 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10371 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1103, 1611, 1553, 1172, 1050, 939, 884, 833, 1226]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 28, 16, 17, 3, 16, 9, 8, 23]
	Time taken saving stuff: 0.01s

=== episode:1618 Env-steps-taken:69984
 	picked: 69 |actions: {0: 608, 1: 531, 2: 732, 3: 924, 4: 490, 5: 384, 6: 491, 7: 538, 8: 328}
episode: 1618/2000 -> reward: 111.0468749999999, steps:5026, time-taken: 2.88min, time-elasped: 8300.84min
-> berries picked: 69 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10358 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1102, 1610, 1548, 1172, 1058, 929, 876, 836, 1227]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 22, 15, 16, 15, 18, 19, 8, 19]
	Time taken saving stuff: 0.00s

=== episode:1619 Env-steps-taken:69120
 	picked: 80 |actions: {0: 627, 1: 513, 2: 703, 3: 553, 4: 691, 5: 475, 6: 719, 7: 927, 8: 326}
episode: 1619/2000 -> reward: 105.91666666666657, steps:5534, time-taken: 3.26min, time-elasped: 8304.10min
-> berries picked: 80 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10362 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1100, 1606, 1547, 1173, 1061, 930, 882, 840, 1223]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 19, 17, 11, 15, 13, 10, 11, 28]
	Time taken saving stuff: 0.01s

=== episode:1620 Env-steps-taken:70656
 	picked: 81 |actions: {0: 426, 1: 478, 2: 503, 3: 600, 4: 509, 5: 457, 6: 480, 7: 796, 8: 337}
episode: 1620/2000 -> reward: 111.91666666666654, steps:4586, time-taken: 2.72min, time-elasped: 8306.82min
-> berries picked: 81 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10363 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1101, 1602, 1551, 1174, 1054, 937, 885, 838, 1221]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 17, 19, 14, 13, 13, 13, 9, 26]
	Time taken saving stuff: 0.06s

=== episode:162 Env-steps-taken:62400
 	picked: 57 |actions: {0: 215, 1: 289, 2: 102, 3: 940, 4: 205, 5: 112, 6: 131, 7: 2366, 8: 77}

==================================================
eval-episode: 1620 -> reward: 72.234375, steps: 4437.0, wall-time: 47.77s
-> berries picked: 57 of 800 | patches-visited: [1, 5] | juice left:-0.00
==================================================


=== episode:163 Env-steps-taken:70272
 	picked: 77 |actions: {0: 545, 1: 262, 2: 451, 3: 707, 4: 37, 5: 128, 6: 149, 7: 407, 8: 65}
evalEpisode: 0 -> reward: 112.58854166666656 steps: 2751
-> berries picked: 77 of 800 | patches-visited: [1, 4, 6] | juice left:-0.00
