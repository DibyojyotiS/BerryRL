copied Agent.py to .temp\2022-6-21 4-56-39/pyfiles-backup
copied debugging.py to .temp\2022-6-21 4-56-39/pyfiles-backup/agent_utils/debugging
copied debugging_utils.py to .temp\2022-6-21 4-56-39/pyfiles-backup/agent_utils/debugging
copied __init__.py to .temp\2022-6-21 4-56-39/pyfiles-backup/agent_utils/debugging

copied fubar.py to .temp\2022-6-21 4-56-39/pyfiles-backup/agent_utils/exploration_subroutines
copied random_exploration.py to .temp\2022-6-21 4-56-39/pyfiles-backup/agent_utils/exploration_subroutines
copied random_exploration_v1.py to .temp\2022-6-21 4-56-39/pyfiles-backup/agent_utils/exploration_subroutines
copied skipsteps.py to .temp\2022-6-21 4-56-39/pyfiles-backup/agent_utils/exploration_subroutines/utils
copied __init__.py to .temp\2022-6-21 4-56-39/pyfiles-backup/agent_utils/exploration_subroutines/utils

copied __init__.py to .temp\2022-6-21 4-56-39/pyfiles-backup/agent_utils/exploration_subroutines

copied patch_discovery.py to .temp\2022-6-21 4-56-39/pyfiles-backup/agent_utils/intrinsic_rewards
copied __init__.py to .temp\2022-6-21 4-56-39/pyfiles-backup/agent_utils/intrinsic_rewards

copied plots.py to .temp\2022-6-21 4-56-39/pyfiles-backup/agent_utils/misc
copied printing.py to .temp\2022-6-21 4-56-39/pyfiles-backup/agent_utils/misc
copied __init__.py to .temp\2022-6-21 4-56-39/pyfiles-backup/agent_utils/misc

copied make_net.py to .temp\2022-6-21 4-56-39/pyfiles-backup/agent_utils/nn_utils
copied __init__.py to .temp\2022-6-21 4-56-39/pyfiles-backup/agent_utils/nn_utils

copied berry_worth_function.py to .temp\2022-6-21 4-56-39/pyfiles-backup/agent_utils/state_utils
copied sectorized_states.py to .temp\2022-6-21 4-56-39/pyfiles-backup/agent_utils/state_utils
copied __init__.py to .temp\2022-6-21 4-56-39/pyfiles-backup/agent_utils/state_utils

copied __init__.py to .temp\2022-6-21 4-56-39/pyfiles-backup/agent_utils

copied ensemble.py to .temp\2022-6-21 4-56-39/pyfiles-backup
copied eval.py to .temp\2022-6-21 4-56-39/pyfiles-backup
copied train.py to .temp\2022-6-21 4-56-39/pyfiles-backup
copied utils.py to .temp\2022-6-21 4-56-39/pyfiles-backup/utils/copyfiles
copied __init__.py to .temp\2022-6-21 4-56-39/pyfiles-backup/utils/copyfiles

copied random_env.py to .temp\2022-6-21 4-56-39/pyfiles-backup/utils/env_generation
copied __init__.py to .temp\2022-6-21 4-56-39/pyfiles-backup/utils/env_generation

copied utils.py to .temp\2022-6-21 4-56-39/pyfiles-backup/utils/printing
copied __init__.py to .temp\2022-6-21 4-56-39/pyfiles-backup/utils/printing

copied env_picture.py to .temp\2022-6-21 4-56-39/pyfiles-backup/utils/visualization
copied graphs.py to .temp\2022-6-21 4-56-39/pyfiles-backup/utils/visualization
copied __init__.py to .temp\2022-6-21 4-56-39/pyfiles-backup/utils/visualization

copied __init__.py to .temp\2022-6-21 4-56-39/pyfiles-backup/utils


random_train_env
getBabyEnv :
	 logDir : .temp\2022-6-21 4-56-39
	 initial_juice : 0.5
	 end_on_boundary_hit : False
	 penalize_boundary_hit : False
	 allow_no_action : False
	 no_action_threshold : 0.7
	 add_exploration : True
	 field_size : (20000, 20000)
	 initial_pos_around_berry : True
	 nberries : 80
	 num_patches : 10
	 patch_size : (2600, 2600)
	 patch_with_agent_at_center : True
	 sampling_type : 0
	 seperation : 2400
	 show : False
	 spawn_radius : 100


Agent :
	 self : <Agent.Agent object at 0x0000019417F6A188>
	 berryField : <BerryFieldEnv instance>
	 mode : train
	 angle : 45
	 persistence : 0.8
	 worth_offset : 0.05
	 noise : 0.01
	 nstep_transition : [1]
	 positive_emphasis : 0
	 skipStep : 10
	 reward_patch_discovery : True
	 add_exploration : True
	 time_memory_factor : 0.5
	 time_memory_exp : 1.0
	 time_memory_sizes : [50, 100, 200]
	 render : False
	 debug : False
	 debugDir : .temp
	 device : cuda


total-params:  2098
rewards scaled by 2/(berryField.REWARD_RATE*MAXSIZE)
rewards are clipped between 0 and 2
Exploration subroutine as an action
p_action: 7
Rewarding patch discovery
rewards scaled by 2/(berryField.REWARD_RATE*MAXSIZE)
rewards are clipped between 0 and 2
Exploration subroutine as an action
p_action: 5
Rewarding patch discovery
net(
  (feedforward): ModuleList(
    (0): Linear(in_features=41, out_features=32, bias=True)
    (1): LeakyReLU(negative_slope=0.1)
    (2): Linear(in_features=32, out_features=16, bias=True)
    (3): LeakyReLU(negative_slope=0.1)
  )
  (final_stage): ModuleList(
    (0): Linear(in_features=16, out_features=8, bias=True)
    (1): LeakyReLU(negative_slope=0.1)
  )
  (valueL): Linear(in_features=8, out_features=1, bias=True)
  (actadvs): Linear(in_features=8, out_features=9, bias=True)
)
PrioritizedBuffer of type replace-min
optim = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005
    weight_decay: 0
), num_gradient_steps= 25
optimizing the online-model after every 100 actions
batch size=512, gamma=0.9, alpha=0.95
polyak_tau=0.1, update_freq=5

=== episode:0 Env-steps-taken:50016
 	picked: 6 |actions: {0: 134, 1: 115, 2: 136, 3: 821, 4: 135, 5: 363, 6: 123, 7: 115, 8: 294}
episode: 0/2000 -> reward: 10.90625, steps:2236, time-taken: 1.29min, time-elasped: 1.30min
-> berries picked: 6 of 800 | patches-visited: [0, 1, 4, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9 | amount-filled: 3.73%
	| action-stats:  [3, 5, 8] [4, 1, 4]
	| approx positives in sample 512: 21
	| approx action-dist in sample 512: [3, 5, 8] [10, 8, 3]
	Time taken saving stuff: 0.35s

=== episode:0 Env-steps-taken:49440
 	picked: 5 |actions: {0: 0, 1: 0, 2: 0, 3: 192, 4: 0, 5: 115, 6: 0, 7: 0, 8: 165}

==================================================
eval-episode: 0 -> reward: 7.463541666666667, steps: 472.0, wall-time: 22.64s
-> berries picked: 5 of 800 | patches-visited: [0, 1] | juice left:-0.00
==================================================


=== episode:1 Env-steps-taken:48288
 	picked: 1 |actions: {0: 32, 1: 26, 2: 37, 3: 109, 4: 46, 5: 198, 6: 41, 7: 43, 8: 90}
episode: 1/2000 -> reward: 1.692708333333333, steps:622, time-taken: 0.70min, time-elasped: 2.38min
-> berries picked: 1 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 11 | amount-filled: 4.76%
	| action-stats:  [3, 5, 8] [5, 1, 5]
	| approx positives in sample 512: 13
	| approx action-dist in sample 512: [3, 5, 8] [6, 4, 3]
	Time taken saving stuff: 0.09s

=== episode:2 Env-steps-taken:49920
 	picked: 7 |actions: {0: 115, 1: 134, 2: 93, 3: 238, 4: 183, 5: 437, 6: 114, 7: 274, 8: 137}
episode: 2/2000 -> reward: 9.598958333333337, steps:1725, time-taken: 1.22min, time-elasped: 3.60min
-> berries picked: 7 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 18 | amount-filled: 7.64%
	| action-stats:  [1, 3, 4, 5, 8] [1, 7, 1, 4, 5]
	| approx positives in sample 512: 30
	| approx action-dist in sample 512: [1, 3, 4, 5, 8] [1, 14, 1, 13, 1]
	Time taken saving stuff: 0.10s

=== episode:3 Env-steps-taken:49728
 	picked: 5 |actions: {0: 43, 1: 67, 2: 29, 3: 92, 4: 90, 5: 86, 6: 26, 7: 38, 8: 23}
episode: 3/2000 -> reward: 8.713541666666668, steps:494, time-taken: 0.57min, time-elasped: 4.18min
-> berries picked: 5 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 23 | amount-filled: 8.46%
	| action-stats:  [1, 3, 4, 5, 8] [1, 9, 2, 6, 5]
	| approx positives in sample 512: 23
	| approx action-dist in sample 512: [1, 3, 4, 5, 8] [1, 9, 4, 7, 2]
	Time taken saving stuff: 0.04s

=== episode:4 Env-steps-taken:52224
 	picked: 13 |actions: {0: 79, 1: 280, 2: 86, 3: 211, 4: 532, 5: 122, 6: 89, 7: 107, 8: 126}
episode: 4/2000 -> reward: 21.50520833333334, steps:1632, time-taken: 1.01min, time-elasped: 5.19min
-> berries picked: 13 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 37 | amount-filled: 11.18%
	| action-stats:  [1, 3, 4, 5, 8] [4, 10, 9, 7, 7]
	| approx positives in sample 512: 60
	| approx action-dist in sample 512: [1, 3, 4, 5, 8] [6, 10, 23, 15, 6]
	Time taken saving stuff: 0.09s

=== episode:5 Env-steps-taken:50016
 	picked: 7 |actions: {0: 105, 1: 478, 2: 110, 3: 354, 4: 328, 5: 112, 6: 95, 7: 119, 8: 185}
episode: 5/2000 -> reward: 10.098958333333334, steps:1886, time-taken: 1.14min, time-elasped: 6.34min
-> berries picked: 7 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 44 | amount-filled: 14.32%
	| action-stats:  [1, 3, 4, 5, 8] [9, 10, 11, 7, 7]
	| approx positives in sample 512: 32
	| approx action-dist in sample 512: [1, 3, 4, 5, 8] [11, 6, 8, 5, 2]
	Time taken saving stuff: 0.09s

=== episode:6 Env-steps-taken:50208
 	picked: 8 |actions: {0: 149, 1: 646, 2: 222, 3: 527, 4: 307, 5: 229, 6: 395, 7: 150, 8: 317}
episode: 6/2000 -> reward: 11.041666666666668, steps:2942, time-taken: 1.65min, time-elasped: 8.00min
-> berries picked: 8 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 52 | amount-filled: 19.23%
	| action-stats:  [1, 2, 3, 4, 5, 6, 8] [10, 2, 11, 14, 7, 1, 7]
	| approx positives in sample 512: 23
	| approx action-dist in sample 512: [1, 3, 4, 5, 6, 8] [6, 4, 5, 3, 3, 2]
	Time taken saving stuff: 0.09s

=== episode:7 Env-steps-taken:48000
 	picked: 0 |actions: {0: 98, 1: 127, 2: 380, 3: 214, 4: 82, 5: 135, 6: 364, 7: 105, 8: 192}
episode: 7/2000 -> reward: 0.0, steps:1697, time-taken: 1.00min, time-elasped: 9.00min
-> berries picked: 0 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 52 | amount-filled: 22.06%
	| action-stats:  [1, 2, 3, 4, 5, 6, 8] [10, 2, 11, 14, 7, 1, 7]
	| approx positives in sample 512: 26
	| approx action-dist in sample 512: [1, 3, 4, 5, 6, 8] [7, 5, 6, 3, 3, 2]
	Time taken saving stuff: 0.01s

=== episode:8 Env-steps-taken:49824
 	picked: 6 |actions: {0: 164, 1: 310, 2: 321, 3: 364, 4: 181, 5: 232, 6: 123, 7: 209, 8: 360}
episode: 8/2000 -> reward: 9.40625, steps:2264, time-taken: 1.23min, time-elasped: 10.23min
-> berries picked: 6 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 59 | amount-filled: 25.83%
	| action-stats:  [1, 2, 3, 4, 5, 6, 8] [12, 4, 11, 14, 9, 1, 8]
	| approx positives in sample 512: 20
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 8] [6, 2, 3, 3, 4, 2]
	Time taken saving stuff: 0.11s

=== episode:9 Env-steps-taken:52512
 	picked: 19 |actions: {0: 210, 1: 562, 2: 669, 3: 413, 4: 407, 5: 238, 6: 224, 7: 420, 8: 450}
episode: 9/2000 -> reward: 22.411458333333325, steps:3593, time-taken: 1.75min, time-elasped: 11.99min
-> berries picked: 19 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 78 | amount-filled: 31.82%
	| action-stats:  [1, 2, 3, 4, 5, 6, 7, 8] [18, 7, 13, 19, 11, 1, 1, 8]
	| approx positives in sample 512: 27
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 8] [8, 7, 2, 7, 2, 1]
	Time taken saving stuff: 0.03s

=== episode:10 Env-steps-taken:52992
 	picked: 15 |actions: {0: 97, 1: 197, 2: 344, 3: 164, 4: 262, 5: 157, 6: 160, 7: 130, 8: 190}
episode: 10/2000 -> reward: 25.390625, steps:1701, time-taken: 1.18min, time-elasped: 13.18min
-> berries picked: 15 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 94 | amount-filled: 34.65%
	| action-stats:  [1, 2, 3, 4, 5, 6, 7, 8] [18, 13, 15, 21, 14, 2, 2, 9]
	| approx positives in sample 512: 31
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 7, 8] [3, 5, 6, 5, 6, 1, 5]
	Time taken saving stuff: 0.15s

=== episode:1 Env-steps-taken:48192
 	picked: 1 |actions: {0: 0, 1: 0, 2: 1028, 3: 9, 4: 54, 5: 1803, 6: 0, 7: 0, 8: 1488}

==================================================
eval-episode: 10 -> reward: 0.9427083333333334, steps: 4382.0, wall-time: 46.75s
-> berries picked: 1 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:11 Env-steps-taken:50016
 	picked: 7 |actions: {0: 366, 1: 453, 2: 490, 3: 200, 4: 699, 5: 260, 6: 598, 7: 435, 8: 306}
episode: 11/2000 -> reward: 10.348958333333332, steps:3807, time-taken: 1.89min, time-elasped: 15.85min
-> berries picked: 7 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 102 | amount-filled: 41.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1, 20, 14, 16, 21, 14, 3, 3, 10]
	| approx positives in sample 512: 24
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 8] [7, 3, 3, 5, 2, 1, 3]
	Time taken saving stuff: 0.03s

=== episode:12 Env-steps-taken:57504
 	picked: 35 |actions: {0: 339, 1: 630, 2: 572, 3: 664, 4: 572, 5: 385, 6: 715, 7: 356, 8: 487}
episode: 12/2000 -> reward: 47.49479166666671, steps:4720, time-taken: 2.33min, time-elasped: 18.18min
-> berries picked: 35 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 137 | amount-filled: 48.87%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 27, 20, 22, 31, 17, 3, 3, 11]
	| approx positives in sample 512: 29
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 7, 8] [1, 7, 7, 2, 5, 3, 1, 3]
	Time taken saving stuff: 0.11s

=== episode:13 Env-steps-taken:53280
 	picked: 22 |actions: {0: 490, 1: 569, 2: 519, 3: 362, 4: 643, 5: 629, 6: 651, 7: 611, 8: 370}
episode: 13/2000 -> reward: 26.23958333333332, steps:4844, time-taken: 2.22min, time-elasped: 20.41min
-> berries picked: 22 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 159 | amount-filled: 56.94%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 31, 26, 23, 35, 21, 4, 4, 11]
	| approx positives in sample 512: 20
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 7, 8] [7, 4, 4, 2, 1, 1, 1]
	Time taken saving stuff: 0.08s

=== episode:14 Env-steps-taken:59616
 	picked: 42 |actions: {0: 300, 1: 518, 2: 788, 3: 356, 4: 478, 5: 658, 6: 565, 7: 1084, 8: 332}
episode: 14/2000 -> reward: 56.70833333333338, steps:5079, time-taken: 2.45min, time-elasped: 22.86min
-> berries picked: 42 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 200 | amount-filled: 65.40%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 36, 43, 25, 47, 22, 4, 8, 11]
	| approx positives in sample 512: 38
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7, 8] [6, 9, 3, 7, 5, 1, 5, 2]
	Time taken saving stuff: 0.10s

=== episode:15 Env-steps-taken:62400
 	picked: 48 |actions: {0: 401, 1: 437, 2: 574, 3: 337, 4: 501, 5: 667, 6: 481, 7: 570, 8: 253}
episode: 15/2000 -> reward: 72.50000000000001, steps:4221, time-taken: 2.36min, time-elasped: 25.22min
-> berries picked: 48 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 249 | amount-filled: 72.44%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 47, 54, 34, 54, 27, 4, 10, 14]
	| approx positives in sample 512: 31
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 7] [1, 7, 10, 3, 6, 3, 1]
	Time taken saving stuff: 0.01s

=== episode:16 Env-steps-taken:53664
 	picked: 21 |actions: {0: 414, 1: 829, 2: 414, 3: 384, 4: 734, 5: 420, 6: 496, 7: 810, 8: 302}
episode: 16/2000 -> reward: 28.296875, steps:4803, time-taken: 2.29min, time-elasped: 27.52min
-> berries picked: 21 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 270 | amount-filled: 80.44%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 49, 61, 35, 57, 29, 4, 11, 16]
	| approx positives in sample 512: 35
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 8] [2, 10, 8, 2, 10, 2, 1]
	Time taken saving stuff: 0.08s

=== episode:17 Env-steps-taken:61440
 	picked: 48 |actions: {0: 597, 1: 864, 2: 647, 3: 421, 4: 640, 5: 538, 6: 463, 7: 681, 8: 395}
episode: 17/2000 -> reward: 67.25000000000003, steps:5246, time-taken: 2.53min, time-elasped: 30.05min
-> berries picked: 48 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 318 | amount-filled: 89.19%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 66, 68, 42, 62, 33, 5, 14, 18]
	| approx positives in sample 512: 30
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 8] [2, 4, 11, 1, 7, 2, 1, 2]
	Time taken saving stuff: 0.07s

=== episode:18 Env-steps-taken:56448
 	picked: 35 |actions: {0: 806, 1: 833, 2: 503, 3: 371, 4: 451, 5: 777, 6: 376, 7: 549, 8: 466}
episode: 18/2000 -> reward: 41.99479166666667, steps:5132, time-taken: 2.34min, time-elasped: 32.40min
-> berries picked: 35 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 353 | amount-filled: 97.74%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 77, 78, 46, 65, 37, 6, 14, 20]
	| approx positives in sample 512: 43
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 8] [1, 8, 11, 6, 6, 7, 4]
	Time taken saving stuff: 0.09s

=== episode:19 Env-steps-taken:57600
 	picked: 35 |actions: {0: 603, 1: 617, 2: 372, 3: 309, 4: 421, 5: 409, 6: 425, 7: 424, 8: 245}
episode: 19/2000 -> reward: 47.99479166666669, steps:3825, time-taken: 2.24min, time-elasped: 34.64min
-> berries picked: 35 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 387 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 85, 81, 50, 70, 37, 9, 16, 20]
	| approx positives in sample 512: 35
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6] [1, 10, 5, 3, 10, 3, 3]
	Time taken saving stuff: 0.05s

=== episode:20 Env-steps-taken:57504
 	picked: 34 |actions: {0: 481, 1: 555, 2: 329, 3: 298, 4: 295, 5: 501, 6: 348, 7: 229, 8: 234}
episode: 20/2000 -> reward: 47.80208333333335, steps:3270, time-taken: 1.87min, time-elasped: 36.52min
-> berries picked: 34 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 420 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [24, 93, 87, 54, 71, 39, 11, 16, 25]
	| approx positives in sample 512: 35
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 7, 8] [3, 10, 10, 1, 1, 3, 3, 4]
	Time taken saving stuff: 0.16s

=== episode:2 Env-steps-taken:57984
 	picked: 34 |actions: {0: 1823, 1: 458, 2: 147, 3: 91, 4: 1758, 5: 714, 6: 57, 7: 0, 8: 224}

==================================================
eval-episode: 20 -> reward: 50.05208333333336, steps: 5272.0, wall-time: 55.03s
-> berries picked: 34 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:21 Env-steps-taken:62208
 	picked: 48 |actions: {0: 720, 1: 519, 2: 379, 3: 479, 4: 336, 5: 570, 6: 571, 7: 349, 8: 346}
episode: 21/2000 -> reward: 71.50000000000001, steps:4269, time-taken: 2.43min, time-elasped: 39.87min
-> berries picked: 48 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 464 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [28, 101, 94, 57, 80, 40, 18, 17, 29]
	| approx positives in sample 512: 38
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 7, 8] [1, 8, 8, 5, 4, 5, 3, 4]
	Time taken saving stuff: 0.04s

=== episode:22 Env-steps-taken:56736
 	picked: 35 |actions: {0: 552, 1: 599, 2: 284, 3: 267, 4: 313, 5: 281, 6: 496, 7: 211, 8: 216}
episode: 22/2000 -> reward: 43.744791666666686, steps:3219, time-taken: 1.62min, time-elasped: 41.49min
-> berries picked: 35 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 500 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [32, 110, 102, 58, 83, 43, 23, 17, 32]
	| approx positives in sample 512: 34
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 7, 9, 3, 1, 3, 2, 3, 3]
	Time taken saving stuff: 0.10s

=== episode:23 Env-steps-taken:62016
 	picked: 49 |actions: {0: 963, 1: 576, 2: 628, 3: 522, 4: 523, 5: 548, 6: 1032, 7: 343, 8: 503}
episode: 23/2000 -> reward: 70.19270833333336, steps:5638, time-taken: 2.65min, time-elasped: 44.15min
-> berries picked: 49 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 544 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [42, 117, 106, 65, 85, 47, 28, 19, 35]
	| approx positives in sample 512: 39
	| approx action-dist in sample 512: [0, 1, 2, 4, 5, 6, 7, 8] [10, 8, 7, 4, 3, 3, 3, 1]
	Time taken saving stuff: 0.10s

=== episode:24 Env-steps-taken:55008
 	picked: 25 |actions: {0: 502, 1: 457, 2: 216, 3: 221, 4: 282, 5: 313, 6: 503, 7: 184, 8: 291}
episode: 24/2000 -> reward: 35.06770833333334, steps:2969, time-taken: 1.53min, time-elasped: 45.68min
-> berries picked: 25 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 567 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [47, 123, 107, 67, 90, 50, 29, 19, 35]
	| approx positives in sample 512: 41
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 9, 8, 2, 2, 5, 3, 2, 2]
	Time taken saving stuff: 0.02s

=== episode:25 Env-steps-taken:56544
 	picked: 29 |actions: {0: 283, 1: 373, 2: 196, 3: 245, 4: 166, 5: 240, 6: 345, 7: 191, 8: 281}
episode: 25/2000 -> reward: 43.08854166666668, steps:2320, time-taken: 1.39min, time-elasped: 47.08min
-> berries picked: 29 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 596 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [54, 127, 111, 68, 89, 54, 35, 22, 36]
	| approx positives in sample 512: 44
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 10, 10, 4, 3, 5, 4, 2, 2]
	Time taken saving stuff: 0.09s

=== episode:26 Env-steps-taken:52704
 	picked: 16 |actions: {0: 205, 1: 235, 2: 149, 3: 180, 4: 357, 5: 226, 6: 180, 7: 111, 8: 300}
episode: 26/2000 -> reward: 23.583333333333332, steps:1943, time-taken: 1.07min, time-elasped: 48.16min
-> berries picked: 16 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 607 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [57, 131, 110, 68, 89, 56, 37, 22, 37]
	| approx positives in sample 512: 47
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 11, 12, 5, 2, 6, 2, 2, 1]
	Time taken saving stuff: 0.03s

=== episode:27 Env-steps-taken:61152
 	picked: 45 |actions: {0: 476, 1: 509, 2: 322, 3: 530, 4: 270, 5: 224, 6: 600, 7: 244, 8: 274}
episode: 27/2000 -> reward: 66.17187500000003, steps:3449, time-taken: 1.89min, time-elasped: 50.05min
-> berries picked: 45 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 652 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [62, 146, 115, 74, 90, 60, 41, 23, 41]
	| approx positives in sample 512: 49
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 10, 11, 7, 4, 3, 2, 2, 1]
	Time taken saving stuff: 0.11s

=== episode:28 Env-steps-taken:61728
 	picked: 44 |actions: {0: 755, 1: 738, 2: 484, 3: 673, 4: 573, 5: 527, 6: 945, 7: 497, 8: 420}
episode: 28/2000 -> reward: 68.97916666666667, steps:5612, time-taken: 2.64min, time-elasped: 52.69min
-> berries picked: 44 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 683 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [67, 159, 119, 74, 95, 61, 44, 23, 41]
	| approx positives in sample 512: 65
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 15, 12, 4, 5, 9, 7, 3]
	Time taken saving stuff: 0.10s

=== episode:29 Env-steps-taken:56544
 	picked: 30 |actions: {0: 388, 1: 734, 2: 466, 3: 419, 4: 441, 5: 477, 6: 660, 7: 467, 8: 606}
episode: 29/2000 -> reward: 43.031250000000014, steps:4658, time-taken: 2.48min, time-elasped: 55.18min
-> berries picked: 30 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 711 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [70, 163, 122, 78, 101, 64, 46, 23, 44]
	| approx positives in sample 512: 52
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 13, 5, 8, 5, 6, 4, 3, 3]
	Time taken saving stuff: 0.00s

=== episode:30 Env-steps-taken:55488
 	picked: 24 |actions: {0: 277, 1: 292, 2: 212, 3: 205, 4: 308, 5: 189, 6: 214, 7: 265, 8: 234}
episode: 30/2000 -> reward: 35.98958333333334, steps:2196, time-taken: 1.52min, time-elasped: 56.70min
-> berries picked: 24 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 730 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [72, 166, 122, 82, 101, 66, 49, 25, 47]
	| approx positives in sample 512: 52
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 13, 9, 1, 4, 8, 5, 1, 5]
	Time taken saving stuff: 0.05s

=== episode:3 Env-steps-taken:54528
 	picked: 22 |actions: {0: 145, 1: 207, 2: 117, 3: 104, 4: 85, 5: 57, 6: 188, 7: 61, 8: 135}

==================================================
eval-episode: 30 -> reward: 32.73958333333333, steps: 1099.0, wall-time: 38.24s
-> berries picked: 22 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:31 Env-steps-taken:51360
 	picked: 10 |actions: {0: 147, 1: 383, 2: 106, 3: 153, 4: 94, 5: 467, 6: 272, 7: 117, 8: 211}
episode: 31/2000 -> reward: 16.92708333333334, steps:1950, time-taken: 1.67min, time-elasped: 59.01min
-> berries picked: 10 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 737 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [73, 168, 124, 82, 100, 67, 50, 25, 48]
	| approx positives in sample 512: 48
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 7, 6, 8, 5, 5, 5, 2, 3]
	Time taken saving stuff: 0.22s

=== episode:32 Env-steps-taken:59424
 	picked: 41 |actions: {0: 307, 1: 464, 2: 371, 3: 270, 4: 508, 5: 416, 6: 491, 7: 274, 8: 578}
episode: 32/2000 -> reward: 55.45833333333338, steps:3679, time-taken: 2.98min, time-elasped: 62.01min
-> berries picked: 41 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 774 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [77, 177, 131, 86, 103, 69, 54, 27, 50]
	| approx positives in sample 512: 48
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 9, 13, 3, 3, 4, 5, 2, 3]
	Time taken saving stuff: 0.10s

=== episode:33 Env-steps-taken:60864
 	picked: 43 |actions: {0: 393, 1: 459, 2: 341, 3: 355, 4: 321, 5: 276, 6: 490, 7: 363, 8: 518}
episode: 33/2000 -> reward: 65.03645833333339, steps:3516, time-taken: 2.45min, time-elasped: 64.47min
-> berries picked: 43 of 800 | patches-visited: [0, 4, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 816 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [84, 188, 136, 90, 108, 71, 55, 30, 54]
	| approx positives in sample 512: 54
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 12, 13, 3, 3, 6, 4, 3, 2]
	Time taken saving stuff: 0.01s

=== episode:34 Env-steps-taken:56928
 	picked: 31 |actions: {0: 472, 1: 467, 2: 351, 3: 303, 4: 367, 5: 256, 6: 386, 7: 546, 8: 597}
episode: 34/2000 -> reward: 44.72395833333334, steps:3745, time-taken: 2.42min, time-elasped: 66.88min
-> berries picked: 31 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 845 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [86, 197, 141, 94, 112, 71, 58, 32, 54]
	| approx positives in sample 512: 45
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 9, 6, 6, 7, 5, 3, 1]
	Time taken saving stuff: 0.03s

=== episode:35 Env-steps-taken:62400
 	picked: 48 |actions: {0: 302, 1: 462, 2: 590, 3: 380, 4: 429, 5: 357, 6: 416, 7: 325, 8: 602}
episode: 35/2000 -> reward: 70.80729166666669, steps:3863, time-taken: 2.50min, time-elasped: 69.39min
-> berries picked: 48 of 800 | patches-visited: [0, 4, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 881 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [91, 206, 143, 97, 119, 77, 59, 33, 56]
	| approx positives in sample 512: 46
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 9, 6, 3, 7, 2, 6, 1, 6]
	Time taken saving stuff: 0.00s

=== episode:36 Env-steps-taken:49152
 	picked: 5 |actions: {0: 86, 1: 80, 2: 92, 3: 88, 4: 169, 5: 91, 6: 95, 7: 61, 8: 190}
episode: 36/2000 -> reward: 5.713541666666665, steps:952, time-taken: 1.00min, time-elasped: 70.39min
-> berries picked: 5 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 886 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [92, 206, 143, 99, 119, 78, 60, 33, 56]
	| approx positives in sample 512: 48
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 13, 6, 2, 3, 7, 5, 1, 5]
	Time taken saving stuff: 0.04s

=== episode:37 Env-steps-taken:60576
 	picked: 45 |actions: {0: 776, 1: 531, 2: 498, 3: 464, 4: 694, 5: 394, 6: 672, 7: 849, 8: 629}
episode: 37/2000 -> reward: 62.921875000000064, steps:5507, time-taken: 3.20min, time-elasped: 73.60min
-> berries picked: 45 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 921 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [105, 208, 142, 104, 122, 82, 66, 34, 58]
	| approx positives in sample 512: 49
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 10, 7, 8, 3, 6, 5, 1, 3]
	Time taken saving stuff: 0.03s

=== episode:38 Env-steps-taken:52032
 	picked: 16 |actions: {0: 540, 1: 396, 2: 291, 3: 278, 4: 485, 5: 358, 6: 486, 7: 523, 8: 703}
episode: 38/2000 -> reward: 20.333333333333336, steps:4060, time-taken: 2.72min, time-elasped: 76.32min
-> berries picked: 16 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 933 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [109, 208, 142, 106, 123, 81, 67, 37, 60]
	| approx positives in sample 512: 55
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 12, 9, 2, 5, 3, 8, 2, 6]
	Time taken saving stuff: 0.01s

=== episode:39 Env-steps-taken:56064
 	picked: 30 |actions: {0: 298, 1: 372, 2: 282, 3: 343, 4: 403, 5: 446, 6: 422, 7: 601, 8: 617}
episode: 39/2000 -> reward: 40.531250000000014, steps:3784, time-taken: 2.24min, time-elasped: 78.56min
-> berries picked: 30 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 958 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [114, 212, 143, 108, 123, 84, 70, 43, 61]
	| approx positives in sample 512: 69
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 11, 12, 8, 6, 6, 6, 5, 3]
	Time taken saving stuff: 0.02s

=== episode:40 Env-steps-taken:63648
 	picked: 52 |actions: {0: 354, 1: 483, 2: 469, 3: 412, 4: 439, 5: 537, 6: 593, 7: 629, 8: 647}
episode: 40/2000 -> reward: 79.02083333333333, steps:4563, time-taken: 3.01min, time-elasped: 81.58min
-> berries picked: 52 of 800 | patches-visited: [0, 2, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1003 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [119, 217, 146, 115, 129, 91, 75, 47, 64]
	| approx positives in sample 512: 57
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 13, 11, 5, 4, 4, 5, 3, 6]
	Time taken saving stuff: 0.10s

=== episode:4 Env-steps-taken:68352
 	picked: 66 |actions: {0: 428, 1: 172, 2: 64, 3: 543, 4: 190, 5: 280, 6: 399, 7: 409, 8: 396}

==================================================
eval-episode: 40 -> reward: 102.96874999999994, steps: 2881.0, wall-time: 66.96s
-> berries picked: 66 of 800 | patches-visited: [0, 1, 3, 9] | juice left:-0.00
==================================================


=== episode:41 Env-steps-taken:62400
 	picked: 47 |actions: {0: 380, 1: 278, 2: 401, 3: 437, 4: 754, 5: 394, 6: 583, 7: 445, 8: 557}
episode: 41/2000 -> reward: 72.55729166666669, steps:4229, time-taken: 2.99min, time-elasped: 85.69min
-> berries picked: 47 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1042 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [124, 217, 149, 116, 140, 93, 88, 51, 64]
	| approx positives in sample 512: 70
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 9, 8, 8, 7, 5, 7, 8, 3]
	Time taken saving stuff: 0.04s

=== episode:42 Env-steps-taken:62880
 	picked: 57 |actions: {0: 388, 1: 394, 2: 475, 3: 483, 4: 600, 5: 460, 6: 629, 7: 655, 8: 608}
episode: 42/2000 -> reward: 74.04166666666667, steps:4692, time-taken: 2.75min, time-elasped: 88.44min
-> berries picked: 57 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1087 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [128, 223, 155, 119, 151, 98, 93, 54, 66]
	| approx positives in sample 512: 74
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 20, 7, 2, 9, 4, 13, 3, 10]
	Time taken saving stuff: 0.00s

=== episode:43 Env-steps-taken:60864
 	picked: 48 |actions: {0: 396, 1: 811, 2: 581, 3: 548, 4: 517, 5: 463, 6: 473, 7: 703, 8: 809}
episode: 43/2000 -> reward: 64.25000000000007, steps:5301, time-taken: 3.31min, time-elasped: 91.76min
-> berries picked: 48 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1126 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [131, 228, 160, 125, 156, 102, 98, 54, 72]
	| approx positives in sample 512: 70
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 14, 6, 5, 7, 9, 11, 5, 4]
	Time taken saving stuff: 0.02s

=== episode:44 Env-steps-taken:60960
 	picked: 44 |actions: {0: 378, 1: 503, 2: 404, 3: 720, 4: 388, 5: 424, 6: 465, 7: 700, 8: 549}
episode: 44/2000 -> reward: 63.286458333333385, steps:4531, time-taken: 2.72min, time-elasped: 94.48min
-> berries picked: 44 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1158 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [137, 233, 161, 129, 158, 104, 104, 58, 74]
	| approx positives in sample 512: 79
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 15, 11, 2, 13, 9, 11, 6, 3]
	Time taken saving stuff: 0.09s

=== episode:45 Env-steps-taken:62016
 	picked: 50 |actions: {0: 434, 1: 473, 2: 387, 3: 531, 4: 454, 5: 564, 6: 741, 7: 620, 8: 799}
episode: 45/2000 -> reward: 70.3854166666667, steps:5003, time-taken: 3.10min, time-elasped: 97.59min
-> berries picked: 50 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1196 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [139, 239, 166, 131, 164, 109, 110, 61, 77]
	| approx positives in sample 512: 59
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 10, 7, 4, 5, 9, 7, 5, 5]
	Time taken saving stuff: 0.08s

=== episode:46 Env-steps-taken:60672
 	picked: 45 |actions: {0: 542, 1: 476, 2: 430, 3: 461, 4: 592, 5: 923, 6: 462, 7: 909, 8: 721}
episode: 46/2000 -> reward: 63.42187500000004, steps:5516, time-taken: 3.40min, time-elasped: 101.00min
-> berries picked: 45 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1223 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [147, 241, 165, 132, 167, 114, 116, 64, 77]
	| approx positives in sample 512: 61
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 14, 7, 5, 7, 7, 5, 5, 3]
	Time taken saving stuff: 0.00s

=== episode:47 Env-steps-taken:61248
 	picked: 51 |actions: {0: 401, 1: 410, 2: 401, 3: 498, 4: 404, 5: 744, 6: 584, 7: 748, 8: 658}
episode: 47/2000 -> reward: 66.32812500000006, steps:4848, time-taken: 3.14min, time-elasped: 104.15min
-> berries picked: 51 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1257 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [155, 241, 167, 135, 167, 117, 125, 70, 80]
	| approx positives in sample 512: 59
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 15, 4, 3, 3, 6, 12, 4, 3]
	Time taken saving stuff: 0.03s

=== episode:48 Env-steps-taken:62496
 	picked: 49 |actions: {0: 494, 1: 522, 2: 567, 3: 520, 4: 807, 5: 648, 6: 715, 7: 770, 8: 566}
episode: 48/2000 -> reward: 72.69270833333336, steps:5609, time-taken: 3.44min, time-elasped: 107.59min
-> berries picked: 49 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1291 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [162, 240, 169, 134, 172, 125, 135, 73, 81]
	| approx positives in sample 512: 77
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 11, 10, 2, 9, 9, 11, 8, 2]
	Time taken saving stuff: 0.01s

=== episode:49 Env-steps-taken:67872
 	picked: 71 |actions: {0: 444, 1: 556, 2: 599, 3: 781, 4: 668, 5: 614, 6: 562, 7: 632, 8: 650}
episode: 49/2000 -> reward: 99.68229166666656, steps:5506, time-taken: 3.39min, time-elasped: 110.98min
-> berries picked: 71 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1350 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [168, 246, 174, 140, 180, 136, 146, 77, 83]
	| approx positives in sample 512: 71
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 9, 4, 5, 6, 8, 6, 11, 7]
	Time taken saving stuff: 0.03s

=== episode:50 Env-steps-taken:64896
 	picked: 66 |actions: {0: 534, 1: 616, 2: 787, 3: 858, 4: 665, 5: 655, 6: 506, 7: 563, 8: 716}
episode: 50/2000 -> reward: 84.21875, steps:5900, time-taken: 3.44min, time-elasped: 114.43min
-> berries picked: 66 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1395 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [169, 256, 174, 146, 187, 139, 154, 83, 87]
	| approx positives in sample 512: 84
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 13, 11, 8, 7, 11, 11, 7, 3]
	Time taken saving stuff: 0.16s

=== episode:5 Env-steps-taken:70560
 	picked: 80 |actions: {0: 483, 1: 668, 2: 385, 3: 950, 4: 403, 5: 865, 6: 177, 7: 1252, 8: 991}

==================================================
eval-episode: 50 -> reward: 112.2812499999999, steps: 6174.0, wall-time: 78.66s
-> berries picked: 80 of 800 | patches-visited: [1, 4] | juice left:-0.00
==================================================


=== episode:51 Env-steps-taken:63936
 	picked: 61 |actions: {0: 494, 1: 616, 2: 697, 3: 576, 4: 508, 5: 479, 6: 578, 7: 866, 8: 845}
episode: 51/2000 -> reward: 79.5052083333333, steps:5659, time-taken: 3.58min, time-elasped: 119.32min
-> berries picked: 61 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1441 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [174, 263, 180, 146, 191, 144, 164, 90, 89]
	| approx positives in sample 512: 93
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 11, 11, 7, 10, 10, 18, 11, 3]
	Time taken saving stuff: 0.02s

=== episode:52 Env-steps-taken:70752
 	picked: 83 |actions: {0: 616, 1: 707, 2: 621, 3: 669, 4: 740, 5: 539, 6: 572, 7: 597, 8: 444}
episode: 52/2000 -> reward: 113.99479166666653, steps:5505, time-taken: 3.47min, time-elasped: 122.79min
-> berries picked: 83 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1513 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [184, 273, 191, 156, 199, 149, 174, 97, 90]
	| approx positives in sample 512: 96
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [24, 8, 9, 8, 8, 12, 12, 6, 9]
	Time taken saving stuff: 0.00s

=== episode:53 Env-steps-taken:62496
 	picked: 54 |actions: {0: 404, 1: 598, 2: 701, 3: 560, 4: 492, 5: 603, 6: 645, 7: 710, 8: 410}
episode: 53/2000 -> reward: 72.65625, steps:5123, time-taken: 3.41min, time-elasped: 126.20min
-> berries picked: 54 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1551 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [190, 274, 192, 160, 206, 155, 179, 103, 92]
	| approx positives in sample 512: 92
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 19, 6, 6, 8, 9, 16, 11, 6]
	Time taken saving stuff: 0.01s

=== episode:54 Env-steps-taken:59712
 	picked: 44 |actions: {0: 447, 1: 601, 2: 690, 3: 453, 4: 367, 5: 592, 6: 484, 7: 441, 8: 521}
episode: 54/2000 -> reward: 58.7291666666667, steps:4596, time-taken: 2.81min, time-elasped: 129.01min
-> berries picked: 44 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1576 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [194, 275, 198, 161, 205, 161, 183, 104, 95]
	| approx positives in sample 512: 81
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 21, 5, 1, 10, 12, 14, 6, 3]
	Time taken saving stuff: 0.01s

=== episode:55 Env-steps-taken:57504
 	picked: 34 |actions: {0: 290, 1: 585, 2: 395, 3: 595, 4: 337, 5: 345, 6: 420, 7: 796, 8: 409}
episode: 55/2000 -> reward: 47.55208333333336, steps:4172, time-taken: 2.81min, time-elasped: 131.83min
-> berries picked: 34 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1594 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [196, 277, 194, 164, 208, 162, 187, 110, 96]
	| approx positives in sample 512: 96
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 13, 11, 10, 10, 10, 13, 9, 10]
	Time taken saving stuff: 0.09s

=== episode:56 Env-steps-taken:59232
 	picked: 37 |actions: {0: 256, 1: 363, 2: 359, 3: 228, 4: 382, 5: 392, 6: 314, 7: 254, 8: 191}
episode: 56/2000 -> reward: 55.49479166666669, steps:2739, time-taken: 1.99min, time-elasped: 133.83min
-> berries picked: 37 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1620 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [196, 280, 197, 168, 214, 165, 193, 111, 96]
	| approx positives in sample 512: 82
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 11, 6, 5, 8, 8, 20, 7, 4]
	Time taken saving stuff: 0.01s

=== episode:57 Env-steps-taken:63072
 	picked: 57 |actions: {0: 404, 1: 907, 2: 502, 3: 488, 4: 469, 5: 381, 6: 503, 7: 411, 8: 468}
episode: 57/2000 -> reward: 75.23437500000001, steps:4533, time-taken: 2.91min, time-elasped: 136.74min
-> berries picked: 57 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1661 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [203, 283, 205, 168, 219, 172, 200, 113, 98]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 14, 4, 9, 13, 13, 14, 10, 10]
	Time taken saving stuff: 0.08s

=== episode:58 Env-steps-taken:64992
 	picked: 65 |actions: {0: 489, 1: 845, 2: 959, 3: 730, 4: 612, 5: 525, 6: 628, 7: 646, 8: 444}
episode: 58/2000 -> reward: 84.77604166666664, steps:5878, time-taken: 3.72min, time-elasped: 140.46min
-> berries picked: 65 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1700 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [207, 290, 206, 173, 220, 173, 212, 121, 98]
	| approx positives in sample 512: 96
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 18, 8, 8, 14, 12, 14, 7, 5]
	Time taken saving stuff: 0.01s

=== episode:59 Env-steps-taken:62208
 	picked: 52 |actions: {0: 518, 1: 968, 2: 767, 3: 515, 4: 611, 5: 534, 6: 553, 7: 584, 8: 606}
episode: 59/2000 -> reward: 71.02083333333336, steps:5656, time-taken: 3.45min, time-elasped: 143.91min
-> berries picked: 52 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1730 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [212, 298, 207, 176, 221, 177, 215, 124, 100]
	| approx positives in sample 512: 91
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 6, 10, 9, 8, 12, 11, 10, 7]
	Time taken saving stuff: 0.00s

=== episode:60 Env-steps-taken:63072
 	picked: 58 |actions: {0: 487, 1: 561, 2: 900, 3: 645, 4: 548, 5: 549, 6: 531, 7: 525, 8: 472}
episode: 60/2000 -> reward: 75.17708333333333, steps:5218, time-taken: 3.30min, time-elasped: 147.22min
-> berries picked: 58 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1761 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [217, 299, 213, 175, 227, 181, 218, 131, 100]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 11, 14, 5, 6, 14, 22, 18, 3]
	Time taken saving stuff: 0.05s

=== episode:6 Env-steps-taken:56160
 	picked: 31 |actions: {0: 268, 1: 2065, 2: 63, 3: 73, 4: 324, 5: 1507, 6: 421, 7: 164, 8: 221}

==================================================
eval-episode: 60 -> reward: 39.83854166666667, steps: 5106.0, wall-time: 68.12s
-> berries picked: 31 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:61 Env-steps-taken:63648
 	picked: 67 |actions: {0: 588, 1: 601, 2: 832, 3: 698, 4: 636, 5: 506, 6: 497, 7: 687, 8: 478}
episode: 61/2000 -> reward: 77.66145833333334, steps:5523, time-taken: 3.57min, time-elasped: 151.93min
-> berries picked: 67 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1800 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [221, 301, 213, 177, 233, 191, 225, 138, 101]
	| approx positives in sample 512: 96
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 10, 6, 2, 11, 5, 21, 13, 9]
	Time taken saving stuff: 0.08s

=== episode:62 Env-steps-taken:66624
 	picked: 66 |actions: {0: 487, 1: 700, 2: 682, 3: 708, 4: 668, 5: 727, 6: 417, 7: 526, 8: 455}
episode: 62/2000 -> reward: 93.46874999999996, steps:5370, time-taken: 3.23min, time-elasped: 155.17min
-> berries picked: 66 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1835 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [222, 308, 224, 178, 237, 199, 226, 142, 99]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 11, 7, 2, 10, 15, 20, 13, 7]
	Time taken saving stuff: 0.03s

=== episode:63 Env-steps-taken:66048
 	picked: 67 |actions: {0: 509, 1: 560, 2: 689, 3: 706, 4: 697, 5: 565, 6: 515, 7: 607, 8: 555}
episode: 63/2000 -> reward: 88.46874999999999, steps:5403, time-taken: 3.72min, time-elasped: 158.90min
-> berries picked: 67 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1867 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [225, 301, 231, 186, 239, 209, 230, 145, 101]
	| approx positives in sample 512: 101
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 9, 7, 3, 19, 13, 11, 18, 7]
	Time taken saving stuff: 0.03s

=== episode:64 Env-steps-taken:62688
 	picked: 57 |actions: {0: 528, 1: 481, 2: 733, 3: 702, 4: 743, 5: 604, 6: 450, 7: 531, 8: 563}
episode: 64/2000 -> reward: 73.54166666666669, steps:5335, time-taken: 3.42min, time-elasped: 162.32min
-> berries picked: 57 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1891 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [230, 292, 228, 190, 240, 222, 234, 152, 103]
	| approx positives in sample 512: 100
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 16, 4, 3, 11, 19, 15, 11, 3]
	Time taken saving stuff: 0.08s

=== episode:65 Env-steps-taken:65760
 	picked: 59 |actions: {0: 372, 1: 469, 2: 550, 3: 575, 4: 466, 5: 479, 6: 374, 7: 478, 8: 351}
episode: 65/2000 -> reward: 89.36979166666663, steps:4114, time-taken: 2.80min, time-elasped: 165.12min
-> berries picked: 59 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1925 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [234, 296, 229, 196, 243, 225, 238, 159, 105]
	| approx positives in sample 512: 87
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 8, 10, 7, 7, 11, 17, 13, 4]
	Time taken saving stuff: 0.03s

=== episode:66 Env-steps-taken:55776
 	picked: 26 |actions: {0: 365, 1: 553, 2: 889, 3: 561, 4: 766, 5: 486, 6: 395, 7: 408, 8: 648}
episode: 66/2000 -> reward: 39.01041666666668, steps:5071, time-taken: 3.24min, time-elasped: 168.36min
-> berries picked: 26 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1911 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [235, 293, 225, 187, 240, 228, 238, 160, 105]
	| approx positives in sample 512: 89
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 10, 3, 3, 9, 5, 21, 20, 4]
	Time taken saving stuff: 0.10s

=== episode:67 Env-steps-taken:55008
 	picked: 26 |actions: {0: 174, 1: 282, 2: 308, 3: 313, 4: 201, 5: 219, 6: 298, 7: 256, 8: 183}
episode: 67/2000 -> reward: 34.62499999999999, steps:2234, time-taken: 1.63min, time-elasped: 170.00min
-> berries picked: 26 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1920 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [238, 291, 224, 189, 238, 231, 240, 162, 107]
	| approx positives in sample 512: 93
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 9, 8, 4, 7, 13, 17, 13, 4]
	Time taken saving stuff: 0.01s

=== episode:68 Env-steps-taken:64608
 	picked: 57 |actions: {0: 626, 1: 583, 2: 796, 3: 663, 4: 493, 5: 431, 6: 534, 7: 510, 8: 606}
episode: 68/2000 -> reward: 83.48437499999996, steps:5242, time-taken: 3.45min, time-elasped: 173.45min
-> berries picked: 57 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1936 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [244, 288, 223, 190, 241, 233, 245, 164, 108]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 6, 9, 3, 10, 20, 19, 19, 6]
	Time taken saving stuff: 0.09s

=== episode:69 Env-steps-taken:65856
 	picked: 70 |actions: {0: 618, 1: 741, 2: 853, 3: 751, 4: 457, 5: 541, 6: 635, 7: 608, 8: 733}
episode: 69/2000 -> reward: 88.98958333333327, steps:5937, time-taken: 3.67min, time-elasped: 177.13min
-> berries picked: 70 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1968 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [251, 290, 224, 195, 239, 238, 253, 170, 108]
	| approx positives in sample 512: 95
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 7, 5, 9, 6, 15, 19, 15, 4]
	Time taken saving stuff: 0.10s

=== episode:70 Env-steps-taken:59808
 	picked: 38 |actions: {0: 377, 1: 371, 2: 323, 3: 364, 4: 280, 5: 241, 6: 337, 7: 352, 8: 206}
episode: 70/2000 -> reward: 59.32291666666671, steps:2851, time-taken: 2.01min, time-elasped: 179.14min
-> berries picked: 38 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1975 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [256, 291, 217, 191, 243, 239, 254, 175, 109]
	| approx positives in sample 512: 100
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 11, 4, 7, 12, 14, 18, 11, 9]
	Time taken saving stuff: 0.08s

=== episode:7 Env-steps-taken:65856
 	picked: 65 |actions: {0: 298, 1: 1109, 2: 121, 3: 395, 4: 43, 5: 1083, 6: 899, 7: 290, 8: 1365}

==================================================
eval-episode: 70 -> reward: 88.64062499999994, steps: 5603.0, wall-time: 68.37s
-> berries picked: 65 of 800 | patches-visited: [1, 4] | juice left:-0.00
==================================================


=== episode:71 Env-steps-taken:63264
 	picked: 57 |actions: {0: 496, 1: 481, 2: 604, 3: 380, 4: 365, 5: 458, 6: 457, 7: 501, 8: 316}
episode: 71/2000 -> reward: 76.234375, steps:4058, time-taken: 2.73min, time-elasped: 183.02min
-> berries picked: 57 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1997 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [261, 294, 222, 184, 241, 244, 261, 182, 108]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 6, 5, 7, 9, 12, 22, 16, 5]
	Time taken saving stuff: 0.01s

=== episode:72 Env-steps-taken:64992
 	picked: 64 |actions: {0: 619, 1: 704, 2: 744, 3: 574, 4: 471, 5: 480, 6: 501, 7: 649, 8: 414}
episode: 72/2000 -> reward: 84.8333333333333, steps:5156, time-taken: 3.28min, time-elasped: 186.30min
-> berries picked: 64 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2033 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [271, 297, 223, 188, 242, 248, 267, 188, 109]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 13, 9, 9, 13, 13, 18, 18, 8]
	Time taken saving stuff: 0.01s

=== episode:73 Env-steps-taken:55584
 	picked: 28 |actions: {0: 478, 1: 371, 2: 643, 3: 551, 4: 1069, 5: 405, 6: 448, 7: 832, 8: 257}
episode: 73/2000 -> reward: 37.89583333333334, steps:5054, time-taken: 3.09min, time-elasped: 189.39min
-> berries picked: 28 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2036 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [271, 292, 226, 188, 243, 247, 272, 189, 108]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 7, 6, 4, 8, 17, 25, 19, 5]
	Time taken saving stuff: 0.09s

=== episode:74 Env-steps-taken:64992
 	picked: 64 |actions: {0: 450, 1: 501, 2: 602, 3: 615, 4: 470, 5: 589, 6: 471, 7: 550, 8: 414}
episode: 74/2000 -> reward: 85.0833333333333, steps:4662, time-taken: 3.13min, time-elasped: 192.53min
-> berries picked: 64 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2073 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [279, 298, 228, 189, 246, 244, 280, 197, 112]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [28, 15, 10, 6, 7, 7, 10, 17, 9]
	Time taken saving stuff: 0.08s

=== episode:75 Env-steps-taken:64416
 	picked: 65 |actions: {0: 461, 1: 595, 2: 656, 3: 532, 4: 484, 5: 407, 6: 477, 7: 547, 8: 412}
episode: 75/2000 -> reward: 82.02604166666666, steps:4571, time-taken: 3.01min, time-elasped: 195.54min
-> berries picked: 65 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2108 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [293, 303, 229, 185, 248, 250, 284, 202, 114]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 12, 9, 3, 7, 14, 20, 12, 2]
	Time taken saving stuff: 0.03s

=== episode:76 Env-steps-taken:69024
 	picked: 81 |actions: {0: 488, 1: 644, 2: 664, 3: 666, 4: 499, 5: 479, 6: 542, 7: 661, 8: 340}
episode: 76/2000 -> reward: 105.35937499999993, steps:4983, time-taken: 3.52min, time-elasped: 199.07min
-> berries picked: 81 of 800 | patches-visited: [0, 3, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2154 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [297, 313, 227, 194, 247, 253, 295, 210, 118]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 8, 4, 6, 8, 13, 23, 24, 6]
	Time taken saving stuff: 0.08s

=== episode:77 Env-steps-taken:67392
 	picked: 76 |actions: {0: 611, 1: 698, 2: 778, 3: 757, 4: 548, 5: 624, 6: 508, 7: 640, 8: 368}
episode: 77/2000 -> reward: 96.89583333333326, steps:5532, time-taken: 3.22min, time-elasped: 202.29min
-> berries picked: 76 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2190 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [303, 313, 228, 197, 251, 257, 303, 217, 121]
	| approx positives in sample 512: 100
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 10, 8, 8, 11, 8, 21, 17, 1]
	Time taken saving stuff: 0.03s

=== episode:78 Env-steps-taken:60384
 	picked: 49 |actions: {0: 485, 1: 402, 2: 757, 3: 440, 4: 447, 5: 426, 6: 466, 7: 596, 8: 313}
episode: 78/2000 -> reward: 61.94270833333338, steps:4332, time-taken: 2.67min, time-elasped: 204.97min
-> berries picked: 49 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2206 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [306, 320, 225, 190, 254, 260, 309, 219, 123]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 16, 6, 7, 6, 10, 18, 18, 8]
	Time taken saving stuff: 0.07s

=== episode:79 Env-steps-taken:54720
 	picked: 23 |actions: {0: 121, 1: 203, 2: 253, 3: 233, 4: 142, 5: 238, 6: 231, 7: 179, 8: 120}
episode: 79/2000 -> reward: 33.682291666666664, steps:1720, time-taken: 1.43min, time-elasped: 206.40min
-> berries picked: 23 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2214 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [308, 316, 224, 192, 256, 261, 311, 223, 123]
	| approx positives in sample 512: 101
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 9, 3, 6, 11, 10, 18, 18, 8]
	Time taken saving stuff: 0.04s

=== episode:80 Env-steps-taken:76224
 	picked: 105 |actions: {0: 734, 1: 569, 2: 918, 3: 661, 4: 795, 5: 685, 6: 812, 7: 778, 8: 460}
episode: 80/2000 -> reward: 141.23437499999991, steps:6412, time-taken: 3.87min, time-elasped: 210.28min
-> berries picked: 105 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2278 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [320, 323, 230, 193, 266, 268, 324, 229, 125]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [23, 9, 6, 10, 7, 12, 23, 22, 8]
	Time taken saving stuff: 0.18s

=== episode:8 Env-steps-taken:67680
 	picked: 77 |actions: {0: 291, 1: 1630, 2: 2293, 3: 290, 4: 481, 5: 445, 6: 260, 7: 463, 8: 0}

==================================================
eval-episode: 80 -> reward: 98.33854166666657, steps: 6153.0, wall-time: 55.26s
-> berries picked: 77 of 800 | patches-visited: [1, 4] | juice left:-0.00
==================================================


=== episode:81 Env-steps-taken:64992
 	picked: 59 |actions: {0: 455, 1: 489, 2: 742, 3: 722, 4: 446, 5: 432, 6: 621, 7: 648, 8: 342}
episode: 81/2000 -> reward: 85.36979166666666, steps:4897, time-taken: 3.27min, time-elasped: 214.47min
-> berries picked: 59 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2304 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [325, 325, 226, 192, 268, 274, 330, 237, 127]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 10, 2, 1, 11, 16, 29, 20, 4]
	Time taken saving stuff: 0.00s

=== episode:82 Env-steps-taken:70656
 	picked: 78 |actions: {0: 437, 1: 488, 2: 660, 3: 511, 4: 448, 5: 470, 6: 444, 7: 502, 8: 300}
episode: 82/2000 -> reward: 111.83854166666657, steps:4260, time-taken: 2.88min, time-elasped: 217.35min
-> berries picked: 78 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2342 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [326, 324, 231, 196, 273, 276, 339, 247, 130]
	| approx positives in sample 512: 101
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 11, 6, 2, 5, 9, 26, 18, 8]
	Time taken saving stuff: 0.03s

=== episode:83 Env-steps-taken:60384
 	picked: 52 |actions: {0: 428, 1: 566, 2: 903, 3: 450, 4: 463, 5: 334, 6: 436, 7: 518, 8: 350}
episode: 83/2000 -> reward: 61.52083333333338, steps:4448, time-taken: 2.72min, time-elasped: 220.08min
-> berries picked: 52 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2354 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [331, 329, 227, 196, 265, 282, 340, 255, 129]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 14, 7, 7, 14, 12, 19, 17, 9]
	Time taken saving stuff: 0.02s

=== episode:84 Env-steps-taken:63168
 	picked: 54 |actions: {0: 396, 1: 353, 2: 645, 3: 555, 4: 440, 5: 355, 6: 397, 7: 446, 8: 201}
episode: 84/2000 -> reward: 75.90625, steps:3788, time-taken: 2.60min, time-elasped: 222.69min
-> berries picked: 54 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2376 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [337, 323, 232, 196, 267, 288, 343, 261, 129]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 6, 8, 12, 9, 13, 26, 24, 13]
	Time taken saving stuff: 0.01s

=== episode:85 Env-steps-taken:71808
 	picked: 89 |actions: {0: 765, 1: 651, 2: 1105, 3: 710, 4: 622, 5: 529, 6: 659, 7: 707, 8: 489}
episode: 85/2000 -> reward: 119.15104166666654, steps:6237, time-taken: 4.08min, time-elasped: 226.78min
-> berries picked: 89 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2401 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [349, 326, 227, 195, 263, 290, 354, 266, 131]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 14, 10, 4, 8, 10, 23, 22, 4]
	Time taken saving stuff: 0.06s

=== episode:86 Env-steps-taken:59328
 	picked: 38 |actions: {0: 275, 1: 288, 2: 994, 3: 469, 4: 271, 5: 265, 6: 321, 7: 393, 8: 268}
episode: 86/2000 -> reward: 57.07291666666671, steps:3544, time-taken: 2.31min, time-elasped: 229.09min
-> berries picked: 38 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2406 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [353, 321, 222, 194, 265, 291, 359, 268, 133]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 8, 8, 6, 9, 10, 28, 19, 8]
	Time taken saving stuff: 0.09s

=== episode:87 Env-steps-taken:56736
 	picked: 28 |actions: {0: 140, 1: 203, 2: 388, 3: 299, 4: 223, 5: 168, 6: 128, 7: 165, 8: 190}
episode: 87/2000 -> reward: 44.14583333333336, steps:1904, time-taken: 1.72min, time-elasped: 230.82min
-> berries picked: 28 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2413 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [353, 323, 222, 195, 264, 291, 362, 269, 134]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 14, 9, 2, 9, 12, 30, 25, 7]
	Time taken saving stuff: 0.07s

=== episode:88 Env-steps-taken:55392
 	picked: 24 |actions: {0: 178, 1: 203, 2: 180, 3: 214, 4: 111, 5: 170, 6: 190, 7: 294, 8: 181}
episode: 88/2000 -> reward: 37.12500000000001, steps:1721, time-taken: 1.38min, time-elasped: 232.20min
-> berries picked: 24 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2423 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [357, 322, 224, 194, 263, 294, 364, 270, 135]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [24, 14, 8, 7, 11, 16, 24, 15, 2]
	Time taken saving stuff: 0.09s

=== episode:89 Env-steps-taken:55872
 	picked: 31 |actions: {0: 799, 1: 396, 2: 682, 3: 858, 4: 454, 5: 394, 6: 420, 7: 663, 8: 414}
episode: 89/2000 -> reward: 39.22395833333334, steps:5080, time-taken: 3.03min, time-elasped: 235.24min
-> berries picked: 31 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2412 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [362, 317, 221, 191, 259, 292, 365, 270, 135]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 8, 9, 10, 9, 13, 22, 21, 5]
	Time taken saving stuff: 0.04s

=== episode:90 Env-steps-taken:57312
 	picked: 34 |actions: {0: 206, 1: 270, 2: 405, 3: 383, 4: 271, 5: 197, 6: 173, 7: 204, 8: 203}
episode: 90/2000 -> reward: 46.552083333333364, steps:2312, time-taken: 1.73min, time-elasped: 236.97min
-> berries picked: 34 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2433 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [363, 323, 225, 195, 262, 293, 365, 272, 135]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 8, 5, 7, 11, 14, 16, 20, 4]
	Time taken saving stuff: 0.25s

=== episode:9 Env-steps-taken:63168
 	picked: 54 |actions: {0: 282, 1: 761, 2: 3382, 3: 724, 4: 151, 5: 76, 6: 354, 7: 7, 8: 6}

==================================================
eval-episode: 90 -> reward: 76.15624999999999, steps: 5743.0, wall-time: 45.66s
-> berries picked: 54 of 800 | patches-visited: [1, 4] | juice left:-0.00
==================================================


=== episode:91 Env-steps-taken:66720
 	picked: 67 |actions: {0: 470, 1: 454, 2: 703, 3: 682, 4: 529, 5: 530, 6: 772, 7: 691, 8: 651}
episode: 91/2000 -> reward: 94.16145833333329, steps:5482, time-taken: 3.45min, time-elasped: 241.18min
-> berries picked: 67 of 800 | patches-visited: [0, 1, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2443 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [369, 323, 220, 193, 255, 297, 373, 275, 138]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 13, 4, 8, 5, 13, 18, 25, 6]
	Time taken saving stuff: 0.10s

=== episode:92 Env-steps-taken:68448
 	picked: 72 |actions: {0: 482, 1: 563, 2: 656, 3: 725, 4: 540, 5: 418, 6: 697, 7: 541, 8: 469}
episode: 92/2000 -> reward: 102.8749999999999, steps:5091, time-taken: 3.19min, time-elasped: 244.38min
-> berries picked: 72 of 800 | patches-visited: [0, 4, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2463 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [371, 325, 224, 187, 249, 298, 384, 285, 140]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 13, 8, 9, 5, 9, 21, 25, 3]
	Time taken saving stuff: 0.11s

=== episode:93 Env-steps-taken:61920
 	picked: 57 |actions: {0: 379, 1: 465, 2: 795, 3: 905, 4: 449, 5: 414, 6: 554, 7: 543, 8: 524}
episode: 93/2000 -> reward: 69.23437500000004, steps:5028, time-taken: 3.22min, time-elasped: 247.60min
-> berries picked: 57 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2477 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [371, 330, 225, 186, 248, 297, 389, 290, 141]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 9, 5, 3, 14, 8, 20, 24, 5]
	Time taken saving stuff: 0.09s

=== episode:94 Env-steps-taken:63648
 	picked: 62 |actions: {0: 561, 1: 558, 2: 848, 3: 889, 4: 667, 5: 463, 6: 646, 7: 526, 8: 553}
episode: 94/2000 -> reward: 77.94791666666667, steps:5711, time-taken: 3.38min, time-elasped: 250.98min
-> berries picked: 62 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2499 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [376, 335, 226, 189, 249, 299, 388, 298, 139]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 9, 5, 5, 9, 6, 23, 16, 8]
	Time taken saving stuff: 0.03s

=== episode:95 Env-steps-taken:63744
 	picked: 60 |actions: {0: 365, 1: 493, 2: 703, 3: 640, 4: 496, 5: 419, 6: 544, 7: 468, 8: 355}
episode: 95/2000 -> reward: 78.56249999999999, steps:4483, time-taken: 2.88min, time-elasped: 253.87min
-> berries picked: 60 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2518 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [377, 336, 222, 191, 255, 298, 392, 306, 141]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 11, 12, 3, 6, 10, 20, 24, 6]
	Time taken saving stuff: 0.02s

=== episode:96 Env-steps-taken:72288
 	picked: 84 |actions: {0: 339, 1: 534, 2: 703, 3: 540, 4: 598, 5: 542, 6: 493, 7: 592, 8: 252}
episode: 96/2000 -> reward: 118.60937499999986, steps:4593, time-taken: 2.93min, time-elasped: 256.81min
-> berries picked: 84 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2555 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [376, 340, 226, 198, 254, 305, 399, 314, 143]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 7, 3, 7, 14, 9, 24, 26, 6]
	Time taken saving stuff: 0.01s

=== episode:97 Env-steps-taken:70272
 	picked: 79 |actions: {0: 496, 1: 532, 2: 694, 3: 608, 4: 538, 5: 535, 6: 560, 7: 734, 8: 427}
episode: 97/2000 -> reward: 111.97395833333321, steps:5124, time-taken: 3.43min, time-elasped: 260.24min
-> berries picked: 79 of 800 | patches-visited: [0, 5, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2582 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [379, 332, 228, 198, 257, 311, 406, 324, 147]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 9, 15, 5, 5, 10, 21, 20, 6]
	Time taken saving stuff: 0.08s

=== episode:98 Env-steps-taken:63168
 	picked: 57 |actions: {0: 298, 1: 404, 2: 580, 3: 586, 4: 642, 5: 521, 6: 471, 7: 469, 8: 320}
episode: 98/2000 -> reward: 75.73437499999997, steps:4291, time-taken: 2.89min, time-elasped: 263.14min
-> berries picked: 57 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2601 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [380, 332, 226, 200, 261, 317, 411, 326, 148]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 8, 11, 3, 11, 10, 21, 26, 6]
	Time taken saving stuff: 0.01s

=== episode:99 Env-steps-taken:65376
 	picked: 59 |actions: {0: 285, 1: 317, 2: 555, 3: 582, 4: 376, 5: 377, 6: 340, 7: 385, 8: 227}
episode: 99/2000 -> reward: 85.48437499999997, steps:3444, time-taken: 2.40min, time-elasped: 265.55min
-> berries picked: 59 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2626 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [383, 332, 228, 203, 267, 316, 416, 332, 149]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 12, 9, 9, 3, 9, 20, 26, 10]
	Time taken saving stuff: 0.10s

=== episode:100 Env-steps-taken:65568
 	picked: 70 |actions: {0: 553, 1: 614, 2: 951, 3: 806, 4: 637, 5: 585, 6: 635, 7: 675, 8: 505}
episode: 100/2000 -> reward: 87.48958333333329, steps:5961, time-taken: 44.51min, time-elasped: 310.06min
-> berries picked: 70 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2640 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [382, 341, 229, 197, 272, 311, 422, 338, 148]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 17, 4, 5, 10, 12, 19, 19, 5]
	Time taken saving stuff: 0.08s

=== episode:10 Env-steps-taken:53472
 	picked: 19 |actions: {0: 54, 1: 1425, 2: 112, 3: 525, 4: 1331, 5: 20, 6: 185, 7: 1210, 8: 0}

==================================================
eval-episode: 100 -> reward: 27.411458333333332, steps: 4862.0, wall-time: 36.57s
-> berries picked: 19 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:101 Env-steps-taken:62016
 	picked: 59 |actions: {0: 408, 1: 399, 2: 692, 3: 720, 4: 484, 5: 602, 6: 558, 7: 456, 8: 380}
episode: 101/2000 -> reward: 69.61979166666669, steps:4699, time-taken: 2.44min, time-elasped: 313.11min
-> berries picked: 59 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2657 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [386, 339, 229, 198, 275, 319, 423, 340, 148]
	| approx positives in sample 512: 99
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 6, 6, 6, 12, 11, 16, 15, 6]
	Time taken saving stuff: 0.01s

=== episode:102 Env-steps-taken:55296
 	picked: 27 |actions: {0: 230, 1: 193, 2: 336, 3: 268, 4: 255, 5: 285, 6: 285, 7: 369, 8: 198}
episode: 102/2000 -> reward: 36.45312500000001, steps:2419, time-taken: 1.76min, time-elasped: 314.88min
-> berries picked: 27 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2658 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [385, 335, 232, 195, 272, 317, 428, 346, 148]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 12, 8, 3, 8, 11, 16, 27, 5]
	Time taken saving stuff: 0.11s

=== episode:103 Env-steps-taken:64128
 	picked: 57 |actions: {0: 409, 1: 373, 2: 719, 3: 489, 4: 349, 5: 434, 6: 482, 7: 513, 8: 285}
episode: 103/2000 -> reward: 80.98437499999997, steps:4053, time-taken: 2.40min, time-elasped: 317.28min
-> berries picked: 57 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2680 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [384, 337, 238, 195, 271, 324, 434, 348, 149]
	| approx positives in sample 512: 93
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 12, 8, 3, 5, 9, 15, 16, 9]
	Time taken saving stuff: 0.03s

=== episode:104 Env-steps-taken:63168
 	picked: 53 |actions: {0: 339, 1: 396, 2: 702, 3: 517, 4: 547, 5: 372, 6: 407, 7: 435, 8: 297}
episode: 104/2000 -> reward: 75.96354166666666, steps:4012, time-taken: 2.60min, time-elasped: 319.89min
-> berries picked: 53 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2683 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [386, 333, 237, 193, 280, 321, 435, 347, 151]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 15, 7, 5, 11, 8, 23, 13, 6]
	Time taken saving stuff: 0.01s

=== episode:105 Env-steps-taken:54720
 	picked: 25 |actions: {0: 144, 1: 129, 2: 305, 3: 117, 4: 149, 5: 80, 6: 122, 7: 160, 8: 82}
episode: 105/2000 -> reward: 32.182291666666664, steps:1288, time-taken: 1.37min, time-elasped: 321.26min
-> berries picked: 25 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2692 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [386, 332, 244, 193, 277, 322, 436, 350, 152]
	| approx positives in sample 512: 84
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 14, 6, 5, 6, 4, 13, 21, 3]
	Time taken saving stuff: 0.01s

=== episode:106 Env-steps-taken:71616
 	picked: 87 |actions: {0: 589, 1: 739, 2: 995, 3: 871, 4: 618, 5: 572, 6: 483, 7: 761, 8: 503}
episode: 106/2000 -> reward: 118.26562499999986, steps:6131, time-taken: 4.44min, time-elasped: 325.71min
-> berries picked: 87 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2715 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [386, 338, 249, 193, 281, 324, 430, 358, 156]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 9, 5, 5, 14, 13, 19, 24, 5]
	Time taken saving stuff: 0.01s

=== episode:107 Env-steps-taken:63072
 	picked: 53 |actions: {0: 341, 1: 423, 2: 565, 3: 394, 4: 342, 5: 388, 6: 375, 7: 564, 8: 281}
episode: 107/2000 -> reward: 75.71354166666667, steps:3673, time-taken: 2.56min, time-elasped: 328.28min
-> berries picked: 53 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2730 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [387, 345, 250, 198, 282, 319, 431, 362, 156]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 12, 9, 4, 9, 10, 17, 18, 9]
	Time taken saving stuff: 0.10s

=== episode:108 Env-steps-taken:61248
 	picked: 46 |actions: {0: 260, 1: 271, 2: 381, 3: 348, 4: 316, 5: 238, 6: 321, 7: 294, 8: 137}
episode: 108/2000 -> reward: 66.61458333333336, steps:2566, time-taken: 1.91min, time-elasped: 330.19min
-> berries picked: 46 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2752 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [386, 350, 253, 203, 287, 313, 434, 369, 157]
	| approx positives in sample 512: 90
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 14, 5, 10, 3, 10, 6, 22, 8]
	Time taken saving stuff: 0.10s

=== episode:109 Env-steps-taken:69888
 	picked: 75 |actions: {0: 370, 1: 396, 2: 637, 3: 564, 4: 431, 5: 437, 6: 498, 7: 525, 8: 288}
episode: 109/2000 -> reward: 109.9531249999999, steps:4146, time-taken: 2.69min, time-elasped: 332.89min
-> berries picked: 75 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2791 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [387, 361, 260, 210, 289, 316, 430, 377, 161]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 8, 9, 8, 11, 8, 15, 29, 9]
	Time taken saving stuff: 0.10s

=== episode:110 Env-steps-taken:63840
 	picked: 62 |actions: {0: 472, 1: 521, 2: 1258, 3: 708, 4: 556, 5: 400, 6: 555, 7: 548, 8: 339}
episode: 110/2000 -> reward: 78.94791666666666, steps:5357, time-taken: 3.27min, time-elasped: 336.16min
-> berries picked: 62 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2794 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [384, 362, 264, 214, 287, 313, 427, 382, 161]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 12, 9, 4, 10, 9, 25, 21, 7]
	Time taken saving stuff: 0.11s

=== episode:11 Env-steps-taken:80544
 	picked: 122 |actions: {0: 433, 1: 1485, 2: 2838, 3: 671, 4: 442, 5: 586, 6: 390, 7: 477, 8: 1}

==================================================
eval-episode: 110 -> reward: 162.76041666666677, steps: 7323.0, wall-time: 62.29s
-> berries picked: 122 of 800 | patches-visited: [1, 4] | juice left:-0.00
==================================================


=== episode:111 Env-steps-taken:58176
 	picked: 37 |actions: {0: 309, 1: 327, 2: 591, 3: 304, 4: 293, 5: 218, 6: 305, 7: 353, 8: 194}
episode: 111/2000 -> reward: 50.88020833333336, steps:2894, time-taken: 2.00min, time-elasped: 339.21min
-> berries picked: 37 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2801 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [380, 361, 270, 216, 289, 310, 429, 385, 161]
	| approx positives in sample 512: 83
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 11, 6, 9, 4, 4, 18, 14, 4]
	Time taken saving stuff: 0.09s

=== episode:112 Env-steps-taken:58560
 	picked: 36 |actions: {0: 207, 1: 275, 2: 334, 3: 292, 4: 433, 5: 248, 6: 304, 7: 270, 8: 159}
episode: 112/2000 -> reward: 52.937500000000036, steps:2522, time-taken: 1.85min, time-elasped: 341.06min
-> berries picked: 36 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2806 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [377, 358, 270, 217, 293, 308, 433, 388, 162]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 12, 14, 5, 2, 12, 14, 31, 9]
	Time taken saving stuff: 0.05s

=== episode:113 Env-steps-taken:56160
 	picked: 28 |actions: {0: 154, 1: 222, 2: 317, 3: 283, 4: 261, 5: 225, 6: 207, 7: 162, 8: 124}
episode: 113/2000 -> reward: 41.14583333333334, steps:1955, time-taken: 1.58min, time-elasped: 342.65min
-> berries picked: 28 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2811 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [375, 357, 270, 220, 293, 307, 432, 391, 166]
	| approx positives in sample 512: 96
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 7, 8, 8, 6, 9, 15, 21, 7]
	Time taken saving stuff: 0.09s

=== episode:114 Env-steps-taken:63264
 	picked: 50 |actions: {0: 473, 1: 409, 2: 663, 3: 512, 4: 497, 5: 376, 6: 407, 7: 634, 8: 335}
episode: 114/2000 -> reward: 76.88541666666667, steps:4306, time-taken: 2.71min, time-elasped: 345.36min
-> berries picked: 50 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2807 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [371, 360, 272, 219, 290, 298, 431, 396, 170]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 8, 10, 8, 10, 11, 12, 25, 11]
	Time taken saving stuff: 0.10s

=== episode:115 Env-steps-taken:69024
 	picked: 80 |actions: {0: 476, 1: 857, 2: 931, 3: 627, 4: 590, 5: 522, 6: 505, 7: 514, 8: 331}
episode: 115/2000 -> reward: 105.16666666666656, steps:5353, time-taken: 3.46min, time-elasped: 348.83min
-> berries picked: 80 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2852 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [372, 367, 287, 229, 297, 300, 426, 400, 174]
	| approx positives in sample 512: 79
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 6, 7, 3, 5, 7, 10, 23, 6]
	Time taken saving stuff: 0.08s

=== episode:116 Env-steps-taken:54720
 	picked: 24 |actions: {0: 164, 1: 223, 2: 326, 3: 217, 4: 188, 5: 113, 6: 103, 7: 134, 8: 99}
episode: 116/2000 -> reward: 33.625, steps:1567, time-taken: 1.46min, time-elasped: 350.30min
-> berries picked: 24 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2859 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [370, 372, 286, 233, 302, 300, 423, 399, 174]
	| approx positives in sample 512: 91
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 7, 6, 7, 5, 10, 20, 17, 6]
	Time taken saving stuff: 0.07s

=== episode:117 Env-steps-taken:61632
 	picked: 58 |actions: {0: 418, 1: 457, 2: 756, 3: 418, 4: 556, 5: 574, 6: 429, 7: 498, 8: 295}
episode: 117/2000 -> reward: 67.67708333333339, steps:4401, time-taken: 2.95min, time-elasped: 353.25min
-> berries picked: 58 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2859 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [362, 375, 288, 235, 302, 302, 419, 403, 173]
	| approx positives in sample 512: 89
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 5, 5, 9, 7, 8, 22, 16, 4]
	Time taken saving stuff: 0.10s

=== episode:118 Env-steps-taken:53760
 	picked: 17 |actions: {0: 48, 1: 168, 2: 163, 3: 110, 4: 102, 5: 62, 6: 80, 7: 112, 8: 88}
episode: 118/2000 -> reward: 29.026041666666664, steps:933, time-taken: 0.94min, time-elasped: 354.19min
-> berries picked: 17 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2863 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [363, 378, 288, 237, 302, 300, 417, 403, 175]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 14, 11, 7, 5, 5, 12, 25, 9]
	Time taken saving stuff: 0.07s

=== episode:119 Env-steps-taken:56448
 	picked: 27 |actions: {0: 136, 1: 396, 2: 199, 3: 152, 4: 147, 5: 81, 6: 110, 7: 162, 8: 86}
episode: 119/2000 -> reward: 42.70312500000002, steps:1469, time-taken: 1.42min, time-elasped: 355.61min
-> berries picked: 27 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2875 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [364, 384, 290, 243, 305, 298, 413, 403, 175]
	| approx positives in sample 512: 96
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 16, 5, 5, 8, 9, 21, 18, 5]
	Time taken saving stuff: 0.01s

=== episode:120 Env-steps-taken:70656
 	picked: 88 |actions: {0: 653, 1: 715, 2: 976, 3: 458, 4: 828, 5: 433, 6: 572, 7: 585, 8: 317}
episode: 120/2000 -> reward: 113.20833333333316, steps:5537, time-taken: 3.36min, time-elasped: 358.97min
-> berries picked: 88 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2904 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [365, 392, 300, 247, 314, 292, 410, 407, 177]
	| approx positives in sample 512: 95
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 8, 9, 9, 11, 8, 19, 23, 2]
	Time taken saving stuff: 0.10s

=== episode:12 Env-steps-taken:59328
 	picked: 40 |actions: {0: 168, 1: 860, 2: 3049, 3: 106, 4: 612, 5: 40, 6: 64, 7: 419, 8: 76}

==================================================
eval-episode: 120 -> reward: 56.95833333333338, steps: 5394.0, wall-time: 45.11s
-> berries picked: 40 of 800 | patches-visited: [1, 4] | juice left:-0.00
==================================================


=== episode:121 Env-steps-taken:64800
 	picked: 66 |actions: {0: 507, 1: 500, 2: 768, 3: 409, 4: 549, 5: 315, 6: 365, 7: 459, 8: 325}
episode: 121/2000 -> reward: 83.96874999999996, steps:4197, time-taken: 2.64min, time-elasped: 362.37min
-> berries picked: 66 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2911 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [365, 395, 304, 248, 321, 283, 405, 415, 175]
	| approx positives in sample 512: 100
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 8, 12, 9, 6, 9, 11, 24, 9]
	Time taken saving stuff: 0.10s

=== episode:122 Env-steps-taken:66336
 	picked: 62 |actions: {0: 303, 1: 496, 2: 568, 3: 305, 4: 581, 5: 383, 6: 327, 7: 312, 8: 251}
episode: 122/2000 -> reward: 90.25520833333329, steps:3526, time-taken: 2.40min, time-elasped: 364.77min
-> berries picked: 62 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2932 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [363, 398, 303, 259, 326, 285, 402, 421, 175]
	| approx positives in sample 512: 100
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 13, 8, 9, 9, 12, 10, 18, 9]
	Time taken saving stuff: 0.09s

=== episode:123 Env-steps-taken:75360
 	picked: 91 |actions: {0: 479, 1: 546, 2: 595, 3: 521, 4: 629, 5: 546, 6: 524, 7: 566, 8: 374}
episode: 123/2000 -> reward: 137.78645833333323, steps:4780, time-taken: 3.05min, time-elasped: 367.83min
-> berries picked: 91 of 800 | patches-visited: [0, 5, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2965 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [362, 402, 300, 275, 334, 289, 399, 428, 176]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 20, 8, 16, 2, 10, 16, 27, 6]
	Time taken saving stuff: 0.09s

=== episode:124 Env-steps-taken:75072
 	picked: 96 |actions: {0: 636, 1: 618, 2: 806, 3: 487, 4: 723, 5: 556, 6: 668, 7: 640, 8: 339}
episode: 124/2000 -> reward: 134.36458333333323, steps:5473, time-taken: 3.23min, time-elasped: 371.07min
-> berries picked: 96 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2999 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [362, 411, 305, 281, 341, 299, 389, 434, 177]
	| approx positives in sample 512: 88
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 3, 5, 10, 11, 9, 17, 16, 9]
	Time taken saving stuff: 0.01s

=== episode:125 Env-steps-taken:72672
 	picked: 87 |actions: {0: 548, 1: 630, 2: 703, 3: 568, 4: 710, 5: 496, 6: 445, 7: 481, 8: 350}
episode: 125/2000 -> reward: 124.01562499999984, steps:4931, time-taken: 3.41min, time-elasped: 374.48min
-> berries picked: 87 of 800 | patches-visited: [0, 1, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3040 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [367, 413, 315, 291, 345, 301, 389, 438, 181]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 12, 7, 9, 11, 8, 16, 19, 4]
	Time taken saving stuff: 0.00s

=== episode:126 Env-steps-taken:76320
 	picked: 99 |actions: {0: 597, 1: 566, 2: 955, 3: 608, 4: 731, 5: 723, 6: 563, 7: 515, 8: 483}
episode: 126/2000 -> reward: 141.44270833333326, steps:5741, time-taken: 3.69min, time-elasped: 378.18min
-> berries picked: 99 of 800 | patches-visited: [0, 1, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3101 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [372, 423, 317, 301, 362, 305, 387, 449, 185]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 14, 7, 8, 10, 11, 15, 26, 9]
	Time taken saving stuff: 0.03s

=== episode:127 Env-steps-taken:54720
 	picked: 26 |actions: {0: 165, 1: 142, 2: 191, 3: 135, 4: 171, 5: 198, 6: 134, 7: 129, 8: 151}
episode: 127/2000 -> reward: 33.51041666666666, steps:1416, time-taken: 1.25min, time-elasped: 379.44min
-> berries picked: 26 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3115 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [376, 421, 318, 303, 364, 309, 389, 449, 186]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 8, 5, 7, 5, 11, 16, 26, 5]
	Time taken saving stuff: 0.01s

=== episode:128 Env-steps-taken:53472
 	picked: 23 |actions: {0: 100, 1: 165, 2: 199, 3: 126, 4: 170, 5: 151, 6: 134, 7: 95, 8: 72}
episode: 128/2000 -> reward: 27.239583333333325, steps:1212, time-taken: 1.22min, time-elasped: 380.66min
-> berries picked: 23 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3125 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [375, 422, 318, 307, 369, 311, 390, 448, 185]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 5, 10, 9, 12, 8, 18, 26, 3]
	Time taken saving stuff: 0.00s

=== episode:129 Env-steps-taken:61920
 	picked: 50 |actions: {0: 327, 1: 328, 2: 386, 3: 186, 4: 312, 5: 299, 6: 364, 7: 291, 8: 204}
episode: 129/2000 -> reward: 69.63541666666669, steps:2697, time-taken: 2.04min, time-elasped: 382.71min
-> berries picked: 50 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3143 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [377, 419, 322, 309, 373, 315, 389, 453, 186]
	| approx positives in sample 512: 95
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 10, 9, 12, 8, 11, 16, 16, 4]
	Time taken saving stuff: 0.01s

=== episode:130 Env-steps-taken:67296
 	picked: 72 |actions: {0: 504, 1: 377, 2: 635, 3: 519, 4: 584, 5: 435, 6: 560, 7: 420, 8: 344}
episode: 130/2000 -> reward: 96.62499999999991, steps:4378, time-taken: 2.87min, time-elasped: 385.58min
-> berries picked: 72 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3179 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [379, 421, 326, 308, 382, 322, 393, 459, 189]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 16, 9, 8, 6, 7, 17, 25, 10]
	Time taken saving stuff: 0.17s

=== episode:13 Env-steps-taken:60576
 	picked: 44 |actions: {0: 269, 1: 83, 2: 719, 3: 287, 4: 131, 5: 246, 6: 128, 7: 173, 8: 757}

==================================================
eval-episode: 130 -> reward: 63.22916666666672, steps: 2793.0, wall-time: 43.04s
-> berries picked: 44 of 800 | patches-visited: [1, 3] | juice left:-0.00
==================================================


=== episode:131 Env-steps-taken:57504
 	picked: 35 |actions: {0: 251, 1: 368, 2: 457, 3: 240, 4: 281, 5: 264, 6: 242, 7: 218, 8: 149}
episode: 131/2000 -> reward: 47.494791666666686, steps:2470, time-taken: 1.79min, time-elasped: 388.10min
-> berries picked: 35 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3190 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [380, 423, 327, 310, 385, 325, 392, 459, 189]
	| approx positives in sample 512: 96
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 10, 5, 7, 10, 10, 12, 19, 7]
	Time taken saving stuff: 0.01s

=== episode:132 Env-steps-taken:73440
 	picked: 92 |actions: {0: 594, 1: 740, 2: 699, 3: 553, 4: 738, 5: 592, 6: 498, 7: 473, 8: 440}
episode: 132/2000 -> reward: 126.84374999999982, steps:5327, time-taken: 3.32min, time-elasped: 391.42min
-> berries picked: 92 of 800 | patches-visited: [0, 1, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3238 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [385, 427, 335, 317, 394, 332, 394, 465, 189]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 13, 10, 9, 7, 9, 12, 30, 6]
	Time taken saving stuff: 0.01s

=== episode:133 Env-steps-taken:74976
 	picked: 106 |actions: {0: 720, 1: 656, 2: 921, 3: 679, 4: 940, 5: 664, 6: 726, 7: 698, 8: 395}
episode: 133/2000 -> reward: 134.67708333333317, steps:6399, time-taken: 3.93min, time-elasped: 395.35min
-> berries picked: 106 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3281 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [389, 426, 335, 333, 403, 332, 399, 471, 193]
	| approx positives in sample 512: 87
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 16, 7, 9, 6, 8, 9, 19, 2]
	Time taken saving stuff: 0.00s

=== episode:134 Env-steps-taken:57600
 	picked: 32 |actions: {0: 185, 1: 228, 2: 340, 3: 178, 4: 192, 5: 264, 6: 286, 7: 217, 8: 151}
episode: 134/2000 -> reward: 48.1666666666667, steps:2041, time-taken: 1.74min, time-elasped: 397.10min
-> berries picked: 32 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3300 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [387, 427, 339, 336, 406, 335, 404, 473, 193]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 10, 5, 8, 13, 14, 11, 19, 8]
	Time taken saving stuff: 0.01s

=== episode:135 Env-steps-taken:64032
 	picked: 62 |actions: {0: 479, 1: 605, 2: 1028, 3: 541, 4: 754, 5: 710, 6: 541, 7: 516, 8: 466}
episode: 135/2000 -> reward: 79.94791666666664, steps:5640, time-taken: 3.26min, time-elasped: 400.36min
-> berries picked: 62 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3308 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [388, 423, 343, 346, 409, 336, 399, 470, 194]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 15, 8, 9, 8, 7, 14, 18, 5]
	Time taken saving stuff: 0.03s

=== episode:136 Env-steps-taken:72960
 	picked: 95 |actions: {0: 532, 1: 533, 2: 782, 3: 609, 4: 709, 5: 766, 6: 724, 7: 505, 8: 506}
episode: 136/2000 -> reward: 124.80729166666652, steps:5666, time-taken: 3.69min, time-elasped: 404.06min
-> berries picked: 95 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3343 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [393, 419, 347, 358, 415, 348, 394, 470, 199]
	| approx positives in sample 512: 95
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 12, 9, 7, 9, 8, 8, 19, 13]
	Time taken saving stuff: 0.00s

=== episode:137 Env-steps-taken:52320
 	picked: 14 |actions: {0: 54, 1: 124, 2: 109, 3: 63, 4: 66, 5: 89, 6: 76, 7: 50, 8: 71}
episode: 137/2000 -> reward: 21.697916666666664, steps:702, time-taken: 0.88min, time-elasped: 404.94min
-> berries picked: 14 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3346 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [391, 421, 345, 359, 416, 351, 394, 470, 199]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 16, 4, 15, 17, 7, 6, 13, 10]
	Time taken saving stuff: 0.01s

=== episode:138 Env-steps-taken:64416
 	picked: 70 |actions: {0: 666, 1: 599, 2: 927, 3: 543, 4: 526, 5: 571, 6: 573, 7: 536, 8: 424}
episode: 138/2000 -> reward: 81.48958333333329, steps:5365, time-taken: 3.28min, time-elasped: 408.23min
-> berries picked: 70 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3358 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [393, 424, 352, 362, 417, 348, 393, 468, 201]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 15, 7, 10, 17, 11, 12, 14, 11]
	Time taken saving stuff: 0.00s

=== episode:139 Env-steps-taken:73056
 	picked: 96 |actions: {0: 691, 1: 703, 2: 800, 3: 629, 4: 672, 5: 715, 6: 810, 7: 692, 8: 370}
episode: 139/2000 -> reward: 125.24999999999983, steps:6082, time-taken: 3.75min, time-elasped: 411.99min
-> berries picked: 96 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3375 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [392, 426, 354, 367, 426, 346, 389, 472, 203]
	| approx positives in sample 512: 86
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 14, 11, 10, 7, 14, 9, 12, 5]
	Time taken saving stuff: 0.01s

=== episode:140 Env-steps-taken:67200
 	picked: 74 |actions: {0: 525, 1: 498, 2: 686, 3: 621, 4: 574, 5: 672, 6: 527, 7: 530, 8: 476}
episode: 140/2000 -> reward: 96.01041666666657, steps:5109, time-taken: 3.09min, time-elasped: 415.08min
-> berries picked: 74 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3380 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [393, 422, 364, 371, 429, 351, 375, 474, 201]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 15, 10, 15, 5, 12, 9, 20, 7]
	Time taken saving stuff: 0.17s

=== episode:14 Env-steps-taken:81792
 	picked: 135 |actions: {0: 744, 1: 428, 2: 1003, 3: 649, 4: 326, 5: 502, 6: 844, 7: 216, 8: 384}

==================================================
eval-episode: 140 -> reward: 166.6302083333336, steps: 5096.0, wall-time: 74.96s
-> berries picked: 135 of 800 | patches-visited: [0, 1] | juice left:-0.00
==================================================


=== episode:141 Env-steps-taken:75072
 	picked: 96 |actions: {0: 623, 1: 624, 2: 832, 3: 662, 4: 773, 5: 849, 6: 757, 7: 703, 8: 418}
episode: 141/2000 -> reward: 135.7499999999999, steps:6241, time-taken: 3.62min, time-elasped: 419.96min
-> berries picked: 96 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3392 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [382, 420, 368, 383, 430, 358, 376, 472, 203]
	| approx positives in sample 512: 96
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 11, 6, 13, 12, 5, 7, 23, 4]
	Time taken saving stuff: 0.01s

=== episode:142 Env-steps-taken:67296
 	picked: 65 |actions: {0: 351, 1: 524, 2: 585, 3: 367, 4: 462, 5: 403, 6: 456, 7: 322, 8: 299}
episode: 142/2000 -> reward: 97.02604166666661, steps:3769, time-taken: 2.55min, time-elasped: 422.52min
-> berries picked: 65 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3410 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [385, 423, 372, 386, 429, 367, 379, 468, 201]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 14, 12, 15, 12, 11, 7, 20, 7]
	Time taken saving stuff: 0.09s

=== episode:143 Env-steps-taken:69504
 	picked: 82 |actions: {0: 590, 1: 662, 2: 801, 3: 582, 4: 561, 5: 590, 6: 626, 7: 545, 8: 434}
episode: 143/2000 -> reward: 107.8593749999999, steps:5391, time-taken: 3.42min, time-elasped: 425.95min
-> berries picked: 82 of 800 | patches-visited: [0, 1, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3448 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [389, 433, 377, 393, 431, 365, 378, 478, 204]
	| approx positives in sample 512: 86
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 12, 12, 7, 8, 9, 6, 13, 5]
	Time taken saving stuff: 0.01s

=== episode:144 Env-steps-taken:65280
 	picked: 67 |actions: {0: 357, 1: 490, 2: 665, 3: 414, 4: 493, 5: 564, 6: 564, 7: 397, 8: 330}
episode: 144/2000 -> reward: 86.4114583333333, steps:4274, time-taken: 2.73min, time-elasped: 428.68min
-> berries picked: 67 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3470 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [391, 437, 378, 392, 439, 366, 378, 483, 206]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 14, 11, 7, 12, 9, 15, 16, 5]
	Time taken saving stuff: 0.00s

=== episode:145 Env-steps-taken:66240
 	picked: 68 |actions: {0: 391, 1: 586, 2: 490, 3: 450, 4: 517, 5: 486, 6: 443, 7: 438, 8: 323}
episode: 145/2000 -> reward: 90.21874999999997, steps:4124, time-taken: 2.70min, time-elasped: 431.39min
-> berries picked: 68 of 800 | patches-visited: [0, 1, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3487 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [396, 441, 378, 395, 445, 370, 370, 483, 209]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 19, 8, 15, 14, 11, 6, 17, 7]
	Time taken saving stuff: 0.11s

=== episode:146 Env-steps-taken:66144
 	picked: 73 |actions: {0: 381, 1: 433, 2: 688, 3: 471, 4: 539, 5: 577, 6: 659, 7: 465, 8: 385}
episode: 146/2000 -> reward: 90.31770833333326, steps:4598, time-taken: 2.85min, time-elasped: 434.24min
-> berries picked: 73 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3488 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [404, 438, 380, 398, 450, 367, 361, 481, 209]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 20, 9, 10, 10, 8, 8, 18, 12]
	Time taken saving stuff: 0.09s

=== episode:147 Env-steps-taken:71040
 	picked: 81 |actions: {0: 436, 1: 713, 2: 553, 3: 566, 4: 556, 5: 507, 6: 511, 7: 441, 8: 325}
episode: 147/2000 -> reward: 115.85937499999987, steps:4608, time-taken: 3.08min, time-elasped: 437.33min
-> berries picked: 81 of 800 | patches-visited: [0, 5, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3519 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [411, 440, 384, 408, 454, 368, 358, 482, 214]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 11, 13, 8, 12, 12, 14, 12, 12]
	Time taken saving stuff: 0.12s

=== episode:148 Env-steps-taken:64416
 	picked: 66 |actions: {0: 389, 1: 431, 2: 674, 3: 629, 4: 412, 5: 500, 6: 457, 7: 559, 8: 381}
episode: 148/2000 -> reward: 81.71874999999999, steps:4432, time-taken: 2.71min, time-elasped: 440.04min
-> berries picked: 66 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3540 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [413, 440, 378, 416, 463, 368, 361, 484, 217]
	| approx positives in sample 512: 94
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 15, 8, 5, 16, 3, 7, 21, 7]
	Time taken saving stuff: 0.10s

=== episode:149 Env-steps-taken:59904
 	picked: 44 |actions: {0: 253, 1: 279, 2: 417, 3: 437, 4: 291, 5: 362, 6: 389, 7: 231, 8: 340}
episode: 149/2000 -> reward: 59.343750000000036, steps:2999, time-taken: 1.95min, time-elasped: 442.00min
-> berries picked: 44 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3553 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [411, 440, 383, 422, 464, 372, 355, 486, 220]
	| approx positives in sample 512: 93
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 11, 10, 11, 14, 10, 9, 12, 7]
	Time taken saving stuff: 0.02s

=== episode:150 Env-steps-taken:66336
 	picked: 71 |actions: {0: 440, 1: 444, 2: 392, 3: 359, 4: 410, 5: 511, 6: 481, 7: 471, 8: 414}
episode: 150/2000 -> reward: 91.73958333333326, steps:3922, time-taken: 2.69min, time-elasped: 444.70min
-> berries picked: 71 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3578 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [411, 446, 384, 422, 466, 383, 355, 489, 222]
	| approx positives in sample 512: 93
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 13, 10, 10, 8, 11, 11, 9, 9]
	Time taken saving stuff: 0.17s

=== episode:15 Env-steps-taken:69120
 	picked: 80 |actions: {0: 247, 1: 159, 2: 599, 3: 522, 4: 303, 5: 415, 6: 337, 7: 567, 8: 194}

==================================================
eval-episode: 150 -> reward: 105.03124999999989, steps: 3343.0, wall-time: 65.40s
-> berries picked: 80 of 800 | patches-visited: [1, 2, 9] | juice left:-0.00
==================================================


=== episode:151 Env-steps-taken:66624
 	picked: 70 |actions: {0: 493, 1: 481, 2: 635, 3: 403, 4: 610, 5: 843, 6: 557, 7: 479, 8: 405}
episode: 151/2000 -> reward: 93.2395833333333, steps:4906, time-taken: 3.19min, time-elasped: 448.98min
-> berries picked: 70 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3551 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [414, 447, 377, 429, 462, 383, 342, 476, 221]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 12, 5, 15, 11, 11, 9, 14, 8]
	Time taken saving stuff: 0.11s

=== episode:152 Env-steps-taken:67392
 	picked: 78 |actions: {0: 585, 1: 740, 2: 639, 3: 435, 4: 496, 5: 545, 6: 454, 7: 760, 8: 338}
episode: 152/2000 -> reward: 96.78124999999991, steps:4992, time-taken: 3.24min, time-elasped: 452.23min
-> berries picked: 78 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3553 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [430, 442, 379, 427, 459, 380, 335, 478, 223]
	| approx positives in sample 512: 74
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 11, 7, 8, 7, 3, 6, 11, 10]
	Time taken saving stuff: 0.03s

=== episode:153 Env-steps-taken:61440
 	picked: 51 |actions: {0: 241, 1: 284, 2: 397, 3: 371, 4: 419, 5: 500, 6: 315, 7: 243, 8: 273}
episode: 153/2000 -> reward: 67.07812500000006, steps:3043, time-taken: 2.13min, time-elasped: 454.37min
-> berries picked: 51 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3562 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [428, 444, 382, 433, 468, 382, 332, 470, 223]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 18, 11, 13, 19, 4, 7, 11, 13]
	Time taken saving stuff: 0.09s

=== episode:154 Env-steps-taken:74208
 	picked: 96 |actions: {0: 678, 1: 746, 2: 671, 3: 640, 4: 676, 5: 818, 6: 611, 7: 716, 8: 374}
episode: 154/2000 -> reward: 130.86458333333317, steps:5930, time-taken: 3.76min, time-elasped: 458.14min
-> berries picked: 96 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3588 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [438, 446, 385, 438, 474, 386, 327, 468, 226]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 13, 6, 9, 15, 5, 12, 14, 12]
	Time taken saving stuff: 0.01s

=== episode:155 Env-steps-taken:53376
 	picked: 22 |actions: {0: 196, 1: 338, 2: 415, 3: 221, 4: 274, 5: 216, 6: 169, 7: 157, 8: 198}
episode: 155/2000 -> reward: 26.739583333333325, steps:2184, time-taken: 1.71min, time-elasped: 459.85min
-> berries picked: 22 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3588 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [438, 445, 380, 443, 477, 387, 326, 465, 227]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 10, 13, 13, 5, 18, 7, 13, 11]
	Time taken saving stuff: 0.11s

=== episode:156 Env-steps-taken:73344
 	picked: 91 |actions: {0: 542, 1: 582, 2: 731, 3: 561, 4: 596, 5: 696, 6: 509, 7: 687, 8: 586}
episode: 156/2000 -> reward: 127.28645833333319, steps:5490, time-taken: 3.41min, time-elasped: 463.26min
-> berries picked: 91 of 800 | patches-visited: [0, 7, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3601 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [439, 450, 385, 452, 483, 386, 316, 463, 227]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 15, 17, 13, 15, 7, 8, 14, 9]
	Time taken saving stuff: 0.01s

=== episode:157 Env-steps-taken:62016
 	picked: 51 |actions: {0: 352, 1: 522, 2: 509, 3: 304, 4: 350, 5: 397, 6: 395, 7: 272, 8: 338}
episode: 157/2000 -> reward: 70.32812500000001, steps:3439, time-taken: 2.35min, time-elasped: 465.62min
-> berries picked: 51 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3602 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [443, 454, 391, 451, 488, 386, 307, 456, 226]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 16, 8, 11, 13, 9, 7, 12, 17]
	Time taken saving stuff: 0.01s

=== episode:158 Env-steps-taken:70464
 	picked: 82 |actions: {0: 525, 1: 593, 2: 604, 3: 662, 4: 608, 5: 770, 6: 707, 7: 717, 8: 488}
episode: 158/2000 -> reward: 112.5520833333332, steps:5674, time-taken: 3.39min, time-elasped: 469.01min
-> berries picked: 82 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3588 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [442, 448, 391, 448, 501, 382, 298, 453, 225]
	| approx positives in sample 512: 84
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 12, 6, 18, 8, 5, 6, 10, 8]
	Time taken saving stuff: 0.01s

=== episode:159 Env-steps-taken:56160
 	picked: 28 |actions: {0: 125, 1: 236, 2: 272, 3: 272, 4: 236, 5: 271, 6: 203, 7: 200, 8: 192}
episode: 159/2000 -> reward: 40.89583333333336, steps:2007, time-taken: 1.72min, time-elasped: 470.73min
-> berries picked: 28 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3588 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [442, 450, 398, 447, 503, 377, 296, 449, 226]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 13, 12, 17, 16, 9, 8, 11, 7]
	Time taken saving stuff: 0.01s

=== episode:160 Env-steps-taken:63360
 	picked: 60 |actions: {0: 335, 1: 394, 2: 530, 3: 317, 4: 309, 5: 484, 6: 466, 7: 326, 8: 345}
episode: 160/2000 -> reward: 76.8125, steps:3506, time-taken: 2.51min, time-elasped: 473.24min
-> berries picked: 60 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3606 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [444, 453, 405, 449, 499, 387, 297, 445, 227]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 15, 10, 20, 16, 8, 6, 12, 6]
	Time taken saving stuff: 0.18s

=== episode:16 Env-steps-taken:75648
 	picked: 105 |actions: {0: 118, 1: 947, 2: 453, 3: 430, 4: 414, 5: 459, 6: 741, 7: 424, 8: 58}

==================================================
eval-episode: 160 -> reward: 137.3489583333332, steps: 4044.0, wall-time: 67.83s
-> berries picked: 105 of 800 | patches-visited: [1, 4] | juice left:-0.00
==================================================


=== episode:161 Env-steps-taken:63072
 	picked: 55 |actions: {0: 352, 1: 508, 2: 755, 3: 420, 4: 394, 5: 453, 6: 416, 7: 388, 8: 427}
episode: 161/2000 -> reward: 75.59895833333334, steps:4113, time-taken: 2.89min, time-elasped: 477.26min
-> berries picked: 55 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3607 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [443, 454, 413, 449, 500, 386, 293, 438, 231]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 18, 19, 9, 17, 5, 5, 17, 9]
	Time taken saving stuff: 0.01s

=== episode:162 Env-steps-taken:71808
 	picked: 90 |actions: {0: 414, 1: 391, 2: 604, 3: 533, 4: 557, 5: 734, 6: 603, 7: 435, 8: 350}
episode: 162/2000 -> reward: 119.09374999999986, steps:4621, time-taken: 3.25min, time-elasped: 480.51min
-> berries picked: 90 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3626 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [448, 452, 412, 455, 509, 393, 296, 428, 233]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 16, 14, 14, 15, 4, 6, 13, 13]
	Time taken saving stuff: 0.03s

=== episode:163 Env-steps-taken:68160
 	picked: 69 |actions: {0: 435, 1: 473, 2: 448, 3: 387, 4: 540, 5: 527, 6: 481, 7: 505, 8: 321}
episode: 163/2000 -> reward: 101.29687499999991, steps:4117, time-taken: 2.78min, time-elasped: 483.30min
-> berries picked: 69 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3636 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [451, 454, 413, 463, 510, 396, 291, 424, 234]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 9, 12, 14, 13, 8, 10, 15, 11]
	Time taken saving stuff: 0.00s

=== episode:164 Env-steps-taken:65568
 	picked: 68 |actions: {0: 439, 1: 541, 2: 469, 3: 493, 4: 483, 5: 739, 6: 730, 7: 630, 8: 495}
episode: 164/2000 -> reward: 87.85416666666663, steps:5019, time-taken: 3.25min, time-elasped: 486.55min
-> berries picked: 68 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3633 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [453, 450, 416, 468, 511, 389, 284, 426, 236]
	| approx positives in sample 512: 90
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 12, 11, 12, 16, 5, 7, 6, 7]
	Time taken saving stuff: 0.00s

=== episode:165 Env-steps-taken:57024
 	picked: 28 |actions: {0: 83, 1: 195, 2: 156, 3: 171, 4: 186, 5: 189, 6: 144, 7: 112, 8: 68}
episode: 165/2000 -> reward: 45.64583333333336, steps:1304, time-taken: 1.23min, time-elasped: 487.78min
-> berries picked: 28 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3646 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [455, 451, 423, 471, 512, 391, 283, 422, 238]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 13, 16, 10, 12, 6, 9, 10, 5]
	Time taken saving stuff: 0.03s

=== episode:166 Env-steps-taken:65760
 	picked: 63 |actions: {0: 420, 1: 519, 2: 653, 3: 335, 4: 457, 5: 531, 6: 501, 7: 576, 8: 479}
episode: 166/2000 -> reward: 87.19791666666663, steps:4471, time-taken: 3.09min, time-elasped: 490.87min
-> berries picked: 63 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3633 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [450, 454, 426, 472, 508, 392, 279, 411, 241]
	| approx positives in sample 512: 82
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 6, 10, 14, 16, 8, 2, 9, 7]
	Time taken saving stuff: 0.02s

=== episode:167 Env-steps-taken:65856
 	picked: 69 |actions: {0: 454, 1: 436, 2: 484, 3: 427, 4: 571, 5: 505, 6: 492, 7: 527, 8: 401}
episode: 167/2000 -> reward: 88.91145833333327, steps:4297, time-taken: 2.85min, time-elasped: 493.72min
-> berries picked: 69 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3645 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [447, 454, 428, 473, 513, 393, 285, 410, 242]
	| approx positives in sample 512: 93
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 15, 11, 10, 12, 10, 8, 13, 9]
	Time taken saving stuff: 0.11s

=== episode:168 Env-steps-taken:66336
 	picked: 61 |actions: {0: 319, 1: 382, 2: 475, 3: 428, 4: 366, 5: 328, 6: 376, 7: 517, 8: 416}
episode: 168/2000 -> reward: 92.25520833333331, steps:3607, time-taken: 2.54min, time-elasped: 496.27min
-> berries picked: 61 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3657 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [455, 460, 431, 478, 512, 390, 278, 407, 246]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 11, 12, 18, 18, 6, 4, 6, 10]
	Time taken saving stuff: 0.10s

=== episode:169 Env-steps-taken:61248
 	picked: 47 |actions: {0: 188, 1: 163, 2: 211, 3: 254, 4: 275, 5: 344, 6: 356, 7: 448, 8: 218}
episode: 169/2000 -> reward: 66.5572916666667, steps:2457, time-taken: 1.84min, time-elasped: 498.11min
-> berries picked: 47 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3656 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [456, 454, 431, 476, 516, 385, 280, 410, 248]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 10, 10, 16, 13, 7, 7, 11, 10]
	Time taken saving stuff: 0.01s

=== episode:170 Env-steps-taken:68256
 	picked: 70 |actions: {0: 404, 1: 438, 2: 555, 3: 399, 4: 440, 5: 566, 6: 742, 7: 540, 8: 431}
episode: 170/2000 -> reward: 101.48958333333324, steps:4515, time-taken: 3.15min, time-elasped: 501.27min
-> berries picked: 70 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3671 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [455, 457, 435, 482, 519, 384, 278, 414, 247]
	| approx positives in sample 512: 96
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 13, 14, 12, 11, 9, 8, 13, 8]
	Time taken saving stuff: 0.06s

=== episode:17 Env-steps-taken:64608
 	picked: 58 |actions: {0: 175, 1: 145, 2: 106, 3: 442, 4: 180, 5: 205, 6: 278, 7: 78, 8: 470}

==================================================
eval-episode: 170 -> reward: 83.67708333333331, steps: 2079.0, wall-time: 49.81s
-> berries picked: 58 of 800 | patches-visited: [1, 2, 9] | juice left:-0.00
==================================================


=== episode:171 Env-steps-taken:66912
 	picked: 70 |actions: {0: 444, 1: 613, 2: 568, 3: 542, 4: 498, 5: 629, 6: 412, 7: 482, 8: 450}
episode: 171/2000 -> reward: 94.73958333333327, steps:4638, time-taken: 3.03min, time-elasped: 505.14min
-> berries picked: 70 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3687 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [453, 459, 438, 486, 526, 380, 277, 418, 250]
	| approx positives in sample 512: 93
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 10, 9, 11, 19, 8, 10, 12, 5]
	Time taken saving stuff: 0.03s

=== episode:172 Env-steps-taken:67776
 	picked: 73 |actions: {0: 443, 1: 570, 2: 630, 3: 600, 4: 519, 5: 555, 6: 555, 7: 577, 8: 379}
episode: 172/2000 -> reward: 99.06770833333324, steps:4828, time-taken: 3.16min, time-elasped: 508.30min
-> berries picked: 73 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3696 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [454, 453, 439, 493, 535, 386, 276, 409, 251]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 15, 8, 10, 12, 14, 8, 7, 13]
	Time taken saving stuff: 0.10s

=== episode:173 Env-steps-taken:63936
 	picked: 62 |actions: {0: 449, 1: 515, 2: 569, 3: 597, 4: 515, 5: 820, 6: 648, 7: 617, 8: 565}
episode: 173/2000 -> reward: 79.69791666666664, steps:5295, time-taken: 3.36min, time-elasped: 511.66min
-> berries picked: 62 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3706 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [454, 453, 437, 498, 537, 390, 278, 406, 253]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 14, 13, 8, 18, 10, 6, 18, 7]
	Time taken saving stuff: 0.03s

=== episode:174 Env-steps-taken:65376
 	picked: 71 |actions: {0: 581, 1: 398, 2: 577, 3: 680, 4: 507, 5: 746, 6: 793, 7: 675, 8: 714}
episode: 174/2000 -> reward: 85.54687499999996, steps:5671, time-taken: 3.30min, time-elasped: 514.96min
-> berries picked: 71 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3703 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [445, 448, 431, 501, 548, 396, 275, 407, 252]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 11, 10, 16, 10, 19, 7, 18, 9]
	Time taken saving stuff: 0.11s

=== episode:175 Env-steps-taken:55968
 	picked: 30 |actions: {0: 130, 1: 176, 2: 188, 3: 209, 4: 250, 5: 163, 6: 315, 7: 185, 8: 171}
episode: 175/2000 -> reward: 40.03125, steps:1787, time-taken: 1.40min, time-elasped: 516.37min
-> berries picked: 30 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3709 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [447, 447, 431, 502, 549, 397, 273, 408, 255]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 13, 10, 8, 9, 10, 10, 10, 17]
	Time taken saving stuff: 0.08s

=== episode:176 Env-steps-taken:65280
 	picked: 67 |actions: {0: 480, 1: 434, 2: 491, 3: 684, 4: 411, 5: 675, 6: 634, 7: 639, 8: 335}
episode: 176/2000 -> reward: 84.77604166666661, steps:4783, time-taken: 2.95min, time-elasped: 519.32min
-> berries picked: 67 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3738 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [449, 445, 432, 505, 556, 403, 282, 410, 256]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 15, 12, 8, 17, 19, 9, 16, 10]
	Time taken saving stuff: 0.11s

=== episode:177 Env-steps-taken:62112
 	picked: 47 |actions: {0: 270, 1: 264, 2: 276, 3: 286, 4: 291, 5: 339, 6: 313, 7: 333, 8: 303}
episode: 177/2000 -> reward: 71.0572916666667, steps:2675, time-taken: 1.92min, time-elasped: 521.25min
-> berries picked: 47 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3765 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [452, 443, 433, 509, 558, 410, 287, 413, 260]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 9, 16, 11, 16, 11, 8, 11, 11]
	Time taken saving stuff: 0.03s

=== episode:178 Env-steps-taken:58848
 	picked: 42 |actions: {0: 274, 1: 289, 2: 515, 3: 485, 4: 438, 5: 391, 6: 526, 7: 388, 8: 276}
episode: 178/2000 -> reward: 54.09375000000005, steps:3582, time-taken: 2.46min, time-elasped: 523.72min
-> berries picked: 42 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3775 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [449, 443, 438, 508, 566, 411, 287, 413, 260]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 14, 13, 8, 15, 25, 7, 15, 4]
	Time taken saving stuff: 0.00s

=== episode:179 Env-steps-taken:56544
 	picked: 31 |actions: {0: 205, 1: 151, 2: 223, 3: 191, 4: 187, 5: 303, 6: 243, 7: 192, 8: 148}
episode: 179/2000 -> reward: 42.72395833333334, steps:1843, time-taken: 1.72min, time-elasped: 525.44min
-> berries picked: 31 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3788 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [453, 446, 439, 507, 567, 417, 283, 414, 262]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 14, 11, 10, 15, 10, 12, 8, 10]
	Time taken saving stuff: 0.01s

=== episode:180 Env-steps-taken:63840
 	picked: 66 |actions: {0: 318, 1: 339, 2: 451, 3: 368, 4: 499, 5: 529, 6: 479, 7: 507, 8: 505}
episode: 180/2000 -> reward: 78.96875, steps:3995, time-taken: 2.64min, time-elasped: 528.08min
-> berries picked: 66 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3812 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [455, 443, 447, 518, 569, 423, 282, 411, 264]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 12, 12, 15, 17, 17, 8, 10, 7]
	Time taken saving stuff: 0.06s

=== episode:18 Env-steps-taken:76896
 	picked: 106 |actions: {0: 218, 1: 405, 2: 365, 3: 232, 4: 233, 5: 322, 6: 682, 7: 448, 8: 1143}

==================================================
eval-episode: 180 -> reward: 144.92708333333326, steps: 4048.0, wall-time: 69.46s
-> berries picked: 106 of 800 | patches-visited: [1, 2, 3] | juice left:-0.00
==================================================


=== episode:181 Env-steps-taken:55872
 	picked: 29 |actions: {0: 145, 1: 235, 2: 347, 3: 311, 4: 177, 5: 213, 6: 200, 7: 245, 8: 242}
episode: 181/2000 -> reward: 39.33854166666668, steps:2115, time-taken: 1.74min, time-elasped: 530.99min
-> berries picked: 29 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3820 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [455, 447, 447, 521, 571, 421, 281, 414, 263]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 18, 20, 16, 17, 11, 10, 10, 14]
	Time taken saving stuff: 0.01s

=== episode:182 Env-steps-taken:69120
 	picked: 80 |actions: {0: 471, 1: 554, 2: 692, 3: 659, 4: 565, 5: 822, 6: 685, 7: 779, 8: 519}
episode: 182/2000 -> reward: 104.22395833333324, steps:5746, time-taken: 3.62min, time-elasped: 534.61min
-> berries picked: 80 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3842 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [455, 438, 454, 524, 575, 428, 287, 415, 266]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 9, 4, 12, 15, 11, 11, 12, 16]
	Time taken saving stuff: 0.10s

=== episode:183 Env-steps-taken:60288
 	picked: 46 |actions: {0: 249, 1: 294, 2: 335, 3: 279, 4: 283, 5: 291, 6: 312, 7: 356, 8: 225}
episode: 183/2000 -> reward: 59.67187500000004, steps:2624, time-taken: 2.12min, time-elasped: 536.74min
-> berries picked: 46 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3857 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [458, 439, 457, 523, 575, 433, 286, 417, 269]
	| approx positives in sample 512: 91
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 8, 11, 10, 12, 11, 7, 11, 11]
	Time taken saving stuff: 0.01s

=== episode:184 Env-steps-taken:50208
 	picked: 10 |actions: {0: 21, 1: 34, 2: 29, 3: 49, 4: 58, 5: 71, 6: 118, 7: 78, 8: 24}
episode: 184/2000 -> reward: 10.927083333333336, steps:482, time-taken: 0.75min, time-elasped: 537.50min
-> berries picked: 10 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3861 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [457, 437, 458, 523, 577, 434, 289, 417, 269]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 10, 11, 10, 9, 11, 13, 15, 4]
	Time taken saving stuff: 0.09s

=== episode:185 Env-steps-taken:61920
 	picked: 48 |actions: {0: 291, 1: 301, 2: 324, 3: 339, 4: 474, 5: 425, 6: 388, 7: 324, 8: 288}
episode: 185/2000 -> reward: 68.05729166666671, steps:3154, time-taken: 2.18min, time-elasped: 539.69min
-> berries picked: 48 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3879 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [461, 440, 460, 527, 579, 433, 289, 419, 271]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 13, 16, 17, 11, 13, 12, 9, 14]
	Time taken saving stuff: 0.01s

=== episode:186 Env-steps-taken:56736
 	picked: 32 |actions: {0: 208, 1: 293, 2: 314, 3: 190, 4: 253, 5: 194, 6: 251, 7: 215, 8: 286}
episode: 186/2000 -> reward: 43.66666666666668, steps:2204, time-taken: 1.96min, time-elasped: 541.66min
-> berries picked: 32 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3871 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [461, 440, 462, 529, 574, 429, 290, 416, 270]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 15, 16, 8, 13, 13, 4, 7, 18]
	Time taken saving stuff: 0.01s

=== episode:187 Env-steps-taken:64800
 	picked: 60 |actions: {0: 375, 1: 477, 2: 531, 3: 454, 4: 509, 5: 443, 6: 504, 7: 452, 8: 420}
episode: 187/2000 -> reward: 84.31249999999999, steps:4165, time-taken: 2.89min, time-elasped: 544.56min
-> berries picked: 60 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3874 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [460, 438, 466, 536, 583, 426, 284, 409, 272]
	| approx positives in sample 512: 101
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 13, 12, 16, 21, 10, 6, 11, 5]
	Time taken saving stuff: 0.01s

=== episode:188 Env-steps-taken:65664
 	picked: 68 |actions: {0: 314, 1: 439, 2: 574, 3: 595, 4: 591, 5: 642, 6: 724, 7: 475, 8: 415}
episode: 188/2000 -> reward: 88.35416666666661, steps:4769, time-taken: 3.29min, time-elasped: 547.84min
-> berries picked: 68 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3880 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [458, 437, 472, 540, 586, 429, 279, 408, 271]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 14, 14, 18, 11, 8, 4, 15, 8]
	Time taken saving stuff: 0.01s

=== episode:189 Env-steps-taken:65856
 	picked: 65 |actions: {0: 287, 1: 273, 2: 316, 3: 314, 4: 504, 5: 509, 6: 429, 7: 329, 8: 259}
episode: 189/2000 -> reward: 89.52604166666661, steps:3220, time-taken: 2.59min, time-elasped: 550.44min
-> berries picked: 65 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3896 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [461, 432, 474, 545, 593, 440, 284, 399, 268]
	| approx positives in sample 512: 99
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 9, 14, 15, 17, 8, 8, 9, 12]
	Time taken saving stuff: 0.11s

=== episode:190 Env-steps-taken:56352
 	picked: 32 |actions: {0: 147, 1: 186, 2: 116, 3: 151, 4: 170, 5: 264, 6: 247, 7: 126, 8: 142}
episode: 190/2000 -> reward: 41.6666666666667, steps:1549, time-taken: 1.37min, time-elasped: 551.81min
-> berries picked: 32 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3912 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [462, 434, 476, 548, 593, 446, 285, 399, 269]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 10, 13, 16, 19, 11, 5, 9, 4]
	Time taken saving stuff: 0.07s

=== episode:19 Env-steps-taken:70176
 	picked: 81 |actions: {0: 123, 1: 1111, 2: 112, 3: 330, 4: 1583, 5: 1260, 6: 163, 7: 1449, 8: 249}

==================================================
eval-episode: 190 -> reward: 111.10937499999989, steps: 6380.0, wall-time: 78.20s
-> berries picked: 81 of 800 | patches-visited: [1, 3] | juice left:-0.00
==================================================


=== episode:191 Env-steps-taken:67008
 	picked: 71 |actions: {0: 472, 1: 524, 2: 563, 3: 464, 4: 643, 5: 558, 6: 811, 7: 667, 8: 548}
episode: 191/2000 -> reward: 94.93229166666657, steps:5250, time-taken: 3.16min, time-elasped: 556.28min
-> berries picked: 71 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3899 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [458, 436, 471, 551, 596, 451, 276, 393, 267]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 10, 13, 9, 14, 20, 9, 6, 8]
	Time taken saving stuff: 0.03s

=== episode:192 Env-steps-taken:60192
 	picked: 48 |actions: {0: 265, 1: 378, 2: 368, 3: 328, 4: 290, 5: 386, 6: 451, 7: 277, 8: 338}
episode: 192/2000 -> reward: 61.000000000000036, steps:3081, time-taken: 2.29min, time-elasped: 558.58min
-> berries picked: 48 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3908 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [462, 440, 475, 553, 593, 451, 273, 391, 270]
	| approx positives in sample 512: 94
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 10, 10, 9, 13, 11, 5, 8, 12]
	Time taken saving stuff: 0.01s

=== episode:193 Env-steps-taken:65376
 	picked: 60 |actions: {0: 371, 1: 438, 2: 533, 3: 418, 4: 565, 5: 525, 6: 494, 7: 468, 8: 380}
episode: 193/2000 -> reward: 87.31249999999994, steps:4192, time-taken: 2.88min, time-elasped: 561.46min
-> berries picked: 60 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3917 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [467, 443, 480, 552, 590, 451, 273, 388, 273]
	| approx positives in sample 512: 99
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 13, 12, 13, 19, 7, 6, 10, 7]
	Time taken saving stuff: 0.01s

=== episode:194 Env-steps-taken:48480
 	picked: 2 |actions: {0: 12, 1: 12, 2: 27, 3: 9, 4: 23, 5: 17, 6: 27, 7: 7, 8: 60}
episode: 194/2000 -> reward: 2.3854166666666665, steps:194, time-taken: 0.64min, time-elasped: 562.11min
-> berries picked: 2 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3916 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [468, 444, 480, 551, 590, 451, 273, 386, 273]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 11, 13, 19, 22, 13, 9, 7, 10]
	Time taken saving stuff: 0.01s

=== episode:195 Env-steps-taken:66336
 	picked: 63 |actions: {0: 390, 1: 423, 2: 497, 3: 353, 4: 678, 5: 637, 6: 527, 7: 579, 8: 503}
episode: 195/2000 -> reward: 92.14062499999997, steps:4587, time-taken: 3.08min, time-elasped: 565.19min
-> berries picked: 63 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3905 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [464, 442, 479, 552, 592, 454, 265, 381, 276]
	| approx positives in sample 512: 90
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 16, 9, 10, 12, 4, 9, 12, 4]
	Time taken saving stuff: 0.09s

=== episode:196 Env-steps-taken:52896
 	picked: 18 |actions: {0: 175, 1: 165, 2: 156, 3: 113, 4: 109, 5: 108, 6: 428, 7: 189, 8: 177}
episode: 196/2000 -> reward: 24.468749999999993, steps:1620, time-taken: 1.44min, time-elasped: 566.64min
-> berries picked: 18 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3905 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [467, 441, 477, 546, 591, 458, 268, 381, 276]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 14, 15, 13, 21, 10, 14, 9, 8]
	Time taken saving stuff: 0.04s

=== episode:197 Env-steps-taken:63456
 	picked: 53 |actions: {0: 261, 1: 337, 2: 334, 3: 192, 4: 385, 5: 332, 6: 459, 7: 246, 8: 254}
episode: 197/2000 -> reward: 75.82812500000001, steps:2800, time-taken: 2.06min, time-elasped: 568.71min
-> berries picked: 53 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3925 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [473, 440, 479, 550, 592, 459, 270, 385, 277]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 11, 15, 18, 13, 10, 5, 10, 8]
	Time taken saving stuff: 0.09s

=== episode:198 Env-steps-taken:74112
 	picked: 99 |actions: {0: 488, 1: 455, 2: 731, 3: 470, 4: 658, 5: 616, 6: 707, 7: 503, 8: 522}
episode: 198/2000 -> reward: 128.63541666666654, steps:5150, time-taken: 3.64min, time-elasped: 572.35min
-> berries picked: 99 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3967 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [472, 443, 484, 563, 601, 470, 272, 382, 280]
	| approx positives in sample 512: 84
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 7, 11, 12, 13, 15, 1, 10, 10]
	Time taken saving stuff: 0.11s

=== episode:199 Env-steps-taken:59424
 	picked: 37 |actions: {0: 356, 1: 214, 2: 245, 3: 180, 4: 189, 5: 321, 6: 310, 7: 360, 8: 212}
episode: 199/2000 -> reward: 57.38020833333336, steps:2387, time-taken: 1.72min, time-elasped: 574.08min
-> berries picked: 37 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3967 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [474, 442, 485, 561, 599, 470, 272, 384, 280]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 13, 7, 17, 18, 10, 12, 20, 8]
	Time taken saving stuff: 0.09s

=== episode:200 Env-steps-taken:66528
 	picked: 65 |actions: {0: 369, 1: 377, 2: 580, 3: 408, 4: 450, 5: 377, 6: 425, 7: 436, 8: 530}
episode: 200/2000 -> reward: 93.02604166666663, steps:3952, time-taken: 2.68min, time-elasped: 576.77min
-> berries picked: 65 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3990 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [478, 447, 486, 569, 599, 470, 270, 389, 282]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 19, 10, 7, 16, 18, 11, 16, 13]
	Time taken saving stuff: 0.18s

=== episode:20 Env-steps-taken:64992
 	picked: 61 |actions: {0: 259, 1: 156, 2: 144, 3: 428, 4: 118, 5: 2579, 6: 426, 7: 197, 8: 592}

==================================================
eval-episode: 200 -> reward: 85.2552083333333, steps: 4899.0, wall-time: 50.08s
-> berries picked: 61 of 800 | patches-visited: [1, 6] | juice left:-0.00
==================================================


=== episode:201 Env-steps-taken:62688
 	picked: 55 |actions: {0: 307, 1: 439, 2: 508, 3: 428, 4: 372, 5: 472, 6: 525, 7: 464, 8: 509}
episode: 201/2000 -> reward: 72.9635416666667, steps:4024, time-taken: 2.74min, time-elasped: 580.36min
-> berries picked: 55 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3975 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [476, 451, 481, 571, 595, 467, 268, 382, 284]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 16, 16, 21, 15, 15, 7, 12, 6]
	Time taken saving stuff: 0.01s

=== episode:202 Env-steps-taken:58464
 	picked: 39 |actions: {0: 256, 1: 155, 2: 302, 3: 275, 4: 257, 5: 313, 6: 353, 7: 310, 8: 227}
episode: 202/2000 -> reward: 52.26562500000003, steps:2448, time-taken: 1.83min, time-elasped: 582.19min
-> berries picked: 39 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3964 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [477, 448, 480, 575, 591, 465, 260, 384, 284]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 10, 17, 23, 15, 15, 5, 12, 10]
	Time taken saving stuff: 0.10s

=== episode:203 Env-steps-taken:60384
 	picked: 46 |actions: {0: 326, 1: 298, 2: 468, 3: 239, 4: 335, 5: 343, 6: 616, 7: 402, 8: 309}
episode: 203/2000 -> reward: 62.1145833333334, steps:3336, time-taken: 2.49min, time-elasped: 584.69min
-> berries picked: 46 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3963 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [477, 444, 485, 575, 588, 462, 258, 387, 287]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 12, 22, 12, 12, 6, 3, 11, 13]
	Time taken saving stuff: 0.10s

=== episode:204 Env-steps-taken:65184
 	picked: 67 |actions: {0: 360, 1: 332, 2: 540, 3: 314, 4: 449, 5: 475, 6: 619, 7: 585, 8: 367}
episode: 204/2000 -> reward: 85.6614583333333, steps:4041, time-taken: 2.66min, time-elasped: 587.35min
-> berries picked: 67 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3965 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [477, 445, 490, 569, 588, 463, 258, 385, 290]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 11, 13, 14, 14, 6, 7, 9, 15]
	Time taken saving stuff: 0.10s

=== episode:205 Env-steps-taken:62112
 	picked: 54 |actions: {0: 299, 1: 363, 2: 371, 3: 319, 4: 369, 5: 363, 6: 469, 7: 612, 8: 348}
episode: 205/2000 -> reward: 70.65625, steps:3513, time-taken: 2.85min, time-elasped: 590.21min
-> berries picked: 54 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3968 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [481, 442, 494, 571, 582, 459, 256, 392, 291]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 14, 13, 13, 10, 10, 4, 7, 12]
	Time taken saving stuff: 0.01s

=== episode:206 Env-steps-taken:57984
 	picked: 36 |actions: {0: 272, 1: 249, 2: 318, 3: 291, 4: 300, 5: 532, 6: 387, 7: 318, 8: 373}
episode: 206/2000 -> reward: 49.93750000000003, steps:3040, time-taken: 2.00min, time-elasped: 592.22min
-> berries picked: 36 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3950 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [483, 438, 495, 567, 582, 452, 254, 387, 292]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 12, 18, 14, 12, 10, 5, 10, 9]
	Time taken saving stuff: 0.02s

=== episode:207 Env-steps-taken:55392
 	picked: 27 |actions: {0: 248, 1: 199, 2: 268, 3: 148, 4: 228, 5: 307, 6: 166, 7: 216, 8: 293}
episode: 207/2000 -> reward: 37.203125, steps:2073, time-taken: 1.75min, time-elasped: 593.97min
-> berries picked: 27 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3957 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [486, 438, 495, 569, 580, 456, 253, 385, 295]
	| approx positives in sample 512: 101
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 14, 14, 14, 11, 11, 10, 15, 6]
	Time taken saving stuff: 0.01s

=== episode:208 Env-steps-taken:66624
 	picked: 71 |actions: {0: 425, 1: 484, 2: 638, 3: 515, 4: 602, 5: 562, 6: 533, 7: 636, 8: 547}
episode: 208/2000 -> reward: 93.18229166666663, steps:4942, time-taken: 3.26min, time-elasped: 597.23min
-> berries picked: 71 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3964 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [487, 441, 498, 571, 576, 455, 251, 387, 298]
	| approx positives in sample 512: 96
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 11, 14, 13, 15, 8, 8, 13, 7]
	Time taken saving stuff: 0.11s

=== episode:209 Env-steps-taken:77088
 	picked: 98 |actions: {0: 539, 1: 711, 2: 840, 3: 581, 4: 528, 5: 693, 6: 789, 7: 586, 8: 618}
episode: 209/2000 -> reward: 146.38541666666666, steps:5885, time-taken: 3.84min, time-elasped: 601.07min
-> berries picked: 98 of 800 | patches-visited: [0, 1, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3980 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [495, 447, 505, 574, 571, 454, 252, 383, 299]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 10, 16, 10, 17, 4, 11, 10, 9]
	Time taken saving stuff: 0.00s

=== episode:210 Env-steps-taken:68736
 	picked: 83 |actions: {0: 485, 1: 473, 2: 796, 3: 418, 4: 544, 5: 603, 6: 548, 7: 640, 8: 593}
episode: 210/2000 -> reward: 103.74479166666656, steps:5100, time-taken: 3.29min, time-elasped: 604.37min
-> berries picked: 83 of 800 | patches-visited: [0, 3, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4004 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [500, 447, 506, 584, 571, 453, 256, 383, 304]
	| approx positives in sample 512: 89
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 8, 18, 14, 8, 12, 6, 8, 9]
	Time taken saving stuff: 0.17s

=== episode:21 Env-steps-taken:60000
 	picked: 40 |actions: {0: 284, 1: 113, 2: 106, 3: 21, 4: 234, 5: 103, 6: 107, 7: 150, 8: 417}

==================================================
eval-episode: 210 -> reward: 60.458333333333364, steps: 1535.0, wall-time: 51.24s
-> berries picked: 40 of 800 | patches-visited: [1, 5] | juice left:-0.00
==================================================


=== episode:211 Env-steps-taken:60384
 	picked: 48 |actions: {0: 295, 1: 303, 2: 343, 3: 262, 4: 473, 5: 444, 6: 426, 7: 424, 8: 364}
episode: 211/2000 -> reward: 61.750000000000064, steps:3334, time-taken: 2.36min, time-elasped: 607.59min
-> berries picked: 48 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4020 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [505, 447, 504, 587, 577, 459, 255, 382, 304]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 25, 16, 16, 13, 10, 6, 11, 12]
	Time taken saving stuff: 0.01s

=== episode:212 Env-steps-taken:68832
 	picked: 79 |actions: {0: 397, 1: 438, 2: 522, 3: 408, 4: 430, 5: 470, 6: 566, 7: 697, 8: 576}
episode: 212/2000 -> reward: 104.22395833333323, steps:4504, time-taken: 3.13min, time-elasped: 610.72min
-> berries picked: 79 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4042 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [505, 453, 504, 594, 581, 456, 253, 389, 307]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 9, 10, 22, 13, 9, 8, 10, 9]
	Time taken saving stuff: 0.02s

=== episode:213 Env-steps-taken:73344
 	picked: 89 |actions: {0: 615, 1: 745, 2: 845, 3: 576, 4: 587, 5: 563, 6: 583, 7: 697, 8: 753}
episode: 213/2000 -> reward: 127.1510416666665, steps:5964, time-taken: 3.86min, time-elasped: 614.59min
-> berries picked: 89 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4064 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [509, 465, 509, 594, 585, 452, 254, 389, 307]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 16, 18, 15, 13, 9, 5, 11, 11]
	Time taken saving stuff: 0.11s

=== episode:214 Env-steps-taken:62400
 	picked: 49 |actions: {0: 288, 1: 243, 2: 352, 3: 222, 4: 242, 5: 318, 6: 434, 7: 388, 8: 495}
episode: 214/2000 -> reward: 70.421875, steps:2982, time-taken: 2.26min, time-elasped: 616.85min
-> berries picked: 49 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4076 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [516, 469, 511, 595, 583, 452, 250, 393, 307]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 13, 7, 14, 14, 15, 5, 16, 14]
	Time taken saving stuff: 0.09s

=== episode:215 Env-steps-taken:65760
 	picked: 64 |actions: {0: 381, 1: 316, 2: 380, 3: 337, 4: 364, 5: 435, 6: 385, 7: 435, 8: 382}
episode: 215/2000 -> reward: 89.08333333333329, steps:3415, time-taken: 2.56min, time-elasped: 619.41min
-> berries picked: 64 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4093 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [522, 472, 516, 594, 587, 451, 252, 390, 309]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 6, 14, 16, 16, 19, 9, 6, 11]
	Time taken saving stuff: 0.01s

=== episode:216 Env-steps-taken:55680
 	picked: 23 |actions: {0: 181, 1: 144, 2: 162, 3: 114, 4: 72, 5: 144, 6: 175, 7: 196, 8: 111}
episode: 216/2000 -> reward: 38.93229166666667, steps:1299, time-taken: 1.10min, time-elasped: 620.51min
-> berries picked: 23 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4101 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [526, 471, 518, 592, 586, 451, 255, 392, 310]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 16, 12, 20, 11, 11, 11, 16, 10]
	Time taken saving stuff: 0.01s

=== episode:217 Env-steps-taken:65472
 	picked: 64 |actions: {0: 394, 1: 344, 2: 463, 3: 307, 4: 451, 5: 391, 6: 361, 7: 350, 8: 561}
episode: 217/2000 -> reward: 87.58333333333329, steps:3622, time-taken: 2.50min, time-elasped: 623.01min
-> berries picked: 64 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4115 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [527, 474, 527, 587, 599, 454, 256, 382, 309]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 15, 10, 16, 14, 15, 10, 16, 8]
	Time taken saving stuff: 0.01s

=== episode:218 Env-steps-taken:73248
 	picked: 91 |actions: {0: 518, 1: 553, 2: 743, 3: 538, 4: 394, 5: 442, 6: 488, 7: 667, 8: 610}
episode: 218/2000 -> reward: 124.59374999999983, steps:4953, time-taken: 3.20min, time-elasped: 626.22min
-> berries picked: 91 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4144 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [534, 484, 537, 585, 602, 456, 255, 381, 310]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 17, 11, 19, 17, 13, 5, 8, 12]
	Time taken saving stuff: 0.01s

=== episode:219 Env-steps-taken:60192
 	picked: 51 |actions: {0: 317, 1: 286, 2: 440, 3: 290, 4: 350, 5: 349, 6: 419, 7: 407, 8: 363}
episode: 219/2000 -> reward: 60.57812500000005, steps:3221, time-taken: 2.37min, time-elasped: 628.59min
-> berries picked: 51 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4150 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [535, 481, 539, 586, 604, 459, 254, 382, 310]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 16, 18, 14, 13, 14, 2, 13, 13]
	Time taken saving stuff: 0.11s

=== episode:220 Env-steps-taken:70272
 	picked: 81 |actions: {0: 385, 1: 459, 2: 564, 3: 550, 4: 438, 5: 574, 6: 666, 7: 475, 8: 529}
episode: 220/2000 -> reward: 111.85937499999986, steps:4640, time-taken: 3.21min, time-elasped: 631.80min
-> berries picked: 81 of 800 | patches-visited: [0, 4, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4187 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [538, 481, 548, 592, 609, 465, 258, 382, 314]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 11, 13, 24, 15, 13, 10, 11, 11]
	Time taken saving stuff: 0.07s

=== episode:22 Env-steps-taken:84192
 	picked: 130 |actions: {0: 436, 1: 313, 2: 504, 3: 165, 4: 653, 5: 730, 6: 594, 7: 409, 8: 611}

==================================================
eval-episode: 220 -> reward: 180.66666666666688, steps: 4415.0, wall-time: 70.42s
-> berries picked: 130 of 800 | patches-visited: [1, 2, 9] | juice left:-0.00
==================================================


=== episode:221 Env-steps-taken:60864
 	picked: 49 |actions: {0: 334, 1: 451, 2: 403, 3: 445, 4: 455, 5: 510, 6: 570, 7: 535, 8: 672}
episode: 221/2000 -> reward: 64.44270833333339, steps:4375, time-taken: 2.72min, time-elasped: 635.69min
-> berries picked: 49 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4145 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [541, 480, 539, 582, 599, 462, 251, 376, 315]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 14, 12, 13, 16, 12, 8, 13, 9]
	Time taken saving stuff: 0.10s

=== episode:222 Env-steps-taken:70368
 	picked: 79 |actions: {0: 581, 1: 505, 2: 504, 3: 586, 4: 747, 5: 657, 6: 672, 7: 540, 8: 809}
episode: 222/2000 -> reward: 111.33854166666656, steps:5601, time-taken: 3.49min, time-elasped: 639.19min
-> berries picked: 79 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4142 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [545, 483, 533, 580, 604, 459, 247, 372, 319]
	| approx positives in sample 512: 88
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 11, 8, 12, 11, 9, 8, 5, 8]
	Time taken saving stuff: 0.11s

=== episode:223 Env-steps-taken:61632
 	picked: 52 |actions: {0: 343, 1: 284, 2: 315, 3: 401, 4: 268, 5: 345, 6: 334, 7: 363, 8: 419}
episode: 223/2000 -> reward: 67.63541666666671, steps:3072, time-taken: 2.05min, time-elasped: 641.25min
-> berries picked: 52 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4148 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [544, 485, 536, 574, 601, 467, 249, 372, 320]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 10, 13, 16, 10, 11, 5, 15, 16]
	Time taken saving stuff: 0.10s

=== episode:224 Env-steps-taken:67008
 	picked: 67 |actions: {0: 403, 1: 540, 2: 516, 3: 570, 4: 478, 5: 522, 6: 524, 7: 517, 8: 586}
episode: 224/2000 -> reward: 95.66145833333329, steps:4656, time-taken: 3.15min, time-elasped: 644.40min
-> berries picked: 67 of 800 | patches-visited: [0, 5, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4147 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [546, 482, 543, 570, 604, 464, 245, 370, 323]
	| approx positives in sample 512: 86
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 7, 8] [11, 11, 7, 15, 13, 12, 10, 7]
	Time taken saving stuff: 0.09s

=== episode:225 Env-steps-taken:72096
 	picked: 89 |actions: {0: 466, 1: 507, 2: 672, 3: 519, 4: 444, 5: 519, 6: 655, 7: 567, 8: 581}
episode: 225/2000 -> reward: 120.65104166666652, steps:4930, time-taken: 3.36min, time-elasped: 647.76min
-> berries picked: 89 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4177 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [549, 484, 550, 570, 609, 474, 243, 375, 323]
	| approx positives in sample 512: 100
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 10, 17, 11, 14, 12, 9, 10, 7]
	Time taken saving stuff: 0.01s

=== episode:226 Env-steps-taken:58080
 	picked: 36 |actions: {0: 235, 1: 175, 2: 186, 3: 205, 4: 256, 5: 225, 6: 216, 7: 261, 8: 288}
episode: 226/2000 -> reward: 50.68750000000003, steps:2047, time-taken: 1.71min, time-elasped: 649.48min
-> berries picked: 36 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4187 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [550, 485, 546, 570, 612, 478, 247, 373, 326]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 16, 13, 11, 18, 15, 12, 7, 12]
	Time taken saving stuff: 0.03s

=== episode:227 Env-steps-taken:65664
 	picked: 62 |actions: {0: 479, 1: 455, 2: 567, 3: 504, 4: 429, 5: 516, 6: 679, 7: 613, 8: 619}
episode: 227/2000 -> reward: 88.94791666666664, steps:4861, time-taken: 3.01min, time-elasped: 652.49min
-> berries picked: 62 of 800 | patches-visited: [0, 7, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4186 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [552, 490, 543, 565, 613, 475, 246, 374, 328]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 16, 8, 15, 10, 20, 8, 9, 9]
	Time taken saving stuff: 0.01s

=== episode:228 Env-steps-taken:54912
 	picked: 28 |actions: {0: 132, 1: 199, 2: 185, 3: 251, 4: 189, 5: 112, 6: 160, 7: 164, 8: 231}
episode: 228/2000 -> reward: 34.39583333333334, steps:1623, time-taken: 1.35min, time-elasped: 653.84min
-> berries picked: 28 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4193 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [551, 491, 543, 564, 617, 476, 246, 376, 329]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 18, 15, 7, 9, 8, 7, 15, 11]
	Time taken saving stuff: 0.03s

=== episode:229 Env-steps-taken:67104
 	picked: 74 |actions: {0: 434, 1: 344, 2: 478, 3: 451, 4: 370, 5: 383, 6: 511, 7: 548, 8: 619}
episode: 229/2000 -> reward: 95.51041666666663, steps:4138, time-taken: 2.87min, time-elasped: 656.71min
-> berries picked: 74 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4211 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [554, 490, 540, 570, 619, 480, 250, 378, 330]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 12, 14, 6, 17, 17, 7, 14, 13]
	Time taken saving stuff: 0.00s

=== episode:230 Env-steps-taken:64416
 	picked: 58 |actions: {0: 256, 1: 391, 2: 389, 3: 330, 4: 329, 5: 352, 6: 446, 7: 268, 8: 331}
episode: 230/2000 -> reward: 81.54166666666664, steps:3092, time-taken: 2.28min, time-elasped: 658.99min
-> berries picked: 58 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4225 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [556, 495, 538, 570, 626, 479, 248, 381, 332]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [25, 7, 8, 10, 18, 15, 11, 12, 15]
	Time taken saving stuff: 0.07s

=== episode:23 Env-steps-taken:72096
 	picked: 86 |actions: {0: 245, 1: 156, 2: 428, 3: 77, 4: 227, 5: 496, 6: 1804, 7: 628, 8: 288}

==================================================
eval-episode: 230 -> reward: 121.07291666666652, steps: 4349.0, wall-time: 60.38s
-> berries picked: 86 of 800 | patches-visited: [1, 2, 5] | juice left:-0.00
==================================================


=== episode:231 Env-steps-taken:72864
 	picked: 88 |actions: {0: 587, 1: 570, 2: 644, 3: 480, 4: 612, 5: 789, 6: 548, 7: 880, 8: 745}
episode: 231/2000 -> reward: 124.7083333333332, steps:5855, time-taken: 3.52min, time-elasped: 663.52min
-> berries picked: 88 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4230 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [555, 493, 546, 560, 630, 490, 244, 378, 334]
	| approx positives in sample 512: 92
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 11, 16, 11, 12, 6, 11, 6, 10]
	Time taken saving stuff: 0.01s

=== episode:232 Env-steps-taken:64032
 	picked: 52 |actions: {0: 185, 1: 320, 2: 341, 3: 335, 4: 278, 5: 362, 6: 407, 7: 360, 8: 457}
episode: 232/2000 -> reward: 81.02083333333331, steps:3045, time-taken: 2.22min, time-elasped: 665.74min
-> berries picked: 52 of 800 | patches-visited: [0, 1, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4249 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [559, 499, 541, 555, 636, 496, 246, 381, 336]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 9, 13, 12, 20, 19, 10, 4, 16]
	Time taken saving stuff: 0.02s

=== episode:233 Env-steps-taken:62880
 	picked: 55 |actions: {0: 525, 1: 292, 2: 421, 3: 289, 4: 300, 5: 345, 6: 366, 7: 490, 8: 531}
episode: 233/2000 -> reward: 74.59895833333331, steps:3559, time-taken: 2.30min, time-elasped: 668.05min
-> berries picked: 55 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4260 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [565, 496, 542, 555, 638, 497, 246, 384, 337]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 10, 12, 8, 15, 12, 9, 10, 17]
	Time taken saving stuff: 0.01s

=== episode:234 Env-steps-taken:57216
 	picked: 33 |actions: {0: 150, 1: 179, 2: 182, 3: 234, 4: 182, 5: 206, 6: 165, 7: 172, 8: 196}
episode: 234/2000 -> reward: 45.22395833333336, steps:1666, time-taken: 1.31min, time-elasped: 669.36min
-> berries picked: 33 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4268 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [565, 495, 542, 561, 640, 502, 244, 382, 337]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 12, 9, 16, 12, 12, 9, 12, 9]
	Time taken saving stuff: 0.09s

=== episode:235 Env-steps-taken:51648
 	picked: 12 |actions: {0: 66, 1: 70, 2: 75, 3: 65, 4: 95, 5: 107, 6: 64, 7: 129, 8: 117}
episode: 235/2000 -> reward: 18.3125, steps:788, time-taken: 0.74min, time-elasped: 670.10min
-> berries picked: 12 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4267 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [561, 496, 543, 560, 641, 502, 243, 384, 337]
	| approx positives in sample 512: 95
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 10, 18, 10, 11, 15, 8, 8, 7]
	Time taken saving stuff: 0.01s

=== episode:236 Env-steps-taken:59136
 	picked: 36 |actions: {0: 245, 1: 208, 2: 237, 3: 215, 4: 158, 5: 243, 6: 234, 7: 247, 8: 243}
episode: 236/2000 -> reward: 56.18750000000003, steps:2030, time-taken: 1.72min, time-elasped: 671.83min
-> berries picked: 36 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4250 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [562, 495, 544, 560, 634, 498, 243, 379, 335]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [23, 12, 9, 12, 18, 12, 7, 7, 2]
	Time taken saving stuff: 0.12s

=== episode:237 Env-steps-taken:73920
 	picked: 89 |actions: {0: 705, 1: 447, 2: 564, 3: 452, 4: 492, 5: 394, 6: 655, 7: 625, 8: 482}
episode: 237/2000 -> reward: 130.45833333333317, steps:4816, time-taken: 3.18min, time-elasped: 675.02min
-> berries picked: 89 of 800 | patches-visited: [0, 4, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4247 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [562, 493, 548, 557, 624, 498, 241, 384, 340]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 10, 17, 14, 10, 13, 7, 11, 10]
	Time taken saving stuff: 0.03s

=== episode:238 Env-steps-taken:60576
 	picked: 45 |actions: {0: 400, 1: 293, 2: 282, 3: 201, 4: 203, 5: 238, 6: 325, 7: 496, 8: 404}
episode: 238/2000 -> reward: 63.42187500000005, steps:2842, time-taken: 2.00min, time-elasped: 677.02min
-> berries picked: 45 of 800 | patches-visited: [0, 3, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4247 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [562, 498, 548, 556, 622, 493, 240, 386, 342]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 15, 14, 15, 14, 12, 8, 12, 16]
	Time taken saving stuff: 0.03s

=== episode:239 Env-steps-taken:64608
 	picked: 58 |actions: {0: 423, 1: 307, 2: 408, 3: 248, 4: 330, 5: 334, 6: 409, 7: 486, 8: 430}
episode: 239/2000 -> reward: 83.67708333333333, steps:3375, time-taken: 2.46min, time-elasped: 679.48min
-> berries picked: 58 of 800 | patches-visited: [0, 2, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4262 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [563, 502, 552, 552, 626, 489, 244, 388, 346]
	| approx positives in sample 512: 85
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 9, 6, 9, 17, 8, 7, 7, 9]
	Time taken saving stuff: 0.06s

=== episode:240 Env-steps-taken:63552
 	picked: 56 |actions: {0: 348, 1: 320, 2: 401, 3: 351, 4: 323, 5: 315, 6: 288, 7: 514, 8: 554}
episode: 240/2000 -> reward: 78.04166666666666, steps:3414, time-taken: 2.61min, time-elasped: 682.09min
-> berries picked: 56 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4255 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [567, 492, 554, 556, 623, 485, 242, 389, 347]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 15, 13, 11, 16, 7, 7, 13, 18]
	Time taken saving stuff: 0.10s

=== episode:24 Env-steps-taken:64032
 	picked: 57 |actions: {0: 328, 1: 346, 2: 106, 3: 119, 4: 22, 5: 61, 6: 71, 7: 254, 8: 408}

==================================================
eval-episode: 240 -> reward: 80.984375, steps: 1715.0, wall-time: 54.67s
-> berries picked: 57 of 800 | patches-visited: [1, 2, 3, 5] | juice left:-0.00
==================================================


=== episode:241 Env-steps-taken:57696
 	picked: 38 |actions: {0: 202, 1: 271, 2: 292, 3: 328, 4: 223, 5: 229, 6: 291, 7: 320, 8: 332}
episode: 241/2000 -> reward: 48.32291666666669, steps:2488, time-taken: 1.77min, time-elasped: 684.78min
-> berries picked: 38 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4261 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [568, 496, 554, 556, 627, 488, 239, 386, 347]
	| approx positives in sample 512: 88
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 8, 7, 4, 14, 12, 8, 10, 10]
	Time taken saving stuff: 0.00s

=== episode:242 Env-steps-taken:68832
 	picked: 79 |actions: {0: 536, 1: 368, 2: 331, 3: 425, 4: 476, 5: 431, 6: 517, 7: 586, 8: 582}
episode: 242/2000 -> reward: 104.47395833333326, steps:4252, time-taken: 2.81min, time-elasped: 687.59min
-> berries picked: 79 of 800 | patches-visited: [0, 4, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4273 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [579, 496, 550, 548, 632, 489, 246, 382, 351]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 12, 9, 13, 24, 11, 7, 10, 23]
	Time taken saving stuff: 0.04s

=== episode:243 Env-steps-taken:53088
 	picked: 17 |actions: {0: 181, 1: 261, 2: 228, 3: 154, 4: 184, 5: 185, 6: 181, 7: 320, 8: 429}
episode: 243/2000 -> reward: 25.526041666666664, steps:2123, time-taken: 1.78min, time-elasped: 689.38min
-> berries picked: 17 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4268 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [579, 492, 549, 546, 633, 491, 243, 383, 352]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 19, 15, 19, 17, 10, 9, 16, 10]
	Time taken saving stuff: 0.10s

=== episode:244 Env-steps-taken:85440
 	picked: 130 |actions: {0: 660, 1: 687, 2: 763, 3: 621, 4: 613, 5: 844, 6: 831, 7: 966, 8: 857}
episode: 244/2000 -> reward: 186.1666666666669, steps:6842, time-taken: 4.48min, time-elasped: 693.86min
-> berries picked: 130 of 800 | patches-visited: [0, 1, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4290 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [580, 497, 556, 548, 633, 494, 249, 379, 354]
	| approx positives in sample 512: 89
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 7, 10, 11, 13, 14, 6, 7, 11]
	Time taken saving stuff: 0.01s

=== episode:245 Env-steps-taken:63456
 	picked: 60 |actions: {0: 487, 1: 436, 2: 424, 3: 364, 4: 268, 5: 305, 6: 340, 7: 645, 8: 510}
episode: 245/2000 -> reward: 77.11979166666666, steps:3779, time-taken: 2.50min, time-elasped: 696.36min
-> berries picked: 60 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4305 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [582, 500, 562, 550, 630, 494, 246, 387, 354]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 9, 10, 15, 16, 12, 5, 12, 20]
	Time taken saving stuff: 0.10s

=== episode:246 Env-steps-taken:55872
 	picked: 26 |actions: {0: 200, 1: 100, 2: 99, 3: 86, 4: 137, 5: 130, 6: 200, 7: 258, 8: 127}
episode: 246/2000 -> reward: 39.76041666666667, steps:1337, time-taken: 1.24min, time-elasped: 697.60min
-> berries picked: 26 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4306 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [582, 504, 562, 545, 631, 494, 245, 389, 354]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 15, 15, 8, 7, 13, 6, 4, 15]
	Time taken saving stuff: 0.01s

=== episode:247 Env-steps-taken:65760
 	picked: 67 |actions: {0: 407, 1: 382, 2: 597, 3: 374, 4: 325, 5: 440, 6: 400, 7: 723, 8: 480}
episode: 247/2000 -> reward: 88.91145833333331, steps:4128, time-taken: 2.77min, time-elasped: 700.37min
-> berries picked: 67 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4304 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [583, 501, 557, 541, 640, 492, 243, 391, 356]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 16, 16, 6, 12, 12, 5, 16, 10]
	Time taken saving stuff: 0.01s

=== episode:248 Env-steps-taken:53088
 	picked: 20 |actions: {0: 180, 1: 99, 2: 216, 3: 154, 4: 118, 5: 138, 6: 145, 7: 254, 8: 237}
episode: 248/2000 -> reward: 23.96875, steps:1541, time-taken: 1.44min, time-elasped: 701.82min
-> berries picked: 20 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4301 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [585, 500, 555, 536, 640, 495, 241, 393, 356]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 15, 14, 13, 16, 5, 9, 13, 12]
	Time taken saving stuff: 0.04s

=== episode:249 Env-steps-taken:71136
 	picked: 79 |actions: {0: 492, 1: 483, 2: 489, 3: 430, 4: 479, 5: 568, 6: 686, 7: 570, 8: 598}
episode: 249/2000 -> reward: 114.45312499999989, steps:4795, time-taken: 3.00min, time-elasped: 704.83min
-> berries picked: 79 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4317 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [595, 502, 560, 534, 642, 500, 246, 384, 354]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 15, 9, 10, 14, 14, 7, 9, 13]
	Time taken saving stuff: 0.01s

=== episode:250 Env-steps-taken:72576
 	picked: 91 |actions: {0: 465, 1: 528, 2: 702, 3: 632, 4: 598, 5: 623, 6: 827, 7: 554, 8: 594}
episode: 250/2000 -> reward: 123.28645833333317, steps:5523, time-taken: 3.36min, time-elasped: 708.19min
-> berries picked: 91 of 800 | patches-visited: [0, 1, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4331 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [595, 502, 563, 534, 646, 503, 249, 384, 355]
	| approx positives in sample 512: 94
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 16, 11, 12, 12, 9, 2, 11, 8]
	Time taken saving stuff: 0.16s

=== episode:25 Env-steps-taken:89088
 	picked: 154 |actions: {0: 1336, 1: 252, 2: 870, 3: 190, 4: 448, 5: 528, 6: 1141, 7: 316, 8: 923}

==================================================
eval-episode: 250 -> reward: 205.92708333333377, steps: 6004.0, wall-time: 76.63s
-> berries picked: 154 of 800 | patches-visited: [1, 2, 5, 7] | juice left:-0.00
==================================================


=== episode:251 Env-steps-taken:62400
 	picked: 55 |actions: {0: 346, 1: 376, 2: 363, 3: 318, 4: 320, 5: 480, 6: 426, 7: 609, 8: 499}
episode: 251/2000 -> reward: 71.84895833333334, steps:3737, time-taken: 2.18min, time-elasped: 711.66min
-> berries picked: 55 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4327 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [598, 503, 563, 526, 649, 505, 248, 378, 357]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 8, 22, 10, 13, 11, 8, 8, 15]
	Time taken saving stuff: 0.03s

=== episode:252 Env-steps-taken:61056
 	picked: 47 |actions: {0: 353, 1: 316, 2: 304, 3: 319, 4: 293, 5: 295, 6: 273, 7: 278, 8: 421}
episode: 252/2000 -> reward: 63.61458333333337, steps:2852, time-taken: 1.88min, time-elasped: 713.54min
-> berries picked: 47 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4333 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [602, 502, 566, 521, 644, 511, 246, 379, 362]
	| approx positives in sample 512: 100
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 15, 12, 17, 16, 11, 6, 4, 11]
	Time taken saving stuff: 0.11s

=== episode:253 Env-steps-taken:71424
 	picked: 86 |actions: {0: 529, 1: 524, 2: 498, 3: 550, 4: 337, 5: 476, 6: 608, 7: 807, 8: 760}
episode: 253/2000 -> reward: 117.57291666666654, steps:5089, time-taken: 2.82min, time-elasped: 716.36min
-> berries picked: 86 of 800 | patches-visited: [0, 8, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4343 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [604, 502, 572, 520, 642, 511, 251, 378, 363]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 11, 19, 12, 12, 15, 7, 10, 12]
	Time taken saving stuff: 0.02s

=== episode:254 Env-steps-taken:76032
 	picked: 103 |actions: {0: 668, 1: 638, 2: 775, 3: 673, 4: 582, 5: 808, 6: 703, 7: 738, 8: 664}
episode: 254/2000 -> reward: 140.3489583333333, steps:6249, time-taken: 3.38min, time-elasped: 719.75min
-> berries picked: 103 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4364 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [605, 509, 572, 525, 648, 514, 251, 373, 367]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 17, 9, 9, 15, 21, 5, 11, 10]
	Time taken saving stuff: 0.03s

=== episode:255 Env-steps-taken:68448
 	picked: 74 |actions: {0: 480, 1: 563, 2: 582, 3: 520, 4: 486, 5: 581, 6: 560, 7: 619, 8: 596}
episode: 255/2000 -> reward: 102.51041666666659, steps:4987, time-taken: 2.87min, time-elasped: 722.63min
-> berries picked: 74 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4382 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [609, 511, 580, 521, 654, 519, 250, 370, 368]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 19, 12, 13, 19, 12, 10, 14, 8]
	Time taken saving stuff: 0.09s

=== episode:256 Env-steps-taken:67296
 	picked: 70 |actions: {0: 645, 1: 446, 2: 528, 3: 506, 4: 390, 5: 514, 6: 456, 7: 535, 8: 574}
episode: 256/2000 -> reward: 96.73958333333326, steps:4594, time-taken: 2.72min, time-elasped: 725.35min
-> berries picked: 70 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4395 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [613, 515, 589, 520, 648, 520, 251, 372, 367]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 7, 15, 10, 14, 10, 13, 9, 15]
	Time taken saving stuff: 0.01s

=== episode:257 Env-steps-taken:64704
 	picked: 61 |actions: {0: 496, 1: 451, 2: 546, 3: 436, 4: 354, 5: 401, 6: 424, 7: 473, 8: 576}
episode: 257/2000 -> reward: 83.7552083333333, steps:4157, time-taken: 3.78min, time-elasped: 729.13min
-> berries picked: 61 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4411 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [623, 520, 597, 521, 646, 516, 243, 376, 369]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 15, 11, 18, 17, 16, 4, 6, 14]
	Time taken saving stuff: 0.00s

=== episode:258 Env-steps-taken:67584
 	picked: 74 |actions: {0: 502, 1: 416, 2: 437, 3: 507, 4: 472, 5: 553, 6: 490, 7: 545, 8: 462}
episode: 258/2000 -> reward: 98.01041666666657, steps:4384, time-taken: 2.89min, time-elasped: 732.02min
-> berries picked: 74 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4434 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [629, 520, 600, 522, 653, 516, 242, 379, 373]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 17, 8, 14, 14, 12, 11, 13, 11]
	Time taken saving stuff: 0.00s

=== episode:259 Env-steps-taken:86880
 	picked: 131 |actions: {0: 838, 1: 647, 2: 658, 3: 730, 4: 610, 5: 687, 6: 792, 7: 932, 8: 737}
episode: 259/2000 -> reward: 195.74479166666697, steps:6631, time-taken: 513.04min, time-elasped: 1245.07min
-> berries picked: 131 of 800 | patches-visited: [0, 1, 5, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4486 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [640, 525, 606, 520, 651, 536, 247, 382, 379]
	| approx positives in sample 512: 99
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 10, 20, 14, 9, 13, 6, 5, 7]
	Time taken saving stuff: 0.12s

=== episode:260 Env-steps-taken:61440
 	picked: 50 |actions: {0: 356, 1: 271, 2: 232, 3: 166, 4: 266, 5: 344, 6: 333, 7: 326, 8: 312}
episode: 260/2000 -> reward: 67.3854166666667, steps:2606, time-taken: 1578.48min, time-elasped: 2823.55min
-> berries picked: 50 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4498 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [644, 531, 609, 513, 655, 535, 250, 380, 381]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 17, 16, 10, 13, 21, 11, 7, 14]
	Time taken saving stuff: 0.07s

=== episode:26 Env-steps-taken:75264
 	picked: 97 |actions: {0: 303, 1: 362, 2: 135, 3: 682, 4: 200, 5: 341, 6: 40, 7: 829, 8: 587}

==================================================
eval-episode: 260 -> reward: 135.80729166666657, steps: 3479.0, wall-time: 46.47s
-> berries picked: 97 of 800 | patches-visited: [1, 8] | juice left:-0.00
==================================================


=== episode:261 Env-steps-taken:60960
 	picked: 49 |actions: {0: 298, 1: 308, 2: 267, 3: 274, 4: 360, 5: 357, 6: 395, 7: 537, 8: 511}
episode: 261/2000 -> reward: 64.94270833333337, steps:3307, time-taken: 2.21min, time-elasped: 2826.54min
-> berries picked: 49 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4495 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [648, 526, 608, 512, 655, 534, 252, 380, 380]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 23, 13, 12, 13, 11, 6, 7, 15]
	Time taken saving stuff: 0.04s

=== episode:262 Env-steps-taken:67200
 	picked: 67 |actions: {0: 426, 1: 378, 2: 366, 3: 414, 4: 387, 5: 418, 6: 418, 7: 350, 8: 388}
episode: 262/2000 -> reward: 96.41145833333326, steps:3545, time-taken: 2.26min, time-elasped: 2828.80min
-> berries picked: 67 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4507 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [654, 524, 614, 515, 658, 528, 252, 381, 381]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [26, 14, 9, 13, 16, 10, 3, 12, 14]
	Time taken saving stuff: 0.09s

=== episode:263 Env-steps-taken:67680
 	picked: 78 |actions: {0: 581, 1: 456, 2: 500, 3: 533, 4: 498, 5: 542, 6: 561, 7: 779, 8: 588}
episode: 263/2000 -> reward: 98.28124999999993, steps:5038, time-taken: 3.31min, time-elasped: 2832.11min
-> berries picked: 78 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4525 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [655, 527, 618, 515, 653, 538, 256, 382, 381]
	| approx positives in sample 512: 101
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 14, 10, 14, 11, 12, 3, 8, 13]
	Time taken saving stuff: 0.01s

=== episode:264 Env-steps-taken:65472
 	picked: 62 |actions: {0: 499, 1: 464, 2: 466, 3: 589, 4: 421, 5: 531, 6: 688, 7: 579, 8: 768}
episode: 264/2000 -> reward: 86.0052083333333, steps:5005, time-taken: 4.82min, time-elasped: 2836.94min
-> berries picked: 62 of 800 | patches-visited: [0, 1, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4524 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [655, 530, 619, 516, 651, 531, 256, 383, 383]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 12, 12, 15, 17, 13, 4, 16, 9]
	Time taken saving stuff: 0.01s

=== episode:265 Env-steps-taken:64320
 	picked: 64 |actions: {0: 345, 1: 357, 2: 410, 3: 346, 4: 392, 5: 397, 6: 386, 7: 489, 8: 350}
episode: 265/2000 -> reward: 81.58333333333334, steps:3472, time-taken: 2.75min, time-elasped: 2839.69min
-> berries picked: 64 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4538 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [659, 529, 622, 517, 655, 531, 254, 387, 384]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 9, 14, 9, 14, 15, 3, 11, 18]
	Time taken saving stuff: 0.03s

=== episode:266 Env-steps-taken:73536
 	picked: 89 |actions: {0: 604, 1: 662, 2: 558, 3: 728, 4: 628, 5: 747, 6: 622, 7: 705, 8: 627}
episode: 266/2000 -> reward: 128.15104166666652, steps:5881, time-taken: 4.40min, time-elasped: 2844.09min
-> berries picked: 89 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4560 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [670, 538, 621, 514, 656, 538, 251, 387, 385]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 12, 21, 12, 11, 12, 2, 14, 15]
	Time taken saving stuff: 0.00s

=== episode:267 Env-steps-taken:74976
 	picked: 104 |actions: {0: 690, 1: 563, 2: 673, 3: 579, 4: 732, 5: 754, 6: 774, 7: 799, 8: 683}
episode: 267/2000 -> reward: 134.79166666666657, steps:6247, time-taken: 4.53min, time-elasped: 2848.63min
-> berries picked: 104 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4587 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [674, 540, 631, 511, 661, 541, 250, 392, 387]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 17, 17, 16, 13, 12, 2, 5, 11]
	Time taken saving stuff: 0.10s

=== episode:268 Env-steps-taken:64320
 	picked: 59 |actions: {0: 425, 1: 291, 2: 360, 3: 446, 4: 417, 5: 422, 6: 667, 7: 530, 8: 534}
episode: 268/2000 -> reward: 81.86979166666663, steps:4092, time-taken: 2.85min, time-elasped: 2851.49min
-> berries picked: 59 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4600 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [682, 539, 633, 510, 662, 537, 256, 392, 389]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 14, 14, 7, 11, 16, 7, 11, 19]
	Time taken saving stuff: 0.03s

=== episode:269 Env-steps-taken:74688
 	picked: 98 |actions: {0: 519, 1: 428, 2: 547, 3: 503, 4: 609, 5: 612, 6: 646, 7: 717, 8: 578}
episode: 269/2000 -> reward: 131.9427083333332, steps:5159, time-taken: 4.32min, time-elasped: 2855.81min
-> berries picked: 98 of 800 | patches-visited: [0, 2, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4638 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [685, 544, 637, 513, 666, 548, 259, 396, 390]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 16, 9, 10, 16, 9, 5, 9, 16]
	Time taken saving stuff: 0.08s

=== episode:270 Env-steps-taken:62976
 	picked: 53 |actions: {0: 340, 1: 321, 2: 338, 3: 278, 4: 299, 5: 355, 6: 430, 7: 474, 8: 496}
episode: 270/2000 -> reward: 74.96354166666669, steps:3331, time-taken: 2.67min, time-elasped: 2858.48min
-> berries picked: 53 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4644 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [692, 544, 638, 516, 665, 546, 260, 391, 392]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 16, 14, 11, 18, 11, 3, 10, 14]
	Time taken saving stuff: 0.07s

=== episode:27 Env-steps-taken:65280
 	picked: 66 |actions: {0: 226, 1: 262, 2: 716, 3: 94, 4: 1387, 5: 245, 6: 849, 7: 129, 8: 157}

==================================================
eval-episode: 270 -> reward: 86.21874999999994, steps: 4065.0, wall-time: 65.13s
-> berries picked: 66 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:271 Env-steps-taken:65952
 	picked: 67 |actions: {0: 352, 1: 385, 2: 407, 3: 373, 4: 427, 5: 414, 6: 324, 7: 504, 8: 372}
episode: 271/2000 -> reward: 89.91145833333327, steps:3558, time-taken: 2.46min, time-elasped: 2862.04min
-> berries picked: 67 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4658 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [693, 552, 642, 511, 671, 539, 261, 397, 392]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 7, 7, 12, 19, 13, 6, 9, 16]
	Time taken saving stuff: 0.08s

=== episode:272 Env-steps-taken:54720
 	picked: 25 |actions: {0: 170, 1: 144, 2: 230, 3: 258, 4: 323, 5: 255, 6: 223, 7: 221, 8: 168}
episode: 272/2000 -> reward: 33.81770833333333, steps:1992, time-taken: 1.74min, time-elasped: 2863.78min
-> berries picked: 25 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4667 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [693, 553, 645, 512, 673, 537, 264, 398, 392]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 15, 21, 8, 12, 13, 10, 11, 10]
	Time taken saving stuff: 0.11s

=== episode:273 Env-steps-taken:71520
 	picked: 86 |actions: {0: 544, 1: 498, 2: 649, 3: 525, 4: 462, 5: 755, 6: 585, 7: 723, 8: 549}
episode: 273/2000 -> reward: 117.82291666666654, steps:5290, time-taken: 3.52min, time-elasped: 2867.31min
-> berries picked: 86 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4677 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [691, 552, 656, 508, 668, 543, 267, 401, 391]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 13, 17, 16, 16, 10, 9, 7, 13]
	Time taken saving stuff: 0.00s

=== episode:274 Env-steps-taken:67776
 	picked: 71 |actions: {0: 475, 1: 465, 2: 602, 3: 547, 4: 481, 5: 500, 6: 426, 7: 568, 8: 439}
episode: 274/2000 -> reward: 99.18229166666659, steps:4503, time-taken: 3.28min, time-elasped: 2870.59min
-> berries picked: 71 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4680 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [691, 560, 658, 509, 662, 539, 267, 402, 392]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 17, 18, 13, 18, 15, 11, 7, 11]
	Time taken saving stuff: 0.03s

=== episode:275 Env-steps-taken:70176
 	picked: 83 |actions: {0: 644, 1: 581, 2: 819, 3: 465, 4: 553, 5: 664, 6: 597, 7: 882, 8: 654}
episode: 275/2000 -> reward: 109.55208333333323, steps:5859, time-taken: 3.92min, time-elasped: 2874.51min
-> berries picked: 83 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4693 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [694, 562, 662, 507, 663, 547, 265, 399, 394]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 13, 12, 11, 15, 13, 9, 17, 17]
	Time taken saving stuff: 0.08s

=== episode:276 Env-steps-taken:68640
 	picked: 78 |actions: {0: 493, 1: 466, 2: 605, 3: 322, 4: 551, 5: 437, 6: 519, 7: 505, 8: 590}
episode: 276/2000 -> reward: 101.58854166666657, steps:4488, time-taken: 3.33min, time-elasped: 2877.84min
-> berries picked: 78 of 800 | patches-visited: [0, 7, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4691 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [684, 568, 669, 508, 665, 544, 270, 389, 394]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 20, 21, 13, 15, 11, 5, 6, 15]
	Time taken saving stuff: 0.03s

=== episode:277 Env-steps-taken:54048
 	picked: 22 |actions: {0: 101, 1: 134, 2: 188, 3: 71, 4: 140, 5: 212, 6: 131, 7: 88, 8: 171}
episode: 277/2000 -> reward: 30.239583333333336, steps:1236, time-taken: 1.64min, time-elasped: 2879.49min
-> berries picked: 22 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4686 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [678, 568, 671, 509, 667, 540, 269, 387, 397]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 14, 13, 12, 14, 17, 5, 10, 15]
	Time taken saving stuff: 0.01s

=== episode:278 Env-steps-taken:72576
 	picked: 83 |actions: {0: 444, 1: 504, 2: 455, 3: 385, 4: 404, 5: 500, 6: 509, 7: 499, 8: 507}
episode: 278/2000 -> reward: 123.74479166666652, steps:4207, time-taken: 3.51min, time-elasped: 2883.01min
-> berries picked: 83 of 800 | patches-visited: [0, 3, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4717 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [677, 568, 678, 515, 670, 539, 279, 392, 399]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 13, 13, 7, 17, 15, 4, 10, 16]
	Time taken saving stuff: 0.05s

=== episode:279 Env-steps-taken:68832
 	picked: 74 |actions: {0: 425, 1: 284, 2: 424, 3: 376, 4: 522, 5: 610, 6: 552, 7: 646, 8: 501}
episode: 279/2000 -> reward: 104.51041666666657, steps:4340, time-taken: 5.08min, time-elasped: 2888.10min
-> berries picked: 74 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4720 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [676, 562, 679, 517, 677, 534, 288, 390, 397]
	| approx positives in sample 512: 96
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 11, 16, 9, 13, 12, 7, 5, 8]
	Time taken saving stuff: 0.03s

=== episode:280 Env-steps-taken:59232
 	picked: 41 |actions: {0: 365, 1: 399, 2: 285, 3: 231, 4: 270, 5: 323, 6: 287, 7: 484, 8: 527}
episode: 280/2000 -> reward: 56.40104166666669, steps:3171, time-taken: 2.72min, time-elasped: 2890.83min
-> berries picked: 41 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4716 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [672, 559, 682, 516, 678, 530, 289, 390, 400]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 16, 15, 7, 12, 9, 9, 5, 16]
	Time taken saving stuff: 0.09s

=== episode:28 Env-steps-taken:54432
 	picked: 22 |actions: {0: 69, 1: 92, 2: 225, 3: 1281, 4: 17, 5: 1011, 6: 33, 7: 1108, 8: 1113}

==================================================
eval-episode: 280 -> reward: 32.239583333333336, steps: 4949.0, wall-time: 76.62s
-> berries picked: 22 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:281 Env-steps-taken:52992
 	picked: 18 |actions: {0: 163, 1: 122, 2: 166, 3: 108, 4: 92, 5: 148, 6: 207, 7: 219, 8: 174}
episode: 281/2000 -> reward: 25.218749999999993, steps:1399, time-taken: 1.70min, time-elasped: 2893.81min
-> berries picked: 18 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4724 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [674, 559, 682, 516, 679, 530, 289, 394, 401]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 11, 8, 13, 27, 17, 8, 7, 12]
	Time taken saving stuff: 0.03s

=== episode:282 Env-steps-taken:59712
 	picked: 42 |actions: {0: 303, 1: 279, 2: 485, 3: 247, 4: 283, 5: 258, 6: 389, 7: 306, 8: 257}
episode: 282/2000 -> reward: 58.84375000000004, steps:2807, time-taken: 2.53min, time-elasped: 2896.35min
-> berries picked: 42 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4741 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [673, 564, 686, 516, 683, 531, 291, 397, 400]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 11, 14, 15, 9, 13, 8, 10, 11]
	Time taken saving stuff: 0.07s

=== episode:283 Env-steps-taken:56064
 	picked: 30 |actions: {0: 97, 1: 142, 2: 178, 3: 114, 4: 93, 5: 273, 6: 188, 7: 164, 8: 159}
episode: 283/2000 -> reward: 40.28125000000001, steps:1408, time-taken: 1.76min, time-elasped: 2898.12min
-> berries picked: 30 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4755 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [677, 566, 688, 514, 685, 532, 296, 395, 402]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 14, 12, 11, 15, 21, 5, 18, 15]
	Time taken saving stuff: 0.09s

=== episode:284 Env-steps-taken:59904
 	picked: 42 |actions: {0: 403, 1: 202, 2: 362, 3: 251, 4: 349, 5: 355, 6: 450, 7: 455, 8: 519}
episode: 284/2000 -> reward: 59.59375000000004, steps:3346, time-taken: 2.72min, time-elasped: 2900.84min
-> berries picked: 42 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4753 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [677, 559, 686, 511, 684, 536, 293, 400, 407]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [24, 18, 15, 11, 16, 16, 4, 6, 12]
	Time taken saving stuff: 0.01s

=== episode:285 Env-steps-taken:67488
 	picked: 66 |actions: {0: 477, 1: 399, 2: 722, 3: 621, 4: 458, 5: 514, 6: 697, 7: 641, 8: 531}
episode: 285/2000 -> reward: 97.96874999999993, steps:5060, time-taken: 3.86min, time-elasped: 2904.71min
-> berries picked: 66 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4747 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [675, 553, 694, 516, 679, 530, 294, 400, 406]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 13, 21, 7, 14, 8, 5, 4, 17]
	Time taken saving stuff: 0.01s

=== episode:286 Env-steps-taken:64896
 	picked: 61 |actions: {0: 466, 1: 394, 2: 548, 3: 367, 4: 472, 5: 478, 6: 501, 7: 644, 8: 731}
episode: 286/2000 -> reward: 85.0052083333333, steps:4601, time-taken: 3.02min, time-elasped: 2907.73min
-> berries picked: 61 of 800 | patches-visited: [0, 3, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4757 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [676, 549, 704, 517, 677, 526, 296, 404, 408]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 12, 13, 7, 10, 15, 9, 8, 13]
	Time taken saving stuff: 0.08s

=== episode:287 Env-steps-taken:64320
 	picked: 61 |actions: {0: 370, 1: 407, 2: 586, 3: 375, 4: 391, 5: 379, 6: 422, 7: 524, 8: 522}
episode: 287/2000 -> reward: 80.86979166666664, steps:3976, time-taken: 2.78min, time-elasped: 2910.52min
-> berries picked: 61 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4761 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [679, 553, 707, 515, 678, 522, 294, 403, 410]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 10, 18, 11, 21, 9, 9, 13, 11]
	Time taken saving stuff: 0.01s

=== episode:288 Env-steps-taken:63648
 	picked: 57 |actions: {0: 384, 1: 278, 2: 312, 3: 326, 4: 344, 5: 386, 6: 421, 7: 394, 8: 365}
episode: 288/2000 -> reward: 78.23437499999997, steps:3210, time-taken: 2.37min, time-elasped: 2912.89min
-> berries picked: 57 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4773 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [682, 555, 711, 515, 684, 524, 294, 399, 409]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 8, 20, 11, 14, 11, 5, 9, 12]
	Time taken saving stuff: 0.08s

=== episode:289 Env-steps-taken:66624
 	picked: 67 |actions: {0: 589, 1: 493, 2: 614, 3: 455, 4: 551, 5: 553, 6: 471, 7: 393, 8: 504}
episode: 289/2000 -> reward: 93.66145833333327, steps:4623, time-taken: 3.25min, time-elasped: 2916.15min
-> berries picked: 67 of 800 | patches-visited: [0, 1, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4795 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [685, 565, 714, 518, 685, 524, 294, 399, 411]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 15, 11, 11, 17, 4, 7, 12, 13]
	Time taken saving stuff: 0.11s

=== episode:290 Env-steps-taken:64800
 	picked: 59 |actions: {0: 339, 1: 238, 2: 416, 3: 347, 4: 409, 5: 352, 6: 346, 7: 417, 8: 521}
episode: 290/2000 -> reward: 84.86979166666663, steps:3385, time-taken: 2.56min, time-elasped: 2918.72min
-> berries picked: 59 of 800 | patches-visited: [0, 2, 4, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4822 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [693, 562, 717, 525, 688, 527, 296, 400, 414]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 13, 12, 13, 11, 11, 4, 13, 18]
	Time taken saving stuff: 0.09s

=== episode:29 Env-steps-taken:76416
 	picked: 101 |actions: {0: 402, 1: 182, 2: 469, 3: 194, 4: 287, 5: 520, 6: 276, 7: 840, 8: 1139}

==================================================
eval-episode: 290 -> reward: 141.2708333333333, steps: 4309.0, wall-time: 74.35s
-> berries picked: 101 of 800 | patches-visited: [0, 1, 2, 3, 5] | juice left:-0.00
==================================================


=== episode:291 Env-steps-taken:56352
 	picked: 32 |actions: {0: 278, 1: 200, 2: 227, 3: 189, 4: 140, 5: 125, 6: 142, 7: 199, 8: 229}
episode: 291/2000 -> reward: 41.91666666666668, steps:1729, time-taken: 1.61min, time-elasped: 2921.57min
-> berries picked: 32 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4833 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [700, 564, 719, 526, 687, 527, 292, 401, 417]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 16, 12, 11, 18, 11, 5, 10, 17]
	Time taken saving stuff: 0.00s

=== episode:292 Env-steps-taken:63456
 	picked: 56 |actions: {0: 536, 1: 229, 2: 325, 3: 409, 4: 499, 5: 483, 6: 349, 7: 644, 8: 489}
episode: 292/2000 -> reward: 77.79166666666666, steps:3963, time-taken: 2.65min, time-elasped: 2924.23min
-> berries picked: 56 of 800 | patches-visited: [0, 4, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4838 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [701, 564, 718, 524, 695, 519, 295, 405, 417]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 11, 22, 9, 16, 16, 8, 5, 20]
	Time taken saving stuff: 0.10s

=== episode:293 Env-steps-taken:62592
 	picked: 51 |actions: {0: 330, 1: 323, 2: 431, 3: 452, 4: 429, 5: 454, 6: 561, 7: 462, 8: 453}
episode: 293/2000 -> reward: 73.32812500000001, steps:3895, time-taken: 2.67min, time-elasped: 2926.90min
-> berries picked: 51 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4847 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [702, 561, 718, 523, 695, 520, 300, 409, 419]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 12, 16, 13, 16, 11, 12, 9, 13]
	Time taken saving stuff: 0.02s

=== episode:294 Env-steps-taken:71040
 	picked: 91 |actions: {0: 524, 1: 505, 2: 735, 3: 613, 4: 547, 5: 697, 6: 697, 7: 668, 8: 589}
episode: 294/2000 -> reward: 115.03645833333319, steps:5575, time-taken: 3.90min, time-elasped: 2930.82min
-> berries picked: 91 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4862 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [709, 560, 722, 524, 695, 520, 303, 409, 420]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 10, 12, 13, 17, 9, 5, 7, 18]
	Time taken saving stuff: 0.04s

=== episode:295 Env-steps-taken:64896
 	picked: 61 |actions: {0: 365, 1: 330, 2: 353, 3: 336, 4: 420, 5: 304, 6: 552, 7: 574, 8: 490}
episode: 295/2000 -> reward: 82.81249999999999, steps:3724, time-taken: 2.77min, time-elasped: 2933.59min
-> berries picked: 61 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4870 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [710, 564, 726, 525, 687, 516, 312, 411, 419]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 15, 23, 10, 13, 14, 4, 9, 14]
	Time taken saving stuff: 0.00s

=== episode:296 Env-steps-taken:64416
 	picked: 66 |actions: {0: 568, 1: 571, 2: 775, 3: 446, 4: 466, 5: 386, 6: 516, 7: 457, 8: 759}
episode: 296/2000 -> reward: 81.71874999999997, steps:4944, time-taken: 3.30min, time-elasped: 2936.90min
-> berries picked: 66 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4870 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [712, 568, 736, 522, 684, 511, 309, 410, 418]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 11, 22, 14, 12, 13, 11, 10, 8]
	Time taken saving stuff: 0.08s

=== episode:297 Env-steps-taken:66336
 	picked: 62 |actions: {0: 556, 1: 469, 2: 662, 3: 349, 4: 385, 5: 403, 6: 537, 7: 507, 8: 564}
episode: 297/2000 -> reward: 92.19791666666663, steps:4432, time-taken: 3.14min, time-elasped: 2940.05min
-> berries picked: 62 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4877 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [711, 573, 740, 521, 682, 506, 306, 416, 422]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 14, 12, 14, 10, 13, 9, 9, 15]
	Time taken saving stuff: 0.01s

=== episode:298 Env-steps-taken:68064
 	picked: 73 |actions: {0: 519, 1: 380, 2: 582, 3: 414, 4: 521, 5: 549, 6: 537, 7: 534, 8: 600}
episode: 298/2000 -> reward: 100.81770833333326, steps:4636, time-taken: 3.39min, time-elasped: 2943.44min
-> berries picked: 73 of 800 | patches-visited: [0, 7, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4902 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [708, 571, 739, 527, 689, 512, 315, 415, 426]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 14, 16, 8, 14, 11, 5, 11, 14]
	Time taken saving stuff: 0.11s

=== episode:299 Env-steps-taken:65184
 	picked: 64 |actions: {0: 365, 1: 356, 2: 357, 3: 384, 4: 580, 5: 509, 6: 537, 7: 574, 8: 509}
episode: 299/2000 -> reward: 86.0833333333333, steps:4171, time-taken: 3.18min, time-elasped: 2946.62min
-> berries picked: 64 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4910 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [708, 574, 737, 529, 693, 511, 320, 410, 428]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 4, 17, 7, 19, 13, 7, 11, 10]
	Time taken saving stuff: 0.09s

=== episode:300 Env-steps-taken:67488
 	picked: 72 |actions: {0: 544, 1: 410, 2: 489, 3: 450, 4: 514, 5: 529, 6: 685, 7: 576, 8: 682}
episode: 300/2000 -> reward: 97.87499999999991, steps:4879, time-taken: 3.60min, time-elasped: 2950.23min
-> berries picked: 72 of 800 | patches-visited: [0, 5, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4929 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [712, 576, 740, 529, 692, 521, 315, 410, 434]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 12, 12, 10, 6, 15, 11, 13, 15]
	Time taken saving stuff: 0.10s

=== episode:30 Env-steps-taken:67872
 	picked: 74 |actions: {0: 155, 1: 182, 2: 225, 3: 135, 4: 855, 5: 250, 6: 260, 7: 1734, 8: 1009}

==================================================
eval-episode: 300 -> reward: 99.76041666666659, steps: 4805.0, wall-time: 67.10s
-> berries picked: 74 of 800 | patches-visited: [1, 3, 9] | juice left:-0.00
==================================================


=== episode:301 Env-steps-taken:61248
 	picked: 50 |actions: {0: 392, 1: 352, 2: 591, 3: 320, 4: 393, 5: 343, 6: 414, 7: 384, 8: 518}
episode: 301/2000 -> reward: 66.19270833333337, steps:3707, time-taken: 2.75min, time-elasped: 2954.11min
-> berries picked: 50 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4926 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [710, 576, 740, 529, 695, 523, 310, 409, 434]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 15, 16, 15, 10, 12, 16, 10, 11]
	Time taken saving stuff: 0.02s

=== episode:302 Env-steps-taken:69984
 	picked: 74 |actions: {0: 550, 1: 424, 2: 497, 3: 560, 4: 429, 5: 528, 6: 374, 7: 509, 8: 500}
episode: 302/2000 -> reward: 109.62499999999989, steps:4371, time-taken: 3.14min, time-elasped: 2957.25min
-> berries picked: 74 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4955 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [723, 580, 746, 532, 697, 524, 310, 410, 433]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 15, 16, 15, 12, 12, 5, 18, 15]
	Time taken saving stuff: 0.09s

=== episode:303 Env-steps-taken:55776
 	picked: 28 |actions: {0: 207, 1: 264, 2: 390, 3: 297, 4: 373, 5: 271, 6: 214, 7: 253, 8: 347}
episode: 303/2000 -> reward: 38.89583333333332, steps:2616, time-taken: 1.94min, time-elasped: 2959.20min
-> berries picked: 28 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4952 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [721, 581, 746, 537, 700, 521, 308, 405, 433]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 14, 14, 13, 12, 7, 10, 8, 16]
	Time taken saving stuff: 0.03s

=== episode:304 Env-steps-taken:63744
 	picked: 60 |actions: {0: 359, 1: 431, 2: 464, 3: 397, 4: 365, 5: 380, 6: 446, 7: 609, 8: 404}
episode: 304/2000 -> reward: 78.8125, steps:3855, time-taken: 2.70min, time-elasped: 2961.90min
-> berries picked: 60 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4960 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [720, 583, 751, 537, 697, 524, 310, 404, 434]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 9, 16, 13, 9, 13, 12, 11, 22]
	Time taken saving stuff: 0.03s

=== episode:305 Env-steps-taken:77088
 	picked: 100 |actions: {0: 783, 1: 638, 2: 894, 3: 587, 4: 621, 5: 588, 6: 672, 7: 636, 8: 568}
episode: 305/2000 -> reward: 144.32812499999994, steps:5987, time-taken: 3.96min, time-elasped: 2965.87min
-> berries picked: 100 of 800 | patches-visited: [0, 3, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4993 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [727, 593, 750, 536, 700, 527, 312, 410, 438]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 11, 14, 11, 12, 15, 7, 14, 13]
	Time taken saving stuff: 0.10s

=== episode:306 Env-steps-taken:66144
 	picked: 63 |actions: {0: 488, 1: 444, 2: 523, 3: 422, 4: 588, 5: 419, 6: 514, 7: 514, 8: 436}
episode: 306/2000 -> reward: 91.14062499999997, steps:4348, time-taken: 3.31min, time-elasped: 2969.18min
-> berries picked: 63 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4991 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [737, 593, 752, 535, 694, 527, 310, 405, 438]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 16, 30, 11, 12, 9, 7, 6, 15]
	Time taken saving stuff: 0.09s

=== episode:307 Env-steps-taken:62880
 	picked: 55 |actions: {0: 424, 1: 346, 2: 382, 3: 218, 4: 291, 5: 292, 6: 409, 7: 388, 8: 347}
episode: 307/2000 -> reward: 72.02083333333334, steps:3097, time-taken: 2.36min, time-elasped: 2971.54min
-> berries picked: 55 of 800 | patches-visited: [0, 6, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4998 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [738, 597, 750, 535, 693, 526, 311, 406, 442]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 16, 10, 8, 27, 10, 7, 7, 17]
	Time taken saving stuff: 0.07s

=== episode:308 Env-steps-taken:62784
 	picked: 48 |actions: {0: 317, 1: 335, 2: 345, 3: 376, 4: 252, 5: 364, 6: 370, 7: 313, 8: 314}
episode: 308/2000 -> reward: 74.50000000000001, steps:2986, time-taken: 2.41min, time-elasped: 2973.96min
-> berries picked: 48 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5010 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [742, 597, 752, 538, 698, 531, 309, 400, 443]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 13, 15, 11, 9, 9, 8, 8, 10]
	Time taken saving stuff: 0.02s

=== episode:309 Env-steps-taken:65952
 	picked: 69 |actions: {0: 794, 1: 498, 2: 612, 3: 549, 4: 442, 5: 500, 6: 634, 7: 567, 8: 679}
episode: 309/2000 -> reward: 89.54687499999994, steps:5275, time-taken: 3.39min, time-elasped: 2977.36min
-> berries picked: 69 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5002 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [739, 589, 756, 543, 693, 533, 302, 402, 445]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 14, 19, 12, 20, 11, 6, 8, 14]
	Time taken saving stuff: 0.01s

=== episode:310 Env-steps-taken:60672
 	picked: 46 |actions: {0: 288, 1: 218, 2: 367, 3: 371, 4: 297, 5: 295, 6: 355, 7: 364, 8: 367}
episode: 310/2000 -> reward: 62.229166666666714, steps:2922, time-taken: 2.25min, time-elasped: 2979.61min
-> berries picked: 46 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5011 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [734, 584, 757, 544, 695, 540, 304, 406, 447]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 15, 21, 14, 11, 15, 9, 8, 18]
	Time taken saving stuff: 0.09s

=== episode:31 Env-steps-taken:52800
 	picked: 18 |actions: {0: 89, 1: 46, 2: 2001, 3: 13, 4: 61, 5: 769, 6: 942, 7: 878, 8: 1}

==================================================
eval-episode: 310 -> reward: 23.968749999999996, steps: 4800.0, wall-time: 65.07s
-> berries picked: 18 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:311 Env-steps-taken:60768
 	picked: 44 |actions: {0: 339, 1: 394, 2: 476, 3: 311, 4: 318, 5: 290, 6: 345, 7: 630, 8: 381}
episode: 311/2000 -> reward: 63.84375000000004, steps:3484, time-taken: 2.36min, time-elasped: 2983.05min
-> berries picked: 44 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4993 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [733, 582, 753, 540, 692, 530, 305, 407, 451]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 14, 17, 11, 14, 12, 9, 12, 14]
	Time taken saving stuff: 0.08s

=== episode:312 Env-steps-taken:69888
 	picked: 85 |actions: {0: 589, 1: 498, 2: 636, 3: 447, 4: 596, 5: 466, 6: 573, 7: 713, 8: 451}
episode: 312/2000 -> reward: 109.38020833333319, steps:4969, time-taken: 3.54min, time-elasped: 2986.60min
-> berries picked: 85 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4994 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [737, 588, 749, 537, 686, 535, 300, 409, 453]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 10, 13, 7, 12, 16, 5, 10, 14]
	Time taken saving stuff: 0.10s

=== episode:313 Env-steps-taken:67488
 	picked: 73 |actions: {0: 739, 1: 535, 2: 605, 3: 407, 4: 557, 5: 412, 6: 601, 7: 724, 8: 544}
episode: 313/2000 -> reward: 97.31770833333321, steps:5124, time-taken: 3.50min, time-elasped: 2990.10min
-> berries picked: 73 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4982 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [740, 583, 749, 537, 680, 530, 299, 411, 453]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 16, 19, 10, 11, 7, 10, 9, 13]
	Time taken saving stuff: 0.00s

=== episode:314 Env-steps-taken:64512
 	picked: 61 |actions: {0: 599, 1: 540, 2: 725, 3: 400, 4: 502, 5: 372, 6: 529, 7: 576, 8: 520}
episode: 314/2000 -> reward: 82.7552083333333, steps:4763, time-taken: 3.19min, time-elasped: 2993.30min
-> berries picked: 61 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4968 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [747, 583, 753, 526, 673, 526, 295, 411, 454]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 15, 19, 14, 14, 12, 3, 7, 15]
	Time taken saving stuff: 0.00s

=== episode:315 Env-steps-taken:64800
 	picked: 64 |actions: {0: 634, 1: 541, 2: 561, 3: 480, 4: 450, 5: 355, 6: 464, 7: 635, 8: 435}
episode: 315/2000 -> reward: 83.83333333333331, steps:4555, time-taken: 3.24min, time-elasped: 2996.54min
-> berries picked: 64 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4972 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [747, 584, 756, 531, 667, 523, 299, 415, 450]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 11, 19, 11, 13, 17, 5, 7, 13]
	Time taken saving stuff: 0.07s

=== episode:316 Env-steps-taken:66336
 	picked: 65 |actions: {0: 378, 1: 340, 2: 379, 3: 390, 4: 316, 5: 405, 6: 282, 7: 463, 8: 290}
episode: 316/2000 -> reward: 90.08333333333329, steps:3243, time-taken: 2.37min, time-elasped: 2998.91min
-> berries picked: 65 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4979 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [749, 590, 754, 532, 663, 523, 299, 416, 453]
	| approx positives in sample 512: 101
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 10, 13, 7, 10, 14, 6, 16, 13]
	Time taken saving stuff: 0.00s

=== episode:317 Env-steps-taken:68256
 	picked: 74 |actions: {0: 529, 1: 449, 2: 659, 3: 450, 4: 495, 5: 421, 6: 447, 7: 569, 8: 578}
episode: 317/2000 -> reward: 101.51041666666657, steps:4597, time-taken: 3.29min, time-elasped: 3002.20min
-> berries picked: 74 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4945 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [750, 586, 742, 525, 662, 520, 291, 416, 453]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 10, 13, 10, 18, 16, 6, 12, 19]
	Time taken saving stuff: 0.03s

=== episode:318 Env-steps-taken:66912
 	picked: 70 |actions: {0: 446, 1: 450, 2: 512, 3: 414, 4: 552, 5: 562, 6: 500, 7: 614, 8: 404}
episode: 318/2000 -> reward: 94.73958333333327, steps:4454, time-taken: 3.12min, time-elasped: 3005.33min
-> berries picked: 70 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4955 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [756, 591, 738, 525, 656, 522, 291, 423, 453]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 18, 8, 7, 9, 10, 8, 7, 23]
	Time taken saving stuff: 0.11s

=== episode:319 Env-steps-taken:60576
 	picked: 54 |actions: {0: 567, 1: 725, 2: 815, 3: 585, 4: 415, 5: 492, 6: 484, 7: 708, 8: 656}
episode: 319/2000 -> reward: 62.40625000000006, steps:5447, time-taken: 3.88min, time-elasped: 3009.22min
-> berries picked: 54 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4931 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [763, 592, 737, 520, 652, 512, 283, 419, 453]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 13, 18, 15, 11, 13, 12, 13, 14]
	Time taken saving stuff: 0.10s

=== episode:320 Env-steps-taken:56736
 	picked: 33 |actions: {0: 214, 1: 219, 2: 235, 3: 198, 4: 193, 5: 255, 6: 237, 7: 246, 8: 217}
episode: 320/2000 -> reward: 43.60937500000001, steps:2014, time-taken: 1.75min, time-elasped: 3010.98min
-> berries picked: 33 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4934 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [768, 592, 738, 519, 655, 512, 280, 416, 454]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [25, 13, 15, 14, 20, 7, 6, 8, 16]
	Time taken saving stuff: 0.07s

=== episode:32 Env-steps-taken:86208
 	picked: 143 |actions: {0: 738, 1: 377, 2: 962, 3: 672, 4: 230, 5: 413, 6: 190, 7: 690, 8: 1133}

==================================================
eval-episode: 320 -> reward: 191.30729166666697, steps: 5405.0, wall-time: 82.58s
-> berries picked: 143 of 800 | patches-visited: [1, 4, 7] | juice left:-0.00
==================================================


=== episode:321 Env-steps-taken:74016
 	picked: 94 |actions: {0: 616, 1: 709, 2: 815, 3: 480, 4: 537, 5: 509, 6: 591, 7: 793, 8: 465}
episode: 321/2000 -> reward: 130.36458333333317, steps:5515, time-taken: 4.18min, time-elasped: 3016.54min
-> berries picked: 94 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4961 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [774, 602, 735, 527, 653, 514, 282, 417, 457]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 15, 15, 8, 13, 11, 7, 14, 15]
	Time taken saving stuff: 0.01s

=== episode:322 Env-steps-taken:61824
 	picked: 51 |actions: {0: 371, 1: 524, 2: 666, 3: 283, 4: 347, 5: 368, 6: 428, 7: 367, 8: 393}
episode: 322/2000 -> reward: 69.07812500000003, steps:3747, time-taken: 2.74min, time-elasped: 3019.28min
-> berries picked: 51 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4971 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [773, 600, 742, 529, 657, 515, 280, 419, 456]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 14, 12, 7, 12, 12, 4, 5, 15]
	Time taken saving stuff: 0.10s

=== episode:323 Env-steps-taken:64128
 	picked: 66 |actions: {0: 619, 1: 465, 2: 690, 3: 365, 4: 390, 5: 515, 6: 570, 7: 504, 8: 512}
episode: 323/2000 -> reward: 80.46874999999994, steps:4630, time-taken: 3.13min, time-elasped: 3022.42min
-> berries picked: 66 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4972 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [776, 600, 744, 532, 651, 515, 282, 416, 456]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 15, 11, 10, 17, 21, 4, 9, 15]
	Time taken saving stuff: 0.01s

=== episode:324 Env-steps-taken:69024
 	picked: 79 |actions: {0: 595, 1: 499, 2: 641, 3: 428, 4: 542, 5: 476, 6: 529, 7: 745, 8: 454}
episode: 324/2000 -> reward: 103.2812499999999, steps:4909, time-taken: 3.45min, time-elasped: 3025.88min
-> berries picked: 79 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4970 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [780, 601, 742, 530, 654, 517, 275, 417, 454]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 15, 11, 15, 11, 17, 10, 13, 9]
	Time taken saving stuff: 0.03s

=== episode:325 Env-steps-taken:72864
 	picked: 97 |actions: {0: 650, 1: 666, 2: 882, 3: 532, 4: 707, 5: 625, 6: 631, 7: 764, 8: 523}
episode: 325/2000 -> reward: 124.44270833333317, steps:5980, time-taken: 4.13min, time-elasped: 3030.01min
-> berries picked: 97 of 800 | patches-visited: [0, 1, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4995 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [785, 607, 754, 530, 646, 525, 275, 417, 456]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 14, 13, 10, 21, 13, 5, 4, 7]
	Time taken saving stuff: 0.10s

=== episode:326 Env-steps-taken:58944
 	picked: 34 |actions: {0: 195, 1: 193, 2: 224, 3: 109, 4: 112, 5: 158, 6: 218, 7: 198, 8: 176}
episode: 326/2000 -> reward: 53.35937500000003, steps:1583, time-taken: 1.54min, time-elasped: 3031.55min
-> berries picked: 34 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5000 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [787, 611, 754, 530, 645, 524, 278, 413, 458]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 17, 17, 16, 11, 18, 7, 7, 17]
	Time taken saving stuff: 0.00s

=== episode:327 Env-steps-taken:69408
 	picked: 75 |actions: {0: 489, 1: 431, 2: 533, 3: 432, 4: 442, 5: 555, 6: 748, 7: 713, 8: 490}
episode: 327/2000 -> reward: 107.06770833333321, steps:4833, time-taken: 3.34min, time-elasped: 3034.89min
-> berries picked: 75 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5009 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [783, 612, 751, 529, 650, 524, 291, 412, 457]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 11, 11, 14, 14, 9, 12, 9, 10]
	Time taken saving stuff: 0.11s

=== episode:328 Env-steps-taken:70368
 	picked: 84 |actions: {0: 720, 1: 654, 2: 878, 3: 524, 4: 589, 5: 499, 6: 545, 7: 692, 8: 621}
episode: 328/2000 -> reward: 110.0520833333332, steps:5722, time-taken: 3.82min, time-elasped: 3038.71min
-> berries picked: 84 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5013 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [784, 617, 755, 530, 645, 517, 294, 411, 460]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 9, 17, 7, 9, 10, 8, 18, 15]
	Time taken saving stuff: 0.02s

=== episode:329 Env-steps-taken:68928
 	picked: 78 |actions: {0: 565, 1: 488, 2: 613, 3: 373, 4: 513, 5: 508, 6: 557, 7: 677, 8: 444}
episode: 329/2000 -> reward: 104.39583333333323, steps:4738, time-taken: 3.27min, time-elasped: 3041.98min
-> berries picked: 78 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5015 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [784, 622, 751, 530, 646, 518, 290, 411, 463]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 11, 15, 14, 12, 16, 7, 11, 9]
	Time taken saving stuff: 0.03s

=== episode:330 Env-steps-taken:60192
 	picked: 48 |actions: {0: 414, 1: 274, 2: 523, 3: 265, 4: 358, 5: 361, 6: 348, 7: 400, 8: 407}
episode: 330/2000 -> reward: 61.00000000000005, steps:3350, time-taken: 2.40min, time-elasped: 3044.39min
-> berries picked: 48 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5005 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [776, 626, 749, 530, 645, 520, 289, 408, 462]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [24, 18, 17, 9, 12, 13, 11, 4, 8]
	Time taken saving stuff: 0.10s

=== episode:33 Env-steps-taken:76032
 	picked: 103 |actions: {0: 1164, 1: 311, 2: 331, 3: 193, 4: 102, 5: 324, 6: 294, 7: 507, 8: 1694}

==================================================
eval-episode: 330 -> reward: 139.40624999999994, steps: 4920.0, wall-time: 64.96s
-> berries picked: 103 of 800 | patches-visited: [1, 2, 5, 9] | juice left:-0.00
==================================================


=== episode:331 Env-steps-taken:62784
 	picked: 54 |actions: {0: 603, 1: 474, 2: 419, 3: 280, 4: 414, 5: 364, 6: 577, 7: 763, 8: 539}
episode: 331/2000 -> reward: 74.15625000000003, steps:4433, time-taken: 3.10min, time-elasped: 3048.57min
-> berries picked: 54 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4992 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [768, 625, 746, 531, 645, 518, 294, 405, 460]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 14, 26, 12, 14, 15, 9, 12, 12]
	Time taken saving stuff: 0.09s

=== episode:332 Env-steps-taken:65280
 	picked: 73 |actions: {0: 446, 1: 524, 2: 775, 3: 537, 4: 550, 5: 427, 6: 699, 7: 626, 8: 621}
episode: 332/2000 -> reward: 86.06770833333329, steps:5205, time-taken: 3.66min, time-elasped: 3052.25min
-> berries picked: 73 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4990 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [766, 627, 751, 539, 649, 515, 285, 397, 461]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 10, 8, 14, 11, 11, 9, 7, 9]
	Time taken saving stuff: 0.10s

=== episode:333 Env-steps-taken:59232
 	picked: 44 |actions: {0: 547, 1: 317, 2: 383, 3: 283, 4: 342, 5: 247, 6: 331, 7: 336, 8: 333}
episode: 333/2000 -> reward: 55.97916666666672, steps:3119, time-taken: 2.22min, time-elasped: 3054.47min
-> berries picked: 44 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4980 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [768, 631, 746, 540, 649, 511, 284, 391, 460]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 16, 16, 11, 11, 13, 3, 7, 16]
	Time taken saving stuff: 0.10s

=== episode:334 Env-steps-taken:72192
 	picked: 87 |actions: {0: 776, 1: 576, 2: 899, 3: 512, 4: 560, 5: 611, 6: 828, 7: 827, 8: 561}
episode: 334/2000 -> reward: 121.26562499999986, steps:6150, time-taken: 4.12min, time-elasped: 3058.59min
-> berries picked: 87 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4975 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [771, 634, 740, 539, 645, 513, 282, 390, 461]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 13, 15, 9, 20, 6, 6, 13, 13]
	Time taken saving stuff: 0.10s

=== episode:335 Env-steps-taken:66624
 	picked: 71 |actions: {0: 604, 1: 469, 2: 628, 3: 448, 4: 512, 5: 518, 6: 647, 7: 597, 8: 561}
episode: 335/2000 -> reward: 93.18229166666659, steps:4984, time-taken: 3.55min, time-elasped: 3062.15min
-> berries picked: 71 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4962 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [772, 634, 731, 541, 638, 512, 286, 390, 458]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 13, 17, 12, 8, 15, 11, 7, 18]
	Time taken saving stuff: 0.11s

=== episode:336 Env-steps-taken:68064
 	picked: 72 |actions: {0: 560, 1: 430, 2: 482, 3: 346, 4: 436, 5: 442, 6: 420, 7: 502, 8: 489}
episode: 336/2000 -> reward: 100.62499999999993, steps:4107, time-taken: 3.17min, time-elasped: 3065.32min
-> berries picked: 72 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4964 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [769, 638, 725, 544, 638, 517, 283, 390, 460]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 12, 17, 18, 12, 14, 6, 15, 15]
	Time taken saving stuff: 0.08s

=== episode:337 Env-steps-taken:70272
 	picked: 85 |actions: {0: 780, 1: 614, 2: 610, 3: 520, 4: 604, 5: 410, 6: 478, 7: 706, 8: 489}
episode: 337/2000 -> reward: 111.38020833333323, steps:5211, time-taken: 3.51min, time-elasped: 3068.84min
-> berries picked: 85 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4979 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [769, 643, 724, 549, 640, 518, 285, 390, 461]
	| approx positives in sample 512: 99
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 9, 17, 10, 14, 10, 6, 5, 14]
	Time taken saving stuff: 0.18s

=== episode:338 Env-steps-taken:68736
 	picked: 70 |actions: {0: 495, 1: 479, 2: 558, 3: 384, 4: 534, 5: 498, 6: 440, 7: 481, 8: 557}
episode: 338/2000 -> reward: 104.23958333333324, steps:4426, time-taken: 3.09min, time-elasped: 3071.94min
-> berries picked: 70 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4993 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [773, 643, 723, 557, 643, 520, 281, 392, 461]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 17, 16, 15, 11, 10, 7, 6, 15]
	Time taken saving stuff: 0.11s

=== episode:339 Env-steps-taken:69024
 	picked: 79 |actions: {0: 604, 1: 403, 2: 579, 3: 344, 4: 546, 5: 510, 6: 498, 7: 502, 8: 416}
episode: 339/2000 -> reward: 105.22395833333321, steps:4402, time-taken: 3.18min, time-elasped: 3075.12min
-> berries picked: 79 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5012 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [776, 647, 735, 558, 643, 520, 280, 392, 461]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 17, 24, 12, 17, 15, 5, 10, 9]
	Time taken saving stuff: 0.03s

=== episode:340 Env-steps-taken:71808
 	picked: 93 |actions: {0: 788, 1: 642, 2: 724, 3: 398, 4: 571, 5: 576, 6: 781, 7: 796, 8: 674}
episode: 340/2000 -> reward: 118.53645833333319, steps:5950, time-taken: 4.34min, time-elasped: 3079.47min
-> berries picked: 93 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5020 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [783, 653, 733, 555, 638, 526, 282, 389, 461]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 12, 17, 13, 12, 8, 7, 18, 14]
	Time taken saving stuff: 0.09s

=== episode:34 Env-steps-taken:60288
 	picked: 45 |actions: {0: 233, 1: 120, 2: 108, 3: 6, 4: 97, 5: 854, 6: 41, 7: 307, 8: 103}

==================================================
eval-episode: 340 -> reward: 61.67187500000005, steps: 1869.0, wall-time: 55.20s
-> berries picked: 45 of 800 | patches-visited: [1, 2] | juice left:-0.00
==================================================


=== episode:341 Env-steps-taken:51168
 	picked: 12 |actions: {0: 135, 1: 80, 2: 68, 3: 66, 4: 110, 5: 71, 6: 215, 7: 110, 8: 63}
episode: 341/2000 -> reward: 15.8125, steps:918, time-taken: 1.49min, time-elasped: 3081.88min
-> berries picked: 12 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5013 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [784, 651, 733, 554, 638, 524, 279, 389, 461]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 14, 21, 10, 16, 10, 6, 7, 18]
	Time taken saving stuff: 0.00s

=== episode:342 Env-steps-taken:52992
 	picked: 15 |actions: {0: 72, 1: 130, 2: 101, 3: 56, 4: 46, 5: 45, 6: 45, 7: 100, 8: 70}
episode: 342/2000 -> reward: 25.140625000000004, steps:665, time-taken: 1.17min, time-elasped: 3083.05min
-> berries picked: 15 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5021 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [788, 652, 737, 554, 638, 524, 277, 390, 461]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 21, 14, 9, 16, 7, 7, 16, 14]
	Time taken saving stuff: 0.08s

=== episode:343 Env-steps-taken:52416
 	picked: 17 |actions: {0: 168, 1: 133, 2: 121, 3: 131, 4: 157, 5: 124, 6: 114, 7: 109, 8: 160}
episode: 343/2000 -> reward: 22.026041666666664, steps:1217, time-taken: 1.47min, time-elasped: 3084.53min
-> berries picked: 17 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5023 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [787, 653, 736, 555, 636, 526, 278, 391, 461]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 9, 15, 11, 12, 11, 9, 12, 10]
	Time taken saving stuff: 0.01s

=== episode:344 Env-steps-taken:66528
 	picked: 68 |actions: {0: 795, 1: 537, 2: 627, 3: 441, 4: 713, 5: 549, 6: 709, 7: 882, 8: 687}
episode: 344/2000 -> reward: 92.60416666666659, steps:5940, time-taken: 4.16min, time-elasped: 3088.69min
-> berries picked: 68 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5007 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [786, 655, 731, 552, 637, 523, 271, 393, 459]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 17, 11, 8, 16, 15, 3, 7, 14]
	Time taken saving stuff: 0.03s

=== episode:345 Env-steps-taken:68448
 	picked: 68 |actions: {0: 555, 1: 431, 2: 432, 3: 466, 4: 558, 5: 517, 6: 403, 7: 566, 8: 523}
episode: 345/2000 -> reward: 102.85416666666659, steps:4451, time-taken: 3.52min, time-elasped: 3092.22min
-> berries picked: 68 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5013 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [786, 662, 724, 553, 642, 519, 268, 395, 464]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 16, 12, 9, 17, 14, 6, 13, 13]
	Time taken saving stuff: 0.00s

=== episode:346 Env-steps-taken:64512
 	picked: 57 |actions: {0: 429, 1: 376, 2: 681, 3: 462, 4: 401, 5: 362, 6: 761, 7: 515, 8: 538}
episode: 346/2000 -> reward: 82.98437499999997, steps:4525, time-taken: 3.45min, time-elasped: 3095.67min
-> berries picked: 57 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5003 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [782, 656, 729, 550, 637, 516, 271, 396, 466]
	| approx positives in sample 512: 93
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 16, 7, 10, 14, 10, 5, 7, 11]
	Time taken saving stuff: 0.01s

=== episode:347 Env-steps-taken:62880
 	picked: 53 |actions: {0: 344, 1: 262, 2: 405, 3: 333, 4: 361, 5: 339, 6: 504, 7: 338, 8: 332}
episode: 347/2000 -> reward: 73.82812500000001, steps:3218, time-taken: 2.76min, time-elasped: 3098.44min
-> berries picked: 53 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5007 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [783, 654, 726, 557, 634, 517, 271, 398, 467]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 8, 23, 13, 9, 6, 11, 11, 10]
	Time taken saving stuff: 0.10s

=== episode:348 Env-steps-taken:65280
 	picked: 73 |actions: {0: 554, 1: 554, 2: 577, 3: 484, 4: 691, 5: 529, 6: 865, 7: 872, 8: 742}
episode: 348/2000 -> reward: 85.81770833333329, steps:5868, time-taken: 4.18min, time-elasped: 3102.62min
-> berries picked: 73 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5009 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [784, 646, 724, 560, 636, 520, 271, 402, 466]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [25, 13, 13, 8, 13, 12, 8, 14, 20]
	Time taken saving stuff: 0.01s

=== episode:349 Env-steps-taken:73536
 	picked: 90 |actions: {0: 452, 1: 499, 2: 676, 3: 559, 4: 673, 5: 484, 6: 600, 7: 776, 8: 527}
episode: 349/2000 -> reward: 126.15104166666649, steps:5246, time-taken: 3.96min, time-elasped: 3106.58min
-> berries picked: 90 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5030 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [789, 649, 729, 562, 646, 523, 269, 399, 464]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 10, 11, 9, 15, 11, 11, 10, 16]
	Time taken saving stuff: 0.08s

=== episode:350 Env-steps-taken:59904
 	picked: 44 |actions: {0: 263, 1: 358, 2: 458, 3: 283, 4: 211, 5: 264, 6: 319, 7: 335, 8: 342}
episode: 350/2000 -> reward: 59.72916666666671, steps:2833, time-taken: 2.33min, time-elasped: 3108.92min
-> berries picked: 44 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5036 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [789, 650, 739, 561, 638, 522, 267, 401, 469]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 12, 12, 13, 16, 12, 6, 9, 15]
	Time taken saving stuff: 0.18s

=== episode:35 Env-steps-taken:56736
 	picked: 31 |actions: {0: 212, 1: 1387, 2: 278, 3: 27, 4: 51, 5: 819, 6: 238, 7: 65, 8: 494}

==================================================
eval-episode: 350 -> reward: 43.97395833333334, steps: 3571.0, wall-time: 58.40s
-> berries picked: 31 of 800 | patches-visited: [1, 4] | juice left:-0.00
==================================================


=== episode:351 Env-steps-taken:67584
 	picked: 83 |actions: {0: 461, 1: 761, 2: 683, 3: 509, 4: 806, 5: 529, 6: 614, 7: 503, 8: 470}
episode: 351/2000 -> reward: 97.49479166666656, steps:5336, time-taken: 4.07min, time-elasped: 3113.98min
-> berries picked: 83 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5026 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [771, 652, 738, 560, 644, 525, 270, 396, 470]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 17, 17, 13, 14, 13, 8, 6, 15]
	Time taken saving stuff: 0.03s

=== episode:352 Env-steps-taken:69216
 	picked: 78 |actions: {0: 624, 1: 446, 2: 451, 3: 486, 4: 573, 5: 590, 6: 880, 7: 722, 8: 662}
episode: 352/2000 -> reward: 105.39583333333323, steps:5434, time-taken: 4.46min, time-elasped: 3118.44min
-> berries picked: 78 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5022 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [763, 648, 738, 556, 646, 525, 278, 398, 470]
	| approx positives in sample 512: 95
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 17, 10, 11, 9, 13, 11, 9, 6]
	Time taken saving stuff: 0.08s

=== episode:353 Env-steps-taken:67104
 	picked: 69 |actions: {0: 553, 1: 474, 2: 543, 3: 461, 4: 665, 5: 468, 6: 556, 7: 610, 8: 638}
episode: 353/2000 -> reward: 95.41145833333327, steps:4968, time-taken: 3.81min, time-elasped: 3122.26min
-> berries picked: 69 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5011 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [757, 646, 737, 554, 645, 529, 276, 395, 472]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 8, 14, 8, 16, 12, 16, 10, 7]
	Time taken saving stuff: 0.10s

=== episode:354 Env-steps-taken:73152
 	picked: 90 |actions: {0: 532, 1: 570, 2: 604, 3: 512, 4: 701, 5: 465, 6: 733, 7: 531, 8: 778}
episode: 354/2000 -> reward: 126.09374999999983, steps:5426, time-taken: 4.01min, time-elasped: 3126.28min
-> berries picked: 90 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5011 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [759, 648, 735, 553, 643, 534, 273, 394, 472]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 16, 17, 12, 8, 22, 9, 8, 7]
	Time taken saving stuff: 0.03s

=== episode:355 Env-steps-taken:58368
 	picked: 37 |actions: {0: 305, 1: 177, 2: 200, 3: 176, 4: 190, 5: 168, 6: 269, 7: 345, 8: 312}
episode: 355/2000 -> reward: 52.13020833333335, steps:2142, time-taken: 2.27min, time-elasped: 3128.55min
-> berries picked: 37 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5021 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [761, 648, 737, 555, 642, 534, 278, 393, 473]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 19, 7, 10, 16, 14, 9, 16, 10]
	Time taken saving stuff: 0.03s

=== episode:356 Env-steps-taken:76896
 	picked: 100 |actions: {0: 653, 1: 577, 2: 631, 3: 620, 4: 669, 5: 652, 6: 639, 7: 816, 8: 610}
episode: 356/2000 -> reward: 143.32812499999994, steps:5867, time-taken: 4.36min, time-elasped: 3132.92min
-> berries picked: 100 of 800 | patches-visited: [0, 2, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5061 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [768, 663, 741, 551, 653, 536, 284, 390, 475]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 14, 13, 11, 11, 16, 10, 9, 13]
	Time taken saving stuff: 0.10s

=== episode:357 Env-steps-taken:61440
 	picked: 47 |actions: {0: 443, 1: 267, 2: 487, 3: 308, 4: 373, 5: 329, 6: 463, 7: 297, 8: 402}
episode: 357/2000 -> reward: 66.11458333333337, steps:3369, time-taken: 2.82min, time-elasped: 3135.74min
-> berries picked: 47 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5081 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [774, 665, 741, 551, 657, 541, 287, 389, 476]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 12, 19, 10, 14, 9, 12, 6, 20]
	Time taken saving stuff: 0.01s

=== episode:358 Env-steps-taken:66912
 	picked: 66 |actions: {0: 417, 1: 384, 2: 661, 3: 580, 4: 567, 5: 468, 6: 607, 7: 506, 8: 611}
episode: 358/2000 -> reward: 93.08333333333329, steps:4801, time-taken: 3.99min, time-elasped: 3139.73min
-> berries picked: 66 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5092 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [779, 659, 743, 553, 656, 539, 288, 393, 482]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 15, 26, 7, 10, 12, 10, 7, 12]
	Time taken saving stuff: 0.02s

=== episode:359 Env-steps-taken:66336
 	picked: 77 |actions: {0: 491, 1: 547, 2: 611, 3: 569, 4: 856, 5: 667, 6: 587, 7: 479, 8: 595}
episode: 359/2000 -> reward: 91.08854166666659, steps:5402, time-taken: 4.23min, time-elasped: 3143.97min
-> berries picked: 77 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5112 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [779, 665, 748, 555, 667, 542, 288, 390, 478]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 16, 13, 10, 9, 6, 10, 7, 18]
	Time taken saving stuff: 0.04s

=== episode:360 Env-steps-taken:66528
 	picked: 74 |actions: {0: 411, 1: 447, 2: 640, 3: 420, 4: 533, 5: 441, 6: 723, 7: 486, 8: 471}
episode: 360/2000 -> reward: 92.51041666666661, steps:4572, time-taken: 3.51min, time-elasped: 3147.64min
-> berries picked: 74 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5143 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [783, 669, 759, 561, 670, 543, 289, 389, 480]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 17, 18, 9, 14, 7, 6, 14, 10]
	Time taken saving stuff: 0.18s

=== episode:36 Env-steps-taken:84288
 	picked: 144 |actions: {0: 630, 1: 1459, 2: 847, 3: 262, 4: 522, 5: 709, 6: 465, 7: 1264, 8: 1183}

==================================================
eval-episode: 360 -> reward: 181.00000000000028, steps: 7341.0, wall-time: 93.37s
-> berries picked: 144 of 800 | patches-visited: [1, 4] | juice left:-0.00
==================================================


=== episode:361 Env-steps-taken:67680
 	picked: 69 |actions: {0: 431, 1: 508, 2: 562, 3: 383, 4: 521, 5: 341, 6: 457, 7: 505, 8: 446}
episode: 361/2000 -> reward: 98.79687499999994, steps:4154, time-taken: 3.50min, time-elasped: 3152.70min
-> berries picked: 69 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5154 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [784, 672, 758, 559, 676, 545, 292, 386, 482]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 11, 15, 14, 13, 12, 6, 5, 15]
	Time taken saving stuff: 0.10s

=== episode:362 Env-steps-taken:66720
 	picked: 69 |actions: {0: 615, 1: 497, 2: 716, 3: 422, 4: 582, 5: 438, 6: 544, 7: 529, 8: 576}
episode: 362/2000 -> reward: 93.79687499999996, steps:4919, time-taken: 3.95min, time-elasped: 3156.67min
-> berries picked: 69 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5148 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [779, 669, 755, 559, 674, 553, 297, 379, 483]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 12, 23, 15, 10, 7, 6, 6, 12]
	Time taken saving stuff: 0.03s

=== episode:363 Env-steps-taken:69888
 	picked: 86 |actions: {0: 650, 1: 642, 2: 657, 3: 459, 4: 600, 5: 425, 6: 660, 7: 690, 8: 640}
episode: 363/2000 -> reward: 107.38020833333317, steps:5423, time-taken: 4.81min, time-elasped: 3161.49min
-> berries picked: 86 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5154 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [775, 672, 757, 565, 668, 556, 298, 379, 484]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 18, 22, 14, 8, 17, 8, 8, 12]
	Time taken saving stuff: 0.03s

=== episode:364 Env-steps-taken:64992
 	picked: 60 |actions: {0: 353, 1: 384, 2: 330, 3: 325, 4: 495, 5: 290, 6: 507, 7: 288, 8: 419}
episode: 364/2000 -> reward: 85.31249999999997, steps:3391, time-taken: 2.50min, time-elasped: 3163.99min
-> berries picked: 60 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5165 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [776, 670, 760, 568, 675, 556, 300, 376, 484]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 14, 18, 16, 11, 8, 6, 5, 19]
	Time taken saving stuff: 0.03s

=== episode:365 Env-steps-taken:63648
 	picked: 71 |actions: {0: 436, 1: 531, 2: 753, 3: 552, 4: 799, 5: 525, 6: 545, 7: 541, 8: 497}
episode: 365/2000 -> reward: 77.43229166666664, steps:5179, time-taken: 3.56min, time-elasped: 3167.56min
-> berries picked: 71 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5163 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [760, 674, 765, 579, 683, 551, 294, 375, 482]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 12, 16, 9, 18, 11, 6, 17, 5]
	Time taken saving stuff: 0.00s

=== episode:366 Env-steps-taken:50016
 	picked: 8 |actions: {0: 62, 1: 107, 2: 95, 3: 110, 4: 190, 5: 80, 6: 97, 7: 94, 8: 201}
episode: 366/2000 -> reward: 10.041666666666668, steps:1036, time-taken: 1.10min, time-elasped: 3168.66min
-> berries picked: 8 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5151 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [761, 674, 763, 577, 681, 550, 294, 371, 480]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 11, 9, 11, 17, 10, 8, 7, 12]
	Time taken saving stuff: 0.03s

=== episode:367 Env-steps-taken:69984
 	picked: 85 |actions: {0: 633, 1: 535, 2: 564, 3: 460, 4: 492, 5: 682, 6: 732, 7: 860, 8: 769}
episode: 367/2000 -> reward: 109.88020833333319, steps:5727, time-taken: 3.45min, time-elasped: 3172.12min
-> berries picked: 85 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5148 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [761, 671, 761, 585, 668, 554, 292, 372, 484]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 23, 15, 8, 10, 15, 11, 7, 16]
	Time taken saving stuff: 0.01s

=== episode:368 Env-steps-taken:65280
 	picked: 68 |actions: {0: 535, 1: 393, 2: 473, 3: 419, 4: 591, 5: 565, 6: 635, 7: 474, 8: 571}
episode: 368/2000 -> reward: 86.35416666666663, steps:4656, time-taken: 3.34min, time-elasped: 3175.46min
-> berries picked: 68 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5153 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [769, 660, 762, 589, 672, 556, 293, 367, 485]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 13, 17, 12, 17, 18, 8, 3, 6]
	Time taken saving stuff: 0.03s

=== episode:369 Env-steps-taken:62016
 	picked: 53 |actions: {0: 345, 1: 314, 2: 572, 3: 509, 4: 640, 5: 495, 6: 626, 7: 473, 8: 581}
episode: 369/2000 -> reward: 69.96354166666667, steps:4555, time-taken: 2.94min, time-elasped: 3178.40min
-> berries picked: 53 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5143 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [772, 658, 762, 593, 670, 556, 289, 358, 485]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [23, 17, 19, 10, 15, 8, 8, 12, 19]
	Time taken saving stuff: 0.10s

=== episode:370 Env-steps-taken:65088
 	picked: 71 |actions: {0: 652, 1: 524, 2: 590, 3: 504, 4: 647, 5: 460, 6: 659, 7: 662, 8: 609}
episode: 370/2000 -> reward: 85.18229166666667, steps:5307, time-taken: 3.37min, time-elasped: 3181.77min
-> berries picked: 71 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5141 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [773, 656, 768, 588, 672, 554, 287, 354, 489]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 19, 18, 20, 16, 11, 5, 9, 15]
	Time taken saving stuff: 0.11s

=== episode:37 Env-steps-taken:73344
 	picked: 89 |actions: {0: 352, 1: 122, 2: 923, 3: 351, 4: 494, 5: 1179, 6: 269, 7: 218, 8: 228}

==================================================
eval-episode: 370 -> reward: 127.4010416666665, steps: 4136.0, wall-time: 84.21s
-> berries picked: 89 of 800 | patches-visited: [0, 1, 3] | juice left:-0.00
==================================================


=== episode:371 Env-steps-taken:59136
 	picked: 40 |actions: {0: 234, 1: 237, 2: 396, 3: 328, 4: 354, 5: 371, 6: 424, 7: 320, 8: 306}
episode: 371/2000 -> reward: 56.208333333333364, steps:2970, time-taken: 2.05min, time-elasped: 3185.23min
-> berries picked: 40 of 800 | patches-visited: [0, 3, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5146 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [775, 652, 768, 591, 676, 557, 284, 353, 490]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 13, 20, 11, 9, 11, 9, 3, 10]
	Time taken saving stuff: 0.01s

=== episode:372 Env-steps-taken:58752
 	picked: 41 |actions: {0: 154, 1: 205, 2: 287, 3: 321, 4: 255, 5: 223, 6: 277, 7: 239, 8: 381}
episode: 372/2000 -> reward: 53.901041666666714, steps:2342, time-taken: 1.96min, time-elasped: 3187.20min
-> berries picked: 41 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5164 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [774, 649, 772, 601, 679, 561, 284, 352, 492]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [25, 11, 10, 13, 16, 12, 7, 12, 11]
	Time taken saving stuff: 0.11s

=== episode:373 Env-steps-taken:66624
 	picked: 72 |actions: {0: 441, 1: 614, 2: 690, 3: 661, 4: 782, 5: 693, 6: 644, 7: 705, 8: 505}
episode: 373/2000 -> reward: 92.87499999999993, steps:5735, time-taken: 3.80min, time-elasped: 3191.00min
-> berries picked: 72 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5163 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [770, 652, 778, 594, 682, 565, 279, 352, 491]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 10, 12, 14, 11, 9, 4, 9, 18]
	Time taken saving stuff: 0.01s

=== episode:374 Env-steps-taken:66432
 	picked: 77 |actions: {0: 433, 1: 530, 2: 697, 3: 672, 4: 848, 5: 558, 6: 800, 7: 587, 8: 534}
episode: 374/2000 -> reward: 91.64583333333326, steps:5659, time-taken: 4.04min, time-elasped: 3195.05min
-> berries picked: 77 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5165 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [767, 654, 779, 600, 690, 559, 276, 349, 491]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 11, 12, 12, 16, 13, 8, 9, 8]
	Time taken saving stuff: 0.11s

=== episode:375 Env-steps-taken:68640
 	picked: 75 |actions: {0: 676, 1: 685, 2: 709, 3: 598, 4: 788, 5: 658, 6: 559, 7: 732, 8: 574}
episode: 375/2000 -> reward: 103.20312499999991, steps:5979, time-taken: 4.07min, time-elasped: 3199.13min
-> berries picked: 75 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5127 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [763, 653, 772, 595, 683, 563, 266, 341, 491]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 11, 19, 5, 13, 6, 13, 2, 13]
	Time taken saving stuff: 0.09s

=== episode:376 Env-steps-taken:62112
 	picked: 49 |actions: {0: 266, 1: 290, 2: 493, 3: 338, 4: 295, 5: 240, 6: 247, 7: 178, 8: 191}
episode: 376/2000 -> reward: 70.69270833333334, steps:2538, time-taken: 2.03min, time-elasped: 3201.17min
-> berries picked: 49 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5115 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [752, 651, 783, 594, 689, 562, 266, 330, 488]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 8, 11, 9, 15, 21, 5, 4, 11]
	Time taken saving stuff: 0.06s

=== episode:377 Env-steps-taken:74304
 	picked: 97 |actions: {0: 489, 1: 611, 2: 629, 3: 750, 4: 775, 5: 562, 6: 725, 7: 712, 8: 703}
episode: 377/2000 -> reward: 131.69270833333317, steps:5956, time-taken: 3.98min, time-elasped: 3205.15min
-> berries picked: 97 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5113 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [729, 653, 783, 603, 692, 570, 271, 324, 488]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 14, 14, 14, 16, 12, 11, 6, 16]
	Time taken saving stuff: 0.03s

=== episode:378 Env-steps-taken:65472
 	picked: 59 |actions: {0: 413, 1: 329, 2: 334, 3: 312, 4: 350, 5: 378, 6: 365, 7: 469, 8: 261}
episode: 378/2000 -> reward: 87.86979166666663, steps:3211, time-taken: 2.53min, time-elasped: 3207.68min
-> berries picked: 59 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5122 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [721, 656, 788, 602, 697, 570, 276, 322, 490]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 12, 15, 9, 15, 10, 12, 2, 24]
	Time taken saving stuff: 0.00s

=== episode:379 Env-steps-taken:55872
 	picked: 28 |actions: {0: 291, 1: 185, 2: 245, 3: 194, 4: 258, 5: 256, 6: 219, 7: 240, 8: 309}
episode: 379/2000 -> reward: 39.64583333333336, steps:2197, time-taken: 1.65min, time-elasped: 3209.33min
-> berries picked: 28 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5109 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [719, 658, 788, 604, 695, 566, 271, 319, 489]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 15, 13, 16, 14, 19, 5, 9, 14]
	Time taken saving stuff: 0.01s

=== episode:380 Env-steps-taken:64896
 	picked: 63 |actions: {0: 506, 1: 408, 2: 448, 3: 369, 4: 385, 5: 339, 6: 363, 7: 483, 8: 592}
episode: 380/2000 -> reward: 84.89062499999997, steps:3893, time-taken: 3.16min, time-elasped: 3212.50min
-> berries picked: 63 of 800 | patches-visited: [0, 3, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5120 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [721, 663, 790, 607, 691, 562, 272, 323, 491]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 14, 23, 9, 11, 14, 8, 5, 11]
	Time taken saving stuff: 0.13s

=== episode:38 Env-steps-taken:82752
 	picked: 134 |actions: {0: 243, 1: 680, 2: 613, 3: 380, 4: 575, 5: 878, 6: 282, 7: 802, 8: 714}

==================================================
eval-episode: 380 -> reward: 172.68750000000023, steps: 5167.0, wall-time: 77.57s
-> berries picked: 134 of 800 | patches-visited: [1, 3] | juice left:-0.00
==================================================


=== episode:381 Env-steps-taken:61440
 	picked: 54 |actions: {0: 276, 1: 337, 2: 262, 3: 496, 4: 511, 5: 468, 6: 370, 7: 369, 8: 493}
episode: 381/2000 -> reward: 67.15625000000004, steps:3582, time-taken: 2.46min, time-elasped: 3216.26min
-> berries picked: 54 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5124 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [725, 660, 789, 614, 690, 571, 269, 318, 488]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 8, 13, 12, 16, 9, 7, 9, 23]
	Time taken saving stuff: 0.09s

=== episode:382 Env-steps-taken:69696
 	picked: 74 |actions: {0: 505, 1: 468, 2: 422, 3: 403, 4: 529, 5: 539, 6: 489, 7: 572, 8: 633}
episode: 382/2000 -> reward: 109.26041666666659, steps:4560, time-taken: 3.28min, time-elasped: 3219.54min
-> berries picked: 74 of 800 | patches-visited: [0, 5, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5112 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [731, 657, 790, 614, 688, 563, 263, 317, 489]
	| approx positives in sample 512: 95
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 15, 16, 5, 9, 12, 10, 5, 11]
	Time taken saving stuff: 0.00s

=== episode:383 Env-steps-taken:56736
 	picked: 29 |actions: {0: 276, 1: 164, 2: 221, 3: 139, 4: 176, 5: 145, 6: 270, 7: 293, 8: 225}
episode: 383/2000 -> reward: 43.83854166666668, steps:1909, time-taken: 1.71min, time-elasped: 3221.25min
-> berries picked: 29 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5112 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [731, 655, 790, 616, 689, 558, 265, 320, 488]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 10, 14, 15, 14, 9, 7, 6, 17]
	Time taken saving stuff: 0.09s

=== episode:384 Env-steps-taken:55104
 	picked: 25 |actions: {0: 123, 1: 107, 2: 118, 3: 165, 4: 244, 5: 244, 6: 239, 7: 230, 8: 296}
episode: 384/2000 -> reward: 36.067708333333336, steps:1766, time-taken: 1.58min, time-elasped: 3222.84min
-> berries picked: 25 of 800 | patches-visited: [0, 6, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5107 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [725, 654, 789, 616, 692, 563, 265, 314, 489]
	| approx positives in sample 512: 94
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 14, 10, 10, 8, 9, 5, 8, 15]
	Time taken saving stuff: 0.03s

=== episode:385 Env-steps-taken:67872
 	picked: 77 |actions: {0: 566, 1: 455, 2: 423, 3: 523, 4: 565, 5: 564, 6: 748, 7: 881, 8: 806}
episode: 385/2000 -> reward: 99.33854166666657, steps:5531, time-taken: 3.85min, time-elasped: 3226.69min
-> berries picked: 77 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5096 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [720, 647, 793, 610, 688, 564, 271, 313, 490]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 10, 14, 17, 13, 19, 10, 7, 8]
	Time taken saving stuff: 0.09s

=== episode:386 Env-steps-taken:57024
 	picked: 32 |actions: {0: 273, 1: 187, 2: 216, 3: 284, 4: 399, 5: 453, 6: 359, 7: 293, 8: 398}
episode: 386/2000 -> reward: 45.1666666666667, steps:2862, time-taken: 2.27min, time-elasped: 3228.97min
-> berries picked: 32 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5088 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [718, 646, 790, 605, 687, 563, 274, 314, 491]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 15, 17, 13, 11, 10, 3, 7, 11]
	Time taken saving stuff: 0.10s

=== episode:387 Env-steps-taken:69408
 	picked: 70 |actions: {0: 642, 1: 458, 2: 462, 3: 308, 4: 292, 5: 270, 6: 499, 7: 550, 8: 464}
episode: 387/2000 -> reward: 107.98958333333324, steps:3945, time-taken: 3.03min, time-elasped: 3232.00min
-> berries picked: 70 of 800 | patches-visited: [0, 3, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5087 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [726, 646, 789, 596, 683, 559, 274, 319, 495]
	| approx positives in sample 512: 93
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 15, 12, 15, 14, 3, 3, 10, 11]
	Time taken saving stuff: 0.09s

=== episode:388 Env-steps-taken:55200
 	picked: 24 |actions: {0: 207, 1: 159, 2: 211, 3: 207, 4: 205, 5: 298, 6: 357, 7: 245, 8: 339}
episode: 388/2000 -> reward: 36.37500000000001, steps:2228, time-taken: 1.91min, time-elasped: 3233.92min
-> berries picked: 24 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5074 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [723, 642, 785, 591, 680, 561, 276, 320, 496]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 13, 9, 15, 9, 11, 8, 5, 13]
	Time taken saving stuff: 0.10s

=== episode:389 Env-steps-taken:61440
 	picked: 45 |actions: {0: 406, 1: 348, 2: 359, 3: 350, 4: 291, 5: 293, 6: 399, 7: 437, 8: 377}
episode: 389/2000 -> reward: 67.67187500000004, steps:3260, time-taken: 2.35min, time-elasped: 3236.27min
-> berries picked: 45 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5073 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [729, 643, 785, 588, 680, 554, 276, 320, 498]
	| approx positives in sample 512: 91
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 11, 13, 8, 12, 10, 5, 8, 14]
	Time taken saving stuff: 0.10s

=== episode:390 Env-steps-taken:67200
 	picked: 72 |actions: {0: 436, 1: 411, 2: 549, 3: 579, 4: 390, 5: 439, 6: 601, 7: 674, 8: 353}
episode: 390/2000 -> reward: 96.18229166666661, steps:4432, time-taken: 3.25min, time-elasped: 3239.52min
-> berries picked: 72 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5103 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [731, 644, 788, 590, 687, 560, 281, 321, 501]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 9, 24, 10, 12, 9, 9, 8, 16]
	Time taken saving stuff: 0.16s

=== episode:39 Env-steps-taken:71040
 	picked: 87 |actions: {0: 856, 1: 109, 2: 2098, 3: 799, 4: 144, 5: 1391, 6: 823, 7: 211, 8: 28}

==================================================
eval-episode: 390 -> reward: 115.51562499999984, steps: 6459.0, wall-time: 78.56s
-> berries picked: 87 of 800 | patches-visited: [0, 1, 8] | juice left:-0.00
==================================================


=== episode:391 Env-steps-taken:60768
 	picked: 49 |actions: {0: 369, 1: 421, 2: 459, 3: 467, 4: 383, 5: 397, 6: 335, 7: 463, 8: 417}
episode: 391/2000 -> reward: 63.69270833333339, steps:3711, time-taken: 2.72min, time-elasped: 3243.56min
-> berries picked: 49 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5102 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [728, 648, 786, 594, 684, 558, 284, 323, 497]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 17, 10, 7, 17, 20, 4, 12, 20]
	Time taken saving stuff: 0.02s

=== episode:392 Env-steps-taken:62016
 	picked: 56 |actions: {0: 376, 1: 420, 2: 389, 3: 416, 4: 374, 5: 319, 6: 424, 7: 460, 8: 350}
episode: 392/2000 -> reward: 70.04166666666669, steps:3528, time-taken: 2.75min, time-elasped: 3246.30min
-> berries picked: 56 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5108 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [731, 651, 790, 595, 678, 559, 287, 318, 499]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 15, 17, 10, 12, 16, 5, 11, 17]
	Time taken saving stuff: 0.03s

=== episode:393 Env-steps-taken:63744
 	picked: 50 |actions: {0: 364, 1: 313, 2: 438, 3: 300, 4: 245, 5: 311, 6: 359, 7: 327, 8: 417}
episode: 393/2000 -> reward: 77.69270833333333, steps:3074, time-taken: 2.41min, time-elasped: 3248.72min
-> berries picked: 50 of 800 | patches-visited: [0, 3, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5091 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [735, 651, 778, 599, 674, 552, 286, 315, 501]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 17, 14, 10, 9, 8, 8, 8, 20]
	Time taken saving stuff: 0.01s

=== episode:394 Env-steps-taken:72096
 	picked: 90 |actions: {0: 556, 1: 520, 2: 800, 3: 566, 4: 543, 5: 508, 6: 554, 7: 635, 8: 776}
episode: 394/2000 -> reward: 120.84374999999986, steps:5458, time-taken: 3.88min, time-elasped: 3252.60min
-> berries picked: 90 of 800 | patches-visited: [0, 5, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5107 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [735, 652, 779, 607, 676, 556, 289, 308, 505]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 18, 13, 10, 8, 11, 10, 7, 13]
	Time taken saving stuff: 0.01s

=== episode:395 Env-steps-taken:66144
 	picked: 69 |actions: {0: 481, 1: 569, 2: 584, 3: 444, 4: 530, 5: 322, 6: 353, 7: 516, 8: 470}
episode: 395/2000 -> reward: 90.79687499999993, steps:4269, time-taken: 2.77min, time-elasped: 3255.38min
-> berries picked: 69 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5113 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [738, 660, 779, 609, 678, 552, 286, 308, 503]
	| approx positives in sample 512: 101
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 11, 17, 7, 9, 9, 7, 8, 21]
	Time taken saving stuff: 0.00s

=== episode:396 Env-steps-taken:64704
 	picked: 55 |actions: {0: 411, 1: 294, 2: 266, 3: 243, 4: 278, 5: 304, 6: 497, 7: 479, 8: 315}
episode: 396/2000 -> reward: 84.09895833333331, steps:3087, time-taken: 2.33min, time-elasped: 3257.71min
-> berries picked: 55 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5101 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [735, 658, 771, 604, 677, 547, 291, 315, 503]
	| approx positives in sample 512: 96
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 8, 18, 13, 11, 6, 7, 9, 7]
	Time taken saving stuff: 0.03s

=== episode:397 Env-steps-taken:60960
 	picked: 43 |actions: {0: 513, 1: 392, 2: 432, 3: 348, 4: 352, 5: 297, 6: 737, 7: 296, 8: 501}
episode: 397/2000 -> reward: 65.28645833333337, steps:3868, time-taken: 2.60min, time-elasped: 3260.32min
-> berries picked: 43 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5081 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [741, 655, 766, 592, 672, 546, 291, 315, 503]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 19, 18, 7, 12, 10, 9, 5, 14]
	Time taken saving stuff: 0.01s

=== episode:398 Env-steps-taken:63552
 	picked: 58 |actions: {0: 477, 1: 372, 2: 411, 3: 411, 4: 343, 5: 285, 6: 550, 7: 408, 8: 420}
episode: 398/2000 -> reward: 77.67708333333334, steps:3677, time-taken: 2.66min, time-elasped: 3262.98min
-> berries picked: 58 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5064 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [742, 653, 768, 583, 672, 538, 292, 314, 502]
	| approx positives in sample 512: 99
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 13, 10, 10, 11, 15, 6, 4, 13]
	Time taken saving stuff: 0.03s

=== episode:399 Env-steps-taken:63264
 	picked: 53 |actions: {0: 495, 1: 268, 2: 309, 3: 339, 4: 435, 5: 334, 6: 547, 7: 534, 8: 314}
episode: 399/2000 -> reward: 76.46354166666666, steps:3575, time-taken: 2.72min, time-elasped: 3265.71min
-> berries picked: 53 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5050 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [744, 648, 759, 580, 667, 539, 294, 319, 500]
	| approx positives in sample 512: 91
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 13, 10, 8, 10, 10, 8, 7, 9]
	Time taken saving stuff: 0.04s

=== episode:400 Env-steps-taken:56640
 	picked: 32 |actions: {0: 416, 1: 222, 2: 210, 3: 167, 4: 272, 5: 227, 6: 354, 7: 328, 8: 245}
episode: 400/2000 -> reward: 43.16666666666669, steps:2441, time-taken: 1.83min, time-elasped: 3267.56min
-> berries picked: 32 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5041 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [744, 649, 752, 576, 665, 541, 290, 324, 500]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 13, 16, 5, 9, 18, 6, 7, 18]
	Time taken saving stuff: 0.13s

=== episode:40 Env-steps-taken:60096
 	picked: 47 |actions: {0: 188, 1: 261, 2: 195, 3: 15, 4: 231, 5: 108, 6: 1641, 7: 1728, 8: 533}

==================================================
eval-episode: 400 -> reward: 60.55729166666671, steps: 4900.0, wall-time: 51.96s
-> berries picked: 47 of 800 | patches-visited: [1, 7] | juice left:-0.00
==================================================


=== episode:401 Env-steps-taken:55872
 	picked: 29 |actions: {0: 259, 1: 343, 2: 316, 3: 238, 4: 322, 5: 228, 6: 348, 7: 290, 8: 386}
episode: 401/2000 -> reward: 39.58854166666667, steps:2730, time-taken: 2.23min, time-elasped: 3270.66min
-> berries picked: 29 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5024 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [748, 642, 755, 572, 657, 536, 294, 322, 498]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 18, 8, 7, 15, 20, 5, 13, 14]
	Time taken saving stuff: 0.03s

=== episode:402 Env-steps-taken:62880
 	picked: 51 |actions: {0: 321, 1: 412, 2: 454, 3: 356, 4: 380, 5: 322, 6: 527, 7: 439, 8: 372}
episode: 402/2000 -> reward: 74.44270833333334, steps:3583, time-taken: 2.75min, time-elasped: 3273.42min
-> berries picked: 51 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5025 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [750, 640, 756, 571, 653, 535, 298, 322, 500]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 14, 9, 15, 8, 11, 9, 9, 11]
	Time taken saving stuff: 0.01s

=== episode:403 Env-steps-taken:66240
 	picked: 73 |actions: {0: 606, 1: 447, 2: 486, 3: 357, 4: 467, 5: 506, 6: 783, 7: 661, 8: 607}
episode: 403/2000 -> reward: 91.0677083333333, steps:4920, time-taken: 3.58min, time-elasped: 3277.00min
-> berries picked: 73 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5009 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [760, 637, 746, 560, 646, 530, 305, 324, 501]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 8, 20, 17, 13, 12, 5, 5, 15]
	Time taken saving stuff: 0.11s

=== episode:404 Env-steps-taken:63264
 	picked: 53 |actions: {0: 422, 1: 523, 2: 337, 3: 386, 4: 367, 5: 523, 6: 727, 7: 503, 8: 582}
episode: 404/2000 -> reward: 76.71354166666666, steps:4370, time-taken: 3.08min, time-elasped: 3280.09min
-> berries picked: 53 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5017 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [765, 640, 739, 561, 649, 530, 306, 324, 503]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 14, 15, 7, 12, 12, 10, 7, 14]
	Time taken saving stuff: 0.10s

=== episode:405 Env-steps-taken:61344
 	picked: 49 |actions: {0: 363, 1: 425, 2: 305, 3: 357, 4: 451, 5: 332, 6: 435, 7: 389, 8: 565}
episode: 405/2000 -> reward: 66.94270833333336, steps:3622, time-taken: 2.43min, time-elasped: 3282.53min
-> berries picked: 49 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5008 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [761, 640, 739, 555, 644, 533, 300, 330, 506]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 16, 13, 10, 11, 10, 6, 5, 14]
	Time taken saving stuff: 0.03s

=== episode:406 Env-steps-taken:61056
 	picked: 46 |actions: {0: 328, 1: 305, 2: 392, 3: 258, 4: 458, 5: 353, 6: 385, 7: 334, 8: 549}
episode: 406/2000 -> reward: 65.61458333333339, steps:3362, time-taken: 2.57min, time-elasped: 3285.11min
-> berries picked: 46 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4981 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [753, 636, 732, 552, 640, 534, 304, 324, 506]
	| approx positives in sample 512: 90
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 9, 10, 11, 12, 11, 10, 4, 16]
	Time taken saving stuff: 0.01s

=== episode:407 Env-steps-taken:52128
 	picked: 14 |actions: {0: 96, 1: 116, 2: 48, 3: 75, 4: 109, 5: 132, 6: 204, 7: 111, 8: 119}
episode: 407/2000 -> reward: 20.697916666666664, steps:1010, time-taken: 1.21min, time-elasped: 3286.33min
-> berries picked: 14 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4984 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [750, 635, 732, 551, 641, 536, 307, 327, 505]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 14, 15, 8, 14, 16, 9, 10, 9]
	Time taken saving stuff: 0.01s

=== episode:408 Env-steps-taken:56256
 	picked: 28 |actions: {0: 159, 1: 306, 2: 178, 3: 154, 4: 219, 5: 141, 6: 196, 7: 235, 8: 297}
episode: 408/2000 -> reward: 40.760416666666686, steps:1885, time-taken: 1.75min, time-elasped: 3288.08min
-> berries picked: 28 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4986 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [750, 640, 732, 553, 641, 532, 305, 326, 507]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 7, 14, 8, 10, 20, 8, 8, 17]
	Time taken saving stuff: 0.01s

=== episode:409 Env-steps-taken:57120
 	picked: 29 |actions: {0: 284, 1: 248, 2: 250, 3: 266, 4: 243, 5: 193, 6: 233, 7: 341, 8: 343}
episode: 409/2000 -> reward: 45.83854166666669, steps:2401, time-taken: 2.22min, time-elasped: 3290.30min
-> berries picked: 29 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4989 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [750, 641, 729, 549, 641, 536, 308, 327, 508]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 15, 11, 17, 9, 12, 4, 11, 15]
	Time taken saving stuff: 0.03s

=== episode:410 Env-steps-taken:67872
 	picked: 69 |actions: {0: 505, 1: 463, 2: 351, 3: 317, 4: 344, 5: 308, 6: 374, 7: 457, 8: 490}
episode: 410/2000 -> reward: 99.16145833333324, steps:3609, time-taken: 3.28min, time-elasped: 3293.59min
-> berries picked: 69 of 800 | patches-visited: [0, 7, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5000 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [747, 645, 724, 551, 643, 537, 311, 331, 511]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 14, 15, 10, 14, 15, 6, 12, 19]
	Time taken saving stuff: 0.08s

=== episode:41 Env-steps-taken:68352
 	picked: 74 |actions: {0: 601, 1: 199, 2: 245, 3: 234, 4: 656, 5: 113, 6: 567, 7: 69, 8: 1232}

==================================================
eval-episode: 410 -> reward: 102.01041666666659, steps: 3916.0, wall-time: 64.13s
-> berries picked: 74 of 800 | patches-visited: [1, 2] | juice left:-0.00
==================================================


=== episode:411 Env-steps-taken:55872
 	picked: 29 |actions: {0: 214, 1: 236, 2: 259, 3: 181, 4: 249, 5: 182, 6: 183, 7: 237, 8: 415}
episode: 411/2000 -> reward: 39.83854166666668, steps:2156, time-taken: 2.02min, time-elasped: 3296.69min
-> berries picked: 29 of 800 | patches-visited: [0, 1, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4988 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [746, 649, 718, 551, 644, 533, 307, 326, 514]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 14, 17, 16, 9, 12, 5, 3, 13]
	Time taken saving stuff: 0.10s

=== episode:412 Env-steps-taken:60192
 	picked: 47 |actions: {0: 247, 1: 375, 2: 285, 3: 275, 4: 367, 5: 266, 6: 392, 7: 377, 8: 476}
episode: 412/2000 -> reward: 61.057291666666714, steps:3060, time-taken: 2.45min, time-elasped: 3299.14min
-> berries picked: 47 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4988 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [744, 649, 716, 549, 643, 533, 309, 331, 514]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 14, 18, 10, 7, 9, 6, 8, 15]
	Time taken saving stuff: 0.09s

=== episode:413 Env-steps-taken:64800
 	picked: 68 |actions: {0: 418, 1: 420, 2: 422, 3: 312, 4: 345, 5: 431, 6: 480, 7: 489, 8: 611}
episode: 413/2000 -> reward: 83.85416666666663, steps:3928, time-taken: 2.78min, time-elasped: 3301.92min
-> berries picked: 68 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4976 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [741, 641, 717, 544, 643, 531, 312, 333, 514]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 13, 13, 8, 13, 13, 5, 9, 16]
	Time taken saving stuff: 0.02s

=== episode:414 Env-steps-taken:62016
 	picked: 56 |actions: {0: 222, 1: 241, 2: 310, 3: 271, 4: 258, 5: 367, 6: 311, 7: 274, 8: 458}
episode: 414/2000 -> reward: 70.29166666666669, steps:2712, time-taken: 2.21min, time-elasped: 3304.14min
-> berries picked: 56 of 800 | patches-visited: [0, 3, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4985 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [738, 635, 719, 549, 645, 531, 320, 333, 515]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 15, 21, 10, 14, 15, 3, 7, 11]
	Time taken saving stuff: 0.10s

=== episode:415 Env-steps-taken:60672
 	picked: 46 |actions: {0: 382, 1: 382, 2: 324, 3: 225, 4: 223, 5: 396, 6: 373, 7: 339, 8: 401}
episode: 415/2000 -> reward: 63.614583333333385, steps:3045, time-taken: 2.59min, time-elasped: 3306.73min
-> berries picked: 46 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4984 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [743, 632, 715, 550, 640, 536, 322, 331, 515]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 11, 17, 18, 13, 10, 8, 8, 7]
	Time taken saving stuff: 0.09s

=== episode:416 Env-steps-taken:53184
 	picked: 17 |actions: {0: 103, 1: 158, 2: 101, 3: 133, 4: 72, 5: 82, 6: 109, 7: 188, 8: 115}
episode: 416/2000 -> reward: 26.026041666666664, steps:1061, time-taken: 1.26min, time-elasped: 3307.99min
-> berries picked: 17 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4969 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [744, 626, 712, 547, 637, 534, 325, 330, 514]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 15, 19, 13, 11, 10, 7, 11, 17]
	Time taken saving stuff: 0.01s

=== episode:417 Env-steps-taken:60000
 	picked: 43 |actions: {0: 343, 1: 221, 2: 265, 3: 232, 4: 173, 5: 216, 6: 303, 7: 364, 8: 331}
episode: 417/2000 -> reward: 60.28645833333338, steps:2448, time-taken: 1.92min, time-elasped: 3309.91min
-> berries picked: 43 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4960 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [745, 624, 705, 550, 636, 531, 323, 331, 515]
	| approx positives in sample 512: 84
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 6, 14, 10, 10, 10, 5, 2, 12]
	Time taken saving stuff: 0.11s

=== episode:418 Env-steps-taken:56352
 	picked: 29 |actions: {0: 157, 1: 203, 2: 253, 3: 251, 4: 228, 5: 176, 6: 144, 7: 114, 8: 260}
episode: 418/2000 -> reward: 42.08854166666668, steps:1786, time-taken: 1.58min, time-elasped: 3311.50min
-> berries picked: 29 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4959 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [744, 622, 707, 554, 634, 533, 318, 331, 516]
	| approx positives in sample 512: 90
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 13, 9, 6, 10, 9, 7, 6, 14]
	Time taken saving stuff: 0.01s

=== episode:419 Env-steps-taken:60768
 	picked: 50 |actions: {0: 448, 1: 424, 2: 303, 3: 428, 4: 298, 5: 254, 6: 477, 7: 558, 8: 449}
episode: 419/2000 -> reward: 63.250000000000036, steps:3639, time-taken: 2.71min, time-elasped: 3314.22min
-> berries picked: 50 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4935 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [748, 617, 702, 552, 630, 531, 312, 329, 514]
	| approx positives in sample 512: 95
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 10, 14, 7, 19, 8, 5, 3, 12]
	Time taken saving stuff: 0.12s

=== episode:420 Env-steps-taken:73344
 	picked: 90 |actions: {0: 740, 1: 598, 2: 629, 3: 614, 4: 498, 5: 547, 6: 738, 7: 856, 8: 680}
episode: 420/2000 -> reward: 127.09374999999984, steps:5900, time-taken: 4.29min, time-elasped: 3318.51min
-> berries picked: 90 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4912 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [738, 615, 695, 547, 628, 531, 310, 333, 515]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 16, 11, 10, 15, 13, 8, 7, 14]
	Time taken saving stuff: 0.12s

=== episode:42 Env-steps-taken:77280
 	picked: 108 |actions: {0: 335, 1: 875, 2: 180, 3: 738, 4: 87, 5: 154, 6: 1258, 7: 234, 8: 442}

==================================================
eval-episode: 420 -> reward: 146.8125, steps: 4303.0, wall-time: 81.03s
-> berries picked: 108 of 800 | patches-visited: [1, 5, 7] | juice left:-0.00
==================================================


=== episode:43 Env-steps-taken:61632
 	picked: 45 |actions: {0: 111, 1: 197, 2: 815, 3: 180, 4: 71, 5: 461, 6: 306, 7: 632, 8: 299}
evalEpisode: 0 -> reward: 66.97916666666671 steps: 3072
-> berries picked: 45 of 800 | patches-visited: [0, 1, 6] | juice left:-0.00
