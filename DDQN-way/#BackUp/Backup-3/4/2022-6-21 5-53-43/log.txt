copied Agent.py to .temp\2022-6-21 5-53-43/pyfiles-backup
copied debugging.py to .temp\2022-6-21 5-53-43/pyfiles-backup/agent_utils/debugging
copied debugging_utils.py to .temp\2022-6-21 5-53-43/pyfiles-backup/agent_utils/debugging
copied __init__.py to .temp\2022-6-21 5-53-43/pyfiles-backup/agent_utils/debugging

copied fubar.py to .temp\2022-6-21 5-53-43/pyfiles-backup/agent_utils/exploration_subroutines
copied random_exploration.py to .temp\2022-6-21 5-53-43/pyfiles-backup/agent_utils/exploration_subroutines
copied random_exploration_v1.py to .temp\2022-6-21 5-53-43/pyfiles-backup/agent_utils/exploration_subroutines
copied skipsteps.py to .temp\2022-6-21 5-53-43/pyfiles-backup/agent_utils/exploration_subroutines/utils
copied __init__.py to .temp\2022-6-21 5-53-43/pyfiles-backup/agent_utils/exploration_subroutines/utils

copied __init__.py to .temp\2022-6-21 5-53-43/pyfiles-backup/agent_utils/exploration_subroutines

copied patch_discovery.py to .temp\2022-6-21 5-53-43/pyfiles-backup/agent_utils/intrinsic_rewards
copied __init__.py to .temp\2022-6-21 5-53-43/pyfiles-backup/agent_utils/intrinsic_rewards

copied plots.py to .temp\2022-6-21 5-53-43/pyfiles-backup/agent_utils/misc
copied printing.py to .temp\2022-6-21 5-53-43/pyfiles-backup/agent_utils/misc
copied __init__.py to .temp\2022-6-21 5-53-43/pyfiles-backup/agent_utils/misc

copied make_net.py to .temp\2022-6-21 5-53-43/pyfiles-backup/agent_utils/nn_utils
copied __init__.py to .temp\2022-6-21 5-53-43/pyfiles-backup/agent_utils/nn_utils

copied berry_worth_function.py to .temp\2022-6-21 5-53-43/pyfiles-backup/agent_utils/state_utils
copied sectorized_states.py to .temp\2022-6-21 5-53-43/pyfiles-backup/agent_utils/state_utils
copied __init__.py to .temp\2022-6-21 5-53-43/pyfiles-backup/agent_utils/state_utils

copied __init__.py to .temp\2022-6-21 5-53-43/pyfiles-backup/agent_utils

copied ensemble.py to .temp\2022-6-21 5-53-43/pyfiles-backup
copied eval.py to .temp\2022-6-21 5-53-43/pyfiles-backup
copied train.py to .temp\2022-6-21 5-53-43/pyfiles-backup
copied utils.py to .temp\2022-6-21 5-53-43/pyfiles-backup/utils/copyfiles
copied __init__.py to .temp\2022-6-21 5-53-43/pyfiles-backup/utils/copyfiles

copied random_env.py to .temp\2022-6-21 5-53-43/pyfiles-backup/utils/env_generation
copied __init__.py to .temp\2022-6-21 5-53-43/pyfiles-backup/utils/env_generation

copied utils.py to .temp\2022-6-21 5-53-43/pyfiles-backup/utils/printing
copied __init__.py to .temp\2022-6-21 5-53-43/pyfiles-backup/utils/printing

copied env_picture.py to .temp\2022-6-21 5-53-43/pyfiles-backup/utils/visualization
copied graphs.py to .temp\2022-6-21 5-53-43/pyfiles-backup/utils/visualization
copied __init__.py to .temp\2022-6-21 5-53-43/pyfiles-backup/utils/visualization

copied __init__.py to .temp\2022-6-21 5-53-43/pyfiles-backup/utils


random_train_env
getBabyEnv :
	 logDir : .temp\2022-6-21 5-53-43
	 initial_juice : 0.5
	 end_on_boundary_hit : False
	 penalize_boundary_hit : False
	 allow_no_action : False
	 no_action_threshold : 0.7
	 add_exploration : True
	 field_size : (20000, 20000)
	 initial_pos_around_berry : True
	 nberries : 80
	 num_patches : 10
	 patch_size : (2600, 2600)
	 patch_with_agent_at_center : True
	 sampling_type : 0
	 seperation : 2400
	 show : False
	 spawn_radius : 100


Agent :
	 self : <Agent.Agent object at 0x00000194E7754F88>
	 berryField : <BerryFieldEnv instance>
	 mode : train
	 angle : 45
	 persistence : 0.8
	 worth_offset : 0.05
	 noise : 0.01
	 nstep_transition : [1]
	 positive_emphasis : 0
	 skipStep : 10
	 reward_patch_discovery : True
	 add_exploration : True
	 time_memory_factor : 0.5
	 time_memory_exp : 1.0
	 time_memory_sizes : [50, 100, 200]
	 render : False
	 debug : False
	 debugDir : .temp
	 device : cuda


total-params:  2098
rewards scaled by 2/(berryField.REWARD_RATE*MAXSIZE)
rewards are clipped between 0 and 2
Exploration subroutine as an action
p_action: 7
Rewarding patch discovery
rewards scaled by 2/(berryField.REWARD_RATE*MAXSIZE)
rewards are clipped between 0 and 2
Exploration subroutine as an action
p_action: 5
Rewarding patch discovery
net(
  (feedforward): ModuleList(
    (0): Linear(in_features=41, out_features=32, bias=True)
    (1): LeakyReLU(negative_slope=0.1)
    (2): Linear(in_features=32, out_features=16, bias=True)
    (3): LeakyReLU(negative_slope=0.1)
  )
  (final_stage): ModuleList(
    (0): Linear(in_features=16, out_features=8, bias=True)
    (1): LeakyReLU(negative_slope=0.1)
  )
  (valueL): Linear(in_features=8, out_features=1, bias=True)
  (actadvs): Linear(in_features=8, out_features=9, bias=True)
)
PrioritizedBuffer of type replace-min
optim = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
), num_gradient_steps= 25
optimizing the online-model after every 100 actions
batch size=512, gamma=0.9, alpha=0.95
polyak_tau=0.1, update_freq=5

=== episode:0 Env-steps-taken:50112
 	picked: 6 |actions: {0: 107, 1: 94, 2: 110, 3: 987, 4: 109, 5: 108, 6: 103, 7: 91, 8: 100}
episode: 0/2000 -> reward: 12.156250000000002, steps:1809, time-taken: 1.41min, time-elasped: 1.42min
-> berries picked: 6 of 800 | patches-visited: [0, 1, 4, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9 | amount-filled: 3.02%
	| action-stats:  [3, 5, 8] [5, 1, 3]
	| approx positives in sample 512: 14
	| approx action-dist in sample 512: [3, 5, 8] [8, 3, 3]
	Time taken saving stuff: 0.12s

=== episode:0 Env-steps-taken:48000
 	picked: 0 |actions: {0: 0, 1: 0, 2: 0, 3: 4364, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0}

==================================================
eval-episode: 0 -> reward: 0.5, steps: 4364.0, wall-time: 36.89s
-> berries picked: 0 of 800 | patches-visited: [1, 8] | juice left:-0.00
==================================================


=== episode:1 Env-steps-taken:49248
 	picked: 5 |actions: {0: 60, 1: 48, 2: 64, 3: 592, 4: 77, 5: 47, 6: 62, 7: 69, 8: 51}
episode: 1/2000 -> reward: 6.713541666666666, steps:1070, time-taken: 1.31min, time-elasped: 3.35min
-> berries picked: 5 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 15 | amount-filled: 4.80%
	| action-stats:  [3, 5, 8] [10, 1, 4]
	| approx positives in sample 512: 6
	| approx action-dist in sample 512: [3, 5, 8] [3, 1, 2]
	Time taken saving stuff: 0.10s

=== episode:2 Env-steps-taken:48576
 	picked: 2 |actions: {0: 19, 1: 13, 2: 14, 3: 82, 4: 20, 5: 104, 6: 23, 7: 21, 8: 13}
episode: 2/2000 -> reward: 2.885416666666667, steps:309, time-taken: 0.59min, time-elasped: 3.95min
-> berries picked: 2 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 17 | amount-filled: 5.31%
	| action-stats:  [3, 5, 7, 8] [10, 2, 1, 4]
	| approx positives in sample 512: 21
	| approx action-dist in sample 512: [3, 5, 7, 8] [14, 1, 4, 2]
	Time taken saving stuff: 0.00s

=== episode:3 Env-steps-taken:49056
 	picked: 5 |actions: {0: 41, 1: 51, 2: 45, 3: 267, 4: 30, 5: 226, 6: 55, 7: 37, 8: 37}
episode: 3/2000 -> reward: 5.213541666666666, steps:789, time-taken: 0.83min, time-elasped: 4.78min
-> berries picked: 5 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 22 | amount-filled: 6.63%
	| action-stats:  [3, 5, 6, 7, 8] [10, 5, 2, 1, 4]
	| approx positives in sample 512: 24
	| approx action-dist in sample 512: [3, 5, 6, 7] [14, 3, 5, 2]
	Time taken saving stuff: 0.00s

=== episode:4 Env-steps-taken:48000
 	picked: 0 |actions: {0: 22, 1: 22, 2: 25, 3: 167, 4: 30, 5: 83, 6: 23, 7: 17, 8: 33}
episode: 4/2000 -> reward: 0.0, steps:422, time-taken: 0.76min, time-elasped: 5.54min
-> berries picked: 0 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 22 | amount-filled: 7.33%
	| action-stats:  [3, 5, 6, 7, 8] [10, 5, 2, 1, 4]
	| approx positives in sample 512: 25
	| approx action-dist in sample 512: [3, 5, 6, 7, 8] [15, 3, 2, 1, 4]
	Time taken saving stuff: 0.00s

=== episode:5 Env-steps-taken:50016
 	picked: 7 |actions: {0: 51, 1: 44, 2: 44, 3: 243, 4: 32, 5: 211, 6: 38, 7: 42, 8: 45}
episode: 5/2000 -> reward: 10.098958333333336, steps:750, time-taken: 0.86min, time-elasped: 6.40min
-> berries picked: 7 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 29 | amount-filled: 8.58%
	| action-stats:  [2, 3, 5, 6, 7, 8] [1, 12, 9, 2, 1, 4]
	| approx positives in sample 512: 32
	| approx action-dist in sample 512: [3, 5, 6, 7] [17, 10, 2, 3]
	Time taken saving stuff: 0.04s

=== episode:6 Env-steps-taken:49056
 	picked: 3 |actions: {0: 41, 1: 48, 2: 41, 3: 94, 4: 40, 5: 366, 6: 46, 7: 42, 8: 69}
episode: 6/2000 -> reward: 5.328125000000002, steps:787, time-taken: 1.02min, time-elasped: 7.43min
-> berries picked: 3 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 32 | amount-filled: 9.89%
	| action-stats:  [2, 3, 5, 6, 7, 8] [1, 13, 11, 2, 1, 4]
	| approx positives in sample 512: 32
	| approx action-dist in sample 512: [2, 3, 5, 6, 7, 8] [1, 11, 13, 4, 1, 2]
	Time taken saving stuff: 0.08s

=== episode:7 Env-steps-taken:50112
 	picked: 6 |actions: {0: 237, 1: 238, 2: 242, 3: 973, 4: 268, 5: 981, 6: 232, 7: 485, 8: 900}
episode: 7/2000 -> reward: 10.656250000000002, steps:4556, time-taken: 2.66min, time-elasped: 10.10min
-> berries picked: 6 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 38 | amount-filled: 17.49%
	| action-stats:  [2, 3, 5, 6, 7, 8] [2, 14, 15, 2, 1, 4]
	| approx positives in sample 512: 27
	| approx action-dist in sample 512: [3, 5, 6, 7, 8] [6, 13, 4, 1, 3]
	Time taken saving stuff: 0.00s

=== episode:8 Env-steps-taken:49920
 	picked: 9 |actions: {0: 240, 1: 588, 2: 384, 3: 488, 4: 721, 5: 811, 6: 282, 7: 263, 8: 762}
episode: 8/2000 -> reward: 9.098958333333332, steps:4539, time-taken: 2.72min, time-elasped: 12.82min
-> berries picked: 9 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 46 | amount-filled: 25.05%
	| action-stats:  [2, 3, 4, 5, 6, 7, 8] [3, 14, 1, 20, 3, 1, 4]
	| approx positives in sample 512: 34
	| approx action-dist in sample 512: [2, 3, 4, 5, 8] [2, 9, 1, 20, 2]
	Time taken saving stuff: 0.08s

=== episode:9 Env-steps-taken:54816
 	picked: 25 |actions: {0: 548, 1: 307, 2: 198, 3: 339, 4: 185, 5: 395, 6: 599, 7: 200, 8: 427}
episode: 9/2000 -> reward: 34.56770833333334, steps:3198, time-taken: 2.14min, time-elasped: 14.97min
-> berries picked: 25 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 72 | amount-filled: 30.38%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 2, 3, 16, 1, 25, 12, 1, 5]
	| approx positives in sample 512: 31
	| approx action-dist in sample 512: [0, 2, 3, 4, 5, 6, 8] [6, 1, 9, 1, 6, 6, 2]
	Time taken saving stuff: 0.03s

=== episode:10 Env-steps-taken:55200
 	picked: 27 |actions: {0: 908, 1: 378, 2: 441, 3: 575, 4: 314, 5: 1074, 6: 591, 7: 376, 8: 362}
episode: 10/2000 -> reward: 35.95312500000001, steps:5019, time-taken: 3.13min, time-elasped: 18.11min
-> berries picked: 27 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 99 | amount-filled: 38.75%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 2, 3, 24, 2, 29, 18, 3, 6]
	| approx positives in sample 512: 30
	| approx action-dist in sample 512: [0, 1, 3, 5, 6, 7, 8] [3, 1, 6, 9, 6, 2, 3]
	Time taken saving stuff: 0.11s

=== episode:1 Env-steps-taken:50016
 	picked: 6 |actions: {0: 2336, 1: 8, 2: 4, 3: 11, 4: 2074, 5: 72, 6: 40, 7: 0, 8: 2}

==================================================
eval-episode: 10 -> reward: 10.156250000000002, steps: 4547.0, wall-time: 54.11s
-> berries picked: 6 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:11 Env-steps-taken:55392
 	picked: 27 |actions: {0: 722, 1: 293, 2: 294, 3: 652, 4: 748, 5: 398, 6: 702, 7: 823, 8: 404}
episode: 11/2000 -> reward: 36.95312500000001, steps:5036, time-taken: 3.17min, time-elasped: 22.18min
-> berries picked: 27 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 126 | amount-filled: 47.14%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 2, 3, 28, 7, 32, 27, 7, 7]
	| approx positives in sample 512: 38
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 1, 1, 6, 3, 10, 10, 2, 2]
	Time taken saving stuff: 0.01s

=== episode:12 Env-steps-taken:55872
 	picked: 25 |actions: {0: 542, 1: 253, 2: 261, 3: 572, 4: 743, 5: 299, 6: 591, 7: 371, 8: 778}
episode: 12/2000 -> reward: 40.06770833333334, steps:4410, time-taken: 2.90min, time-elasped: 25.09min
-> berries picked: 25 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 152 | amount-filled: 54.49%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 2, 3, 31, 9, 35, 38, 8, 10]
	| approx positives in sample 512: 45
	| approx action-dist in sample 512: [0, 2, 3, 4, 5, 6, 7, 8] [2, 1, 6, 4, 16, 9, 5, 2]
	Time taken saving stuff: 0.08s

=== episode:13 Env-steps-taken:54912
 	picked: 23 |actions: {0: 509, 1: 139, 2: 167, 3: 267, 4: 582, 5: 214, 6: 294, 7: 426, 8: 251}
episode: 13/2000 -> reward: 34.68229166666667, steps:2849, time-taken: 2.11min, time-elasped: 27.20min
-> berries picked: 23 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 175 | amount-filled: 59.24%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 3, 4, 34, 17, 37, 43, 10, 10]
	| approx positives in sample 512: 44
	| approx action-dist in sample 512: [0, 3, 4, 5, 6, 7, 8] [2, 10, 7, 8, 13, 3, 1]
	Time taken saving stuff: 0.11s

=== episode:14 Env-steps-taken:66048
 	picked: 65 |actions: {0: 1043, 1: 340, 2: 361, 3: 536, 4: 1154, 5: 397, 6: 680, 7: 753, 8: 741}
episode: 14/2000 -> reward: 90.27604166666663, steps:6005, time-taken: 3.74min, time-elasped: 30.95min
-> berries picked: 65 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 240 | amount-filled: 69.25%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [24, 5, 9, 40, 37, 41, 59, 12, 13]
	| approx positives in sample 512: 38
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [2, 1, 1, 7, 8, 1, 12, 2, 4]
	Time taken saving stuff: 0.10s

=== episode:15 Env-steps-taken:63840
 	picked: 65 |actions: {0: 774, 1: 366, 2: 339, 3: 713, 4: 867, 5: 508, 6: 498, 7: 573, 8: 642}
episode: 15/2000 -> reward: 78.77604166666666, steps:5280, time-taken: 3.35min, time-elasped: 34.30min
-> berries picked: 65 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 305 | amount-filled: 78.05%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [30, 9, 11, 53, 50, 50, 69, 16, 17]
	| approx positives in sample 512: 46
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 3, 2, 9, 5, 9, 6, 3, 2]
	Time taken saving stuff: 0.10s

=== episode:16 Env-steps-taken:74784
 	picked: 98 |actions: {0: 1210, 1: 416, 2: 523, 3: 573, 4: 829, 5: 530, 6: 761, 7: 748, 8: 654}
episode: 16/2000 -> reward: 132.44270833333323, steps:6244, time-taken: 3.80min, time-elasped: 38.10min
-> berries picked: 98 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 403 | amount-filled: 88.45%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [45, 11, 21, 58, 78, 57, 83, 24, 26]
	| approx positives in sample 512: 39
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 1, 1, 5, 12, 4, 5, 4, 4]
	Time taken saving stuff: 0.10s

=== episode:17 Env-steps-taken:69984
 	picked: 82 |actions: {0: 879, 1: 535, 2: 677, 3: 456, 4: 772, 5: 445, 6: 732, 7: 680, 8: 656}
episode: 17/2000 -> reward: 110.30208333333323, steps:5832, time-taken: 3.75min, time-elasped: 41.86min
-> berries picked: 82 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 486 | amount-filled: 98.17%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [56, 13, 26, 60, 96, 65, 99, 38, 33]
	| approx positives in sample 512: 45
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 1, 2, 5, 7, 6, 13, 4, 3]
	Time taken saving stuff: 0.01s

=== episode:18 Env-steps-taken:64320
 	picked: 61 |actions: {0: 958, 1: 480, 2: 661, 3: 484, 4: 557, 5: 435, 6: 583, 7: 636, 8: 655}
episode: 18/2000 -> reward: 81.50520833333331, steps:5449, time-taken: 3.21min, time-elasped: 45.08min
-> berries picked: 61 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 546 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [68, 16, 32, 62, 108, 69, 111, 46, 34]
	| approx positives in sample 512: 46
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 3, 1, 5, 4, 4, 12, 8, 4]
	Time taken saving stuff: 0.10s

=== episode:19 Env-steps-taken:73536
 	picked: 97 |actions: {0: 940, 1: 544, 2: 682, 3: 457, 4: 871, 5: 400, 6: 796, 7: 860, 8: 491}
episode: 19/2000 -> reward: 127.94270833333314, steps:6041, time-taken: 3.79min, time-elasped: 48.87min
-> berries picked: 97 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 643 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [83, 22, 35, 66, 123, 72, 136, 59, 47]
	| approx positives in sample 512: 54
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 4, 2, 5, 8, 7, 9, 8, 4]
	Time taken saving stuff: 0.08s

=== episode:20 Env-steps-taken:64416
 	picked: 61 |actions: {0: 668, 1: 637, 2: 506, 3: 452, 4: 512, 5: 331, 6: 553, 7: 434, 8: 640}
episode: 20/2000 -> reward: 82.50520833333329, steps:4733, time-taken: 3.00min, time-elasped: 51.88min
-> berries picked: 61 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 704 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [92, 26, 39, 69, 140, 74, 146, 69, 49]
	| approx positives in sample 512: 67
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 1, 3, 7, 14, 10, 15, 6, 7]
	Time taken saving stuff: 0.16s

=== episode:2 Env-steps-taken:59328
 	picked: 44 |actions: {0: 1123, 1: 736, 2: 411, 3: 866, 4: 1214, 5: 7, 6: 161, 7: 106, 8: 770}

==================================================
eval-episode: 20 -> reward: 56.97916666666671, steps: 5394.0, wall-time: 59.40s
-> berries picked: 44 of 800 | patches-visited: [1, 6] | juice left:-0.00
==================================================


=== episode:21 Env-steps-taken:56544
 	picked: 31 |actions: {0: 357, 1: 583, 2: 442, 3: 347, 4: 446, 5: 179, 6: 278, 7: 275, 8: 462}
episode: 21/2000 -> reward: 42.72395833333334, steps:3369, time-taken: 2.37min, time-elasped: 55.24min
-> berries picked: 31 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 735 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [95, 26, 42, 73, 148, 74, 151, 76, 50]
	| approx positives in sample 512: 65
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 7, 3, 4, 12, 4, 12, 10, 4]
	Time taken saving stuff: 0.09s

=== episode:22 Env-steps-taken:65376
 	picked: 63 |actions: {0: 371, 1: 586, 2: 381, 3: 357, 4: 492, 5: 236, 6: 485, 7: 414, 8: 281}
episode: 22/2000 -> reward: 87.89062499999997, steps:3603, time-taken: 2.50min, time-elasped: 57.74min
-> berries picked: 63 of 800 | patches-visited: [0, 2, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 800 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [101, 30, 48, 77, 158, 80, 166, 86, 54]
	| approx positives in sample 512: 58
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 2, 3, 5, 10, 11, 11, 7, 3]
	Time taken saving stuff: 0.05s

=== episode:23 Env-steps-taken:57408
 	picked: 33 |actions: {0: 293, 1: 538, 2: 450, 3: 493, 4: 406, 5: 217, 6: 199, 7: 263, 8: 360}
episode: 23/2000 -> reward: 47.109375000000036, steps:3219, time-taken: 2.18min, time-elasped: 59.92min
-> berries picked: 33 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 832 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [105, 34, 51, 82, 164, 85, 169, 88, 54]
	| approx positives in sample 512: 62
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 2, 4, 8, 14, 6, 9, 7, 3]
	Time taken saving stuff: 0.00s

=== episode:24 Env-steps-taken:65472
 	picked: 75 |actions: {0: 646, 1: 822, 2: 675, 3: 940, 4: 701, 5: 497, 6: 576, 7: 501, 8: 488}
episode: 24/2000 -> reward: 86.70312499999997, steps:5846, time-taken: 3.73min, time-elasped: 63.66min
-> berries picked: 75 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 902 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [113, 37, 61, 86, 184, 90, 178, 95, 58]
	| approx positives in sample 512: 60
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 1, 8, 8, 12, 2, 12, 5, 3]
	Time taken saving stuff: 0.03s

=== episode:25 Env-steps-taken:59520
 	picked: 43 |actions: {0: 359, 1: 680, 2: 421, 3: 542, 4: 465, 5: 270, 6: 336, 7: 274, 8: 324}
episode: 25/2000 -> reward: 57.536458333333385, steps:3671, time-taken: 2.37min, time-elasped: 66.03min
-> berries picked: 43 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 942 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [119, 41, 63, 90, 191, 93, 182, 103, 60]
	| approx positives in sample 512: 74
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 6, 6, 5, 16, 3, 12, 9, 6]
	Time taken saving stuff: 0.00s

=== episode:26 Env-steps-taken:61344
 	picked: 53 |actions: {0: 478, 1: 513, 2: 373, 3: 424, 4: 374, 5: 353, 6: 440, 7: 336, 8: 359}
episode: 26/2000 -> reward: 66.96354166666669, steps:3650, time-taken: 2.46min, time-elasped: 68.50min
-> berries picked: 53 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 993 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [126, 42, 67, 93, 204, 107, 184, 106, 64]
	| approx positives in sample 512: 66
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 3, 1, 3, 20, 11, 9, 8, 4]
	Time taken saving stuff: 0.03s

=== episode:27 Env-steps-taken:70752
 	picked: 75 |actions: {0: 913, 1: 821, 2: 653, 3: 671, 4: 517, 5: 465, 6: 534, 7: 525, 8: 586}
episode: 27/2000 -> reward: 114.7031249999999, steps:5685, time-taken: 3.73min, time-elasped: 72.23min
-> berries picked: 75 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1067 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [143, 49, 74, 96, 213, 117, 194, 113, 68]
	| approx positives in sample 512: 44
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 1, 5, 3, 14, 7, 4, 3, 2]
	Time taken saving stuff: 0.01s

=== episode:28 Env-steps-taken:63264
 	picked: 55 |actions: {0: 591, 1: 589, 2: 553, 3: 506, 4: 461, 5: 407, 6: 506, 7: 288, 8: 449}
episode: 28/2000 -> reward: 76.84895833333333, steps:4350, time-taken: 3.05min, time-elasped: 75.28min
-> berries picked: 55 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1123 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [154, 52, 78, 96, 234, 123, 200, 116, 70]
	| approx positives in sample 512: 57
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 4, 7, 3, 12, 5, 2, 11, 6]
	Time taken saving stuff: 0.01s

=== episode:29 Env-steps-taken:64416
 	picked: 57 |actions: {0: 469, 1: 539, 2: 442, 3: 472, 4: 444, 5: 332, 6: 268, 7: 292, 8: 331}
episode: 29/2000 -> reward: 82.73437499999999, steps:3589, time-taken: 2.41min, time-elasped: 77.70min
-> berries picked: 57 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1179 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [161, 58, 87, 97, 247, 131, 207, 119, 72]
	| approx positives in sample 512: 65
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 7, 3, 5, 19, 6, 7, 8, 5]
	Time taken saving stuff: 0.02s

=== episode:30 Env-steps-taken:74976
 	picked: 92 |actions: {0: 952, 1: 701, 2: 728, 3: 792, 4: 662, 5: 546, 6: 803, 7: 633, 8: 585}
episode: 30/2000 -> reward: 135.7291666666666, steps:6402, time-taken: 4.09min, time-elasped: 81.79min
-> berries picked: 92 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1267 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [173, 60, 93, 102, 266, 145, 222, 128, 78]
	| approx positives in sample 512: 62
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 6, 6, 4, 13, 12, 8, 4, 3]
	Time taken saving stuff: 0.17s

=== episode:3 Env-steps-taken:67104
 	picked: 79 |actions: {0: 505, 1: 351, 2: 285, 3: 1668, 4: 255, 5: 325, 6: 466, 7: 250, 8: 55}

==================================================
eval-episode: 30 -> reward: 94.97395833333323, steps: 4160.0, wall-time: 62.71s
-> berries picked: 79 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:31 Env-steps-taken:66240
 	picked: 62 |actions: {0: 485, 1: 458, 2: 521, 3: 616, 4: 520, 5: 444, 6: 522, 7: 528, 8: 320}
episode: 31/2000 -> reward: 91.9479166666666, steps:4414, time-taken: 2.83min, time-elasped: 85.67min
-> berries picked: 62 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1322 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [184, 60, 97, 103, 277, 153, 231, 135, 82]
	| approx positives in sample 512: 61
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 7, 2, 5, 12, 8, 9, 8, 6]
	Time taken saving stuff: 0.01s

=== episode:32 Env-steps-taken:74880
 	picked: 100 |actions: {0: 776, 1: 611, 2: 656, 3: 737, 4: 743, 5: 678, 6: 780, 7: 779, 8: 568}
episode: 32/2000 -> reward: 134.77083333333323, steps:6328, time-taken: 4.11min, time-elasped: 89.79min
-> berries picked: 100 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1421 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [196, 63, 108, 105, 299, 167, 252, 143, 88]
	| approx positives in sample 512: 72
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 7, 2, 7, 16, 5, 13, 6, 7]
	Time taken saving stuff: 0.01s

=== episode:33 Env-steps-taken:54240
 	picked: 28 |actions: {0: 210, 1: 162, 2: 125, 3: 190, 4: 224, 5: 204, 6: 181, 7: 165, 8: 136}
episode: 33/2000 -> reward: 30.895833333333318, steps:1597, time-taken: 1.47min, time-elasped: 91.26min
-> berries picked: 28 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1447 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [199, 66, 109, 105, 307, 167, 258, 145, 91]
	| approx positives in sample 512: 61
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 1, 7, 5, 13, 3, 11, 5, 4]
	Time taken saving stuff: 0.02s

=== episode:34 Env-steps-taken:59424
 	picked: 43 |actions: {0: 385, 1: 368, 2: 375, 3: 253, 4: 342, 5: 217, 6: 211, 7: 191, 8: 308}
episode: 34/2000 -> reward: 57.53645833333338, steps:2650, time-taken: 2.16min, time-elasped: 93.43min
-> berries picked: 43 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1488 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [209, 70, 112, 109, 316, 168, 262, 148, 94]
	| approx positives in sample 512: 83
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 4, 14, 4, 17, 5, 10, 6, 7]
	Time taken saving stuff: 0.10s

=== episode:35 Env-steps-taken:65088
 	picked: 56 |actions: {0: 581, 1: 476, 2: 616, 3: 752, 4: 504, 5: 533, 6: 479, 7: 479, 8: 602}
episode: 35/2000 -> reward: 84.40624999999997, steps:5022, time-taken: 3.44min, time-elasped: 96.87min
-> berries picked: 56 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1541 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [219, 71, 117, 111, 332, 174, 267, 154, 96]
	| approx positives in sample 512: 73
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 3, 6, 4, 18, 11, 11, 10, 4]
	Time taken saving stuff: 0.03s

=== episode:36 Env-steps-taken:74016
 	picked: 88 |actions: {0: 879, 1: 588, 2: 578, 3: 747, 4: 591, 5: 439, 6: 579, 7: 648, 8: 469}
episode: 36/2000 -> reward: 130.9583333333332, steps:5518, time-taken: 3.60min, time-elasped: 100.47min
-> berries picked: 88 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1619 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [236, 72, 128, 115, 345, 181, 275, 168, 99]
	| approx positives in sample 512: 73
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 4, 3, 6, 17, 2, 13, 6, 7]
	Time taken saving stuff: 0.08s

=== episode:37 Env-steps-taken:67392
 	picked: 80 |actions: {0: 780, 1: 610, 2: 687, 3: 642, 4: 574, 5: 425, 6: 545, 7: 615, 8: 542}
episode: 37/2000 -> reward: 96.91666666666659, steps:5420, time-taken: 3.37min, time-elasped: 103.85min
-> berries picked: 80 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1694 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [246, 81, 133, 120, 360, 193, 280, 176, 105]
	| approx positives in sample 512: 72
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 4, 5, 8, 14, 5, 13, 7, 4]
	Time taken saving stuff: 0.02s

=== episode:38 Env-steps-taken:63552
 	picked: 56 |actions: {0: 555, 1: 528, 2: 467, 3: 847, 4: 531, 5: 515, 6: 363, 7: 506, 8: 462}
episode: 38/2000 -> reward: 77.79166666666667, steps:4774, time-taken: 2.92min, time-elasped: 106.78min
-> berries picked: 56 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1747 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [255, 84, 135, 123, 370, 207, 284, 183, 106]
	| approx positives in sample 512: 80
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 4, 5, 5, 22, 9, 11, 14, 3]
	Time taken saving stuff: 0.02s

=== episode:39 Env-steps-taken:62208
 	picked: 51 |actions: {0: 465, 1: 497, 2: 450, 3: 766, 4: 459, 5: 409, 6: 506, 7: 476, 8: 520}
episode: 39/2000 -> reward: 71.57812500000003, steps:4548, time-taken: 3.10min, time-elasped: 109.88min
-> berries picked: 51 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1796 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [264, 89, 139, 125, 383, 214, 289, 186, 107]
	| approx positives in sample 512: 93
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 8, 8, 6, 14, 4, 16, 11, 10]
	Time taken saving stuff: 0.01s

=== episode:40 Env-steps-taken:66720
 	picked: 74 |actions: {0: 650, 1: 871, 2: 659, 3: 700, 4: 519, 5: 540, 6: 497, 7: 493, 8: 438}
episode: 40/2000 -> reward: 93.76041666666659, steps:5367, time-taken: 3.48min, time-elasped: 113.36min
-> berries picked: 74 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1866 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [275, 94, 145, 130, 401, 223, 298, 190, 110]
	| approx positives in sample 512: 76
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 4, 2, 3, 14, 10, 12, 10, 5]
	Time taken saving stuff: 0.16s

=== episode:4 Env-steps-taken:60576
 	picked: 42 |actions: {0: 165, 1: 323, 2: 171, 3: 4279, 4: 169, 5: 125, 6: 112, 7: 111, 8: 52}

==================================================
eval-episode: 40 -> reward: 63.09375000000005, steps: 5507.0, wall-time: 45.54s
-> berries picked: 42 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:41 Env-steps-taken:51456
 	picked: 12 |actions: {0: 86, 1: 163, 2: 144, 3: 146, 4: 115, 5: 92, 6: 56, 7: 59, 8: 84}
episode: 41/2000 -> reward: 17.312500000000004, steps:945, time-taken: 1.15min, time-elasped: 115.28min
-> berries picked: 12 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1875 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [275, 94, 147, 132, 407, 223, 298, 190, 109]
	| approx positives in sample 512: 74
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 6, 7, 3, 7, 12, 16, 5, 12]
	Time taken saving stuff: 0.18s

=== episode:42 Env-steps-taken:66528
 	picked: 69 |actions: {0: 597, 1: 625, 2: 466, 3: 628, 4: 389, 5: 366, 6: 526, 7: 598, 8: 577}
episode: 42/2000 -> reward: 93.04687499999996, steps:4772, time-taken: 3.15min, time-elasped: 118.44min
-> berries picked: 69 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1938 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [286, 101, 151, 137, 414, 230, 307, 198, 114]
	| approx positives in sample 512: 71
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 7, 2, 4, 10, 2, 13, 10, 7]
	Time taken saving stuff: 0.10s

=== episode:43 Env-steps-taken:65760
 	picked: 68 |actions: {0: 626, 1: 824, 2: 577, 3: 526, 4: 492, 5: 430, 6: 409, 7: 493, 8: 567}
episode: 43/2000 -> reward: 89.10416666666663, steps:4944, time-taken: 3.24min, time-elasped: 121.69min
-> berries picked: 68 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2001 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [294, 108, 156, 140, 432, 235, 314, 203, 119]
	| approx positives in sample 512: 82
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 7, 9, 6, 15, 5, 19, 6, 2]
	Time taken saving stuff: 0.02s

=== episode:44 Env-steps-taken:69408
 	picked: 74 |actions: {0: 697, 1: 509, 2: 646, 3: 718, 4: 602, 5: 510, 6: 544, 7: 593, 8: 599}
episode: 44/2000 -> reward: 106.31770833333326, steps:5418, time-taken: 3.56min, time-elasped: 125.25min
-> berries picked: 74 of 800 | patches-visited: [0, 7, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2072 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [308, 111, 163, 142, 454, 241, 320, 210, 123]
	| approx positives in sample 512: 87
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 7, 7, 9, 15, 9, 17, 10, 4]
	Time taken saving stuff: 0.09s

=== episode:45 Env-steps-taken:67008
 	picked: 76 |actions: {0: 587, 1: 623, 2: 647, 3: 1093, 4: 563, 5: 606, 6: 463, 7: 636, 8: 658}
episode: 45/2000 -> reward: 93.26041666666661, steps:5876, time-taken: 3.56min, time-elasped: 128.82min
-> berries picked: 76 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2140 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [323, 117, 168, 144, 469, 256, 322, 217, 124]
	| approx positives in sample 512: 87
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 8, 4, 5, 15, 11, 11, 10, 8]
	Time taken saving stuff: 0.01s

=== episode:46 Env-steps-taken:53760
 	picked: 20 |actions: {0: 196, 1: 164, 2: 203, 3: 87, 4: 106, 5: 117, 6: 124, 7: 179, 8: 90}
episode: 46/2000 -> reward: 28.854166666666657, steps:1266, time-taken: 1.20min, time-elasped: 130.02min
-> berries picked: 20 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2159 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [328, 118, 170, 146, 470, 259, 325, 218, 125]
	| approx positives in sample 512: 91
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 4, 7, 5, 20, 8, 15, 11, 6]
	Time taken saving stuff: 0.10s

=== episode:47 Env-steps-taken:69120
 	picked: 71 |actions: {0: 607, 1: 578, 2: 650, 3: 571, 4: 516, 5: 443, 6: 485, 7: 626, 8: 623}
episode: 47/2000 -> reward: 106.93229166666656, steps:5099, time-taken: 3.42min, time-elasped: 133.45min
-> berries picked: 71 of 800 | patches-visited: [0, 3, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2226 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [344, 121, 169, 150, 485, 272, 332, 222, 131]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 1, 10, 5, 22, 13, 14, 13, 6]
	Time taken saving stuff: 0.03s

=== episode:48 Env-steps-taken:62304
 	picked: 52 |actions: {0: 680, 1: 468, 2: 657, 3: 656, 4: 384, 5: 416, 6: 469, 7: 693, 8: 539}
episode: 48/2000 -> reward: 72.02083333333336, steps:4962, time-taken: 3.10min, time-elasped: 136.55min
-> berries picked: 52 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2275 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [360, 125, 173, 152, 489, 277, 336, 230, 133]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [23, 12, 8, 7, 18, 15, 13, 10, 6]
	Time taken saving stuff: 0.00s

=== episode:49 Env-steps-taken:56736
 	picked: 28 |actions: {0: 206, 1: 176, 2: 165, 3: 210, 4: 215, 5: 257, 6: 186, 7: 245, 8: 243}
episode: 49/2000 -> reward: 42.45312500000001, steps:1903, time-taken: 1.85min, time-elasped: 138.40min
-> berries picked: 28 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2303 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [365, 125, 175, 154, 494, 280, 342, 233, 135]
	| approx positives in sample 512: 91
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 7, 8, 4, 20, 9, 14, 9, 4]
	Time taken saving stuff: 0.04s

=== episode:50 Env-steps-taken:65952
 	picked: 57 |actions: {0: 375, 1: 385, 2: 430, 3: 619, 4: 398, 5: 376, 6: 294, 7: 460, 8: 476}
episode: 50/2000 -> reward: 91.23437499999997, steps:3813, time-taken: 2.86min, time-elasped: 141.27min
-> berries picked: 57 of 800 | patches-visited: [0, 2, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2360 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [370, 130, 179, 160, 507, 287, 349, 240, 138]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 9, 11, 5, 15, 10, 16, 15, 6]
	Time taken saving stuff: 0.07s

=== episode:5 Env-steps-taken:68544
 	picked: 73 |actions: {0: 297, 1: 408, 2: 309, 3: 314, 4: 199, 5: 208, 6: 231, 7: 438, 8: 154}

==================================================
eval-episode: 50 -> reward: 103.31770833333326, steps: 2558.0, wall-time: 68.35s
-> berries picked: 73 of 800 | patches-visited: [1, 6] | juice left:-0.00
==================================================


=== episode:51 Env-steps-taken:52032
 	picked: 20 |actions: {0: 194, 1: 235, 2: 201, 3: 171, 4: 144, 5: 163, 6: 144, 7: 285, 8: 166}
episode: 51/2000 -> reward: 20.354166666666668, steps:1703, time-taken: 1.36min, time-elasped: 143.78min
-> berries picked: 20 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2380 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [374, 131, 180, 164, 511, 288, 351, 242, 139]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [26, 6, 6, 7, 20, 11, 20, 14, 4]
	Time taken saving stuff: 0.01s

=== episode:52 Env-steps-taken:63168
 	picked: 54 |actions: {0: 391, 1: 366, 2: 379, 3: 485, 4: 394, 5: 454, 6: 301, 7: 560, 8: 435}
episode: 52/2000 -> reward: 76.40625, steps:3765, time-taken: 2.54min, time-elasped: 146.32min
-> berries picked: 54 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2434 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [382, 134, 184, 169, 524, 297, 357, 247, 140]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 6, 12, 6, 14, 13, 16, 18, 7]
	Time taken saving stuff: 0.02s

=== episode:53 Env-steps-taken:67200
 	picked: 66 |actions: {0: 557, 1: 495, 2: 475, 3: 584, 4: 495, 5: 350, 6: 359, 7: 414, 8: 332}
episode: 53/2000 -> reward: 94.77604166666663, steps:4061, time-taken: 2.81min, time-elasped: 149.13min
-> berries picked: 66 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2498 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [394, 142, 187, 180, 537, 302, 364, 249, 143]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [24, 7, 5, 9, 24, 6, 15, 15, 1]
	Time taken saving stuff: 0.01s

=== episode:54 Env-steps-taken:59616
 	picked: 44 |actions: {0: 279, 1: 294, 2: 362, 3: 332, 4: 325, 5: 378, 6: 279, 7: 441, 8: 240}
episode: 54/2000 -> reward: 57.97916666666671, steps:2930, time-taken: 1.83min, time-elasped: 150.97min
-> berries picked: 44 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2541 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [401, 146, 190, 181, 541, 309, 373, 254, 146]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 3, 13, 10, 20, 14, 15, 15, 8]
	Time taken saving stuff: 0.01s

=== episode:55 Env-steps-taken:65184
 	picked: 60 |actions: {0: 494, 1: 462, 2: 367, 3: 721, 4: 508, 5: 454, 6: 387, 7: 787, 8: 328}
episode: 55/2000 -> reward: 84.61979166666664, steps:4508, time-taken: 3.02min, time-elasped: 153.99min
-> berries picked: 60 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2598 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [411, 148, 193, 190, 547, 316, 380, 266, 147]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [25, 6, 7, 13, 23, 12, 15, 16, 9]
	Time taken saving stuff: 0.10s

=== episode:56 Env-steps-taken:60960
 	picked: 49 |actions: {0: 373, 1: 533, 2: 403, 3: 376, 4: 304, 5: 382, 6: 398, 7: 564, 8: 336}
episode: 56/2000 -> reward: 65.19270833333337, steps:3669, time-taken: 2.37min, time-elasped: 156.37min
-> berries picked: 49 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2642 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [423, 151, 197, 192, 547, 320, 393, 269, 150]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [23, 7, 13, 6, 25, 15, 18, 9, 8]
	Time taken saving stuff: 0.03s

=== episode:57 Env-steps-taken:63072
 	picked: 54 |actions: {0: 339, 1: 385, 2: 510, 3: 670, 4: 442, 5: 382, 6: 375, 7: 625, 8: 357}
episode: 57/2000 -> reward: 74.52083333333334, steps:4085, time-taken: 2.65min, time-elasped: 159.02min
-> berries picked: 54 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2696 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [434, 153, 204, 195, 559, 329, 399, 271, 152]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [28, 8, 8, 12, 17, 7, 17, 3, 2]
	Time taken saving stuff: 0.01s

=== episode:58 Env-steps-taken:58656
 	picked: 40 |actions: {0: 254, 1: 327, 2: 374, 3: 327, 4: 286, 5: 386, 6: 264, 7: 445, 8: 274}
episode: 58/2000 -> reward: 53.20833333333338, steps:2937, time-taken: 2.05min, time-elasped: 161.07min
-> berries picked: 40 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2729 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [440, 155, 206, 198, 562, 336, 403, 275, 154]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [29, 14, 9, 4, 21, 13, 20, 18, 2]
	Time taken saving stuff: 0.01s

=== episode:59 Env-steps-taken:68832
 	picked: 71 |actions: {0: 498, 1: 606, 2: 702, 3: 665, 4: 475, 5: 470, 6: 410, 7: 536, 8: 333}
episode: 59/2000 -> reward: 104.93229166666659, steps:4695, time-taken: 3.06min, time-elasped: 164.14min
-> berries picked: 71 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2797 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [455, 161, 209, 207, 570, 347, 406, 283, 159]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 10, 15, 4, 26, 15, 22, 14, 3]
	Time taken saving stuff: 0.03s

=== episode:60 Env-steps-taken:64032
 	picked: 62 |actions: {0: 472, 1: 508, 2: 664, 3: 794, 4: 575, 5: 670, 6: 506, 7: 696, 8: 479}
episode: 60/2000 -> reward: 79.06249999999997, steps:5364, time-taken: 3.61min, time-elasped: 167.75min
-> berries picked: 62 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2858 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [460, 168, 211, 214, 583, 357, 418, 285, 162]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [24, 11, 13, 8, 18, 20, 25, 20, 9]
	Time taken saving stuff: 0.05s

=== episode:6 Env-steps-taken:55392
 	picked: 29 |actions: {0: 162, 1: 160, 2: 165, 3: 80, 4: 70, 5: 88, 6: 154, 7: 295, 8: 93}

==================================================
eval-episode: 60 -> reward: 37.33854166666667, steps: 1267.0, wall-time: 52.76s
-> berries picked: 29 of 800 | patches-visited: [1, 3] | juice left:-0.00
==================================================


=== episode:61 Env-steps-taken:62976
 	picked: 54 |actions: {0: 453, 1: 463, 2: 527, 3: 854, 4: 565, 5: 536, 6: 384, 7: 778, 8: 558}
episode: 61/2000 -> reward: 75.40625000000003, steps:5118, time-taken: 3.25min, time-elasped: 171.89min
-> berries picked: 54 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2910 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [468, 173, 215, 222, 593, 361, 423, 290, 165]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [29, 13, 14, 10, 19, 14, 20, 11, 6]
	Time taken saving stuff: 0.04s

=== episode:62 Env-steps-taken:50688
 	picked: 8 |actions: {0: 67, 1: 114, 2: 94, 3: 82, 4: 36, 5: 32, 6: 63, 7: 58, 8: 81}
episode: 62/2000 -> reward: 13.541666666666668, steps:627, time-taken: 0.79min, time-elasped: 172.68min
-> berries picked: 8 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2917 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [469, 175, 216, 222, 594, 361, 423, 292, 165]
	| approx positives in sample 512: 145
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [28, 12, 11, 8, 25, 17, 17, 17, 10]
	Time taken saving stuff: 0.03s

=== episode:63 Env-steps-taken:59040
 	picked: 39 |actions: {0: 871, 1: 498, 2: 677, 3: 552, 4: 884, 5: 405, 6: 384, 7: 661, 8: 436}
episode: 63/2000 -> reward: 55.265625000000036, steps:5368, time-taken: 3.39min, time-elasped: 176.08min
-> berries picked: 39 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2952 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [472, 179, 219, 228, 601, 366, 426, 294, 167]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [31, 10, 13, 10, 22, 14, 15, 16, 10]
	Time taken saving stuff: 0.07s

=== episode:64 Env-steps-taken:63936
 	picked: 60 |actions: {0: 475, 1: 626, 2: 707, 3: 677, 4: 572, 5: 479, 6: 502, 7: 711, 8: 480}
episode: 64/2000 -> reward: 79.56250000000001, steps:5229, time-taken: 3.26min, time-elasped: 179.35min
-> berries picked: 60 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3008 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [480, 183, 225, 234, 605, 376, 433, 303, 169]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [25, 14, 12, 11, 27, 12, 23, 16, 8]
	Time taken saving stuff: 0.09s

=== episode:65 Env-steps-taken:63456
 	picked: 57 |actions: {0: 452, 1: 418, 2: 498, 3: 414, 4: 487, 5: 372, 6: 334, 7: 514, 8: 258}
episode: 65/2000 -> reward: 77.734375, steps:3747, time-taken: 2.55min, time-elasped: 181.91min
-> berries picked: 57 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3061 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [486, 188, 228, 239, 614, 383, 440, 313, 170]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [30, 9, 10, 10, 16, 11, 17, 20, 11]
	Time taken saving stuff: 0.03s

=== episode:66 Env-steps-taken:71328
 	picked: 83 |actions: {0: 515, 1: 588, 2: 534, 3: 612, 4: 615, 5: 661, 6: 535, 7: 532, 8: 588}
episode: 66/2000 -> reward: 117.2447916666665, steps:5180, time-taken: 3.25min, time-elasped: 185.16min
-> berries picked: 83 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3131 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [494, 197, 229, 249, 624, 397, 450, 318, 173]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 15, 11, 12, 15, 16, 14, 21, 4]
	Time taken saving stuff: 0.03s

=== episode:67 Env-steps-taken:68160
 	picked: 74 |actions: {0: 550, 1: 764, 2: 562, 3: 616, 4: 539, 5: 631, 6: 512, 7: 647, 8: 538}
episode: 67/2000 -> reward: 101.2604166666666, steps:5359, time-taken: 3.40min, time-elasped: 188.56min
-> berries picked: 74 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3201 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [501, 202, 232, 261, 635, 410, 457, 328, 175]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [23, 14, 8, 7, 21, 12, 22, 19, 7]
	Time taken saving stuff: 0.04s

=== episode:68 Env-steps-taken:65088
 	picked: 61 |actions: {0: 400, 1: 521, 2: 320, 3: 388, 4: 438, 5: 428, 6: 372, 7: 605, 8: 285}
episode: 68/2000 -> reward: 86.06249999999997, steps:3757, time-taken: 2.71min, time-elasped: 191.28min
-> berries picked: 61 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3258 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [509, 208, 234, 265, 648, 420, 462, 334, 178]
	| approx positives in sample 512: 146
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [32, 9, 12, 11, 19, 9, 25, 18, 11]
	Time taken saving stuff: 0.08s

=== episode:69 Env-steps-taken:70368
 	picked: 80 |actions: {0: 661, 1: 657, 2: 573, 3: 604, 4: 549, 5: 494, 6: 547, 7: 860, 8: 690}
episode: 69/2000 -> reward: 111.5312499999999, steps:5635, time-taken: 3.39min, time-elasped: 194.68min
-> berries picked: 80 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3328 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [520, 212, 239, 274, 659, 433, 474, 337, 180]
	| approx positives in sample 512: 156
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [34, 12, 13, 17, 20, 19, 17, 18, 6]
	Time taken saving stuff: 0.03s

=== episode:70 Env-steps-taken:59232
 	picked: 40 |actions: {0: 338, 1: 401, 2: 413, 3: 302, 4: 306, 5: 278, 6: 308, 7: 449, 8: 395}
episode: 70/2000 -> reward: 56.708333333333385, steps:3190, time-taken: 2.21min, time-elasped: 196.89min
-> berries picked: 40 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3367 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [526, 215, 243, 278, 664, 439, 478, 343, 181]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [29, 15, 10, 9, 14, 13, 19, 10, 12]
	Time taken saving stuff: 0.16s

=== episode:7 Env-steps-taken:56448
 	picked: 30 |actions: {0: 62, 1: 292, 2: 16, 3: 176, 4: 45, 5: 57, 6: 100, 7: 128, 8: 88}

==================================================
eval-episode: 70 -> reward: 42.281250000000014, steps: 964.0, wall-time: 40.03s
-> berries picked: 30 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:71 Env-steps-taken:62016
 	picked: 51 |actions: {0: 387, 1: 312, 2: 463, 3: 643, 4: 610, 5: 456, 6: 318, 7: 391, 8: 494}
episode: 71/2000 -> reward: 70.07812500000001, steps:4074, time-taken: 2.71min, time-elasped: 200.27min
-> berries picked: 51 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3400 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [533, 220, 245, 291, 666, 442, 477, 345, 181]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [32, 11, 10, 10, 22, 10, 20, 18, 11]
	Time taken saving stuff: 0.01s

=== episode:72 Env-steps-taken:64032
 	picked: 57 |actions: {0: 412, 1: 390, 2: 528, 3: 515, 4: 718, 5: 548, 6: 453, 7: 541, 8: 555}
episode: 72/2000 -> reward: 80.23437499999997, steps:4660, time-taken: 2.81min, time-elasped: 203.08min
-> berries picked: 57 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3450 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [539, 223, 249, 298, 670, 451, 486, 352, 182]
	| approx positives in sample 512: 161
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [43, 10, 7, 7, 13, 17, 26, 32, 6]
	Time taken saving stuff: 0.01s

=== episode:73 Env-steps-taken:61536
 	picked: 51 |actions: {0: 368, 1: 387, 2: 415, 3: 557, 4: 344, 5: 361, 6: 314, 7: 382, 8: 300}
episode: 73/2000 -> reward: 66.63541666666671, steps:3428, time-taken: 2.30min, time-elasped: 205.38min
-> berries picked: 51 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3492 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [543, 226, 253, 310, 675, 459, 485, 357, 184]
	| approx positives in sample 512: 147
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [27, 14, 14, 11, 18, 16, 21, 14, 12]
	Time taken saving stuff: 0.01s

=== episode:74 Env-steps-taken:74304
 	picked: 90 |actions: {0: 688, 1: 615, 2: 752, 3: 640, 4: 762, 5: 524, 6: 486, 7: 662, 8: 523}
episode: 74/2000 -> reward: 132.3437499999999, steps:5652, time-taken: 45.44min, time-elasped: 250.83min
-> berries picked: 90 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3569 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [552, 233, 257, 320, 683, 472, 494, 371, 187]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [29, 12, 14, 14, 19, 7, 19, 14, 5]
	Time taken saving stuff: 0.02s

=== episode:75 Env-steps-taken:67776
 	picked: 73 |actions: {0: 590, 1: 787, 2: 759, 3: 466, 4: 585, 5: 425, 6: 461, 7: 558, 8: 625}
episode: 75/2000 -> reward: 98.81770833333324, steps:5256, time-taken: 2.10min, time-elasped: 252.93min
-> berries picked: 73 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3631 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [560, 243, 264, 326, 692, 479, 501, 378, 188]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [32, 14, 9, 11, 20, 9, 16, 19, 7]
	Time taken saving stuff: 0.00s

=== episode:76 Env-steps-taken:66432
 	picked: 65 |actions: {0: 557, 1: 689, 2: 583, 3: 554, 4: 601, 5: 509, 6: 509, 7: 650, 8: 576}
episode: 76/2000 -> reward: 92.77604166666663, steps:5228, time-taken: 2.63min, time-elasped: 255.57min
-> berries picked: 65 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3682 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [563, 250, 270, 329, 695, 482, 514, 388, 191]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [29, 16, 16, 17, 19, 17, 16, 11, 3]
	Time taken saving stuff: 0.00s

=== episode:77 Env-steps-taken:74208
 	picked: 96 |actions: {0: 844, 1: 815, 2: 691, 3: 589, 4: 589, 5: 553, 6: 688, 7: 737, 8: 782}
episode: 77/2000 -> reward: 130.61458333333317, steps:6288, time-taken: 3.71min, time-elasped: 259.28min
-> berries picked: 96 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3763 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [580, 259, 275, 337, 705, 490, 528, 395, 194]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [33, 10, 12, 12, 16, 15, 15, 16, 9]
	Time taken saving stuff: 0.01s

=== episode:78 Env-steps-taken:61344
 	picked: 49 |actions: {0: 483, 1: 347, 2: 269, 3: 257, 4: 325, 5: 264, 6: 271, 7: 358, 8: 284}
episode: 78/2000 -> reward: 66.69270833333337, steps:2858, time-taken: 2.20min, time-elasped: 261.48min
-> berries picked: 49 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3798 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [589, 265, 278, 337, 706, 496, 532, 401, 194]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [26, 16, 20, 12, 17, 9, 15, 15, 7]
	Time taken saving stuff: 0.08s

=== episode:79 Env-steps-taken:76128
 	picked: 105 |actions: {0: 649, 1: 879, 2: 722, 3: 636, 4: 667, 5: 562, 6: 609, 7: 727, 8: 534}
episode: 79/2000 -> reward: 139.09895833333323, steps:5985, time-taken: 4.07min, time-elasped: 265.56min
-> berries picked: 105 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3888 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [603, 271, 280, 356, 712, 515, 541, 413, 197]
	| approx positives in sample 512: 152
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [32, 15, 13, 14, 19, 11, 22, 18, 8]
	Time taken saving stuff: 0.09s

=== episode:80 Env-steps-taken:61056
 	picked: 42 |actions: {0: 334, 1: 271, 2: 230, 3: 232, 4: 322, 5: 319, 6: 232, 7: 352, 8: 191}
episode: 80/2000 -> reward: 65.59375000000004, steps:2483, time-taken: 1.95min, time-elasped: 267.51min
-> berries picked: 42 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3923 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [606, 274, 281, 363, 720, 517, 545, 420, 197]
	| approx positives in sample 512: 143
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [40, 12, 15, 15, 16, 8, 12, 14, 11]
	Time taken saving stuff: 0.15s

=== episode:8 Env-steps-taken:66624
 	picked: 69 |actions: {0: 1468, 1: 399, 2: 153, 3: 154, 4: 1300, 5: 214, 6: 152, 7: 328, 8: 287}

==================================================
eval-episode: 80 -> reward: 93.54687499999996, steps: 4455.0, wall-time: 67.27s
-> berries picked: 69 of 800 | patches-visited: [1, 5] | juice left:-0.00
==================================================


=== episode:81 Env-steps-taken:59136
 	picked: 44 |actions: {0: 795, 1: 428, 2: 429, 3: 474, 4: 422, 5: 338, 6: 376, 7: 395, 8: 681}
episode: 81/2000 -> reward: 55.97916666666669, steps:4338, time-taken: 2.84min, time-elasped: 271.48min
-> berries picked: 44 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3955 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [611, 281, 285, 370, 723, 518, 548, 421, 198]
	| approx positives in sample 512: 157
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [34, 22, 10, 13, 15, 15, 19, 19, 10]
	Time taken saving stuff: 0.09s

=== episode:82 Env-steps-taken:64608
 	picked: 60 |actions: {0: 578, 1: 550, 2: 354, 3: 427, 4: 483, 5: 349, 6: 344, 7: 461, 8: 361}
episode: 82/2000 -> reward: 83.06249999999997, steps:3907, time-taken: 2.64min, time-elasped: 274.13min
-> berries picked: 60 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4006 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [618, 291, 287, 375, 733, 526, 552, 424, 200]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [25, 14, 10, 9, 22, 16, 21, 14, 4]
	Time taken saving stuff: 0.02s

=== episode:83 Env-steps-taken:69312
 	picked: 73 |actions: {0: 633, 1: 534, 2: 562, 3: 585, 4: 480, 5: 446, 6: 595, 7: 547, 8: 717}
episode: 83/2000 -> reward: 107.81770833333323, steps:5099, time-taken: 3.21min, time-elasped: 277.33min
-> berries picked: 73 of 800 | patches-visited: [0, 5, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4068 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [631, 300, 296, 385, 734, 532, 557, 429, 204]
	| approx positives in sample 512: 154
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [30, 17, 10, 23, 18, 15, 20, 16, 5]
	Time taken saving stuff: 0.03s

=== episode:84 Env-steps-taken:69024
 	picked: 76 |actions: {0: 723, 1: 869, 2: 655, 3: 486, 4: 598, 5: 434, 6: 457, 7: 603, 8: 672}
episode: 84/2000 -> reward: 105.64583333333323, steps:5497, time-taken: 3.23min, time-elasped: 280.57min
-> berries picked: 76 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4128 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [646, 306, 300, 394, 735, 547, 559, 435, 206]
	| approx positives in sample 512: 171
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [45, 14, 18, 8, 21, 12, 25, 17, 11]
	Time taken saving stuff: 0.09s

=== episode:85 Env-steps-taken:64032
 	picked: 54 |actions: {0: 637, 1: 477, 2: 264, 3: 269, 4: 514, 5: 416, 6: 376, 7: 526, 8: 686}
episode: 85/2000 -> reward: 81.46354166666666, steps:4165, time-taken: 2.80min, time-elasped: 283.38min
-> berries picked: 54 of 800 | patches-visited: [0, 7, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4174 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [658, 309, 303, 395, 738, 551, 567, 439, 214]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [27, 22, 11, 12, 17, 11, 13, 22, 9]
	Time taken saving stuff: 0.02s

=== episode:86 Env-steps-taken:67296
 	picked: 65 |actions: {0: 565, 1: 586, 2: 557, 3: 442, 4: 553, 5: 398, 6: 461, 7: 652, 8: 654}
episode: 86/2000 -> reward: 95.83333333333329, steps:4868, time-taken: 3.02min, time-elasped: 286.40min
-> berries picked: 65 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4228 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [666, 312, 311, 405, 744, 553, 576, 444, 217]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [43, 13, 9, 13, 16, 15, 15, 17, 7]
	Time taken saving stuff: 0.08s

=== episode:87 Env-steps-taken:68352
 	picked: 68 |actions: {0: 622, 1: 434, 2: 476, 3: 518, 4: 517, 5: 439, 6: 319, 7: 596, 8: 655}
episode: 87/2000 -> reward: 102.60416666666661, steps:4576, time-taken: 2.89min, time-elasped: 289.31min
-> berries picked: 68 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4284 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [674, 317, 315, 414, 743, 558, 584, 458, 221]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [25, 11, 12, 7, 9, 16, 15, 26, 14]
	Time taken saving stuff: 0.06s

=== episode:88 Env-steps-taken:56064
 	picked: 27 |actions: {0: 221, 1: 269, 2: 180, 3: 129, 4: 138, 5: 118, 6: 132, 7: 162, 8: 231}
episode: 88/2000 -> reward: 40.06770833333335, steps:1580, time-taken: 1.30min, time-elasped: 290.60min
-> berries picked: 27 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4306 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [679, 320, 319, 414, 744, 559, 589, 460, 222]
	| approx positives in sample 512: 159
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [36, 13, 17, 12, 9, 19, 24, 23, 6]
	Time taken saving stuff: 0.01s

=== episode:89 Env-steps-taken:73344
 	picked: 92 |actions: {0: 815, 1: 661, 2: 604, 3: 542, 4: 709, 5: 572, 6: 561, 7: 725, 8: 757}
episode: 89/2000 -> reward: 127.2291666666665, steps:5946, time-taken: 3.82min, time-elasped: 294.42min
-> berries picked: 92 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4378 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [695, 328, 321, 422, 753, 557, 604, 474, 224]
	| approx positives in sample 512: 163
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [25, 20, 13, 20, 15, 10, 22, 29, 9]
	Time taken saving stuff: 0.10s

=== episode:90 Env-steps-taken:63936
 	picked: 57 |actions: {0: 392, 1: 332, 2: 347, 3: 350, 4: 476, 5: 318, 6: 277, 7: 404, 8: 672}
episode: 90/2000 -> reward: 78.40624999999999, steps:3568, time-taken: 2.45min, time-elasped: 296.88min
-> berries picked: 57 of 800 | patches-visited: [0, 1, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4422 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [701, 333, 322, 427, 759, 564, 609, 481, 226]
	| approx positives in sample 512: 152
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [29, 20, 14, 13, 12, 11, 24, 19, 10]
	Time taken saving stuff: 0.09s

=== episode:9 Env-steps-taken:83136
 	picked: 128 |actions: {0: 1399, 1: 334, 2: 443, 3: 655, 4: 1293, 5: 448, 6: 231, 7: 604, 8: 973}

==================================================
eval-episode: 90 -> reward: 176.66666666666688, steps: 6380.0, wall-time: 70.11s
-> berries picked: 128 of 800 | patches-visited: [1, 6, 8] | juice left:-0.00
==================================================


=== episode:91 Env-steps-taken:69408
 	picked: 76 |actions: {0: 691, 1: 815, 2: 617, 3: 583, 4: 527, 5: 447, 6: 436, 7: 619, 8: 974}
episode: 91/2000 -> reward: 107.64583333333323, steps:5709, time-taken: 3.52min, time-elasped: 301.58min
-> berries picked: 76 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4479 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [711, 342, 325, 437, 769, 564, 615, 487, 229]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [27, 13, 16, 12, 9, 16, 17, 23, 11]
	Time taken saving stuff: 0.02s

=== episode:92 Env-steps-taken:62496
 	picked: 47 |actions: {0: 290, 1: 346, 2: 393, 3: 411, 4: 270, 5: 227, 6: 213, 7: 274, 8: 376}
episode: 92/2000 -> reward: 73.80729166666667, steps:2800, time-taken: 2.00min, time-elasped: 303.58min
-> berries picked: 47 of 800 | patches-visited: [0, 2, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4519 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [720, 346, 334, 448, 770, 566, 617, 488, 230]
	| approx positives in sample 512: 161
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [40, 15, 15, 15, 20, 16, 15, 18, 7]
	Time taken saving stuff: 0.10s

=== episode:93 Env-steps-taken:74976
 	picked: 97 |actions: {0: 779, 1: 633, 2: 635, 3: 647, 4: 722, 5: 641, 6: 548, 7: 789, 8: 669}
episode: 93/2000 -> reward: 135.44270833333323, steps:6063, time-taken: 3.67min, time-elasped: 307.25min
-> berries picked: 97 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4594 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [743, 349, 341, 459, 768, 579, 621, 498, 236]
	| approx positives in sample 512: 156
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [37, 25, 17, 7, 13, 13, 18, 16, 10]
	Time taken saving stuff: 0.11s

=== episode:94 Env-steps-taken:65088
 	picked: 60 |actions: {0: 394, 1: 278, 2: 430, 3: 526, 4: 482, 5: 381, 6: 326, 7: 373, 8: 623}
episode: 94/2000 -> reward: 86.06249999999997, steps:3813, time-taken: 2.45min, time-elasped: 309.70min
-> berries picked: 60 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4636 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [751, 354, 347, 465, 767, 583, 627, 503, 239]
	| approx positives in sample 512: 153
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [33, 19, 21, 18, 20, 10, 12, 15, 5]
	Time taken saving stuff: 0.01s

=== episode:95 Env-steps-taken:84000
 	picked: 118 |actions: {0: 1018, 1: 746, 2: 726, 3: 680, 4: 821, 5: 675, 6: 606, 7: 812, 8: 1015}
episode: 95/2000 -> reward: 181.73958333333354, steps:7099, time-taken: 4.24min, time-elasped: 313.94min
-> berries picked: 118 of 800 | patches-visited: [0, 1, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4734 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [774, 364, 354, 472, 775, 594, 641, 517, 243]
	| approx positives in sample 512: 154
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [37, 16, 21, 8, 8, 15, 15, 22, 12]
	Time taken saving stuff: 0.08s

=== episode:96 Env-steps-taken:67104
 	picked: 66 |actions: {0: 464, 1: 574, 2: 294, 3: 386, 4: 345, 5: 416, 6: 321, 7: 334, 8: 549}
episode: 96/2000 -> reward: 96.71874999999993, steps:3683, time-taken: 2.49min, time-elasped: 316.44min
-> berries picked: 66 of 800 | patches-visited: [0, 6, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4789 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [784, 373, 356, 476, 778, 606, 647, 517, 252]
	| approx positives in sample 512: 146
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [24, 24, 15, 11, 11, 16, 15, 21, 9]
	Time taken saving stuff: 0.10s

=== episode:97 Env-steps-taken:68640
 	picked: 71 |actions: {0: 549, 1: 454, 2: 412, 3: 485, 4: 646, 5: 596, 6: 470, 7: 626, 8: 885}
episode: 97/2000 -> reward: 104.4322916666666, steps:5123, time-taken: 3.09min, time-elasped: 319.54min
-> berries picked: 71 of 800 | patches-visited: [0, 7, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4843 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [793, 382, 357, 485, 782, 615, 652, 524, 253]
	| approx positives in sample 512: 164
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [34, 25, 19, 12, 14, 11, 23, 18, 8]
	Time taken saving stuff: 0.00s

=== episode:98 Env-steps-taken:57504
 	picked: 39 |actions: {0: 195, 1: 247, 2: 261, 3: 334, 4: 284, 5: 230, 6: 183, 7: 197, 8: 562}
episode: 98/2000 -> reward: 48.26562500000003, steps:2493, time-taken: 1.86min, time-elasped: 321.40min
-> berries picked: 39 of 800 | patches-visited: [0, 5, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4873 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [801, 383, 363, 486, 784, 620, 656, 525, 255]
	| approx positives in sample 512: 154
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [32, 24, 11, 19, 14, 14, 17, 18, 5]
	Time taken saving stuff: 0.10s

=== episode:99 Env-steps-taken:62016
 	picked: 58 |actions: {0: 476, 1: 494, 2: 352, 3: 286, 4: 389, 5: 309, 6: 258, 7: 302, 8: 427}
episode: 99/2000 -> reward: 70.17708333333337, steps:3293, time-taken: 2.39min, time-elasped: 323.80min
-> berries picked: 58 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4925 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [809, 395, 366, 495, 788, 624, 667, 525, 256]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [40, 17, 9, 8, 15, 8, 14, 18, 7]
	Time taken saving stuff: 0.03s

=== episode:100 Env-steps-taken:60384
 	picked: 45 |actions: {0: 293, 1: 343, 2: 331, 3: 473, 4: 408, 5: 361, 6: 289, 7: 295, 8: 575}
episode: 100/2000 -> reward: 62.42187500000005, steps:3368, time-taken: 2.16min, time-elasped: 325.96min
-> berries picked: 45 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4956 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [814, 399, 369, 504, 787, 624, 671, 530, 258]
	| approx positives in sample 512: 167
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [41, 16, 22, 10, 13, 15, 17, 25, 8]
	Time taken saving stuff: 0.08s

=== episode:10 Env-steps-taken:70944
 	picked: 83 |actions: {0: 888, 1: 207, 2: 288, 3: 294, 4: 808, 5: 265, 6: 185, 7: 191, 8: 494}

==================================================
eval-episode: 100 -> reward: 115.74479166666652, steps: 3620.0, wall-time: 60.57s
-> berries picked: 83 of 800 | patches-visited: [1, 4, 6] | juice left:-0.00
==================================================


=== episode:101 Env-steps-taken:56064
 	picked: 28 |actions: {0: 271, 1: 141, 2: 146, 3: 193, 4: 185, 5: 154, 6: 211, 7: 132, 8: 249}
episode: 101/2000 -> reward: 40.39583333333335, steps:1682, time-taken: 1.43min, time-elasped: 328.40min
-> berries picked: 28 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4974 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [824, 399, 369, 503, 789, 626, 674, 530, 260]
	| approx positives in sample 512: 150
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [32, 18, 12, 13, 17, 11, 15, 18, 14]
	Time taken saving stuff: 0.02s

=== episode:102 Env-steps-taken:64512
 	picked: 59 |actions: {0: 550, 1: 464, 2: 374, 3: 383, 4: 597, 5: 456, 6: 363, 7: 409, 8: 919}
episode: 102/2000 -> reward: 83.61979166666666, steps:4515, time-taken: 2.94min, time-elasped: 331.33min
-> berries picked: 59 of 800 | patches-visited: [0, 6, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5003 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [834, 404, 369, 507, 785, 628, 679, 531, 266]
	| approx positives in sample 512: 173
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [41, 25, 11, 9, 19, 21, 16, 18, 13]
	Time taken saving stuff: 0.03s

=== episode:103 Env-steps-taken:57312
 	picked: 32 |actions: {0: 170, 1: 145, 2: 163, 3: 256, 4: 449, 5: 220, 6: 177, 7: 177, 8: 425}
episode: 103/2000 -> reward: 47.16666666666669, steps:2182, time-taken: 1.64min, time-elasped: 332.97min
-> berries picked: 32 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5026 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [837, 405, 369, 511, 789, 632, 682, 532, 269]
	| approx positives in sample 512: 156
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [33, 13, 9, 16, 30, 10, 24, 10, 11]
	Time taken saving stuff: 0.01s

=== episode:104 Env-steps-taken:57120
 	picked: 33 |actions: {0: 268, 1: 167, 2: 237, 3: 207, 4: 358, 5: 237, 6: 178, 7: 214, 8: 496}
episode: 104/2000 -> reward: 46.10937500000003, steps:2362, time-taken: 1.76min, time-elasped: 334.74min
-> berries picked: 33 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5046 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [841, 406, 372, 513, 789, 635, 684, 535, 271]
	| approx positives in sample 512: 157
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [30, 17, 13, 17, 17, 18, 15, 18, 12]
	Time taken saving stuff: 0.02s

=== episode:105 Env-steps-taken:60576
 	picked: 41 |actions: {0: 413, 1: 314, 2: 463, 3: 280, 4: 417, 5: 266, 6: 322, 7: 353, 8: 758}
episode: 105/2000 -> reward: 61.76562500000005, steps:3586, time-taken: 2.28min, time-elasped: 337.03min
-> berries picked: 41 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5061 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [849, 407, 375, 518, 787, 630, 688, 535, 272]
	| approx positives in sample 512: 139
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [30, 14, 9, 17, 13, 18, 17, 10, 11]
	Time taken saving stuff: 0.09s

=== episode:106 Env-steps-taken:57600
 	picked: 35 |actions: {0: 176, 1: 199, 2: 237, 3: 234, 4: 203, 5: 248, 6: 220, 7: 172, 8: 471}
episode: 106/2000 -> reward: 48.4947916666667, steps:2160, time-taken: 1.54min, time-elasped: 338.58min
-> berries picked: 35 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5075 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [851, 413, 376, 523, 782, 630, 692, 534, 274]
	| approx positives in sample 512: 171
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [37, 19, 10, 17, 15, 12, 33, 18, 10]
	Time taken saving stuff: 0.06s

=== episode:107 Env-steps-taken:57696
 	picked: 40 |actions: {0: 306, 1: 243, 2: 213, 3: 302, 4: 479, 5: 253, 6: 269, 7: 267, 8: 590}
episode: 107/2000 -> reward: 48.20833333333335, steps:2922, time-taken: 2.02min, time-elasped: 340.60min
-> berries picked: 40 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5093 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [857, 415, 376, 522, 787, 630, 697, 534, 275]
	| approx positives in sample 512: 162
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [36, 21, 15, 18, 11, 10, 21, 22, 8]
	Time taken saving stuff: 0.01s

=== episode:108 Env-steps-taken:52896
 	picked: 15 |actions: {0: 121, 1: 62, 2: 61, 3: 82, 4: 61, 5: 48, 6: 75, 7: 93, 8: 97}
episode: 108/2000 -> reward: 24.640624999999996, steps:700, time-taken: 1.06min, time-elasped: 341.67min
-> berries picked: 15 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5102 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [858, 416, 378, 525, 786, 629, 699, 535, 276]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [35, 13, 15, 11, 12, 9, 21, 16, 2]
	Time taken saving stuff: 0.11s

=== episode:109 Env-steps-taken:59520
 	picked: 37 |actions: {0: 270, 1: 247, 2: 203, 3: 187, 4: 292, 5: 220, 6: 210, 7: 220, 8: 337}
episode: 109/2000 -> reward: 58.38020833333337, steps:2186, time-taken: 1.85min, time-elasped: 343.52min
-> berries picked: 37 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5129 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [865, 419, 380, 527, 787, 631, 702, 540, 278]
	| approx positives in sample 512: 151
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [37, 15, 6, 21, 11, 11, 22, 17, 11]
	Time taken saving stuff: 0.04s

=== episode:110 Env-steps-taken:60288
 	picked: 40 |actions: {0: 359, 1: 206, 2: 170, 3: 188, 4: 537, 5: 327, 6: 262, 7: 235, 8: 332}
episode: 110/2000 -> reward: 62.20833333333337, steps:2616, time-taken: 1.83min, time-elasped: 345.35min
-> berries picked: 40 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5144 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [868, 421, 381, 528, 788, 631, 710, 540, 277]
	| approx positives in sample 512: 158
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [31, 18, 12, 17, 20, 14, 19, 11, 16]
	Time taken saving stuff: 0.09s

=== episode:11 Env-steps-taken:57408
 	picked: 33 |actions: {0: 237, 1: 78, 2: 163, 3: 65, 4: 124, 5: 51, 6: 102, 7: 96, 8: 527}

==================================================
eval-episode: 110 -> reward: 47.10937500000002, steps: 1443.0, wall-time: 40.99s
-> berries picked: 33 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:111 Env-steps-taken:50400
 	picked: 9 |actions: {0: 78, 1: 25, 2: 59, 3: 28, 4: 48, 5: 42, 6: 38, 7: 35, 8: 75}
episode: 111/2000 -> reward: 11.984375000000002, steps:428, time-taken: 0.76min, time-elasped: 346.80min
-> berries picked: 9 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5143 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [869, 421, 381, 528, 786, 631, 709, 541, 277]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [33, 13, 14, 11, 11, 10, 15, 5, 9]
	Time taken saving stuff: 0.11s

=== episode:112 Env-steps-taken:55584
 	picked: 31 |actions: {0: 337, 1: 329, 2: 252, 3: 314, 4: 525, 5: 394, 6: 413, 7: 253, 8: 481}
episode: 112/2000 -> reward: 37.723958333333336, steps:3298, time-taken: 2.23min, time-elasped: 349.03min
-> berries picked: 31 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5120 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [872, 420, 383, 530, 774, 618, 705, 542, 276]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [23, 11, 12, 13, 14, 5, 19, 15, 16]
	Time taken saving stuff: 0.03s

=== episode:113 Env-steps-taken:52800
 	picked: 17 |actions: {0: 100, 1: 67, 2: 77, 3: 88, 4: 137, 5: 141, 6: 150, 7: 92, 8: 220}
episode: 113/2000 -> reward: 24.526041666666664, steps:1072, time-taken: 1.04min, time-elasped: 350.08min
-> berries picked: 17 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5117 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [873, 420, 383, 532, 772, 615, 703, 542, 277]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [26, 21, 8, 13, 11, 8, 12, 19, 10]
	Time taken saving stuff: 0.01s

=== episode:114 Env-steps-taken:49056
 	picked: 4 |actions: {0: 15, 1: 25, 2: 46, 3: 42, 4: 24, 5: 55, 6: 43, 7: 19, 8: 82}
episode: 114/2000 -> reward: 5.270833333333333, steps:351, time-taken: 0.71min, time-elasped: 350.79min
-> berries picked: 4 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5110 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [872, 420, 383, 532, 768, 614, 703, 541, 277]
	| approx positives in sample 512: 152
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [28, 13, 19, 16, 15, 18, 15, 13, 15]
	Time taken saving stuff: 0.01s

=== episode:115 Env-steps-taken:61728
 	picked: 49 |actions: {0: 401, 1: 301, 2: 391, 3: 336, 4: 688, 5: 486, 6: 487, 7: 397, 8: 661}
episode: 115/2000 -> reward: 69.19270833333336, steps:4148, time-taken: 2.64min, time-elasped: 353.43min
-> berries picked: 49 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5122 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [879, 422, 386, 529, 765, 611, 710, 541, 279]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 13, 11, 12, 17, 12, 15, 11, 7]
	Time taken saving stuff: 0.01s

=== episode:116 Env-steps-taken:51456
 	picked: 11 |actions: {0: 114, 1: 79, 2: 83, 3: 115, 4: 277, 5: 137, 6: 303, 7: 101, 8: 233}
episode: 116/2000 -> reward: 17.36979166666667, steps:1442, time-taken: 1.29min, time-elasped: 354.73min
-> berries picked: 11 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5122 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [878, 420, 386, 530, 762, 615, 713, 539, 279]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [35, 16, 10, 12, 15, 11, 13, 9, 7]
	Time taken saving stuff: 0.04s

=== episode:117 Env-steps-taken:56064
 	picked: 28 |actions: {0: 214, 1: 156, 2: 147, 3: 225, 4: 422, 5: 218, 6: 216, 7: 242, 8: 269}
episode: 117/2000 -> reward: 40.89583333333334, steps:2109, time-taken: 1.72min, time-elasped: 356.44min
-> berries picked: 28 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5133 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [882, 422, 384, 529, 766, 616, 715, 539, 280]
	| approx positives in sample 512: 143
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [32, 15, 16, 12, 20, 8, 15, 16, 9]
	Time taken saving stuff: 0.01s

=== episode:118 Env-steps-taken:57504
 	picked: 36 |actions: {0: 206, 1: 148, 2: 175, 3: 220, 4: 466, 5: 266, 6: 374, 7: 268, 8: 287}
episode: 118/2000 -> reward: 47.93750000000003, steps:2410, time-taken: 1.76min, time-elasped: 358.21min
-> berries picked: 36 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5154 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [885, 424, 383, 531, 771, 618, 722, 538, 282]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [34, 14, 15, 17, 14, 10, 9, 11, 12]
	Time taken saving stuff: 0.01s

=== episode:119 Env-steps-taken:70176
 	picked: 82 |actions: {0: 570, 1: 519, 2: 609, 3: 585, 4: 975, 5: 603, 6: 610, 7: 546, 8: 723}
episode: 119/2000 -> reward: 111.30208333333321, steps:5740, time-taken: 3.39min, time-elasped: 361.60min
-> berries picked: 82 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5183 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [887, 423, 387, 538, 777, 623, 724, 538, 286]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [31, 15, 9, 17, 10, 10, 15, 14, 12]
	Time taken saving stuff: 0.02s

=== episode:120 Env-steps-taken:71040
 	picked: 72 |actions: {0: 496, 1: 361, 2: 453, 3: 470, 4: 608, 5: 519, 6: 415, 7: 492, 8: 497}
episode: 120/2000 -> reward: 116.3749999999999, steps:4311, time-taken: 2.78min, time-elasped: 364.38min
-> berries picked: 72 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5225 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [894, 427, 392, 543, 784, 628, 729, 540, 288]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [27, 22, 8, 10, 11, 11, 20, 15, 12]
	Time taken saving stuff: 0.18s

=== episode:12 Env-steps-taken:64224
 	picked: 61 |actions: {0: 232, 1: 122, 2: 210, 3: 125, 4: 412, 5: 117, 6: 220, 7: 258, 8: 295}

==================================================
eval-episode: 120 -> reward: 82.00520833333331, steps: 1991.0, wall-time: 51.28s
-> berries picked: 61 of 800 | patches-visited: [1, 2, 4] | juice left:-0.00
==================================================


=== episode:121 Env-steps-taken:68640
 	picked: 72 |actions: {0: 582, 1: 558, 2: 414, 3: 573, 4: 634, 5: 466, 6: 432, 7: 492, 8: 563}
episode: 121/2000 -> reward: 102.48958333333323, steps:4714, time-taken: 3.03min, time-elasped: 368.28min
-> berries picked: 72 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5246 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [895, 429, 398, 548, 781, 629, 736, 540, 290]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [29, 13, 14, 16, 15, 13, 14, 15, 8]
	Time taken saving stuff: 0.24s

=== episode:122 Env-steps-taken:55680
 	picked: 27 |actions: {0: 201, 1: 117, 2: 152, 3: 161, 4: 279, 5: 202, 6: 219, 7: 151, 8: 162}
episode: 122/2000 -> reward: 38.453125000000014, steps:1644, time-taken: 1.31min, time-elasped: 369.60min
-> berries picked: 27 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5258 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [896, 430, 400, 551, 783, 627, 737, 542, 292]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 13, 11, 10, 12, 13, 12, 18, 7]
	Time taken saving stuff: 0.03s

=== episode:123 Env-steps-taken:71904
 	picked: 85 |actions: {0: 501, 1: 469, 2: 643, 3: 574, 4: 938, 5: 562, 6: 440, 7: 615, 8: 784}
episode: 123/2000 -> reward: 120.24479166666654, steps:5526, time-taken: 3.62min, time-elasped: 373.22min
-> berries picked: 85 of 800 | patches-visited: [0, 4, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5309 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [904, 430, 409, 560, 790, 632, 746, 543, 295]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 15, 8, 12, 16, 17, 20, 16, 9]
	Time taken saving stuff: 0.10s

=== episode:124 Env-steps-taken:62016
 	picked: 51 |actions: {0: 283, 1: 245, 2: 283, 3: 385, 4: 611, 5: 310, 6: 299, 7: 274, 8: 468}
episode: 124/2000 -> reward: 70.57812500000003, steps:3158, time-taken: 2.07min, time-elasped: 375.29min
-> berries picked: 51 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5335 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [907, 434, 410, 562, 795, 636, 747, 545, 299]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [33, 7, 18, 17, 11, 3, 16, 12, 4]
	Time taken saving stuff: 0.02s

=== episode:125 Env-steps-taken:60192
 	picked: 44 |actions: {0: 287, 1: 198, 2: 264, 3: 317, 4: 336, 5: 255, 6: 300, 7: 302, 8: 264}
episode: 125/2000 -> reward: 59.59375000000004, steps:2523, time-taken: 2.04min, time-elasped: 377.33min
-> berries picked: 44 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5351 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [910, 436, 413, 566, 796, 638, 746, 547, 299]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [32, 17, 12, 12, 20, 8, 22, 7, 6]
	Time taken saving stuff: 0.10s

=== episode:126 Env-steps-taken:58176
 	picked: 34 |actions: {0: 423, 1: 198, 2: 167, 3: 146, 4: 414, 5: 226, 6: 262, 7: 216, 8: 183}
episode: 126/2000 -> reward: 51.1666666666667, steps:2235, time-taken: 1.69min, time-elasped: 379.02min
-> berries picked: 34 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5373 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [918, 437, 413, 568, 797, 639, 752, 549, 300]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [29, 15, 14, 12, 17, 12, 20, 10, 13]
	Time taken saving stuff: 0.03s

=== episode:127 Env-steps-taken:61056
 	picked: 48 |actions: {0: 326, 1: 315, 2: 252, 3: 236, 4: 462, 5: 418, 6: 384, 7: 386, 8: 494}
episode: 127/2000 -> reward: 65.75000000000004, steps:3273, time-taken: 2.17min, time-elasped: 381.20min
-> berries picked: 48 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5398 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [921, 441, 414, 565, 797, 649, 758, 550, 303]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [34, 13, 13, 10, 13, 14, 21, 10, 8]
	Time taken saving stuff: 0.02s

=== episode:128 Env-steps-taken:64224
 	picked: 56 |actions: {0: 449, 1: 383, 2: 311, 3: 469, 4: 525, 5: 371, 6: 365, 7: 504, 8: 554}
episode: 128/2000 -> reward: 81.79166666666666, steps:3931, time-taken: 2.65min, time-elasped: 383.86min
-> berries picked: 56 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5428 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [920, 448, 417, 570, 795, 651, 770, 552, 305]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [28, 16, 13, 9, 10, 19, 20, 5, 12]
	Time taken saving stuff: 0.03s

=== episode:129 Env-steps-taken:68256
 	picked: 72 |actions: {0: 602, 1: 405, 2: 345, 3: 547, 4: 536, 5: 370, 6: 427, 7: 551, 8: 561}
episode: 129/2000 -> reward: 102.37499999999991, steps:4344, time-taken: 2.79min, time-elasped: 386.65min
-> berries picked: 72 of 800 | patches-visited: [0, 3, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5476 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [929, 452, 420, 577, 804, 655, 773, 558, 308]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [32, 17, 12, 8, 17, 8, 18, 3, 12]
	Time taken saving stuff: 0.02s

=== episode:130 Env-steps-taken:57312
 	picked: 36 |actions: {0: 502, 1: 747, 2: 398, 3: 358, 4: 513, 5: 561, 6: 547, 7: 526, 8: 490}
episode: 130/2000 -> reward: 46.437500000000036, steps:4642, time-taken: 2.90min, time-elasped: 389.56min
-> berries picked: 36 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5480 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [932, 455, 421, 578, 800, 653, 775, 559, 307]
	| approx positives in sample 512: 146
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [24, 13, 16, 17, 22, 10, 18, 15, 11]
	Time taken saving stuff: 0.04s

=== episode:13 Env-steps-taken:66144
 	picked: 65 |actions: {0: 230, 1: 279, 2: 136, 3: 148, 4: 471, 5: 285, 6: 160, 7: 383, 8: 280}

==================================================
eval-episode: 130 -> reward: 91.2760416666666, steps: 2372.0, wall-time: 57.75s
-> berries picked: 65 of 800 | patches-visited: [1, 2] | juice left:-0.00
==================================================


=== episode:131 Env-steps-taken:72768
 	picked: 84 |actions: {0: 563, 1: 512, 2: 450, 3: 489, 4: 664, 5: 463, 6: 372, 7: 550, 8: 490}
episode: 131/2000 -> reward: 125.18749999999984, steps:4553, time-taken: 3.00min, time-elasped: 393.53min
-> berries picked: 84 of 800 | patches-visited: [0, 1, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5529 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [942, 467, 430, 583, 796, 655, 778, 565, 313]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [30, 13, 10, 12, 18, 19, 15, 12, 5]
	Time taken saving stuff: 0.09s

=== episode:132 Env-steps-taken:59136
 	picked: 39 |actions: {0: 541, 1: 208, 2: 287, 3: 341, 4: 488, 5: 269, 6: 212, 7: 287, 8: 394}
episode: 132/2000 -> reward: 56.265625000000036, steps:3027, time-taken: 2.32min, time-elasped: 395.85min
-> berries picked: 39 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5541 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [942, 466, 436, 588, 792, 654, 778, 569, 316]
	| approx positives in sample 512: 152
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [28, 18, 9, 13, 24, 18, 15, 20, 7]
	Time taken saving stuff: 0.05s

=== episode:133 Env-steps-taken:62880
 	picked: 49 |actions: {0: 471, 1: 366, 2: 346, 3: 362, 4: 535, 5: 495, 6: 451, 7: 434, 8: 537}
episode: 133/2000 -> reward: 75.19270833333333, steps:3997, time-taken: 2.64min, time-elasped: 398.50min
-> berries picked: 49 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5549 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [947, 464, 440, 585, 791, 653, 783, 570, 316]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [36, 13, 8, 12, 8, 21, 18, 11, 15]
	Time taken saving stuff: 0.03s

=== episode:134 Env-steps-taken:60672
 	picked: 50 |actions: {0: 368, 1: 363, 2: 426, 3: 458, 4: 284, 5: 293, 6: 276, 7: 387, 8: 370}
episode: 134/2000 -> reward: 63.13541666666672, steps:3225, time-taken: 2.29min, time-elasped: 400.79min
-> berries picked: 50 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5570 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [959, 467, 445, 585, 793, 652, 784, 570, 315]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 16, 21, 12, 9, 13, 19, 12, 11]
	Time taken saving stuff: 0.03s

=== episode:135 Env-steps-taken:53952
 	picked: 23 |actions: {0: 159, 1: 177, 2: 211, 3: 178, 4: 214, 5: 260, 6: 261, 7: 183, 8: 213}
episode: 135/2000 -> reward: 29.682291666666664, steps:1856, time-taken: 1.63min, time-elasped: 402.43min
-> berries picked: 23 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5568 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [959, 467, 444, 582, 796, 652, 783, 570, 315]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [29, 10, 7, 8, 18, 12, 22, 18, 6]
	Time taken saving stuff: 0.01s

=== episode:136 Env-steps-taken:56448
 	picked: 31 |actions: {0: 254, 1: 236, 2: 205, 3: 193, 4: 260, 5: 214, 6: 184, 7: 190, 8: 246}
episode: 136/2000 -> reward: 42.22395833333334, steps:1982, time-taken: 1.80min, time-elasped: 404.24min
-> berries picked: 31 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5550 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [950, 464, 445, 579, 790, 653, 785, 569, 315]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 12, 15, 10, 19, 24, 16, 9, 10]
	Time taken saving stuff: 0.01s

=== episode:137 Env-steps-taken:51456
 	picked: 11 |actions: {0: 75, 1: 64, 2: 55, 3: 82, 4: 162, 5: 181, 6: 90, 7: 128, 8: 136}
episode: 137/2000 -> reward: 17.369791666666668, steps:973, time-taken: 0.90min, time-elasped: 405.14min
-> berries picked: 11 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5552 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [948, 464, 444, 579, 791, 654, 786, 571, 315]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 17, 8, 13, 18, 13, 22, 11, 9]
	Time taken saving stuff: 0.01s

=== episode:138 Env-steps-taken:62592
 	picked: 51 |actions: {0: 234, 1: 260, 2: 267, 3: 272, 4: 403, 5: 347, 6: 292, 7: 416, 8: 328}
episode: 138/2000 -> reward: 72.13541666666667, steps:2819, time-taken: 2.07min, time-elasped: 407.21min
-> berries picked: 51 of 800 | patches-visited: [0, 1, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5559 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [939, 466, 441, 580, 790, 654, 791, 579, 319]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [24, 8, 12, 14, 11, 16, 17, 10, 8]
	Time taken saving stuff: 0.03s

=== episode:139 Env-steps-taken:71808
 	picked: 87 |actions: {0: 592, 1: 529, 2: 574, 3: 603, 4: 616, 5: 608, 6: 550, 7: 806, 8: 623}
episode: 139/2000 -> reward: 119.51562499999984, steps:5501, time-taken: 3.38min, time-elasped: 410.60min
-> berries picked: 87 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5567 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [944, 465, 440, 575, 784, 647, 799, 594, 319]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 14, 7, 11, 19, 11, 19, 10, 6]
	Time taken saving stuff: 0.01s

=== episode:140 Env-steps-taken:62016
 	picked: 50 |actions: {0: 360, 1: 264, 2: 236, 3: 325, 4: 412, 5: 379, 6: 293, 7: 599, 8: 501}
episode: 140/2000 -> reward: 70.63541666666669, steps:3369, time-taken: 2.36min, time-elasped: 412.96min
-> berries picked: 50 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5592 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [954, 467, 440, 577, 785, 648, 801, 598, 322]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [29, 13, 5, 9, 10, 17, 12, 14, 11]
	Time taken saving stuff: 0.11s

=== episode:14 Env-steps-taken:77568
 	picked: 102 |actions: {0: 458, 1: 260, 2: 217, 3: 311, 4: 429, 5: 291, 6: 324, 7: 388, 8: 875}

==================================================
eval-episode: 140 -> reward: 146.38541666666666, steps: 3553.0, wall-time: 78.47s
-> berries picked: 102 of 800 | patches-visited: [0, 1, 3] | juice left:-0.00
==================================================


=== episode:141 Env-steps-taken:61056
 	picked: 48 |actions: {0: 293, 1: 340, 2: 367, 3: 400, 4: 378, 5: 316, 6: 345, 7: 494, 8: 375}
episode: 141/2000 -> reward: 65.75000000000006, steps:3308, time-taken: 2.25min, time-elasped: 416.53min
-> berries picked: 48 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5586 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [942, 468, 443, 572, 783, 648, 804, 602, 324]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 11, 13, 9, 13, 19, 20, 12, 9]
	Time taken saving stuff: 0.01s

=== episode:142 Env-steps-taken:50688
 	picked: 9 |actions: {0: 58, 1: 45, 2: 57, 3: 63, 4: 72, 5: 30, 6: 46, 7: 23, 8: 112}
episode: 142/2000 -> reward: 13.984375000000005, steps:506, time-taken: 0.85min, time-elasped: 417.38min
-> berries picked: 9 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5586 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [941, 469, 441, 573, 784, 647, 804, 602, 325]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [25, 18, 11, 13, 16, 11, 12, 13, 10]
	Time taken saving stuff: 0.01s

=== episode:143 Env-steps-taken:56640
 	picked: 27 |actions: {0: 178, 1: 195, 2: 149, 3: 179, 4: 246, 5: 132, 6: 161, 7: 123, 8: 222}
episode: 143/2000 -> reward: 43.45312500000002, steps:1585, time-taken: 1.55min, time-elasped: 418.94min
-> berries picked: 27 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5581 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [938, 472, 442, 577, 771, 651, 804, 601, 325]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 13, 5, 8, 13, 12, 11, 15, 8]
	Time taken saving stuff: 0.03s

=== episode:144 Env-steps-taken:65856
 	picked: 72 |actions: {0: 574, 1: 508, 2: 438, 3: 490, 4: 427, 5: 472, 6: 396, 7: 514, 8: 489}
episode: 144/2000 -> reward: 89.37499999999994, steps:4308, time-taken: 2.96min, time-elasped: 421.90min
-> berries picked: 72 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5592 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [940, 474, 449, 576, 767, 651, 809, 598, 328]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 15, 11, 16, 12, 11, 17, 15, 9]
	Time taken saving stuff: 0.01s

=== episode:145 Env-steps-taken:55392
 	picked: 26 |actions: {0: 232, 1: 192, 2: 235, 3: 145, 4: 165, 5: 222, 6: 152, 7: 152, 8: 214}
episode: 145/2000 -> reward: 37.010416666666664, steps:1709, time-taken: 1.40min, time-elasped: 423.30min
-> berries picked: 26 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5600 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [940, 480, 452, 578, 765, 651, 810, 596, 328]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [27, 11, 12, 18, 12, 13, 21, 12, 9]
	Time taken saving stuff: 0.00s

=== episode:146 Env-steps-taken:67872
 	picked: 72 |actions: {0: 502, 1: 446, 2: 438, 3: 382, 4: 649, 5: 572, 6: 404, 7: 533, 8: 600}
episode: 146/2000 -> reward: 99.87499999999993, steps:4526, time-taken: 3.05min, time-elasped: 426.36min
-> berries picked: 72 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5623 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [939, 478, 450, 582, 772, 655, 810, 607, 330]
	| approx positives in sample 512: 149
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 15, 15, 15, 16, 20, 22, 14, 10]
	Time taken saving stuff: 0.11s

=== episode:147 Env-steps-taken:64512
 	picked: 62 |actions: {0: 278, 1: 316, 2: 301, 3: 264, 4: 414, 5: 285, 6: 330, 7: 421, 8: 408}
episode: 147/2000 -> reward: 81.56249999999999, steps:3017, time-taken: 2.36min, time-elasped: 428.72min
-> berries picked: 62 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5643 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [942, 482, 455, 585, 773, 655, 812, 612, 327]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 15, 15, 19, 11, 12, 14, 19, 6]
	Time taken saving stuff: 0.08s

=== episode:148 Env-steps-taken:58464
 	picked: 42 |actions: {0: 244, 1: 276, 2: 306, 3: 349, 4: 248, 5: 240, 6: 346, 7: 352, 8: 396}
episode: 148/2000 -> reward: 52.59375000000004, steps:2757, time-taken: 2.07min, time-elasped: 430.80min
-> berries picked: 42 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5651 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [945, 480, 456, 586, 772, 656, 814, 613, 329]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [24, 13, 10, 9, 16, 15, 22, 14, 8]
	Time taken saving stuff: 0.03s

=== episode:149 Env-steps-taken:72864
 	picked: 86 |actions: {0: 576, 1: 601, 2: 656, 3: 582, 4: 563, 5: 581, 6: 535, 7: 649, 8: 734}
episode: 149/2000 -> reward: 123.1302083333332, steps:5477, time-taken: 3.41min, time-elasped: 434.22min
-> berries picked: 86 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5686 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [954, 486, 459, 593, 771, 660, 814, 620, 329]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 11, 9, 10, 16, 9, 20, 12, 16]
	Time taken saving stuff: 0.00s

=== episode:150 Env-steps-taken:64032
 	picked: 60 |actions: {0: 404, 1: 405, 2: 566, 3: 409, 4: 493, 5: 408, 6: 408, 7: 403, 8: 498}
episode: 150/2000 -> reward: 78.67708333333333, steps:3994, time-taken: 2.71min, time-elasped: 436.93min
-> berries picked: 60 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5706 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [956, 489, 468, 595, 774, 662, 817, 618, 327]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 13, 12, 9, 14, 15, 19, 10, 11]
	Time taken saving stuff: 0.07s

=== episode:15 Env-steps-taken:83328
 	picked: 125 |actions: {0: 426, 1: 491, 2: 400, 3: 463, 4: 607, 5: 437, 6: 508, 7: 675, 8: 825}

==================================================
eval-episode: 150 -> reward: 176.45312500000014, steps: 4832.0, wall-time: 70.24s
-> berries picked: 125 of 800 | patches-visited: [0, 1, 3, 9] | juice left:-0.00
==================================================


=== episode:151 Env-steps-taken:66912
 	picked: 66 |actions: {0: 418, 1: 438, 2: 487, 3: 485, 4: 542, 5: 574, 6: 400, 7: 491, 8: 608}
episode: 151/2000 -> reward: 95.71874999999994, steps:4443, time-taken: 3.22min, time-elasped: 441.33min
-> berries picked: 66 of 800 | patches-visited: [0, 5, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5697 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [955, 493, 470, 595, 758, 660, 817, 617, 332]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 8, 11, 11, 18, 12, 14, 12, 12]
	Time taken saving stuff: 0.01s

=== episode:152 Env-steps-taken:57888
 	picked: 38 |actions: {0: 300, 1: 242, 2: 302, 3: 238, 4: 241, 5: 220, 6: 187, 7: 316, 8: 345}
episode: 152/2000 -> reward: 47.88020833333336, steps:2391, time-taken: 1.82min, time-elasped: 443.16min
-> berries picked: 38 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5693 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [961, 499, 470, 592, 755, 656, 811, 615, 334]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 13, 10, 11, 16, 10, 20, 8, 14]
	Time taken saving stuff: 0.00s

=== episode:153 Env-steps-taken:63072
 	picked: 57 |actions: {0: 369, 1: 375, 2: 591, 3: 379, 4: 341, 5: 372, 6: 378, 7: 433, 8: 400}
episode: 153/2000 -> reward: 74.84895833333333, steps:3638, time-taken: 2.46min, time-elasped: 445.62min
-> berries picked: 57 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5709 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [960, 506, 477, 592, 750, 658, 813, 618, 335]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [24, 17, 9, 12, 8, 13, 7, 10, 10]
	Time taken saving stuff: 0.10s

=== episode:154 Env-steps-taken:72288
 	picked: 79 |actions: {0: 670, 1: 622, 2: 833, 3: 700, 4: 749, 5: 640, 6: 653, 7: 655, 8: 821}
episode: 154/2000 -> reward: 122.4739583333332, steps:6343, time-taken: 3.99min, time-elasped: 449.61min
-> berries picked: 79 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5726 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [959, 510, 481, 599, 747, 655, 812, 624, 339]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [27, 13, 13, 17, 7, 13, 20, 7, 13]
	Time taken saving stuff: 0.03s

=== episode:155 Env-steps-taken:63456
 	picked: 61 |actions: {0: 402, 1: 402, 2: 403, 3: 451, 4: 678, 5: 404, 6: 313, 7: 492, 8: 487}
episode: 155/2000 -> reward: 77.50520833333333, steps:4032, time-taken: 2.73min, time-elasped: 452.34min
-> berries picked: 61 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5744 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [963, 516, 479, 604, 750, 659, 808, 623, 342]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 11, 10, 4, 10, 14, 15, 16, 8]
	Time taken saving stuff: 0.03s

=== episode:156 Env-steps-taken:70944
 	picked: 76 |actions: {0: 551, 1: 452, 2: 597, 3: 425, 4: 604, 5: 514, 6: 552, 7: 462, 8: 616}
episode: 156/2000 -> reward: 115.6458333333332, steps:4773, time-taken: 3.22min, time-elasped: 455.57min
-> berries picked: 76 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5796 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [973, 523, 488, 607, 753, 670, 811, 628, 343]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 12, 16, 13, 12, 14, 16, 10, 13]
	Time taken saving stuff: 0.01s

=== episode:157 Env-steps-taken:62496
 	picked: 56 |actions: {0: 649, 1: 397, 2: 436, 3: 487, 4: 532, 5: 452, 6: 460, 7: 450, 8: 568}
episode: 157/2000 -> reward: 72.79166666666669, steps:4431, time-taken: 3.04min, time-elasped: 458.62min
-> berries picked: 56 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5828 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [981, 529, 493, 611, 757, 670, 813, 629, 345]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 8, 11, 17, 12, 13, 19, 18, 17]
	Time taken saving stuff: 0.10s

=== episode:158 Env-steps-taken:65472
 	picked: 61 |actions: {0: 608, 1: 698, 2: 586, 3: 488, 4: 521, 5: 406, 6: 377, 7: 889, 8: 803}
episode: 158/2000 -> reward: 88.00520833333331, steps:5376, time-taken: 3.25min, time-elasped: 461.87min
-> berries picked: 61 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5855 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [990, 538, 497, 620, 754, 667, 811, 629, 349]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [26, 15, 7, 17, 19, 14, 10, 11, 11]
	Time taken saving stuff: 0.01s

=== episode:159 Env-steps-taken:62496
 	picked: 50 |actions: {0: 451, 1: 309, 2: 227, 3: 299, 4: 283, 5: 301, 6: 291, 7: 308, 8: 391}
episode: 159/2000 -> reward: 72.63541666666669, steps:2860, time-taken: 2.26min, time-elasped: 464.14min
-> berries picked: 50 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5890 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [998, 543, 501, 622, 758, 671, 814, 634, 349]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 10, 8, 16, 12, 5, 19, 20, 12]
	Time taken saving stuff: 0.08s

=== episode:160 Env-steps-taken:63168
 	picked: 53 |actions: {0: 482, 1: 540, 2: 690, 3: 348, 4: 357, 5: 333, 6: 389, 7: 417, 8: 488}
episode: 160/2000 -> reward: 76.46354166666669, steps:4044, time-taken: 2.70min, time-elasped: 466.85min
-> berries picked: 53 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5912 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1003, 548, 504, 623, 760, 673, 815, 637, 349]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [23, 17, 5, 12, 12, 8, 17, 11, 10]
	Time taken saving stuff: 0.06s

=== episode:16 Env-steps-taken:70752
 	picked: 84 |actions: {0: 378, 1: 551, 2: 201, 3: 226, 4: 286, 5: 248, 6: 293, 7: 400, 8: 443}

==================================================
eval-episode: 160 -> reward: 112.3020833333332, steps: 3026.0, wall-time: 54.66s
-> berries picked: 84 of 800 | patches-visited: [1, 4] | juice left:-0.00
==================================================


=== episode:161 Env-steps-taken:60288
 	picked: 45 |actions: {0: 433, 1: 316, 2: 271, 3: 387, 4: 354, 5: 403, 6: 402, 7: 495, 8: 390}
episode: 161/2000 -> reward: 61.42187500000005, steps:3451, time-taken: 2.30min, time-elasped: 470.06min
-> berries picked: 45 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5912 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1008, 548, 503, 628, 760, 672, 808, 637, 348]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 9, 9, 10, 19, 15, 23, 15, 7]
	Time taken saving stuff: 0.03s

=== episode:162 Env-steps-taken:73632
 	picked: 89 |actions: {0: 653, 1: 663, 2: 527, 3: 544, 4: 572, 5: 527, 6: 526, 7: 568, 8: 423}
episode: 162/2000 -> reward: 127.95833333333319, steps:5003, time-taken: 3.45min, time-elasped: 473.51min
-> berries picked: 89 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5918 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1019, 547, 502, 624, 759, 677, 806, 634, 350]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 13, 9, 13, 18, 13, 12, 15, 12]
	Time taken saving stuff: 0.02s

=== episode:163 Env-steps-taken:60000
 	picked: 48 |actions: {0: 328, 1: 402, 2: 388, 3: 295, 4: 319, 5: 317, 6: 231, 7: 259, 8: 436}
episode: 163/2000 -> reward: 60.25000000000005, steps:2975, time-taken: 2.16min, time-elasped: 475.67min
-> berries picked: 48 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5931 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1019, 551, 506, 623, 762, 680, 807, 630, 353]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 7, 14, 15, 11, 11, 16, 6, 12]
	Time taken saving stuff: 0.01s

=== episode:164 Env-steps-taken:69504
 	picked: 72 |actions: {0: 559, 1: 621, 2: 547, 3: 442, 4: 509, 5: 447, 6: 409, 7: 397, 8: 496}
episode: 164/2000 -> reward: 107.98958333333326, steps:4427, time-taken: 3.13min, time-elasped: 478.81min
-> berries picked: 72 of 800 | patches-visited: [0, 3, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5955 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1022, 553, 513, 629, 764, 681, 806, 630, 357]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 11, 16, 14, 15, 15, 15, 15, 6]
	Time taken saving stuff: 0.01s

=== episode:165 Env-steps-taken:67584
 	picked: 75 |actions: {0: 589, 1: 645, 2: 683, 3: 590, 4: 578, 5: 493, 6: 484, 7: 599, 8: 745}
episode: 165/2000 -> reward: 98.20312499999993, steps:5406, time-taken: 3.32min, time-elasped: 482.13min
-> berries picked: 75 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5959 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1026, 560, 514, 635, 760, 679, 801, 626, 358]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [23, 9, 9, 20, 10, 8, 18, 12, 9]
	Time taken saving stuff: 0.11s

=== episode:166 Env-steps-taken:57024
 	picked: 35 |actions: {0: 399, 1: 564, 2: 350, 3: 255, 4: 222, 5: 226, 6: 309, 7: 303, 8: 276}
episode: 166/2000 -> reward: 45.49479166666668, steps:2904, time-taken: 2.23min, time-elasped: 484.37min
-> berries picked: 35 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 5976 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1035, 566, 519, 636, 762, 675, 798, 626, 359]
	| approx positives in sample 512: 146
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [26, 17, 15, 17, 14, 12, 14, 18, 13]
	Time taken saving stuff: 0.01s

=== episode:167 Env-steps-taken:73248
 	picked: 92 |actions: {0: 709, 1: 606, 2: 547, 3: 601, 4: 800, 5: 720, 6: 707, 7: 639, 8: 511}
episode: 167/2000 -> reward: 124.78645833333316, steps:5840, time-taken: 3.79min, time-elasped: 488.16min
-> berries picked: 92 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6017 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1040, 569, 522, 640, 763, 681, 805, 637, 360]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [28, 12, 10, 13, 9, 9, 18, 9, 14]
	Time taken saving stuff: 0.01s

=== episode:168 Env-steps-taken:54240
 	picked: 21 |actions: {0: 165, 1: 209, 2: 164, 3: 110, 4: 115, 5: 207, 6: 109, 7: 224, 8: 187}
episode: 168/2000 -> reward: 31.29687499999999, steps:1490, time-taken: 1.37min, time-elasped: 489.54min
-> berries picked: 21 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6025 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1043, 570, 524, 640, 763, 684, 801, 639, 361]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [25, 20, 10, 9, 16, 12, 13, 6, 17]
	Time taken saving stuff: 0.10s

=== episode:169 Env-steps-taken:71904
 	picked: 79 |actions: {0: 545, 1: 587, 2: 391, 3: 477, 4: 478, 5: 428, 6: 449, 7: 475, 8: 329}
episode: 169/2000 -> reward: 120.47395833333319, steps:4159, time-taken: 2.98min, time-elasped: 492.52min
-> berries picked: 79 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6070 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1054, 577, 530, 646, 767, 691, 800, 643, 362]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 10, 7, 12, 12, 15, 8, 10, 13]
	Time taken saving stuff: 0.01s

=== episode:170 Env-steps-taken:75744
 	picked: 100 |actions: {0: 747, 1: 663, 2: 653, 3: 768, 4: 719, 5: 645, 6: 740, 7: 878, 8: 685}
episode: 170/2000 -> reward: 137.32812499999991, steps:6498, time-taken: 4.03min, time-elasped: 496.56min
-> berries picked: 100 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6117 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1066, 591, 540, 650, 766, 690, 800, 648, 366]
	| approx positives in sample 512: 145
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [35, 21, 20, 5, 7, 11, 20, 12, 14]
	Time taken saving stuff: 0.18s

=== episode:17 Env-steps-taken:59808
 	picked: 42 |actions: {0: 316, 1: 152, 2: 168, 3: 92, 4: 115, 5: 91, 6: 153, 7: 208, 8: 344}

==================================================
eval-episode: 170 -> reward: 59.59375000000004, steps: 1639.0, wall-time: 42.97s
-> berries picked: 42 of 800 | patches-visited: [1, 5] | juice left:-0.00
==================================================


=== episode:171 Env-steps-taken:64992
 	picked: 61 |actions: {0: 603, 1: 508, 2: 409, 3: 270, 4: 353, 5: 431, 6: 534, 7: 464, 8: 571}
episode: 171/2000 -> reward: 85.11979166666664, steps:4143, time-taken: 2.77min, time-elasped: 500.06min
-> berries picked: 61 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6147 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1076, 600, 538, 648, 767, 694, 804, 654, 366]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 15, 6, 13, 18, 10, 23, 8, 7]
	Time taken saving stuff: 0.02s

=== episode:172 Env-steps-taken:60288
 	picked: 43 |actions: {0: 313, 1: 322, 2: 270, 3: 212, 4: 273, 5: 288, 6: 321, 7: 224, 8: 242}
episode: 172/2000 -> reward: 62.03645833333338, steps:2465, time-taken: 1.92min, time-elasped: 501.98min
-> berries picked: 43 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6176 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1083, 605, 539, 649, 773, 696, 804, 660, 367]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [27, 13, 10, 12, 12, 9, 13, 11, 12]
	Time taken saving stuff: 0.10s

=== episode:173 Env-steps-taken:62976
 	picked: 54 |actions: {0: 390, 1: 269, 2: 358, 3: 326, 4: 304, 5: 392, 6: 385, 7: 386, 8: 373}
episode: 173/2000 -> reward: 74.90625000000003, steps:3183, time-taken: 2.37min, time-elasped: 504.36min
-> berries picked: 54 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6210 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1084, 609, 544, 651, 774, 701, 809, 670, 368]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [24, 12, 9, 11, 15, 16, 11, 11, 7]
	Time taken saving stuff: 0.00s

=== episode:174 Env-steps-taken:61920
 	picked: 55 |actions: {0: 403, 1: 331, 2: 460, 3: 404, 4: 495, 5: 396, 6: 346, 7: 296, 8: 524}
episode: 174/2000 -> reward: 69.84895833333336, steps:3655, time-taken: 2.55min, time-elasped: 506.91min
-> berries picked: 55 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6232 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1087, 610, 551, 656, 774, 703, 809, 671, 371]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 11, 14, 11, 14, 15, 11, 15, 9]
	Time taken saving stuff: 0.09s

=== episode:175 Env-steps-taken:67776
 	picked: 71 |actions: {0: 875, 1: 585, 2: 555, 3: 390, 4: 498, 5: 607, 6: 583, 7: 827, 8: 823}
episode: 175/2000 -> reward: 99.4322916666666, steps:5743, time-taken: 3.72min, time-elasped: 510.65min
-> berries picked: 71 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6249 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1094, 616, 549, 655, 766, 702, 815, 678, 374]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 17, 8, 18, 15, 10, 10, 9, 16]
	Time taken saving stuff: 0.05s

=== episode:176 Env-steps-taken:73536
 	picked: 92 |actions: {0: 710, 1: 625, 2: 515, 3: 525, 4: 735, 5: 674, 6: 459, 7: 685, 8: 517}
episode: 176/2000 -> reward: 128.7291666666665, steps:5445, time-taken: 3.74min, time-elasped: 514.39min
-> berries picked: 92 of 800 | patches-visited: [0, 4, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6278 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1099, 618, 553, 655, 764, 712, 821, 680, 376]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [25, 15, 11, 12, 19, 17, 12, 7, 10]
	Time taken saving stuff: 0.10s

=== episode:177 Env-steps-taken:72384
 	picked: 87 |actions: {0: 566, 1: 644, 2: 467, 3: 468, 4: 603, 5: 575, 6: 768, 7: 548, 8: 651}
episode: 177/2000 -> reward: 123.01562499999983, steps:5290, time-taken: 3.40min, time-elasped: 517.80min
-> berries picked: 87 of 800 | patches-visited: [0, 1, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6311 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1108, 621, 554, 654, 768, 719, 829, 683, 375]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 12, 11, 7, 21, 18, 15, 23, 11]
	Time taken saving stuff: 0.03s

=== episode:178 Env-steps-taken:54912
 	picked: 22 |actions: {0: 161, 1: 121, 2: 116, 3: 102, 4: 126, 5: 223, 6: 145, 7: 144, 8: 259}
episode: 178/2000 -> reward: 35.239583333333336, steps:1397, time-taken: 1.22min, time-elasped: 519.02min
-> berries picked: 22 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6321 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1114, 624, 555, 653, 767, 721, 827, 684, 376]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 20, 14, 11, 11, 9, 14, 10, 11]
	Time taken saving stuff: 0.03s

=== episode:179 Env-steps-taken:64896
 	picked: 61 |actions: {0: 494, 1: 495, 2: 450, 3: 390, 4: 456, 5: 378, 6: 489, 7: 439, 8: 651}
episode: 179/2000 -> reward: 86.0052083333333, steps:4242, time-taken: 2.97min, time-elasped: 522.00min
-> berries picked: 61 of 800 | patches-visited: [0, 2, 7, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6333 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1119, 625, 556, 653, 766, 722, 825, 687, 380]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [23, 14, 7, 15, 15, 13, 12, 12, 7]
	Time taken saving stuff: 0.04s

=== episode:180 Env-steps-taken:64320
 	picked: 63 |actions: {0: 510, 1: 486, 2: 551, 3: 474, 4: 560, 5: 687, 6: 589, 7: 522, 8: 588}
episode: 180/2000 -> reward: 81.39062499999999, steps:4967, time-taken: 3.21min, time-elasped: 525.21min
-> berries picked: 63 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6342 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1122, 628, 560, 654, 768, 720, 825, 684, 381]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [24, 13, 10, 10, 17, 15, 14, 11, 8]
	Time taken saving stuff: 0.05s

=== episode:18 Env-steps-taken:87936
 	picked: 146 |actions: {0: 478, 1: 1038, 2: 416, 3: 698, 4: 452, 5: 426, 6: 416, 7: 468, 8: 794}

==================================================
eval-episode: 180 -> reward: 200.635416666667, steps: 5186.0, wall-time: 74.86s
-> berries picked: 146 of 800 | patches-visited: [1, 4, 6] | juice left:-0.00
==================================================


=== episode:181 Env-steps-taken:61248
 	picked: 51 |actions: {0: 414, 1: 432, 2: 360, 3: 245, 4: 338, 5: 245, 6: 334, 7: 283, 8: 345}
episode: 181/2000 -> reward: 66.07812500000003, steps:2996, time-taken: 2.10min, time-elasped: 528.56min
-> berries picked: 51 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6319 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1123, 632, 558, 641, 758, 722, 824, 680, 381]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 13, 14, 10, 14, 15, 11, 17, 7]
	Time taken saving stuff: 0.03s

=== episode:182 Env-steps-taken:62688
 	picked: 58 |actions: {0: 428, 1: 530, 2: 439, 3: 385, 4: 383, 5: 345, 6: 323, 7: 370, 8: 358}
episode: 182/2000 -> reward: 73.67708333333333, steps:3561, time-taken: 2.53min, time-elasped: 531.10min
-> berries picked: 58 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6292 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1112, 636, 552, 631, 758, 725, 821, 671, 386]
	| approx positives in sample 512: 95
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 6, 5, 4, 11, 11, 16, 11, 11]
	Time taken saving stuff: 0.09s

=== episode:183 Env-steps-taken:65280
 	picked: 57 |actions: {0: 322, 1: 424, 2: 273, 3: 231, 4: 332, 5: 274, 6: 264, 7: 360, 8: 366}
episode: 183/2000 -> reward: 87.23437499999997, steps:2846, time-taken: 2.45min, time-elasped: 533.55min
-> berries picked: 57 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6298 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1116, 638, 548, 628, 758, 725, 823, 673, 389]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 13, 11, 9, 14, 8, 12, 19, 9]
	Time taken saving stuff: 0.01s

=== episode:184 Env-steps-taken:67584
 	picked: 72 |actions: {0: 512, 1: 504, 2: 379, 3: 418, 4: 451, 5: 400, 6: 654, 7: 487, 8: 435}
episode: 184/2000 -> reward: 98.37499999999991, steps:4240, time-taken: 2.84min, time-elasped: 536.40min
-> berries picked: 72 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6297 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1116, 638, 546, 627, 755, 727, 820, 678, 390]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 7, 6, 15, 9, 13, 16, 17, 11]
	Time taken saving stuff: 0.02s

=== episode:185 Env-steps-taken:70272
 	picked: 79 |actions: {0: 468, 1: 554, 2: 369, 3: 390, 4: 544, 5: 517, 6: 500, 7: 529, 8: 405}
episode: 185/2000 -> reward: 112.4739583333332, steps:4276, time-taken: 2.88min, time-elasped: 539.29min
-> berries picked: 79 of 800 | patches-visited: [0, 1, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6316 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1114, 647, 539, 635, 761, 730, 823, 675, 392]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 8, 14, 14, 8, 18, 15, 14, 15]
	Time taken saving stuff: 0.02s

=== episode:186 Env-steps-taken:58080
 	picked: 38 |actions: {0: 291, 1: 386, 2: 247, 3: 203, 4: 267, 5: 254, 6: 257, 7: 250, 8: 500}
episode: 186/2000 -> reward: 50.3229166666667, steps:2655, time-taken: 1.87min, time-elasped: 541.16min
-> berries picked: 38 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6263 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1115, 640, 522, 618, 762, 730, 822, 661, 393]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 17, 7, 5, 14, 13, 13, 11, 10]
	Time taken saving stuff: 0.10s

=== episode:187 Env-steps-taken:71328
 	picked: 85 |actions: {0: 570, 1: 560, 2: 524, 3: 529, 4: 531, 5: 458, 6: 593, 7: 679, 8: 535}
episode: 187/2000 -> reward: 117.1302083333332, steps:4979, time-taken: 3.26min, time-elasped: 544.43min
-> berries picked: 85 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6258 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1116, 643, 511, 617, 764, 737, 821, 655, 394]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 11, 7, 12, 14, 8, 11, 8, 9]
	Time taken saving stuff: 0.07s

=== episode:188 Env-steps-taken:57312
 	picked: 28 |actions: {0: 166, 1: 162, 2: 109, 3: 76, 4: 141, 5: 167, 6: 122, 7: 230, 8: 219}
episode: 188/2000 -> reward: 46.89583333333335, steps:1392, time-taken: 1.30min, time-elasped: 545.73min
-> berries picked: 28 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6265 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1112, 647, 509, 620, 762, 738, 825, 656, 396]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 16, 11, 15, 17, 11, 16, 17, 9]
	Time taken saving stuff: 0.08s

=== episode:189 Env-steps-taken:71328
 	picked: 78 |actions: {0: 562, 1: 460, 2: 436, 3: 548, 4: 620, 5: 594, 6: 531, 7: 432, 8: 397}
episode: 189/2000 -> reward: 117.53124999999989, steps:4580, time-taken: 3.22min, time-elasped: 548.95min
-> berries picked: 78 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6246 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1106, 636, 507, 620, 762, 742, 822, 653, 398]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [23, 19, 10, 8, 17, 11, 10, 19, 9]
	Time taken saving stuff: 0.00s

=== episode:190 Env-steps-taken:69504
 	picked: 76 |actions: {0: 459, 1: 469, 2: 519, 3: 394, 4: 522, 5: 424, 6: 496, 7: 593, 8: 540}
episode: 190/2000 -> reward: 107.26041666666657, steps:4416, time-taken: 2.97min, time-elasped: 551.92min
-> berries picked: 76 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6269 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1114, 640, 521, 626, 759, 739, 820, 650, 400]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 19, 13, 10, 11, 9, 13, 9, 10]
	Time taken saving stuff: 0.17s

=== episode:19 Env-steps-taken:85152
 	picked: 142 |actions: {0: 518, 1: 790, 2: 487, 3: 328, 4: 521, 5: 521, 6: 656, 7: 654, 8: 764}

==================================================
eval-episode: 190 -> reward: 183.65104166666686, steps: 5239.0, wall-time: 80.02s
-> berries picked: 142 of 800 | patches-visited: [0, 1, 8] | juice left:-0.00
==================================================


=== episode:191 Env-steps-taken:68160
 	picked: 72 |actions: {0: 606, 1: 936, 2: 430, 3: 512, 4: 521, 5: 430, 6: 555, 7: 544, 8: 564}
episode: 191/2000 -> reward: 101.37499999999991, steps:5098, time-taken: 3.22min, time-elasped: 556.49min
-> berries picked: 72 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6172 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1076, 635, 509, 622, 760, 734, 819, 616, 401]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 15, 5, 13, 11, 9, 16, 17, 11]
	Time taken saving stuff: 0.03s

=== episode:192 Env-steps-taken:72288
 	picked: 95 |actions: {0: 456, 1: 683, 2: 579, 3: 504, 4: 626, 5: 591, 6: 682, 7: 503, 8: 561}
episode: 192/2000 -> reward: 120.11458333333317, steps:5185, time-taken: 3.58min, time-elasped: 560.07min
-> berries picked: 95 of 800 | patches-visited: [0, 3, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6160 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1071, 639, 499, 623, 760, 737, 816, 612, 403]
	| approx positives in sample 512: 93
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 15, 4, 4, 10, 9, 15, 11, 13]
	Time taken saving stuff: 0.03s

=== episode:193 Env-steps-taken:68256
 	picked: 76 |actions: {0: 539, 1: 730, 2: 530, 3: 428, 4: 457, 5: 617, 6: 735, 7: 532, 8: 569}
episode: 193/2000 -> reward: 101.64583333333324, steps:5137, time-taken: 3.27min, time-elasped: 563.34min
-> berries picked: 76 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6141 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1073, 635, 494, 626, 762, 737, 813, 598, 403]
	| approx positives in sample 512: 99
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 7, 7, 7, 9, 13, 12, 12, 11]
	Time taken saving stuff: 0.00s

=== episode:194 Env-steps-taken:65376
 	picked: 61 |actions: {0: 317, 1: 496, 2: 315, 3: 334, 4: 502, 5: 368, 6: 389, 7: 329, 8: 353}
episode: 194/2000 -> reward: 88.00520833333331, steps:3403, time-taken: 2.39min, time-elasped: 565.73min
-> berries picked: 61 of 800 | patches-visited: [0, 1, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6152 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1064, 640, 497, 626, 775, 743, 807, 592, 408]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 14, 9, 10, 10, 14, 10, 12, 11]
	Time taken saving stuff: 0.12s

=== episode:195 Env-steps-taken:66720
 	picked: 67 |actions: {0: 399, 1: 500, 2: 463, 3: 379, 4: 660, 5: 475, 6: 475, 7: 561, 8: 723}
episode: 195/2000 -> reward: 94.16145833333326, steps:4635, time-taken: 2.99min, time-elasped: 568.73min
-> berries picked: 67 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6153 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1057, 632, 499, 629, 780, 746, 810, 591, 409]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 7, 11, 9, 14, 13, 16, 8, 11]
	Time taken saving stuff: 0.01s

=== episode:196 Env-steps-taken:64032
 	picked: 66 |actions: {0: 628, 1: 792, 2: 768, 3: 541, 4: 498, 5: 488, 6: 441, 7: 667, 8: 998}
episode: 196/2000 -> reward: 79.71874999999999, steps:5821, time-taken: 3.71min, time-elasped: 572.44min
-> berries picked: 66 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6105 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1045, 635, 504, 630, 779, 742, 793, 570, 407]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 12, 14, 9, 16, 15, 11, 7, 5]
	Time taken saving stuff: 0.11s

=== episode:197 Env-steps-taken:63360
 	picked: 55 |actions: {0: 491, 1: 431, 2: 433, 3: 450, 4: 425, 5: 345, 6: 348, 7: 327, 8: 397}
episode: 197/2000 -> reward: 77.84895833333333, steps:3647, time-taken: 2.53min, time-elasped: 574.97min
-> berries picked: 55 of 800 | patches-visited: [0, 4, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6092 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1049, 639, 511, 634, 779, 740, 768, 561, 411]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [23, 17, 7, 10, 20, 13, 13, 10, 11]
	Time taken saving stuff: 0.01s

=== episode:198 Env-steps-taken:62592
 	picked: 55 |actions: {0: 410, 1: 718, 2: 351, 3: 351, 4: 384, 5: 361, 6: 542, 7: 439, 8: 513}
episode: 198/2000 -> reward: 72.84895833333334, steps:4069, time-taken: 2.53min, time-elasped: 577.50min
-> berries picked: 55 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6086 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1047, 645, 517, 640, 779, 740, 758, 549, 411]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [29, 15, 9, 13, 17, 13, 6, 7, 7]
	Time taken saving stuff: 0.08s

=== episode:199 Env-steps-taken:70080
 	picked: 77 |actions: {0: 501, 1: 616, 2: 485, 3: 411, 4: 474, 5: 542, 6: 465, 7: 546, 8: 468}
episode: 199/2000 -> reward: 111.58854166666653, steps:4508, time-taken: 3.07min, time-elasped: 580.58min
-> berries picked: 77 of 800 | patches-visited: [0, 5, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6118 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1053, 655, 524, 644, 784, 736, 756, 552, 414]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 18, 11, 8, 9, 9, 13, 6, 18]
	Time taken saving stuff: 0.03s

=== episode:200 Env-steps-taken:68928
 	picked: 85 |actions: {0: 631, 1: 644, 2: 523, 3: 491, 4: 562, 5: 465, 6: 553, 7: 729, 8: 869}
episode: 200/2000 -> reward: 104.63020833333324, steps:5467, time-taken: 3.36min, time-elasped: 583.95min
-> berries picked: 85 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6141 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1057, 665, 537, 645, 777, 738, 756, 550, 416]
	| approx positives in sample 512: 99
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 14, 15, 11, 12, 9, 6, 10, 5]
	Time taken saving stuff: 0.13s

=== episode:20 Env-steps-taken:67104
 	picked: 67 |actions: {0: 221, 1: 433, 2: 221, 3: 164, 4: 320, 5: 92, 6: 577, 7: 268, 8: 723}

==================================================
eval-episode: 200 -> reward: 95.7760416666666, steps: 3019.0, wall-time: 56.62s
-> berries picked: 67 of 800 | patches-visited: [0, 1, 6] | juice left:-0.00
==================================================


=== episode:201 Env-steps-taken:64416
 	picked: 53 |actions: {0: 379, 1: 464, 2: 422, 3: 313, 4: 392, 5: 471, 6: 996, 7: 685, 8: 694}
episode: 201/2000 -> reward: 82.96354166666664, steps:4816, time-taken: 2.93min, time-elasped: 587.83min
-> berries picked: 53 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6060 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1030, 656, 533, 634, 762, 736, 744, 547, 418]
	| approx positives in sample 512: 96
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 11, 7, 11, 12, 12, 8, 9, 9]
	Time taken saving stuff: 0.00s

=== episode:202 Env-steps-taken:74112
 	picked: 91 |actions: {0: 548, 1: 643, 2: 554, 3: 554, 4: 647, 5: 710, 6: 632, 7: 831, 8: 743}
episode: 202/2000 -> reward: 131.2864583333332, steps:5862, time-taken: 3.91min, time-elasped: 591.75min
-> berries picked: 91 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6052 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1022, 654, 537, 640, 762, 738, 737, 545, 417]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 11, 6, 10, 15, 16, 12, 14, 12]
	Time taken saving stuff: 0.01s

=== episode:203 Env-steps-taken:68160
 	picked: 74 |actions: {0: 380, 1: 540, 2: 442, 3: 398, 4: 561, 5: 499, 6: 531, 7: 565, 8: 472}
episode: 203/2000 -> reward: 101.76041666666656, steps:4388, time-taken: 2.96min, time-elasped: 594.71min
-> berries picked: 74 of 800 | patches-visited: [0, 4, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6066 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1020, 658, 537, 650, 758, 741, 737, 546, 419]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 6, 8, 13, 13, 13, 11, 11, 5]
	Time taken saving stuff: 0.01s

=== episode:204 Env-steps-taken:69312
 	picked: 83 |actions: {0: 470, 1: 483, 2: 487, 3: 388, 4: 522, 5: 544, 6: 521, 7: 671, 8: 536}
episode: 204/2000 -> reward: 106.74479166666653, steps:4622, time-taken: 3.10min, time-elasped: 597.81min
-> berries picked: 83 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6085 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1024, 656, 534, 649, 763, 750, 738, 550, 421]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 8, 5, 14, 14, 13, 16, 17, 6]
	Time taken saving stuff: 0.00s

=== episode:205 Env-steps-taken:65376
 	picked: 64 |actions: {0: 400, 1: 448, 2: 431, 3: 405, 4: 520, 5: 505, 6: 713, 7: 563, 8: 531}
episode: 205/2000 -> reward: 87.3333333333333, steps:4516, time-taken: 3.03min, time-elasped: 600.84min
-> berries picked: 64 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6093 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1022, 659, 536, 655, 770, 746, 732, 549, 424]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [29, 12, 9, 15, 17, 7, 13, 14, 12]
	Time taken saving stuff: 0.10s

=== episode:206 Env-steps-taken:69984
 	picked: 74 |actions: {0: 427, 1: 598, 2: 446, 3: 402, 4: 460, 5: 436, 6: 606, 7: 547, 8: 629}
episode: 206/2000 -> reward: 111.26041666666657, steps:4551, time-taken: 3.05min, time-elasped: 603.90min
-> berries picked: 74 of 800 | patches-visited: [0, 4, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6072 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1005, 651, 534, 654, 761, 754, 733, 554, 426]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 11, 8, 11, 17, 12, 14, 11, 14]
	Time taken saving stuff: 0.06s

=== episode:207 Env-steps-taken:73824
 	picked: 94 |actions: {0: 574, 1: 711, 2: 606, 3: 455, 4: 675, 5: 479, 6: 533, 7: 723, 8: 630}
episode: 207/2000 -> reward: 129.61458333333314, steps:5386, time-taken: 3.48min, time-elasped: 607.38min
-> berries picked: 94 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6097 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1012, 653, 538, 656, 760, 764, 736, 549, 429]
	| approx positives in sample 512: 99
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 7, 12, 10, 11, 14, 9, 10, 11]
	Time taken saving stuff: 0.01s

=== episode:208 Env-steps-taken:72576
 	picked: 94 |actions: {0: 492, 1: 697, 2: 574, 3: 528, 4: 624, 5: 471, 6: 760, 7: 833, 8: 692}
episode: 208/2000 -> reward: 120.28645833333317, steps:5671, time-taken: 3.54min, time-elasped: 610.92min
-> berries picked: 94 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6121 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1011, 655, 539, 660, 763, 764, 742, 557, 430]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 14, 8, 14, 10, 16, 11, 4, 13]
	Time taken saving stuff: 0.01s

=== episode:209 Env-steps-taken:65856
 	picked: 61 |actions: {0: 570, 1: 678, 2: 508, 3: 367, 4: 500, 5: 397, 6: 481, 7: 564, 8: 607}
episode: 209/2000 -> reward: 90.5052083333333, steps:4672, time-taken: 2.98min, time-elasped: 613.90min
-> berries picked: 61 of 800 | patches-visited: [0, 5, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6150 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1019, 665, 542, 660, 764, 769, 741, 557, 433]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 15, 11, 7, 13, 14, 11, 9, 13]
	Time taken saving stuff: 0.00s

=== episode:210 Env-steps-taken:73920
 	picked: 91 |actions: {0: 628, 1: 799, 2: 613, 3: 526, 4: 776, 5: 576, 6: 646, 7: 845, 8: 749}
episode: 210/2000 -> reward: 130.2864583333332, steps:6158, time-taken: 3.79min, time-elasped: 617.69min
-> berries picked: 91 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6170 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1015, 669, 543, 658, 777, 772, 742, 560, 434]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [25, 8, 13, 9, 15, 10, 12, 11, 12]
	Time taken saving stuff: 0.07s

=== episode:21 Env-steps-taken:64800
 	picked: 59 |actions: {0: 204, 1: 205, 2: 301, 3: 158, 4: 90, 5: 65, 6: 265, 7: 875, 8: 1099}

==================================================
eval-episode: 210 -> reward: 85.11979166666664, steps: 3262.0, wall-time: 48.41s
-> berries picked: 59 of 800 | patches-visited: [1, 4, 7] | juice left:-0.00
==================================================


=== episode:211 Env-steps-taken:71232
 	picked: 81 |actions: {0: 580, 1: 812, 2: 855, 3: 450, 4: 526, 5: 489, 6: 583, 7: 783, 8: 680}
episode: 211/2000 -> reward: 117.35937499999986, steps:5758, time-taken: 4.02min, time-elasped: 622.52min
-> berries picked: 81 of 800 | patches-visited: [0, 6, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6188 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1027, 677, 549, 661, 762, 769, 745, 562, 436]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 9, 8, 13, 14, 13, 19, 18, 13]
	Time taken saving stuff: 0.04s

=== episode:212 Env-steps-taken:58656
 	picked: 34 |actions: {0: 209, 1: 284, 2: 290, 3: 197, 4: 281, 5: 207, 6: 234, 7: 266, 8: 424}
episode: 212/2000 -> reward: 54.552083333333364, steps:2392, time-taken: 1.80min, time-elasped: 624.33min
-> berries picked: 34 of 800 | patches-visited: [0, 2, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6203 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1027, 681, 552, 662, 764, 770, 745, 564, 438]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 15, 18, 14, 10, 15, 13, 7, 10]
	Time taken saving stuff: 0.01s

=== episode:213 Env-steps-taken:63840
 	picked: 56 |actions: {0: 525, 1: 617, 2: 610, 3: 320, 4: 384, 5: 432, 6: 578, 7: 618, 8: 553}
episode: 213/2000 -> reward: 79.79166666666664, steps:4637, time-taken: 3.20min, time-elasped: 627.53min
-> berries picked: 56 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6211 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1028, 689, 551, 659, 764, 770, 742, 566, 442]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [25, 19, 8, 16, 13, 11, 11, 7, 11]
	Time taken saving stuff: 0.01s

=== episode:214 Env-steps-taken:66720
 	picked: 60 |actions: {0: 368, 1: 659, 2: 474, 3: 431, 4: 594, 5: 364, 6: 449, 7: 355, 8: 761}
episode: 214/2000 -> reward: 95.06249999999994, steps:4455, time-taken: 3.08min, time-elasped: 630.61min
-> berries picked: 60 of 800 | patches-visited: [0, 3, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6240 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1034, 692, 557, 661, 767, 771, 743, 569, 446]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 14, 7, 13, 20, 13, 16, 15, 9]
	Time taken saving stuff: 0.01s

=== episode:215 Env-steps-taken:61152
 	picked: 48 |actions: {0: 313, 1: 336, 2: 384, 3: 237, 4: 339, 5: 226, 6: 412, 7: 349, 8: 314}
episode: 215/2000 -> reward: 66.25000000000004, steps:2910, time-taken: 2.11min, time-elasped: 632.73min
-> berries picked: 48 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6267 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1037, 691, 568, 665, 770, 776, 743, 570, 447]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 12, 10, 10, 13, 19, 9, 13, 7]
	Time taken saving stuff: 0.01s

=== episode:216 Env-steps-taken:72576
 	picked: 91 |actions: {0: 705, 1: 718, 2: 511, 3: 504, 4: 701, 5: 472, 6: 753, 7: 809, 8: 726}
episode: 216/2000 -> reward: 123.28645833333316, steps:5899, time-taken: 3.83min, time-elasped: 636.56min
-> berries picked: 91 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6286 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1040, 700, 575, 667, 771, 770, 743, 568, 452]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 13, 8, 14, 10, 4, 16, 8, 12]
	Time taken saving stuff: 0.01s

=== episode:217 Env-steps-taken:72192
 	picked: 89 |actions: {0: 468, 1: 586, 2: 406, 3: 451, 4: 573, 5: 468, 6: 536, 7: 482, 8: 615}
episode: 217/2000 -> reward: 121.90104166666653, steps:4585, time-taken: 3.00min, time-elasped: 639.57min
-> berries picked: 89 of 800 | patches-visited: [0, 2, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6327 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1046, 709, 578, 673, 782, 772, 751, 562, 454]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 13, 8, 11, 19, 13, 20, 9, 10]
	Time taken saving stuff: 0.00s

=== episode:218 Env-steps-taken:65952
 	picked: 63 |actions: {0: 433, 1: 530, 2: 305, 3: 402, 4: 500, 5: 301, 6: 331, 7: 444, 8: 578}
episode: 218/2000 -> reward: 90.89062499999996, steps:3824, time-taken: 2.82min, time-elasped: 642.39min
-> berries picked: 63 of 800 | patches-visited: [0, 5, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6350 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1053, 715, 580, 676, 782, 772, 752, 563, 457]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 9, 11, 17, 12, 14, 16, 15, 5]
	Time taken saving stuff: 0.03s

=== episode:219 Env-steps-taken:68544
 	picked: 66 |actions: {0: 413, 1: 549, 2: 376, 3: 343, 4: 355, 5: 320, 6: 530, 7: 582, 8: 495}
episode: 219/2000 -> reward: 103.71874999999991, steps:3963, time-taken: 2.66min, time-elasped: 645.05min
-> berries picked: 66 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6379 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1060, 726, 585, 677, 781, 768, 757, 567, 458]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [25, 10, 10, 8, 9, 10, 11, 8, 16]
	Time taken saving stuff: 0.11s

=== episode:220 Env-steps-taken:68832
 	picked: 85 |actions: {0: 557, 1: 834, 2: 473, 3: 400, 4: 438, 5: 469, 6: 682, 7: 720, 8: 647}
episode: 220/2000 -> reward: 104.1302083333332, steps:5220, time-taken: 3.09min, time-elasped: 648.14min
-> berries picked: 85 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6423 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1063, 738, 593, 682, 778, 777, 762, 570, 460]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 10, 10, 12, 9, 15, 14, 9, 12]
	Time taken saving stuff: 0.16s

=== episode:22 Env-steps-taken:91872
 	picked: 168 |actions: {0: 461, 1: 1203, 2: 479, 3: 237, 4: 778, 5: 192, 6: 972, 7: 961, 8: 1039}

==================================================
eval-episode: 220 -> reward: 219.87500000000057, steps: 6322.0, wall-time: 70.95s
-> berries picked: 168 of 800 | patches-visited: [1, 4, 7] | juice left:-0.00
==================================================


=== episode:221 Env-steps-taken:64896
 	picked: 60 |actions: {0: 298, 1: 623, 2: 349, 3: 351, 4: 500, 5: 373, 6: 341, 7: 313, 8: 673}
episode: 221/2000 -> reward: 85.06249999999996, steps:3821, time-taken: 2.49min, time-elasped: 651.82min
-> berries picked: 60 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6452 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1059, 746, 598, 690, 782, 783, 762, 570, 462]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 10, 10, 12, 13, 13, 12, 11, 14]
	Time taken saving stuff: 0.01s

=== episode:222 Env-steps-taken:70656
 	picked: 74 |actions: {0: 481, 1: 670, 2: 464, 3: 451, 4: 695, 5: 544, 6: 662, 7: 815, 8: 981}
episode: 222/2000 -> reward: 114.26041666666656, steps:5763, time-taken: 3.30min, time-elasped: 655.12min
-> berries picked: 74 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6472 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1058, 751, 604, 687, 793, 785, 762, 568, 464]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 7, 10, 6, 15, 16, 19, 9, 8]
	Time taken saving stuff: 0.03s

=== episode:223 Env-steps-taken:67872
 	picked: 67 |actions: {0: 516, 1: 637, 2: 411, 3: 369, 4: 496, 5: 385, 6: 477, 7: 580, 8: 628}
episode: 223/2000 -> reward: 100.66145833333327, steps:4499, time-taken: 2.53min, time-elasped: 657.66min
-> berries picked: 67 of 800 | patches-visited: [0, 2, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6500 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1070, 752, 607, 685, 796, 786, 765, 572, 467]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 4, 12, 13, 15, 13, 12, 8, 10]
	Time taken saving stuff: 0.02s

=== episode:224 Env-steps-taken:68544
 	picked: 75 |actions: {0: 600, 1: 611, 2: 568, 3: 517, 4: 493, 5: 450, 6: 542, 7: 559, 8: 524}
episode: 224/2000 -> reward: 103.2031249999999, steps:4864, time-taken: 2.92min, time-elasped: 660.58min
-> berries picked: 75 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6518 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1068, 760, 608, 688, 799, 792, 763, 572, 468]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 17, 11, 18, 20, 13, 8, 5, 11]
	Time taken saving stuff: 0.08s

=== episode:225 Env-steps-taken:66240
 	picked: 63 |actions: {0: 330, 1: 555, 2: 503, 3: 383, 4: 483, 5: 349, 6: 622, 7: 464, 8: 598}
episode: 225/2000 -> reward: 91.89062499999996, steps:4287, time-taken: 2.61min, time-elasped: 663.19min
-> berries picked: 63 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6545 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1072, 765, 615, 689, 803, 792, 765, 572, 472]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [26, 16, 4, 10, 11, 20, 15, 12, 10]
	Time taken saving stuff: 0.10s

=== episode:226 Env-steps-taken:57312
 	picked: 33 |actions: {0: 259, 1: 338, 2: 297, 3: 286, 4: 311, 5: 338, 6: 653, 7: 297, 8: 1045}
episode: 226/2000 -> reward: 47.10937500000002, steps:3824, time-taken: 2.20min, time-elasped: 665.40min
-> berries picked: 33 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6559 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1069, 770, 616, 693, 803, 797, 768, 570, 473]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 9, 8, 12, 12, 17, 21, 11, 11]
	Time taken saving stuff: 0.02s

=== episode:227 Env-steps-taken:68448
 	picked: 67 |actions: {0: 310, 1: 514, 2: 422, 3: 360, 4: 528, 5: 398, 6: 524, 7: 464, 8: 481}
episode: 227/2000 -> reward: 103.66145833333326, steps:4001, time-taken: 2.47min, time-elasped: 667.87min
-> berries picked: 67 of 800 | patches-visited: [0, 1, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6587 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1071, 777, 622, 696, 804, 806, 768, 567, 476]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 11, 11, 17, 9, 16, 11, 11, 17]
	Time taken saving stuff: 0.10s

=== episode:228 Env-steps-taken:70656
 	picked: 82 |actions: {0: 537, 1: 634, 2: 345, 3: 419, 4: 509, 5: 534, 6: 657, 7: 574, 8: 544}
episode: 228/2000 -> reward: 114.30208333333324, steps:4753, time-taken: 4.00min, time-elasped: 671.87min
-> berries picked: 82 of 800 | patches-visited: [0, 4, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6632 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1085, 780, 626, 695, 808, 816, 773, 568, 481]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 13, 19, 14, 13, 20, 16, 9, 11]
	Time taken saving stuff: 0.01s

=== episode:229 Env-steps-taken:50208
 	picked: 7 |actions: {0: 64, 1: 56, 2: 30, 3: 31, 4: 55, 5: 52, 6: 44, 7: 41, 8: 131}
episode: 229/2000 -> reward: 10.213541666666668, steps:504, time-taken: 1.05min, time-elasped: 672.92min
-> berries picked: 7 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6634 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1086, 779, 627, 696, 807, 818, 773, 567, 481]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 15, 5, 16, 23, 5, 15, 9, 13]
	Time taken saving stuff: 0.01s

=== episode:230 Env-steps-taken:70944
 	picked: 84 |actions: {0: 419, 1: 519, 2: 478, 3: 506, 4: 566, 5: 441, 6: 544, 7: 507, 8: 760}
episode: 230/2000 -> reward: 115.68749999999983, steps:4740, time-taken: 2.83min, time-elasped: 675.76min
-> berries picked: 84 of 800 | patches-visited: [0, 3, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6675 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1093, 779, 635, 701, 820, 821, 777, 564, 485]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 10, 12, 12, 15, 13, 14, 11, 9]
	Time taken saving stuff: 0.06s

=== episode:23 Env-steps-taken:76224
 	picked: 101 |actions: {0: 429, 1: 390, 2: 85, 3: 143, 4: 296, 5: 427, 6: 218, 7: 786, 8: 765}

==================================================
eval-episode: 230 -> reward: 142.21354166666663, steps: 3539.0, wall-time: 62.79s
-> berries picked: 101 of 800 | patches-visited: [1, 2, 5] | juice left:-0.00
==================================================


=== episode:231 Env-steps-taken:74208
 	picked: 92 |actions: {0: 558, 1: 650, 2: 393, 3: 427, 4: 565, 5: 583, 6: 483, 7: 644, 8: 828}
episode: 231/2000 -> reward: 132.22916666666657, steps:5131, time-taken: 2088.60min, time-elasped: 2765.41min
-> berries picked: 92 of 800 | patches-visited: [0, 1, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6714 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1095, 784, 639, 702, 823, 832, 778, 574, 487]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 13, 9, 6, 10, 12, 9, 11, 14]
	Time taken saving stuff: 0.02s

=== episode:232 Env-steps-taken:65664
 	picked: 71 |actions: {0: 523, 1: 585, 2: 571, 3: 455, 4: 541, 5: 504, 6: 499, 7: 960, 8: 890}
episode: 232/2000 -> reward: 88.43229166666661, steps:5528, time-taken: 2.80min, time-elasped: 2768.21min
-> berries picked: 71 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6734 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1096, 785, 643, 707, 824, 832, 779, 581, 487]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 17, 14, 10, 19, 14, 19, 12, 15]
	Time taken saving stuff: 0.00s

=== episode:233 Env-steps-taken:71232
 	picked: 82 |actions: {0: 600, 1: 771, 2: 549, 3: 466, 4: 549, 5: 444, 6: 553, 7: 655, 8: 741}
episode: 233/2000 -> reward: 113.97395833333321, steps:5328, time-taken: 3.32min, time-elasped: 2771.53min
-> berries picked: 82 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6765 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1109, 792, 649, 706, 831, 831, 779, 579, 489]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 16, 7, 11, 12, 16, 17, 8, 15]
	Time taken saving stuff: 0.00s

=== episode:234 Env-steps-taken:67680
 	picked: 72 |actions: {0: 483, 1: 728, 2: 398, 3: 397, 4: 441, 5: 543, 6: 534, 7: 807, 8: 657}
episode: 234/2000 -> reward: 98.87499999999993, steps:4988, time-taken: 3.43min, time-elasped: 2774.97min
-> berries picked: 72 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6798 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1113, 798, 652, 707, 836, 836, 784, 580, 492]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 13, 13, 11, 17, 9, 17, 8, 17]
	Time taken saving stuff: 0.10s

=== episode:235 Env-steps-taken:64992
 	picked: 59 |actions: {0: 313, 1: 334, 2: 326, 3: 229, 4: 398, 5: 486, 6: 374, 7: 495, 8: 363}
episode: 235/2000 -> reward: 86.11979166666664, steps:3318, time-taken: 3.83min, time-elasped: 2778.80min
-> berries picked: 59 of 800 | patches-visited: [0, 5, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6831 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1116, 804, 650, 710, 842, 842, 786, 587, 494]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 17, 9, 9, 15, 14, 9, 10, 11]
	Time taken saving stuff: 0.15s

=== episode:236 Env-steps-taken:70560
 	picked: 73 |actions: {0: 479, 1: 577, 2: 398, 3: 401, 4: 465, 5: 458, 6: 359, 7: 505, 8: 756}
episode: 236/2000 -> reward: 112.37499999999989, steps:4398, time-taken: 3.53min, time-elasped: 2782.33min
-> berries picked: 73 of 800 | patches-visited: [0, 4, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6817 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1118, 801, 656, 714, 842, 846, 757, 585, 498]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 19, 13, 14, 13, 15, 21, 9, 19]
	Time taken saving stuff: 0.01s

=== episode:237 Env-steps-taken:74688
 	picked: 100 |actions: {0: 615, 1: 717, 2: 539, 3: 546, 4: 657, 5: 574, 6: 534, 7: 723, 8: 834}
episode: 237/2000 -> reward: 133.94270833333317, steps:5739, time-taken: 4.46min, time-elasped: 2786.80min
-> berries picked: 100 of 800 | patches-visited: [0, 5, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6826 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1114, 808, 656, 715, 850, 850, 748, 581, 504]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 16, 8, 16, 17, 14, 12, 7, 17]
	Time taken saving stuff: 0.01s

=== episode:238 Env-steps-taken:66528
 	picked: 64 |actions: {0: 388, 1: 665, 2: 450, 3: 312, 4: 524, 5: 474, 6: 527, 7: 583, 8: 654}
episode: 238/2000 -> reward: 93.33333333333329, steps:4577, time-taken: 3.47min, time-elasped: 2790.27min
-> berries picked: 64 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6834 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1117, 814, 657, 715, 852, 851, 742, 578, 508]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 16, 13, 13, 21, 12, 17, 8, 12]
	Time taken saving stuff: 0.03s

=== episode:239 Env-steps-taken:60768
 	picked: 39 |actions: {0: 277, 1: 268, 2: 158, 3: 191, 4: 244, 5: 335, 6: 213, 7: 319, 8: 318}
episode: 239/2000 -> reward: 65.26562500000004, steps:2323, time-taken: 1.87min, time-elasped: 2792.15min
-> berries picked: 39 of 800 | patches-visited: [0, 4, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6841 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1120, 819, 656, 720, 851, 853, 738, 574, 510]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 22, 8, 13, 10, 21, 6, 10, 15]
	Time taken saving stuff: 0.01s

=== episode:240 Env-steps-taken:68352
 	picked: 77 |actions: {0: 414, 1: 612, 2: 396, 3: 356, 4: 599, 5: 523, 6: 686, 7: 647, 8: 593}
episode: 240/2000 -> reward: 102.0885416666666, steps:4826, time-taken: 3.51min, time-elasped: 2795.66min
-> berries picked: 77 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6869 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1125, 827, 661, 723, 858, 860, 735, 570, 510]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 16, 15, 16, 14, 11, 15, 12, 17]
	Time taken saving stuff: 0.07s

=== episode:24 Env-steps-taken:85056
 	picked: 141 |actions: {0: 447, 1: 1214, 2: 293, 3: 257, 4: 661, 5: 357, 6: 578, 7: 1034, 8: 1181}

==================================================
eval-episode: 240 -> reward: 185.92187500000026, steps: 6022.0, wall-time: 99.79s
-> berries picked: 141 of 800 | patches-visited: [1, 2, 5] | juice left:-0.00
==================================================


=== episode:241 Env-steps-taken:55392
 	picked: 26 |actions: {0: 120, 1: 126, 2: 65, 3: 88, 4: 80, 5: 94, 6: 84, 7: 146, 8: 177}
episode: 241/2000 -> reward: 37.01041666666667, steps:980, time-taken: 1.22min, time-elasped: 2798.55min
-> berries picked: 26 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6870 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1124, 827, 660, 722, 860, 864, 735, 568, 510]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 10, 7, 11, 16, 12, 14, 6, 13]
	Time taken saving stuff: 0.01s

=== episode:242 Env-steps-taken:67392
 	picked: 71 |actions: {0: 459, 1: 519, 2: 404, 3: 329, 4: 418, 5: 434, 6: 465, 7: 759, 8: 567}
episode: 242/2000 -> reward: 97.43229166666659, steps:4354, time-taken: 3.22min, time-elasped: 2801.77min
-> berries picked: 71 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6906 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1126, 838, 665, 722, 869, 866, 736, 573, 511]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 10, 9, 16, 11, 23, 12, 9, 15]
	Time taken saving stuff: 0.02s

=== episode:243 Env-steps-taken:49632
 	picked: 7 |actions: {0: 18, 1: 29, 2: 27, 3: 53, 4: 73, 5: 59, 6: 47, 7: 22, 8: 170}
episode: 243/2000 -> reward: 8.09895833333333, steps:498, time-taken: 0.88min, time-elasped: 2802.66min
-> berries picked: 7 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6908 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1125, 838, 667, 723, 871, 864, 736, 573, 511]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [28, 11, 6, 18, 16, 25, 10, 8, 7]
	Time taken saving stuff: 0.01s

=== episode:244 Env-steps-taken:65568
 	picked: 66 |actions: {0: 559, 1: 620, 2: 376, 3: 328, 4: 495, 5: 372, 6: 344, 7: 660, 8: 544}
episode: 244/2000 -> reward: 87.2760416666666, steps:4298, time-taken: 2.97min, time-elasped: 2805.64min
-> berries picked: 66 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6926 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1131, 843, 668, 724, 873, 867, 734, 574, 512]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [24, 15, 13, 13, 21, 7, 11, 7, 15]
	Time taken saving stuff: 0.03s

=== episode:245 Env-steps-taken:68736
 	picked: 77 |actions: {0: 540, 1: 645, 2: 497, 3: 443, 4: 535, 5: 528, 6: 388, 7: 571, 8: 613}
episode: 245/2000 -> reward: 104.58854166666653, steps:4760, time-taken: 3.07min, time-elasped: 2808.71min
-> berries picked: 77 of 800 | patches-visited: [0, 5, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6962 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1140, 847, 667, 728, 874, 878, 734, 579, 515]
	| approx positives in sample 512: 101
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 7, 8, 9, 16, 16, 16, 4, 10]
	Time taken saving stuff: 0.09s

=== episode:246 Env-steps-taken:64608
 	picked: 58 |actions: {0: 351, 1: 497, 2: 372, 3: 389, 4: 411, 5: 419, 6: 363, 7: 393, 8: 557}
episode: 246/2000 -> reward: 82.79166666666664, steps:3752, time-taken: 2.92min, time-elasped: 2811.63min
-> berries picked: 58 of 800 | patches-visited: [0, 8, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6966 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1137, 850, 663, 732, 872, 885, 733, 577, 517]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 15, 8, 14, 15, 13, 10, 16, 8]
	Time taken saving stuff: 0.02s

=== episode:247 Env-steps-taken:71520
 	picked: 84 |actions: {0: 605, 1: 890, 2: 534, 3: 479, 4: 597, 5: 615, 6: 544, 7: 810, 8: 770}
episode: 247/2000 -> reward: 118.18749999999984, steps:5844, time-taken: 3.76min, time-elasped: 2815.40min
-> berries picked: 84 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6958 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1135, 851, 662, 724, 880, 888, 730, 566, 522]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [23, 8, 9, 22, 16, 12, 13, 11, 15]
	Time taken saving stuff: 0.03s

=== episode:248 Env-steps-taken:71136
 	picked: 81 |actions: {0: 517, 1: 661, 2: 336, 3: 403, 4: 488, 5: 451, 6: 465, 7: 574, 8: 540}
episode: 248/2000 -> reward: 116.3593749999999, steps:4435, time-taken: 3.22min, time-elasped: 2818.63min
-> berries picked: 81 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6979 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1144, 855, 656, 727, 883, 890, 731, 570, 523]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 11, 10, 10, 19, 8, 18, 3, 12]
	Time taken saving stuff: 0.03s

=== episode:249 Env-steps-taken:61344
 	picked: 53 |actions: {0: 472, 1: 693, 2: 375, 3: 326, 4: 494, 5: 424, 6: 379, 7: 607, 8: 664}
episode: 249/2000 -> reward: 66.96354166666669, steps:4434, time-taken: 3.26min, time-elasped: 2821.89min
-> berries picked: 53 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6980 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1144, 851, 655, 726, 894, 890, 731, 566, 523]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [24, 22, 9, 18, 16, 10, 12, 11, 10]
	Time taken saving stuff: 0.10s

=== episode:250 Env-steps-taken:68256
 	picked: 80 |actions: {0: 639, 1: 729, 2: 469, 3: 366, 4: 530, 5: 499, 6: 468, 7: 705, 8: 690}
episode: 250/2000 -> reward: 101.9166666666666, steps:5095, time-taken: 3.90min, time-elasped: 2825.80min
-> berries picked: 80 of 800 | patches-visited: [0, 4, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6995 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1154, 854, 653, 723, 898, 894, 728, 564, 527]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 9, 11, 13, 21, 16, 9, 7, 12]
	Time taken saving stuff: 0.12s

=== episode:25 Env-steps-taken:77952
 	picked: 104 |actions: {0: 513, 1: 231, 2: 123, 3: 99, 4: 297, 5: 465, 6: 364, 7: 499, 8: 1089}

==================================================
eval-episode: 250 -> reward: 149.65624999999997, steps: 3680.0, wall-time: 74.25s
-> berries picked: 104 of 800 | patches-visited: [1, 4, 5, 7] | juice left:-0.00
==================================================


=== episode:251 Env-steps-taken:70560
 	picked: 80 |actions: {0: 702, 1: 713, 2: 566, 3: 526, 4: 592, 5: 492, 6: 433, 7: 564, 8: 738}
episode: 251/2000 -> reward: 111.97395833333321, steps:5326, time-taken: 5.65min, time-elasped: 2832.70min
-> berries picked: 80 of 800 | patches-visited: [0, 1, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6992 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1155, 860, 653, 724, 890, 899, 723, 556, 532]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 19, 3, 14, 13, 15, 11, 13, 11]
	Time taken saving stuff: 0.02s

=== episode:252 Env-steps-taken:59232
 	picked: 47 |actions: {0: 275, 1: 367, 2: 181, 3: 242, 4: 379, 5: 250, 6: 243, 7: 390, 8: 374}
episode: 252/2000 -> reward: 55.421875000000036, steps:2701, time-taken: 2.56min, time-elasped: 2835.26min
-> berries picked: 47 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6973 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1158, 864, 648, 723, 888, 896, 719, 542, 535]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 12, 11, 15, 22, 13, 8, 4, 10]
	Time taken saving stuff: 0.03s

=== episode:253 Env-steps-taken:59136
 	picked: 44 |actions: {0: 266, 1: 240, 2: 200, 3: 277, 4: 409, 5: 271, 6: 205, 7: 339, 8: 257}
episode: 253/2000 -> reward: 55.479166666666714, steps:2464, time-taken: 2.47min, time-elasped: 2837.73min
-> berries picked: 44 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 6987 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1159, 863, 653, 724, 893, 901, 713, 544, 537]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [23, 13, 7, 23, 10, 19, 14, 12, 10]
	Time taken saving stuff: 0.03s

=== episode:254 Env-steps-taken:70080
 	picked: 80 |actions: {0: 513, 1: 637, 2: 551, 3: 471, 4: 519, 5: 602, 6: 338, 7: 652, 8: 453}
episode: 254/2000 -> reward: 111.41666666666654, steps:4736, time-taken: 3.73min, time-elasped: 2841.46min
-> berries picked: 80 of 800 | patches-visited: [0, 6, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7000 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1152, 867, 650, 730, 895, 902, 711, 550, 543]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 11, 6, 10, 15, 19, 15, 12, 10]
	Time taken saving stuff: 0.00s

=== episode:255 Env-steps-taken:60576
 	picked: 47 |actions: {0: 277, 1: 495, 2: 295, 3: 296, 4: 349, 5: 360, 6: 338, 7: 345, 8: 526}
episode: 255/2000 -> reward: 63.307291666666714, steps:3281, time-taken: 2.86min, time-elasped: 2844.33min
-> berries picked: 47 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7008 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1158, 868, 649, 729, 894, 901, 717, 547, 545]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 14, 13, 12, 14, 6, 8, 15, 11]
	Time taken saving stuff: 0.09s

=== episode:256 Env-steps-taken:61824
 	picked: 51 |actions: {0: 325, 1: 267, 2: 281, 3: 337, 4: 389, 5: 356, 6: 394, 7: 262, 8: 531}
episode: 256/2000 -> reward: 70.07812500000003, steps:3142, time-taken: 2.60min, time-elasped: 2846.94min
-> berries picked: 51 of 800 | patches-visited: [0, 4, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7015 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1157, 863, 651, 734, 891, 907, 717, 548, 547]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 13, 10, 9, 12, 16, 12, 5, 8]
	Time taken saving stuff: 0.08s

=== episode:257 Env-steps-taken:72288
 	picked: 86 |actions: {0: 676, 1: 603, 2: 458, 3: 520, 4: 632, 5: 655, 6: 567, 7: 833, 8: 714}
episode: 257/2000 -> reward: 122.07291666666653, steps:5658, time-taken: 3.85min, time-elasped: 2850.79min
-> berries picked: 86 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7022 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1161, 863, 645, 729, 891, 914, 721, 550, 548]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [26, 19, 7, 10, 17, 12, 15, 12, 5]
	Time taken saving stuff: 0.00s

=== episode:258 Env-steps-taken:63168
 	picked: 59 |actions: {0: 421, 1: 410, 2: 393, 3: 444, 4: 474, 5: 447, 6: 352, 7: 532, 8: 727}
episode: 258/2000 -> reward: 74.734375, steps:4200, time-taken: 2.88min, time-elasped: 2853.67min
-> berries picked: 59 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7037 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1159, 866, 643, 733, 896, 920, 724, 548, 548]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 15, 10, 11, 15, 15, 9, 5, 16]
	Time taken saving stuff: 0.11s

=== episode:259 Env-steps-taken:57120
 	picked: 40 |actions: {0: 260, 1: 484, 2: 319, 3: 227, 4: 330, 5: 271, 6: 239, 7: 408, 8: 563}
episode: 259/2000 -> reward: 45.765625000000036, steps:3101, time-taken: 2.51min, time-elasped: 2856.19min
-> berries picked: 40 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7036 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1156, 867, 645, 730, 895, 924, 725, 545, 549]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 11, 7, 9, 16, 19, 16, 12, 13]
	Time taken saving stuff: 0.01s

=== episode:260 Env-steps-taken:70080
 	picked: 75 |actions: {0: 481, 1: 570, 2: 371, 3: 338, 4: 463, 5: 459, 6: 369, 7: 618, 8: 500}
episode: 260/2000 -> reward: 110.81770833333321, steps:4169, time-taken: 2.85min, time-elasped: 2859.04min
-> berries picked: 75 of 800 | patches-visited: [0, 5, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7060 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1159, 874, 645, 734, 891, 930, 726, 546, 555]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [25, 14, 5, 10, 11, 17, 13, 13, 11]
	Time taken saving stuff: 0.10s

=== episode:26 Env-steps-taken:73728
 	picked: 88 |actions: {0: 269, 1: 805, 2: 284, 3: 207, 4: 252, 5: 379, 6: 115, 7: 574, 8: 989}

==================================================
eval-episode: 260 -> reward: 129.9583333333332, steps: 3874.0, wall-time: 68.70s
-> berries picked: 88 of 800 | patches-visited: [0, 1, 3] | juice left:-0.00
==================================================


=== episode:261 Env-steps-taken:64320
 	picked: 57 |actions: {0: 453, 1: 570, 2: 531, 3: 429, 4: 468, 5: 474, 6: 473, 7: 905, 8: 824}
episode: 261/2000 -> reward: 82.73437499999999, steps:5127, time-taken: 3.39min, time-elasped: 2863.59min
-> berries picked: 57 of 800 | patches-visited: [0, 4, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7074 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1156, 881, 648, 731, 887, 931, 732, 551, 557]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 13, 6, 17, 13, 19, 18, 8, 13]
	Time taken saving stuff: 0.08s

=== episode:262 Env-steps-taken:60384
 	picked: 42 |actions: {0: 366, 1: 592, 2: 304, 3: 257, 4: 286, 5: 278, 6: 248, 7: 693, 8: 494}
episode: 262/2000 -> reward: 62.59375000000005, steps:3518, time-taken: 2.58min, time-elasped: 2866.18min
-> berries picked: 42 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7088 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1160, 881, 650, 731, 889, 934, 729, 556, 558]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 12, 9, 14, 14, 11, 8, 10, 16]
	Time taken saving stuff: 0.00s

=== episode:263 Env-steps-taken:64704
 	picked: 59 |actions: {0: 336, 1: 535, 2: 397, 3: 412, 4: 460, 5: 612, 6: 361, 7: 655, 8: 650}
episode: 263/2000 -> reward: 84.61979166666663, steps:4418, time-taken: 2.94min, time-elasped: 2869.12min
-> berries picked: 59 of 800 | patches-visited: [0, 3, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7107 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1156, 884, 650, 736, 895, 938, 733, 554, 561]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [24, 12, 13, 17, 18, 13, 8, 7, 13]
	Time taken saving stuff: 0.10s

=== episode:264 Env-steps-taken:62400
 	picked: 53 |actions: {0: 424, 1: 446, 2: 390, 3: 380, 4: 395, 5: 335, 6: 357, 7: 672, 8: 650}
episode: 264/2000 -> reward: 72.96354166666669, steps:4049, time-taken: 3.05min, time-elasped: 2872.17min
-> berries picked: 53 of 800 | patches-visited: [0, 3, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7136 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1163, 886, 659, 739, 895, 932, 739, 558, 565]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 13, 6, 13, 17, 20, 11, 8, 20]
	Time taken saving stuff: 0.09s

=== episode:265 Env-steps-taken:63840
 	picked: 61 |actions: {0: 392, 1: 453, 2: 345, 3: 372, 4: 536, 5: 511, 6: 322, 7: 697, 8: 415}
episode: 265/2000 -> reward: 79.00520833333331, steps:4043, time-taken: 2.97min, time-elasped: 2875.15min
-> berries picked: 61 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7159 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1168, 887, 658, 740, 898, 941, 743, 558, 566]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 14, 11, 17, 17, 16, 13, 12, 12]
	Time taken saving stuff: 0.01s

=== episode:266 Env-steps-taken:64416
 	picked: 68 |actions: {0: 674, 1: 614, 2: 475, 3: 380, 4: 537, 5: 506, 6: 411, 7: 768, 8: 694}
episode: 266/2000 -> reward: 81.60416666666663, steps:5059, time-taken: 3.32min, time-elasped: 2878.47min
-> berries picked: 68 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7184 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1172, 893, 662, 747, 897, 948, 738, 561, 566]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [26, 20, 8, 14, 10, 9, 13, 14, 14]
	Time taken saving stuff: 0.02s

=== episode:267 Env-steps-taken:68064
 	picked: 71 |actions: {0: 592, 1: 609, 2: 535, 3: 382, 4: 434, 5: 473, 6: 345, 7: 717, 8: 929}
episode: 267/2000 -> reward: 100.9322916666666, steps:5016, time-taken: 3.51min, time-elasped: 2881.99min
-> berries picked: 71 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7217 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1181, 892, 666, 750, 899, 952, 737, 572, 568]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 17, 17, 11, 19, 23, 13, 7, 9]
	Time taken saving stuff: 0.10s

=== episode:268 Env-steps-taken:77760
 	picked: 102 |actions: {0: 629, 1: 644, 2: 545, 3: 607, 4: 790, 5: 643, 6: 610, 7: 814, 8: 615}
episode: 268/2000 -> reward: 149.65625, steps:5897, time-taken: 4.28min, time-elasped: 2886.27min
-> berries picked: 102 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7274 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1188, 899, 672, 757, 908, 958, 744, 578, 570]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 19, 8, 17, 19, 9, 13, 9, 10]
	Time taken saving stuff: 0.04s

=== episode:269 Env-steps-taken:69216
 	picked: 78 |actions: {0: 508, 1: 491, 2: 417, 3: 395, 4: 582, 5: 505, 6: 374, 7: 464, 8: 368}
episode: 269/2000 -> reward: 107.0312499999999, steps:4104, time-taken: 3.36min, time-elasped: 2889.64min
-> berries picked: 78 of 800 | patches-visited: [0, 2, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7308 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1191, 901, 682, 754, 917, 964, 741, 583, 575]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [25, 16, 9, 14, 15, 23, 17, 6, 17]
	Time taken saving stuff: 0.02s

=== episode:270 Env-steps-taken:64032
 	picked: 64 |actions: {0: 393, 1: 389, 2: 401, 3: 341, 4: 423, 5: 383, 6: 374, 7: 609, 8: 540}
episode: 270/2000 -> reward: 80.33333333333331, steps:3853, time-taken: 2.94min, time-elasped: 2892.58min
-> berries picked: 64 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7348 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1195, 908, 686, 760, 920, 964, 751, 587, 577]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [27, 16, 8, 6, 15, 15, 13, 3, 16]
	Time taken saving stuff: 0.09s

=== episode:27 Env-steps-taken:88800
 	picked: 144 |actions: {0: 653, 1: 586, 2: 309, 3: 443, 4: 573, 5: 356, 6: 303, 7: 839, 8: 942}

==================================================
eval-episode: 270 -> reward: 204.36458333333368, steps: 5004.0, wall-time: 88.95s
-> berries picked: 144 of 800 | patches-visited: [0, 1, 8] | juice left:-0.00
==================================================


=== episode:271 Env-steps-taken:65088
 	picked: 63 |actions: {0: 494, 1: 405, 2: 395, 3: 384, 4: 480, 5: 367, 6: 420, 7: 527, 8: 625}
episode: 271/2000 -> reward: 85.89062499999999, steps:4097, time-taken: 3.09min, time-elasped: 2897.16min
-> berries picked: 63 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7365 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1196, 909, 689, 757, 924, 969, 756, 588, 577]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 12, 12, 10, 9, 12, 10, 10, 10]
	Time taken saving stuff: 0.07s

=== episode:272 Env-steps-taken:60960
 	picked: 43 |actions: {0: 284, 1: 366, 2: 222, 3: 273, 4: 336, 5: 311, 6: 215, 7: 359, 8: 379}
episode: 272/2000 -> reward: 63.651041666666714, steps:2745, time-taken: 2.16min, time-elasped: 2899.33min
-> berries picked: 43 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7375 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1200, 909, 689, 757, 925, 970, 760, 585, 580]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 15, 11, 17, 17, 15, 10, 12, 16]
	Time taken saving stuff: 0.03s

=== episode:273 Env-steps-taken:59136
 	picked: 42 |actions: {0: 247, 1: 324, 2: 214, 3: 271, 4: 289, 5: 242, 6: 258, 7: 252, 8: 384}
episode: 273/2000 -> reward: 56.093750000000036, steps:2481, time-taken: 1.87min, time-elasped: 2901.20min
-> berries picked: 42 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7393 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1200, 911, 688, 761, 930, 973, 762, 587, 581]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [27, 11, 13, 10, 17, 12, 13, 10, 10]
	Time taken saving stuff: 0.03s

=== episode:274 Env-steps-taken:70560
 	picked: 80 |actions: {0: 599, 1: 571, 2: 524, 3: 515, 4: 771, 5: 573, 6: 461, 7: 757, 8: 704}
episode: 274/2000 -> reward: 113.91666666666654, steps:5475, time-taken: 3.62min, time-elasped: 2904.83min
-> berries picked: 80 of 800 | patches-visited: [0, 6, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7413 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1205, 912, 688, 757, 933, 980, 766, 584, 588]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 19, 8, 16, 14, 14, 21, 9, 11]
	Time taken saving stuff: 0.03s

=== episode:275 Env-steps-taken:55200
 	picked: 26 |actions: {0: 146, 1: 157, 2: 100, 3: 106, 4: 187, 5: 179, 6: 165, 7: 195, 8: 468}
episode: 275/2000 -> reward: 37.01041666666667, steps:1703, time-taken: 1.49min, time-elasped: 2906.32min
-> berries picked: 26 of 800 | patches-visited: [0, 4, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7426 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1207, 914, 688, 757, 935, 984, 768, 585, 588]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 13, 15, 9, 16, 16, 17, 10, 12]
	Time taken saving stuff: 0.02s

=== episode:276 Env-steps-taken:66144
 	picked: 70 |actions: {0: 382, 1: 481, 2: 303, 3: 404, 4: 397, 5: 360, 6: 502, 7: 485, 8: 598}
episode: 276/2000 -> reward: 90.98958333333326, steps:3912, time-taken: 2.83min, time-elasped: 2909.16min
-> berries picked: 70 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7429 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1205, 909, 681, 756, 938, 988, 778, 583, 591]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [24, 13, 14, 11, 11, 19, 14, 10, 15]
	Time taken saving stuff: 0.03s

=== episode:277 Env-steps-taken:64416
 	picked: 64 |actions: {0: 576, 1: 486, 2: 370, 3: 378, 4: 535, 5: 416, 6: 351, 7: 511, 8: 391}
episode: 277/2000 -> reward: 81.94791666666664, steps:4014, time-taken: 2.97min, time-elasped: 2912.13min
-> berries picked: 64 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7429 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1207, 902, 671, 758, 941, 992, 777, 588, 593]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [23, 6, 12, 15, 15, 21, 14, 15, 13]
	Time taken saving stuff: 0.11s

=== episode:278 Env-steps-taken:67104
 	picked: 67 |actions: {0: 471, 1: 447, 2: 361, 3: 350, 4: 442, 5: 475, 6: 482, 7: 688, 8: 842}
episode: 278/2000 -> reward: 96.66145833333326, steps:4558, time-taken: 3.08min, time-elasped: 2915.22min
-> berries picked: 67 of 800 | patches-visited: [0, 3, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7446 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1210, 899, 667, 757, 942, 997, 781, 591, 602]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 13, 10, 11, 12, 11, 12, 12, 15]
	Time taken saving stuff: 0.08s

=== episode:279 Env-steps-taken:67968
 	picked: 71 |actions: {0: 543, 1: 578, 2: 422, 3: 409, 4: 531, 5: 397, 6: 382, 7: 476, 8: 578}
episode: 279/2000 -> reward: 100.43229166666657, steps:4316, time-taken: 3.28min, time-elasped: 2918.51min
-> berries picked: 71 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7482 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1216, 901, 667, 768, 944, 1003, 785, 594, 604]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 12, 12, 10, 14, 13, 19, 16, 8]
	Time taken saving stuff: 0.00s

=== episode:280 Env-steps-taken:67968
 	picked: 69 |actions: {0: 331, 1: 425, 2: 390, 3: 489, 4: 558, 5: 340, 6: 276, 7: 571, 8: 365}
episode: 280/2000 -> reward: 100.54687499999996, steps:3745, time-taken: 2.79min, time-elasped: 2921.31min
-> berries picked: 69 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7506 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1222, 896, 669, 769, 956, 1003, 788, 598, 605]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 10, 11, 7, 20, 16, 15, 9, 16]
	Time taken saving stuff: 0.17s

=== episode:28 Env-steps-taken:61248
 	picked: 48 |actions: {0: 149, 1: 188, 2: 55, 3: 28, 4: 184, 5: 146, 6: 145, 7: 335, 8: 334}

==================================================
eval-episode: 280 -> reward: 66.75000000000004, steps: 1564.0, wall-time: 52.43s
-> berries picked: 48 of 800 | patches-visited: [1, 3] | juice left:-0.00
==================================================


=== episode:281 Env-steps-taken:70080
 	picked: 84 |actions: {0: 663, 1: 617, 2: 397, 3: 407, 4: 592, 5: 599, 6: 490, 7: 803, 8: 696}
episode: 281/2000 -> reward: 110.68749999999987, steps:5264, time-taken: 3.61min, time-elasped: 2925.80min
-> berries picked: 84 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7530 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1227, 905, 672, 771, 953, 1003, 792, 600, 607]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 16, 11, 13, 14, 17, 11, 11, 13]
	Time taken saving stuff: 0.01s

=== episode:282 Env-steps-taken:62592
 	picked: 51 |actions: {0: 409, 1: 393, 2: 284, 3: 332, 4: 479, 5: 327, 6: 233, 7: 596, 8: 378}
episode: 282/2000 -> reward: 73.07812500000004, steps:3431, time-taken: 2.72min, time-elasped: 2928.53min
-> berries picked: 51 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7551 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1229, 907, 677, 776, 950, 1005, 794, 606, 607]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [23, 9, 6, 12, 15, 16, 14, 9, 12]
	Time taken saving stuff: 0.01s

=== episode:283 Env-steps-taken:64128
 	picked: 57 |actions: {0: 402, 1: 361, 2: 306, 3: 267, 4: 342, 5: 328, 6: 293, 7: 413, 8: 383}
episode: 283/2000 -> reward: 81.23437499999999, steps:3095, time-taken: 2.28min, time-elasped: 2930.81min
-> berries picked: 57 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7576 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1238, 908, 685, 780, 950, 1004, 794, 606, 611]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 21, 16, 7, 16, 13, 12, 10, 13]
	Time taken saving stuff: 0.01s

=== episode:284 Env-steps-taken:68928
 	picked: 75 |actions: {0: 439, 1: 435, 2: 452, 3: 401, 4: 551, 5: 387, 6: 307, 7: 624, 8: 458}
episode: 284/2000 -> reward: 105.70312499999993, steps:4054, time-taken: 3.15min, time-elasped: 2933.97min
-> berries picked: 75 of 800 | patches-visited: [0, 3, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7620 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1240, 909, 697, 784, 955, 1009, 803, 607, 616]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 18, 9, 24, 8, 13, 21, 15, 8]
	Time taken saving stuff: 0.00s

=== episode:285 Env-steps-taken:76320
 	picked: 106 |actions: {0: 678, 1: 640, 2: 530, 3: 591, 4: 721, 5: 692, 6: 528, 7: 1138, 8: 642}
episode: 285/2000 -> reward: 142.42708333333326, steps:6160, time-taken: 4.11min, time-elasped: 2938.08min
-> berries picked: 106 of 800 | patches-visited: [0, 5, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7665 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1244, 917, 698, 795, 957, 1016, 810, 610, 618]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [27, 14, 6, 12, 17, 10, 11, 9, 11]
	Time taken saving stuff: 0.10s

=== episode:286 Env-steps-taken:55488
 	picked: 28 |actions: {0: 198, 1: 230, 2: 184, 3: 160, 4: 229, 5: 311, 6: 237, 7: 384, 8: 228}
episode: 286/2000 -> reward: 37.39583333333334, steps:2161, time-taken: 1.89min, time-elasped: 2939.97min
-> berries picked: 28 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7666 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1246, 918, 696, 791, 954, 1020, 811, 611, 619]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 18, 9, 9, 9, 14, 19, 9, 13]
	Time taken saving stuff: 0.02s

=== episode:287 Env-steps-taken:63840
 	picked: 63 |actions: {0: 406, 1: 475, 2: 366, 3: 465, 4: 519, 5: 366, 6: 331, 7: 864, 8: 635}
episode: 287/2000 -> reward: 79.39062499999999, steps:4427, time-taken: 2.97min, time-elasped: 2942.94min
-> berries picked: 63 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7688 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1250, 921, 700, 788, 952, 1024, 815, 613, 625]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 14, 10, 17, 10, 19, 10, 14, 6]
	Time taken saving stuff: 0.04s

=== episode:288 Env-steps-taken:63936
 	picked: 53 |actions: {0: 395, 1: 371, 2: 263, 3: 274, 4: 336, 5: 330, 6: 343, 7: 393, 8: 299}
episode: 288/2000 -> reward: 80.96354166666666, steps:3004, time-taken: 2.40min, time-elasped: 2945.35min
-> berries picked: 53 of 800 | patches-visited: [0, 5, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7709 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1256, 925, 698, 789, 951, 1027, 818, 618, 627]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 15, 10, 15, 18, 19, 12, 10, 9]
	Time taken saving stuff: 0.01s

=== episode:289 Env-steps-taken:59616
 	picked: 39 |actions: {0: 224, 1: 247, 2: 248, 3: 193, 4: 256, 5: 184, 6: 126, 7: 346, 8: 249}
episode: 289/2000 -> reward: 58.76562500000004, steps:2073, time-taken: 1.78min, time-elasped: 2947.13min
-> berries picked: 39 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7722 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1257, 924, 702, 797, 955, 1027, 817, 615, 628]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 14, 13, 11, 18, 20, 9, 8, 17]
	Time taken saving stuff: 0.00s

=== episode:290 Env-steps-taken:64704
 	picked: 55 |actions: {0: 281, 1: 328, 2: 278, 3: 328, 4: 342, 5: 375, 6: 287, 7: 449, 8: 310}
episode: 290/2000 -> reward: 84.84895833333331, steps:2978, time-taken: 2.41min, time-elasped: 2949.54min
-> berries picked: 55 of 800 | patches-visited: [0, 1, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7756 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1260, 929, 702, 804, 960, 1029, 822, 617, 633]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [23, 10, 15, 14, 17, 14, 16, 7, 13]
	Time taken saving stuff: 0.10s

=== episode:29 Env-steps-taken:60768
 	picked: 47 |actions: {0: 116, 1: 282, 2: 91, 3: 83, 4: 86, 5: 137, 6: 85, 7: 383, 8: 465}

==================================================
eval-episode: 290 -> reward: 64.30729166666671, steps: 1728.0, wall-time: 64.97s
-> berries picked: 47 of 800 | patches-visited: [1, 7] | juice left:-0.00
==================================================


=== episode:291 Env-steps-taken:72000
 	picked: 87 |actions: {0: 664, 1: 528, 2: 451, 3: 603, 4: 641, 5: 744, 6: 477, 7: 991, 8: 804}
episode: 291/2000 -> reward: 120.13020833333319, steps:5903, time-taken: 3.94min, time-elasped: 2954.57min
-> berries picked: 87 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7785 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1260, 935, 705, 807, 956, 1038, 830, 621, 633]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [26, 12, 7, 10, 13, 17, 9, 19, 22]
	Time taken saving stuff: 0.08s

=== episode:292 Env-steps-taken:67008
 	picked: 75 |actions: {0: 568, 1: 640, 2: 371, 3: 433, 4: 658, 5: 653, 6: 616, 7: 1014, 8: 785}
episode: 292/2000 -> reward: 94.70312499999993, steps:5738, time-taken: 3.98min, time-elasped: 2958.56min
-> berries picked: 75 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7809 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1262, 940, 705, 810, 963, 1042, 831, 622, 634]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 13, 8, 18, 15, 16, 13, 5, 7]
	Time taken saving stuff: 0.02s

=== episode:293 Env-steps-taken:67200
 	picked: 66 |actions: {0: 484, 1: 465, 2: 339, 3: 336, 4: 427, 5: 476, 6: 322, 7: 815, 8: 722}
episode: 293/2000 -> reward: 96.71874999999996, steps:4386, time-taken: 3.38min, time-elasped: 2961.94min
-> berries picked: 66 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7829 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1260, 941, 704, 811, 970, 1044, 836, 626, 637]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [28, 14, 11, 8, 23, 16, 9, 11, 12]
	Time taken saving stuff: 0.01s

=== episode:294 Env-steps-taken:68640
 	picked: 72 |actions: {0: 412, 1: 485, 2: 337, 3: 291, 4: 407, 5: 423, 6: 314, 7: 635, 8: 504}
episode: 294/2000 -> reward: 103.87499999999991, steps:3808, time-taken: 2.94min, time-elasped: 2964.88min
-> berries picked: 72 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7867 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1263, 952, 708, 815, 973, 1052, 833, 632, 639]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 23, 13, 19, 17, 19, 12, 10, 13]
	Time taken saving stuff: 0.09s

=== episode:295 Env-steps-taken:73632
 	picked: 95 |actions: {0: 626, 1: 603, 2: 567, 3: 641, 4: 617, 5: 693, 6: 570, 7: 1034, 8: 585}
episode: 295/2000 -> reward: 129.11458333333314, steps:5936, time-taken: 4.14min, time-elasped: 2969.03min
-> berries picked: 95 of 800 | patches-visited: [0, 4, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7920 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1268, 958, 711, 823, 978, 1063, 837, 636, 646]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 19, 13, 20, 14, 9, 17, 11, 10]
	Time taken saving stuff: 0.03s

=== episode:296 Env-steps-taken:55200
 	picked: 27 |actions: {0: 140, 1: 133, 2: 142, 3: 180, 4: 175, 5: 198, 6: 121, 7: 186, 8: 270}
episode: 296/2000 -> reward: 35.95312500000001, steps:1545, time-taken: 1.39min, time-elasped: 2970.42min
-> berries picked: 27 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7922 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1264, 957, 710, 822, 984, 1064, 840, 634, 647]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 17, 14, 17, 15, 15, 25, 11, 10]
	Time taken saving stuff: 0.02s

=== episode:297 Env-steps-taken:72288
 	picked: 90 |actions: {0: 454, 1: 718, 2: 489, 3: 503, 4: 764, 5: 448, 6: 387, 7: 844, 8: 496}
episode: 297/2000 -> reward: 122.34374999999984, steps:5103, time-taken: 3.56min, time-elasped: 2973.99min
-> berries picked: 90 of 800 | patches-visited: [0, 2, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7965 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1263, 964, 710, 828, 996, 1076, 840, 639, 649]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 13, 17, 9, 14, 13, 12, 12, 9]
	Time taken saving stuff: 0.10s

=== episode:298 Env-steps-taken:67296
 	picked: 73 |actions: {0: 423, 1: 492, 2: 348, 3: 427, 4: 499, 5: 466, 6: 318, 7: 517, 8: 569}
episode: 298/2000 -> reward: 95.43229166666661, steps:4059, time-taken: 2.81min, time-elasped: 2976.81min
-> berries picked: 73 of 800 | patches-visited: [0, 2, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 7996 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1262, 968, 715, 836, 996, 1083, 841, 645, 650]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 10, 15, 8, 12, 12, 6, 12, 17]
	Time taken saving stuff: 0.03s

=== episode:299 Env-steps-taken:69984
 	picked: 76 |actions: {0: 490, 1: 442, 2: 467, 3: 455, 4: 510, 5: 560, 6: 431, 7: 708, 8: 531}
episode: 299/2000 -> reward: 109.20312499999993, steps:4594, time-taken: 3.39min, time-elasped: 2980.20min
-> berries picked: 76 of 800 | patches-visited: [0, 2, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8032 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1273, 971, 720, 835, 1001, 1082, 850, 648, 652]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [23, 9, 9, 20, 14, 16, 10, 12, 15]
	Time taken saving stuff: 0.08s

=== episode:300 Env-steps-taken:68352
 	picked: 76 |actions: {0: 496, 1: 538, 2: 384, 3: 382, 4: 460, 5: 459, 6: 298, 7: 571, 8: 524}
episode: 300/2000 -> reward: 102.6458333333332, steps:4112, time-taken: 3.01min, time-elasped: 2983.22min
-> berries picked: 76 of 800 | patches-visited: [0, 3, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8067 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1276, 980, 721, 842, 1006, 1082, 853, 651, 656]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 18, 11, 17, 11, 18, 17, 7, 12]
	Time taken saving stuff: 0.17s

=== episode:30 Env-steps-taken:81984
 	picked: 137 |actions: {0: 568, 1: 448, 2: 275, 3: 449, 4: 492, 5: 299, 6: 427, 7: 848, 8: 896}

==================================================
eval-episode: 300 -> reward: 169.6510416666668, steps: 4702.0, wall-time: 62.64s
-> berries picked: 137 of 800 | patches-visited: [1, 2] | juice left:-0.00
==================================================


=== episode:301 Env-steps-taken:62304
 	picked: 47 |actions: {0: 347, 1: 324, 2: 229, 3: 302, 4: 255, 5: 300, 6: 229, 7: 342, 8: 336}
episode: 301/2000 -> reward: 72.3072916666667, steps:2664, time-taken: 2.14min, time-elasped: 2986.41min
-> berries picked: 47 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8090 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1274, 983, 723, 844, 1013, 1082, 857, 656, 658]
	| approx positives in sample 512: 143
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 16, 18, 16, 19, 6, 16, 14, 19]
	Time taken saving stuff: 0.01s

=== episode:302 Env-steps-taken:69600
 	picked: 80 |actions: {0: 424, 1: 402, 2: 328, 3: 453, 4: 513, 5: 549, 6: 361, 7: 865, 8: 488}
episode: 302/2000 -> reward: 108.41666666666653, steps:4383, time-taken: 3.08min, time-elasped: 2989.49min
-> berries picked: 80 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8139 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1275, 984, 726, 854, 1017, 1090, 869, 664, 660]
	| approx positives in sample 512: 158
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 19, 14, 23, 21, 16, 16, 17, 16]
	Time taken saving stuff: 0.00s

=== episode:303 Env-steps-taken:68832
 	picked: 73 |actions: {0: 410, 1: 381, 2: 378, 3: 408, 4: 475, 5: 513, 6: 474, 7: 728, 8: 464}
episode: 303/2000 -> reward: 104.81770833333321, steps:4231, time-taken: 3.06min, time-elasped: 2992.55min
-> berries picked: 73 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8185 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1277, 990, 734, 858, 1019, 1097, 879, 667, 664]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 17, 8, 23, 18, 14, 18, 13, 10]
	Time taken saving stuff: 0.08s

=== episode:304 Env-steps-taken:76128
 	picked: 106 |actions: {0: 670, 1: 500, 2: 493, 3: 575, 4: 668, 5: 698, 6: 492, 7: 891, 8: 852}
episode: 304/2000 -> reward: 141.42708333333326, steps:5839, time-taken: 4.05min, time-elasped: 2996.61min
-> berries picked: 106 of 800 | patches-visited: [0, 6, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8248 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1285, 990, 739, 867, 1025, 1108, 886, 681, 667]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 13, 15, 14, 9, 10, 8, 11, 9]
	Time taken saving stuff: 0.03s

=== episode:305 Env-steps-taken:63648
 	picked: 55 |actions: {0: 456, 1: 420, 2: 285, 3: 332, 4: 382, 5: 375, 6: 315, 7: 578, 8: 515}
episode: 305/2000 -> reward: 77.40625, steps:3658, time-taken: 2.67min, time-elasped: 2999.28min
-> berries picked: 55 of 800 | patches-visited: [0, 1, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8275 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1292, 994, 739, 871, 1029, 1111, 887, 679, 673]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 20, 13, 14, 16, 17, 16, 6, 16]
	Time taken saving stuff: 0.10s

=== episode:306 Env-steps-taken:51456
 	picked: 13 |actions: {0: 71, 1: 94, 2: 71, 3: 107, 4: 141, 5: 105, 6: 109, 7: 81, 8: 173}
episode: 306/2000 -> reward: 17.75520833333334, steps:952, time-taken: 0.89min, time-elasped: 3000.18min
-> berries picked: 13 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8277 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1292, 994, 738, 874, 1029, 1109, 888, 679, 674]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 15, 16, 16, 16, 16, 11, 4, 18]
	Time taken saving stuff: 0.03s

=== episode:307 Env-steps-taken:65184
 	picked: 65 |actions: {0: 525, 1: 493, 2: 388, 3: 412, 4: 403, 5: 420, 6: 459, 7: 837, 8: 654}
episode: 307/2000 -> reward: 86.27604166666664, steps:4591, time-taken: 3.04min, time-elasped: 3003.22min
-> berries picked: 65 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8312 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1300, 998, 747, 872, 1033, 1108, 893, 683, 678]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [33, 20, 11, 9, 17, 9, 11, 16, 12]
	Time taken saving stuff: 0.01s

=== episode:308 Env-steps-taken:70944
 	picked: 87 |actions: {0: 744, 1: 520, 2: 418, 3: 526, 4: 574, 5: 573, 6: 638, 7: 877, 8: 678}
episode: 308/2000 -> reward: 115.01562499999987, steps:5548, time-taken: 4.02min, time-elasped: 3007.24min
-> berries picked: 87 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8360 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1306, 1001, 754, 870, 1039, 1112, 901, 698, 679]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [25, 16, 16, 11, 21, 23, 9, 12, 9]
	Time taken saving stuff: 0.03s

=== episode:309 Env-steps-taken:69984
 	picked: 79 |actions: {0: 498, 1: 436, 2: 510, 3: 636, 4: 550, 5: 535, 6: 565, 7: 633, 8: 621}
episode: 309/2000 -> reward: 109.08854166666659, steps:4984, time-taken: 3.42min, time-elasped: 3010.66min
-> berries picked: 79 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8389 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1306, 1006, 755, 879, 1047, 1112, 903, 701, 680]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [23, 11, 13, 21, 13, 19, 12, 6, 11]
	Time taken saving stuff: 0.03s

=== episode:310 Env-steps-taken:65664
 	picked: 74 |actions: {0: 599, 1: 475, 2: 381, 3: 482, 4: 558, 5: 549, 6: 511, 7: 672, 8: 434}
episode: 310/2000 -> reward: 87.76041666666659, steps:4661, time-taken: 2.98min, time-elasped: 3013.64min
-> berries picked: 74 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8413 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1307, 1009, 758, 878, 1043, 1124, 907, 707, 680]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 16, 11, 12, 19, 12, 17, 10, 11]
	Time taken saving stuff: 0.18s

=== episode:31 Env-steps-taken:77760
 	picked: 109 |actions: {0: 378, 1: 349, 2: 370, 3: 218, 4: 244, 5: 199, 6: 278, 7: 451, 8: 838}

==================================================
eval-episode: 310 -> reward: 148.86979166666663, steps: 3325.0, wall-time: 67.14s
-> berries picked: 109 of 800 | patches-visited: [1, 2, 6] | juice left:-0.00
==================================================


=== episode:311 Env-steps-taken:80928
 	picked: 119 |actions: {0: 838, 1: 687, 2: 647, 3: 652, 4: 760, 5: 774, 6: 688, 7: 804, 8: 593}
episode: 311/2000 -> reward: 165.6822916666668, steps:6443, time-taken: 4.45min, time-elasped: 3019.21min
-> berries picked: 119 of 800 | patches-visited: [0, 2, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8464 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1321, 1011, 764, 880, 1051, 1130, 918, 705, 684]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [24, 16, 13, 14, 16, 21, 18, 9, 17]
	Time taken saving stuff: 0.01s

=== episode:312 Env-steps-taken:69600
 	picked: 82 |actions: {0: 709, 1: 545, 2: 455, 3: 549, 4: 604, 5: 657, 6: 510, 7: 957, 8: 669}
episode: 312/2000 -> reward: 108.3020833333332, steps:5655, time-taken: 4.29min, time-elasped: 3023.50min
-> berries picked: 82 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8510 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1332, 1019, 763, 886, 1052, 1136, 927, 708, 687]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 16, 8, 22, 16, 11, 17, 14, 18]
	Time taken saving stuff: 0.01s

=== episode:313 Env-steps-taken:75552
 	picked: 92 |actions: {0: 580, 1: 467, 2: 416, 3: 404, 4: 473, 5: 570, 6: 598, 7: 740, 8: 452}
episode: 313/2000 -> reward: 139.2291666666666, steps:4700, time-taken: 3.71min, time-elasped: 3027.22min
-> berries picked: 92 of 800 | patches-visited: [0, 2, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8574 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1343, 1018, 772, 893, 1054, 1148, 933, 721, 692]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 12, 6, 20, 16, 12, 17, 13, 18]
	Time taken saving stuff: 0.03s

=== episode:314 Env-steps-taken:66528
 	picked: 71 |actions: {0: 698, 1: 439, 2: 365, 3: 325, 4: 410, 5: 617, 6: 480, 7: 570, 8: 574}
episode: 314/2000 -> reward: 92.43229166666657, steps:4478, time-taken: 3.47min, time-elasped: 3030.70min
-> berries picked: 71 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8595 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1351, 1025, 768, 889, 1052, 1152, 938, 725, 695]
	| approx positives in sample 512: 151
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 16, 18, 15, 11, 20, 22, 19, 13]
	Time taken saving stuff: 0.09s

=== episode:315 Env-steps-taken:67296
 	picked: 71 |actions: {0: 690, 1: 487, 2: 452, 3: 418, 4: 533, 5: 622, 6: 534, 7: 791, 8: 821}
episode: 315/2000 -> reward: 96.48958333333324, steps:5348, time-taken: 3.78min, time-elasped: 3034.48min
-> berries picked: 71 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8597 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1348, 1023, 772, 881, 1056, 1157, 943, 719, 698]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [26, 13, 13, 15, 16, 17, 12, 10, 13]
	Time taken saving stuff: 0.01s

=== episode:316 Env-steps-taken:67008
 	picked: 67 |actions: {0: 389, 1: 326, 2: 418, 3: 311, 4: 435, 5: 487, 6: 385, 7: 395, 8: 540}
episode: 316/2000 -> reward: 95.66145833333329, steps:3686, time-taken: 3.01min, time-elasped: 3037.50min
-> berries picked: 67 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8625 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1352, 1019, 779, 884, 1058, 1168, 942, 721, 702]
	| approx positives in sample 512: 143
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 15, 11, 11, 17, 17, 20, 10, 23]
	Time taken saving stuff: 0.11s

=== episode:317 Env-steps-taken:64128
 	picked: 63 |actions: {0: 444, 1: 443, 2: 361, 3: 334, 4: 368, 5: 487, 6: 397, 7: 613, 8: 636}
episode: 317/2000 -> reward: 80.39062499999999, steps:4083, time-taken: 3.03min, time-elasped: 3040.54min
-> berries picked: 63 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8642 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1355, 1016, 780, 890, 1055, 1179, 948, 717, 702]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 24, 8, 16, 17, 12, 15, 12, 16]
	Time taken saving stuff: 0.01s

=== episode:318 Env-steps-taken:65568
 	picked: 68 |actions: {0: 534, 1: 416, 2: 479, 3: 363, 4: 488, 5: 485, 6: 422, 7: 694, 8: 570}
episode: 318/2000 -> reward: 88.1041666666666, steps:4451, time-taken: 3.28min, time-elasped: 3043.82min
-> berries picked: 68 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8672 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1360, 1017, 785, 890, 1057, 1187, 953, 719, 704]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 14, 18, 13, 15, 19, 15, 19, 17]
	Time taken saving stuff: 0.02s

=== episode:319 Env-steps-taken:69888
 	picked: 82 |actions: {0: 710, 1: 429, 2: 476, 3: 511, 4: 686, 5: 584, 6: 480, 7: 854, 8: 478}
episode: 319/2000 -> reward: 107.85937499999987, steps:5208, time-taken: 4.05min, time-elasped: 3047.87min
-> berries picked: 82 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8694 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1362, 1015, 792, 887, 1061, 1190, 957, 725, 705]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 19, 7, 10, 11, 17, 22, 15, 16]
	Time taken saving stuff: 0.01s

=== episode:320 Env-steps-taken:78624
 	picked: 105 |actions: {0: 640, 1: 521, 2: 604, 3: 597, 4: 745, 5: 696, 6: 608, 7: 694, 8: 540}
episode: 320/2000 -> reward: 154.48437500000003, steps:5645, time-taken: 4.48min, time-elasped: 3052.36min
-> berries picked: 105 of 800 | patches-visited: [0, 1, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8747 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1368, 1018, 804, 895, 1069, 1197, 967, 722, 707]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 16, 11, 17, 14, 15, 12, 18, 9]
	Time taken saving stuff: 0.09s

=== episode:32 Env-steps-taken:69504
 	picked: 81 |actions: {0: 332, 1: 258, 2: 92, 3: 190, 4: 310, 5: 244, 6: 230, 7: 195, 8: 351}

==================================================
eval-episode: 320 -> reward: 105.9739583333332, steps: 2202.0, wall-time: 65.60s
-> berries picked: 81 of 800 | patches-visited: [0, 1] | juice left:-0.00
==================================================


=== episode:321 Env-steps-taken:68928
 	picked: 83 |actions: {0: 749, 1: 570, 2: 502, 3: 475, 4: 683, 5: 500, 6: 440, 7: 542, 8: 528}
episode: 321/2000 -> reward: 104.74479166666656, steps:4989, time-taken: 3.95min, time-elasped: 3057.41min
-> berries picked: 83 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8758 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1372, 1023, 805, 897, 1076, 1196, 960, 719, 710]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [25, 14, 11, 13, 11, 21, 14, 13, 20]
	Time taken saving stuff: 0.01s

=== episode:322 Env-steps-taken:66336
 	picked: 64 |actions: {0: 609, 1: 437, 2: 401, 3: 321, 4: 367, 5: 378, 6: 319, 7: 804, 8: 596}
episode: 322/2000 -> reward: 91.4479166666666, steps:4232, time-taken: 3.28min, time-elasped: 3060.70min
-> berries picked: 64 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8784 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1379, 1030, 806, 900, 1077, 1199, 961, 723, 709]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 15, 18, 11, 12, 10, 7, 11, 11]
	Time taken saving stuff: 0.01s

=== episode:323 Env-steps-taken:69312
 	picked: 80 |actions: {0: 428, 1: 394, 2: 323, 3: 412, 4: 538, 5: 470, 6: 375, 7: 616, 8: 423}
episode: 323/2000 -> reward: 106.91666666666654, steps:3979, time-taken: 3.23min, time-elasped: 3063.93min
-> berries picked: 80 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8801 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1373, 1035, 808, 911, 1081, 1202, 963, 717, 711]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [24, 14, 10, 16, 11, 14, 13, 9, 15]
	Time taken saving stuff: 0.03s

=== episode:324 Env-steps-taken:69120
 	picked: 73 |actions: {0: 511, 1: 322, 2: 402, 3: 411, 4: 595, 5: 546, 6: 356, 7: 616, 8: 337}
episode: 324/2000 -> reward: 106.81770833333323, steps:4096, time-taken: 3.53min, time-elasped: 3067.47min
-> berries picked: 73 of 800 | patches-visited: [0, 1, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8815 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1375, 1036, 809, 905, 1085, 1204, 965, 723, 713]
	| approx positives in sample 512: 139
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 10, 19, 18, 16, 20, 19, 8, 11]
	Time taken saving stuff: 0.03s

=== episode:325 Env-steps-taken:70080
 	picked: 76 |actions: {0: 694, 1: 341, 2: 397, 3: 309, 4: 401, 5: 453, 6: 480, 7: 682, 8: 286}
episode: 325/2000 -> reward: 111.14583333333323, steps:4043, time-taken: 3.26min, time-elasped: 3070.73min
-> berries picked: 76 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8839 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1382, 1035, 816, 911, 1087, 1206, 974, 716, 712]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 11, 19, 14, 12, 17, 14, 12, 14]
	Time taken saving stuff: 0.10s

=== episode:326 Env-steps-taken:71616
 	picked: 85 |actions: {0: 599, 1: 459, 2: 450, 3: 447, 4: 687, 5: 887, 6: 410, 7: 538, 8: 594}
episode: 326/2000 -> reward: 116.68749999999987, steps:5071, time-taken: 4.06min, time-elasped: 3074.80min
-> berries picked: 85 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8789 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1376, 1041, 808, 917, 1092, 1196, 956, 689, 714]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 15, 12, 16, 22, 18, 12, 8, 14]
	Time taken saving stuff: 0.03s

=== episode:327 Env-steps-taken:66624
 	picked: 75 |actions: {0: 606, 1: 403, 2: 406, 3: 418, 4: 516, 5: 655, 6: 336, 7: 776, 8: 406}
episode: 327/2000 -> reward: 93.20312499999994, steps:4522, time-taken: 3.67min, time-elasped: 3078.47min
-> berries picked: 75 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8790 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1378, 1042, 809, 912, 1098, 1195, 955, 682, 719]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 11, 8, 12, 15, 11, 11, 8, 13]
	Time taken saving stuff: 0.04s

=== episode:328 Env-steps-taken:69408
 	picked: 73 |actions: {0: 560, 1: 557, 2: 633, 3: 368, 4: 417, 5: 664, 6: 350, 7: 689, 8: 559}
episode: 328/2000 -> reward: 107.81770833333326, steps:4797, time-taken: 4.05min, time-elasped: 3082.52min
-> berries picked: 73 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8789 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1382, 1042, 814, 913, 1096, 1196, 950, 675, 721]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 11, 21, 12, 17, 17, 15, 8, 16]
	Time taken saving stuff: 0.01s

=== episode:329 Env-steps-taken:63360
 	picked: 50 |actions: {0: 308, 1: 235, 2: 198, 3: 262, 4: 355, 5: 471, 6: 224, 7: 377, 8: 303}
episode: 329/2000 -> reward: 77.63541666666667, steps:2733, time-taken: 2.50min, time-elasped: 3085.03min
-> berries picked: 50 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8806 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1385, 1044, 809, 917, 1104, 1202, 948, 674, 723]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [24, 18, 15, 11, 14, 21, 9, 14, 15]
	Time taken saving stuff: 0.03s

=== episode:330 Env-steps-taken:54432
 	picked: 24 |actions: {0: 185, 1: 151, 2: 120, 3: 169, 4: 137, 5: 149, 6: 152, 7: 223, 8: 179}
episode: 330/2000 -> reward: 32.12499999999999, steps:1465, time-taken: 1.76min, time-elasped: 3086.80min
-> berries picked: 24 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8808 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1382, 1045, 812, 919, 1103, 1203, 948, 673, 723]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 13, 16, 8, 15, 16, 12, 10, 15]
	Time taken saving stuff: 0.08s

=== episode:33 Env-steps-taken:72480
 	picked: 79 |actions: {0: 251, 1: 278, 2: 187, 3: 156, 4: 205, 5: 254, 6: 302, 7: 473, 8: 379}

==================================================
eval-episode: 330 -> reward: 123.08854166666653, steps: 2485.0, wall-time: 64.51s
-> berries picked: 79 of 800 | patches-visited: [1, 2, 9] | juice left:-0.00
==================================================


=== episode:331 Env-steps-taken:65568
 	picked: 69 |actions: {0: 558, 1: 463, 2: 473, 3: 451, 4: 554, 5: 695, 6: 596, 7: 1167, 8: 682}
episode: 331/2000 -> reward: 87.54687499999994, steps:5639, time-taken: 4.31min, time-elasped: 3092.20min
-> berries picked: 69 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8789 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1368, 1051, 810, 925, 1106, 1207, 945, 653, 724]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 14, 9, 13, 16, 11, 10, 11, 12]
	Time taken saving stuff: 0.10s

=== episode:332 Env-steps-taken:68160
 	picked: 73 |actions: {0: 536, 1: 341, 2: 429, 3: 346, 4: 497, 5: 505, 6: 415, 7: 581, 8: 329}
episode: 332/2000 -> reward: 101.31770833333324, steps:3979, time-taken: 3.33min, time-elasped: 3095.54min
-> berries picked: 73 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8804 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1362, 1048, 814, 923, 1112, 1213, 952, 653, 727]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [24, 17, 8, 16, 14, 16, 11, 9, 18]
	Time taken saving stuff: 0.03s

=== episode:333 Env-steps-taken:60096
 	picked: 50 |actions: {0: 462, 1: 324, 2: 289, 3: 222, 4: 300, 5: 410, 6: 244, 7: 341, 8: 311}
episode: 333/2000 -> reward: 60.135416666666735, steps:2903, time-taken: 2.56min, time-elasped: 3098.10min
-> berries picked: 50 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8805 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1363, 1042, 816, 921, 1114, 1217, 959, 644, 729]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 14, 13, 16, 12, 16, 12, 12, 18]
	Time taken saving stuff: 0.01s

=== episode:334 Env-steps-taken:51168
 	picked: 9 |actions: {0: 59, 1: 29, 2: 27, 3: 41, 4: 85, 5: 90, 6: 48, 7: 31, 8: 121}
episode: 334/2000 -> reward: 15.984375000000002, steps:531, time-taken: 1.23min, time-elasped: 3099.34min
-> berries picked: 9 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8810 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1362, 1042, 817, 921, 1116, 1220, 958, 644, 730]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 7, 12, 13, 14, 14, 13, 7, 14]
	Time taken saving stuff: 0.01s

=== episode:335 Env-steps-taken:64992
 	picked: 58 |actions: {0: 392, 1: 357, 2: 397, 3: 318, 4: 312, 5: 349, 6: 278, 7: 479, 8: 321}
episode: 335/2000 -> reward: 85.6770833333333, steps:3203, time-taken: 3.41min, time-elasped: 3102.76min
-> berries picked: 58 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8824 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1362, 1043, 824, 921, 1118, 1224, 961, 639, 732]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 19, 17, 14, 23, 19, 11, 10, 15]
	Time taken saving stuff: 0.02s

=== episode:336 Env-steps-taken:65760
 	picked: 64 |actions: {0: 543, 1: 426, 2: 291, 3: 299, 4: 301, 5: 486, 6: 301, 7: 559, 8: 357}
episode: 336/2000 -> reward: 86.9479166666666, steps:3563, time-taken: 2.74min, time-elasped: 3105.50min
-> berries picked: 64 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8743 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1329, 1025, 817, 912, 1118, 1229, 958, 623, 732]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 10, 4, 11, 27, 18, 16, 8, 10]
	Time taken saving stuff: 0.04s

=== episode:337 Env-steps-taken:77952
 	picked: 111 |actions: {0: 712, 1: 777, 2: 566, 3: 521, 4: 683, 5: 781, 6: 610, 7: 855, 8: 549}
episode: 337/2000 -> reward: 148.25520833333337, steps:6054, time-taken: 3.94min, time-elasped: 3109.45min
-> berries picked: 111 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8684 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1298, 1002, 815, 907, 1126, 1233, 958, 611, 734]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [24, 15, 6, 18, 15, 24, 19, 7, 10]
	Time taken saving stuff: 0.03s

=== episode:338 Env-steps-taken:69792
 	picked: 76 |actions: {0: 541, 1: 469, 2: 446, 3: 406, 4: 452, 5: 698, 6: 361, 7: 730, 8: 286}
episode: 338/2000 -> reward: 109.64583333333323, steps:4389, time-taken: 2.91min, time-elasped: 3112.36min
-> berries picked: 76 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8681 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1298, 998, 808, 905, 1131, 1234, 964, 605, 738]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 14, 13, 14, 19, 15, 8, 6, 13]
	Time taken saving stuff: 0.09s

=== episode:339 Env-steps-taken:63936
 	picked: 59 |actions: {0: 464, 1: 335, 2: 331, 3: 313, 4: 337, 5: 501, 6: 411, 7: 516, 8: 397}
episode: 339/2000 -> reward: 80.11979166666663, steps:3605, time-taken: 2.56min, time-elasped: 3114.92min
-> berries picked: 59 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8668 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1288, 995, 802, 900, 1133, 1240, 967, 604, 739]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 16, 11, 15, 13, 20, 16, 9, 18]
	Time taken saving stuff: 0.03s

=== episode:340 Env-steps-taken:75456
 	picked: 106 |actions: {0: 677, 1: 567, 2: 470, 3: 421, 4: 553, 5: 1046, 6: 480, 7: 766, 8: 516}
episode: 340/2000 -> reward: 137.92708333333323, steps:5496, time-taken: 3.68min, time-elasped: 3118.61min
-> berries picked: 106 of 800 | patches-visited: [0, 4, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8695 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1292, 992, 802, 903, 1142, 1244, 973, 606, 741]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 12, 11, 11, 25, 22, 15, 5, 15]
	Time taken saving stuff: 0.06s

=== episode:34 Env-steps-taken:68832
 	picked: 76 |actions: {0: 383, 1: 188, 2: 179, 3: 99, 4: 172, 5: 286, 6: 341, 7: 528, 8: 552}

==================================================
eval-episode: 340 -> reward: 103.37499999999993, steps: 2728.0, wall-time: 52.13s
-> berries picked: 76 of 800 | patches-visited: [1, 2, 5] | juice left:-0.00
==================================================


=== episode:341 Env-steps-taken:62688
 	picked: 53 |actions: {0: 442, 1: 376, 2: 286, 3: 280, 4: 420, 5: 333, 6: 282, 7: 711, 8: 576}
episode: 341/2000 -> reward: 73.46354166666669, steps:3706, time-taken: 2.53min, time-elasped: 3122.01min
-> berries picked: 53 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8646 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1291, 982, 785, 888, 1145, 1242, 969, 603, 741]
	| approx positives in sample 512: 145
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [27, 24, 11, 11, 12, 23, 11, 10, 16]
	Time taken saving stuff: 0.03s

=== episode:342 Env-steps-taken:66624
 	picked: 64 |actions: {0: 552, 1: 524, 2: 342, 3: 376, 4: 381, 5: 438, 6: 352, 7: 780, 8: 622}
episode: 342/2000 -> reward: 93.8333333333333, steps:4367, time-taken: 2.98min, time-elasped: 3125.00min
-> berries picked: 64 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8626 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1295, 976, 773, 881, 1149, 1238, 968, 603, 743]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 8, 13, 13, 17, 18, 13, 14, 13]
	Time taken saving stuff: 0.03s

=== episode:343 Env-steps-taken:68640
 	picked: 81 |actions: {0: 553, 1: 510, 2: 461, 3: 533, 4: 467, 5: 626, 6: 467, 7: 1133, 8: 510}
episode: 343/2000 -> reward: 103.35937499999989, steps:5260, time-taken: 3.48min, time-elasped: 3128.48min
-> berries picked: 81 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8614 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1292, 979, 771, 874, 1153, 1234, 968, 600, 743]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 14, 16, 19, 12, 16, 14, 8, 17]
	Time taken saving stuff: 0.09s

=== episode:344 Env-steps-taken:69312
 	picked: 75 |actions: {0: 482, 1: 517, 2: 386, 3: 379, 4: 421, 5: 771, 6: 525, 7: 1007, 8: 659}
episode: 344/2000 -> reward: 107.20312499999991, steps:5147, time-taken: 3.46min, time-elasped: 3131.95min
-> berries picked: 75 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8599 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1286, 981, 763, 867, 1154, 1233, 971, 599, 745]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 9, 15, 10, 13, 17, 13, 7, 12]
	Time taken saving stuff: 0.00s

=== episode:345 Env-steps-taken:79872
 	picked: 118 |actions: {0: 854, 1: 631, 2: 522, 3: 589, 4: 756, 5: 998, 6: 607, 7: 1104, 8: 478}
episode: 345/2000 -> reward: 159.73958333333348, steps:6539, time-taken: 4.65min, time-elasped: 3136.60min
-> berries picked: 118 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8621 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1296, 982, 759, 864, 1158, 1243, 968, 604, 747]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 15, 10, 13, 20, 12, 11, 8, 14]
	Time taken saving stuff: 0.09s

=== episode:346 Env-steps-taken:60768
 	picked: 43 |actions: {0: 217, 1: 230, 2: 200, 3: 189, 4: 249, 5: 397, 6: 259, 7: 301, 8: 362}
episode: 346/2000 -> reward: 62.59375000000005, steps:2404, time-taken: 1.89min, time-elasped: 3138.50min
-> berries picked: 43 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8618 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1299, 977, 752, 861, 1156, 1249, 969, 606, 749]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 19, 14, 9, 21, 12, 16, 8, 13]
	Time taken saving stuff: 0.01s

=== episode:347 Env-steps-taken:49632
 	picked: 6 |actions: {0: 44, 1: 37, 2: 33, 3: 68, 4: 66, 5: 60, 6: 36, 7: 51, 8: 245}
episode: 347/2000 -> reward: 8.15625, steps:640, time-taken: 0.85min, time-elasped: 3139.36min
-> berries picked: 6 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8611 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1299, 975, 748, 861, 1157, 1247, 969, 606, 749]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [26, 11, 6, 17, 13, 17, 15, 8, 12]
	Time taken saving stuff: 0.04s

=== episode:348 Env-steps-taken:68256
 	picked: 64 |actions: {0: 490, 1: 447, 2: 316, 3: 412, 4: 448, 5: 508, 6: 302, 7: 479, 8: 443}
episode: 348/2000 -> reward: 102.33333333333329, steps:3845, time-taken: 3.13min, time-elasped: 3142.49min
-> berries picked: 64 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8605 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1300, 970, 744, 864, 1148, 1251, 972, 608, 748]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 13, 16, 13, 8, 14, 16, 8, 14]
	Time taken saving stuff: 0.01s

=== episode:349 Env-steps-taken:63936
 	picked: 64 |actions: {0: 539, 1: 388, 2: 391, 3: 270, 4: 383, 5: 545, 6: 260, 7: 528, 8: 305}
episode: 349/2000 -> reward: 79.3333333333333, steps:3609, time-taken: 2.75min, time-elasped: 3145.24min
-> berries picked: 64 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8622 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1308, 974, 743, 859, 1150, 1253, 972, 615, 748]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 16, 15, 14, 22, 19, 16, 5, 16]
	Time taken saving stuff: 0.01s

=== episode:350 Env-steps-taken:65568
 	picked: 64 |actions: {0: 450, 1: 392, 2: 270, 3: 272, 4: 344, 5: 533, 6: 249, 7: 522, 8: 642}
episode: 350/2000 -> reward: 86.89062499999997, steps:3674, time-taken: 2.75min, time-elasped: 3148.00min
-> berries picked: 64 of 800 | patches-visited: [0, 2, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8627 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1304, 975, 744, 856, 1150, 1249, 978, 621, 750]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 13, 13, 11, 16, 20, 18, 10, 18]
	Time taken saving stuff: 0.06s

=== episode:35 Env-steps-taken:64416
 	picked: 60 |actions: {0: 171, 1: 193, 2: 364, 3: 150, 4: 141, 5: 256, 6: 113, 7: 374, 8: 241}

==================================================
eval-episode: 350 -> reward: 81.17708333333331, steps: 2003.0, wall-time: 55.50s
-> berries picked: 60 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:351 Env-steps-taken:71328
 	picked: 92 |actions: {0: 560, 1: 668, 2: 794, 3: 500, 4: 556, 5: 656, 6: 440, 7: 845, 8: 512}
episode: 351/2000 -> reward: 116.78645833333316, steps:5531, time-taken: 4.05min, time-elasped: 3152.98min
-> berries picked: 92 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8657 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1315, 980, 747, 859, 1145, 1254, 982, 622, 753]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [25, 14, 12, 19, 16, 8, 17, 12, 11]
	Time taken saving stuff: 0.08s

=== episode:352 Env-steps-taken:63936
 	picked: 59 |actions: {0: 317, 1: 352, 2: 278, 3: 375, 4: 398, 5: 393, 6: 266, 7: 443, 8: 214}
episode: 352/2000 -> reward: 78.67708333333333, steps:3036, time-taken: 2.75min, time-elasped: 3155.74min
-> berries picked: 59 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8673 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1316, 983, 751, 861, 1148, 1251, 985, 626, 752]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 15, 18, 15, 12, 23, 19, 6, 13]
	Time taken saving stuff: 0.01s

=== episode:353 Env-steps-taken:75840
 	picked: 98 |actions: {0: 616, 1: 572, 2: 569, 3: 440, 4: 523, 5: 585, 6: 415, 7: 856, 8: 562}
episode: 353/2000 -> reward: 137.9999999999999, steps:5138, time-taken: 3.54min, time-elasped: 3159.29min
-> berries picked: 98 of 800 | patches-visited: [0, 1, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8707 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1328, 986, 755, 862, 1144, 1253, 992, 632, 755]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 15, 16, 13, 20, 6, 6, 10, 14]
	Time taken saving stuff: 0.03s

=== episode:354 Env-steps-taken:65856
 	picked: 65 |actions: {0: 368, 1: 305, 2: 267, 3: 231, 4: 363, 5: 526, 6: 281, 7: 486, 8: 475}
episode: 354/2000 -> reward: 90.27604166666663, steps:3302, time-taken: 2.68min, time-elasped: 3161.97min
-> berries picked: 65 of 800 | patches-visited: [0, 1, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8729 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1334, 988, 756, 857, 1144, 1255, 998, 638, 759]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [24, 14, 14, 6, 16, 11, 12, 8, 11]
	Time taken saving stuff: 0.03s

=== episode:355 Env-steps-taken:79680
 	picked: 109 |actions: {0: 688, 1: 505, 2: 636, 3: 494, 4: 633, 5: 744, 6: 471, 7: 719, 8: 413}
episode: 355/2000 -> reward: 159.75520833333343, steps:5303, time-taken: 3.92min, time-elasped: 3165.90min
-> berries picked: 109 of 800 | patches-visited: [0, 1, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8791 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1338, 1001, 763, 864, 1148, 1259, 1009, 645, 764]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 16, 12, 12, 14, 18, 12, 14, 18]
	Time taken saving stuff: 0.06s

=== episode:356 Env-steps-taken:68352
 	picked: 72 |actions: {0: 433, 1: 385, 2: 416, 3: 339, 4: 380, 5: 441, 6: 343, 7: 542, 8: 422}
episode: 356/2000 -> reward: 102.37499999999994, steps:3701, time-taken: 2.68min, time-elasped: 3168.58min
-> berries picked: 72 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8787 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1337, 1003, 761, 874, 1130, 1251, 1014, 649, 768]
	| approx positives in sample 512: 143
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [25, 16, 13, 15, 11, 21, 13, 13, 16]
	Time taken saving stuff: 0.03s

=== episode:357 Env-steps-taken:85536
 	picked: 131 |actions: {0: 941, 1: 581, 2: 757, 3: 610, 4: 631, 5: 915, 6: 639, 7: 1006, 8: 580}
episode: 357/2000 -> reward: 188.99479166666688, steps:6660, time-taken: 4.89min, time-elasped: 3173.47min
-> berries picked: 131 of 800 | patches-visited: [0, 7, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8802 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1333, 996, 770, 877, 1134, 1252, 1015, 655, 770]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [24, 11, 23, 14, 9, 18, 15, 6, 15]
	Time taken saving stuff: 0.10s

=== episode:358 Env-steps-taken:67968
 	picked: 79 |actions: {0: 521, 1: 386, 2: 483, 3: 417, 4: 415, 5: 634, 6: 445, 7: 621, 8: 545}
episode: 358/2000 -> reward: 99.97395833333323, steps:4467, time-taken: 3.24min, time-elasped: 3176.72min
-> berries picked: 79 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8790 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1334, 990, 769, 880, 1122, 1255, 1013, 657, 770]
	| approx positives in sample 512: 139
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 14, 9, 12, 22, 21, 20, 10, 18]
	Time taken saving stuff: 0.01s

=== episode:359 Env-steps-taken:76320
 	picked: 101 |actions: {0: 728, 1: 637, 2: 729, 3: 501, 4: 636, 5: 725, 6: 465, 7: 628, 8: 593}
episode: 359/2000 -> reward: 141.32812499999994, steps:5642, time-taken: 3.99min, time-elasped: 3180.72min
-> berries picked: 101 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8814 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1334, 998, 769, 886, 1122, 1254, 1013, 661, 777]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 16, 12, 7, 24, 19, 17, 4, 20]
	Time taken saving stuff: 0.01s

=== episode:360 Env-steps-taken:74496
 	picked: 96 |actions: {0: 653, 1: 500, 2: 555, 3: 519, 4: 542, 5: 693, 6: 392, 7: 600, 8: 417}
episode: 360/2000 -> reward: 132.99999999999986, steps:4871, time-taken: 3.70min, time-elasped: 3184.43min
-> berries picked: 96 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8849 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1337, 1004, 776, 896, 1120, 1255, 1019, 662, 780]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [24, 18, 9, 10, 12, 16, 10, 11, 10]
	Time taken saving stuff: 0.16s

=== episode:36 Env-steps-taken:64608
 	picked: 59 |actions: {0: 294, 1: 116, 2: 104, 3: 109, 4: 94, 5: 282, 6: 234, 7: 210, 8: 349}

==================================================
eval-episode: 360 -> reward: 84.11979166666664, steps: 1792.0, wall-time: 48.39s
-> berries picked: 59 of 800 | patches-visited: [0, 1, 3] | juice left:-0.00
==================================================


=== episode:361 Env-steps-taken:74016
 	picked: 95 |actions: {0: 576, 1: 662, 2: 570, 3: 435, 4: 519, 5: 836, 6: 460, 7: 939, 8: 570}
episode: 361/2000 -> reward: 130.55729166666652, steps:5567, time-taken: 3.78min, time-elasped: 3189.03min
-> berries picked: 95 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8869 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1327, 1010, 784, 898, 1117, 1263, 1021, 666, 783]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 14, 12, 17, 13, 14, 13, 10, 22]
	Time taken saving stuff: 0.00s

=== episode:362 Env-steps-taken:67104
 	picked: 68 |actions: {0: 354, 1: 426, 2: 503, 3: 332, 4: 283, 5: 463, 6: 379, 7: 502, 8: 542}
episode: 362/2000 -> reward: 96.10416666666661, steps:3784, time-taken: 2.85min, time-elasped: 3191.88min
-> berries picked: 68 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8881 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1325, 1013, 792, 894, 1121, 1267, 1013, 671, 785]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 13, 10, 9, 11, 23, 10, 10, 15]
	Time taken saving stuff: 0.02s

=== episode:363 Env-steps-taken:66816
 	picked: 67 |actions: {0: 477, 1: 506, 2: 406, 3: 364, 4: 488, 5: 433, 6: 296, 7: 613, 8: 549}
episode: 363/2000 -> reward: 92.71874999999994, steps:4132, time-taken: 2.80min, time-elasped: 3194.69min
-> berries picked: 67 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8882 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1328, 1011, 792, 893, 1125, 1272, 1010, 664, 787]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 11, 14, 14, 21, 17, 18, 11, 14]
	Time taken saving stuff: 0.03s

=== episode:364 Env-steps-taken:60768
 	picked: 49 |actions: {0: 350, 1: 327, 2: 300, 3: 298, 4: 326, 5: 374, 6: 249, 7: 579, 8: 330}
episode: 364/2000 -> reward: 63.69270833333339, steps:3133, time-taken: 2.39min, time-elasped: 3197.08min
-> berries picked: 49 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8884 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1329, 1008, 793, 894, 1124, 1275, 1010, 664, 787]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 18, 11, 11, 13, 18, 26, 9, 11]
	Time taken saving stuff: 0.10s

=== episode:365 Env-steps-taken:64800
 	picked: 60 |actions: {0: 366, 1: 562, 2: 539, 3: 431, 4: 365, 5: 487, 6: 434, 7: 560, 8: 429}
episode: 365/2000 -> reward: 84.06249999999994, steps:4173, time-taken: 2.75min, time-elasped: 3199.84min
-> berries picked: 60 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8892 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1325, 1014, 800, 895, 1128, 1277, 1007, 660, 786]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 14, 14, 18, 14, 15, 6, 7, 12]
	Time taken saving stuff: 0.01s

=== episode:366 Env-steps-taken:69312
 	picked: 76 |actions: {0: 547, 1: 382, 2: 389, 3: 374, 4: 421, 5: 502, 6: 446, 7: 709, 8: 487}
episode: 366/2000 -> reward: 107.14583333333323, steps:4257, time-taken: 2.90min, time-elasped: 3202.74min
-> berries picked: 76 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8797 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1306, 991, 787, 891, 1118, 1272, 1009, 642, 781]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 15, 11, 7, 16, 21, 14, 11, 13]
	Time taken saving stuff: 0.10s

=== episode:367 Env-steps-taken:65568
 	picked: 61 |actions: {0: 382, 1: 300, 2: 319, 3: 297, 4: 334, 5: 472, 6: 402, 7: 425, 8: 203}
episode: 367/2000 -> reward: 88.50520833333329, steps:3134, time-taken: 2.32min, time-elasped: 3205.06min
-> berries picked: 61 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8776 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1300, 986, 779, 894, 1113, 1268, 1012, 642, 782]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 17, 10, 13, 14, 14, 13, 12, 15]
	Time taken saving stuff: 0.01s

=== episode:368 Env-steps-taken:74592
 	picked: 102 |actions: {0: 769, 1: 682, 2: 863, 3: 543, 4: 605, 5: 713, 6: 563, 7: 913, 8: 705}
episode: 368/2000 -> reward: 131.88541666666657, steps:6356, time-taken: 4.03min, time-elasped: 3209.10min
-> berries picked: 102 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8736 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1295, 972, 774, 886, 1111, 1260, 1009, 646, 783]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 10, 8, 11, 11, 16, 15, 7, 12]
	Time taken saving stuff: 0.02s

=== episode:369 Env-steps-taken:62592
 	picked: 50 |actions: {0: 315, 1: 246, 2: 248, 3: 306, 4: 325, 5: 451, 6: 234, 7: 425, 8: 314}
episode: 369/2000 -> reward: 73.63541666666669, steps:2864, time-taken: 2.49min, time-elasped: 3211.59min
-> berries picked: 50 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8745 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1295, 969, 776, 885, 1112, 1264, 1012, 649, 783]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 13, 14, 11, 14, 16, 20, 13, 14]
	Time taken saving stuff: 0.02s

=== episode:370 Env-steps-taken:76032
 	picked: 100 |actions: {0: 611, 1: 562, 2: 639, 3: 668, 4: 749, 5: 845, 6: 513, 7: 989, 8: 604}
episode: 370/2000 -> reward: 140.77083333333326, steps:6180, time-taken: 4.26min, time-elasped: 3215.86min
-> berries picked: 100 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8770 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1301, 972, 779, 890, 1109, 1274, 1012, 646, 787]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 14, 11, 11, 14, 20, 14, 10, 19]
	Time taken saving stuff: 0.08s

=== episode:37 Env-steps-taken:83808
 	picked: 128 |actions: {0: 707, 1: 497, 2: 826, 3: 239, 4: 391, 5: 502, 6: 317, 7: 886, 8: 793}

==================================================
eval-episode: 370 -> reward: 180.16666666666688, steps: 5158.0, wall-time: 84.32s
-> berries picked: 128 of 800 | patches-visited: [1, 2, 5] | juice left:-0.00
==================================================


=== episode:371 Env-steps-taken:69792
 	picked: 87 |actions: {0: 578, 1: 561, 2: 403, 3: 390, 4: 557, 5: 635, 6: 500, 7: 758, 8: 512}
episode: 371/2000 -> reward: 109.01562499999986, steps:4894, time-taken: 3.44min, time-elasped: 3220.71min
-> berries picked: 87 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8791 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1305, 973, 779, 891, 1105, 1285, 1017, 647, 789]
	| approx positives in sample 512: 143
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [25, 14, 12, 20, 12, 22, 13, 5, 20]
	Time taken saving stuff: 0.03s

=== episode:372 Env-steps-taken:85152
 	picked: 127 |actions: {0: 739, 1: 595, 2: 602, 3: 499, 4: 802, 5: 874, 6: 561, 7: 889, 8: 546}
episode: 372/2000 -> reward: 182.39583333333357, steps:6107, time-taken: 4.06min, time-elasped: 3224.77min
-> berries picked: 127 of 800 | patches-visited: [0, 3, 4, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8834 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1309, 970, 780, 896, 1104, 1301, 1025, 655, 794]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [23, 9, 10, 16, 18, 17, 12, 8, 15]
	Time taken saving stuff: 0.02s

=== episode:373 Env-steps-taken:72000
 	picked: 97 |actions: {0: 494, 1: 608, 2: 609, 3: 412, 4: 679, 5: 709, 6: 415, 7: 945, 8: 397}
episode: 373/2000 -> reward: 119.94270833333317, steps:5268, time-taken: 3.88min, time-elasped: 3228.65min
-> berries picked: 97 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8854 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1317, 967, 786, 902, 1108, 1307, 1025, 648, 794]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 11, 12, 13, 19, 21, 9, 7, 21]
	Time taken saving stuff: 0.01s

=== episode:374 Env-steps-taken:69024
 	picked: 68 |actions: {0: 358, 1: 397, 2: 458, 3: 353, 4: 375, 5: 473, 6: 387, 7: 610, 8: 315}
episode: 374/2000 -> reward: 106.10416666666659, steps:3726, time-taken: 2.91min, time-elasped: 3231.57min
-> berries picked: 68 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8878 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1322, 971, 788, 906, 1107, 1312, 1030, 647, 795]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 6, 11, 8, 14, 19, 12, 19, 19]
	Time taken saving stuff: 0.00s

=== episode:375 Env-steps-taken:64128
 	picked: 58 |actions: {0: 559, 1: 632, 2: 444, 3: 425, 4: 415, 5: 537, 6: 344, 7: 961, 8: 666}
episode: 375/2000 -> reward: 81.17708333333331, steps:4983, time-taken: 3.40min, time-elasped: 3234.98min
-> berries picked: 58 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8874 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1321, 965, 786, 905, 1106, 1309, 1034, 648, 800]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 8, 13, 15, 14, 18, 16, 18, 15]
	Time taken saving stuff: 0.08s

=== episode:376 Env-steps-taken:63168
 	picked: 60 |actions: {0: 349, 1: 422, 2: 457, 3: 315, 4: 538, 5: 478, 6: 438, 7: 905, 8: 556}
episode: 376/2000 -> reward: 76.0625, steps:4458, time-taken: 3.51min, time-elasped: 3238.49min
-> berries picked: 60 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8884 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1318, 962, 782, 906, 1110, 1316, 1038, 651, 801]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 10, 10, 14, 15, 12, 16, 6, 15]
	Time taken saving stuff: 0.03s

=== episode:377 Env-steps-taken:64128
 	picked: 61 |actions: {0: 356, 1: 446, 2: 428, 3: 290, 4: 439, 5: 554, 6: 298, 7: 608, 8: 459}
episode: 377/2000 -> reward: 79.5625, steps:3878, time-taken: 2.81min, time-elasped: 3241.31min
-> berries picked: 61 of 800 | patches-visited: [0, 5, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8892 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1318, 961, 788, 906, 1115, 1312, 1038, 651, 803]
	| approx positives in sample 512: 139
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 15, 5, 16, 27, 12, 16, 3, 23]
	Time taken saving stuff: 0.02s

=== episode:378 Env-steps-taken:61632
 	picked: 50 |actions: {0: 285, 1: 246, 2: 224, 3: 196, 4: 325, 5: 272, 6: 176, 7: 390, 8: 264}
episode: 378/2000 -> reward: 68.6354166666667, steps:2378, time-taken: 1.93min, time-elasped: 3243.24min
-> berries picked: 50 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8899 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1314, 963, 793, 908, 1114, 1308, 1040, 654, 805]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 15, 20, 18, 16, 8, 17, 9, 14]
	Time taken saving stuff: 0.10s

=== episode:379 Env-steps-taken:76704
 	picked: 106 |actions: {0: 621, 1: 746, 2: 748, 3: 637, 4: 667, 5: 746, 6: 527, 7: 979, 8: 475}
episode: 379/2000 -> reward: 143.92708333333334, steps:6146, time-taken: 3.91min, time-elasped: 3247.16min
-> berries picked: 106 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8922 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1315, 966, 805, 913, 1114, 1311, 1036, 653, 809]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 8, 15, 10, 17, 14, 8, 5, 13]
	Time taken saving stuff: 0.10s

=== episode:380 Env-steps-taken:61920
 	picked: 49 |actions: {0: 240, 1: 317, 2: 288, 3: 221, 4: 223, 5: 261, 6: 264, 7: 413, 8: 252}
episode: 380/2000 -> reward: 69.69270833333336, steps:2479, time-taken: 2.27min, time-elasped: 3249.43min
-> berries picked: 49 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8934 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1318, 969, 806, 913, 1111, 1310, 1041, 656, 810]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 11, 14, 6, 14, 21, 16, 3, 17]
	Time taken saving stuff: 0.09s

=== episode:38 Env-steps-taken:96960
 	picked: 186 |actions: {0: 614, 1: 652, 2: 1002, 3: 319, 4: 687, 5: 827, 6: 356, 7: 1440, 8: 519}

==================================================
eval-episode: 380 -> reward: 245.84375000000063, steps: 6416.0, wall-time: 85.53s
-> berries picked: 186 of 800 | patches-visited: [1, 2, 5, 7] | juice left:-0.00
==================================================


=== episode:381 Env-steps-taken:65568
 	picked: 70 |actions: {0: 640, 1: 631, 2: 489, 3: 412, 4: 487, 5: 456, 6: 316, 7: 827, 8: 460}
episode: 381/2000 -> reward: 87.48958333333327, steps:4718, time-taken: 3.16min, time-elasped: 3254.03min
-> berries picked: 70 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8936 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1323, 973, 801, 912, 1110, 1307, 1040, 661, 809]
	| approx positives in sample 512: 100
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 18, 6, 10, 6, 15, 11, 6, 13]
	Time taken saving stuff: 0.01s

=== episode:382 Env-steps-taken:61152
 	picked: 48 |actions: {0: 194, 1: 224, 2: 275, 3: 222, 4: 245, 5: 270, 6: 216, 7: 290, 8: 191}
episode: 382/2000 -> reward: 65.75000000000004, steps:2127, time-taken: 1.87min, time-elasped: 3255.91min
-> berries picked: 48 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8958 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1328, 974, 803, 920, 1114, 1311, 1040, 659, 809]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 18, 12, 13, 20, 14, 19, 17, 10]
	Time taken saving stuff: 0.08s

=== episode:383 Env-steps-taken:70848
 	picked: 80 |actions: {0: 535, 1: 572, 2: 424, 3: 368, 4: 557, 5: 654, 6: 384, 7: 676, 8: 398}
episode: 383/2000 -> reward: 114.91666666666656, steps:4568, time-taken: 3.24min, time-elasped: 3259.15min
-> berries picked: 80 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8996 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1332, 976, 805, 924, 1122, 1317, 1043, 666, 811]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 14, 14, 19, 17, 13, 20, 9, 17]
	Time taken saving stuff: 0.01s

=== episode:384 Env-steps-taken:69696
 	picked: 84 |actions: {0: 633, 1: 655, 2: 758, 3: 614, 4: 584, 5: 591, 6: 448, 7: 714, 8: 663}
episode: 384/2000 -> reward: 108.30208333333323, steps:5660, time-taken: 4.30min, time-elasped: 3263.46min
-> berries picked: 84 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9026 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1336, 983, 816, 924, 1131, 1321, 1042, 663, 810]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [24, 14, 13, 8, 15, 14, 13, 10, 14]
	Time taken saving stuff: 0.09s

=== episode:385 Env-steps-taken:65856
 	picked: 71 |actions: {0: 431, 1: 466, 2: 461, 3: 404, 4: 508, 5: 507, 6: 333, 7: 896, 8: 280}
episode: 385/2000 -> reward: 88.93229166666661, steps:4286, time-taken: 2.67min, time-elasped: 3266.14min
-> berries picked: 71 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9052 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1343, 987, 816, 929, 1134, 1323, 1042, 668, 810]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 17, 10, 14, 11, 22, 7, 9, 21]
	Time taken saving stuff: 0.01s

=== episode:386 Env-steps-taken:71808
 	picked: 90 |actions: {0: 646, 1: 468, 2: 680, 3: 550, 4: 687, 5: 641, 6: 444, 7: 974, 8: 460}
episode: 386/2000 -> reward: 117.01562499999986, steps:5550, time-taken: 3.15min, time-elasped: 3269.30min
-> berries picked: 90 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9060 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1344, 990, 818, 924, 1132, 1327, 1040, 673, 812]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 17, 11, 17, 17, 12, 8, 12, 13]
	Time taken saving stuff: 0.01s

=== episode:387 Env-steps-taken:70656
 	picked: 88 |actions: {0: 638, 1: 621, 2: 664, 3: 481, 4: 598, 5: 600, 6: 427, 7: 835, 8: 474}
episode: 387/2000 -> reward: 113.45833333333319, steps:5338, time-taken: 2.99min, time-elasped: 3272.29min
-> berries picked: 88 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9085 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1346, 997, 823, 926, 1136, 1325, 1042, 675, 815]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 15, 16, 16, 14, 15, 13, 9, 12]
	Time taken saving stuff: 0.01s

=== episode:388 Env-steps-taken:74304
 	picked: 99 |actions: {0: 703, 1: 566, 2: 710, 3: 535, 4: 719, 5: 755, 6: 462, 7: 773, 8: 446}
episode: 388/2000 -> reward: 131.82812499999991, steps:5669, time-taken: 3.06min, time-elasped: 3275.36min
-> berries picked: 99 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9095 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1347, 1005, 819, 931, 1133, 1320, 1048, 679, 813]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 15, 16, 13, 10, 19, 9, 16, 12]
	Time taken saving stuff: 0.00s

=== episode:389 Env-steps-taken:67872
 	picked: 79 |actions: {0: 744, 1: 571, 2: 653, 3: 451, 4: 630, 5: 519, 6: 533, 7: 906, 8: 485}
episode: 389/2000 -> reward: 98.97395833333323, steps:5492, time-taken: 4.18min, time-elasped: 3279.54min
-> berries picked: 79 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9111 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1346, 1015, 823, 930, 1134, 1319, 1048, 682, 814]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 13, 13, 20, 16, 9, 17, 10, 13]
	Time taken saving stuff: 0.01s

=== episode:390 Env-steps-taken:65952
 	picked: 72 |actions: {0: 530, 1: 479, 2: 540, 3: 402, 4: 608, 5: 655, 6: 447, 7: 965, 8: 400}
episode: 390/2000 -> reward: 89.87499999999996, steps:5026, time-taken: 3.43min, time-elasped: 3282.97min
-> berries picked: 72 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9131 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1346, 1014, 825, 929, 1137, 1332, 1050, 682, 816]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 17, 8, 10, 17, 16, 11, 11, 14]
	Time taken saving stuff: 0.09s

=== episode:39 Env-steps-taken:101376
 	picked: 213 |actions: {0: 1405, 1: 701, 2: 739, 3: 445, 4: 669, 5: 904, 6: 823, 7: 1002, 8: 1260}

==================================================
eval-episode: 390 -> reward: 265.91145833333394, steps: 7948.0, wall-time: 78.26s
-> berries picked: 213 of 800 | patches-visited: [1, 4, 7] | juice left:-0.00
==================================================


=== episode:391 Env-steps-taken:70560
 	picked: 86 |actions: {0: 719, 1: 356, 2: 478, 3: 395, 4: 675, 5: 653, 6: 483, 7: 812, 8: 413}
episode: 391/2000 -> reward: 113.07291666666652, steps:4984, time-taken: 2.94min, time-elasped: 3287.22min
-> berries picked: 86 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9151 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1344, 1011, 830, 931, 1138, 1338, 1057, 685, 817]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 10, 12, 12, 16, 13, 24, 9, 15]
	Time taken saving stuff: 0.01s

=== episode:392 Env-steps-taken:67680
 	picked: 74 |actions: {0: 587, 1: 310, 2: 444, 3: 372, 4: 500, 5: 519, 6: 293, 7: 596, 8: 372}
episode: 392/2000 -> reward: 98.26041666666657, steps:3993, time-taken: 2.33min, time-elasped: 3289.56min
-> berries picked: 74 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9187 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1352, 1011, 830, 938, 1146, 1347, 1056, 690, 817]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 11, 16, 17, 6, 17, 17, 8, 20]
	Time taken saving stuff: 0.01s

=== episode:393 Env-steps-taken:60480
 	picked: 56 |actions: {0: 381, 1: 282, 2: 422, 3: 303, 4: 414, 5: 407, 6: 251, 7: 600, 8: 300}
episode: 393/2000 -> reward: 61.791666666666735, steps:3360, time-taken: 1.78min, time-elasped: 3291.34min
-> berries picked: 56 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9209 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1353, 1009, 831, 943, 1150, 1356, 1061, 689, 817]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 17, 11, 14, 19, 13, 18, 7, 21]
	Time taken saving stuff: 0.01s

=== episode:394 Env-steps-taken:73248
 	picked: 93 |actions: {0: 856, 1: 519, 2: 531, 3: 459, 4: 488, 5: 629, 6: 515, 7: 927, 8: 467}
episode: 394/2000 -> reward: 126.28645833333317, steps:5391, time-taken: 2.91min, time-elasped: 3294.25min
-> berries picked: 93 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9223 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1355, 1006, 832, 943, 1151, 1358, 1067, 692, 819]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 18, 8, 16, 12, 13, 16, 11, 13]
	Time taken saving stuff: 0.01s

=== episode:395 Env-steps-taken:72384
 	picked: 96 |actions: {0: 611, 1: 456, 2: 527, 3: 413, 4: 536, 5: 525, 6: 382, 7: 524, 8: 295}
episode: 395/2000 -> reward: 122.49999999999982, steps:4269, time-taken: 2.68min, time-elasped: 3296.94min
-> berries picked: 96 of 800 | patches-visited: [0, 1, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9269 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1363, 1008, 838, 946, 1153, 1366, 1079, 693, 823]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 13, 11, 15, 15, 18, 15, 13, 21]
	Time taken saving stuff: 0.01s

=== episode:396 Env-steps-taken:70560
 	picked: 81 |actions: {0: 701, 1: 563, 2: 527, 3: 492, 4: 661, 5: 654, 6: 426, 7: 691, 8: 420}
episode: 396/2000 -> reward: 113.35937499999986, steps:5135, time-taken: 3.13min, time-elasped: 3300.08min
-> berries picked: 81 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9289 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1367, 1008, 838, 949, 1155, 1372, 1083, 693, 824]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 14, 9, 11, 12, 22, 13, 10, 17]
	Time taken saving stuff: 0.13s

=== episode:397 Env-steps-taken:64032
 	picked: 64 |actions: {0: 433, 1: 445, 2: 304, 3: 243, 4: 450, 5: 421, 6: 257, 7: 510, 8: 183}
episode: 397/2000 -> reward: 80.33333333333331, steps:3246, time-taken: 289.39min, time-elasped: 3589.47min
-> berries picked: 64 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9308 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1369, 1015, 836, 956, 1155, 1377, 1084, 688, 828]
	| approx positives in sample 512: 155
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [26, 15, 12, 20, 20, 21, 12, 14, 15]
	Time taken saving stuff: 0.02s

=== episode:398 Env-steps-taken:63936
 	picked: 54 |actions: {0: 405, 1: 300, 2: 289, 3: 278, 4: 395, 5: 376, 6: 266, 7: 764, 8: 263}
episode: 398/2000 -> reward: 80.40624999999997, steps:3336, time-taken: 5.09min, time-elasped: 3594.57min
-> berries picked: 54 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9328 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1372, 1014, 835, 959, 1159, 1384, 1083, 691, 831]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 21, 9, 10, 17, 19, 11, 14, 15]
	Time taken saving stuff: 0.04s

=== episode:399 Env-steps-taken:66720
 	picked: 69 |actions: {0: 492, 1: 382, 2: 352, 3: 359, 4: 472, 5: 456, 6: 363, 7: 604, 8: 228}
episode: 399/2000 -> reward: 94.04687499999993, steps:3708, time-taken: 6.18min, time-elasped: 3600.76min
-> berries picked: 69 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9360 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1383, 1017, 835, 963, 1164, 1386, 1086, 694, 832]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 8, 12, 16, 18, 16, 20, 12, 15]
	Time taken saving stuff: 0.10s

=== episode:400 Env-steps-taken:74496
 	picked: 101 |actions: {0: 803, 1: 725, 2: 616, 3: 553, 4: 703, 5: 607, 6: 536, 7: 818, 8: 384}
episode: 400/2000 -> reward: 132.71354166666654, steps:5745, time-taken: 8.49min, time-elasped: 3609.25min
-> berries picked: 101 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9396 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1390, 1017, 836, 967, 1172, 1386, 1096, 698, 834]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [27, 10, 10, 11, 15, 15, 13, 10, 11]
	Time taken saving stuff: 0.17s

=== episode:40 Env-steps-taken:85440
 	picked: 152 |actions: {0: 934, 1: 277, 2: 442, 3: 585, 4: 580, 5: 436, 6: 1005, 7: 1032, 8: 654}

==================================================
eval-episode: 400 -> reward: 186.791666666667, steps: 5945.0, wall-time: 163.59s
-> berries picked: 152 of 800 | patches-visited: [1, 6] | juice left:-0.00
==================================================


=== episode:401 Env-steps-taken:73920
 	picked: 90 |actions: {0: 890, 1: 427, 2: 451, 3: 416, 4: 662, 5: 653, 6: 553, 7: 751, 8: 605}
episode: 401/2000 -> reward: 130.84374999999986, steps:5408, time-taken: 1296.58min, time-elasped: 4908.58min
-> berries picked: 90 of 800 | patches-visited: [0, 2, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9366 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1389, 1003, 829, 963, 1171, 1383, 1096, 697, 835]
	| approx positives in sample 512: 139
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [23, 16, 18, 11, 16, 19, 8, 14, 14]
	Time taken saving stuff: 0.02s

=== episode:402 Env-steps-taken:74304
 	picked: 90 |actions: {0: 701, 1: 562, 2: 622, 3: 474, 4: 728, 5: 610, 6: 417, 7: 718, 8: 525}
episode: 402/2000 -> reward: 130.9583333333332, steps:5357, time-taken: 2.06min, time-elasped: 4910.64min
-> berries picked: 90 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9373 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1384, 997, 827, 969, 1175, 1387, 1096, 701, 837]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 16, 16, 10, 19, 12, 17, 11, 17]
	Time taken saving stuff: 0.00s

=== episode:403 Env-steps-taken:58752
 	picked: 38 |actions: {0: 235, 1: 153, 2: 160, 3: 148, 4: 187, 5: 238, 6: 183, 7: 373, 8: 220}
episode: 403/2000 -> reward: 53.9947916666667, steps:1897, time-taken: 0.92min, time-elasped: 4911.57min
-> berries picked: 38 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9386 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1388, 998, 829, 967, 1173, 1386, 1101, 705, 839]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 11, 17, 13, 16, 15, 18, 11, 13]
	Time taken saving stuff: 0.09s

=== episode:404 Env-steps-taken:67680
 	picked: 79 |actions: {0: 818, 1: 590, 2: 526, 3: 409, 4: 656, 5: 671, 6: 576, 7: 957, 8: 739}
episode: 404/2000 -> reward: 97.97395833333324, steps:5942, time-taken: 2.41min, time-elasped: 4913.98min
-> berries picked: 79 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9411 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1387, 1007, 829, 968, 1182, 1389, 1102, 707, 840]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 14, 14, 11, 18, 18, 13, 14, 16]
	Time taken saving stuff: 0.02s

=== episode:405 Env-steps-taken:65376
 	picked: 67 |actions: {0: 568, 1: 408, 2: 448, 3: 307, 4: 625, 5: 484, 6: 516, 7: 708, 8: 381}
episode: 405/2000 -> reward: 87.1614583333333, steps:4445, time-taken: 2.25min, time-elasped: 4916.24min
-> berries picked: 67 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9420 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1387, 1006, 831, 973, 1177, 1391, 1106, 708, 841]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 10, 17, 12, 16, 17, 13, 9, 13]
	Time taken saving stuff: 0.11s

=== episode:406 Env-steps-taken:52416
 	picked: 16 |actions: {0: 156, 1: 78, 2: 73, 3: 66, 4: 85, 5: 148, 6: 187, 7: 102, 8: 239}
episode: 406/2000 -> reward: 22.083333333333332, steps:1134, time-taken: 0.84min, time-elasped: 4917.08min
-> berries picked: 16 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9398 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1384, 996, 827, 972, 1176, 1393, 1108, 703, 839]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 9, 11, 10, 11, 21, 15, 5, 12]
	Time taken saving stuff: 0.10s

=== episode:407 Env-steps-taken:67584
 	picked: 71 |actions: {0: 927, 1: 561, 2: 407, 3: 408, 4: 671, 5: 534, 6: 598, 7: 846, 8: 565}
episode: 407/2000 -> reward: 97.93229166666657, steps:5517, time-taken: 2.81min, time-elasped: 4919.90min
-> berries picked: 71 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9372 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1381, 987, 818, 970, 1177, 1388, 1111, 702, 838]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 16, 10, 13, 22, 15, 13, 9, 11]
	Time taken saving stuff: 0.01s

=== episode:408 Env-steps-taken:74688
 	picked: 96 |actions: {0: 849, 1: 619, 2: 569, 3: 504, 4: 752, 5: 562, 6: 427, 7: 783, 8: 510}
episode: 408/2000 -> reward: 134.55729166666654, steps:5575, time-taken: 2.80min, time-elasped: 4922.70min
-> berries picked: 96 of 800 | patches-visited: [0, 5, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9379 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1387, 983, 812, 976, 1172, 1399, 1110, 703, 837]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 10, 2, 17, 23, 15, 8, 10, 12]
	Time taken saving stuff: 0.01s

=== episode:409 Env-steps-taken:74976
 	picked: 98 |actions: {0: 919, 1: 555, 2: 550, 3: 589, 4: 692, 5: 529, 6: 624, 7: 846, 8: 489}
episode: 409/2000 -> reward: 134.4427083333332, steps:5793, time-taken: 2.91min, time-elasped: 4925.61min
-> berries picked: 98 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9390 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1390, 980, 813, 977, 1176, 1395, 1116, 702, 841]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [24, 20, 10, 15, 14, 21, 9, 14, 14]
	Time taken saving stuff: 0.01s

=== episode:410 Env-steps-taken:63072
 	picked: 51 |actions: {0: 378, 1: 300, 2: 279, 3: 245, 4: 328, 5: 303, 6: 356, 7: 389, 8: 346}
episode: 410/2000 -> reward: 76.078125, steps:2924, time-taken: 2.29min, time-elasped: 4927.91min
-> berries picked: 51 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9396 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1398, 978, 813, 979, 1177, 1389, 1115, 705, 842]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [23, 16, 12, 11, 21, 14, 12, 4, 14]
	Time taken saving stuff: 0.06s

=== episode:41 Env-steps-taken:99264
 	picked: 189 |actions: {0: 1085, 1: 552, 2: 361, 3: 581, 4: 552, 5: 724, 6: 356, 7: 870, 8: 312}

==================================================
eval-episode: 410 -> reward: 255.90104166666737, steps: 5393.0, wall-time: 71.02s
-> berries picked: 189 of 800 | patches-visited: [1, 2, 5, 9] | juice left:-0.00
==================================================


=== episode:411 Env-steps-taken:72864
 	picked: 96 |actions: {0: 610, 1: 663, 2: 512, 3: 465, 4: 601, 5: 579, 6: 408, 7: 990, 8: 285}
episode: 411/2000 -> reward: 122.55729166666649, steps:5113, time-taken: 3.15min, time-elasped: 4932.25min
-> berries picked: 96 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9316 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1374, 977, 797, 983, 1166, 1374, 1113, 690, 842]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 15, 19, 11, 13, 15, 10, 5, 19]
	Time taken saving stuff: 0.01s

=== episode:412 Env-steps-taken:73536
 	picked: 101 |actions: {0: 720, 1: 850, 2: 582, 3: 502, 4: 829, 5: 736, 6: 644, 7: 841, 8: 541}
episode: 412/2000 -> reward: 127.71354166666649, steps:6245, time-taken: 3.47min, time-elasped: 4935.72min
-> berries picked: 101 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9295 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1363, 970, 785, 979, 1169, 1370, 1123, 696, 840]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 15, 5, 9, 16, 15, 14, 7, 24]
	Time taken saving stuff: 0.02s

=== episode:413 Env-steps-taken:72768
 	picked: 94 |actions: {0: 627, 1: 518, 2: 460, 3: 494, 4: 703, 5: 599, 6: 483, 7: 819, 8: 653}
episode: 413/2000 -> reward: 124.61458333333317, steps:5356, time-taken: 3.29min, time-elasped: 4939.02min
-> berries picked: 94 of 800 | patches-visited: [0, 3, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9284 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1365, 973, 775, 976, 1167, 1366, 1122, 696, 844]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 13, 16, 19, 17, 28, 11, 7, 8]
	Time taken saving stuff: 0.10s

=== episode:414 Env-steps-taken:55296
 	picked: 24 |actions: {0: 251, 1: 150, 2: 124, 3: 88, 4: 140, 5: 146, 6: 135, 7: 114, 8: 278}
episode: 414/2000 -> reward: 36.62500000000001, steps:1426, time-taken: 1.36min, time-elasped: 4940.38min
-> berries picked: 24 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9283 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1368, 975, 774, 974, 1165, 1362, 1124, 697, 844]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 7, 13, 12, 16, 13, 14, 9, 17]
	Time taken saving stuff: 0.10s

=== episode:415 Env-steps-taken:69216
 	picked: 80 |actions: {0: 729, 1: 581, 2: 433, 3: 399, 4: 673, 5: 596, 6: 565, 7: 737, 8: 552}
episode: 415/2000 -> reward: 106.41666666666654, steps:5265, time-taken: 3.36min, time-elasped: 4943.75min
-> berries picked: 80 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9242 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1365, 971, 765, 963, 1169, 1356, 1120, 691, 842]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 11, 12, 13, 16, 17, 21, 10, 17]
	Time taken saving stuff: 0.09s

=== episode:416 Env-steps-taken:71904
 	picked: 95 |actions: {0: 571, 1: 472, 2: 561, 3: 447, 4: 708, 5: 718, 6: 486, 7: 683, 8: 343}
episode: 416/2000 -> reward: 119.17187499999986, steps:4989, time-taken: 2.89min, time-elasped: 4946.65min
-> berries picked: 95 of 800 | patches-visited: [0, 1, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9248 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1369, 966, 765, 956, 1165, 1365, 1125, 692, 845]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 9, 12, 7, 14, 19, 19, 10, 15]
	Time taken saving stuff: 0.01s

=== episode:417 Env-steps-taken:62880
 	picked: 51 |actions: {0: 465, 1: 490, 2: 311, 3: 277, 4: 357, 5: 327, 6: 259, 7: 353, 8: 252}
episode: 417/2000 -> reward: 75.07812500000001, steps:3091, time-taken: 1.67min, time-elasped: 4948.32min
-> berries picked: 51 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9233 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1374, 966, 764, 958, 1153, 1364, 1121, 689, 844]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 13, 8, 19, 17, 19, 19, 8, 15]
	Time taken saving stuff: 0.01s

=== episode:418 Env-steps-taken:79680
 	picked: 113 |actions: {0: 853, 1: 869, 2: 661, 3: 483, 4: 751, 5: 750, 6: 606, 7: 1043, 8: 693}
episode: 418/2000 -> reward: 157.58333333333331, steps:6709, time-taken: 3.77min, time-elasped: 4952.09min
-> berries picked: 113 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9246 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1373, 971, 773, 956, 1150, 1370, 1120, 691, 842]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 12, 9, 13, 11, 22, 13, 15, 20]
	Time taken saving stuff: 0.10s

=== episode:419 Env-steps-taken:64320
 	picked: 66 |actions: {0: 452, 1: 373, 2: 492, 3: 426, 4: 698, 5: 424, 6: 314, 7: 638, 8: 407}
episode: 419/2000 -> reward: 81.71874999999997, steps:4224, time-taken: 2.28min, time-elasped: 4954.37min
-> berries picked: 66 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9255 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1369, 968, 780, 959, 1154, 1372, 1121, 687, 845]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 7, 10, 20, 12, 10, 15, 11, 21]
	Time taken saving stuff: 0.09s

=== episode:420 Env-steps-taken:61440
 	picked: 50 |actions: {0: 453, 1: 281, 2: 359, 3: 189, 4: 272, 5: 300, 6: 248, 7: 393, 8: 161}
episode: 420/2000 -> reward: 67.13541666666671, steps:2656, time-taken: 1.76min, time-elasped: 4956.14min
-> berries picked: 50 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9248 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1368, 970, 782, 954, 1154, 1367, 1123, 686, 844]
	| approx positives in sample 512: 147
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [24, 17, 9, 13, 18, 23, 18, 8, 17]
	Time taken saving stuff: 0.06s

=== episode:42 Env-steps-taken:84192
 	picked: 143 |actions: {0: 805, 1: 358, 2: 685, 3: 235, 4: 628, 5: 382, 6: 646, 7: 1738, 8: 350}

==================================================
eval-episode: 420 -> reward: 180.8072916666669, steps: 5827.0, wall-time: 58.18s
-> berries picked: 143 of 800 | patches-visited: [1, 5] | juice left:-0.00
==================================================


=== episode:421 Env-steps-taken:64896
 	picked: 62 |actions: {0: 402, 1: 386, 2: 330, 3: 357, 4: 457, 5: 309, 6: 341, 7: 723, 8: 311}
episode: 421/2000 -> reward: 84.44791666666663, steps:3616, time-taken: 1.98min, time-elasped: 4959.09min
-> berries picked: 62 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9216 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1369, 961, 782, 959, 1149, 1347, 1118, 688, 843]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 12, 16, 19, 23, 14, 12, 13, 12]
	Time taken saving stuff: 0.02s

=== episode:422 Env-steps-taken:80256
 	picked: 116 |actions: {0: 831, 1: 667, 2: 734, 3: 580, 4: 902, 5: 674, 6: 637, 7: 1145, 8: 522}
episode: 422/2000 -> reward: 161.85416666666674, steps:6692, time-taken: 3.61min, time-elasped: 4962.71min
-> berries picked: 116 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9175 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1356, 954, 782, 960, 1141, 1343, 1100, 693, 846]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 12, 10, 10, 13, 14, 18, 12, 17]
	Time taken saving stuff: 0.01s

=== episode:423 Env-steps-taken:74112
 	picked: 104 |actions: {0: 888, 1: 605, 2: 461, 3: 548, 4: 759, 5: 678, 6: 456, 7: 978, 8: 426}
episode: 423/2000 -> reward: 130.54166666666654, steps:5799, time-taken: 3.97min, time-elasped: 4966.68min
-> berries picked: 104 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9147 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1355, 950, 783, 958, 1133, 1331, 1093, 696, 848]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 15, 12, 11, 10, 15, 23, 11, 17]
	Time taken saving stuff: 0.01s

=== episode:424 Env-steps-taken:68160
 	picked: 69 |actions: {0: 532, 1: 343, 2: 393, 3: 355, 4: 479, 5: 589, 6: 364, 7: 651, 8: 496}
episode: 424/2000 -> reward: 101.54687499999991, steps:4202, time-taken: 2.96min, time-elasped: 4969.65min
-> berries picked: 69 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9145 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1355, 949, 786, 957, 1129, 1328, 1094, 700, 847]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [26, 13, 12, 15, 9, 17, 17, 10, 21]
	Time taken saving stuff: 0.02s

=== episode:425 Env-steps-taken:66624
 	picked: 75 |actions: {0: 574, 1: 446, 2: 575, 3: 484, 4: 588, 5: 496, 6: 544, 7: 975, 8: 455}
episode: 425/2000 -> reward: 92.70312499999994, steps:5137, time-taken: 3.37min, time-elasped: 4973.03min
-> berries picked: 75 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9143 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1353, 950, 786, 962, 1129, 1323, 1098, 694, 848]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 9, 13, 10, 14, 13, 15, 15, 9]
	Time taken saving stuff: 0.10s

=== episode:426 Env-steps-taken:70656
 	picked: 92 |actions: {0: 607, 1: 631, 2: 575, 3: 545, 4: 746, 5: 603, 6: 549, 7: 1070, 8: 342}
episode: 426/2000 -> reward: 113.2291666666665, steps:5668, time-taken: 3.58min, time-elasped: 4976.60min
-> berries picked: 92 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9164 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1359, 951, 789, 963, 1122, 1326, 1105, 699, 850]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 12, 15, 10, 13, 19, 13, 7, 11]
	Time taken saving stuff: 0.03s

=== episode:427 Env-steps-taken:75456
 	picked: 102 |actions: {0: 704, 1: 658, 2: 627, 3: 594, 4: 798, 5: 654, 6: 525, 7: 857, 8: 447}
episode: 427/2000 -> reward: 136.27083333333326, steps:5864, time-taken: 3.97min, time-elasped: 4980.58min
-> berries picked: 102 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9168 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1368, 955, 797, 972, 1117, 1316, 1097, 699, 847]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 14, 13, 9, 13, 17, 18, 11, 16]
	Time taken saving stuff: 0.01s

=== episode:428 Env-steps-taken:66144
 	picked: 64 |actions: {0: 509, 1: 430, 2: 347, 3: 368, 4: 526, 5: 441, 6: 348, 7: 471, 8: 277}
episode: 428/2000 -> reward: 89.39062499999994, steps:3717, time-taken: 2.56min, time-elasped: 4983.14min
-> berries picked: 64 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9160 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1372, 957, 797, 970, 1117, 1310, 1098, 697, 842]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 15, 11, 9, 21, 18, 14, 7, 10]
	Time taken saving stuff: 0.03s

=== episode:429 Env-steps-taken:68160
 	picked: 72 |actions: {0: 498, 1: 324, 2: 279, 3: 297, 4: 552, 5: 531, 6: 330, 7: 644, 8: 345}
episode: 429/2000 -> reward: 100.48958333333327, steps:3800, time-taken: 3.04min, time-elasped: 4986.19min
-> berries picked: 72 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9176 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1374, 963, 794, 971, 1113, 1314, 1103, 703, 841]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 9, 13, 14, 15, 17, 15, 13, 13]
	Time taken saving stuff: 0.01s

=== episode:430 Env-steps-taken:76416
 	picked: 107 |actions: {0: 848, 1: 592, 2: 598, 3: 629, 4: 830, 5: 784, 6: 540, 7: 1133, 8: 574}
episode: 430/2000 -> reward: 142.36979166666657, steps:6528, time-taken: 4.23min, time-elasped: 4990.43min
-> berries picked: 107 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9192 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1375, 965, 797, 966, 1121, 1318, 1108, 700, 842]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 14, 12, 19, 15, 17, 14, 9, 11]
	Time taken saving stuff: 0.09s

=== episode:43 Env-steps-taken:82176
 	picked: 135 |actions: {0: 1124, 1: 412, 2: 525, 3: 206, 4: 546, 5: 486, 6: 583, 7: 2486, 8: 727}

==================================================
eval-episode: 430 -> reward: 169.8802083333334, steps: 7095.0, wall-time: 76.04s
-> berries picked: 135 of 800 | patches-visited: [1, 5] | juice left:-0.00
==================================================


=== episode:431 Env-steps-taken:68448
 	picked: 74 |actions: {0: 604, 1: 392, 2: 344, 3: 404, 4: 497, 5: 634, 6: 405, 7: 466, 8: 337}
episode: 431/2000 -> reward: 102.76041666666657, steps:4083, time-taken: 2.78min, time-elasped: 4994.48min
-> berries picked: 74 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9214 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1378, 963, 796, 968, 1128, 1320, 1113, 703, 845]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 10, 13, 12, 13, 16, 12, 7, 10]
	Time taken saving stuff: 0.02s

=== episode:432 Env-steps-taken:74496
 	picked: 97 |actions: {0: 686, 1: 424, 2: 570, 3: 473, 4: 616, 5: 617, 6: 435, 7: 802, 8: 396}
episode: 432/2000 -> reward: 133.44270833333317, steps:5019, time-taken: 3.12min, time-elasped: 4997.61min
-> berries picked: 97 of 800 | patches-visited: [0, 1, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9218 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1375, 964, 792, 969, 1129, 1328, 1111, 701, 849]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 19, 8, 13, 17, 13, 13, 11, 8]
	Time taken saving stuff: 0.10s

=== episode:433 Env-steps-taken:69120
 	picked: 79 |actions: {0: 834, 1: 483, 2: 325, 3: 341, 4: 509, 5: 520, 6: 417, 7: 597, 8: 615}
episode: 433/2000 -> reward: 105.97395833333323, steps:4641, time-taken: 2.98min, time-elasped: 5000.59min
-> berries picked: 79 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9222 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1381, 961, 794, 968, 1133, 1333, 1114, 689, 849]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 14, 8, 7, 9, 19, 12, 15, 10]
	Time taken saving stuff: 0.03s

=== episode:434 Env-steps-taken:73440
 	picked: 97 |actions: {0: 734, 1: 529, 2: 558, 3: 507, 4: 604, 5: 571, 6: 419, 7: 654, 8: 454}
episode: 434/2000 -> reward: 127.44270833333313, steps:5030, time-taken: 3.26min, time-elasped: 5003.86min
-> berries picked: 97 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9244 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1379, 965, 798, 974, 1137, 1338, 1117, 683, 853]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 12, 14, 11, 15, 14, 10, 9, 15]
	Time taken saving stuff: 0.02s

=== episode:435 Env-steps-taken:57408
 	picked: 32 |actions: {0: 233, 1: 157, 2: 253, 3: 195, 4: 285, 5: 203, 6: 193, 7: 305, 8: 132}
episode: 435/2000 -> reward: 47.666666666666686, steps:1956, time-taken: 1.61min, time-elasped: 5005.47min
-> berries picked: 32 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9252 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1379, 961, 802, 979, 1135, 1341, 1120, 683, 852]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 20, 21, 19, 17, 13, 18, 7, 16]
	Time taken saving stuff: 0.01s

=== episode:436 Env-steps-taken:55296
 	picked: 28 |actions: {0: 373, 1: 219, 2: 199, 3: 172, 4: 316, 5: 227, 6: 227, 7: 909, 8: 215}
episode: 436/2000 -> reward: 36.395833333333336, steps:2857, time-taken: 1.74min, time-elasped: 5007.22min
-> berries picked: 28 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9220 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1374, 951, 788, 971, 1137, 1340, 1121, 688, 850]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 13, 13, 11, 18, 15, 16, 9, 21]
	Time taken saving stuff: 0.01s

=== episode:437 Env-steps-taken:56160
 	picked: 27 |actions: {0: 179, 1: 107, 2: 82, 3: 105, 4: 148, 5: 154, 6: 132, 7: 305, 8: 120}
episode: 437/2000 -> reward: 40.95312500000002, steps:1332, time-taken: 1.38min, time-elasped: 5008.60min
-> berries picked: 27 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9218 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1378, 945, 786, 965, 1138, 1344, 1124, 689, 849]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 18, 18, 15, 9, 13, 14, 11, 15]
	Time taken saving stuff: 0.00s

=== episode:438 Env-steps-taken:66624
 	picked: 66 |actions: {0: 734, 1: 412, 2: 433, 3: 354, 4: 603, 5: 381, 6: 381, 7: 549, 8: 348}
episode: 438/2000 -> reward: 93.71874999999996, steps:4195, time-taken: 2.52min, time-elasped: 5011.13min
-> berries picked: 66 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9171 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1369, 936, 772, 955, 1136, 1345, 1121, 687, 850]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [23, 8, 16, 14, 19, 4, 16, 9, 15]
	Time taken saving stuff: 0.11s

=== episode:439 Env-steps-taken:65376
 	picked: 64 |actions: {0: 489, 1: 309, 2: 399, 3: 313, 4: 490, 5: 398, 6: 325, 7: 602, 8: 237}
episode: 439/2000 -> reward: 85.94791666666666, steps:3562, time-taken: 2.22min, time-elasped: 5013.35min
-> berries picked: 64 of 800 | patches-visited: [0, 2, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9174 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1367, 930, 766, 955, 1136, 1352, 1125, 692, 851]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 10, 10, 9, 18, 17, 16, 17, 19]
	Time taken saving stuff: 0.19s

=== episode:440 Env-steps-taken:63648
 	picked: 56 |actions: {0: 515, 1: 288, 2: 298, 3: 276, 4: 392, 5: 345, 6: 262, 7: 651, 8: 269}
episode: 440/2000 -> reward: 76.84895833333334, steps:3296, time-taken: 2.18min, time-elasped: 5015.54min
-> berries picked: 56 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9165 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1364, 925, 764, 954, 1136, 1355, 1126, 689, 852]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [24, 9, 12, 13, 9, 15, 10, 9, 18]
	Time taken saving stuff: 0.15s

=== episode:44 Env-steps-taken:70944
 	picked: 81 |actions: {0: 3312, 1: 195, 2: 210, 3: 246, 4: 456, 5: 306, 6: 125, 7: 1564, 8: 36}

==================================================
eval-episode: 440 -> reward: 115.35937499999986, steps: 6450.0, wall-time: 45.60s
-> berries picked: 81 of 800 | patches-visited: [1, 5] | juice left:-0.00
==================================================


=== episode:441 Env-steps-taken:73824
 	picked: 96 |actions: {0: 788, 1: 464, 2: 587, 3: 401, 4: 856, 5: 739, 6: 427, 7: 808, 8: 396}
episode: 441/2000 -> reward: 129.49999999999986, steps:5466, time-taken: 2.96min, time-elasped: 5019.27min
-> berries picked: 96 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9140 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1364, 924, 767, 935, 1136, 1351, 1126, 685, 852]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 8, 14, 8, 23, 19, 13, 6, 15]
	Time taken saving stuff: 0.03s

=== episode:442 Env-steps-taken:75648
 	picked: 100 |actions: {0: 802, 1: 600, 2: 615, 3: 557, 4: 885, 5: 578, 6: 486, 7: 785, 8: 450}
episode: 442/2000 -> reward: 138.77083333333326, steps:5758, time-taken: 3.31min, time-elasped: 5022.58min
-> berries picked: 100 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9151 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1366, 926, 773, 927, 1143, 1349, 1123, 692, 852]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 16, 13, 13, 8, 18, 14, 7, 16]
	Time taken saving stuff: 0.01s

=== episode:443 Env-steps-taken:56928
 	picked: 35 |actions: {0: 362, 1: 148, 2: 118, 3: 153, 4: 195, 5: 220, 6: 177, 7: 462, 8: 145}
episode: 443/2000 -> reward: 44.552083333333364, steps:1980, time-taken: 1.54min, time-elasped: 5024.13min
-> berries picked: 35 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9155 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1373, 923, 774, 925, 1140, 1348, 1125, 699, 848]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 14, 13, 8, 18, 13, 11, 9, 16]
	Time taken saving stuff: 0.08s

=== episode:444 Env-steps-taken:73344
 	picked: 91 |actions: {0: 948, 1: 578, 2: 666, 3: 453, 4: 847, 5: 475, 6: 502, 7: 650, 8: 380}
episode: 444/2000 -> reward: 127.28645833333316, steps:5499, time-taken: 3.09min, time-elasped: 5027.22min
-> berries picked: 91 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9178 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1376, 934, 779, 925, 1141, 1351, 1124, 702, 846]
	| approx positives in sample 512: 152
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 16, 23, 16, 13, 15, 19, 12, 19]
	Time taken saving stuff: 0.02s

=== episode:445 Env-steps-taken:55680
 	picked: 27 |actions: {0: 187, 1: 105, 2: 105, 3: 75, 4: 135, 5: 179, 6: 169, 7: 272, 8: 82}
episode: 445/2000 -> reward: 38.45312500000001, steps:1309, time-taken: 1.14min, time-elasped: 5028.36min
-> berries picked: 27 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9193 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1378, 935, 782, 924, 1144, 1356, 1127, 702, 845]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 17, 9, 12, 17, 17, 9, 15, 20]
	Time taken saving stuff: 0.01s

=== episode:446 Env-steps-taken:62304
 	picked: 54 |actions: {0: 464, 1: 374, 2: 305, 3: 264, 4: 382, 5: 449, 6: 229, 7: 462, 8: 315}
episode: 446/2000 -> reward: 71.40625000000003, steps:3244, time-taken: 2.36min, time-elasped: 5030.73min
-> berries picked: 54 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9116 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1372, 923, 780, 914, 1133, 1347, 1112, 691, 844]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 15, 11, 14, 19, 15, 14, 11, 13]
	Time taken saving stuff: 0.21s

=== episode:447 Env-steps-taken:77952
 	picked: 115 |actions: {0: 1082, 1: 666, 2: 576, 3: 433, 4: 786, 5: 845, 6: 473, 7: 984, 8: 531}
episode: 447/2000 -> reward: 149.91145833333331, steps:6376, time-taken: 3.99min, time-elasped: 5034.72min
-> berries picked: 115 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9074 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1367, 912, 774, 913, 1132, 1348, 1101, 688, 839]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [27, 3, 18, 11, 10, 12, 12, 10, 14]
	Time taken saving stuff: 0.00s

=== episode:448 Env-steps-taken:66336
 	picked: 76 |actions: {0: 574, 1: 494, 2: 503, 3: 426, 4: 604, 5: 529, 6: 384, 7: 747, 8: 400}
episode: 448/2000 -> reward: 91.14583333333324, steps:4661, time-taken: 2.81min, time-elasped: 5037.53min
-> berries picked: 76 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9057 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1357, 909, 771, 911, 1133, 1349, 1096, 693, 838]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 9, 13, 15, 18, 11, 15, 8, 21]
	Time taken saving stuff: 0.01s

=== episode:449 Env-steps-taken:62208
 	picked: 53 |actions: {0: 513, 1: 343, 2: 332, 3: 250, 4: 322, 5: 383, 6: 346, 7: 677, 8: 251}
episode: 449/2000 -> reward: 70.96354166666669, steps:3417, time-taken: 2.12min, time-elasped: 5039.66min
-> berries picked: 53 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9021 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1355, 902, 768, 901, 1134, 1340, 1097, 688, 836]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 15, 21, 16, 19, 13, 20, 9, 13]
	Time taken saving stuff: 0.03s

=== episode:450 Env-steps-taken:77856
 	picked: 108 |actions: {0: 853, 1: 598, 2: 570, 3: 607, 4: 895, 5: 683, 6: 455, 7: 1025, 8: 433}
episode: 450/2000 -> reward: 149.81249999999997, steps:6119, time-taken: 562.30min, time-elasped: 5601.96min
-> berries picked: 108 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9002 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1360, 897, 766, 893, 1138, 1344, 1087, 684, 833]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [23, 4, 11, 13, 17, 22, 14, 4, 13]
	Time taken saving stuff: 0.06s

=== episode:45 Env-steps-taken:81792
 	picked: 127 |actions: {0: 781, 1: 591, 2: 169, 3: 330, 4: 525, 5: 351, 6: 291, 7: 3124, 8: 397}

==================================================
eval-episode: 450 -> reward: 169.72395833333346, steps: 6559.0, wall-time: 39.42s
-> berries picked: 127 of 800 | patches-visited: [1, 5, 9] | juice left:-0.00
==================================================


=== episode:451 Env-steps-taken:76608
 	picked: 112 |actions: {0: 699, 1: 760, 2: 760, 3: 430, 4: 792, 5: 793, 6: 401, 7: 949, 8: 333}
episode: 451/2000 -> reward: 141.69791666666657, steps:5917, time-taken: 2.92min, time-elasped: 5605.54min
-> berries picked: 112 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8943 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1357, 890, 768, 887, 1137, 1325, 1065, 682, 832]
	| approx positives in sample 512: 145
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 16, 16, 17, 21, 13, 17, 12, 17]
	Time taken saving stuff: 0.02s

=== episode:452 Env-steps-taken:65472
 	picked: 66 |actions: {0: 443, 1: 448, 2: 401, 3: 277, 4: 339, 5: 429, 6: 260, 7: 610, 8: 345}
episode: 452/2000 -> reward: 87.71874999999997, steps:3552, time-taken: 1.83min, time-elasped: 5607.37min
-> berries picked: 66 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8947 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1360, 894, 772, 884, 1138, 1321, 1061, 685, 832]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 11, 9, 12, 16, 16, 20, 12, 10]
	Time taken saving stuff: 0.04s

=== episode:453 Env-steps-taken:66144
 	picked: 70 |actions: {0: 483, 1: 440, 2: 419, 3: 318, 4: 464, 5: 573, 6: 400, 7: 775, 8: 400}
episode: 453/2000 -> reward: 90.98958333333329, steps:4272, time-taken: 1.99min, time-elasped: 5609.36min
-> berries picked: 70 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8929 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1355, 895, 768, 882, 1135, 1319, 1062, 681, 832]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 8, 10, 11, 14, 12, 9, 9, 12]
	Time taken saving stuff: 0.12s

=== episode:454 Env-steps-taken:61056
 	picked: 43 |actions: {0: 189, 1: 187, 2: 161, 3: 151, 4: 208, 5: 254, 6: 199, 7: 317, 8: 108}
episode: 454/2000 -> reward: 66.03645833333337, steps:1774, time-taken: 1.27min, time-elasped: 5610.64min
-> berries picked: 43 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8942 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1358, 894, 769, 879, 1139, 1321, 1065, 682, 835]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 8, 8, 12, 20, 16, 12, 9, 20]
	Time taken saving stuff: 0.09s

=== episode:455 Env-steps-taken:65760
 	picked: 63 |actions: {0: 400, 1: 405, 2: 400, 3: 313, 4: 490, 5: 593, 6: 313, 7: 582, 8: 303}
episode: 455/2000 -> reward: 89.39062499999993, steps:3799, time-taken: 2.35min, time-elasped: 5613.00min
-> berries picked: 63 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8944 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1359, 890, 772, 880, 1142, 1322, 1063, 681, 835]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 8, 9, 15, 13, 19, 22, 6, 15]
	Time taken saving stuff: 0.01s

=== episode:456 Env-steps-taken:70464
 	picked: 84 |actions: {0: 641, 1: 513, 2: 460, 3: 414, 4: 573, 5: 570, 6: 500, 7: 665, 8: 295}
episode: 456/2000 -> reward: 112.68749999999987, steps:4631, time-taken: 2.56min, time-elasped: 5615.56min
-> berries picked: 84 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8949 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1358, 891, 766, 881, 1147, 1323, 1062, 689, 832]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [26, 6, 9, 15, 13, 14, 16, 11, 17]
	Time taken saving stuff: 0.05s

=== episode:457 Env-steps-taken:63552
 	picked: 66 |actions: {0: 862, 1: 571, 2: 454, 3: 386, 4: 641, 5: 517, 6: 441, 7: 725, 8: 302}
episode: 457/2000 -> reward: 77.21874999999999, steps:4899, time-taken: 2.89min, time-elasped: 5618.46min
-> berries picked: 66 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8938 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1356, 885, 767, 883, 1143, 1316, 1067, 689, 832]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 11, 9, 10, 17, 16, 15, 8, 11]
	Time taken saving stuff: 0.00s

=== episode:458 Env-steps-taken:76704
 	picked: 109 |actions: {0: 834, 1: 540, 2: 592, 3: 561, 4: 988, 5: 791, 6: 583, 7: 854, 8: 568}
episode: 458/2000 -> reward: 141.86979166666663, steps:6311, time-taken: 3.36min, time-elasped: 5621.82min
-> berries picked: 109 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8953 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1359, 884, 767, 886, 1136, 1319, 1072, 696, 834]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 9, 9, 10, 16, 9, 15, 9, 17]
	Time taken saving stuff: 0.01s

=== episode:459 Env-steps-taken:66144
 	picked: 75 |actions: {0: 526, 1: 580, 2: 507, 3: 453, 4: 632, 5: 732, 6: 524, 7: 1228, 8: 591}
episode: 459/2000 -> reward: 90.20312499999994, steps:5773, time-taken: 3.02min, time-elasped: 5624.85min
-> berries picked: 75 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8961 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1361, 888, 766, 884, 1140, 1323, 1075, 690, 834]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 12, 9, 9, 17, 21, 26, 12, 13]
	Time taken saving stuff: 0.01s

=== episode:460 Env-steps-taken:63168
 	picked: 53 |actions: {0: 583, 1: 316, 2: 408, 3: 238, 4: 306, 5: 456, 6: 419, 7: 604, 8: 398}
episode: 460/2000 -> reward: 75.96354166666666, steps:3728, time-taken: 2.42min, time-elasped: 5627.27min
-> berries picked: 53 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8974 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1368, 891, 767, 881, 1135, 1329, 1074, 696, 833]
	| approx positives in sample 512: 146
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 11, 11, 17, 18, 22, 17, 11, 24]
	Time taken saving stuff: 0.06s

=== episode:46 Env-steps-taken:79776
 	picked: 123 |actions: {0: 571, 1: 539, 2: 428, 3: 211, 4: 624, 5: 388, 6: 498, 7: 641, 8: 263}

==================================================
eval-episode: 460 -> reward: 158.95312500000006, steps: 4163.0, wall-time: 49.30s
-> berries picked: 123 of 800 | patches-visited: [1, 4] | juice left:-0.00
==================================================


=== episode:461 Env-steps-taken:73824
 	picked: 101 |actions: {0: 487, 1: 614, 2: 437, 3: 589, 4: 707, 5: 677, 6: 507, 7: 915, 8: 388}
episode: 461/2000 -> reward: 129.7135416666665, steps:5321, time-taken: 2.83min, time-elasped: 5630.92min
-> berries picked: 101 of 800 | patches-visited: [0, 5, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8981 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1355, 895, 768, 891, 1130, 1339, 1076, 694, 833]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 12, 13, 10, 13, 24, 15, 8, 12]
	Time taken saving stuff: 0.11s

=== episode:462 Env-steps-taken:70848
 	picked: 84 |actions: {0: 380, 1: 532, 2: 406, 3: 367, 4: 530, 5: 669, 6: 336, 7: 744, 8: 407}
episode: 462/2000 -> reward: 114.68749999999987, steps:4371, time-taken: 2.41min, time-elasped: 5633.33min
-> berries picked: 84 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8984 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1345, 899, 771, 891, 1133, 1345, 1077, 690, 833]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 18, 13, 15, 21, 8, 14, 16, 21]
	Time taken saving stuff: 0.01s

=== episode:463 Env-steps-taken:64704
 	picked: 66 |actions: {0: 405, 1: 437, 2: 381, 3: 315, 4: 527, 5: 573, 6: 372, 7: 542, 8: 212}
episode: 463/2000 -> reward: 83.21874999999997, steps:3764, time-taken: 2.52min, time-elasped: 5635.86min
-> berries picked: 66 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8988 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1342, 895, 775, 889, 1134, 1347, 1076, 694, 836]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [23, 15, 3, 13, 10, 16, 21, 5, 16]
	Time taken saving stuff: 0.01s

=== episode:464 Env-steps-taken:66336
 	picked: 74 |actions: {0: 504, 1: 501, 2: 472, 3: 321, 4: 508, 5: 567, 6: 404, 7: 769, 8: 376}
episode: 464/2000 -> reward: 91.26041666666657, steps:4422, time-taken: 2.32min, time-elasped: 5638.19min
-> berries picked: 74 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 8992 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1349, 893, 774, 883, 1131, 1351, 1076, 700, 835]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 12, 8, 14, 19, 17, 11, 6, 13]
	Time taken saving stuff: 0.01s

=== episode:465 Env-steps-taken:63648
 	picked: 59 |actions: {0: 260, 1: 427, 2: 395, 3: 372, 4: 496, 5: 423, 6: 287, 7: 492, 8: 391}
episode: 465/2000 -> reward: 78.11979166666664, steps:3543, time-taken: 1.94min, time-elasped: 5640.13min
-> berries picked: 59 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9003 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1349, 896, 772, 890, 1130, 1347, 1078, 705, 836]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 11, 10, 21, 15, 14, 20, 8, 22]
	Time taken saving stuff: 0.01s

=== episode:466 Env-steps-taken:80832
 	picked: 123 |actions: {0: 674, 1: 795, 2: 635, 3: 570, 4: 785, 5: 1099, 6: 508, 7: 972, 8: 427}
episode: 466/2000 -> reward: 164.45312500000006, steps:6465, time-taken: 3.44min, time-elasped: 5643.58min
-> berries picked: 123 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9027 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1348, 899, 781, 888, 1140, 1353, 1076, 706, 836]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 9, 21, 13, 14, 18, 12, 16, 15]
	Time taken saving stuff: 0.01s

=== episode:467 Env-steps-taken:80448
 	picked: 118 |actions: {0: 802, 1: 844, 2: 602, 3: 556, 4: 874, 5: 948, 6: 499, 7: 948, 8: 492}
episode: 467/2000 -> reward: 162.73958333333348, steps:6565, time-taken: 3.49min, time-elasped: 5647.07min
-> berries picked: 118 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9043 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1349, 905, 786, 883, 1149, 1355, 1077, 703, 836]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 17, 11, 10, 15, 19, 22, 10, 18]
	Time taken saving stuff: 0.10s

=== episode:468 Env-steps-taken:67776
 	picked: 77 |actions: {0: 542, 1: 708, 2: 536, 3: 345, 4: 433, 5: 547, 6: 377, 7: 709, 8: 406}
episode: 468/2000 -> reward: 98.5885416666666, steps:4603, time-taken: 2.58min, time-elasped: 5649.66min
-> berries picked: 77 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9054 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1350, 913, 785, 881, 1149, 1353, 1080, 706, 837]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 19, 13, 7, 9, 13, 12, 7, 15]
	Time taken saving stuff: 0.02s

=== episode:469 Env-steps-taken:66240
 	picked: 65 |actions: {0: 318, 1: 354, 2: 319, 3: 321, 4: 525, 5: 515, 6: 269, 7: 418, 8: 174}
episode: 469/2000 -> reward: 91.77604166666661, steps:3213, time-taken: 2.16min, time-elasped: 5651.82min
-> berries picked: 65 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9077 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1355, 915, 789, 885, 1152, 1359, 1080, 705, 837]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [27, 9, 10, 12, 19, 26, 13, 14, 8]
	Time taken saving stuff: 0.12s

=== episode:470 Env-steps-taken:71040
 	picked: 88 |actions: {0: 507, 1: 561, 2: 606, 3: 460, 4: 655, 5: 489, 6: 410, 7: 791, 8: 679}
episode: 470/2000 -> reward: 115.45833333333319, steps:5158, time-taken: 3.35min, time-elasped: 5655.17min
-> berries picked: 88 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9086 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1357, 920, 790, 884, 1152, 1360, 1077, 708, 838]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [25, 13, 11, 11, 15, 21, 12, 13, 20]
	Time taken saving stuff: 0.17s

=== episode:47 Env-steps-taken:83424
 	picked: 140 |actions: {0: 534, 1: 430, 2: 543, 3: 219, 4: 583, 5: 511, 6: 419, 7: 890, 8: 389}

==================================================
eval-episode: 470 -> reward: 177.47916666666688, steps: 4518.0, wall-time: 78.30s
-> berries picked: 140 of 800 | patches-visited: [1, 3, 4] | juice left:-0.00
==================================================


=== episode:471 Env-steps-taken:69504
 	picked: 72 |actions: {0: 514, 1: 491, 2: 348, 3: 276, 4: 456, 5: 528, 6: 380, 7: 457, 8: 354}
episode: 471/2000 -> reward: 108.3749999999999, steps:3804, time-taken: 2.56min, time-elasped: 5659.05min
-> berries picked: 72 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9066 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1353, 914, 782, 881, 1153, 1365, 1076, 705, 837]
	| approx positives in sample 512: 139
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [23, 8, 13, 16, 21, 14, 13, 14, 17]
	Time taken saving stuff: 0.03s

=== episode:472 Env-steps-taken:68352
 	picked: 75 |actions: {0: 457, 1: 645, 2: 452, 3: 445, 4: 563, 5: 518, 6: 497, 7: 594, 8: 510}
episode: 472/2000 -> reward: 102.20312499999991, steps:4681, time-taken: 2.68min, time-elasped: 5661.73min
-> berries picked: 75 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9051 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1348, 913, 772, 878, 1155, 1368, 1076, 704, 837]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 9, 14, 9, 14, 19, 14, 10, 17]
	Time taken saving stuff: 0.11s

=== episode:473 Env-steps-taken:73920
 	picked: 100 |actions: {0: 680, 1: 595, 2: 575, 3: 420, 4: 724, 5: 688, 6: 563, 7: 928, 8: 576}
episode: 473/2000 -> reward: 127.8281249999998, steps:5749, time-taken: 3.24min, time-elasped: 5664.98min
-> berries picked: 100 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9047 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1340, 915, 771, 872, 1164, 1374, 1080, 696, 835]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 7, 8, 10, 12, 18, 9, 8, 17]
	Time taken saving stuff: 0.10s

=== episode:474 Env-steps-taken:69600
 	picked: 85 |actions: {0: 443, 1: 502, 2: 493, 3: 353, 4: 674, 5: 528, 6: 434, 7: 709, 8: 438}
episode: 474/2000 -> reward: 106.74479166666654, steps:4574, time-taken: 2.60min, time-elasped: 5667.59min
-> berries picked: 85 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9061 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1338, 916, 768, 876, 1166, 1381, 1078, 700, 838]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 16, 15, 15, 11, 14, 11, 11, 15]
	Time taken saving stuff: 0.10s

=== episode:475 Env-steps-taken:67680
 	picked: 73 |actions: {0: 426, 1: 581, 2: 493, 3: 383, 4: 557, 5: 658, 6: 471, 7: 1481, 8: 470}
episode: 475/2000 -> reward: 98.31770833333323, steps:5520, time-taken: 2.89min, time-elasped: 5670.49min
-> berries picked: 73 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9063 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1333, 917, 767, 878, 1165, 1387, 1080, 699, 837]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [25, 13, 13, 12, 10, 18, 22, 15, 16]
	Time taken saving stuff: 0.02s

=== episode:476 Env-steps-taken:65088
 	picked: 68 |actions: {0: 372, 1: 568, 2: 434, 3: 333, 4: 585, 5: 527, 6: 429, 7: 738, 8: 280}
episode: 476/2000 -> reward: 85.10416666666661, steps:4266, time-taken: 2.10min, time-elasped: 5672.59min
-> berries picked: 68 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9077 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1331, 918, 766, 881, 1170, 1388, 1086, 697, 840]
	| approx positives in sample 512: 145
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 15, 7, 14, 20, 16, 24, 10, 21]
	Time taken saving stuff: 0.10s

=== episode:477 Env-steps-taken:68832
 	picked: 71 |actions: {0: 364, 1: 483, 2: 470, 3: 363, 4: 539, 5: 455, 6: 391, 7: 441, 8: 246}
episode: 477/2000 -> reward: 104.9322916666666, steps:3752, time-taken: 2.20min, time-elasped: 5674.80min
-> berries picked: 71 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9094 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1333, 916, 768, 886, 1174, 1392, 1086, 697, 842]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 7, 11, 15, 23, 15, 12, 13, 20]
	Time taken saving stuff: 0.10s

=== episode:478 Env-steps-taken:74496
 	picked: 98 |actions: {0: 663, 1: 692, 2: 666, 3: 502, 4: 754, 5: 693, 6: 622, 7: 1042, 8: 539}
episode: 478/2000 -> reward: 132.88541666666654, steps:6173, time-taken: 3.46min, time-elasped: 5678.26min
-> berries picked: 98 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9110 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1332, 923, 770, 891, 1173, 1397, 1089, 692, 843]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 9, 9, 16, 16, 20, 17, 7, 23]
	Time taken saving stuff: 0.10s

=== episode:479 Env-steps-taken:73536
 	picked: 100 |actions: {0: 620, 1: 628, 2: 600, 3: 456, 4: 740, 5: 626, 6: 451, 7: 696, 8: 397}
episode: 479/2000 -> reward: 127.77083333333314, steps:5214, time-taken: 2.87min, time-elasped: 5681.14min
-> berries picked: 100 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9156 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1334, 933, 770, 899, 1181, 1405, 1091, 698, 845]
	| approx positives in sample 512: 150
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [23, 16, 3, 20, 21, 13, 19, 10, 25]
	Time taken saving stuff: 0.11s

=== episode:480 Env-steps-taken:67008
 	picked: 73 |actions: {0: 464, 1: 551, 2: 517, 3: 337, 4: 467, 5: 437, 6: 512, 7: 617, 8: 445}
episode: 480/2000 -> reward: 94.81770833333324, steps:4347, time-taken: 2.51min, time-elasped: 5683.66min
-> berries picked: 73 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9169 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1339, 930, 765, 900, 1187, 1409, 1096, 699, 844]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 10, 12, 14, 15, 10, 27, 9, 9]
	Time taken saving stuff: 0.09s

=== episode:48 Env-steps-taken:81792
 	picked: 132 |actions: {0: 255, 1: 549, 2: 437, 3: 398, 4: 509, 5: 412, 6: 351, 7: 837, 8: 343}

==================================================
eval-episode: 480 -> reward: 168.93750000000009, steps: 4091.0, wall-time: 60.35s
-> berries picked: 132 of 800 | patches-visited: [1, 3] | juice left:-0.00
==================================================


=== episode:481 Env-steps-taken:74688
 	picked: 94 |actions: {0: 469, 1: 714, 2: 680, 3: 468, 4: 638, 5: 520, 6: 666, 7: 720, 8: 463}
episode: 481/2000 -> reward: 132.22916666666654, steps:5338, time-taken: 2.81min, time-elasped: 5687.48min
-> berries picked: 94 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9166 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1325, 924, 770, 899, 1189, 1417, 1091, 700, 851]
	| approx positives in sample 512: 146
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 9, 11, 16, 17, 15, 26, 17, 15]
	Time taken saving stuff: 0.00s

=== episode:482 Env-steps-taken:69312
 	picked: 70 |actions: {0: 513, 1: 547, 2: 438, 3: 337, 4: 622, 5: 515, 6: 581, 7: 758, 8: 512}
episode: 482/2000 -> reward: 107.98958333333323, steps:4823, time-taken: 3.02min, time-elasped: 5690.51min
-> berries picked: 70 of 800 | patches-visited: [0, 5, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9193 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1324, 929, 767, 900, 1198, 1423, 1095, 706, 851]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 17, 13, 17, 18, 17, 13, 8, 19]
	Time taken saving stuff: 0.01s

=== episode:483 Env-steps-taken:79104
 	picked: 119 |actions: {0: 691, 1: 695, 2: 876, 3: 521, 4: 742, 5: 527, 6: 565, 7: 936, 8: 509}
episode: 483/2000 -> reward: 155.29687500000006, steps:6062, time-taken: 3.62min, time-elasped: 5694.13min
-> berries picked: 119 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9211 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1319, 923, 771, 902, 1210, 1422, 1098, 711, 855]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 10, 14, 11, 16, 23, 13, 7, 14]
	Time taken saving stuff: 0.11s

=== episode:484 Env-steps-taken:78816
 	picked: 116 |actions: {0: 763, 1: 920, 2: 723, 3: 492, 4: 771, 5: 701, 6: 693, 7: 799, 8: 583}
episode: 484/2000 -> reward: 154.35416666666677, steps:6445, time-taken: 3.99min, time-elasped: 5698.13min
-> berries picked: 116 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9233 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1319, 921, 776, 901, 1215, 1430, 1102, 712, 857]
	| approx positives in sample 512: 139
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 14, 14, 16, 17, 28, 12, 11, 10]
	Time taken saving stuff: 0.03s

=== episode:485 Env-steps-taken:77472
 	picked: 104 |actions: {0: 613, 1: 735, 2: 492, 3: 501, 4: 763, 5: 654, 6: 703, 7: 919, 8: 589}
episode: 485/2000 -> reward: 147.65624999999997, steps:5969, time-taken: 3.58min, time-elasped: 5701.71min
-> berries picked: 104 of 800 | patches-visited: [0, 2, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9261 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1316, 918, 775, 902, 1224, 1440, 1109, 717, 860]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 8, 8, 15, 18, 11, 16, 19, 21]
	Time taken saving stuff: 0.03s

=== episode:486 Env-steps-taken:74400
 	picked: 105 |actions: {0: 707, 1: 674, 2: 514, 3: 714, 4: 650, 5: 586, 6: 677, 7: 924, 8: 705}
episode: 486/2000 -> reward: 131.98437499999986, steps:6151, time-taken: 3.56min, time-elasped: 5705.27min
-> berries picked: 105 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9278 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1316, 919, 778, 907, 1222, 1437, 1118, 721, 860]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 10, 7, 13, 13, 18, 16, 16, 10]
	Time taken saving stuff: 0.20s

=== episode:487 Env-steps-taken:62976
 	picked: 58 |actions: {0: 543, 1: 415, 2: 354, 3: 352, 4: 353, 5: 315, 6: 448, 7: 351, 8: 232}
episode: 487/2000 -> reward: 74.67708333333333, steps:3363, time-taken: 2.07min, time-elasped: 5707.35min
-> berries picked: 58 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9296 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1322, 922, 775, 909, 1221, 1442, 1123, 722, 860]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 14, 7, 13, 17, 16, 12, 8, 12]
	Time taken saving stuff: 0.02s

=== episode:488 Env-steps-taken:61152
 	picked: 52 |actions: {0: 303, 1: 323, 2: 249, 3: 293, 4: 211, 5: 240, 6: 259, 7: 336, 8: 266}
episode: 488/2000 -> reward: 65.52083333333339, steps:2480, time-taken: 1.59min, time-elasped: 5708.94min
-> berries picked: 52 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9299 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1324, 920, 779, 907, 1217, 1436, 1127, 726, 863]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [25, 7, 11, 7, 14, 21, 17, 8, 19]
	Time taken saving stuff: 0.15s

=== episode:489 Env-steps-taken:86016
 	picked: 135 |actions: {0: 762, 1: 871, 2: 701, 3: 749, 4: 740, 5: 680, 6: 581, 7: 737, 8: 490}
episode: 489/2000 -> reward: 189.32291666666686, steps:6311, time-taken: 3.70min, time-elasped: 5712.65min
-> berries picked: 135 of 800 | patches-visited: [0, 1, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9343 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1327, 922, 784, 912, 1220, 1447, 1136, 730, 865]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [23, 9, 12, 7, 15, 14, 15, 10, 18]
	Time taken saving stuff: 0.09s

=== episode:490 Env-steps-taken:71424
 	picked: 87 |actions: {0: 645, 1: 661, 2: 523, 3: 367, 4: 434, 5: 480, 6: 786, 7: 550, 8: 571}
episode: 490/2000 -> reward: 117.51562499999984, steps:5017, time-taken: 3.09min, time-elasped: 5715.75min
-> berries picked: 87 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9362 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1330, 921, 789, 909, 1219, 1453, 1142, 734, 865]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 9, 9, 14, 12, 18, 10, 10, 15]
	Time taken saving stuff: 0.16s

=== episode:49 Env-steps-taken:79968
 	picked: 122 |actions: {0: 349, 1: 632, 2: 308, 3: 357, 4: 443, 5: 281, 6: 495, 7: 482, 8: 467}

==================================================
eval-episode: 490 -> reward: 160.0104166666667, steps: 3814.0, wall-time: 68.84s
-> berries picked: 122 of 800 | patches-visited: [1, 4] | juice left:-0.00
==================================================


=== episode:491 Env-steps-taken:71904
 	picked: 85 |actions: {0: 504, 1: 619, 2: 389, 3: 396, 4: 506, 5: 528, 6: 474, 7: 619, 8: 386}
episode: 491/2000 -> reward: 120.1302083333332, steps:4421, time-taken: 2.74min, time-elasped: 5719.64min
-> berries picked: 85 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9363 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1339, 928, 792, 905, 1217, 1447, 1139, 731, 865]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 16, 10, 8, 16, 16, 16, 18, 13]
	Time taken saving stuff: 0.02s

=== episode:492 Env-steps-taken:68640
 	picked: 75 |actions: {0: 379, 1: 556, 2: 322, 3: 391, 4: 619, 5: 401, 6: 377, 7: 687, 8: 354}
episode: 492/2000 -> reward: 103.70312499999993, steps:4086, time-taken: 2.57min, time-elasped: 5722.22min
-> berries picked: 75 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9368 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1345, 921, 788, 910, 1225, 1447, 1133, 732, 867]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 12, 11, 11, 15, 14, 13, 16, 14]
	Time taken saving stuff: 0.10s

=== episode:493 Env-steps-taken:74592
 	picked: 92 |actions: {0: 595, 1: 832, 2: 391, 3: 487, 4: 640, 5: 614, 6: 498, 7: 738, 8: 584}
episode: 493/2000 -> reward: 133.72916666666654, steps:5379, time-taken: 3.09min, time-elasped: 5725.31min
-> berries picked: 92 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9370 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1344, 922, 788, 912, 1222, 1450, 1132, 733, 867]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 18, 13, 7, 15, 15, 11, 6, 18]
	Time taken saving stuff: 0.11s

=== episode:494 Env-steps-taken:71616
 	picked: 84 |actions: {0: 579, 1: 628, 2: 353, 3: 420, 4: 537, 5: 365, 6: 466, 7: 837, 8: 364}
episode: 494/2000 -> reward: 118.68749999999986, steps:4549, time-taken: 2.68min, time-elasped: 5728.00min
-> berries picked: 84 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9381 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1342, 923, 792, 916, 1217, 1449, 1135, 736, 871]
	| approx positives in sample 512: 149
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 7, 15, 12, 10, 30, 19, 16, 19]
	Time taken saving stuff: 0.03s

=== episode:495 Env-steps-taken:69408
 	picked: 82 |actions: {0: 567, 1: 635, 2: 457, 3: 510, 4: 642, 5: 570, 6: 598, 7: 749, 8: 853}
episode: 495/2000 -> reward: 107.30208333333319, steps:5581, time-taken: 3.17min, time-elasped: 5731.17min
-> berries picked: 82 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9405 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1343, 926, 796, 914, 1222, 1453, 1139, 738, 874]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 19, 8, 11, 13, 19, 10, 6, 15]
	Time taken saving stuff: 0.09s

=== episode:496 Env-steps-taken:63936
 	picked: 66 |actions: {0: 480, 1: 411, 2: 423, 3: 330, 4: 491, 5: 517, 6: 517, 7: 744, 8: 525}
episode: 496/2000 -> reward: 79.21874999999996, steps:4438, time-taken: 2.52min, time-elasped: 5733.69min
-> berries picked: 66 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9427 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1345, 927, 800, 910, 1225, 1458, 1145, 743, 874]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 18, 17, 12, 14, 11, 8, 14, 14]
	Time taken saving stuff: 0.11s

=== episode:497 Env-steps-taken:70848
 	picked: 78 |actions: {0: 481, 1: 443, 2: 306, 3: 314, 4: 479, 5: 465, 6: 424, 7: 796, 8: 540}
episode: 497/2000 -> reward: 115.53124999999989, steps:4248, time-taken: 2.37min, time-elasped: 5736.07min
-> berries picked: 78 of 800 | patches-visited: [0, 2, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9453 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1350, 928, 797, 914, 1222, 1468, 1148, 751, 875]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 15, 13, 16, 16, 12, 16, 9, 12]
	Time taken saving stuff: 0.02s

=== episode:498 Env-steps-taken:74304
 	picked: 98 |actions: {0: 661, 1: 677, 2: 556, 3: 757, 4: 624, 5: 645, 6: 484, 7: 746, 8: 499}
episode: 498/2000 -> reward: 131.88541666666652, steps:5649, time-taken: 2.99min, time-elasped: 5739.06min
-> berries picked: 98 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9482 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1355, 930, 804, 922, 1220, 1470, 1154, 750, 877]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [26, 15, 13, 9, 17, 14, 17, 14, 11]
	Time taken saving stuff: 0.02s

=== episode:499 Env-steps-taken:67008
 	picked: 65 |actions: {0: 543, 1: 481, 2: 407, 3: 419, 4: 475, 5: 518, 6: 389, 7: 904, 8: 515}
episode: 499/2000 -> reward: 93.83333333333327, steps:4651, time-taken: 2.51min, time-elasped: 5741.58min
-> berries picked: 65 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9499 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1359, 930, 807, 927, 1220, 1471, 1156, 750, 879]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 11, 16, 21, 15, 24, 14, 11, 14]
	Time taken saving stuff: 0.00s

=== episode:500 Env-steps-taken:78912
 	picked: 107 |actions: {0: 586, 1: 864, 2: 420, 3: 658, 4: 720, 5: 612, 6: 626, 7: 771, 8: 463}
episode: 500/2000 -> reward: 155.48437500000003, steps:5720, time-taken: 2.93min, time-elasped: 5744.51min
-> berries picked: 107 of 800 | patches-visited: [0, 3, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9533 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1357, 944, 804, 932, 1230, 1477, 1159, 746, 884]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 11, 12, 17, 11, 20, 11, 8, 19]
	Time taken saving stuff: 0.16s

=== episode:50 Env-steps-taken:82944
 	picked: 136 |actions: {0: 561, 1: 575, 2: 307, 3: 482, 4: 283, 5: 453, 6: 277, 7: 681, 8: 173}

==================================================
eval-episode: 500 -> reward: 175.2083333333336, steps: 3792.0, wall-time: 60.55s
-> berries picked: 136 of 800 | patches-visited: [1, 2, 5] | juice left:-0.00
==================================================


=== episode:501 Env-steps-taken:63360
 	picked: 59 |actions: {0: 549, 1: 415, 2: 378, 3: 426, 4: 459, 5: 423, 6: 401, 7: 781, 8: 574}
episode: 501/2000 -> reward: 77.11979166666667, steps:4406, time-taken: 2.52min, time-elasped: 5748.04min
-> berries picked: 59 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9555 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1361, 946, 808, 937, 1229, 1481, 1159, 749, 885]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 16, 11, 13, 10, 17, 15, 15, 25]
	Time taken saving stuff: 0.09s

=== episode:502 Env-steps-taken:70368
 	picked: 81 |actions: {0: 467, 1: 488, 2: 333, 3: 414, 4: 682, 5: 455, 6: 556, 7: 555, 8: 296}
episode: 502/2000 -> reward: 110.47395833333323, steps:4246, time-taken: 2.56min, time-elasped: 5750.61min
-> berries picked: 81 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9591 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1361, 949, 812, 934, 1240, 1489, 1167, 752, 887]
	| approx positives in sample 512: 179
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [35, 16, 9, 17, 23, 19, 26, 12, 22]
	Time taken saving stuff: 0.02s

=== episode:503 Env-steps-taken:66912
 	picked: 62 |actions: {0: 440, 1: 334, 2: 265, 3: 254, 4: 296, 5: 441, 6: 533, 7: 701, 8: 231}
episode: 503/2000 -> reward: 94.00520833333329, steps:3495, time-taken: 2.11min, time-elasped: 5752.72min
-> berries picked: 62 of 800 | patches-visited: [0, 4, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9619 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1360, 954, 812, 935, 1241, 1496, 1173, 760, 888]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 15, 17, 18, 19, 22, 13, 10, 9]
	Time taken saving stuff: 0.02s

=== episode:504 Env-steps-taken:65568
 	picked: 65 |actions: {0: 388, 1: 512, 2: 306, 3: 380, 4: 478, 5: 421, 6: 455, 7: 555, 8: 247}
episode: 504/2000 -> reward: 87.33333333333333, steps:3742, time-taken: 2.10min, time-elasped: 5754.82min
-> berries picked: 65 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9624 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1362, 949, 810, 938, 1249, 1490, 1176, 762, 888]
	| approx positives in sample 512: 154
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 20, 11, 19, 16, 19, 20, 13, 14]
	Time taken saving stuff: 0.12s

=== episode:505 Env-steps-taken:72096
 	picked: 87 |actions: {0: 705, 1: 581, 2: 421, 3: 449, 4: 697, 5: 594, 6: 687, 7: 834, 8: 597}
episode: 505/2000 -> reward: 119.07291666666653, steps:5565, time-taken: 3.06min, time-elasped: 5757.88min
-> berries picked: 87 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9646 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1367, 947, 815, 932, 1254, 1494, 1180, 768, 889]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 14, 8, 13, 13, 24, 15, 18, 15]
	Time taken saving stuff: 0.10s

=== episode:506 Env-steps-taken:61920
 	picked: 54 |actions: {0: 569, 1: 522, 2: 363, 3: 486, 4: 441, 5: 386, 6: 480, 7: 661, 8: 567}
episode: 506/2000 -> reward: 69.40625, steps:4475, time-taken: 2.41min, time-elasped: 5760.30min
-> berries picked: 54 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9652 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1372, 946, 814, 933, 1255, 1495, 1179, 768, 890]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 14, 10, 12, 14, 21, 13, 12, 19]
	Time taken saving stuff: 0.10s

=== episode:507 Env-steps-taken:64512
 	picked: 63 |actions: {0: 420, 1: 313, 2: 289, 3: 331, 4: 304, 5: 413, 6: 471, 7: 462, 8: 235}
episode: 507/2000 -> reward: 82.39062499999999, steps:3238, time-taken: 1.91min, time-elasped: 5762.20min
-> berries picked: 63 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9676 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1377, 947, 818, 931, 1254, 1503, 1188, 772, 886]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [25, 14, 9, 15, 15, 19, 17, 13, 8]
	Time taken saving stuff: 0.09s

=== episode:508 Env-steps-taken:73056
 	picked: 91 |actions: {0: 702, 1: 478, 2: 446, 3: 432, 4: 705, 5: 676, 6: 811, 7: 723, 8: 510}
episode: 508/2000 -> reward: 125.78645833333314, steps:5483, time-taken: 2.99min, time-elasped: 5765.20min
-> berries picked: 91 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9696 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1378, 946, 813, 932, 1258, 1509, 1195, 778, 887]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 12, 11, 15, 13, 19, 15, 14, 13]
	Time taken saving stuff: 0.08s

=== episode:509 Env-steps-taken:77760
 	picked: 107 |actions: {0: 775, 1: 763, 2: 650, 3: 652, 4: 678, 5: 638, 6: 647, 7: 679, 8: 510}
episode: 509/2000 -> reward: 149.36979166666663, steps:5992, time-taken: 3.18min, time-elasped: 5768.39min
-> berries picked: 107 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9730 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1382, 952, 824, 932, 1260, 1514, 1205, 772, 889]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 21, 10, 14, 17, 12, 21, 16, 10]
	Time taken saving stuff: 0.01s

=== episode:510 Env-steps-taken:74784
 	picked: 105 |actions: {0: 819, 1: 667, 2: 562, 3: 627, 4: 779, 5: 736, 6: 805, 7: 696, 8: 439}
episode: 510/2000 -> reward: 133.98437499999983, steps:6130, time-taken: 3.59min, time-elasped: 5771.98min
-> berries picked: 105 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9734 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1379, 950, 824, 935, 1261, 1518, 1211, 767, 889]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [25, 7, 12, 14, 17, 23, 18, 11, 10]
	Time taken saving stuff: 0.05s

=== episode:51 Env-steps-taken:102240
 	picked: 214 |actions: {0: 820, 1: 789, 2: 539, 3: 855, 4: 804, 5: 768, 6: 686, 7: 1026, 8: 213}

==================================================
eval-episode: 510 -> reward: 271.2395833333337, steps: 6500.0, wall-time: 75.32s
-> berries picked: 214 of 800 | patches-visited: [1, 5, 7] | juice left:-0.00
==================================================


=== episode:511 Env-steps-taken:64896
 	picked: 69 |actions: {0: 332, 1: 419, 2: 394, 3: 313, 4: 528, 5: 471, 6: 440, 7: 592, 8: 265}
episode: 511/2000 -> reward: 84.04687499999994, steps:3754, time-taken: 2.14min, time-elasped: 5775.38min
-> berries picked: 69 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9745 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1380, 955, 829, 938, 1261, 1515, 1210, 768, 889]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [23, 9, 10, 7, 19, 22, 21, 13, 18]
	Time taken saving stuff: 0.11s

=== episode:512 Env-steps-taken:79296
 	picked: 110 |actions: {0: 723, 1: 631, 2: 543, 3: 667, 4: 842, 5: 798, 6: 771, 7: 736, 8: 589}
episode: 512/2000 -> reward: 155.75520833333334, steps:6300, time-taken: 3.46min, time-elasped: 5778.85min
-> berries picked: 110 of 800 | patches-visited: [0, 1, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9789 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1386, 957, 830, 949, 1272, 1522, 1212, 767, 894]
	| approx positives in sample 512: 154
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 16, 16, 15, 24, 23, 16, 13, 10]
	Time taken saving stuff: 0.03s

=== episode:513 Env-steps-taken:69216
 	picked: 73 |actions: {0: 481, 1: 406, 2: 301, 3: 345, 4: 525, 5: 419, 6: 396, 7: 565, 8: 325}
episode: 513/2000 -> reward: 106.81770833333324, steps:3763, time-taken: 2.13min, time-elasped: 5780.98min
-> berries picked: 73 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9812 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1387, 960, 828, 950, 1279, 1531, 1211, 770, 896]
	| approx positives in sample 512: 139
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 13, 16, 15, 21, 17, 14, 18, 11]
	Time taken saving stuff: 0.02s

=== episode:514 Env-steps-taken:73440
 	picked: 97 |actions: {0: 854, 1: 784, 2: 642, 3: 593, 4: 768, 5: 604, 6: 480, 7: 710, 8: 458}
episode: 514/2000 -> reward: 124.67187499999983, steps:5893, time-taken: 3.27min, time-elasped: 5784.25min
-> berries picked: 97 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9824 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1386, 967, 832, 952, 1277, 1534, 1204, 773, 899]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 9, 13, 17, 12, 21, 16, 15, 19]
	Time taken saving stuff: 0.02s

=== episode:515 Env-steps-taken:83616
 	picked: 128 |actions: {0: 844, 1: 690, 2: 522, 3: 680, 4: 829, 5: 886, 6: 769, 7: 832, 8: 437}
episode: 515/2000 -> reward: 179.16666666666686, steps:6489, time-taken: 3.62min, time-elasped: 5787.88min
-> berries picked: 128 of 800 | patches-visited: [0, 3, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9844 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1392, 959, 826, 959, 1286, 1544, 1207, 771, 900]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 12, 12, 8, 16, 13, 11, 10, 20]
	Time taken saving stuff: 0.09s

=== episode:516 Env-steps-taken:63264
 	picked: 51 |actions: {0: 375, 1: 289, 2: 266, 3: 246, 4: 290, 5: 344, 6: 342, 7: 397, 8: 168}
episode: 516/2000 -> reward: 76.57812500000001, steps:2717, time-taken: 1.86min, time-elasped: 5789.74min
-> berries picked: 51 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9849 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1392, 955, 828, 960, 1288, 1540, 1211, 773, 902]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 11, 18, 12, 13, 14, 20, 15, 18]
	Time taken saving stuff: 0.11s

=== episode:517 Env-steps-taken:59424
 	picked: 38 |actions: {0: 247, 1: 237, 2: 140, 3: 143, 4: 280, 5: 153, 6: 221, 7: 211, 8: 164}
episode: 517/2000 -> reward: 57.3229166666667, steps:1796, time-taken: 1.25min, time-elasped: 5791.00min
-> berries picked: 38 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9864 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1398, 948, 827, 964, 1291, 1544, 1215, 776, 901]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 9, 17, 11, 18, 19, 20, 14, 13]
	Time taken saving stuff: 0.04s

=== episode:518 Env-steps-taken:70464
 	picked: 82 |actions: {0: 670, 1: 546, 2: 496, 3: 375, 4: 541, 5: 511, 6: 599, 7: 790, 8: 425}
episode: 518/2000 -> reward: 112.80208333333317, steps:4953, time-taken: 2.87min, time-elasped: 5793.87min
-> berries picked: 82 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9889 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1402, 954, 829, 968, 1296, 1544, 1217, 777, 902]
	| approx positives in sample 512: 151
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 16, 11, 15, 21, 26, 23, 10, 15]
	Time taken saving stuff: 0.10s

=== episode:519 Env-steps-taken:63552
 	picked: 62 |actions: {0: 657, 1: 491, 2: 345, 3: 393, 4: 385, 5: 466, 6: 369, 7: 653, 8: 414}
episode: 519/2000 -> reward: 77.5052083333333, steps:4173, time-taken: 2.47min, time-elasped: 5796.35min
-> berries picked: 62 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9913 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1407, 958, 832, 970, 1300, 1541, 1220, 783, 902]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 20, 16, 11, 18, 17, 11, 12, 18]
	Time taken saving stuff: 0.01s

=== episode:520 Env-steps-taken:72192
 	picked: 91 |actions: {0: 1012, 1: 645, 2: 480, 3: 462, 4: 735, 5: 652, 6: 683, 7: 742, 8: 536}
episode: 520/2000 -> reward: 121.28645833333319, steps:5947, time-taken: 3.52min, time-elasped: 5799.87min
-> berries picked: 91 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9947 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1413, 960, 837, 969, 1309, 1546, 1225, 784, 904]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 16, 12, 10, 19, 19, 18, 14, 14]
	Time taken saving stuff: 0.06s

=== episode:52 Env-steps-taken:81216
 	picked: 130 |actions: {0: 627, 1: 491, 2: 488, 3: 369, 4: 310, 5: 463, 6: 546, 7: 453, 8: 270}

==================================================
eval-episode: 520 -> reward: 166.05208333333337, steps: 4017.0, wall-time: 53.65s
-> berries picked: 130 of 800 | patches-visited: [1, 4] | juice left:-0.00
==================================================


=== episode:521 Env-steps-taken:74496
 	picked: 100 |actions: {0: 607, 1: 726, 2: 521, 3: 726, 4: 883, 5: 725, 6: 660, 7: 731, 8: 454}
episode: 521/2000 -> reward: 132.7708333333332, steps:6033, time-taken: 3.16min, time-elasped: 5803.93min
-> berries picked: 100 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9978 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1414, 966, 843, 974, 1311, 1555, 1225, 785, 905]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 16, 10, 13, 17, 18, 13, 13, 19]
	Time taken saving stuff: 0.02s

=== episode:522 Env-steps-taken:66048
 	picked: 74 |actions: {0: 568, 1: 577, 2: 366, 3: 395, 4: 401, 5: 480, 6: 682, 7: 551, 8: 446}
episode: 522/2000 -> reward: 89.7604166666666, steps:4466, time-taken: 2.57min, time-elasped: 5806.50min
-> berries picked: 74 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9994 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1415, 974, 846, 975, 1313, 1550, 1232, 782, 907]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 14, 10, 11, 20, 27, 12, 10, 16]
	Time taken saving stuff: 0.09s

=== episode:523 Env-steps-taken:70656
 	picked: 83 |actions: {0: 656, 1: 558, 2: 387, 3: 424, 4: 445, 5: 498, 6: 430, 7: 502, 8: 376}
episode: 523/2000 -> reward: 113.3593749999999, steps:4276, time-taken: 2.53min, time-elasped: 5809.04min
-> berries picked: 83 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10023 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1422, 976, 848, 978, 1317, 1554, 1233, 786, 909]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 15, 7, 20, 17, 17, 11, 13, 11]
	Time taken saving stuff: 0.03s

=== episode:524 Env-steps-taken:75360
 	picked: 102 |actions: {0: 717, 1: 658, 2: 450, 3: 491, 4: 660, 5: 586, 6: 747, 7: 648, 8: 310}
episode: 524/2000 -> reward: 137.15624999999986, steps:5267, time-taken: 3.26min, time-elasped: 5812.31min
-> berries picked: 102 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10051 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1424, 981, 852, 981, 1316, 1564, 1236, 787, 910]
	| approx positives in sample 512: 147
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 16, 9, 10, 17, 22, 17, 11, 23]
	Time taken saving stuff: 0.03s

=== episode:525 Env-steps-taken:72192
 	picked: 96 |actions: {0: 907, 1: 711, 2: 530, 3: 592, 4: 703, 5: 729, 6: 559, 7: 660, 8: 513}
episode: 525/2000 -> reward: 120.9999999999998, steps:5904, time-taken: 3.45min, time-elasped: 5815.77min
-> berries picked: 96 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10060 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1425, 979, 850, 990, 1318, 1560, 1241, 787, 910]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [26, 7, 11, 15, 23, 16, 15, 10, 13]
	Time taken saving stuff: 0.01s

=== episode:526 Env-steps-taken:62112
 	picked: 59 |actions: {0: 721, 1: 395, 2: 335, 3: 451, 4: 400, 5: 383, 6: 469, 7: 413, 8: 269}
episode: 526/2000 -> reward: 70.6197916666667, steps:3836, time-taken: 2.08min, time-elasped: 5817.85min
-> berries picked: 59 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10088 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1431, 980, 853, 988, 1324, 1561, 1248, 792, 911]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 15, 14, 17, 17, 17, 13, 15, 22]
	Time taken saving stuff: 0.00s

=== episode:527 Env-steps-taken:63072
 	picked: 62 |actions: {0: 784, 1: 398, 2: 400, 3: 475, 4: 491, 5: 628, 6: 453, 7: 569, 8: 630}
episode: 527/2000 -> reward: 75.44791666666669, steps:4828, time-taken: 2.66min, time-elasped: 5820.51min
-> berries picked: 62 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10120 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1435, 982, 857, 991, 1331, 1570, 1248, 794, 912]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 9, 6, 9, 18, 27, 20, 10, 15]
	Time taken saving stuff: 0.01s

=== episode:528 Env-steps-taken:67296
 	picked: 74 |actions: {0: 619, 1: 641, 2: 441, 3: 444, 4: 589, 5: 513, 6: 664, 7: 594, 8: 544}
episode: 528/2000 -> reward: 96.76041666666661, steps:5049, time-taken: 2.72min, time-elasped: 5823.22min
-> berries picked: 74 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10149 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1441, 983, 859, 996, 1338, 1564, 1252, 800, 916]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 10, 9, 13, 16, 15, 18, 16, 19]
	Time taken saving stuff: 0.01s

=== episode:529 Env-steps-taken:71712
 	picked: 83 |actions: {0: 787, 1: 404, 2: 378, 3: 459, 4: 474, 5: 534, 6: 678, 7: 525, 8: 571}
episode: 529/2000 -> reward: 120.24479166666656, steps:4810, time-taken: 3.89min, time-elasped: 5827.12min
-> berries picked: 83 of 800 | patches-visited: [0, 1, 6, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10184 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1444, 987, 856, 997, 1341, 1574, 1259, 806, 920]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 14, 11, 12, 22, 20, 15, 10, 11]
	Time taken saving stuff: 0.11s

=== episode:530 Env-steps-taken:74688
 	picked: 104 |actions: {0: 949, 1: 630, 2: 477, 3: 599, 4: 707, 5: 702, 6: 850, 7: 701, 8: 561}
episode: 530/2000 -> reward: 133.54166666666652, steps:6176, time-taken: 2.87min, time-elasped: 5829.99min
-> berries picked: 104 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10210 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1448, 986, 858, 997, 1345, 1580, 1264, 809, 923]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 12, 12, 24, 16, 24, 14, 6, 13]
	Time taken saving stuff: 0.10s

=== episode:53 Env-steps-taken:112800
 	picked: 249 |actions: {0: 897, 1: 923, 2: 651, 3: 778, 4: 868, 5: 785, 6: 897, 7: 1227, 8: 295}

==================================================
eval-episode: 530 -> reward: 325.23437499999966, steps: 7321.0, wall-time: 82.17s
-> berries picked: 249 of 800 | patches-visited: [0, 1, 3, 4, 6] | juice left:-0.00
==================================================


=== episode:531 Env-steps-taken:66720
 	picked: 64 |actions: {0: 544, 1: 404, 2: 274, 3: 341, 4: 383, 5: 433, 6: 333, 7: 445, 8: 233}
episode: 531/2000 -> reward: 93.44791666666661, steps:3390, time-taken: 1.93min, time-elasped: 5833.30min
-> berries picked: 64 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10233 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1451, 991, 864, 998, 1344, 1583, 1268, 809, 925]
	| approx positives in sample 512: 145
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 22, 13, 10, 21, 18, 14, 13, 15]
	Time taken saving stuff: 0.10s

=== episode:532 Env-steps-taken:57696
 	picked: 37 |actions: {0: 365, 1: 292, 2: 268, 3: 289, 4: 337, 5: 293, 6: 267, 7: 302, 8: 395}
episode: 532/2000 -> reward: 49.38020833333335, steps:2808, time-taken: 1.75min, time-elasped: 5835.05min
-> berries picked: 37 of 800 | patches-visited: [0, 3, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10252 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1453, 993, 868, 999, 1345, 1580, 1270, 814, 930]
	| approx positives in sample 512: 160
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [25, 19, 12, 15, 18, 24, 13, 15, 19]
	Time taken saving stuff: 0.02s

=== episode:533 Env-steps-taken:65664
 	picked: 65 |actions: {0: 662, 1: 454, 2: 492, 3: 394, 4: 446, 5: 409, 6: 493, 7: 433, 8: 585}
episode: 533/2000 -> reward: 87.33333333333329, steps:4368, time-taken: 2.29min, time-elasped: 5837.35min
-> berries picked: 65 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10262 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1455, 990, 866, 1007, 1347, 1578, 1275, 812, 932]
	| approx positives in sample 512: 152
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [26, 24, 9, 11, 18, 18, 17, 12, 17]
	Time taken saving stuff: 0.08s

=== episode:534 Env-steps-taken:77376
 	picked: 110 |actions: {0: 765, 1: 696, 2: 640, 3: 595, 4: 712, 5: 657, 6: 774, 7: 683, 8: 561}
episode: 534/2000 -> reward: 147.19791666666669, steps:6083, time-taken: 3.34min, time-elasped: 5840.69min
-> berries picked: 110 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10297 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1461, 997, 873, 1012, 1358, 1572, 1277, 811, 936]
	| approx positives in sample 512: 150
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 19, 13, 17, 24, 18, 15, 15, 12]
	Time taken saving stuff: 0.01s

=== episode:535 Env-steps-taken:73440
 	picked: 93 |actions: {0: 680, 1: 516, 2: 442, 3: 560, 4: 476, 5: 600, 6: 753, 7: 685, 8: 474}
episode: 535/2000 -> reward: 127.6718749999998, steps:5186, time-taken: 2.97min, time-elasped: 5843.66min
-> berries picked: 93 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10334 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1464, 1003, 875, 1015, 1359, 1578, 1283, 817, 940]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 12, 10, 14, 22, 20, 23, 11, 13]
	Time taken saving stuff: 0.03s

=== episode:536 Env-steps-taken:67296
 	picked: 75 |actions: {0: 996, 1: 460, 2: 395, 3: 508, 4: 538, 5: 727, 6: 699, 7: 686, 8: 723}
episode: 536/2000 -> reward: 96.70312499999996, steps:5732, time-taken: 3.49min, time-elasped: 5847.16min
-> berries picked: 75 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10286 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1459, 984, 869, 1011, 1350, 1587, 1272, 816, 938]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 16, 18, 15, 14, 16, 12, 8, 17]
	Time taken saving stuff: 0.10s

=== episode:537 Env-steps-taken:67584
 	picked: 78 |actions: {0: 868, 1: 464, 2: 423, 3: 534, 4: 516, 5: 649, 6: 570, 7: 629, 8: 572}
episode: 537/2000 -> reward: 98.03124999999991, steps:5225, time-taken: 2.99min, time-elasped: 5850.15min
-> berries picked: 78 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10240 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1456, 973, 865, 998, 1347, 1582, 1270, 809, 940]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 12, 11, 8, 21, 13, 13, 11, 25]
	Time taken saving stuff: 0.09s

=== episode:538 Env-steps-taken:67968
 	picked: 78 |actions: {0: 560, 1: 426, 2: 401, 3: 336, 4: 424, 5: 535, 6: 507, 7: 540, 8: 485}
episode: 538/2000 -> reward: 99.14583333333323, steps:4214, time-taken: 2.53min, time-elasped: 5852.69min
-> berries picked: 78 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10247 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1458, 974, 864, 997, 1348, 1586, 1269, 811, 940]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [23, 11, 9, 15, 18, 13, 16, 16, 12]
	Time taken saving stuff: 0.09s

=== episode:539 Env-steps-taken:69984
 	picked: 74 |actions: {0: 645, 1: 496, 2: 353, 3: 396, 4: 541, 5: 573, 6: 472, 7: 368, 8: 608}
episode: 539/2000 -> reward: 110.76041666666654, steps:4452, time-taken: 2.86min, time-elasped: 5855.56min
-> berries picked: 74 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10224 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1455, 977, 860, 995, 1349, 1582, 1257, 810, 939]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 9, 12, 19, 17, 15, 22, 14, 14]
	Time taken saving stuff: 0.00s

=== episode:540 Env-steps-taken:74784
 	picked: 101 |actions: {0: 1188, 1: 668, 2: 575, 3: 513, 4: 697, 5: 644, 6: 655, 7: 763, 8: 574}
episode: 540/2000 -> reward: 134.21354166666652, steps:6277, time-taken: 3.66min, time-elasped: 5859.22min
-> berries picked: 101 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10234 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1454, 977, 863, 993, 1349, 1581, 1259, 817, 941]
	| approx positives in sample 512: 150
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 13, 15, 18, 14, 23, 14, 17, 16]
	Time taken saving stuff: 0.12s

=== episode:54 Env-steps-taken:85440
 	picked: 136 |actions: {0: 942, 1: 421, 2: 340, 3: 242, 4: 465, 5: 398, 6: 442, 7: 499, 8: 333}

==================================================
eval-episode: 540 -> reward: 188.20833333333354, steps: 4082.0, wall-time: 70.84s
-> berries picked: 136 of 800 | patches-visited: [1, 3, 9] | juice left:-0.00
==================================================


=== episode:541 Env-steps-taken:64128
 	picked: 55 |actions: {0: 318, 1: 484, 2: 219, 3: 267, 4: 313, 5: 227, 6: 336, 7: 359, 8: 240}
episode: 541/2000 -> reward: 81.84895833333331, steps:2763, time-taken: 1.94min, time-elasped: 5862.34min
-> berries picked: 55 of 800 | patches-visited: [0, 2, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10205 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1452, 979, 848, 991, 1342, 1582, 1258, 813, 940]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 16, 8, 13, 15, 20, 21, 10, 22]
	Time taken saving stuff: 0.10s

=== episode:542 Env-steps-taken:59904
 	picked: 46 |actions: {0: 263, 1: 326, 2: 174, 3: 250, 4: 254, 5: 303, 6: 366, 7: 220, 8: 299}
episode: 542/2000 -> reward: 59.36458333333339, steps:2455, time-taken: 1.86min, time-elasped: 5864.21min
-> berries picked: 46 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10202 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1452, 978, 848, 989, 1340, 1581, 1263, 812, 939]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 5, 10, 10, 20, 17, 15, 15, 17]
	Time taken saving stuff: 0.03s

=== episode:543 Env-steps-taken:69888
 	picked: 84 |actions: {0: 556, 1: 596, 2: 374, 3: 510, 4: 603, 5: 467, 6: 455, 7: 615, 8: 502}
episode: 543/2000 -> reward: 108.80208333333324, steps:4678, time-taken: 2.76min, time-elasped: 5866.98min
-> berries picked: 84 of 800 | patches-visited: [0, 2, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10197 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1448, 970, 841, 984, 1346, 1588, 1263, 813, 944]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 10, 13, 16, 15, 14, 18, 14, 16]
	Time taken saving stuff: 0.11s

=== episode:544 Env-steps-taken:71424
 	picked: 89 |actions: {0: 654, 1: 659, 2: 357, 3: 423, 4: 549, 5: 497, 6: 636, 7: 474, 8: 460}
episode: 544/2000 -> reward: 117.40104166666652, steps:4709, time-taken: 2.76min, time-elasped: 5869.74min
-> berries picked: 89 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10188 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1449, 966, 835, 982, 1348, 1590, 1264, 807, 947]
	| approx positives in sample 512: 150
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 15, 14, 10, 22, 18, 14, 14, 25]
	Time taken saving stuff: 0.10s

=== episode:545 Env-steps-taken:74208
 	picked: 104 |actions: {0: 715, 1: 702, 2: 562, 3: 595, 4: 878, 5: 723, 6: 692, 7: 801, 8: 495}
episode: 545/2000 -> reward: 131.04166666666652, steps:6163, time-taken: 3.22min, time-elasped: 5872.96min
-> berries picked: 104 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10183 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1437, 963, 834, 987, 1348, 1593, 1266, 809, 946]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 14, 9, 10, 22, 19, 18, 6, 20]
	Time taken saving stuff: 0.03s

=== episode:546 Env-steps-taken:76320
 	picked: 102 |actions: {0: 837, 1: 746, 2: 662, 3: 517, 4: 774, 5: 598, 6: 690, 7: 729, 8: 545}
episode: 546/2000 -> reward: 140.2135416666666, steps:6098, time-taken: 3.31min, time-elasped: 5876.27min
-> berries picked: 102 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10089 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1399, 941, 835, 982, 1347, 1595, 1262, 777, 951]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 13, 6, 12, 12, 25, 13, 12, 16]
	Time taken saving stuff: 0.10s

=== episode:547 Env-steps-taken:72192
 	picked: 90 |actions: {0: 539, 1: 512, 2: 404, 3: 334, 4: 503, 5: 537, 6: 529, 7: 615, 8: 475}
episode: 547/2000 -> reward: 121.34374999999987, steps:4448, time-taken: 2.63min, time-elasped: 5878.91min
-> berries picked: 90 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10054 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1379, 939, 827, 983, 1347, 1590, 1266, 772, 951]
	| approx positives in sample 512: 145
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 14, 21, 18, 18, 10, 14, 16, 16]
	Time taken saving stuff: 0.11s

=== episode:548 Env-steps-taken:80832
 	picked: 129 |actions: {0: 792, 1: 859, 2: 575, 3: 567, 4: 883, 5: 889, 6: 676, 7: 732, 8: 628}
episode: 548/2000 -> reward: 164.10937500000006, steps:6601, time-taken: 3.76min, time-elasped: 5882.68min
-> berries picked: 129 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10057 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1372, 933, 828, 989, 1350, 1594, 1270, 768, 953]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 14, 15, 9, 17, 26, 15, 9, 15]
	Time taken saving stuff: 0.01s

=== episode:549 Env-steps-taken:72096
 	picked: 92 |actions: {0: 762, 1: 638, 2: 537, 3: 448, 4: 516, 5: 609, 6: 682, 7: 768, 8: 515}
episode: 549/2000 -> reward: 120.72916666666654, steps:5475, time-taken: 2.88min, time-elasped: 5885.56min
-> berries picked: 92 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10037 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1370, 930, 822, 984, 1349, 1589, 1268, 774, 951]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 7, 16, 18, 10, 14, 12, 15, 17]
	Time taken saving stuff: 0.00s

=== episode:550 Env-steps-taken:80544
 	picked: 114 |actions: {0: 797, 1: 684, 2: 669, 3: 569, 4: 713, 5: 991, 6: 743, 7: 690, 8: 574}
episode: 550/2000 -> reward: 163.96875000000009, steps:6430, time-taken: 3.38min, time-elasped: 5888.94min
-> berries picked: 114 of 800 | patches-visited: [0, 3, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10011 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1362, 922, 820, 989, 1340, 1590, 1267, 769, 952]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 11, 14, 12, 21, 20, 16, 7, 18]
	Time taken saving stuff: 0.08s

=== episode:55 Env-steps-taken:93888
 	picked: 175 |actions: {0: 496, 1: 512, 2: 1077, 3: 404, 4: 556, 5: 374, 6: 673, 7: 776, 8: 236}

==================================================
eval-episode: 550 -> reward: 230.03125000000057, steps: 5104.0, wall-time: 59.55s
-> berries picked: 175 of 800 | patches-visited: [1, 6, 8] | juice left:-0.00
==================================================


=== episode:551 Env-steps-taken:66240
 	picked: 68 |actions: {0: 568, 1: 394, 2: 357, 3: 300, 4: 422, 5: 430, 6: 453, 7: 488, 8: 394}
episode: 551/2000 -> reward: 90.21874999999996, steps:3806, time-taken: 2.32min, time-elasped: 5892.25min
-> berries picked: 68 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9997 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1360, 910, 816, 986, 1341, 1593, 1264, 770, 957]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 12, 12, 12, 20, 10, 18, 16, 22]
	Time taken saving stuff: 0.01s

=== episode:552 Env-steps-taken:66720
 	picked: 67 |actions: {0: 511, 1: 405, 2: 251, 3: 278, 4: 292, 5: 521, 6: 450, 7: 527, 8: 417}
episode: 552/2000 -> reward: 94.66145833333327, steps:3652, time-taken: 2.24min, time-elasped: 5894.49min
-> berries picked: 67 of 800 | patches-visited: [0, 5, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9997 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1360, 908, 814, 978, 1342, 1590, 1271, 775, 959]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 13, 11, 18, 21, 14, 12, 14, 21]
	Time taken saving stuff: 0.11s

=== episode:553 Env-steps-taken:62304
 	picked: 51 |actions: {0: 387, 1: 456, 2: 257, 3: 270, 4: 297, 5: 277, 6: 271, 7: 419, 8: 323}
episode: 553/2000 -> reward: 72.07812500000003, steps:2957, time-taken: 1.78min, time-elasped: 5896.28min
-> berries picked: 51 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9995 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1361, 902, 816, 980, 1344, 1593, 1269, 770, 960]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 13, 11, 11, 14, 16, 13, 6, 19]
	Time taken saving stuff: 0.11s

=== episode:554 Env-steps-taken:75552
 	picked: 104 |actions: {0: 676, 1: 718, 2: 485, 3: 513, 4: 582, 5: 805, 6: 673, 7: 692, 8: 488}
episode: 554/2000 -> reward: 138.0416666666666, steps:5632, time-taken: 3.04min, time-elasped: 5899.32min
-> berries picked: 104 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9988 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1357, 897, 812, 981, 1346, 1593, 1275, 767, 960]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 7, 4, 15, 17, 25, 15, 10, 21]
	Time taken saving stuff: 0.11s

=== episode:555 Env-steps-taken:64128
 	picked: 62 |actions: {0: 410, 1: 494, 2: 338, 3: 285, 4: 371, 5: 439, 6: 462, 7: 556, 8: 583}
episode: 555/2000 -> reward: 80.94791666666664, steps:3938, time-taken: 2.25min, time-elasped: 5901.58min
-> berries picked: 62 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9994 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1357, 897, 811, 980, 1346, 1594, 1276, 772, 961]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 10, 11, 15, 20, 17, 21, 11, 22]
	Time taken saving stuff: 0.11s

=== episode:556 Env-steps-taken:73536
 	picked: 93 |actions: {0: 655, 1: 646, 2: 579, 3: 442, 4: 733, 5: 684, 6: 516, 7: 699, 8: 496}
episode: 556/2000 -> reward: 126.28645833333319, steps:5450, time-taken: 3.44min, time-elasped: 5905.03min
-> berries picked: 93 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9993 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1347, 899, 814, 972, 1355, 1592, 1277, 771, 966]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [24, 12, 15, 9, 15, 14, 13, 10, 15]
	Time taken saving stuff: 0.10s

=== episode:557 Env-steps-taken:82368
 	picked: 129 |actions: {0: 683, 1: 903, 2: 818, 3: 585, 4: 783, 5: 838, 6: 794, 7: 822, 8: 541}
episode: 557/2000 -> reward: 172.10937500000017, steps:6767, time-taken: 4.74min, time-elasped: 5909.78min
-> berries picked: 129 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10020 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1344, 897, 816, 974, 1359, 1597, 1293, 774, 966]
	| approx positives in sample 512: 139
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 14, 9, 13, 25, 20, 15, 6, 18]
	Time taken saving stuff: 0.01s

=== episode:558 Env-steps-taken:76224
 	picked: 108 |actions: {0: 652, 1: 875, 2: 648, 3: 516, 4: 675, 5: 742, 6: 763, 7: 920, 8: 691}
episode: 558/2000 -> reward: 139.42708333333326, steps:6482, time-taken: 4.08min, time-elasped: 5913.87min
-> berries picked: 108 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10027 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1348, 881, 818, 973, 1357, 1611, 1298, 774, 967]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 14, 13, 10, 20, 14, 17, 17, 21]
	Time taken saving stuff: 0.01s

=== episode:559 Env-steps-taken:62304
 	picked: 57 |actions: {0: 343, 1: 473, 2: 283, 3: 306, 4: 332, 5: 238, 6: 359, 7: 285, 8: 432}
episode: 559/2000 -> reward: 70.2916666666667, steps:3051, time-taken: 2.45min, time-elasped: 5916.32min
-> berries picked: 57 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10031 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1346, 882, 823, 971, 1361, 1610, 1296, 773, 969]
	| approx positives in sample 512: 143
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 6, 16, 14, 20, 18, 18, 23, 18]
	Time taken saving stuff: 0.01s

=== episode:560 Env-steps-taken:63168
 	picked: 58 |actions: {0: 448, 1: 414, 2: 288, 3: 199, 4: 333, 5: 357, 6: 284, 7: 378, 8: 262}
episode: 560/2000 -> reward: 76.17708333333333, steps:2963, time-taken: 2.43min, time-elasped: 5918.76min
-> berries picked: 58 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10039 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1344, 881, 822, 967, 1363, 1619, 1298, 775, 970]
	| approx positives in sample 512: 139
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 11, 15, 19, 11, 21, 23, 5, 18]
	Time taken saving stuff: 0.08s

=== episode:56 Env-steps-taken:79008
 	picked: 115 |actions: {0: 375, 1: 503, 2: 363, 3: 334, 4: 323, 5: 400, 6: 341, 7: 422, 8: 446}

==================================================
eval-episode: 560 -> reward: 155.41145833333334, steps: 3507.0, wall-time: 73.25s
-> berries picked: 115 of 800 | patches-visited: [0, 1] | juice left:-0.00
==================================================


=== episode:561 Env-steps-taken:86784
 	picked: 137 |actions: {0: 886, 1: 814, 2: 671, 3: 762, 4: 809, 5: 1093, 6: 699, 7: 828, 8: 588}
episode: 561/2000 -> reward: 194.70833333333363, steps:7150, time-taken: 4.75min, time-elasped: 5924.73min
-> berries picked: 137 of 800 | patches-visited: [0, 4, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10017 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1334, 878, 830, 969, 1366, 1622, 1286, 760, 972]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 13, 8, 18, 20, 14, 14, 14, 15]
	Time taken saving stuff: 0.01s

=== episode:562 Env-steps-taken:77088
 	picked: 110 |actions: {0: 799, 1: 760, 2: 508, 3: 579, 4: 653, 5: 701, 6: 658, 7: 610, 8: 622}
episode: 562/2000 -> reward: 145.69791666666657, steps:5890, time-taken: 3.99min, time-elasped: 5928.73min
-> berries picked: 110 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10020 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1338, 881, 830, 977, 1370, 1623, 1268, 760, 973]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 15, 10, 9, 16, 16, 22, 10, 20]
	Time taken saving stuff: 0.01s

=== episode:563 Env-steps-taken:75264
 	picked: 101 |actions: {0: 864, 1: 773, 2: 515, 3: 517, 4: 573, 5: 624, 6: 541, 7: 773, 8: 515}
episode: 563/2000 -> reward: 137.21354166666657, steps:5695, time-taken: 3.66min, time-elasped: 5932.40min
-> berries picked: 101 of 800 | patches-visited: [0, 4, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10037 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1341, 879, 831, 978, 1375, 1625, 1271, 763, 974]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 17, 13, 10, 14, 18, 13, 8, 16]
	Time taken saving stuff: 0.01s

=== episode:564 Env-steps-taken:67008
 	picked: 71 |actions: {0: 694, 1: 539, 2: 398, 3: 408, 4: 576, 5: 554, 6: 577, 7: 464, 8: 576}
episode: 564/2000 -> reward: 95.43229166666656, steps:4786, time-taken: 3.02min, time-elasped: 5935.43min
-> berries picked: 71 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10034 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1337, 877, 834, 981, 1375, 1617, 1276, 761, 976]
	| approx positives in sample 512: 150
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 7, 12, 19, 20, 22, 20, 22, 15]
	Time taken saving stuff: 0.01s

=== episode:565 Env-steps-taken:72192
 	picked: 92 |actions: {0: 722, 1: 592, 2: 422, 3: 505, 4: 502, 5: 688, 6: 768, 7: 843, 8: 528}
episode: 565/2000 -> reward: 121.2291666666665, steps:5570, time-taken: 3.75min, time-elasped: 5939.18min
-> berries picked: 92 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10038 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1338, 876, 832, 980, 1377, 1621, 1282, 754, 978]
	| approx positives in sample 512: 149
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 9, 12, 20, 26, 22, 13, 13, 20]
	Time taken saving stuff: 0.01s

=== episode:566 Env-steps-taken:68160
 	picked: 74 |actions: {0: 355, 1: 381, 2: 393, 3: 266, 4: 396, 5: 501, 6: 455, 7: 563, 8: 322}
episode: 566/2000 -> reward: 101.26041666666657, steps:3632, time-taken: 2.59min, time-elasped: 5941.78min
-> berries picked: 74 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10055 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1334, 877, 834, 983, 1382, 1617, 1293, 757, 978]
	| approx positives in sample 512: 146
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 9, 11, 15, 17, 24, 23, 13, 17]
	Time taken saving stuff: 0.00s

=== episode:567 Env-steps-taken:74112
 	picked: 95 |actions: {0: 487, 1: 937, 2: 490, 3: 591, 4: 568, 5: 577, 6: 535, 7: 726, 8: 720}
episode: 567/2000 -> reward: 131.05729166666657, steps:5631, time-taken: 3.42min, time-elasped: 5945.20min
-> berries picked: 95 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10054 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1331, 879, 839, 982, 1381, 1618, 1290, 756, 978]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 14, 20, 14, 18, 15, 9, 10, 15]
	Time taken saving stuff: 0.00s

=== episode:568 Env-steps-taken:72384
 	picked: 100 |actions: {0: 559, 1: 845, 2: 529, 3: 471, 4: 803, 5: 563, 6: 552, 7: 705, 8: 461}
episode: 568/2000 -> reward: 120.32812499999986, steps:5488, time-taken: 3.52min, time-elasped: 5948.73min
-> berries picked: 100 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10056 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1327, 879, 840, 984, 1389, 1615, 1290, 753, 979]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 10, 9, 16, 15, 16, 20, 9, 20]
	Time taken saving stuff: 0.01s

=== episode:569 Env-steps-taken:74688
 	picked: 111 |actions: {0: 651, 1: 943, 2: 522, 3: 568, 4: 602, 5: 598, 6: 521, 7: 771, 8: 496}
episode: 569/2000 -> reward: 133.14062499999986, steps:5672, time-taken: 3.44min, time-elasped: 5952.17min
-> berries picked: 111 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10064 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1332, 883, 839, 985, 1393, 1615, 1284, 755, 978]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 18, 13, 13, 20, 25, 13, 9, 20]
	Time taken saving stuff: 0.01s

=== episode:570 Env-steps-taken:65952
 	picked: 63 |actions: {0: 485, 1: 547, 2: 301, 3: 319, 4: 518, 5: 496, 6: 428, 7: 576, 8: 658}
episode: 570/2000 -> reward: 90.39062499999994, steps:4328, time-taken: 2.47min, time-elasped: 5954.64min
-> berries picked: 63 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10065 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1331, 875, 838, 988, 1393, 1620, 1288, 755, 977]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 13, 8, 13, 21, 22, 13, 8, 21]
	Time taken saving stuff: 0.06s

=== episode:57 Env-steps-taken:78048
 	picked: 105 |actions: {0: 332, 1: 502, 2: 212, 3: 239, 4: 277, 5: 321, 6: 144, 7: 442, 8: 781}

==================================================
eval-episode: 570 -> reward: 150.54166666666669, steps: 3250.0, wall-time: 52.29s
-> berries picked: 105 of 800 | patches-visited: [1, 2, 4, 5] | juice left:-0.00
==================================================


=== episode:571 Env-steps-taken:73056
 	picked: 102 |actions: {0: 671, 1: 552, 2: 493, 3: 599, 4: 606, 5: 639, 6: 622, 7: 666, 8: 510}
episode: 571/2000 -> reward: 125.15624999999983, steps:5358, time-taken: 3.03min, time-elasped: 5958.55min
-> berries picked: 102 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10079 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1337, 879, 842, 994, 1396, 1620, 1290, 744, 977]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 12, 16, 15, 11, 25, 10, 9, 22]
	Time taken saving stuff: 0.01s

=== episode:572 Env-steps-taken:65184
 	picked: 63 |actions: {0: 426, 1: 481, 2: 413, 3: 398, 4: 360, 5: 307, 6: 402, 7: 372, 8: 267}
episode: 572/2000 -> reward: 86.39062499999996, steps:3426, time-taken: 2.24min, time-elasped: 5960.79min
-> berries picked: 63 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10097 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1333, 882, 847, 1000, 1400, 1621, 1290, 742, 982]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 12, 12, 4, 16, 27, 12, 13, 18]
	Time taken saving stuff: 0.01s

=== episode:573 Env-steps-taken:66432
 	picked: 70 |actions: {0: 611, 1: 659, 2: 522, 3: 415, 4: 467, 5: 400, 6: 392, 7: 434, 8: 720}
episode: 573/2000 -> reward: 92.54687499999996, steps:4620, time-taken: 2.71min, time-elasped: 5963.51min
-> berries picked: 70 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10097 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1330, 887, 850, 1001, 1394, 1622, 1291, 740, 982]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 10, 10, 9, 13, 26, 17, 6, 13]
	Time taken saving stuff: 0.01s

=== episode:574 Env-steps-taken:70272
 	picked: 79 |actions: {0: 639, 1: 618, 2: 521, 3: 473, 4: 475, 5: 335, 6: 387, 7: 466, 8: 337}
episode: 574/2000 -> reward: 110.53124999999993, steps:4251, time-taken: 2.57min, time-elasped: 5966.08min
-> berries picked: 79 of 800 | patches-visited: [0, 1, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10098 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1338, 890, 854, 1006, 1392, 1612, 1287, 734, 985]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 12, 9, 12, 12, 16, 21, 11, 19]
	Time taken saving stuff: 0.01s

=== episode:575 Env-steps-taken:67200
 	picked: 70 |actions: {0: 511, 1: 460, 2: 399, 3: 422, 4: 345, 5: 322, 6: 384, 7: 482, 8: 270}
episode: 575/2000 -> reward: 96.48958333333327, steps:3595, time-taken: 2.11min, time-elasped: 5968.20min
-> berries picked: 70 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10117 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1341, 897, 857, 1007, 1395, 1618, 1282, 734, 986]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 15, 9, 15, 13, 24, 10, 14, 15]
	Time taken saving stuff: 0.01s

=== episode:576 Env-steps-taken:66048
 	picked: 66 |actions: {0: 427, 1: 429, 2: 449, 3: 362, 4: 412, 5: 398, 6: 390, 7: 536, 8: 523}
episode: 576/2000 -> reward: 88.77604166666664, steps:3926, time-taken: 2.23min, time-elasped: 5970.43min
-> berries picked: 66 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10115 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1342, 897, 860, 1007, 1389, 1618, 1281, 735, 986]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 9, 14, 16, 21, 16, 21, 9, 17]
	Time taken saving stuff: 0.00s

=== episode:577 Env-steps-taken:74976
 	picked: 100 |actions: {0: 528, 1: 621, 2: 561, 3: 562, 4: 695, 5: 721, 6: 752, 7: 790, 8: 694}
episode: 577/2000 -> reward: 135.2708333333332, steps:5924, time-taken: 2.93min, time-elasped: 5973.36min
-> berries picked: 100 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10139 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1346, 899, 863, 1011, 1391, 1619, 1287, 735, 988]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 9, 11, 18, 15, 18, 18, 5, 21]
	Time taken saving stuff: 0.00s

=== episode:578 Env-steps-taken:71520
 	picked: 82 |actions: {0: 486, 1: 621, 2: 369, 3: 570, 4: 601, 5: 506, 6: 627, 7: 666, 8: 502}
episode: 578/2000 -> reward: 118.80208333333319, steps:4948, time-taken: 2.62min, time-elasped: 5975.99min
-> berries picked: 82 of 800 | patches-visited: [0, 1, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10153 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1348, 904, 864, 1015, 1386, 1620, 1292, 736, 988]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [27, 14, 11, 20, 11, 22, 8, 9, 13]
	Time taken saving stuff: 0.01s

=== episode:579 Env-steps-taken:75168
 	picked: 106 |actions: {0: 634, 1: 611, 2: 607, 3: 514, 4: 631, 5: 581, 6: 468, 7: 652, 8: 642}
episode: 579/2000 -> reward: 136.42708333333323, steps:5340, time-taken: 2.84min, time-elasped: 5978.84min
-> berries picked: 106 of 800 | patches-visited: [0, 4, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10175 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1352, 908, 864, 1019, 1385, 1617, 1300, 736, 994]
	| approx positives in sample 512: 145
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 12, 8, 16, 17, 19, 23, 15, 22]
	Time taken saving stuff: 0.01s

=== episode:580 Env-steps-taken:77952
 	picked: 114 |actions: {0: 676, 1: 853, 2: 549, 3: 541, 4: 652, 5: 654, 6: 789, 7: 725, 8: 720}
episode: 580/2000 -> reward: 149.08333333333337, steps:6159, time-taken: 3.25min, time-elasped: 5982.09min
-> berries picked: 114 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10202 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1353, 911, 874, 1021, 1384, 1622, 1309, 735, 993]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 15, 11, 17, 19, 25, 17, 9, 15]
	Time taken saving stuff: 0.76s

=== episode:58 Env-steps-taken:92064
 	picked: 161 |actions: {0: 451, 1: 843, 2: 180, 3: 441, 4: 340, 5: 696, 6: 605, 7: 680, 8: 1006}

==================================================
eval-episode: 580 -> reward: 220.89062500000043, steps: 5242.0, wall-time: 60.04s
-> berries picked: 161 of 800 | patches-visited: [1, 2, 5, 9] | juice left:-0.00
==================================================


=== episode:581 Env-steps-taken:82464
 	picked: 123 |actions: {0: 595, 1: 642, 2: 613, 3: 643, 4: 903, 5: 677, 6: 724, 7: 857, 8: 636}
episode: 581/2000 -> reward: 171.56770833333348, steps:6290, time-taken: 3.52min, time-elasped: 5986.62min
-> berries picked: 123 of 800 | patches-visited: [0, 7, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10245 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1356, 917, 879, 1024, 1386, 1627, 1321, 738, 997]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [28, 11, 9, 9, 18, 19, 13, 11, 22]
	Time taken saving stuff: 0.01s

=== episode:582 Env-steps-taken:70752
 	picked: 89 |actions: {0: 732, 1: 657, 2: 527, 3: 436, 4: 524, 5: 565, 6: 666, 7: 539, 8: 862}
episode: 582/2000 -> reward: 113.90104166666653, steps:5508, time-taken: 3.16min, time-elasped: 5989.78min
-> berries picked: 89 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10264 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1364, 919, 881, 1016, 1388, 1628, 1326, 743, 999]
	| approx positives in sample 512: 146
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 15, 14, 12, 14, 26, 13, 14, 22]
	Time taken saving stuff: 0.01s

=== episode:583 Env-steps-taken:71328
 	picked: 86 |actions: {0: 547, 1: 493, 2: 425, 3: 373, 4: 533, 5: 539, 6: 443, 7: 518, 8: 493}
episode: 583/2000 -> reward: 117.18749999999986, steps:4364, time-taken: 2.55min, time-elasped: 5992.34min
-> berries picked: 86 of 800 | patches-visited: [0, 7, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10289 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1371, 921, 882, 1012, 1393, 1635, 1329, 746, 1000]
	| approx positives in sample 512: 149
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 13, 10, 13, 20, 26, 21, 11, 16]
	Time taken saving stuff: 0.01s

=== episode:584 Env-steps-taken:70176
 	picked: 87 |actions: {0: 569, 1: 607, 2: 481, 3: 533, 4: 585, 5: 597, 6: 729, 7: 723, 8: 586}
episode: 584/2000 -> reward: 111.0729166666665, steps:5410, time-taken: 3.28min, time-elasped: 5995.63min
-> berries picked: 87 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10298 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1372, 923, 882, 1016, 1399, 1626, 1333, 744, 1003]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 6, 13, 9, 18, 21, 19, 11, 18]
	Time taken saving stuff: 0.01s

=== episode:585 Env-steps-taken:72864
 	picked: 97 |actions: {0: 658, 1: 573, 2: 510, 3: 560, 4: 756, 5: 563, 6: 572, 7: 703, 8: 710}
episode: 585/2000 -> reward: 124.44270833333316, steps:5605, time-taken: 3.59min, time-elasped: 5999.22min
-> berries picked: 97 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10323 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1378, 934, 889, 1017, 1394, 1622, 1337, 747, 1005]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 18, 14, 13, 18, 22, 15, 5, 11]
	Time taken saving stuff: 0.01s

=== episode:586 Env-steps-taken:70080
 	picked: 86 |actions: {0: 614, 1: 559, 2: 465, 3: 475, 4: 703, 5: 682, 6: 753, 7: 723, 8: 390}
episode: 586/2000 -> reward: 111.07291666666653, steps:5364, time-taken: 3.04min, time-elasped: 6002.27min
-> berries picked: 86 of 800 | patches-visited: [0, 2, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10358 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1383, 934, 890, 1021, 1401, 1625, 1344, 751, 1009]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 12, 8, 14, 12, 24, 17, 5, 16]
	Time taken saving stuff: 0.01s

=== episode:587 Env-steps-taken:65376
 	picked: 68 |actions: {0: 551, 1: 521, 2: 512, 3: 436, 4: 656, 5: 598, 6: 394, 7: 524, 8: 352}
episode: 587/2000 -> reward: 86.60416666666663, steps:4544, time-taken: 2.74min, time-elasped: 6005.01min
-> berries picked: 68 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10365 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1386, 927, 891, 1016, 1405, 1633, 1346, 751, 1010]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 15, 13, 15, 20, 17, 12, 6, 16]
	Time taken saving stuff: 0.01s

=== episode:588 Env-steps-taken:57504
 	picked: 37 |actions: {0: 158, 1: 210, 2: 199, 3: 254, 4: 326, 5: 192, 6: 183, 7: 183, 8: 197}
episode: 588/2000 -> reward: 47.93750000000003, steps:1902, time-taken: 1.57min, time-elasped: 6006.59min
-> berries picked: 37 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10379 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1385, 927, 894, 1018, 1411, 1637, 1347, 751, 1009]
	| approx positives in sample 512: 153
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 18, 12, 11, 16, 19, 24, 8, 26]
	Time taken saving stuff: 0.00s

=== episode:589 Env-steps-taken:78528
 	picked: 115 |actions: {0: 618, 1: 822, 2: 591, 3: 604, 4: 830, 5: 636, 6: 682, 7: 683, 8: 593}
episode: 589/2000 -> reward: 152.9114583333334, steps:6059, time-taken: 3.20min, time-elasped: 6009.79min
-> berries picked: 115 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10418 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1388, 926, 895, 1025, 1419, 1650, 1348, 755, 1012]
	| approx positives in sample 512: 139
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 6, 12, 14, 14, 22, 25, 13, 15]
	Time taken saving stuff: 0.00s

=== episode:590 Env-steps-taken:69504
 	picked: 71 |actions: {0: 396, 1: 737, 2: 437, 3: 546, 4: 543, 5: 492, 6: 614, 7: 445, 8: 466}
episode: 590/2000 -> reward: 108.43229166666657, steps:4676, time-taken: 2.55min, time-elasped: 6012.34min
-> berries picked: 71 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10440 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1386, 932, 900, 1027, 1422, 1658, 1348, 754, 1013]
	| approx positives in sample 512: 139
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 12, 11, 12, 20, 23, 19, 8, 23]
	Time taken saving stuff: 0.08s

=== episode:59 Env-steps-taken:86592
 	picked: 144 |actions: {0: 455, 1: 454, 2: 508, 3: 490, 4: 459, 5: 337, 6: 834, 7: 402, 8: 479}

==================================================
eval-episode: 590 -> reward: 193.75000000000034, steps: 4418.0, wall-time: 58.42s
-> berries picked: 144 of 800 | patches-visited: [1, 6, 8] | juice left:-0.00
==================================================


=== episode:591 Env-steps-taken:74112
 	picked: 97 |actions: {0: 704, 1: 720, 2: 602, 3: 642, 4: 684, 5: 602, 6: 620, 7: 801, 8: 730}
episode: 591/2000 -> reward: 128.99999999999986, steps:6105, time-taken: 3.35min, time-elasped: 6016.66min
-> berries picked: 97 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10438 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1392, 927, 892, 1019, 1430, 1658, 1355, 753, 1012]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 10, 13, 17, 15, 16, 23, 11, 18]
	Time taken saving stuff: 0.01s

=== episode:592 Env-steps-taken:80544
 	picked: 116 |actions: {0: 755, 1: 866, 2: 521, 3: 659, 4: 776, 5: 678, 6: 598, 7: 684, 8: 529}
episode: 592/2000 -> reward: 162.41145833333337, steps:6066, time-taken: 3.67min, time-elasped: 6020.34min
-> berries picked: 116 of 800 | patches-visited: [0, 2, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10438 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1396, 915, 890, 1019, 1435, 1659, 1356, 753, 1015]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 14, 10, 13, 13, 27, 14, 13, 18]
	Time taken saving stuff: 0.01s

=== episode:593 Env-steps-taken:65856
 	picked: 66 |actions: {0: 396, 1: 438, 2: 330, 3: 324, 4: 327, 5: 304, 6: 447, 7: 499, 8: 621}
episode: 593/2000 -> reward: 90.21874999999996, steps:3686, time-taken: 2.46min, time-elasped: 6022.80min
-> berries picked: 66 of 800 | patches-visited: [0, 2, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10442 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1396, 912, 891, 1020, 1433, 1662, 1355, 754, 1019]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 9, 17, 12, 10, 19, 13, 14, 24]
	Time taken saving stuff: 0.01s

=== episode:594 Env-steps-taken:74016
 	picked: 103 |actions: {0: 676, 1: 697, 2: 465, 3: 567, 4: 843, 5: 594, 6: 567, 7: 735, 8: 633}
episode: 594/2000 -> reward: 128.71354166666646, steps:5777, time-taken: 3.83min, time-elasped: 6026.64min
-> berries picked: 103 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10442 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1391, 910, 894, 1016, 1432, 1664, 1360, 756, 1019]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 13, 15, 11, 20, 23, 11, 7, 10]
	Time taken saving stuff: 0.01s

=== episode:595 Env-steps-taken:75456
 	picked: 101 |actions: {0: 590, 1: 982, 2: 603, 3: 502, 4: 655, 5: 505, 6: 535, 7: 753, 8: 409}
episode: 595/2000 -> reward: 137.71354166666654, steps:5534, time-taken: 3.66min, time-elasped: 6030.31min
-> berries picked: 101 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10451 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1388, 916, 893, 1020, 1430, 1665, 1359, 760, 1020]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [24, 10, 12, 19, 15, 20, 14, 13, 17]
	Time taken saving stuff: 0.01s

=== episode:596 Env-steps-taken:67776
 	picked: 71 |actions: {0: 478, 1: 683, 2: 335, 3: 472, 4: 596, 5: 713, 6: 619, 7: 641, 8: 480}
episode: 596/2000 -> reward: 97.54687499999989, steps:5017, time-taken: 3.75min, time-elasped: 6034.05min
-> berries picked: 71 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10457 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1391, 920, 880, 1013, 1432, 1668, 1367, 765, 1021]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 14, 10, 14, 13, 19, 15, 12, 19]
	Time taken saving stuff: 0.01s

=== episode:597 Env-steps-taken:76416
 	picked: 109 |actions: {0: 573, 1: 820, 2: 525, 3: 593, 4: 644, 5: 811, 6: 712, 7: 826, 8: 553}
episode: 597/2000 -> reward: 142.25520833333323, steps:6057, time-taken: 4.31min, time-elasped: 6038.37min
-> berries picked: 109 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10482 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1387, 918, 881, 1020, 1434, 1679, 1369, 770, 1024]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 13, 9, 11, 13, 25, 18, 10, 19]
	Time taken saving stuff: 0.01s

=== episode:598 Env-steps-taken:70368
 	picked: 77 |actions: {0: 464, 1: 586, 2: 338, 3: 500, 4: 506, 5: 608, 6: 404, 7: 672, 8: 329}
episode: 598/2000 -> reward: 112.70312499999991, steps:4407, time-taken: 2.80min, time-elasped: 6041.17min
-> berries picked: 77 of 800 | patches-visited: [0, 4, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10496 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1384, 919, 882, 1020, 1441, 1679, 1371, 775, 1025]
	| approx positives in sample 512: 143
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [30, 12, 13, 8, 13, 22, 17, 12, 16]
	Time taken saving stuff: 0.01s

=== episode:599 Env-steps-taken:75456
 	picked: 101 |actions: {0: 709, 1: 718, 2: 501, 3: 613, 4: 807, 5: 577, 6: 564, 7: 782, 8: 645}
episode: 599/2000 -> reward: 137.7135416666666, steps:5916, time-taken: 3.68min, time-elasped: 6044.86min
-> berries picked: 101 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10515 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1378, 915, 877, 1027, 1450, 1682, 1377, 778, 1031]
	| approx positives in sample 512: 155
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 19, 11, 17, 20, 22, 18, 11, 18]
	Time taken saving stuff: 0.00s

=== episode:600 Env-steps-taken:80448
 	picked: 118 |actions: {0: 677, 1: 800, 2: 607, 3: 562, 4: 632, 5: 925, 6: 695, 7: 903, 8: 556}
episode: 600/2000 -> reward: 162.7395833333334, steps:6357, time-taken: 3.71min, time-elasped: 6048.57min
-> berries picked: 118 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10541 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1380, 914, 882, 1030, 1451, 1686, 1386, 780, 1032]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 10, 11, 11, 14, 17, 14, 5, 16]
	Time taken saving stuff: 0.07s

=== episode:60 Env-steps-taken:97536
 	picked: 189 |actions: {0: 762, 1: 978, 2: 397, 3: 619, 4: 749, 5: 1148, 6: 273, 7: 777, 8: 875}

==================================================
eval-episode: 600 -> reward: 247.2864583333341, steps: 6578.0, wall-time: 80.69s
-> berries picked: 189 of 800 | patches-visited: [0, 1, 3] | juice left:-0.00
==================================================


=== episode:601 Env-steps-taken:75072
 	picked: 101 |actions: {0: 653, 1: 789, 2: 545, 3: 480, 4: 713, 5: 805, 6: 855, 7: 738, 8: 646}
episode: 601/2000 -> reward: 135.71354166666652, steps:6224, time-taken: 3.67min, time-elasped: 6053.59min
-> berries picked: 101 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10573 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1383, 920, 882, 1031, 1460, 1695, 1389, 777, 1036]
	| approx positives in sample 512: 146
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [27, 13, 14, 10, 14, 18, 20, 14, 16]
	Time taken saving stuff: 0.01s

=== episode:602 Env-steps-taken:64512
 	picked: 73 |actions: {0: 414, 1: 631, 2: 450, 3: 317, 4: 535, 5: 516, 6: 468, 7: 557, 8: 344}
episode: 602/2000 -> reward: 81.8177083333333, steps:4232, time-taken: 2.64min, time-elasped: 6056.24min
-> berries picked: 73 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10597 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1384, 919, 885, 1035, 1464, 1700, 1394, 780, 1036]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 12, 13, 15, 16, 18, 17, 10, 23]
	Time taken saving stuff: 0.01s

=== episode:603 Env-steps-taken:75072
 	picked: 100 |actions: {0: 858, 1: 794, 2: 490, 3: 671, 4: 763, 5: 677, 6: 565, 7: 790, 8: 717}
episode: 603/2000 -> reward: 135.7708333333332, steps:6325, time-taken: 3.67min, time-elasped: 6059.91min
-> berries picked: 100 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10643 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1393, 920, 890, 1041, 1471, 1705, 1401, 782, 1040]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 13, 7, 11, 19, 29, 16, 15, 16]
	Time taken saving stuff: 0.01s

=== episode:604 Env-steps-taken:78432
 	picked: 109 |actions: {0: 838, 1: 903, 2: 640, 3: 603, 4: 695, 5: 618, 6: 711, 7: 707, 8: 564}
episode: 604/2000 -> reward: 150.42708333333334, steps:6279, time-taken: 3.79min, time-elasped: 6063.71min
-> berries picked: 109 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10680 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1397, 929, 893, 1047, 1474, 1714, 1401, 784, 1041]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 12, 9, 15, 17, 21, 17, 10, 16]
	Time taken saving stuff: 0.01s

=== episode:605 Env-steps-taken:71232
 	picked: 91 |actions: {0: 830, 1: 725, 2: 480, 3: 451, 4: 546, 5: 674, 6: 616, 7: 619, 8: 639}
episode: 605/2000 -> reward: 116.28645833333319, steps:5580, time-taken: 3.46min, time-elasped: 6067.17min
-> berries picked: 91 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10705 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1400, 932, 898, 1045, 1471, 1717, 1404, 792, 1046]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 12, 16, 15, 12, 18, 24, 13, 14]
	Time taken saving stuff: 0.01s

=== episode:606 Env-steps-taken:76896
 	picked: 117 |actions: {0: 698, 1: 862, 2: 605, 3: 597, 4: 782, 5: 714, 6: 760, 7: 862, 8: 524}
episode: 606/2000 -> reward: 143.41145833333334, steps:6404, time-taken: 3.74min, time-elasped: 6070.92min
-> berries picked: 117 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10730 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1396, 933, 900, 1050, 1474, 1730, 1406, 791, 1050]
	| approx positives in sample 512: 162
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [35, 11, 16, 12, 18, 25, 13, 12, 20]
	Time taken saving stuff: 0.00s

=== episode:607 Env-steps-taken:76896
 	picked: 107 |actions: {0: 628, 1: 728, 2: 552, 3: 496, 4: 589, 5: 609, 6: 665, 7: 685, 8: 571}
episode: 607/2000 -> reward: 145.3697916666666, steps:5523, time-taken: 3.47min, time-elasped: 6074.39min
-> berries picked: 107 of 800 | patches-visited: [0, 6, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10752 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1392, 938, 903, 1054, 1477, 1733, 1408, 793, 1054]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 7, 7, 20, 27, 20, 16, 14, 16]
	Time taken saving stuff: 0.01s

=== episode:608 Env-steps-taken:70464
 	picked: 83 |actions: {0: 682, 1: 577, 2: 446, 3: 615, 4: 533, 5: 505, 6: 644, 7: 568, 8: 314}
episode: 608/2000 -> reward: 112.7447916666665, steps:4884, time-taken: 3.19min, time-elasped: 6077.58min
-> berries picked: 83 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10781 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1390, 944, 902, 1063, 1476, 1736, 1414, 798, 1058]
	| approx positives in sample 512: 160
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 20, 11, 11, 19, 20, 25, 14, 20]
	Time taken saving stuff: 0.01s

=== episode:609 Env-steps-taken:69792
 	picked: 92 |actions: {0: 745, 1: 552, 2: 490, 3: 557, 4: 694, 5: 585, 6: 563, 7: 561, 8: 370}
episode: 609/2000 -> reward: 108.72916666666656, steps:5117, time-taken: 3.28min, time-elasped: 6080.87min
-> berries picked: 92 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10787 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1397, 945, 896, 1063, 1479, 1737, 1414, 797, 1059]
	| approx positives in sample 512: 159
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 11, 8, 16, 28, 19, 17, 18, 22]
	Time taken saving stuff: 0.00s

=== episode:610 Env-steps-taken:67392
 	picked: 71 |actions: {0: 567, 1: 546, 2: 422, 3: 413, 4: 372, 5: 611, 6: 809, 7: 725, 8: 744}
episode: 610/2000 -> reward: 97.4322916666666, steps:5209, time-taken: 3.22min, time-elasped: 6084.09min
-> berries picked: 71 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10805 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1395, 943, 900, 1062, 1481, 1740, 1420, 803, 1061]
	| approx positives in sample 512: 139
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 15, 19, 12, 16, 11, 16, 17, 22]
	Time taken saving stuff: 0.07s

=== episode:61 Env-steps-taken:87552
 	picked: 148 |actions: {0: 1126, 1: 432, 2: 369, 3: 413, 4: 396, 5: 610, 6: 644, 7: 725, 8: 830}

==================================================
eval-episode: 610 -> reward: 197.6354166666669, steps: 5545.0, wall-time: 71.85s
-> berries picked: 148 of 800 | patches-visited: [1, 2, 7] | juice left:-0.00
==================================================


=== episode:611 Env-steps-taken:75936
 	picked: 102 |actions: {0: 687, 1: 566, 2: 625, 3: 657, 4: 745, 5: 578, 6: 743, 7: 628, 8: 467}
episode: 611/2000 -> reward: 140.65624999999994, steps:5696, time-taken: 3.75min, time-elasped: 6089.04min
-> berries picked: 102 of 800 | patches-visited: [0, 2, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10817 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1393, 942, 904, 1061, 1486, 1740, 1422, 804, 1065]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 6, 8, 11, 21, 20, 18, 11, 22]
	Time taken saving stuff: 0.00s

=== episode:612 Env-steps-taken:70272
 	picked: 70 |actions: {0: 659, 1: 430, 2: 351, 3: 445, 4: 620, 5: 389, 6: 489, 7: 448, 8: 322}
episode: 612/2000 -> reward: 112.48958333333323, steps:4153, time-taken: 2.89min, time-elasped: 6091.93min
-> berries picked: 70 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10827 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1393, 942, 906, 1059, 1484, 1741, 1425, 810, 1067]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 6, 15, 6, 24, 20, 12, 11, 21]
	Time taken saving stuff: 0.01s

=== episode:613 Env-steps-taken:63360
 	picked: 60 |actions: {0: 503, 1: 545, 2: 348, 3: 303, 4: 445, 5: 354, 6: 392, 7: 354, 8: 572}
episode: 613/2000 -> reward: 77.0625, steps:3816, time-taken: 2.35min, time-elasped: 6094.28min
-> berries picked: 60 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10835 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1391, 943, 908, 1059, 1490, 1746, 1423, 811, 1064]
	| approx positives in sample 512: 152
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 13, 8, 16, 30, 25, 15, 9, 18]
	Time taken saving stuff: 0.01s

=== episode:614 Env-steps-taken:77760
 	picked: 115 |actions: {0: 932, 1: 582, 2: 642, 3: 758, 4: 790, 5: 625, 6: 661, 7: 718, 8: 593}
episode: 614/2000 -> reward: 148.91145833333337, steps:6301, time-taken: 3.91min, time-elasped: 6098.19min
-> berries picked: 115 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10853 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1391, 939, 914, 1055, 1487, 1751, 1431, 813, 1072]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 16, 10, 17, 17, 17, 24, 13, 12]
	Time taken saving stuff: 0.01s

=== episode:615 Env-steps-taken:65664
 	picked: 66 |actions: {0: 1093, 1: 459, 2: 477, 3: 441, 4: 469, 5: 464, 6: 545, 7: 584, 8: 802}
episode: 615/2000 -> reward: 88.21874999999991, steps:5334, time-taken: 2.81min, time-elasped: 6101.01min
-> berries picked: 66 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10841 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1392, 936, 910, 1046, 1485, 1754, 1429, 818, 1071]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 13, 17, 7, 14, 22, 18, 8, 20]
	Time taken saving stuff: 0.01s

=== episode:616 Env-steps-taken:60960
 	picked: 44 |actions: {0: 258, 1: 237, 2: 124, 3: 166, 4: 189, 5: 182, 6: 218, 7: 348, 8: 213}
episode: 616/2000 -> reward: 65.47916666666671, steps:1935, time-taken: 1.58min, time-elasped: 6102.59min
-> berries picked: 44 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10850 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1390, 936, 908, 1044, 1486, 1758, 1434, 820, 1074]
	| approx positives in sample 512: 153
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 14, 17, 18, 14, 17, 21, 14, 17]
	Time taken saving stuff: 0.01s

=== episode:617 Env-steps-taken:65088
 	picked: 66 |actions: {0: 689, 1: 553, 2: 466, 3: 508, 4: 463, 5: 522, 6: 480, 7: 439, 8: 562}
episode: 617/2000 -> reward: 85.71874999999997, steps:4682, time-taken: 2.65min, time-elasped: 6105.24min
-> berries picked: 66 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10862 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1389, 936, 912, 1049, 1483, 1758, 1439, 819, 1077]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 11, 9, 17, 26, 21, 17, 8, 13]
	Time taken saving stuff: 0.00s

=== episode:618 Env-steps-taken:66144
 	picked: 79 |actions: {0: 791, 1: 511, 2: 378, 3: 509, 4: 525, 5: 621, 6: 665, 7: 716, 8: 615}
episode: 618/2000 -> reward: 89.97395833333323, steps:5331, time-taken: 3.21min, time-elasped: 6108.45min
-> berries picked: 79 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10876 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1386, 938, 913, 1053, 1485, 1759, 1442, 821, 1079]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 11, 11, 14, 12, 23, 25, 13, 8]
	Time taken saving stuff: 0.01s

=== episode:619 Env-steps-taken:76896
 	picked: 111 |actions: {0: 851, 1: 551, 2: 565, 3: 639, 4: 826, 5: 624, 6: 832, 7: 662, 8: 564}
episode: 619/2000 -> reward: 144.64062499999997, steps:6114, time-taken: 3.64min, time-elasped: 6112.10min
-> berries picked: 111 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10902 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1390, 933, 912, 1057, 1492, 1766, 1449, 822, 1081]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 9, 8, 9, 19, 18, 17, 9, 22]
	Time taken saving stuff: 0.02s

=== episode:620 Env-steps-taken:70752
 	picked: 80 |actions: {0: 638, 1: 398, 2: 431, 3: 486, 4: 596, 5: 553, 6: 482, 7: 483, 8: 486}
episode: 620/2000 -> reward: 114.91666666666654, steps:4553, time-taken: 3.04min, time-elasped: 6115.15min
-> berries picked: 80 of 800 | patches-visited: [0, 1, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10914 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1396, 929, 915, 1065, 1493, 1760, 1451, 823, 1082]
	| approx positives in sample 512: 158
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 20, 15, 11, 24, 22, 15, 18, 21]
	Time taken saving stuff: 0.17s

=== episode:62 Env-steps-taken:76896
 	picked: 113 |actions: {0: 724, 1: 395, 2: 357, 3: 408, 4: 328, 5: 360, 6: 177, 7: 695, 8: 952}

==================================================
eval-episode: 620 -> reward: 144.58333333333337, steps: 4396.0, wall-time: 49.59s
-> berries picked: 113 of 800 | patches-visited: [1, 4] | juice left:-0.00
==================================================


=== episode:621 Env-steps-taken:64512
 	picked: 66 |actions: {0: 777, 1: 357, 2: 309, 3: 453, 4: 537, 5: 482, 6: 382, 7: 453, 8: 744}
episode: 621/2000 -> reward: 82.71874999999994, steps:4494, time-taken: 2.66min, time-elasped: 6118.64min
-> berries picked: 66 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10906 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1389, 931, 916, 1064, 1492, 1760, 1450, 820, 1084]
	| approx positives in sample 512: 143
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 13, 13, 17, 24, 17, 19, 10, 17]
	Time taken saving stuff: 0.01s

=== episode:622 Env-steps-taken:70560
 	picked: 92 |actions: {0: 832, 1: 546, 2: 444, 3: 609, 4: 549, 5: 612, 6: 523, 7: 647, 8: 610}
episode: 622/2000 -> reward: 112.72916666666652, steps:5372, time-taken: 2.89min, time-elasped: 6121.53min
-> berries picked: 92 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10886 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1382, 923, 918, 1067, 1491, 1753, 1447, 818, 1087]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 11, 12, 11, 16, 22, 10, 15, 25]
	Time taken saving stuff: 0.00s

=== episode:623 Env-steps-taken:67584
 	picked: 67 |actions: {0: 755, 1: 367, 2: 272, 3: 376, 4: 516, 5: 475, 6: 363, 7: 547, 8: 434}
episode: 623/2000 -> reward: 98.66145833333326, steps:4105, time-taken: 2.54min, time-elasped: 6124.08min
-> berries picked: 67 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10856 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1377, 912, 914, 1064, 1493, 1746, 1447, 818, 1085]
	| approx positives in sample 512: 157
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 20, 9, 16, 18, 18, 18, 15, 26]
	Time taken saving stuff: 0.00s

=== episode:624 Env-steps-taken:65184
 	picked: 61 |actions: {0: 905, 1: 375, 2: 363, 3: 336, 4: 487, 5: 539, 6: 363, 7: 410, 8: 639}
episode: 624/2000 -> reward: 86.50520833333331, steps:4417, time-taken: 2.68min, time-elasped: 6126.76min
-> berries picked: 61 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10835 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1379, 903, 909, 1056, 1494, 1753, 1439, 815, 1087]
	| approx positives in sample 512: 143
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [23, 5, 13, 7, 18, 19, 23, 13, 22]
	Time taken saving stuff: 0.01s

=== episode:625 Env-steps-taken:72192
 	picked: 96 |actions: {0: 1111, 1: 568, 2: 561, 3: 681, 4: 718, 5: 706, 6: 571, 7: 563, 8: 665}
episode: 625/2000 -> reward: 120.99999999999984, steps:6144, time-taken: 3.32min, time-elasped: 6130.08min
-> berries picked: 96 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10830 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1377, 904, 904, 1060, 1496, 1757, 1434, 810, 1088]
	| approx positives in sample 512: 153
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 17, 12, 17, 18, 26, 22, 6, 18]
	Time taken saving stuff: 0.01s

=== episode:626 Env-steps-taken:59904
 	picked: 47 |actions: {0: 463, 1: 227, 2: 220, 3: 344, 4: 426, 5: 446, 6: 308, 7: 349, 8: 458}
episode: 626/2000 -> reward: 59.30729166666672, steps:3241, time-taken: 2.08min, time-elasped: 6132.16min
-> berries picked: 47 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10835 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1375, 904, 902, 1057, 1498, 1759, 1437, 814, 1089]
	| approx positives in sample 512: 158
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 15, 18, 21, 21, 24, 25, 10, 10]
	Time taken saving stuff: 0.00s

=== episode:627 Env-steps-taken:71424
 	picked: 83 |actions: {0: 1372, 1: 473, 2: 466, 3: 445, 4: 587, 5: 577, 6: 623, 7: 548, 8: 406}
episode: 627/2000 -> reward: 118.24479166666653, steps:5497, time-taken: 3.25min, time-elasped: 6135.42min
-> berries picked: 83 of 800 | patches-visited: [0, 7, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10848 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1376, 902, 906, 1055, 1497, 1762, 1443, 814, 1093]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 6, 9, 15, 21, 13, 16, 12, 15]
	Time taken saving stuff: 0.01s

=== episode:628 Env-steps-taken:67584
 	picked: 80 |actions: {0: 669, 1: 575, 2: 426, 3: 504, 4: 475, 5: 713, 6: 731, 7: 603, 8: 464}
episode: 628/2000 -> reward: 97.41666666666656, steps:5160, time-taken: 2.80min, time-elasped: 6138.22min
-> berries picked: 80 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10869 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1384, 905, 909, 1057, 1495, 1768, 1449, 812, 1090]
	| approx positives in sample 512: 149
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 11, 17, 11, 16, 26, 13, 15, 23]
	Time taken saving stuff: 0.01s

=== episode:629 Env-steps-taken:69600
 	picked: 86 |actions: {0: 775, 1: 598, 2: 484, 3: 415, 4: 522, 5: 610, 6: 496, 7: 657, 8: 603}
episode: 629/2000 -> reward: 108.07291666666656, steps:5160, time-taken: 3.02min, time-elasped: 6141.24min
-> berries picked: 86 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10874 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1382, 898, 912, 1058, 1497, 1771, 1450, 814, 1092]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 11, 10, 13, 20, 18, 13, 9, 19]
	Time taken saving stuff: 0.00s

=== episode:630 Env-steps-taken:63936
 	picked: 70 |actions: {0: 885, 1: 455, 2: 364, 3: 468, 4: 472, 5: 536, 6: 480, 7: 623, 8: 575}
episode: 630/2000 -> reward: 78.98958333333334, steps:4858, time-taken: 2.69min, time-elasped: 6143.94min
-> berries picked: 70 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10889 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1386, 899, 912, 1057, 1498, 1773, 1454, 818, 1092]
	| approx positives in sample 512: 143
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 13, 14, 10, 16, 18, 17, 16, 22]
	Time taken saving stuff: 0.06s

=== episode:63 Env-steps-taken:71520
 	picked: 90 |actions: {0: 877, 1: 479, 2: 258, 3: 244, 4: 456, 5: 345, 6: 247, 7: 368, 8: 672}

==================================================
eval-episode: 630 -> reward: 118.34374999999989, steps: 3946.0, wall-time: 60.28s
-> berries picked: 90 of 800 | patches-visited: [1, 3, 9] | juice left:-0.00
==================================================


=== episode:631 Env-steps-taken:70464
 	picked: 86 |actions: {0: 766, 1: 519, 2: 537, 3: 512, 4: 706, 5: 523, 6: 612, 7: 441, 8: 374}
episode: 631/2000 -> reward: 112.57291666666654, steps:4990, time-taken: 2.81min, time-elasped: 6147.75min
-> berries picked: 86 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10921 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1394, 899, 917, 1066, 1508, 1776, 1452, 815, 1094]
	| approx positives in sample 512: 149
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 16, 13, 15, 18, 18, 15, 11, 21]
	Time taken saving stuff: 0.01s

=== episode:632 Env-steps-taken:70176
 	picked: 89 |actions: {0: 1096, 1: 527, 2: 482, 3: 534, 4: 664, 5: 614, 6: 666, 7: 574, 8: 566}
episode: 632/2000 -> reward: 110.9010416666665, steps:5723, time-taken: 2.87min, time-elasped: 6150.62min
-> berries picked: 89 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10956 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1394, 900, 920, 1072, 1514, 1784, 1456, 818, 1098]
	| approx positives in sample 512: 155
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 13, 16, 10, 25, 20, 22, 11, 27]
	Time taken saving stuff: 0.01s

=== episode:633 Env-steps-taken:68640
 	picked: 77 |actions: {0: 678, 1: 322, 2: 350, 3: 328, 4: 609, 5: 580, 6: 468, 7: 386, 8: 436}
episode: 633/2000 -> reward: 101.64583333333324, steps:4157, time-taken: 1.92min, time-elasped: 6152.54min
-> berries picked: 77 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10981 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1397, 902, 920, 1075, 1518, 1789, 1461, 821, 1098]
	| approx positives in sample 512: 152
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 11, 7, 20, 14, 21, 34, 10, 20]
	Time taken saving stuff: 0.00s

=== episode:634 Env-steps-taken:72000
 	picked: 98 |actions: {0: 886, 1: 586, 2: 391, 3: 650, 4: 695, 5: 524, 6: 730, 7: 745, 8: 589}
episode: 634/2000 -> reward: 119.88541666666647, steps:5796, time-taken: 2.39min, time-elasped: 6154.93min
-> berries picked: 98 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 11014 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1401, 909, 918, 1077, 1522, 1797, 1464, 828, 1098]
	| approx positives in sample 512: 147
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 12, 8, 19, 18, 20, 16, 18, 19]
	Time taken saving stuff: 0.01s

=== episode:635 Env-steps-taken:67584
 	picked: 78 |actions: {0: 746, 1: 413, 2: 564, 3: 563, 4: 636, 5: 673, 6: 687, 7: 728, 8: 653}
episode: 635/2000 -> reward: 97.53124999999989, steps:5663, time-taken: 2.83min, time-elasped: 6157.77min
-> berries picked: 78 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 11049 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1404, 909, 920, 1084, 1530, 1804, 1469, 829, 1100]
	| approx positives in sample 512: 169
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [25, 13, 12, 17, 15, 26, 22, 13, 26]
	Time taken saving stuff: 0.00s

=== episode:636 Env-steps-taken:69216
 	picked: 80 |actions: {0: 534, 1: 486, 2: 373, 3: 418, 4: 531, 5: 410, 6: 389, 7: 559, 8: 238}
episode: 636/2000 -> reward: 106.41666666666657, steps:3938, time-taken: 2.29min, time-elasped: 6160.06min
-> berries picked: 80 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 11064 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1410, 910, 918, 1084, 1533, 1808, 1471, 831, 1099]
	| approx positives in sample 512: 165
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 15, 12, 15, 25, 34, 24, 6, 15]
	Time taken saving stuff: 0.02s

=== episode:637 Env-steps-taken:62592
 	picked: 53 |actions: {0: 593, 1: 453, 2: 279, 3: 297, 4: 385, 5: 300, 6: 508, 7: 424, 8: 684}
episode: 637/2000 -> reward: 73.078125, steps:3923, time-taken: 2.18min, time-elasped: 6162.24min
-> berries picked: 53 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 11065 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1414, 910, 917, 1082, 1531, 1803, 1474, 834, 1100]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 12, 11, 14, 22, 18, 24, 8, 15]
	Time taken saving stuff: 0.01s

=== episode:638 Env-steps-taken:65664
 	picked: 70 |actions: {0: 687, 1: 637, 2: 407, 3: 559, 4: 638, 5: 529, 6: 581, 7: 918, 8: 655}
episode: 638/2000 -> reward: 87.98958333333326, steps:5611, time-taken: 2.83min, time-elasped: 6165.07min
-> berries picked: 70 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 11052 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1404, 911, 911, 1074, 1535, 1805, 1474, 836, 1102]
	| approx positives in sample 512: 160
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 17, 10, 19, 16, 22, 25, 19, 23]
	Time taken saving stuff: 0.00s

=== episode:639 Env-steps-taken:70272
 	picked: 87 |actions: {0: 713, 1: 648, 2: 405, 3: 511, 4: 727, 5: 590, 6: 636, 7: 892, 8: 621}
episode: 639/2000 -> reward: 109.6302083333332, steps:5743, time-taken: 3.06min, time-elasped: 6168.14min
-> berries picked: 87 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 11052 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1401, 910, 908, 1072, 1536, 1806, 1480, 836, 1103]
	| approx positives in sample 512: 161
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 10, 13, 22, 17, 27, 24, 9, 22]
	Time taken saving stuff: 0.09s

=== episode:640 Env-steps-taken:65376
 	picked: 67 |actions: {0: 606, 1: 678, 2: 414, 3: 529, 4: 552, 5: 462, 6: 536, 7: 1236, 8: 746}
episode: 640/2000 -> reward: 86.66145833333327, steps:5759, time-taken: 3.76min, time-elasped: 6171.90min
-> berries picked: 67 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 11052 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1404, 905, 907, 1071, 1536, 1811, 1479, 838, 1101]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 14, 13, 16, 18, 17, 24, 11, 19]
	Time taken saving stuff: 0.06s

=== episode:64 Env-steps-taken:63168
 	picked: 56 |actions: {0: 532, 1: 347, 2: 142, 3: 146, 4: 760, 5: 113, 6: 60, 7: 1017, 8: 1141}

==================================================
eval-episode: 640 -> reward: 76.29166666666667, steps: 4258.0, wall-time: 62.75s
-> berries picked: 56 of 800 | patches-visited: [1, 7] | juice left:-0.00
==================================================


=== episode:641 Env-steps-taken:72864
 	picked: 100 |actions: {0: 694, 1: 565, 2: 480, 3: 518, 4: 744, 5: 610, 6: 795, 7: 735, 8: 568}
episode: 641/2000 -> reward: 123.88541666666649, steps:5709, time-taken: 4.12min, time-elasped: 6177.08min
-> berries picked: 100 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 11097 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1407, 906, 910, 1075, 1543, 1818, 1488, 847, 1103]
	| approx positives in sample 512: 156
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [24, 18, 13, 14, 15, 23, 12, 14, 23]
	Time taken saving stuff: 0.01s

=== episode:642 Env-steps-taken:65280
 	picked: 78 |actions: {0: 835, 1: 635, 2: 528, 3: 500, 4: 750, 5: 541, 6: 663, 7: 640, 8: 547}
episode: 642/2000 -> reward: 85.53124999999996, steps:5639, time-taken: 3.56min, time-elasped: 6180.64min
-> berries picked: 78 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 11110 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1409, 907, 914, 1080, 1544, 1816, 1487, 849, 1104]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [24, 15, 10, 11, 11, 16, 15, 13, 17]
	Time taken saving stuff: 0.01s

=== episode:643 Env-steps-taken:75072
 	picked: 104 |actions: {0: 780, 1: 809, 2: 529, 3: 554, 4: 715, 5: 765, 6: 756, 7: 729, 8: 699}
episode: 643/2000 -> reward: 135.54166666666652, steps:6336, time-taken: 4.25min, time-elasped: 6184.89min
-> berries picked: 104 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 11139 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1410, 911, 919, 1083, 1555, 1814, 1492, 848, 1107]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 10, 13, 17, 19, 21, 19, 6, 20]
	Time taken saving stuff: 0.01s

=== episode:644 Env-steps-taken:72864
 	picked: 95 |actions: {0: 729, 1: 646, 2: 507, 3: 514, 4: 671, 5: 561, 6: 630, 7: 592, 8: 446}
episode: 644/2000 -> reward: 124.55729166666647, steps:5296, time-taken: 3.53min, time-elasped: 6188.42min
-> berries picked: 95 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 11168 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1415, 911, 925, 1087, 1563, 1817, 1490, 851, 1109]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 9, 14, 11, 19, 19, 10, 6, 23]
	Time taken saving stuff: 0.01s

=== episode:645 Env-steps-taken:82080
 	picked: 125 |actions: {0: 803, 1: 742, 2: 696, 3: 610, 4: 802, 5: 584, 6: 849, 7: 614, 8: 514}
episode: 645/2000 -> reward: 169.39583333333348, steps:6214, time-taken: 4.62min, time-elasped: 6193.05min
-> berries picked: 125 of 800 | patches-visited: [0, 3, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 11202 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1421, 916, 931, 1093, 1565, 1820, 1491, 853, 1112]
	| approx positives in sample 512: 162
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [30, 11, 9, 15, 16, 26, 16, 18, 21]
	Time taken saving stuff: 0.00s

=== episode:646 Env-steps-taken:73536
 	picked: 97 |actions: {0: 710, 1: 541, 2: 549, 3: 534, 4: 547, 5: 499, 6: 549, 7: 569, 8: 295}
episode: 646/2000 -> reward: 128.44270833333314, steps:4793, time-taken: 3.55min, time-elasped: 6196.60min
-> berries picked: 97 of 800 | patches-visited: [0, 3, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 11216 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1424, 910, 934, 1097, 1567, 1822, 1491, 855, 1116]
	| approx positives in sample 512: 152
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 12, 14, 18, 21, 22, 12, 18, 19]
	Time taken saving stuff: 0.01s

=== episode:647 Env-steps-taken:70272
 	picked: 87 |actions: {0: 746, 1: 566, 2: 435, 3: 475, 4: 491, 5: 487, 6: 537, 7: 473, 8: 531}
episode: 647/2000 -> reward: 112.01562499999986, steps:4741, time-taken: 3.52min, time-elasped: 6200.12min
-> berries picked: 87 of 800 | patches-visited: [0, 3, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 11215 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1427, 908, 933, 1095, 1568, 1819, 1498, 849, 1118]
	| approx positives in sample 512: 146
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 9, 11, 11, 21, 20, 21, 10, 24]
	Time taken saving stuff: 0.01s

=== episode:648 Env-steps-taken:82176
 	picked: 124 |actions: {0: 683, 1: 712, 2: 553, 3: 694, 4: 851, 5: 847, 6: 910, 7: 664, 8: 589}
episode: 648/2000 -> reward: 169.95312500000014, steps:6503, time-taken: 4.47min, time-elasped: 6204.60min
-> berries picked: 124 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 11217 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1427, 903, 932, 1104, 1572, 1829, 1493, 842, 1115]
	| approx positives in sample 512: 171
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [26, 15, 15, 17, 16, 27, 18, 14, 23]
	Time taken saving stuff: 0.01s

=== episode:649 Env-steps-taken:75648
 	picked: 98 |actions: {0: 923, 1: 548, 2: 538, 3: 524, 4: 741, 5: 606, 6: 595, 7: 818, 8: 722}
episode: 649/2000 -> reward: 138.8854166666666, steps:6015, time-taken: 4.19min, time-elasped: 6208.80min
-> berries picked: 98 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 11243 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1425, 904, 932, 1103, 1577, 1837, 1499, 849, 1117]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 8, 10, 12, 16, 17, 16, 11, 27]
	Time taken saving stuff: 0.01s

=== episode:650 Env-steps-taken:74976
 	picked: 113 |actions: {0: 733, 1: 741, 2: 592, 3: 640, 4: 614, 5: 588, 6: 753, 7: 681, 8: 582}
episode: 650/2000 -> reward: 134.52604166666652, steps:5924, time-taken: 4.08min, time-elasped: 6212.88min
-> berries picked: 113 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 11243 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1429, 903, 935, 1102, 1579, 1831, 1498, 847, 1119]
	| approx positives in sample 512: 158
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 12, 17, 11, 21, 19, 19, 14, 25]
	Time taken saving stuff: 0.07s

=== episode:65 Env-steps-taken:93504
 	picked: 173 |actions: {0: 980, 1: 388, 2: 539, 3: 538, 4: 626, 5: 384, 6: 466, 7: 584, 8: 500}

==================================================
eval-episode: 650 -> reward: 228.58854166666734, steps: 5005.0, wall-time: 80.43s
-> berries picked: 173 of 800 | patches-visited: [1, 2, 5, 7] | juice left:-0.00
==================================================


=== episode:651 Env-steps-taken:72288
 	picked: 90 |actions: {0: 741, 1: 521, 2: 547, 3: 663, 4: 689, 5: 834, 6: 455, 7: 609, 8: 412}
episode: 651/2000 -> reward: 121.84374999999987, steps:5471, time-taken: 3.59min, time-elasped: 6217.82min
-> berries picked: 90 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 11198 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1420, 904, 930, 1091, 1568, 1834, 1491, 842, 1118]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 14, 12, 12, 21, 17, 19, 10, 17]
	Time taken saving stuff: 0.01s

=== episode:652 Env-steps-taken:57984
 	picked: 35 |actions: {0: 224, 1: 267, 2: 294, 3: 278, 4: 254, 5: 305, 6: 274, 7: 252, 8: 236}
episode: 652/2000 -> reward: 49.99479166666668, steps:2384, time-taken: 1.83min, time-elasped: 6219.65min
-> berries picked: 35 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 11183 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1414, 903, 931, 1084, 1568, 1841, 1488, 836, 1118]
	| approx positives in sample 512: 151
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 12, 13, 17, 17, 28, 24, 7, 19]
	Time taken saving stuff: 0.01s

=== episode:653 Env-steps-taken:78528
 	picked: 110 |actions: {0: 680, 1: 679, 2: 620, 3: 601, 4: 553, 5: 748, 6: 712, 7: 619, 8: 528}
episode: 653/2000 -> reward: 153.69791666666666, steps:5740, time-taken: 3.85min, time-elasped: 6223.51min
-> berries picked: 110 of 800 | patches-visited: [0, 1, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 11166 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1413, 902, 932, 1092, 1560, 1836, 1482, 833, 1116]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 6, 8, 8, 22, 14, 16, 12, 17]
	Time taken saving stuff: 0.01s

=== episode:654 Env-steps-taken:65856
 	picked: 70 |actions: {0: 904, 1: 602, 2: 492, 3: 469, 4: 496, 5: 659, 6: 539, 7: 765, 8: 705}
episode: 654/2000 -> reward: 88.98958333333326, steps:5631, time-taken: 3.72min, time-elasped: 6227.23min
-> berries picked: 70 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 11158 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1411, 901, 929, 1092, 1555, 1838, 1485, 834, 1113]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [23, 10, 8, 14, 19, 25, 15, 9, 15]
	Time taken saving stuff: 0.01s

=== episode:655 Env-steps-taken:62976
 	picked: 61 |actions: {0: 451, 1: 427, 2: 418, 3: 401, 4: 529, 5: 433, 6: 387, 7: 420, 8: 468}
episode: 655/2000 -> reward: 74.11979166666666, steps:3934, time-taken: 2.68min, time-elasped: 6229.91min
-> berries picked: 61 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 11156 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1410, 903, 930, 1089, 1561, 1835, 1484, 832, 1112]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 15, 9, 15, 16, 23, 12, 10, 19]
	Time taken saving stuff: 0.02s

=== episode:656 Env-steps-taken:75456
 	picked: 100 |actions: {0: 761, 1: 510, 2: 585, 3: 744, 4: 715, 5: 559, 6: 723, 7: 702, 8: 504}
episode: 656/2000 -> reward: 137.77083333333323, steps:5803, time-taken: 3.74min, time-elasped: 6233.65min
-> berries picked: 100 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 11067 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1407, 898, 918, 1093, 1541, 1800, 1465, 834, 1111]
	| approx positives in sample 512: 139
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 9, 13, 15, 15, 18, 17, 11, 19]
	Time taken saving stuff: 0.00s

=== episode:657 Env-steps-taken:60960
 	picked: 43 |actions: {0: 404, 1: 274, 2: 222, 3: 222, 4: 311, 5: 264, 6: 298, 7: 497, 8: 482}
episode: 657/2000 -> reward: 66.03645833333339, steps:2974, time-taken: 1.50min, time-elasped: 6235.15min
-> berries picked: 43 of 800 | patches-visited: [0, 2, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 11044 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1407, 894, 909, 1097, 1539, 1793, 1459, 836, 1110]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 10, 8, 11, 17, 18, 17, 12, 20]
	Time taken saving stuff: 0.01s

=== episode:658 Env-steps-taken:61344
 	picked: 56 |actions: {0: 512, 1: 410, 2: 395, 3: 456, 4: 385, 5: 591, 6: 442, 7: 763, 8: 755}
episode: 658/2000 -> reward: 66.79166666666671, steps:4709, time-taken: 2.41min, time-elasped: 6237.57min
-> berries picked: 56 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 11021 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1405, 893, 912, 1096, 1533, 1785, 1451, 840, 1106]
	| approx positives in sample 512: 149
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 16, 16, 18, 20, 16, 21, 9, 17]
	Time taken saving stuff: 0.00s

=== episode:659 Env-steps-taken:54144
 	picked: 22 |actions: {0: 109, 1: 123, 2: 86, 3: 99, 4: 210, 5: 184, 6: 126, 7: 149, 8: 215}
episode: 659/2000 -> reward: 31.73958333333332, steps:1301, time-taken: 1.05min, time-elasped: 6238.63min
-> berries picked: 22 of 800 | patches-visited: [0, 5, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 11001 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1402, 894, 911, 1097, 1527, 1780, 1443, 839, 1108]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [23, 15, 8, 14, 21, 12, 14, 6, 21]
	Time taken saving stuff: 0.01s

=== episode:660 Env-steps-taken:70368
 	picked: 91 |actions: {0: 837, 1: 538, 2: 436, 3: 566, 4: 667, 5: 605, 6: 802, 7: 616, 8: 495}
episode: 660/2000 -> reward: 111.78645833333319, steps:5562, time-taken: 2.95min, time-elasped: 6241.58min
-> berries picked: 91 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10976 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1398, 896, 912, 1096, 1521, 1775, 1431, 838, 1109]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 13, 19, 16, 21, 17, 11, 8, 16]
	Time taken saving stuff: 0.05s

=== episode:66 Env-steps-taken:91200
 	picked: 163 |actions: {0: 856, 1: 482, 2: 487, 3: 638, 4: 626, 5: 350, 6: 539, 7: 899, 8: 990}

==================================================
eval-episode: 660 -> reward: 214.7760416666671, steps: 5867.0, wall-time: 67.16s
-> berries picked: 163 of 800 | patches-visited: [0, 1, 6] | juice left:-0.00
==================================================


=== episode:661 Env-steps-taken:81600
 	picked: 120 |actions: {0: 747, 1: 575, 2: 607, 3: 934, 4: 745, 5: 786, 6: 600, 7: 536, 8: 625}
episode: 661/2000 -> reward: 169.12500000000006, steps:6155, time-taken: 3.19min, time-elasped: 6245.89min
-> berries picked: 120 of 800 | patches-visited: [0, 2, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10880 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1398, 891, 906, 1108, 1508, 1753, 1392, 817, 1107]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 8, 7, 16, 20, 22, 10, 13, 18]
	Time taken saving stuff: 0.01s

=== episode:662 Env-steps-taken:68352
 	picked: 75 |actions: {0: 480, 1: 375, 2: 331, 3: 530, 4: 508, 5: 438, 6: 484, 7: 516, 8: 450}
episode: 662/2000 -> reward: 102.70312499999989, steps:4112, time-taken: 2.35min, time-elasped: 6248.24min
-> berries picked: 75 of 800 | patches-visited: [0, 2, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10830 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1399, 888, 893, 1104, 1502, 1747, 1379, 815, 1103]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [23, 9, 11, 16, 17, 18, 15, 12, 21]
	Time taken saving stuff: 0.00s

=== episode:663 Env-steps-taken:67776
 	picked: 71 |actions: {0: 968, 1: 550, 2: 485, 3: 479, 4: 551, 5: 545, 6: 383, 7: 626, 8: 813}
episode: 663/2000 -> reward: 99.9322916666666, steps:5400, time-taken: 3.31min, time-elasped: 6251.55min
-> berries picked: 71 of 800 | patches-visited: [0, 6, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10802 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1405, 884, 886, 1102, 1496, 1738, 1376, 813, 1102]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 9, 17, 15, 17, 19, 18, 12, 15]
	Time taken saving stuff: 0.01s

=== episode:664 Env-steps-taken:64800
 	picked: 65 |actions: {0: 719, 1: 461, 2: 355, 3: 429, 4: 470, 5: 567, 6: 693, 7: 751, 8: 801}
episode: 664/2000 -> reward: 84.27604166666663, steps:5246, time-taken: 2.63min, time-elasped: 6254.19min
-> berries picked: 65 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10770 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1406, 879, 884, 1100, 1487, 1734, 1368, 812, 1100]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 7, 12, 15, 13, 20, 16, 5, 25]
	Time taken saving stuff: 0.01s

=== episode:665 Env-steps-taken:74784
 	picked: 106 |actions: {0: 864, 1: 622, 2: 574, 3: 632, 4: 603, 5: 671, 6: 540, 7: 720, 8: 476}
episode: 665/2000 -> reward: 133.92708333333323, steps:5702, time-taken: 2.84min, time-elasped: 6257.04min
-> berries picked: 106 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10757 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1402, 880, 879, 1105, 1485, 1735, 1359, 810, 1102]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 13, 12, 10, 16, 18, 14, 10, 24]
	Time taken saving stuff: 0.00s

=== episode:666 Env-steps-taken:63360
 	picked: 53 |actions: {0: 878, 1: 333, 2: 463, 3: 469, 4: 515, 5: 712, 6: 344, 7: 468, 8: 330}
episode: 666/2000 -> reward: 76.96354166666667, steps:4512, time-taken: 1.73min, time-elasped: 6258.77min
-> berries picked: 53 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10735 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1402, 878, 871, 1103, 1488, 1729, 1356, 811, 1097]
	| approx positives in sample 512: 160
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 25, 7, 13, 23, 20, 15, 17, 21]
	Time taken saving stuff: 0.00s

=== episode:667 Env-steps-taken:72864
 	picked: 87 |actions: {0: 531, 1: 534, 2: 383, 3: 387, 4: 545, 5: 736, 6: 485, 7: 688, 8: 335}
episode: 667/2000 -> reward: 123.5729166666665, steps:4624, time-taken: 1.78min, time-elasped: 6260.55min
-> berries picked: 87 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10706 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1408, 877, 863, 1081, 1491, 1727, 1353, 809, 1097]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 10, 10, 9, 22, 20, 7, 11, 21]
	Time taken saving stuff: 0.01s

=== episode:668 Env-steps-taken:79104
 	picked: 113 |actions: {0: 1013, 1: 588, 2: 570, 3: 667, 4: 746, 5: 911, 6: 648, 7: 654, 8: 566}
episode: 668/2000 -> reward: 156.52604166666666, steps:6363, time-taken: 2.39min, time-elasped: 6262.94min
-> berries picked: 113 of 800 | patches-visited: [0, 1, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10711 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1409, 872, 859, 1082, 1495, 1731, 1354, 811, 1098]
	| approx positives in sample 512: 145
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 21, 9, 13, 18, 20, 18, 15, 16]
	Time taken saving stuff: 0.00s

=== episode:669 Env-steps-taken:70560
 	picked: 80 |actions: {0: 615, 1: 413, 2: 393, 3: 511, 4: 581, 5: 684, 6: 557, 7: 551, 8: 654}
episode: 669/2000 -> reward: 113.91666666666657, steps:4959, time-taken: 1.94min, time-elasped: 6264.89min
-> berries picked: 80 of 800 | patches-visited: [0, 1, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10704 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1407, 880, 862, 1073, 1491, 1731, 1352, 807, 1101]
	| approx positives in sample 512: 143
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 8, 12, 21, 21, 25, 11, 4, 27]
	Time taken saving stuff: 0.00s

=== episode:670 Env-steps-taken:70272
 	picked: 84 |actions: {0: 682, 1: 524, 2: 503, 3: 512, 4: 466, 5: 587, 6: 513, 7: 641, 8: 632}
episode: 670/2000 -> reward: 111.3020833333332, steps:5060, time-taken: 1.92min, time-elasped: 6266.81min
-> berries picked: 84 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10725 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1413, 879, 864, 1072, 1496, 1739, 1354, 808, 1100]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 13, 11, 12, 18, 21, 24, 10, 17]
	Time taken saving stuff: 0.05s

=== episode:67 Env-steps-taken:74112
 	picked: 93 |actions: {0: 827, 1: 298, 2: 237, 3: 191, 4: 165, 5: 888, 6: 475, 7: 438, 8: 1284}

==================================================
eval-episode: 670 -> reward: 130.28645833333317, steps: 4803.0, wall-time: 39.83s
-> berries picked: 93 of 800 | patches-visited: [1, 4] | juice left:-0.00
==================================================


=== episode:671 Env-steps-taken:68928
 	picked: 79 |actions: {0: 481, 1: 481, 2: 554, 3: 409, 4: 388, 5: 427, 6: 352, 7: 388, 8: 381}
episode: 671/2000 -> reward: 104.97395833333326, steps:3861, time-taken: 1.66min, time-elasped: 6269.13min
-> berries picked: 79 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10703 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1407, 873, 865, 1072, 1492, 1732, 1354, 806, 1102]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 16, 13, 9, 14, 19, 18, 12, 12]
	Time taken saving stuff: 0.00s

=== episode:672 Env-steps-taken:79200
 	picked: 117 |actions: {0: 761, 1: 631, 2: 614, 3: 646, 4: 594, 5: 714, 6: 752, 7: 772, 8: 693}
episode: 672/2000 -> reward: 156.29687500000003, steps:6177, time-taken: 3.31min, time-elasped: 6272.45min
-> berries picked: 117 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10687 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1409, 864, 866, 1068, 1487, 1724, 1356, 808, 1105]
	| approx positives in sample 512: 147
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 16, 17, 14, 20, 22, 13, 15, 18]
	Time taken saving stuff: 0.01s

=== episode:673 Env-steps-taken:78048
 	picked: 102 |actions: {0: 636, 1: 582, 2: 550, 3: 510, 4: 630, 5: 679, 6: 697, 7: 561, 8: 596}
episode: 673/2000 -> reward: 149.77083333333331, steps:5441, time-taken: 2.85min, time-elasped: 6275.30min
-> berries picked: 102 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10667 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1407, 855, 865, 1065, 1486, 1721, 1352, 808, 1108]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 15, 10, 16, 14, 21, 17, 11, 15]
	Time taken saving stuff: 0.00s

=== episode:674 Env-steps-taken:72672
 	picked: 101 |actions: {0: 807, 1: 736, 2: 572, 3: 640, 4: 617, 5: 668, 6: 715, 7: 745, 8: 593}
episode: 674/2000 -> reward: 123.21354166666647, steps:6093, time-taken: 3.10min, time-elasped: 6278.41min
-> berries picked: 101 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10645 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1409, 855, 860, 1065, 1487, 1702, 1352, 807, 1108]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 9, 10, 16, 18, 20, 13, 8, 16]
	Time taken saving stuff: 0.00s

=== episode:675 Env-steps-taken:72288
 	picked: 87 |actions: {0: 676, 1: 663, 2: 569, 3: 344, 4: 461, 5: 393, 6: 434, 7: 639, 8: 625}
episode: 675/2000 -> reward: 122.51562499999986, steps:4804, time-taken: 2.86min, time-elasped: 6281.27min
-> berries picked: 87 of 800 | patches-visited: [0, 2, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10650 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1409, 848, 863, 1069, 1483, 1699, 1356, 814, 1109]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 10, 9, 14, 17, 19, 10, 10, 23]
	Time taken saving stuff: 0.01s

=== episode:676 Env-steps-taken:61728
 	picked: 48 |actions: {0: 250, 1: 280, 2: 346, 3: 314, 4: 272, 5: 265, 6: 195, 7: 297, 8: 252}
episode: 676/2000 -> reward: 69.25000000000003, steps:2471, time-taken: 1.70min, time-elasped: 6282.97min
-> berries picked: 48 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10640 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1411, 846, 864, 1073, 1476, 1693, 1352, 816, 1109]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 8, 8, 17, 16, 22, 13, 8, 19]
	Time taken saving stuff: 0.01s

=== episode:677 Env-steps-taken:76992
 	picked: 102 |actions: {0: 636, 1: 521, 2: 679, 3: 504, 4: 530, 5: 566, 6: 518, 7: 587, 8: 595}
episode: 677/2000 -> reward: 145.65624999999994, steps:5136, time-taken: 2.83min, time-elasped: 6285.80min
-> berries picked: 102 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10616 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1405, 842, 870, 1070, 1469, 1678, 1356, 819, 1107]
	| approx positives in sample 512: 149
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 13, 13, 15, 20, 13, 21, 17, 20]
	Time taken saving stuff: 0.02s

=== episode:678 Env-steps-taken:74112
 	picked: 91 |actions: {0: 591, 1: 603, 2: 588, 3: 514, 4: 408, 5: 468, 6: 462, 7: 667, 8: 678}
episode: 678/2000 -> reward: 131.7864583333332, steps:4979, time-taken: 2.76min, time-elasped: 6288.57min
-> berries picked: 91 of 800 | patches-visited: [0, 2, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10601 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1407, 839, 868, 1074, 1464, 1672, 1349, 820, 1108]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 9, 9, 13, 13, 20, 17, 9, 16]
	Time taken saving stuff: 0.00s

=== episode:679 Env-steps-taken:73344
 	picked: 91 |actions: {0: 541, 1: 456, 2: 604, 3: 459, 4: 440, 5: 549, 6: 445, 7: 547, 8: 512}
episode: 679/2000 -> reward: 125.84374999999984, steps:4553, time-taken: 2.84min, time-elasped: 6291.41min
-> berries picked: 91 of 800 | patches-visited: [0, 2, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10597 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1409, 841, 871, 1076, 1462, 1664, 1345, 820, 1109]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 13, 12, 15, 15, 22, 20, 10, 16]
	Time taken saving stuff: 0.00s

=== episode:680 Env-steps-taken:68832
 	picked: 77 |actions: {0: 659, 1: 641, 2: 650, 3: 479, 4: 571, 5: 564, 6: 456, 7: 592, 8: 762}
episode: 680/2000 -> reward: 104.20312499999987, steps:5374, time-taken: 3.03min, time-elasped: 6294.45min
-> berries picked: 77 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10604 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1414, 837, 871, 1076, 1469, 1664, 1342, 821, 1110]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 14, 12, 19, 20, 19, 19, 11, 13]
	Time taken saving stuff: 0.06s

=== episode:68 Env-steps-taken:98784
 	picked: 185 |actions: {0: 1019, 1: 802, 2: 687, 3: 703, 4: 865, 5: 444, 6: 612, 7: 574, 8: 803}

==================================================
eval-episode: 680 -> reward: 255.40104166666737, steps: 6509.0, wall-time: 76.86s
-> berries picked: 185 of 800 | patches-visited: [1, 3, 4, 6] | juice left:-0.00
==================================================


=== episode:681 Env-steps-taken:73536
 	picked: 93 |actions: {0: 491, 1: 555, 2: 593, 3: 492, 4: 533, 5: 596, 6: 617, 7: 733, 8: 506}
episode: 681/2000 -> reward: 128.1718749999998, steps:5116, time-taken: 2.96min, time-elasped: 6298.69min
-> berries picked: 93 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10621 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1412, 837, 868, 1079, 1470, 1658, 1352, 829, 1116]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [25, 22, 7, 14, 10, 13, 23, 13, 8]
	Time taken saving stuff: 0.00s

=== episode:682 Env-steps-taken:66048
 	picked: 75 |actions: {0: 519, 1: 540, 2: 415, 3: 540, 4: 615, 5: 545, 6: 453, 7: 650, 8: 766}
episode: 682/2000 -> reward: 90.20312499999996, steps:5043, time-taken: 3.15min, time-elasped: 6301.84min
-> berries picked: 75 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10613 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1408, 830, 867, 1083, 1475, 1656, 1349, 831, 1114]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 10, 12, 8, 10, 18, 16, 11, 18]
	Time taken saving stuff: 0.00s

=== episode:683 Env-steps-taken:74976
 	picked: 109 |actions: {0: 669, 1: 674, 2: 584, 3: 613, 4: 721, 5: 640, 6: 587, 7: 781, 8: 732}
episode: 683/2000 -> reward: 134.81249999999986, steps:6001, time-taken: 3.61min, time-elasped: 6305.45min
-> berries picked: 109 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10619 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1410, 829, 880, 1077, 1467, 1657, 1349, 837, 1113]
	| approx positives in sample 512: 153
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 14, 13, 17, 16, 24, 18, 10, 21]
	Time taken saving stuff: 0.01s

=== episode:684 Env-steps-taken:77856
 	picked: 115 |actions: {0: 600, 1: 714, 2: 681, 3: 658, 4: 602, 5: 764, 6: 668, 7: 817, 8: 705}
episode: 684/2000 -> reward: 149.41145833333334, steps:6209, time-taken: 3.59min, time-elasped: 6309.05min
-> berries picked: 115 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10627 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1408, 829, 888, 1074, 1463, 1661, 1352, 839, 1113]
	| approx positives in sample 512: 151
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 13, 20, 19, 15, 18, 18, 7, 24]
	Time taken saving stuff: 0.00s

=== episode:685 Env-steps-taken:74016
 	picked: 90 |actions: {0: 529, 1: 536, 2: 637, 3: 519, 4: 626, 5: 538, 6: 551, 7: 560, 8: 564}
episode: 685/2000 -> reward: 129.45833333333317, steps:5060, time-taken: 3.27min, time-elasped: 6312.31min
-> berries picked: 90 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10654 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1411, 834, 890, 1077, 1465, 1668, 1353, 841, 1115]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 11, 18, 10, 12, 25, 10, 8, 22]
	Time taken saving stuff: 0.00s

=== episode:686 Env-steps-taken:79008
 	picked: 118 |actions: {0: 578, 1: 855, 2: 586, 3: 687, 4: 674, 5: 632, 6: 694, 7: 774, 8: 846}
episode: 686/2000 -> reward: 155.29687500000009, steps:6326, time-taken: 4.16min, time-elasped: 6316.47min
-> berries picked: 118 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10629 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1402, 837, 891, 1078, 1459, 1661, 1348, 839, 1114]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 13, 11, 18, 22, 17, 12, 12, 22]
	Time taken saving stuff: 0.00s

=== episode:687 Env-steps-taken:74880
 	picked: 95 |actions: {0: 772, 1: 677, 2: 478, 3: 781, 4: 469, 5: 599, 6: 422, 7: 716, 8: 727}
episode: 687/2000 -> reward: 135.55729166666654, steps:5641, time-taken: 3.55min, time-elasped: 6320.02min
-> berries picked: 95 of 800 | patches-visited: [0, 1, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10615 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1400, 838, 893, 1076, 1456, 1657, 1345, 836, 1114]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [23, 8, 7, 14, 12, 25, 12, 10, 17]
	Time taken saving stuff: 0.00s

=== episode:688 Env-steps-taken:61920
 	picked: 55 |actions: {0: 751, 1: 860, 2: 581, 3: 467, 4: 377, 5: 436, 6: 500, 7: 686, 8: 946}
episode: 688/2000 -> reward: 69.34895833333337, steps:5604, time-taken: 2.68min, time-elasped: 6322.70min
-> berries picked: 55 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10589 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1398, 837, 890, 1076, 1452, 1652, 1338, 833, 1113]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 13, 12, 10, 15, 12, 19, 11, 14]
	Time taken saving stuff: 0.00s

=== episode:689 Env-steps-taken:75264
 	picked: 100 |actions: {0: 543, 1: 618, 2: 458, 3: 638, 4: 614, 5: 664, 6: 553, 7: 568, 8: 428}
episode: 689/2000 -> reward: 137.27083333333326, steps:5084, time-taken: 2.25min, time-elasped: 6324.95min
-> berries picked: 100 of 800 | patches-visited: [0, 1, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10605 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1392, 838, 895, 1082, 1448, 1657, 1345, 833, 1115]
	| approx positives in sample 512: 146
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 10, 10, 17, 18, 20, 19, 12, 27]
	Time taken saving stuff: 0.01s

=== episode:690 Env-steps-taken:84288
 	picked: 129 |actions: {0: 752, 1: 798, 2: 823, 3: 872, 4: 807, 5: 709, 6: 640, 7: 809, 8: 617}
episode: 690/2000 -> reward: 182.6093750000002, steps:6827, time-taken: 3.72min, time-elasped: 6328.68min
-> berries picked: 129 of 800 | patches-visited: [0, 4, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10620 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1391, 843, 895, 1091, 1450, 1652, 1344, 839, 1115]
	| approx positives in sample 512: 139
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [23, 7, 10, 8, 13, 19, 20, 22, 17]
	Time taken saving stuff: 0.06s

=== episode:69 Env-steps-taken:110592
 	picked: 232 |actions: {0: 711, 1: 840, 2: 403, 3: 807, 4: 670, 5: 772, 6: 1158, 7: 649, 8: 760}

==================================================
eval-episode: 690 -> reward: 314.70833333333303, steps: 6770.0, wall-time: 90.24s
-> berries picked: 232 of 800 | patches-visited: [1, 2, 4, 5, 7] | juice left:-0.00
==================================================


=== episode:691 Env-steps-taken:67296
 	picked: 69 |actions: {0: 571, 1: 397, 2: 531, 3: 346, 4: 458, 5: 461, 6: 418, 7: 591, 8: 730}
episode: 691/2000 -> reward: 97.54687499999993, steps:4503, time-taken: 2.70min, time-elasped: 6332.89min
-> berries picked: 69 of 800 | patches-visited: [0, 5, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10601 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1393, 844, 896, 1080, 1431, 1649, 1347, 843, 1118]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 20, 10, 16, 22, 21, 10, 14, 16]
	Time taken saving stuff: 0.01s

=== episode:692 Env-steps-taken:57504
 	picked: 33 |actions: {0: 352, 1: 227, 2: 240, 3: 205, 4: 264, 5: 281, 6: 213, 7: 325, 8: 332}
episode: 692/2000 -> reward: 48.10937500000002, steps:2439, time-taken: 1.72min, time-elasped: 6334.61min
-> berries picked: 33 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10589 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1395, 845, 896, 1078, 1426, 1643, 1345, 843, 1118]
	| approx positives in sample 512: 143
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 11, 10, 20, 13, 21, 17, 11, 19]
	Time taken saving stuff: 0.01s

=== episode:693 Env-steps-taken:71520
 	picked: 85 |actions: {0: 622, 1: 606, 2: 521, 3: 437, 4: 507, 5: 451, 6: 411, 7: 434, 8: 602}
episode: 693/2000 -> reward: 116.74479166666656, steps:4591, time-taken: 2.89min, time-elasped: 6337.50min
-> berries picked: 85 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10579 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1395, 846, 897, 1075, 1418, 1640, 1344, 848, 1116]
	| approx positives in sample 512: 149
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [29, 11, 16, 10, 16, 19, 17, 6, 25]
	Time taken saving stuff: 0.00s

=== episode:694 Env-steps-taken:76704
 	picked: 106 |actions: {0: 799, 1: 676, 2: 675, 3: 470, 4: 630, 5: 615, 6: 650, 7: 750, 8: 768}
episode: 694/2000 -> reward: 144.42708333333331, steps:6033, time-taken: 3.72min, time-elasped: 6341.22min
-> berries picked: 106 of 800 | patches-visited: [0, 3, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10588 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1393, 853, 893, 1076, 1410, 1643, 1347, 855, 1118]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 8, 10, 15, 13, 24, 13, 7, 19]
	Time taken saving stuff: 0.01s

=== episode:695 Env-steps-taken:68352
 	picked: 79 |actions: {0: 650, 1: 473, 2: 438, 3: 467, 4: 552, 5: 527, 6: 346, 7: 466, 8: 505}
episode: 695/2000 -> reward: 100.0312499999999, steps:4424, time-taken: 2.93min, time-elasped: 6344.16min
-> berries picked: 79 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10600 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1397, 853, 895, 1072, 1412, 1647, 1346, 855, 1123]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 17, 15, 11, 14, 26, 12, 13, 18]
	Time taken saving stuff: 0.01s

=== episode:696 Env-steps-taken:66912
 	picked: 70 |actions: {0: 610, 1: 430, 2: 501, 3: 412, 4: 509, 5: 435, 6: 570, 7: 630, 8: 662}
episode: 696/2000 -> reward: 95.04687499999991, steps:4759, time-taken: 2.83min, time-elasped: 6346.99min
-> berries picked: 70 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10563 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1400, 853, 882, 1064, 1400, 1638, 1349, 851, 1126]
	| approx positives in sample 512: 147
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 19, 14, 18, 10, 20, 12, 19, 18]
	Time taken saving stuff: 0.01s

=== episode:697 Env-steps-taken:72288
 	picked: 87 |actions: {0: 687, 1: 492, 2: 463, 3: 505, 4: 488, 5: 528, 6: 550, 7: 528, 8: 601}
episode: 697/2000 -> reward: 122.01562499999989, steps:4842, time-taken: 3.08min, time-elasped: 6350.07min
-> berries picked: 87 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10533 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1403, 849, 880, 1061, 1384, 1626, 1352, 851, 1127]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 12, 6, 16, 13, 19, 18, 14, 33]
	Time taken saving stuff: 0.01s

=== episode:698 Env-steps-taken:66528
 	picked: 74 |actions: {0: 725, 1: 479, 2: 446, 3: 425, 4: 460, 5: 449, 6: 570, 7: 582, 8: 673}
episode: 698/2000 -> reward: 92.76041666666661, steps:4809, time-taken: 3.12min, time-elasped: 6353.20min
-> berries picked: 74 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10520 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1412, 842, 877, 1061, 1372, 1620, 1353, 856, 1127]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 11, 11, 13, 13, 14, 24, 15, 14]
	Time taken saving stuff: 0.00s

=== episode:699 Env-steps-taken:63744
 	picked: 55 |actions: {0: 498, 1: 373, 2: 325, 3: 397, 4: 392, 5: 363, 6: 333, 7: 496, 8: 679}
episode: 699/2000 -> reward: 79.84895833333333, steps:3856, time-taken: 2.57min, time-elasped: 6355.77min
-> berries picked: 55 of 800 | patches-visited: [0, 5, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10517 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1415, 843, 876, 1054, 1372, 1618, 1352, 858, 1129]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 12, 14, 11, 16, 19, 15, 18, 22]
	Time taken saving stuff: 0.01s

=== episode:700 Env-steps-taken:54816
 	picked: 22 |actions: {0: 412, 1: 221, 2: 195, 3: 167, 4: 132, 5: 168, 6: 140, 7: 127, 8: 338}
episode: 700/2000 -> reward: 34.239583333333336, steps:1900, time-taken: 1.75min, time-elasped: 6357.53min
-> berries picked: 22 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10520 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1416, 843, 878, 1053, 1370, 1618, 1354, 859, 1129]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 9, 10, 12, 11, 14, 13, 9, 24]
	Time taken saving stuff: 0.08s

=== episode:70 Env-steps-taken:64224
 	picked: 55 |actions: {0: 346, 1: 206, 2: 263, 3: 130, 4: 59, 5: 154, 6: 122, 7: 120, 8: 437}

==================================================
eval-episode: 700 -> reward: 81.84895833333331, steps: 1837.0, wall-time: 61.69s
-> berries picked: 55 of 800 | patches-visited: [1, 8] | juice left:-0.00
==================================================


=== episode:701 Env-steps-taken:73536
 	picked: 94 |actions: {0: 813, 1: 652, 2: 578, 3: 512, 4: 558, 5: 766, 6: 517, 7: 603, 8: 807}
episode: 701/2000 -> reward: 128.11458333333317, steps:5806, time-taken: 2.63min, time-elasped: 6361.19min
-> berries picked: 94 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10507 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1405, 840, 882, 1058, 1372, 1613, 1355, 857, 1125]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 10, 14, 11, 16, 23, 10, 16, 20]
	Time taken saving stuff: 0.01s

=== episode:702 Env-steps-taken:63840
 	picked: 57 |actions: {0: 593, 1: 496, 2: 322, 3: 335, 4: 351, 5: 296, 6: 320, 7: 431, 8: 502}
episode: 702/2000 -> reward: 79.73437499999999, steps:3646, time-taken: 1.64min, time-elasped: 6362.83min
-> berries picked: 57 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10519 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1406, 842, 880, 1061, 1376, 1612, 1354, 863, 1125]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 12, 11, 9, 19, 17, 15, 11, 15]
	Time taken saving stuff: 0.00s

=== episode:703 Env-steps-taken:68832
 	picked: 79 |actions: {0: 853, 1: 637, 2: 562, 3: 419, 4: 599, 5: 411, 6: 482, 7: 542, 8: 800}
episode: 703/2000 -> reward: 104.4739583333332, steps:5305, time-taken: 2.15min, time-elasped: 6364.98min
-> berries picked: 79 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10514 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1410, 844, 889, 1058, 1378, 1612, 1344, 854, 1125]
	| approx positives in sample 512: 145
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 9, 19, 13, 18, 19, 18, 11, 24]
	Time taken saving stuff: 0.01s

=== episode:704 Env-steps-taken:62976
 	picked: 55 |actions: {0: 423, 1: 431, 2: 326, 3: 260, 4: 306, 5: 316, 6: 201, 7: 318, 8: 474}
episode: 704/2000 -> reward: 75.34895833333336, steps:3055, time-taken: 1.54min, time-elasped: 6366.53min
-> berries picked: 55 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10521 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1416, 844, 893, 1060, 1376, 1611, 1341, 853, 1127]
	| approx positives in sample 512: 152
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 15, 12, 19, 24, 18, 15, 14, 15]
	Time taken saving stuff: 0.00s

=== episode:705 Env-steps-taken:71520
 	picked: 88 |actions: {0: 901, 1: 672, 2: 592, 3: 592, 4: 727, 5: 695, 6: 486, 7: 726, 8: 722}
episode: 705/2000 -> reward: 117.95833333333319, steps:6113, time-taken: 2.93min, time-elasped: 6369.47min
-> berries picked: 88 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10505 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1403, 841, 899, 1064, 1375, 1605, 1343, 849, 1126]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 13, 16, 9, 20, 22, 14, 14, 18]
	Time taken saving stuff: 0.01s

=== episode:706 Env-steps-taken:71424
 	picked: 81 |actions: {0: 642, 1: 649, 2: 494, 3: 523, 4: 456, 5: 474, 6: 446, 7: 589, 8: 514}
episode: 706/2000 -> reward: 117.85937499999987, steps:4787, time-taken: 2.13min, time-elasped: 6371.60min
-> berries picked: 81 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10493 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1404, 838, 900, 1063, 1378, 1605, 1338, 844, 1123]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 9, 9, 11, 24, 14, 18, 10, 15]
	Time taken saving stuff: 0.01s

=== episode:707 Env-steps-taken:70368
 	picked: 82 |actions: {0: 727, 1: 637, 2: 600, 3: 533, 4: 506, 5: 607, 6: 461, 7: 756, 8: 732}
episode: 707/2000 -> reward: 112.30208333333317, steps:5559, time-taken: 3.62min, time-elasped: 6375.23min
-> berries picked: 82 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10509 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1410, 839, 901, 1065, 1379, 1604, 1344, 844, 1123]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 13, 10, 5, 15, 13, 12, 16, 16]
	Time taken saving stuff: 0.01s

=== episode:708 Env-steps-taken:66432
 	picked: 64 |actions: {0: 698, 1: 493, 2: 364, 3: 395, 4: 450, 5: 391, 6: 344, 7: 509, 8: 545}
episode: 708/2000 -> reward: 90.89062499999999, steps:4189, time-taken: 2.36min, time-elasped: 6377.59min
-> berries picked: 64 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10500 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1416, 839, 900, 1061, 1377, 1604, 1339, 840, 1124]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 11, 13, 10, 13, 18, 10, 19, 19]
	Time taken saving stuff: 0.01s

=== episode:709 Env-steps-taken:59712
 	picked: 45 |actions: {0: 521, 1: 315, 2: 516, 3: 274, 4: 333, 5: 370, 6: 249, 7: 416, 8: 666}
episode: 709/2000 -> reward: 58.92187500000004, steps:3660, time-taken: 2.29min, time-elasped: 6379.89min
-> berries picked: 45 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10490 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1412, 839, 896, 1060, 1376, 1601, 1339, 841, 1126]
	| approx positives in sample 512: 147
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [24, 20, 7, 18, 12, 23, 16, 9, 18]
	Time taken saving stuff: 0.01s

=== episode:710 Env-steps-taken:73728
 	picked: 90 |actions: {0: 546, 1: 571, 2: 565, 3: 549, 4: 555, 5: 532, 6: 373, 7: 530, 8: 790}
episode: 710/2000 -> reward: 129.34374999999983, steps:5011, time-taken: 2.88min, time-elasped: 6382.77min
-> berries picked: 90 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10512 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1417, 835, 902, 1072, 1378, 1600, 1337, 844, 1127]
	| approx positives in sample 512: 156
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 10, 19, 18, 17, 20, 18, 18, 14]
	Time taken saving stuff: 0.09s

=== episode:71 Env-steps-taken:87264
 	picked: 153 |actions: {0: 608, 1: 793, 2: 329, 3: 651, 4: 538, 5: 515, 6: 304, 7: 606, 8: 980}

==================================================
eval-episode: 710 -> reward: 194.46354166666694, steps: 5324.0, wall-time: 70.72s
-> berries picked: 153 of 800 | patches-visited: [0, 1, 6, 8] | juice left:-0.00
==================================================


=== episode:711 Env-steps-taken:66432
 	picked: 67 |actions: {0: 412, 1: 348, 2: 330, 3: 327, 4: 361, 5: 446, 6: 247, 7: 354, 8: 392}
episode: 711/2000 -> reward: 92.66145833333329, steps:3217, time-taken: 2.08min, time-elasped: 6386.04min
-> berries picked: 67 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10523 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1417, 840, 903, 1067, 1380, 1606, 1332, 848, 1130]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 2, 16, 17, 12, 22, 21, 12, 19]
	Time taken saving stuff: 0.01s

=== episode:712 Env-steps-taken:70272
 	picked: 76 |actions: {0: 582, 1: 491, 2: 448, 3: 461, 4: 462, 5: 628, 6: 324, 7: 617, 8: 476}
episode: 712/2000 -> reward: 112.64583333333321, steps:4489, time-taken: 2.80min, time-elasped: 6388.84min
-> berries picked: 76 of 800 | patches-visited: [0, 2, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10539 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1420, 837, 904, 1069, 1382, 1609, 1336, 850, 1132]
	| approx positives in sample 512: 143
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 14, 15, 12, 26, 16, 19, 15, 7]
	Time taken saving stuff: 0.01s

=== episode:713 Env-steps-taken:72576
 	picked: 97 |actions: {0: 702, 1: 675, 2: 674, 3: 563, 4: 715, 5: 625, 6: 419, 7: 887, 8: 666}
episode: 713/2000 -> reward: 122.94270833333313, steps:5926, time-taken: 3.53min, time-elasped: 6392.38min
-> berries picked: 97 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10537 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1421, 838, 907, 1066, 1380, 1608, 1336, 849, 1132]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 15, 11, 12, 12, 22, 24, 10, 17]
	Time taken saving stuff: 0.01s

=== episode:714 Env-steps-taken:69504
 	picked: 81 |actions: {0: 504, 1: 606, 2: 462, 3: 388, 4: 492, 5: 631, 6: 262, 7: 646, 8: 531}
episode: 714/2000 -> reward: 106.4739583333332, steps:4522, time-taken: 3.56min, time-elasped: 6395.95min
-> berries picked: 81 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10552 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1425, 845, 910, 1069, 1373, 1606, 1334, 852, 1138]
	| approx positives in sample 512: 149
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 19, 15, 9, 12, 19, 24, 9, 24]
	Time taken saving stuff: 0.01s

=== episode:715 Env-steps-taken:74784
 	picked: 96 |actions: {0: 671, 1: 657, 2: 630, 3: 575, 4: 664, 5: 683, 6: 493, 7: 739, 8: 891}
episode: 715/2000 -> reward: 133.05729166666652, steps:6003, time-taken: 4.04min, time-elasped: 6399.99min
-> berries picked: 96 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10559 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1428, 843, 915, 1067, 1376, 1607, 1335, 847, 1141]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 9, 13, 10, 12, 16, 14, 14, 21]
	Time taken saving stuff: 0.01s

=== episode:716 Env-steps-taken:64800
 	picked: 66 |actions: {0: 310, 1: 533, 2: 471, 3: 288, 4: 476, 5: 397, 6: 307, 7: 609, 8: 425}
episode: 716/2000 -> reward: 82.27604166666663, steps:3816, time-taken: 2.49min, time-elasped: 6402.49min
-> berries picked: 66 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10556 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1422, 847, 915, 1064, 1376, 1609, 1336, 845, 1142]
	| approx positives in sample 512: 143
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 14, 9, 14, 14, 13, 20, 8, 30]
	Time taken saving stuff: 0.00s

=== episode:717 Env-steps-taken:84096
 	picked: 126 |actions: {0: 618, 1: 918, 2: 913, 3: 725, 4: 861, 5: 809, 6: 487, 7: 760, 8: 599}
episode: 717/2000 -> reward: 181.78125000000014, steps:6690, time-taken: 3.94min, time-elasped: 6406.43min
-> berries picked: 126 of 800 | patches-visited: [0, 4, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10576 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1420, 852, 913, 1070, 1385, 1617, 1332, 844, 1143]
	| approx positives in sample 512: 150
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 7, 7, 14, 26, 25, 12, 15, 26]
	Time taken saving stuff: 0.01s

=== episode:718 Env-steps-taken:62400
 	picked: 51 |actions: {0: 518, 1: 467, 2: 401, 3: 240, 4: 322, 5: 335, 6: 226, 7: 378, 8: 329}
episode: 718/2000 -> reward: 72.57812500000001, steps:3216, time-taken: 2.10min, time-elasped: 6408.53min
-> berries picked: 51 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10591 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1424, 853, 914, 1070, 1384, 1617, 1335, 851, 1143]
	| approx positives in sample 512: 143
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 7, 18, 17, 17, 23, 23, 12, 14]
	Time taken saving stuff: 0.00s

=== episode:719 Env-steps-taken:58944
 	picked: 36 |actions: {0: 331, 1: 293, 2: 317, 3: 156, 4: 231, 5: 243, 6: 205, 7: 345, 8: 301}
episode: 719/2000 -> reward: 55.43750000000003, steps:2422, time-taken: 1.74min, time-elasped: 6410.28min
-> berries picked: 36 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10602 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1428, 854, 913, 1069, 1383, 1619, 1340, 852, 1144]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 4, 12, 16, 14, 23, 23, 6, 26]
	Time taken saving stuff: 0.01s

=== episode:720 Env-steps-taken:62976
 	picked: 55 |actions: {0: 301, 1: 351, 2: 379, 3: 284, 4: 422, 5: 399, 6: 308, 7: 347, 8: 262}
episode: 720/2000 -> reward: 75.34895833333334, steps:3053, time-taken: 2.14min, time-elasped: 6412.42min
-> berries picked: 55 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10617 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1429, 855, 913, 1072, 1384, 1626, 1341, 852, 1145]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [27, 8, 10, 14, 14, 21, 11, 12, 21]
	Time taken saving stuff: 0.07s

=== episode:72 Env-steps-taken:75840
 	picked: 104 |actions: {0: 822, 1: 569, 2: 716, 3: 112, 4: 999, 5: 286, 6: 125, 7: 640, 8: 857}

==================================================
eval-episode: 720 -> reward: 138.65624999999994, steps: 5126.0, wall-time: 57.29s
-> berries picked: 104 of 800 | patches-visited: [1, 4] | juice left:-0.00
==================================================


=== episode:721 Env-steps-taken:65952
 	picked: 65 |actions: {0: 504, 1: 677, 2: 772, 3: 423, 4: 545, 5: 513, 6: 315, 7: 532, 8: 646}
episode: 721/2000 -> reward: 90.27604166666663, steps:4927, time-taken: 2.91min, time-elasped: 6416.29min
-> berries picked: 65 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10626 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1429, 858, 919, 1071, 1385, 1624, 1340, 853, 1147]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [29, 18, 8, 8, 19, 14, 18, 8, 10]
	Time taken saving stuff: 0.01s

=== episode:722 Env-steps-taken:60000
 	picked: 42 |actions: {0: 331, 1: 258, 2: 362, 3: 254, 4: 458, 5: 297, 6: 165, 7: 372, 8: 261}
episode: 722/2000 -> reward: 60.59375000000005, steps:2758, time-taken: 1.92min, time-elasped: 6418.22min
-> berries picked: 42 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10639 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1430, 859, 921, 1073, 1392, 1624, 1339, 852, 1149]
	| approx positives in sample 512: 154
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 8, 13, 12, 18, 23, 22, 11, 26]
	Time taken saving stuff: 0.01s

=== episode:723 Env-steps-taken:63744
 	picked: 57 |actions: {0: 428, 1: 409, 2: 467, 3: 368, 4: 507, 5: 401, 6: 242, 7: 359, 8: 436}
episode: 723/2000 -> reward: 79.23437499999999, steps:3617, time-taken: 2.27min, time-elasped: 6420.49min
-> berries picked: 57 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10657 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1431, 861, 923, 1079, 1391, 1626, 1339, 855, 1152]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 13, 11, 9, 13, 21, 19, 10, 24]
	Time taken saving stuff: 0.00s

=== episode:724 Env-steps-taken:76704
 	picked: 106 |actions: {0: 639, 1: 660, 2: 641, 3: 514, 4: 787, 5: 681, 6: 385, 7: 796, 8: 570}
episode: 724/2000 -> reward: 143.04166666666669, steps:5673, time-taken: 3.38min, time-elasped: 6423.88min
-> berries picked: 106 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10688 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1433, 869, 924, 1086, 1396, 1628, 1339, 857, 1156]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 8, 11, 12, 16, 17, 15, 8, 25]
	Time taken saving stuff: 0.00s

=== episode:725 Env-steps-taken:71136
 	picked: 91 |actions: {0: 645, 1: 533, 2: 623, 3: 550, 4: 672, 5: 621, 6: 449, 7: 627, 8: 491}
episode: 725/2000 -> reward: 115.84374999999987, steps:5211, time-taken: 3.01min, time-elasped: 6426.89min
-> berries picked: 91 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10715 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1438, 867, 930, 1093, 1400, 1629, 1342, 857, 1159]
	| approx positives in sample 512: 159
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 11, 15, 15, 20, 19, 16, 14, 29]
	Time taken saving stuff: 0.01s

=== episode:726 Env-steps-taken:75840
 	picked: 94 |actions: {0: 649, 1: 665, 2: 560, 3: 643, 4: 719, 5: 524, 6: 436, 7: 631, 8: 764}
episode: 726/2000 -> reward: 140.61458333333326, steps:5591, time-taken: 3.46min, time-elasped: 6430.35min
-> berries picked: 94 of 800 | patches-visited: [0, 3, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10757 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1443, 869, 931, 1102, 1405, 1633, 1349, 862, 1163]
	| approx positives in sample 512: 155
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [25, 8, 18, 15, 17, 21, 19, 12, 20]
	Time taken saving stuff: 0.00s

=== episode:727 Env-steps-taken:74592
 	picked: 104 |actions: {0: 974, 1: 765, 2: 627, 3: 692, 4: 636, 5: 752, 6: 541, 7: 651, 8: 519}
episode: 727/2000 -> reward: 133.04166666666654, steps:6157, time-taken: 3.69min, time-elasped: 6434.05min
-> berries picked: 104 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10777 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1446, 873, 938, 1104, 1406, 1627, 1353, 863, 1167]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 16, 6, 11, 23, 15, 13, 10, 24]
	Time taken saving stuff: 0.00s

=== episode:728 Env-steps-taken:70080
 	picked: 78 |actions: {0: 496, 1: 500, 2: 670, 3: 470, 4: 431, 5: 449, 6: 318, 7: 425, 8: 638}
episode: 728/2000 -> reward: 110.6458333333332, steps:4397, time-taken: 2.95min, time-elasped: 6437.00min
-> berries picked: 78 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10788 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1448, 876, 942, 1113, 1401, 1627, 1352, 861, 1168]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 14, 16, 15, 17, 16, 13, 13, 18]
	Time taken saving stuff: 0.01s

=== episode:729 Env-steps-taken:72192
 	picked: 88 |actions: {0: 673, 1: 566, 2: 520, 3: 563, 4: 572, 5: 484, 6: 361, 7: 666, 8: 662}
episode: 729/2000 -> reward: 121.51562499999983, steps:5067, time-taken: 3.20min, time-elasped: 6440.21min
-> berries picked: 88 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10799 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1446, 882, 946, 1110, 1402, 1629, 1348, 866, 1170]
	| approx positives in sample 512: 158
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 10, 10, 25, 21, 18, 22, 7, 30]
	Time taken saving stuff: 0.01s

=== episode:730 Env-steps-taken:81216
 	picked: 122 |actions: {0: 792, 1: 705, 2: 734, 3: 577, 4: 673, 5: 744, 6: 504, 7: 880, 8: 689}
episode: 730/2000 -> reward: 165.06770833333346, steps:6298, time-taken: 3.82min, time-elasped: 6444.03min
-> berries picked: 122 of 800 | patches-visited: [0, 6, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10803 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1445, 888, 942, 1116, 1406, 1626, 1343, 866, 1171]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 12, 12, 20, 20, 20, 16, 9, 14]
	Time taken saving stuff: 0.10s

=== episode:73 Env-steps-taken:87936
 	picked: 153 |actions: {0: 457, 1: 620, 2: 666, 3: 462, 4: 639, 5: 517, 6: 285, 7: 704, 8: 497}

==================================================
eval-episode: 730 -> reward: 199.34895833333368, steps: 4847.0, wall-time: 63.53s
-> berries picked: 153 of 800 | patches-visited: [1, 6, 8] | juice left:-0.00
==================================================


=== episode:731 Env-steps-taken:72288
 	picked: 96 |actions: {0: 707, 1: 756, 2: 440, 3: 511, 4: 537, 5: 659, 6: 322, 7: 723, 8: 431}
episode: 731/2000 -> reward: 121.49999999999984, steps:5086, time-taken: 3.16min, time-elasped: 6448.25min
-> berries picked: 96 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10837 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1450, 899, 943, 1124, 1409, 1627, 1343, 868, 1174]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 12, 12, 16, 25, 20, 15, 10, 17]
	Time taken saving stuff: 0.01s

=== episode:732 Env-steps-taken:71136
 	picked: 86 |actions: {0: 509, 1: 541, 2: 391, 3: 368, 4: 569, 5: 512, 6: 314, 7: 590, 8: 395}
episode: 732/2000 -> reward: 116.07291666666652, steps:4189, time-taken: 2.84min, time-elasped: 6451.10min
-> berries picked: 86 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10853 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1449, 899, 946, 1121, 1415, 1626, 1346, 875, 1176]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 7, 13, 8, 21, 19, 18, 6, 12]
	Time taken saving stuff: 0.01s

=== episode:733 Env-steps-taken:80448
 	picked: 117 |actions: {0: 803, 1: 776, 2: 624, 3: 738, 4: 535, 5: 736, 6: 511, 7: 772, 8: 511}
episode: 733/2000 -> reward: 161.41145833333334, steps:6006, time-taken: 3.69min, time-elasped: 6454.81min
-> berries picked: 117 of 800 | patches-visited: [0, 1, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10899 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1453, 905, 951, 1128, 1423, 1633, 1352, 877, 1177]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 10, 11, 16, 12, 18, 24, 13, 20]
	Time taken saving stuff: 0.00s

=== episode:734 Env-steps-taken:79008
 	picked: 106 |actions: {0: 597, 1: 698, 2: 624, 3: 624, 4: 793, 5: 607, 6: 469, 7: 720, 8: 513}
episode: 734/2000 -> reward: 156.4270833333334, steps:5645, time-taken: 3.87min, time-elasped: 6458.68min
-> berries picked: 106 of 800 | patches-visited: [0, 1, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10929 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1454, 909, 960, 1133, 1431, 1635, 1354, 877, 1176]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 14, 25, 17, 21, 18, 14, 5, 20]
	Time taken saving stuff: 0.01s

=== episode:735 Env-steps-taken:68448
 	picked: 79 |actions: {0: 678, 1: 501, 2: 563, 3: 460, 4: 646, 5: 441, 6: 385, 7: 563, 8: 489}
episode: 735/2000 -> reward: 102.47395833333326, steps:4726, time-taken: 2.88min, time-elasped: 6461.56min
-> berries picked: 79 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10953 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1457, 904, 966, 1137, 1441, 1640, 1354, 878, 1176]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 11, 7, 19, 16, 18, 14, 12, 22]
	Time taken saving stuff: 0.02s

=== episode:736 Env-steps-taken:69696
 	picked: 80 |actions: {0: 565, 1: 666, 2: 437, 3: 423, 4: 778, 5: 611, 6: 485, 7: 630, 8: 574}
episode: 736/2000 -> reward: 108.53124999999989, steps:5169, time-taken: 3.39min, time-elasped: 6464.97min
-> berries picked: 80 of 800 | patches-visited: [0, 6, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10954 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1455, 909, 952, 1133, 1446, 1643, 1354, 879, 1183]
	| approx positives in sample 512: 147
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 16, 8, 22, 7, 13, 24, 18, 18]
	Time taken saving stuff: 0.01s

=== episode:737 Env-steps-taken:70752
 	picked: 87 |actions: {0: 725, 1: 651, 2: 655, 3: 510, 4: 674, 5: 594, 6: 449, 7: 530, 8: 341}
episode: 737/2000 -> reward: 114.01562499999989, steps:5129, time-taken: 2.99min, time-elasped: 6467.96min
-> berries picked: 87 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10977 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1455, 917, 955, 1134, 1448, 1651, 1355, 876, 1186]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 12, 17, 10, 16, 8, 28, 22, 14]
	Time taken saving stuff: 0.01s

=== episode:738 Env-steps-taken:60192
 	picked: 46 |actions: {0: 453, 1: 428, 2: 327, 3: 275, 4: 301, 5: 251, 6: 223, 7: 361, 8: 451}
episode: 738/2000 -> reward: 61.364583333333385, steps:3070, time-taken: 2.21min, time-elasped: 6470.17min
-> berries picked: 46 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10986 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1458, 917, 954, 1136, 1450, 1652, 1356, 876, 1187]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 11, 17, 17, 11, 23, 8, 12, 16]
	Time taken saving stuff: 0.01s

=== episode:739 Env-steps-taken:69024
 	picked: 81 |actions: {0: 667, 1: 727, 2: 456, 3: 384, 4: 455, 5: 501, 6: 551, 7: 701, 8: 659}
episode: 739/2000 -> reward: 105.35937499999986, steps:5101, time-taken: 687.31min, time-elasped: 7157.48min
-> berries picked: 81 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10998 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1455, 921, 951, 1135, 1452, 1655, 1363, 878, 1188]
	| approx positives in sample 512: 145
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 12, 14, 15, 14, 22, 11, 9, 27]
	Time taken saving stuff: 0.01s

=== episode:740 Env-steps-taken:62976
 	picked: 50 |actions: {0: 372, 1: 341, 2: 259, 3: 289, 4: 311, 5: 299, 6: 276, 7: 314, 8: 175}
episode: 740/2000 -> reward: 75.13541666666667, steps:2636, time-taken: 2.50min, time-elasped: 7159.99min
-> berries picked: 50 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 11010 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1458, 923, 953, 1140, 1452, 1655, 1361, 880, 1188]
	| approx positives in sample 512: 171
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 15, 13, 14, 22, 26, 20, 18, 22]
	Time taken saving stuff: 0.07s

=== episode:74 Env-steps-taken:102048
 	picked: 205 |actions: {0: 1088, 1: 790, 2: 547, 3: 735, 4: 834, 5: 837, 6: 452, 7: 478, 8: 754}

==================================================
eval-episode: 740 -> reward: 270.3697916666672, steps: 6515.0, wall-time: 56.28s
-> berries picked: 205 of 800 | patches-visited: [1, 2, 5, 7] | juice left:-0.00
==================================================


=== episode:741 Env-steps-taken:69216
 	picked: 83 |actions: {0: 566, 1: 704, 2: 667, 3: 422, 4: 827, 5: 470, 6: 414, 7: 531, 8: 417}
episode: 741/2000 -> reward: 106.24479166666653, steps:5018, time-taken: 2.34min, time-elasped: 7163.26min
-> berries picked: 83 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10940 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1458, 904, 946, 1131, 1452, 1655, 1343, 870, 1181]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 18, 12, 16, 21, 17, 25, 6, 16]
	Time taken saving stuff: 0.01s

=== episode:742 Env-steps-taken:56640
 	picked: 28 |actions: {0: 115, 1: 123, 2: 165, 3: 153, 4: 155, 5: 231, 6: 137, 7: 184, 8: 148}
episode: 742/2000 -> reward: 43.89583333333336, steps:1411, time-taken: 1.03min, time-elasped: 7164.30min
-> berries picked: 28 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10939 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1458, 901, 947, 1134, 1450, 1652, 1341, 870, 1186]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 15, 15, 19, 19, 18, 18, 14, 12]
	Time taken saving stuff: 0.01s

=== episode:743 Env-steps-taken:68160
 	picked: 71 |actions: {0: 424, 1: 384, 2: 412, 3: 340, 4: 628, 5: 398, 6: 347, 7: 544, 8: 289}
episode: 743/2000 -> reward: 101.43229166666659, steps:3766, time-taken: 2.41min, time-elasped: 7166.71min
-> berries picked: 71 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10925 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1448, 901, 941, 1135, 1450, 1648, 1343, 869, 1190]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 19, 5, 12, 19, 17, 12, 9, 19]
	Time taken saving stuff: 0.01s

=== episode:744 Env-steps-taken:75744
 	picked: 103 |actions: {0: 636, 1: 721, 2: 774, 3: 498, 4: 774, 5: 520, 6: 532, 7: 681, 8: 552}
episode: 744/2000 -> reward: 139.09895833333326, steps:5688, time-taken: 3.80min, time-elasped: 7170.51min
-> berries picked: 103 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10924 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1447, 906, 943, 1130, 1453, 1640, 1339, 873, 1193]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 7, 15, 14, 14, 21, 9, 11, 21]
	Time taken saving stuff: 0.01s

=== episode:745 Env-steps-taken:68832
 	picked: 77 |actions: {0: 871, 1: 699, 2: 682, 3: 414, 4: 670, 5: 609, 6: 468, 7: 710, 8: 616}
episode: 745/2000 -> reward: 104.20312499999993, steps:5739, time-taken: 3.60min, time-elasped: 7174.11min
-> berries picked: 77 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10894 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1437, 889, 941, 1131, 1452, 1641, 1340, 871, 1192]
	| approx positives in sample 512: 155
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 14, 12, 13, 17, 20, 23, 12, 26]
	Time taken saving stuff: 0.01s

=== episode:746 Env-steps-taken:68352
 	picked: 76 |actions: {0: 468, 1: 617, 2: 741, 3: 440, 4: 809, 5: 516, 6: 475, 7: 445, 8: 644}
episode: 746/2000 -> reward: 102.14583333333323, steps:5155, time-taken: 3.58min, time-elasped: 7177.69min
-> berries picked: 76 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10876 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1424, 884, 934, 1130, 1461, 1648, 1337, 868, 1190]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 7, 11, 17, 11, 13, 17, 14, 16]
	Time taken saving stuff: 0.07s

=== episode:747 Env-steps-taken:71328
 	picked: 88 |actions: {0: 573, 1: 638, 2: 552, 3: 423, 4: 642, 5: 550, 6: 527, 7: 699, 8: 579}
episode: 747/2000 -> reward: 116.95833333333316, steps:5183, time-taken: 3.94min, time-elasped: 7181.64min
-> berries picked: 88 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10877 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1420, 880, 931, 1129, 1460, 1650, 1341, 873, 1193]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 12, 9, 12, 18, 12, 16, 12, 20]
	Time taken saving stuff: 0.01s

=== episode:748 Env-steps-taken:76224
 	picked: 109 |actions: {0: 580, 1: 962, 2: 904, 3: 590, 4: 801, 5: 659, 6: 515, 7: 581, 8: 496}
episode: 748/2000 -> reward: 141.25520833333334, steps:6088, time-taken: 4.25min, time-elasped: 7185.89min
-> berries picked: 109 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10879 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1412, 866, 943, 1137, 1464, 1653, 1336, 873, 1195]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 11, 14, 9, 14, 19, 21, 11, 21]
	Time taken saving stuff: 0.01s

=== episode:749 Env-steps-taken:73632
 	picked: 96 |actions: {0: 604, 1: 682, 2: 740, 3: 503, 4: 831, 5: 535, 6: 505, 7: 565, 8: 408}
episode: 749/2000 -> reward: 128.49999999999983, steps:5373, time-taken: 3.85min, time-elasped: 7189.74min
-> berries picked: 96 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10881 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1410, 868, 947, 1133, 1463, 1652, 1337, 877, 1194]
	| approx positives in sample 512: 143
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 8, 11, 16, 23, 17, 16, 9, 22]
	Time taken saving stuff: 0.00s

=== episode:750 Env-steps-taken:72768
 	picked: 85 |actions: {0: 644, 1: 647, 2: 823, 3: 396, 4: 716, 5: 497, 6: 468, 7: 616, 8: 584}
episode: 750/2000 -> reward: 123.68749999999984, steps:5391, time-taken: 3.74min, time-elasped: 7193.49min
-> berries picked: 85 of 800 | patches-visited: [0, 4, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10867 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1401, 867, 945, 1128, 1459, 1654, 1341, 880, 1192]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [20, 13, 13, 13, 14, 18, 15, 16, 15]
	Time taken saving stuff: 0.16s

=== episode:75 Env-steps-taken:80928
 	picked: 120 |actions: {0: 949, 1: 499, 2: 495, 3: 341, 4: 876, 5: 191, 6: 512, 7: 415, 8: 704}

==================================================
eval-episode: 750 -> reward: 165.62500000000006, steps: 4982.0, wall-time: 70.10s
-> berries picked: 120 of 800 | patches-visited: [1, 4, 6] | juice left:-0.00
==================================================


=== episode:751 Env-steps-taken:67776
 	picked: 75 |actions: {0: 329, 1: 604, 2: 590, 3: 382, 4: 516, 5: 453, 6: 498, 7: 653, 8: 516}
episode: 751/2000 -> reward: 99.2031249999999, steps:4541, time-taken: 3.50min, time-elasped: 7198.16min
-> berries picked: 75 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10854 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1398, 871, 946, 1123, 1449, 1653, 1342, 880, 1192]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 13, 9, 17, 21, 18, 21, 12, 13]
	Time taken saving stuff: 0.00s

=== episode:752 Env-steps-taken:71136
 	picked: 82 |actions: {0: 404, 1: 664, 2: 462, 3: 530, 4: 644, 5: 565, 6: 444, 7: 571, 8: 651}
episode: 752/2000 -> reward: 116.30208333333321, steps:4935, time-taken: 3.37min, time-elasped: 7201.54min
-> berries picked: 82 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10842 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1395, 866, 948, 1122, 1452, 1646, 1340, 883, 1190]
	| approx positives in sample 512: 146
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 9, 15, 13, 18, 23, 19, 16, 15]
	Time taken saving stuff: 0.04s

=== episode:753 Env-steps-taken:63648
 	picked: 55 |actions: {0: 449, 1: 379, 2: 358, 3: 298, 4: 396, 5: 338, 6: 300, 7: 490, 8: 398}
episode: 753/2000 -> reward: 78.34895833333334, steps:3406, time-taken: 2.39min, time-elasped: 7203.94min
-> berries picked: 55 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10840 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1394, 863, 950, 1125, 1449, 1649, 1337, 886, 1187]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 12, 12, 12, 19, 19, 16, 16, 19]
	Time taken saving stuff: 0.01s

=== episode:754 Env-steps-taken:75360
 	picked: 94 |actions: {0: 848, 1: 823, 2: 630, 3: 475, 4: 635, 5: 535, 6: 568, 7: 672, 8: 509}
episode: 754/2000 -> reward: 137.61458333333323, steps:5695, time-taken: 3.71min, time-elasped: 7207.65min
-> berries picked: 94 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10829 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1392, 864, 949, 1115, 1439, 1653, 1343, 884, 1190]
	| approx positives in sample 512: 143
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 9, 21, 11, 20, 23, 13, 8, 19]
	Time taken saving stuff: 0.01s

=== episode:755 Env-steps-taken:72192
 	picked: 92 |actions: {0: 575, 1: 660, 2: 620, 3: 482, 4: 583, 5: 604, 6: 516, 7: 793, 8: 481}
episode: 755/2000 -> reward: 121.22916666666647, steps:5314, time-taken: 3.65min, time-elasped: 7211.30min
-> berries picked: 92 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10836 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1390, 865, 941, 1120, 1440, 1655, 1346, 889, 1190]
	| approx positives in sample 512: 145
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 15, 10, 16, 13, 20, 18, 14, 23]
	Time taken saving stuff: 0.00s

=== episode:756 Env-steps-taken:67680
 	picked: 82 |actions: {0: 613, 1: 611, 2: 701, 3: 568, 4: 970, 5: 592, 6: 512, 7: 629, 8: 414}
episode: 756/2000 -> reward: 96.9166666666666, steps:5610, time-taken: 3.48min, time-elasped: 7214.78min
-> berries picked: 82 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10808 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1375, 858, 939, 1119, 1444, 1656, 1343, 887, 1187]
	| approx positives in sample 512: 145
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 9, 18, 18, 17, 19, 14, 12, 21]
	Time taken saving stuff: 0.01s

=== episode:757 Env-steps-taken:78528
 	picked: 113 |actions: {0: 721, 1: 930, 2: 814, 3: 683, 4: 953, 5: 830, 6: 545, 7: 667, 8: 553}
episode: 757/2000 -> reward: 153.02604166666666, steps:6696, time-taken: 4.05min, time-elasped: 7218.83min
-> berries picked: 113 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10807 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1365, 856, 949, 1124, 1444, 1659, 1339, 882, 1189]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 9, 8, 10, 21, 19, 17, 14, 14]
	Time taken saving stuff: 0.09s

=== episode:758 Env-steps-taken:68832
 	picked: 73 |actions: {0: 545, 1: 596, 2: 547, 3: 444, 4: 499, 5: 511, 6: 447, 7: 386, 8: 495}
episode: 758/2000 -> reward: 104.81770833333324, steps:4470, time-taken: 3.15min, time-elasped: 7221.99min
-> berries picked: 73 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10789 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1355, 844, 945, 1126, 1449, 1665, 1336, 882, 1187]
	| approx positives in sample 512: 146
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 8, 11, 17, 15, 23, 20, 16, 21]
	Time taken saving stuff: 0.02s

=== episode:759 Env-steps-taken:79200
 	picked: 109 |actions: {0: 670, 1: 762, 2: 690, 3: 569, 4: 947, 5: 725, 6: 562, 7: 650, 8: 478}
episode: 759/2000 -> reward: 154.42708333333334, steps:6053, time-taken: 3.61min, time-elasped: 7225.60min
-> berries picked: 109 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10790 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1340, 840, 942, 1131, 1462, 1670, 1335, 883, 1187]
	| approx positives in sample 512: 149
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 9, 11, 16, 18, 21, 15, 12, 25]
	Time taken saving stuff: 0.02s

=== episode:760 Env-steps-taken:72960
 	picked: 97 |actions: {0: 696, 1: 798, 2: 600, 3: 470, 4: 648, 5: 660, 6: 447, 7: 640, 8: 368}
episode: 760/2000 -> reward: 124.55729166666647, steps:5327, time-taken: 3.72min, time-elasped: 7229.33min
-> berries picked: 97 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10810 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1343, 835, 945, 1137, 1463, 1677, 1340, 886, 1184]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 9, 15, 15, 17, 23, 16, 5, 23]
	Time taken saving stuff: 0.11s

=== episode:76 Env-steps-taken:112896
 	picked: 238 |actions: {0: 843, 1: 1333, 2: 411, 3: 1045, 4: 684, 5: 642, 6: 974, 7: 605, 8: 468}

==================================================
eval-episode: 760 -> reward: 324.5364583333332, steps: 7005.0, wall-time: 85.73s
-> berries picked: 238 of 800 | patches-visited: [0, 1, 4, 6, 8] | juice left:-0.00
==================================================


=== episode:761 Env-steps-taken:67968
 	picked: 71 |actions: {0: 459, 1: 489, 2: 388, 3: 411, 4: 505, 5: 340, 6: 378, 7: 337, 8: 381}
episode: 761/2000 -> reward: 100.43229166666661, steps:3688, time-taken: 2.77min, time-elasped: 7233.53min
-> berries picked: 71 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 10797 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1337, 836, 936, 1141, 1466, 1675, 1341, 883, 1182]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 14, 13, 15, 17, 23, 16, 11, 20]
	Time taken saving stuff: 0.01s

=== episode:77 Env-steps-taken:67488
 	picked: 72 |actions: {0: 355, 1: 408, 2: 227, 3: 209, 4: 317, 5: 272, 6: 62, 7: 292, 8: 186}
evalEpisode: 0 -> reward: 96.98958333333326 steps: 2328
-> berries picked: 72 of 800 | patches-visited: [1, 5] | juice left:-0.00
