copied Agent.py to .temp\2022-6-19 8-35-57/pyfiles-backup
copied debugging.py to .temp\2022-6-19 8-35-57/pyfiles-backup/agent_utils/debugging
copied debugging_utils.py to .temp\2022-6-19 8-35-57/pyfiles-backup/agent_utils/debugging
copied __init__.py to .temp\2022-6-19 8-35-57/pyfiles-backup/agent_utils/debugging

copied fubar.py to .temp\2022-6-19 8-35-57/pyfiles-backup/agent_utils/exploration_subroutines
copied random_exploration.py to .temp\2022-6-19 8-35-57/pyfiles-backup/agent_utils/exploration_subroutines
copied random_exploration_v1.py to .temp\2022-6-19 8-35-57/pyfiles-backup/agent_utils/exploration_subroutines
copied skipsteps.py to .temp\2022-6-19 8-35-57/pyfiles-backup/agent_utils/exploration_subroutines/utils
copied __init__.py to .temp\2022-6-19 8-35-57/pyfiles-backup/agent_utils/exploration_subroutines/utils

copied __init__.py to .temp\2022-6-19 8-35-57/pyfiles-backup/agent_utils/exploration_subroutines

copied patch_discovery.py to .temp\2022-6-19 8-35-57/pyfiles-backup/agent_utils/intrinsic_rewards
copied __init__.py to .temp\2022-6-19 8-35-57/pyfiles-backup/agent_utils/intrinsic_rewards

copied berry_worth_function.py to .temp\2022-6-19 8-35-57/pyfiles-backup/agent_utils/state_utils
copied sectorized_states.py to .temp\2022-6-19 8-35-57/pyfiles-backup/agent_utils/state_utils
copied __init__.py to .temp\2022-6-19 8-35-57/pyfiles-backup/agent_utils/state_utils

copied __init__.py to .temp\2022-6-19 8-35-57/pyfiles-backup/agent_utils

copied ensemble.py to .temp\2022-6-19 8-35-57/pyfiles-backup
copied eval.py to .temp\2022-6-19 8-35-57/pyfiles-backup
copied train.py to .temp\2022-6-19 8-35-57/pyfiles-backup
copied utils.py to .temp\2022-6-19 8-35-57/pyfiles-backup/utils/copyfiles
copied __init__.py to .temp\2022-6-19 8-35-57/pyfiles-backup/utils/copyfiles

copied random_env.py to .temp\2022-6-19 8-35-57/pyfiles-backup/utils/env_generation
copied __init__.py to .temp\2022-6-19 8-35-57/pyfiles-backup/utils/env_generation

copied make_net.py to .temp\2022-6-19 8-35-57/pyfiles-backup/utils/nn_utils
copied __init__.py to .temp\2022-6-19 8-35-57/pyfiles-backup/utils/nn_utils

copied utils.py to .temp\2022-6-19 8-35-57/pyfiles-backup/utils/printing
copied __init__.py to .temp\2022-6-19 8-35-57/pyfiles-backup/utils/printing

copied env_picture.py to .temp\2022-6-19 8-35-57/pyfiles-backup/utils/visualization
copied graphs.py to .temp\2022-6-19 8-35-57/pyfiles-backup/utils/visualization
copied __init__.py to .temp\2022-6-19 8-35-57/pyfiles-backup/utils/visualization

copied __init__.py to .temp\2022-6-19 8-35-57/pyfiles-backup/utils


random_train_env
getBabyEnv :
	 logDir : .temp\2022-6-19 8-35-57
	 initial_juice : 0.5
	 end_on_boundary_hit : False
	 penalize_boundary_hit : False
	 allow_no_action : False
	 no_action_threshold : 0.7
	 add_exploration : True
	 field_size : (20000, 20000)
	 initial_pos_around_berry : True
	 nberries : 80
	 num_patches : 10
	 patch_size : (2600, 2600)
	 patch_with_agent_at_center : True
	 sampling_type : 0
	 seperation : 2400
	 show : False
	 spawn_radius : 100


Agent :
	 self : <Agent.Agent object at 0x0000026C12843288>
	 berryField : <BerryFieldEnv instance>
	 mode : train
	 angle : 45
	 persistence : 0.8
	 worth_offset : 0.05
	 noise : 0.01
	 nstep_transition : [1]
	 positive_emphasis : 0
	 skipStep : 10
	 reward_patch_discovery : True
	 add_exploration : True
	 time_memory_delta : 0.01
	 time_memory_exp : 1.0
	 render : False
	 debug : False
	 debugDir : .temp
	 device : cuda


total-params:  2034
rewards scaled by 2/(berryField.REWARD_RATE*MAXSIZE)
rewards are clipped between 0 and 2
Exploration subroutine as an action
p_action: 7
Rewarding patch discovery
rewards scaled by 2/(berryField.REWARD_RATE*MAXSIZE)
rewards are clipped between 0 and 2
Exploration subroutine as an action
p_action: 5
Rewarding patch discovery
net(
  (feedforward): ModuleList(
    (0): Linear(in_features=39, out_features=32, bias=True)
    (1): LeakyReLU(negative_slope=0.1)
    (2): Linear(in_features=32, out_features=16, bias=True)
    (3): LeakyReLU(negative_slope=0.1)
  )
  (final_stage): ModuleList(
    (0): Linear(in_features=16, out_features=8, bias=True)
    (1): LeakyReLU(negative_slope=0.1)
  )
  (valueL): Linear(in_features=8, out_features=1, bias=True)
  (actadvs): Linear(in_features=8, out_features=9, bias=True)
)
PrioritizedBuffer of type replace-min
optim = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005
    weight_decay: 0
), num_gradient_steps= 25
optimizing the online-model after every 100 actions
batch size=512, gamma=0.9, alpha=0.95
polyak_tau=0.1, update_freq=5

=== episode:0 Env-steps-taken:48384
 	picked: 1 |actions: {0: 20, 1: 12, 2: 18, 3: 16, 4: 19, 5: 14, 6: 144, 7: 13, 8: 15}
episode: 0/2000 -> reward: 1.9427083333333344, steps:271, time-taken: 0.21min, time-elasped: 0.21min
-> berries picked: 1 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1 | amount-filled: 0.45%
	| action-stats:  [6] [1]
	| approx positives in sample 512: 0
	| approx action-dist in sample 512: [] []
	Time taken saving stuff: 0.04s

=== episode:0 Env-steps-taken:48000
 	picked: 0 |actions: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 4364, 7: 0, 8: 0}

==================================================
eval-episode: 0 -> reward: 0.0, steps: 4364.0, wall-time: 19.71s
-> berries picked: 0 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:1 Env-steps-taken:48000
 	picked: 0 |actions: {0: 29, 1: 23, 2: 26, 3: 20, 4: 26, 5: 34, 6: 216, 7: 16, 8: 20}
episode: 1/2000 -> reward: 0, steps:410, time-taken: 0.35min, time-elasped: 0.90min
-> berries picked: 0 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1 | amount-filled: 1.14%
	| action-stats:  [6] [1]
	| approx positives in sample 512: 5
	| approx action-dist in sample 512: [6] [5]
	Time taken saving stuff: 0.00s

=== episode:2 Env-steps-taken:50496
 	picked: 9 |actions: {0: 156, 1: 228, 2: 155, 3: 146, 4: 537, 5: 133, 6: 761, 7: 211, 8: 399}
episode: 2/2000 -> reward: 13.484375, steps:2726, time-taken: 1.07min, time-elasped: 1.97min
-> berries picked: 9 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 11 | amount-filled: 5.68%
	| action-stats:  [4, 5, 6, 8] [2, 1, 5, 3]
	| approx positives in sample 512: 15
	| approx action-dist in sample 512: [4, 6, 8] [3, 3, 9]
	Time taken saving stuff: 0.00s

=== episode:3 Env-steps-taken:48384
 	picked: 1 |actions: {0: 45, 1: 106, 2: 62, 3: 46, 4: 217, 5: 60, 6: 106, 7: 69, 8: 292}
episode: 3/2000 -> reward: 2.9427083333333344, steps:1003, time-taken: 0.54min, time-elasped: 2.51min
-> berries picked: 1 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 13 | amount-filled: 7.35%
	| action-stats:  [4, 5, 6, 8] [2, 1, 5, 5]
	| approx positives in sample 512: 19
	| approx action-dist in sample 512: [4, 5, 6, 8] [2, 2, 9, 6]
	Time taken saving stuff: 0.00s

=== episode:4 Env-steps-taken:53760
 	picked: 21 |actions: {0: 189, 1: 411, 2: 218, 3: 406, 4: 531, 5: 488, 6: 427, 7: 226, 8: 678}
episode: 4/2000 -> reward: 28.796874999999996, steps:3574, time-taken: 1.25min, time-elasped: 3.76min
-> berries picked: 21 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 34 | amount-filled: 13.31%
	| action-stats:  [1, 2, 3, 4, 5, 6, 8] [4, 2, 2, 8, 4, 8, 6]
	| approx positives in sample 512: 15
	| approx action-dist in sample 512: [1, 3, 4, 5, 6, 8] [1, 1, 6, 1, 5, 1]
	Time taken saving stuff: 0.00s

=== episode:5 Env-steps-taken:55872
 	picked: 26 |actions: {0: 167, 1: 697, 2: 404, 3: 254, 4: 429, 5: 352, 6: 248, 7: 195, 8: 328}
episode: 5/2000 -> reward: 39.51041666666667, steps:3074, time-taken: 1.18min, time-elasped: 4.94min
-> berries picked: 26 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 60 | amount-filled: 18.43%
	| action-stats:  [1, 2, 3, 4, 5, 6, 7, 8] [9, 6, 6, 11, 6, 10, 2, 10]
	| approx positives in sample 512: 32
	| approx action-dist in sample 512: [1, 2, 4, 5, 6, 7, 8] [5, 1, 11, 5, 3, 4, 3]
	Time taken saving stuff: 0.00s

=== episode:6 Env-steps-taken:48864
 	picked: 3 |actions: {0: 19, 1: 210, 2: 61, 3: 38, 4: 23, 5: 56, 6: 24, 7: 16, 8: 48}
episode: 6/2000 -> reward: 4.328125000000001, steps:495, time-taken: 0.47min, time-elasped: 5.41min
-> berries picked: 3 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 63 | amount-filled: 19.25%
	| action-stats:  [1, 2, 3, 4, 5, 6, 7, 8] [11, 6, 6, 11, 6, 10, 3, 10]
	| approx positives in sample 512: 27
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7, 8] [6, 3, 6, 2, 1, 4, 1, 4]
	Time taken saving stuff: 0.00s

=== episode:7 Env-steps-taken:55008
 	picked: 25 |actions: {0: 185, 1: 531, 2: 278, 3: 293, 4: 166, 5: 276, 6: 279, 7: 811, 8: 489}
episode: 7/2000 -> reward: 36.067708333333336, steps:3308, time-taken: 1.34min, time-elasped: 6.76min
-> berries picked: 25 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 89 | amount-filled: 24.77%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [1, 14, 8, 8, 13, 8, 13, 12, 12]
	| approx positives in sample 512: 45
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7, 8] [5, 4, 6, 4, 3, 11, 10, 2]
	Time taken saving stuff: 0.01s

=== episode:8 Env-steps-taken:55872
 	picked: 25 |actions: {0: 119, 1: 526, 2: 368, 3: 171, 4: 191, 5: 220, 6: 131, 7: 539, 8: 114}
episode: 8/2000 -> reward: 40.56770833333335, steps:2379, time-taken: 1.01min, time-elasped: 7.77min
-> berries picked: 25 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 115 | amount-filled: 28.73%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [2, 21, 12, 9, 16, 10, 13, 19, 13]
	| approx positives in sample 512: 40
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [2, 8, 4, 2, 3, 3, 2, 12, 4]
	Time taken saving stuff: 0.00s

=== episode:9 Env-steps-taken:48288
 	picked: 1 |actions: {0: 29, 1: 99, 2: 157, 3: 44, 4: 23, 5: 30, 6: 27, 7: 36, 8: 25}
episode: 9/2000 -> reward: 1.4427083333333326, steps:470, time-taken: 0.38min, time-elasped: 8.15min
-> berries picked: 1 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 116 | amount-filled: 29.52%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [2, 21, 12, 10, 16, 10, 13, 19, 13]
	| approx positives in sample 512: 57
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [1, 10, 6, 8, 4, 7, 4, 13, 4]
	Time taken saving stuff: 0.00s

=== episode:10 Env-steps-taken:53088
 	picked: 16 |actions: {0: 62, 1: 203, 2: 255, 3: 90, 4: 87, 5: 131, 6: 71, 7: 242, 8: 66}
episode: 10/2000 -> reward: 25.583333333333336, steps:1207, time-taken: 0.71min, time-elasped: 8.87min
-> berries picked: 16 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 132 | amount-filled: 31.53%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 24, 13, 13, 17, 11, 14, 24, 13]
	| approx positives in sample 512: 58
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [1, 12, 4, 7, 6, 2, 3, 19, 4]
	Time taken saving stuff: 0.04s

=== episode:1 Env-steps-taken:51840
 	picked: 12 |actions: {0: 9, 1: 2241, 2: 75, 3: 42, 4: 32, 5: 2098, 6: 9, 7: 207, 8: 0}

==================================================
eval-episode: 10 -> reward: 19.312499999999996, steps: 4713.0, wall-time: 33.53s
-> berries picked: 12 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:11 Env-steps-taken:55200
 	picked: 23 |actions: {0: 473, 1: 981, 2: 391, 3: 233, 4: 389, 5: 637, 6: 244, 7: 499, 8: 277}
episode: 11/2000 -> reward: 37.18229166666668, steps:4124, time-taken: 1.62min, time-elasped: 11.05min
-> berries picked: 23 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 156 | amount-filled: 38.40%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 33, 16, 13, 20, 11, 14, 30, 16]
	| approx positives in sample 512: 28
	| approx action-dist in sample 512: [1, 2, 3, 4, 6, 7, 8] [7, 3, 4, 8, 1, 4, 1]
	Time taken saving stuff: 0.01s

=== episode:12 Env-steps-taken:52416
 	picked: 17 |actions: {0: 286, 1: 719, 2: 620, 3: 280, 4: 660, 5: 372, 6: 1087, 7: 469, 8: 273}
episode: 12/2000 -> reward: 22.026041666666668, steps:4766, time-taken: 1.78min, time-elasped: 12.83min
-> berries picked: 17 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 173 | amount-filled: 46.34%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 35, 18, 13, 24, 12, 18, 34, 16]
	| approx positives in sample 512: 42
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [2, 10, 4, 2, 5, 3, 3, 12, 1]
	Time taken saving stuff: 0.00s

=== episode:13 Env-steps-taken:58464
 	picked: 39 |actions: {0: 412, 1: 641, 2: 583, 3: 668, 4: 770, 5: 480, 6: 801, 7: 570, 8: 390}
episode: 13/2000 -> reward: 52.26562500000003, steps:5315, time-taken: 1.91min, time-elasped: 14.74min
-> berries picked: 39 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 212 | amount-filled: 55.20%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 37, 21, 24, 27, 12, 24, 45, 18]
	| approx positives in sample 512: 33
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7, 8] [6, 3, 7, 4, 2, 2, 6, 3]
	Time taken saving stuff: 0.00s

=== episode:14 Env-steps-taken:62592
 	picked: 53 |actions: {0: 337, 1: 558, 2: 448, 3: 350, 4: 656, 5: 348, 6: 568, 7: 550, 8: 562}
episode: 14/2000 -> reward: 73.96354166666669, steps:4377, time-taken: 1.57min, time-elasped: 16.30min
-> berries picked: 53 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 266 | amount-filled: 62.50%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 47, 26, 30, 31, 12, 31, 59, 24]
	| approx positives in sample 512: 36
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [1, 3, 5, 6, 2, 1, 2, 12, 4]
	Time taken saving stuff: 0.00s

=== episode:15 Env-steps-taken:62592
 	picked: 48 |actions: {0: 421, 1: 795, 2: 437, 3: 454, 4: 1083, 5: 340, 6: 549, 7: 601, 8: 601}
episode: 15/2000 -> reward: 74.25000000000003, steps:5281, time-taken: 2.00min, time-elasped: 18.30min
-> berries picked: 48 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 315 | amount-filled: 71.30%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 54, 29, 34, 37, 14, 38, 71, 29]
	| approx positives in sample 512: 35
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7, 8] [6, 5, 1, 5, 2, 3, 11, 2]
	Time taken saving stuff: 0.00s

=== episode:16 Env-steps-taken:59040
 	picked: 35 |actions: {0: 433, 1: 419, 2: 364, 3: 361, 4: 679, 5: 288, 6: 407, 7: 475, 8: 397}
episode: 16/2000 -> reward: 56.49479166666669, steps:3823, time-taken: 1.60min, time-elasped: 19.91min
-> berries picked: 35 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 351 | amount-filled: 77.67%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 55, 30, 38, 41, 19, 44, 80, 32]
	| approx positives in sample 512: 34
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 3, 3, 3, 5, 4, 2, 5, 6]
	Time taken saving stuff: 0.00s

=== episode:17 Env-steps-taken:71424
 	picked: 83 |actions: {0: 940, 1: 624, 2: 590, 3: 417, 4: 748, 5: 438, 6: 827, 7: 711, 8: 703}
episode: 17/2000 -> reward: 118.24479166666654, steps:5998, time-taken: 2.20min, time-elasped: 22.10min
-> berries picked: 83 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 435 | amount-filled: 87.67%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 67, 36, 42, 50, 23, 60, 102, 34]
	| approx positives in sample 512: 51
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 9, 7, 3, 5, 4, 4, 14, 2]
	Time taken saving stuff: 0.00s

=== episode:18 Env-steps-taken:58176
 	picked: 32 |actions: {0: 335, 1: 566, 2: 673, 3: 268, 4: 422, 5: 281, 6: 844, 7: 385, 8: 449}
episode: 18/2000 -> reward: 52.16666666666669, steps:4223, time-taken: 1.61min, time-elasped: 23.72min
-> berries picked: 32 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 468 | amount-filled: 94.71%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [24, 74, 40, 43, 52, 24, 65, 111, 35]
	| approx positives in sample 512: 42
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 6, 3, 3, 4, 3, 6, 10, 3]
	Time taken saving stuff: 0.00s

=== episode:19 Env-steps-taken:60480
 	picked: 45 |actions: {0: 684, 1: 728, 2: 563, 3: 389, 4: 513, 5: 371, 6: 667, 7: 578, 8: 628}
episode: 19/2000 -> reward: 62.42187500000005, steps:5121, time-taken: 1.88min, time-elasped: 25.60min
-> berries picked: 45 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 513 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [30, 81, 47, 43, 55, 24, 73, 125, 35]
	| approx positives in sample 512: 40
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7, 8] [7, 7, 2, 3, 4, 7, 7, 3]
	Time taken saving stuff: 0.00s

=== episode:20 Env-steps-taken:60960
 	picked: 52 |actions: {0: 639, 1: 586, 2: 401, 3: 343, 4: 413, 5: 348, 6: 524, 7: 389, 8: 334}
episode: 20/2000 -> reward: 64.5208333333334, steps:3977, time-taken: 1.75min, time-elasped: 27.36min
-> berries picked: 52 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 562 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [41, 88, 51, 43, 57, 26, 84, 134, 38]
	| approx positives in sample 512: 30
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [2, 6, 1, 1, 3, 3, 5, 6, 3]
	Time taken saving stuff: 0.13s

=== episode:2 Env-steps-taken:61536
 	picked: 52 |actions: {0: 343, 1: 259, 2: 256, 3: 87, 4: 184, 5: 149, 6: 395, 7: 103, 8: 134}

==================================================
eval-episode: 20 -> reward: 67.52083333333336, steps: 1910.0, wall-time: 41.50s
-> berries picked: 52 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:21 Env-steps-taken:60384
 	picked: 41 |actions: {0: 468, 1: 357, 2: 342, 3: 190, 4: 328, 5: 320, 6: 553, 7: 323, 8: 269}
episode: 21/2000 -> reward: 62.15104166666671, steps:3150, time-taken: 1.44min, time-elasped: 29.49min
-> berries picked: 41 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 599 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [48, 90, 54, 44, 60, 29, 91, 144, 39]
	| approx positives in sample 512: 44
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 4, 9, 6, 2, 1, 3, 6, 7]
	Time taken saving stuff: 0.00s

=== episode:22 Env-steps-taken:54432
 	picked: 27 |actions: {0: 433, 1: 239, 2: 272, 3: 175, 4: 218, 5: 215, 6: 479, 7: 278, 8: 340}
episode: 22/2000 -> reward: 31.953124999999996, steps:2649, time-taken: 1.13min, time-elasped: 30.63min
-> berries picked: 27 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 623 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [53, 94, 57, 46, 61, 29, 92, 151, 40]
	| approx positives in sample 512: 59
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 5, 8, 1, 9, 3, 7, 18, 4]
	Time taken saving stuff: 0.00s

=== episode:23 Env-steps-taken:75840
 	picked: 102 |actions: {0: 769, 1: 896, 2: 844, 3: 653, 4: 643, 5: 575, 6: 824, 7: 597, 8: 587}
episode: 23/2000 -> reward: 140.15624999999997, steps:6388, time-taken: 2.26min, time-elasped: 32.89min
-> berries picked: 102 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 717 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [68, 100, 73, 52, 67, 35, 112, 163, 47]
	| approx positives in sample 512: 59
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 10, 6, 5, 2, 3, 11, 12, 2]
	Time taken saving stuff: 0.00s

=== episode:24 Env-steps-taken:57888
 	picked: 32 |actions: {0: 417, 1: 975, 2: 446, 3: 474, 4: 716, 5: 418, 6: 336, 7: 322, 8: 578}
episode: 24/2000 -> reward: 50.66666666666669, steps:4682, time-taken: 1.68min, time-elasped: 34.58min
-> berries picked: 32 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 745 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [70, 102, 81, 56, 66, 38, 118, 166, 48]
	| approx positives in sample 512: 52
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 9, 5, 2, 5, 1, 11, 14, 1]
	Time taken saving stuff: 0.00s

=== episode:25 Env-steps-taken:63840
 	picked: 64 |actions: {0: 690, 1: 541, 2: 628, 3: 455, 4: 587, 5: 883, 6: 665, 7: 427, 8: 641}
episode: 25/2000 -> reward: 78.83333333333333, steps:5517, time-taken: 1.95min, time-elasped: 36.53min
-> berries picked: 64 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 802 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [86, 113, 86, 60, 70, 41, 130, 168, 48]
	| approx positives in sample 512: 47
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 8, 4, 3, 5, 3, 10, 7, 3]
	Time taken saving stuff: 0.00s

=== episode:26 Env-steps-taken:63264
 	picked: 55 |actions: {0: 744, 1: 538, 2: 619, 3: 420, 4: 439, 5: 850, 6: 940, 7: 446, 8: 756}
episode: 26/2000 -> reward: 76.34895833333334, steps:5752, time-taken: 2.08min, time-elasped: 38.61min
-> berries picked: 55 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 850 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [94, 119, 90, 61, 75, 44, 141, 177, 49]
	| approx positives in sample 512: 48
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 6, 7, 1, 6, 2, 7, 10, 3]
	Time taken saving stuff: 0.00s

=== episode:27 Env-steps-taken:67104
 	picked: 69 |actions: {0: 571, 1: 498, 2: 477, 3: 411, 4: 445, 5: 776, 6: 634, 7: 407, 8: 717}
episode: 27/2000 -> reward: 95.66145833333327, steps:4936, time-taken: 1.91min, time-elasped: 40.53min
-> berries picked: 69 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 911 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [100, 126, 95, 64, 78, 53, 154, 188, 53]
	| approx positives in sample 512: 44
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 4, 6, 6, 3, 4, 5, 6, 4]
	Time taken saving stuff: 0.00s

=== episode:28 Env-steps-taken:65472
 	picked: 70 |actions: {0: 735, 1: 616, 2: 779, 3: 459, 4: 554, 5: 855, 6: 762, 7: 511, 8: 681}
episode: 28/2000 -> reward: 86.98958333333327, steps:5952, time-taken: 2.11min, time-elasped: 42.64min
-> berries picked: 70 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 968 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [107, 134, 98, 73, 80, 60, 163, 199, 54]
	| approx positives in sample 512: 67
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 8, 7, 7, 6, 7, 8, 13, 1]
	Time taken saving stuff: 0.00s

=== episode:29 Env-steps-taken:64800
 	picked: 68 |actions: {0: 681, 1: 997, 2: 770, 3: 462, 4: 613, 5: 605, 6: 567, 7: 431, 8: 765}
episode: 29/2000 -> reward: 83.60416666666663, steps:5891, time-taken: 2.09min, time-elasped: 44.73min
-> berries picked: 68 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1028 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [119, 141, 104, 76, 87, 66, 172, 210, 53]
	| approx positives in sample 512: 54
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 8, 5, 8, 7, 2, 7, 10, 3]
	Time taken saving stuff: 0.00s

=== episode:30 Env-steps-taken:64032
 	picked: 62 |actions: {0: 659, 1: 597, 2: 662, 3: 364, 4: 499, 5: 571, 6: 724, 7: 421, 8: 513}
episode: 30/2000 -> reward: 79.94791666666666, steps:5010, time-taken: 1.79min, time-elasped: 46.52min
-> berries picked: 62 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1083 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [126, 146, 112, 81, 90, 69, 186, 219, 54]
	| approx positives in sample 512: 60
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 11, 2, 3, 7, 5, 16, 10, 2]
	Time taken saving stuff: 0.05s

=== episode:3 Env-steps-taken:61440
 	picked: 46 |actions: {0: 2724, 1: 291, 2: 1025, 3: 243, 4: 123, 5: 674, 6: 293, 7: 134, 8: 79}

==================================================
eval-episode: 30 -> reward: 67.36458333333336, steps: 5586.0, wall-time: 31.76s
-> berries picked: 46 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:31 Env-steps-taken:58656
 	picked: 39 |actions: {0: 523, 1: 540, 2: 992, 3: 406, 4: 419, 5: 476, 6: 544, 7: 300, 8: 676}
episode: 31/2000 -> reward: 51.32291666666671, steps:4876, time-taken: 1.81min, time-elasped: 48.87min
-> berries picked: 39 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1107 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [130, 147, 115, 86, 94, 73, 189, 219, 54]
	| approx positives in sample 512: 67
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 14, 9, 7, 6, 3, 6, 12, 6]
	Time taken saving stuff: 0.00s

=== episode:32 Env-steps-taken:50592
 	picked: 10 |actions: {0: 161, 1: 159, 2: 255, 3: 242, 4: 240, 5: 607, 6: 312, 7: 164, 8: 622}
episode: 32/2000 -> reward: 13.927083333333334, steps:2762, time-taken: 1.12min, time-elasped: 49.99min
-> berries picked: 10 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1114 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [130, 149, 116, 87, 95, 74, 191, 216, 56]
	| approx positives in sample 512: 63
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 10, 7, 7, 4, 4, 6, 11, 5]
	Time taken saving stuff: 0.00s

=== episode:33 Env-steps-taken:61248
 	picked: 51 |actions: {0: 385, 1: 448, 2: 595, 3: 334, 4: 539, 5: 535, 6: 830, 7: 426, 8: 809}
episode: 33/2000 -> reward: 67.07812500000004, steps:4901, time-taken: 1.87min, time-elasped: 51.86min
-> berries picked: 51 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1150 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [131, 152, 116, 94, 98, 76, 205, 220, 58]
	| approx positives in sample 512: 68
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 14, 11, 6, 5, 3, 8, 11, 3]
	Time taken saving stuff: 0.00s

=== episode:34 Env-steps-taken:62688
 	picked: 60 |actions: {0: 503, 1: 557, 2: 692, 3: 586, 4: 667, 5: 889, 6: 554, 7: 735, 8: 516}
episode: 34/2000 -> reward: 73.06250000000001, steps:5699, time-taken: 2.03min, time-elasped: 53.89min
-> berries picked: 60 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1201 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [141, 157, 121, 97, 104, 82, 212, 227, 60]
	| approx positives in sample 512: 63
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 5, 9, 8, 6, 3, 8, 10, 7]
	Time taken saving stuff: 0.00s

=== episode:35 Env-steps-taken:72384
 	picked: 82 |actions: {0: 508, 1: 844, 2: 818, 3: 470, 4: 568, 5: 594, 6: 788, 7: 759, 8: 424}
episode: 35/2000 -> reward: 123.3020833333332, steps:5773, time-taken: 2.11min, time-elasped: 56.00min
-> berries picked: 82 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1266 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [148, 166, 125, 103, 110, 88, 228, 236, 62]
	| approx positives in sample 512: 55
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 10, 11, 7, 2, 2, 6, 6, 4]
	Time taken saving stuff: 0.00s

=== episode:36 Env-steps-taken:63840
 	picked: 56 |actions: {0: 440, 1: 758, 2: 813, 3: 547, 4: 955, 5: 488, 6: 498, 7: 630, 8: 498}
episode: 36/2000 -> reward: 79.34895833333331, steps:5627, time-taken: 2.08min, time-elasped: 58.08min
-> berries picked: 56 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1298 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [148, 170, 133, 112, 109, 94, 232, 239, 61]
	| approx positives in sample 512: 56
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 11, 7, 2, 5, 5, 10, 8, 4]
	Time taken saving stuff: 0.00s

=== episode:37 Env-steps-taken:65568
 	picked: 72 |actions: {0: 405, 1: 953, 2: 583, 3: 651, 4: 831, 5: 600, 6: 633, 7: 615, 8: 506}
episode: 37/2000 -> reward: 87.37499999999991, steps:5777, time-taken: 1.99min, time-elasped: 60.07min
-> berries picked: 72 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1349 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [151, 177, 136, 120, 115, 98, 240, 247, 65]
	| approx positives in sample 512: 59
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 6, 7, 9, 4, 3, 9, 10, 5]
	Time taken saving stuff: 0.00s

=== episode:38 Env-steps-taken:64512
 	picked: 59 |actions: {0: 387, 1: 693, 2: 507, 3: 609, 4: 618, 5: 407, 6: 552, 7: 706, 8: 505}
episode: 38/2000 -> reward: 83.61979166666664, steps:4984, time-taken: 1.90min, time-elasped: 61.97min
-> berries picked: 59 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1391 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [153, 182, 139, 123, 122, 101, 247, 258, 66]
	| approx positives in sample 512: 60
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 6, 7, 9, 9, 3, 10, 8, 2]
	Time taken saving stuff: 0.00s

=== episode:39 Env-steps-taken:71616
 	picked: 89 |actions: {0: 489, 1: 882, 2: 437, 3: 559, 4: 837, 5: 678, 6: 577, 7: 875, 8: 526}
episode: 39/2000 -> reward: 118.90104166666653, steps:5860, time-taken: 2.17min, time-elasped: 64.15min
-> berries picked: 89 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1455 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [160, 195, 143, 128, 131, 113, 250, 266, 69]
	| approx positives in sample 512: 66
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 15, 9, 2, 4, 7, 10, 9, 4]
	Time taken saving stuff: 0.00s

=== episode:40 Env-steps-taken:70656
 	picked: 80 |actions: {0: 421, 1: 870, 2: 548, 3: 682, 4: 669, 5: 653, 6: 656, 7: 954, 8: 570}
episode: 40/2000 -> reward: 114.41666666666654, steps:6023, time-taken: 2.24min, time-elasped: 66.39min
-> berries picked: 80 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1513 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [162, 206, 147, 131, 137, 123, 259, 277, 71]
	| approx positives in sample 512: 60
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 6, 3, 12, 5, 7, 9, 11, 2]
	Time taken saving stuff: 0.05s

=== episode:4 Env-steps-taken:83904
 	picked: 133 |actions: {0: 291, 1: 1503, 2: 363, 3: 726, 4: 570, 5: 275, 6: 787, 7: 643, 8: 953}

==================================================
eval-episode: 40 -> reward: 181.3802083333335, steps: 6111.0, wall-time: 42.03s
-> berries picked: 133 of 800 | patches-visited: [1, 3, 9] | juice left:-0.00
==================================================


=== episode:41 Env-steps-taken:71616
 	picked: 90 |actions: {0: 362, 1: 860, 2: 452, 3: 583, 4: 691, 5: 607, 6: 744, 7: 793, 8: 607}
episode: 41/2000 -> reward: 119.84374999999982, steps:5699, time-taken: 2.15min, time-elasped: 69.24min
-> berries picked: 90 of 800 | patches-visited: [0, 2, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1582 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [166, 220, 151, 133, 154, 134, 260, 288, 76]
	| approx positives in sample 512: 73
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 13, 8, 12, 9, 5, 7, 7, 3]
	Time taken saving stuff: 0.00s

=== episode:42 Env-steps-taken:66144
 	picked: 68 |actions: {0: 413, 1: 677, 2: 366, 3: 434, 4: 614, 5: 508, 6: 764, 7: 587, 8: 643}
episode: 42/2000 -> reward: 91.60416666666661, steps:5006, time-taken: 1.87min, time-elasped: 71.11min
-> berries picked: 68 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1627 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [167, 227, 154, 142, 162, 142, 264, 291, 78]
	| approx positives in sample 512: 72
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 14, 7, 9, 7, 6, 12, 8, 3]
	Time taken saving stuff: 0.00s

=== episode:43 Env-steps-taken:72192
 	picked: 82 |actions: {0: 369, 1: 722, 2: 383, 3: 616, 4: 817, 5: 527, 6: 851, 7: 590, 8: 599}
episode: 43/2000 -> reward: 122.3020833333332, steps:5474, time-taken: 2.04min, time-elasped: 73.16min
-> berries picked: 82 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1690 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [164, 240, 156, 150, 167, 153, 275, 300, 85]
	| approx positives in sample 512: 80
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 13, 10, 8, 5, 15, 8, 11, 5]
	Time taken saving stuff: 0.00s

=== episode:44 Env-steps-taken:74784
 	picked: 96 |actions: {0: 447, 1: 789, 2: 394, 3: 734, 4: 749, 5: 690, 6: 775, 7: 864, 8: 621}
episode: 44/2000 -> reward: 134.99999999999991, steps:6063, time-taken: 2.20min, time-elasped: 75.36min
-> berries picked: 96 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1767 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [168, 245, 160, 164, 177, 168, 285, 312, 88]
	| approx positives in sample 512: 89
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 14, 12, 8, 9, 14, 12, 8, 7]
	Time taken saving stuff: 0.00s

=== episode:45 Env-steps-taken:74016
 	picked: 89 |actions: {0: 535, 1: 906, 2: 406, 3: 584, 4: 618, 5: 738, 6: 626, 7: 807, 8: 525}
episode: 45/2000 -> reward: 129.51562499999986, steps:5745, time-taken: 2.17min, time-elasped: 77.53min
-> berries picked: 89 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1838 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [173, 261, 161, 174, 183, 182, 290, 325, 89]
	| approx positives in sample 512: 96
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 16, 13, 12, 8, 7, 13, 12, 7]
	Time taken saving stuff: 0.00s

=== episode:46 Env-steps-taken:59136
 	picked: 41 |actions: {0: 283, 1: 431, 2: 263, 3: 325, 4: 288, 5: 276, 6: 343, 7: 496, 8: 593}
episode: 46/2000 -> reward: 56.65104166666669, steps:3298, time-taken: 1.37min, time-elasped: 78.90min
-> berries picked: 41 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1867 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [173, 267, 163, 184, 183, 182, 291, 333, 91]
	| approx positives in sample 512: 92
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 8, 13, 11, 18, 5, 10, 15, 5]
	Time taken saving stuff: 0.00s

=== episode:47 Env-steps-taken:52512
 	picked: 15 |actions: {0: 82, 1: 76, 2: 82, 3: 131, 4: 156, 5: 110, 6: 61, 7: 94, 8: 172}
episode: 47/2000 -> reward: 23.640625000000004, steps:964, time-taken: 0.63min, time-elasped: 79.53min
-> berries picked: 15 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1873 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [174, 267, 163, 188, 184, 183, 290, 332, 92]
	| approx positives in sample 512: 68
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 12, 8, 10, 6, 6, 6, 7, 5]
	Time taken saving stuff: 0.00s

=== episode:48 Env-steps-taken:66144
 	picked: 66 |actions: {0: 415, 1: 580, 2: 332, 3: 515, 4: 553, 5: 522, 6: 611, 7: 646, 8: 849}
episode: 48/2000 -> reward: 91.71874999999993, steps:5023, time-taken: 1.77min, time-elasped: 81.31min
-> berries picked: 66 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1916 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [178, 276, 167, 195, 190, 196, 295, 325, 94]
	| approx positives in sample 512: 89
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 13, 5, 13, 9, 11, 13, 14, 6]
	Time taken saving stuff: 0.00s

=== episode:49 Env-steps-taken:68736
 	picked: 81 |actions: {0: 435, 1: 545, 2: 447, 3: 539, 4: 636, 5: 625, 6: 898, 7: 708, 8: 579}
episode: 49/2000 -> reward: 103.91666666666654, steps:5412, time-taken: 2.06min, time-elasped: 83.37min
-> berries picked: 81 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1972 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [180, 283, 172, 205, 195, 207, 301, 332, 97]
	| approx positives in sample 512: 81
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 7, 12, 16, 11, 7, 9, 9, 4]
	Time taken saving stuff: 0.00s

=== episode:50 Env-steps-taken:77760
 	picked: 112 |actions: {0: 548, 1: 893, 2: 458, 3: 747, 4: 610, 5: 721, 6: 710, 7: 873, 8: 494}
episode: 50/2000 -> reward: 150.58333333333334, steps:6054, time-taken: 2.26min, time-elasped: 85.62min
-> berries picked: 112 of 800 | patches-visited: [0, 4, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2061 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [185, 302, 175, 220, 203, 218, 309, 347, 102]
	| approx positives in sample 512: 85
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 11, 7, 6, 11, 12, 10, 14, 7]
	Time taken saving stuff: 0.05s

=== episode:5 Env-steps-taken:79296
 	picked: 124 |actions: {0: 775, 1: 608, 2: 552, 3: 657, 4: 430, 5: 861, 6: 467, 7: 571, 8: 767}

==================================================
eval-episode: 50 -> reward: 157.95312500000003, steps: 5688.0, wall-time: 37.77s
-> berries picked: 124 of 800 | patches-visited: [1, 4, 7] | juice left:-0.00
==================================================


=== episode:51 Env-steps-taken:72864
 	picked: 86 |actions: {0: 854, 1: 960, 2: 468, 3: 558, 4: 520, 5: 675, 6: 539, 7: 681, 8: 775}
episode: 51/2000 -> reward: 125.57291666666654, steps:6030, time-taken: 2.18min, time-elasped: 88.44min
-> berries picked: 86 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2123 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [188, 320, 182, 226, 210, 226, 313, 353, 105]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 15, 10, 18, 8, 10, 11, 12, 3]
	Time taken saving stuff: 0.00s

=== episode:52 Env-steps-taken:69888
 	picked: 80 |actions: {0: 640, 1: 740, 2: 440, 3: 536, 4: 618, 5: 697, 6: 758, 7: 547, 8: 586}
episode: 52/2000 -> reward: 110.41666666666653, steps:5562, time-taken: 2.11min, time-elasped: 90.55min
-> berries picked: 80 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2173 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [186, 329, 187, 229, 213, 236, 326, 359, 108]
	| approx positives in sample 512: 91
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 17, 6, 7, 9, 13, 7, 15, 7]
	Time taken saving stuff: 0.00s

=== episode:53 Env-steps-taken:63744
 	picked: 60 |actions: {0: 549, 1: 524, 2: 371, 3: 476, 4: 496, 5: 384, 6: 589, 7: 567, 8: 523}
episode: 53/2000 -> reward: 77.17708333333331, steps:4479, time-taken: 1.69min, time-elasped: 92.24min
-> berries picked: 60 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2211 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [191, 334, 188, 235, 215, 235, 327, 373, 113]
	| approx positives in sample 512: 89
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 21, 6, 17, 12, 2, 8, 9, 8]
	Time taken saving stuff: 0.00s

=== episode:54 Env-steps-taken:63552
 	picked: 51 |actions: {0: 405, 1: 380, 2: 262, 3: 278, 4: 354, 5: 334, 6: 430, 7: 361, 8: 296}
episode: 54/2000 -> reward: 77.13541666666666, steps:3100, time-taken: 1.29min, time-elasped: 93.53min
-> berries picked: 51 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2242 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [195, 336, 189, 245, 215, 240, 333, 373, 116]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 13, 7, 15, 9, 14, 12, 11, 6]
	Time taken saving stuff: 0.00s

=== episode:55 Env-steps-taken:75744
 	picked: 97 |actions: {0: 714, 1: 762, 2: 569, 3: 753, 4: 676, 5: 786, 6: 753, 7: 591, 8: 453}
episode: 55/2000 -> reward: 139.9427083333333, steps:6057, time-taken: 2.16min, time-elasped: 95.69min
-> berries picked: 97 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2307 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [207, 350, 198, 259, 219, 252, 336, 368, 118]
	| approx positives in sample 512: 93
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [2, 19, 14, 14, 15, 5, 10, 8, 6]
	Time taken saving stuff: 0.00s

=== episode:56 Env-steps-taken:60768
 	picked: 53 |actions: {0: 524, 1: 856, 2: 459, 3: 595, 4: 818, 5: 947, 6: 466, 7: 435, 8: 425}
episode: 56/2000 -> reward: 63.46354166666673, steps:5525, time-taken: 1.92min, time-elasped: 97.62min
-> berries picked: 53 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2322 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [207, 359, 203, 259, 225, 256, 335, 360, 118]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 15, 14, 20, 11, 4, 13, 10, 8]
	Time taken saving stuff: 0.00s

=== episode:57 Env-steps-taken:64320
 	picked: 66 |actions: {0: 560, 1: 615, 2: 492, 3: 598, 4: 880, 5: 947, 6: 643, 7: 613, 8: 500}
episode: 57/2000 -> reward: 81.21874999999996, steps:5848, time-taken: 2.01min, time-elasped: 99.63min
-> berries picked: 66 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2352 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [206, 358, 208, 269, 237, 266, 335, 356, 117]
	| approx positives in sample 512: 100
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 16, 16, 14, 10, 9, 8, 13, 5]
	Time taken saving stuff: 0.00s

=== episode:58 Env-steps-taken:69792
 	picked: 87 |actions: {0: 602, 1: 681, 2: 590, 3: 593, 4: 622, 5: 791, 6: 733, 7: 807, 8: 580}
episode: 58/2000 -> reward: 107.18749999999993, steps:5999, time-taken: 2.03min, time-elasped: 101.66min
-> berries picked: 87 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2400 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [207, 366, 213, 277, 245, 280, 339, 355, 118]
	| approx positives in sample 512: 93
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 14, 14, 16, 7, 12, 11, 6, 8]
	Time taken saving stuff: 0.00s

=== episode:59 Env-steps-taken:61536
 	picked: 48 |actions: {0: 281, 1: 359, 2: 437, 3: 373, 4: 370, 5: 432, 6: 302, 7: 372, 8: 350}
episode: 59/2000 -> reward: 66.80729166666669, steps:3276, time-taken: 1.23min, time-elasped: 102.89min
-> berries picked: 48 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2429 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [208, 369, 216, 290, 249, 284, 340, 355, 118]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 14, 16, 12, 13, 12, 9, 9, 9]
	Time taken saving stuff: 0.00s

=== episode:60 Env-steps-taken:66432
 	picked: 69 |actions: {0: 486, 1: 597, 2: 549, 3: 470, 4: 469, 5: 460, 6: 430, 7: 688, 8: 422}
episode: 60/2000 -> reward: 92.04687499999993, steps:4571, time-taken: 1.54min, time-elasped: 104.43min
-> berries picked: 69 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2467 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [214, 374, 230, 296, 251, 288, 342, 355, 117]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 13, 14, 15, 9, 7, 9, 14, 9]
	Time taken saving stuff: 0.05s

=== episode:6 Env-steps-taken:54720
 	picked: 23 |actions: {0: 911, 1: 47, 2: 17, 3: 14, 4: 112, 5: 47, 6: 300, 7: 3452, 8: 75}

==================================================
eval-episode: 60 -> reward: 34.68229166666666, steps: 4975.0, wall-time: 18.40s
-> berries picked: 23 of 800 | patches-visited: [1, 2] | juice left:-0.00
==================================================


=== episode:61 Env-steps-taken:69600
 	picked: 83 |actions: {0: 554, 1: 718, 2: 652, 3: 525, 4: 589, 5: 566, 6: 665, 7: 591, 8: 539}
episode: 61/2000 -> reward: 108.74479166666654, steps:5399, time-taken: 1.93min, time-elasped: 106.67min
-> berries picked: 83 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2497 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [217, 370, 240, 299, 263, 295, 341, 351, 121]
	| approx positives in sample 512: 95
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 13, 7, 20, 6, 11, 11, 14, 5]
	Time taken saving stuff: 0.00s

=== episode:62 Env-steps-taken:66528
 	picked: 66 |actions: {0: 526, 1: 473, 2: 416, 3: 500, 4: 549, 5: 679, 6: 503, 7: 484, 8: 523}
episode: 62/2000 -> reward: 93.71874999999993, steps:4653, time-taken: 1.67min, time-elasped: 108.35min
-> berries picked: 66 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2530 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [216, 374, 244, 308, 267, 303, 350, 346, 122]
	| approx positives in sample 512: 82
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 11, 10, 11, 5, 10, 14, 8, 6]
	Time taken saving stuff: 0.00s

=== episode:63 Env-steps-taken:55008
 	picked: 25 |actions: {0: 165, 1: 156, 2: 219, 3: 219, 4: 272, 5: 199, 6: 199, 7: 311, 8: 172}
episode: 63/2000 -> reward: 35.067708333333336, steps:1912, time-taken: 0.76min, time-elasped: 109.11min
-> berries picked: 25 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2548 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [216, 374, 247, 314, 271, 306, 352, 346, 122]
	| approx positives in sample 512: 86
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 12, 12, 15, 8, 11, 12, 5, 4]
	Time taken saving stuff: 0.00s

=== episode:64 Env-steps-taken:66048
 	picked: 64 |actions: {0: 455, 1: 428, 2: 310, 3: 455, 4: 629, 5: 550, 6: 493, 7: 602, 8: 255}
episode: 64/2000 -> reward: 91.39062499999993, steps:4177, time-taken: 1.53min, time-elasped: 110.65min
-> berries picked: 64 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2564 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [214, 370, 251, 323, 271, 315, 353, 343, 124]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 15, 11, 19, 11, 11, 10, 8, 4]
	Time taken saving stuff: 0.00s

=== episode:65 Env-steps-taken:66720
 	picked: 73 |actions: {0: 536, 1: 581, 2: 625, 3: 553, 4: 599, 5: 665, 6: 606, 7: 702, 8: 420}
episode: 65/2000 -> reward: 94.31770833333324, steps:5287, time-taken: 1.86min, time-elasped: 112.51min
-> berries picked: 73 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2605 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [216, 371, 257, 337, 274, 322, 354, 345, 129]
	| approx positives in sample 512: 93
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 12, 19, 15, 4, 12, 7, 6, 12]
	Time taken saving stuff: 0.00s

=== episode:66 Env-steps-taken:77568
 	picked: 111 |actions: {0: 750, 1: 565, 2: 510, 3: 691, 4: 827, 5: 781, 6: 629, 7: 640, 8: 531}
episode: 66/2000 -> reward: 148.64062500000003, steps:5924, time-taken: 2.05min, time-elasped: 114.56min
-> berries picked: 111 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2657 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [222, 375, 261, 353, 289, 328, 356, 342, 131]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 14, 11, 16, 12, 18, 10, 6, 10]
	Time taken saving stuff: 0.00s

=== episode:67 Env-steps-taken:69888
 	picked: 80 |actions: {0: 596, 1: 661, 2: 432, 3: 541, 4: 644, 5: 767, 6: 483, 7: 616, 8: 347}
episode: 67/2000 -> reward: 110.41666666666654, steps:5087, time-taken: 1.84min, time-elasped: 116.40min
-> berries picked: 80 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2692 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [231, 372, 266, 360, 295, 332, 362, 343, 131]
	| approx positives in sample 512: 82
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 12, 7, 14, 12, 9, 9, 8, 8]
	Time taken saving stuff: 0.00s

=== episode:68 Env-steps-taken:69504
 	picked: 84 |actions: {0: 598, 1: 508, 2: 557, 3: 675, 4: 688, 5: 841, 6: 723, 7: 592, 8: 448}
episode: 68/2000 -> reward: 108.1874999999999, steps:5630, time-taken: 2.00min, time-elasped: 118.41min
-> berries picked: 84 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2733 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [231, 370, 267, 369, 303, 349, 365, 346, 133]
	| approx positives in sample 512: 88
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 10, 16, 9, 14, 11, 10, 4, 9]
	Time taken saving stuff: 0.00s

=== episode:69 Env-steps-taken:59712
 	picked: 40 |actions: {0: 336, 1: 366, 2: 283, 3: 430, 4: 414, 5: 438, 6: 422, 7: 458, 8: 325}
episode: 69/2000 -> reward: 58.82291666666671, steps:3472, time-taken: 1.35min, time-elasped: 119.76min
-> berries picked: 40 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2746 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [231, 367, 265, 373, 309, 349, 368, 348, 136]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 19, 9, 18, 10, 17, 4, 8, 10]
	Time taken saving stuff: 0.00s

=== episode:70 Env-steps-taken:70944
 	picked: 89 |actions: {0: 773, 1: 563, 2: 563, 3: 643, 4: 614, 5: 786, 6: 646, 7: 542, 8: 383}
episode: 70/2000 -> reward: 115.40104166666652, steps:5513, time-taken: 1.92min, time-elasped: 121.68min
-> berries picked: 89 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2777 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [233, 366, 269, 387, 311, 352, 375, 346, 138]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 16, 12, 14, 19, 12, 14, 6, 5]
	Time taken saving stuff: 0.05s

=== episode:7 Env-steps-taken:82464
 	picked: 134 |actions: {0: 639, 1: 767, 2: 372, 3: 354, 4: 628, 5: 415, 6: 1262, 7: 429, 8: 458}

==================================================
eval-episode: 70 -> reward: 173.82291666666686, steps: 5324.0, wall-time: 36.28s
-> berries picked: 134 of 800 | patches-visited: [1, 2, 9] | juice left:-0.00
==================================================


=== episode:71 Env-steps-taken:71232
 	picked: 92 |actions: {0: 553, 1: 541, 2: 540, 3: 510, 4: 529, 5: 579, 6: 584, 7: 530, 8: 378}
episode: 71/2000 -> reward: 117.7291666666665, steps:4744, time-taken: 1.78min, time-elasped: 124.06min
-> berries picked: 92 of 800 | patches-visited: [0, 4, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2821 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [239, 366, 278, 397, 319, 361, 368, 349, 144]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 12, 11, 17, 11, 13, 14, 13, 14]
	Time taken saving stuff: 0.00s

=== episode:72 Env-steps-taken:78624
 	picked: 108 |actions: {0: 804, 1: 706, 2: 691, 3: 640, 4: 621, 5: 808, 6: 907, 7: 903, 8: 658}
episode: 72/2000 -> reward: 154.31250000000003, steps:6738, time-taken: 2.50min, time-elasped: 126.57min
-> berries picked: 108 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2869 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [250, 364, 288, 399, 327, 365, 371, 358, 147]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 17, 7, 19, 11, 4, 10, 12, 12]
	Time taken saving stuff: 0.00s

=== episode:73 Env-steps-taken:63840
 	picked: 63 |actions: {0: 639, 1: 351, 2: 364, 3: 460, 4: 389, 5: 345, 6: 508, 7: 454, 8: 371}
episode: 73/2000 -> reward: 77.5052083333333, steps:3881, time-taken: 1.55min, time-elasped: 128.12min
-> berries picked: 63 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2892 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [253, 364, 294, 412, 329, 366, 369, 356, 149]
	| approx positives in sample 512: 100
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 14, 17, 13, 14, 6, 7, 12, 10]
	Time taken saving stuff: 0.01s

=== episode:74 Env-steps-taken:62208
 	picked: 58 |actions: {0: 250, 1: 321, 2: 331, 3: 294, 4: 536, 5: 527, 6: 448, 7: 483, 8: 267}
episode: 74/2000 -> reward: 70.67708333333336, steps:3457, time-taken: 1.49min, time-elasped: 129.61min
-> berries picked: 58 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2909 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [255, 364, 297, 416, 338, 365, 368, 357, 149]
	| approx positives in sample 512: 96
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 12, 11, 13, 9, 13, 9, 10, 10]
	Time taken saving stuff: 0.01s

=== episode:75 Env-steps-taken:73536
 	picked: 98 |actions: {0: 590, 1: 439, 2: 639, 3: 536, 4: 624, 5: 755, 6: 779, 7: 796, 8: 378}
episode: 75/2000 -> reward: 128.38541666666646, steps:5536, time-taken: 2.10min, time-elasped: 131.71min
-> berries picked: 98 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2953 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [263, 365, 307, 423, 340, 372, 370, 359, 154]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 15, 8, 10, 11, 7, 13, 13, 11]
	Time taken saving stuff: 0.02s

=== episode:76 Env-steps-taken:65568
 	picked: 63 |actions: {0: 352, 1: 380, 2: 443, 3: 520, 4: 457, 5: 619, 6: 716, 7: 542, 8: 410}
episode: 76/2000 -> reward: 87.89062499999996, steps:4439, time-taken: 1.90min, time-elasped: 133.62min
-> berries picked: 63 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2973 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [260, 368, 313, 422, 347, 378, 369, 361, 155]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 15, 12, 18, 14, 7, 9, 7, 11]
	Time taken saving stuff: 0.00s

=== episode:77 Env-steps-taken:72480
 	picked: 90 |actions: {0: 516, 1: 409, 2: 531, 3: 505, 4: 570, 5: 678, 6: 602, 7: 513, 8: 352}
episode: 77/2000 -> reward: 123.34374999999983, steps:4676, time-taken: 1.67min, time-elasped: 135.30min
-> berries picked: 90 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3016 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [265, 373, 320, 424, 358, 391, 375, 353, 157]
	| approx positives in sample 512: 96
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 7, 8, 15, 14, 8, 11, 13, 9]
	Time taken saving stuff: 0.00s

=== episode:78 Env-steps-taken:74112
 	picked: 94 |actions: {0: 748, 1: 672, 2: 571, 3: 588, 4: 645, 5: 849, 6: 930, 7: 723, 8: 495}
episode: 78/2000 -> reward: 131.6145833333332, steps:6221, time-taken: 2.09min, time-elasped: 137.39min
-> berries picked: 94 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3044 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [260, 375, 318, 432, 367, 404, 376, 354, 158]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 9, 8, 17, 16, 9, 14, 17, 14]
	Time taken saving stuff: 0.00s

=== episode:79 Env-steps-taken:64704
 	picked: 67 |actions: {0: 471, 1: 526, 2: 475, 3: 411, 4: 388, 5: 456, 6: 495, 7: 597, 8: 347}
episode: 79/2000 -> reward: 83.16145833333329, steps:4166, time-taken: 1.55min, time-elasped: 138.94min
-> berries picked: 67 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3060 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [268, 374, 319, 433, 366, 406, 376, 356, 162]
	| approx positives in sample 512: 94
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 13, 10, 13, 8, 8, 8, 16, 7]
	Time taken saving stuff: 0.00s

=== episode:80 Env-steps-taken:55392
 	picked: 28 |actions: {0: 172, 1: 121, 2: 202, 3: 235, 4: 191, 5: 187, 6: 121, 7: 267, 8: 258}
episode: 80/2000 -> reward: 36.89583333333334, steps:1754, time-taken: 0.82min, time-elasped: 139.77min
-> berries picked: 28 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3065 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [268, 374, 320, 435, 369, 404, 374, 358, 163]
	| approx positives in sample 512: 80
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 11, 6, 9, 5, 11, 12, 10, 8]
	Time taken saving stuff: 0.05s

=== episode:8 Env-steps-taken:72576
 	picked: 94 |actions: {0: 236, 1: 1241, 2: 488, 3: 232, 4: 225, 5: 1361, 6: 317, 7: 646, 8: 369}

==================================================
eval-episode: 80 -> reward: 123.61458333333314, steps: 5115.0, wall-time: 32.60s
-> berries picked: 94 of 800 | patches-visited: [1, 5] | juice left:-0.00
==================================================


=== episode:81 Env-steps-taken:75552
 	picked: 95 |actions: {0: 700, 1: 698, 2: 663, 3: 658, 4: 678, 5: 752, 6: 546, 7: 562, 8: 554}
episode: 81/2000 -> reward: 139.0572916666666, steps:5811, time-taken: 2.06min, time-elasped: 142.37min
-> berries picked: 95 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3106 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [276, 382, 331, 438, 375, 410, 370, 360, 164]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 13, 5, 8, 12, 19, 11, 9, 15]
	Time taken saving stuff: 0.00s

=== episode:82 Env-steps-taken:66432
 	picked: 77 |actions: {0: 537, 1: 421, 2: 404, 3: 484, 4: 415, 5: 448, 6: 442, 7: 560, 8: 402}
episode: 82/2000 -> reward: 90.64583333333329, steps:4113, time-taken: 1.52min, time-elasped: 143.89min
-> berries picked: 77 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3131 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [282, 384, 330, 447, 377, 409, 374, 362, 166]
	| approx positives in sample 512: 82
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 7, 8, 11, 13, 9, 9, 12, 7]
	Time taken saving stuff: 0.00s

=== episode:83 Env-steps-taken:64224
 	picked: 59 |actions: {0: 284, 1: 353, 2: 359, 3: 293, 4: 291, 5: 346, 6: 294, 7: 411, 8: 268}
episode: 83/2000 -> reward: 80.734375, steps:2899, time-taken: 1.10min, time-elasped: 144.99min
-> berries picked: 59 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3143 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [284, 385, 332, 448, 377, 416, 370, 364, 167]
	| approx positives in sample 512: 83
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 10, 4, 17, 6, 11, 11, 10, 6]
	Time taken saving stuff: 0.00s

=== episode:84 Env-steps-taken:74304
 	picked: 90 |actions: {0: 613, 1: 698, 2: 505, 3: 678, 4: 609, 5: 780, 6: 699, 7: 790, 8: 747}
episode: 84/2000 -> reward: 130.5156249999999, steps:6119, time-taken: 2.06min, time-elasped: 147.05min
-> berries picked: 90 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3148 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [285, 385, 338, 447, 374, 416, 364, 368, 171]
	| approx positives in sample 512: 92
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 13, 10, 16, 9, 14, 8, 9, 5]
	Time taken saving stuff: 0.00s

=== episode:85 Env-steps-taken:67392
 	picked: 75 |actions: {0: 529, 1: 480, 2: 531, 3: 595, 4: 519, 5: 735, 6: 812, 7: 878, 8: 579}
episode: 85/2000 -> reward: 96.7031249999999, steps:5658, time-taken: 1.98min, time-elasped: 149.03min
-> berries picked: 75 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3153 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [281, 382, 338, 444, 378, 417, 367, 376, 170]
	| approx positives in sample 512: 100
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 15, 13, 12, 14, 13, 10, 9, 9]
	Time taken saving stuff: 0.00s

=== episode:86 Env-steps-taken:74112
 	picked: 96 |actions: {0: 524, 1: 554, 2: 628, 3: 546, 4: 552, 5: 715, 6: 615, 7: 856, 8: 496}
episode: 86/2000 -> reward: 131.11458333333323, steps:5486, time-taken: 2.01min, time-elasped: 151.05min
-> berries picked: 96 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3182 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [285, 383, 343, 449, 377, 424, 365, 386, 170]
	| approx positives in sample 512: 89
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 9, 8, 12, 7, 11, 12, 12, 7]
	Time taken saving stuff: 0.00s

=== episode:87 Env-steps-taken:66144
 	picked: 63 |actions: {0: 390, 1: 403, 2: 405, 3: 384, 4: 362, 5: 582, 6: 452, 7: 581, 8: 399}
episode: 87/2000 -> reward: 89.94791666666661, steps:3958, time-taken: 1.50min, time-elasped: 152.55min
-> berries picked: 63 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3190 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [285, 384, 344, 448, 377, 418, 371, 392, 171]
	| approx positives in sample 512: 82
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 10, 8, 9, 6, 9, 7, 18, 10]
	Time taken saving stuff: 0.00s

=== episode:88 Env-steps-taken:68352
 	picked: 82 |actions: {0: 451, 1: 594, 2: 591, 3: 578, 4: 551, 5: 687, 6: 525, 7: 541, 8: 552}
episode: 88/2000 -> reward: 102.30208333333321, steps:5070, time-taken: 1.81min, time-elasped: 154.36min
-> berries picked: 82 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3204 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [287, 393, 349, 452, 379, 414, 362, 393, 175]
	| approx positives in sample 512: 84
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 7, 5, 16, 9, 11, 9, 10, 11]
	Time taken saving stuff: 0.00s

=== episode:89 Env-steps-taken:69792
 	picked: 78 |actions: {0: 484, 1: 512, 2: 397, 3: 425, 4: 331, 5: 473, 6: 537, 7: 567, 8: 429}
episode: 89/2000 -> reward: 111.03124999999987, steps:4155, time-taken: 1.60min, time-elasped: 155.96min
-> berries picked: 78 of 800 | patches-visited: [0, 3, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3231 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [293, 399, 344, 454, 379, 422, 371, 393, 176]
	| approx positives in sample 512: 101
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 16, 8, 11, 14, 10, 11, 14, 14]
	Time taken saving stuff: 0.00s

=== episode:90 Env-steps-taken:67392
 	picked: 72 |actions: {0: 417, 1: 442, 2: 395, 3: 561, 4: 465, 5: 633, 6: 489, 7: 454, 8: 490}
episode: 90/2000 -> reward: 97.87499999999994, steps:4346, time-taken: 1.62min, time-elasped: 157.58min
-> berries picked: 72 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3251 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [292, 390, 347, 462, 384, 430, 369, 399, 178]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 9, 6, 16, 16, 9, 9, 19, 13]
	Time taken saving stuff: 0.05s

=== episode:9 Env-steps-taken:76032
 	picked: 108 |actions: {0: 491, 1: 419, 2: 571, 3: 364, 4: 218, 5: 1167, 6: 573, 7: 188, 8: 910}

==================================================
eval-episode: 90 -> reward: 140.81249999999991, steps: 4901.0, wall-time: 43.75s
-> berries picked: 108 of 800 | patches-visited: [1, 6] | juice left:-0.00
==================================================


=== episode:91 Env-steps-taken:73728
 	picked: 98 |actions: {0: 568, 1: 588, 2: 578, 3: 676, 4: 547, 5: 656, 6: 667, 7: 630, 8: 648}
episode: 91/2000 -> reward: 130.38541666666652, steps:5558, time-taken: 2.27min, time-elasped: 160.59min
-> berries picked: 98 of 800 | patches-visited: [0, 5, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3248 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [302, 383, 340, 457, 389, 422, 367, 406, 182]
	| approx positives in sample 512: 91
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 11, 10, 9, 13, 12, 10, 12, 10]
	Time taken saving stuff: 0.00s

=== episode:92 Env-steps-taken:67680
 	picked: 74 |actions: {0: 570, 1: 626, 2: 522, 3: 441, 4: 517, 5: 569, 6: 491, 7: 482, 8: 296}
episode: 92/2000 -> reward: 99.26041666666657, steps:4514, time-taken: 1.79min, time-elasped: 162.38min
-> berries picked: 74 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3249 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [294, 388, 339, 455, 388, 424, 368, 408, 185]
	| approx positives in sample 512: 88
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 6, 4, 16, 11, 15, 16, 8, 6]
	Time taken saving stuff: 0.00s

=== episode:93 Env-steps-taken:64512
 	picked: 56 |actions: {0: 409, 1: 370, 2: 329, 3: 397, 4: 348, 5: 514, 6: 418, 7: 374, 8: 445}
episode: 93/2000 -> reward: 83.79166666666664, steps:3604, time-taken: 1.51min, time-elasped: 163.89min
-> berries picked: 56 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3263 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [302, 392, 338, 452, 385, 425, 369, 413, 187]
	| approx positives in sample 512: 96
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 14, 11, 11, 11, 9, 9, 9, 8]
	Time taken saving stuff: 0.00s

=== episode:94 Env-steps-taken:54912
 	picked: 25 |actions: {0: 160, 1: 135, 2: 196, 3: 149, 4: 134, 5: 165, 6: 166, 7: 154, 8: 126}
episode: 94/2000 -> reward: 33.68229166666667, steps:1385, time-taken: 0.71min, time-elasped: 164.60min
-> berries picked: 25 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3261 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [300, 390, 340, 454, 384, 427, 368, 411, 187]
	| approx positives in sample 512: 89
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 9, 6, 11, 12, 8, 14, 11, 4]
	Time taken saving stuff: 0.01s

=== episode:95 Env-steps-taken:80832
 	picked: 115 |actions: {0: 610, 1: 902, 2: 694, 3: 769, 4: 666, 5: 768, 6: 542, 7: 772, 8: 572}
episode: 95/2000 -> reward: 164.96875000000009, steps:6295, time-taken: 2.38min, time-elasped: 166.98min
-> berries picked: 115 of 800 | patches-visited: [0, 1, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3271 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [301, 393, 346, 457, 385, 427, 361, 411, 190]
	| approx positives in sample 512: 83
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 6, 7, 13, 9, 9, 9, 13, 5]
	Time taken saving stuff: 0.00s

=== episode:96 Env-steps-taken:68928
 	picked: 78 |actions: {0: 482, 1: 630, 2: 570, 3: 459, 4: 430, 5: 480, 6: 608, 7: 613, 8: 601}
episode: 96/2000 -> reward: 104.64583333333323, steps:4873, time-taken: 1.76min, time-elasped: 168.75min
-> berries picked: 78 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3257 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [298, 392, 341, 456, 379, 432, 356, 415, 188]
	| approx positives in sample 512: 87
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 13, 5, 16, 4, 8, 10, 11, 8]
	Time taken saving stuff: 0.00s

=== episode:97 Env-steps-taken:69600
 	picked: 78 |actions: {0: 518, 1: 626, 2: 465, 3: 580, 4: 502, 5: 553, 6: 597, 7: 577, 8: 692}
episode: 97/2000 -> reward: 109.6458333333332, steps:5110, time-taken: 2.02min, time-elasped: 170.77min
-> berries picked: 78 of 800 | patches-visited: [0, 6, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3256 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [305, 397, 334, 442, 379, 437, 355, 417, 190]
	| approx positives in sample 512: 96
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 9, 6, 15, 13, 13, 11, 11, 9]
	Time taken saving stuff: 0.00s

=== episode:98 Env-steps-taken:65376
 	picked: 68 |actions: {0: 364, 1: 445, 2: 501, 3: 413, 4: 461, 5: 452, 6: 549, 7: 541, 8: 316}
episode: 98/2000 -> reward: 87.60416666666664, steps:4042, time-taken: 1.58min, time-elasped: 172.34min
-> berries picked: 68 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3263 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [303, 396, 331, 436, 376, 438, 360, 431, 192]
	| approx positives in sample 512: 86
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 10, 8, 13, 14, 7, 9, 6, 12]
	Time taken saving stuff: 0.00s

=== episode:99 Env-steps-taken:76512
 	picked: 105 |actions: {0: 538, 1: 867, 2: 738, 3: 772, 4: 625, 5: 678, 6: 550, 7: 699, 8: 571}
episode: 99/2000 -> reward: 143.0989583333333, steps:6038, time-taken: 2.14min, time-elasped: 174.49min
-> berries picked: 105 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3271 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [302, 398, 337, 441, 367, 435, 366, 434, 191]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 15, 5, 14, 12, 16, 17, 13, 9]
	Time taken saving stuff: 0.00s

=== episode:100 Env-steps-taken:60960
 	picked: 53 |actions: {0: 321, 1: 367, 2: 358, 3: 286, 4: 364, 5: 342, 6: 375, 7: 557, 8: 470}
episode: 100/2000 -> reward: 64.46354166666671, steps:3440, time-taken: 1.48min, time-elasped: 175.98min
-> berries picked: 53 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3281 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [299, 398, 337, 438, 370, 434, 370, 444, 191]
	| approx positives in sample 512: 93
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 12, 9, 10, 10, 14, 6, 17, 7]
	Time taken saving stuff: 0.05s

=== episode:10 Env-steps-taken:76128
 	picked: 107 |actions: {0: 335, 1: 685, 2: 765, 3: 260, 4: 424, 5: 385, 6: 315, 7: 494, 8: 1118}

==================================================
eval-episode: 100 -> reward: 142.36979166666666, steps: 4781.0, wall-time: 45.04s
-> berries picked: 107 of 800 | patches-visited: [0, 1, 2] | juice left:-0.00
==================================================


=== episode:101 Env-steps-taken:72192
 	picked: 81 |actions: {0: 550, 1: 545, 2: 685, 3: 392, 4: 402, 5: 373, 6: 412, 7: 559, 8: 675}
episode: 101/2000 -> reward: 123.35937499999987, steps:4593, time-taken: 2.58min, time-elasped: 179.31min
-> berries picked: 81 of 800 | patches-visited: [0, 1, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3288 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [298, 405, 335, 432, 373, 437, 372, 444, 192]
	| approx positives in sample 512: 93
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 11, 8, 9, 12, 9, 13, 14, 6]
	Time taken saving stuff: 0.00s

=== episode:102 Env-steps-taken:57120
 	picked: 36 |actions: {0: 382, 1: 584, 2: 734, 3: 384, 4: 442, 5: 346, 6: 522, 7: 705, 8: 631}
episode: 102/2000 -> reward: 45.43750000000001, steps:4730, time-taken: 2.15min, time-elasped: 181.46min
-> berries picked: 36 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3255 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [297, 401, 329, 429, 361, 434, 368, 444, 192]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 16, 9, 12, 13, 9, 12, 18, 15]
	Time taken saving stuff: 0.00s

=== episode:103 Env-steps-taken:78528
 	picked: 107 |actions: {0: 664, 1: 719, 2: 724, 3: 685, 4: 663, 5: 486, 6: 657, 7: 696, 8: 738}
episode: 103/2000 -> reward: 154.9270833333334, steps:6032, time-taken: 2.75min, time-elasped: 184.22min
-> berries picked: 107 of 800 | patches-visited: [0, 5, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3282 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [305, 404, 322, 436, 361, 434, 372, 450, 198]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 16, 7, 14, 9, 12, 9, 15, 12]
	Time taken saving stuff: 0.00s

=== episode:104 Env-steps-taken:66336
 	picked: 63 |actions: {0: 388, 1: 499, 2: 527, 3: 389, 4: 435, 5: 310, 6: 362, 7: 454, 8: 428}
episode: 104/2000 -> reward: 92.89062499999996, steps:3792, time-taken: 1.82min, time-elasped: 186.05min
-> berries picked: 63 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3301 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [308, 410, 323, 438, 361, 435, 375, 452, 199]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 15, 11, 7, 9, 13, 9, 14, 16]
	Time taken saving stuff: 0.00s

=== episode:105 Env-steps-taken:71424
 	picked: 90 |actions: {0: 547, 1: 516, 2: 508, 3: 594, 4: 520, 5: 650, 6: 563, 7: 506, 8: 568}
episode: 105/2000 -> reward: 117.84374999999989, steps:4972, time-taken: 2.51min, time-elasped: 188.56min
-> berries picked: 90 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3318 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [306, 413, 321, 438, 368, 440, 378, 455, 199]
	| approx positives in sample 512: 94
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 10, 3, 15, 10, 5, 10, 11, 17]
	Time taken saving stuff: 0.00s

=== episode:106 Env-steps-taken:65472
 	picked: 61 |actions: {0: 338, 1: 443, 2: 381, 3: 364, 4: 395, 5: 399, 6: 306, 7: 320, 8: 481}
episode: 106/2000 -> reward: 88.5052083333333, steps:3427, time-taken: 1.70min, time-elasped: 190.26min
-> berries picked: 61 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3331 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [305, 420, 321, 440, 368, 442, 381, 454, 200]
	| approx positives in sample 512: 94
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 12, 6, 8, 13, 9, 6, 13, 19]
	Time taken saving stuff: 0.01s

=== episode:107 Env-steps-taken:63552
 	picked: 59 |actions: {0: 408, 1: 450, 2: 361, 3: 343, 4: 473, 5: 394, 6: 503, 7: 376, 8: 560}
episode: 107/2000 -> reward: 78.61979166666666, steps:3868, time-taken: 1.66min, time-elasped: 191.93min
-> berries picked: 59 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3340 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [306, 424, 312, 437, 371, 442, 387, 456, 205]
	| approx positives in sample 512: 76
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 13, 5, 8, 8, 15, 4, 9, 9]
	Time taken saving stuff: 0.00s

=== episode:108 Env-steps-taken:54912
 	picked: 24 |actions: {0: 279, 1: 239, 2: 213, 3: 172, 4: 330, 5: 263, 6: 477, 7: 254, 8: 324}
episode: 108/2000 -> reward: 34.62500000000001, steps:2551, time-taken: 1.32min, time-elasped: 193.25min
-> berries picked: 24 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3329 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [307, 422, 309, 436, 368, 440, 387, 455, 205]
	| approx positives in sample 512: 87
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 12, 7, 12, 9, 12, 12, 11, 8]
	Time taken saving stuff: 0.00s

=== episode:109 Env-steps-taken:61056
 	picked: 50 |actions: {0: 371, 1: 377, 2: 496, 3: 344, 4: 480, 5: 280, 6: 428, 7: 400, 8: 731}
episode: 109/2000 -> reward: 67.13541666666671, steps:3907, time-taken: 1.96min, time-elasped: 195.21min
-> berries picked: 50 of 800 | patches-visited: [0, 5, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3337 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [308, 422, 301, 443, 374, 439, 388, 453, 209]
	| approx positives in sample 512: 86
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 10, 10, 11, 7, 11, 12, 6, 10]
	Time taken saving stuff: 0.00s

=== episode:110 Env-steps-taken:63072
 	picked: 50 |actions: {0: 239, 1: 334, 2: 287, 3: 267, 4: 277, 5: 276, 6: 328, 7: 249, 8: 518}
episode: 110/2000 -> reward: 78.63541666666667, steps:2775, time-taken: 1.38min, time-elasped: 196.59min
-> berries picked: 50 of 800 | patches-visited: [0, 1, 2, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3349 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [311, 424, 298, 442, 376, 438, 392, 457, 211]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 8, 12, 10, 12, 9, 10, 19, 11]
	Time taken saving stuff: 0.05s

=== episode:11 Env-steps-taken:55776
 	picked: 27 |actions: {0: 108, 1: 132, 2: 104, 3: 47, 4: 43, 5: 45, 6: 109, 7: 69, 8: 151}

==================================================
eval-episode: 110 -> reward: 38.953125, steps: 808.0, wall-time: 38.40s
-> berries picked: 27 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:111 Env-steps-taken:55392
 	picked: 26 |actions: {0: 153, 1: 234, 2: 315, 3: 133, 4: 193, 5: 183, 6: 219, 7: 181, 8: 170}
episode: 111/2000 -> reward: 37.01041666666668, steps:1781, time-taken: 1.08min, time-elasped: 198.32min
-> berries picked: 26 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3334 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [310, 419, 298, 438, 374, 437, 389, 457, 212]
	| approx positives in sample 512: 79
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 8, 4, 10, 5, 7, 11, 8, 15]
	Time taken saving stuff: 0.01s

=== episode:112 Env-steps-taken:63744
 	picked: 55 |actions: {0: 399, 1: 416, 2: 348, 3: 337, 4: 291, 5: 249, 6: 275, 7: 264, 8: 363}
episode: 112/2000 -> reward: 79.84895833333333, steps:2942, time-taken: 1.51min, time-elasped: 199.83min
-> berries picked: 55 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3330 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [312, 412, 294, 440, 376, 442, 387, 454, 213]
	| approx positives in sample 512: 89
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 10, 8, 13, 10, 16, 7, 8, 12]
	Time taken saving stuff: 0.01s

=== episode:113 Env-steps-taken:50784
 	picked: 10 |actions: {0: 59, 1: 49, 2: 71, 3: 50, 4: 71, 5: 45, 6: 113, 7: 44, 8: 88}
episode: 113/2000 -> reward: 13.927083333333332, steps:590, time-taken: 0.64min, time-elasped: 200.47min
-> berries picked: 10 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3330 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [313, 412, 296, 439, 376, 442, 387, 453, 212]
	| approx positives in sample 512: 87
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 6, 9, 16, 13, 7, 10, 8, 12]
	Time taken saving stuff: 0.01s

=== episode:114 Env-steps-taken:56832
 	picked: 29 |actions: {0: 225, 1: 297, 2: 275, 3: 274, 4: 237, 5: 234, 6: 197, 7: 301, 8: 340}
episode: 114/2000 -> reward: 44.338541666666686, steps:2380, time-taken: 1.61min, time-elasped: 202.08min
-> berries picked: 29 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3324 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [314, 412, 296, 436, 374, 442, 388, 449, 213]
	| approx positives in sample 512: 96
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 8, 14, 9, 12, 10, 12, 11, 10]
	Time taken saving stuff: 0.01s

=== episode:115 Env-steps-taken:68064
 	picked: 69 |actions: {0: 571, 1: 549, 2: 601, 3: 542, 4: 602, 5: 513, 6: 539, 7: 576, 8: 686}
episode: 115/2000 -> reward: 99.60416666666657, steps:5179, time-taken: 2.41min, time-elasped: 204.50min
-> berries picked: 69 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3294 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [309, 398, 291, 434, 370, 437, 395, 444, 216]
	| approx positives in sample 512: 93
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 8, 6, 12, 13, 10, 12, 8, 12]
	Time taken saving stuff: 0.00s

=== episode:116 Env-steps-taken:60192
 	picked: 45 |actions: {0: 361, 1: 407, 2: 526, 3: 383, 4: 377, 5: 413, 6: 321, 7: 406, 8: 772}
episode: 116/2000 -> reward: 61.92187500000004, steps:3966, time-taken: 2.53min, time-elasped: 207.03min
-> berries picked: 45 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3298 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [314, 401, 290, 430, 368, 439, 395, 444, 217]
	| approx positives in sample 512: 91
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 15, 4, 11, 14, 6, 12, 13, 7]
	Time taken saving stuff: 0.01s

=== episode:117 Env-steps-taken:64224
 	picked: 53 |actions: {0: 352, 1: 411, 2: 422, 3: 279, 4: 233, 5: 266, 6: 412, 7: 292, 8: 304}
episode: 117/2000 -> reward: 81.52083333333331, steps:2971, time-taken: 2.39min, time-elasped: 209.43min
-> berries picked: 53 of 800 | patches-visited: [0, 1, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3313 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [314, 409, 287, 428, 369, 441, 405, 440, 220]
	| approx positives in sample 512: 90
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 16, 3, 9, 12, 11, 12, 10, 13]
	Time taken saving stuff: 0.00s

=== episode:118 Env-steps-taken:59040
 	picked: 43 |actions: {0: 255, 1: 478, 2: 343, 3: 329, 4: 309, 5: 319, 6: 327, 7: 283, 8: 360}
episode: 118/2000 -> reward: 55.036458333333385, steps:3003, time-taken: 1.47min, time-elasped: 210.90min
-> berries picked: 43 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3325 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [317, 408, 292, 431, 365, 444, 409, 439, 220]
	| approx positives in sample 512: 94
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 11, 10, 15, 5, 13, 13, 7, 12]
	Time taken saving stuff: 0.01s

=== episode:119 Env-steps-taken:67776
 	picked: 74 |actions: {0: 490, 1: 538, 2: 878, 3: 587, 4: 634, 5: 598, 6: 450, 7: 529, 8: 736}
episode: 119/2000 -> reward: 99.76041666666661, steps:5440, time-taken: 2.66min, time-elasped: 213.56min
-> berries picked: 74 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3331 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [313, 411, 289, 432, 366, 450, 406, 440, 224]
	| approx positives in sample 512: 99
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 14, 5, 15, 9, 15, 10, 18, 7]
	Time taken saving stuff: 0.01s

=== episode:120 Env-steps-taken:61056
 	picked: 48 |actions: {0: 354, 1: 361, 2: 404, 3: 263, 4: 318, 5: 403, 6: 310, 7: 288, 8: 372}
episode: 120/2000 -> reward: 65.25000000000004, steps:3073, time-taken: 1.45min, time-elasped: 215.02min
-> berries picked: 48 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3346 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [316, 419, 288, 431, 366, 453, 409, 439, 225]
	| approx positives in sample 512: 96
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 17, 6, 11, 9, 9, 10, 14, 10]
	Time taken saving stuff: 0.09s

=== episode:12 Env-steps-taken:69216
 	picked: 79 |actions: {0: 605, 1: 202, 2: 718, 3: 169, 4: 534, 5: 272, 6: 526, 7: 301, 8: 1126}

==================================================
eval-episode: 120 -> reward: 107.97395833333321, steps: 4453.0, wall-time: 39.91s
-> berries picked: 79 of 800 | patches-visited: [1, 3, 9] | juice left:-0.00
==================================================


=== episode:121 Env-steps-taken:61824
 	picked: 50 |actions: {0: 360, 1: 399, 2: 322, 3: 443, 4: 470, 5: 371, 6: 371, 7: 534, 8: 358}
episode: 121/2000 -> reward: 69.13541666666669, steps:3628, time-taken: 1.61min, time-elasped: 217.30min
-> berries picked: 50 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3352 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [320, 419, 286, 433, 365, 453, 407, 445, 224]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 10, 5, 7, 13, 17, 15, 18, 12]
	Time taken saving stuff: 0.00s

=== episode:122 Env-steps-taken:52128
 	picked: 13 |actions: {0: 107, 1: 147, 2: 75, 3: 113, 4: 100, 5: 133, 6: 162, 7: 193, 8: 252}
episode: 122/2000 -> reward: 22.755208333333336, steps:1282, time-taken: 0.74min, time-elasped: 218.04min
-> berries picked: 13 of 800 | patches-visited: [0, 3, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3345 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [323, 417, 282, 427, 365, 455, 404, 445, 227]
	| approx positives in sample 512: 82
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 14, 6, 8, 7, 11, 7, 10, 11]
	Time taken saving stuff: 0.14s

=== episode:123 Env-steps-taken:61728
 	picked: 43 |actions: {0: 310, 1: 522, 2: 358, 3: 302, 4: 292, 5: 191, 6: 257, 7: 435, 8: 483}
episode: 123/2000 -> reward: 70.03645833333337, steps:3150, time-taken: 1.59min, time-elasped: 219.64min
-> berries picked: 43 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3364 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [327, 417, 284, 429, 368, 453, 409, 449, 228]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 10, 7, 17, 9, 13, 10, 19, 14]
	Time taken saving stuff: 0.01s

=== episode:124 Env-steps-taken:63840
 	picked: 59 |actions: {0: 471, 1: 517, 2: 577, 3: 518, 4: 552, 5: 318, 6: 566, 7: 528, 8: 613}
episode: 124/2000 -> reward: 76.23437499999999, steps:4660, time-taken: 2.00min, time-elasped: 221.64min
-> berries picked: 59 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3381 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [332, 418, 282, 436, 369, 452, 408, 455, 229]
	| approx positives in sample 512: 81
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 10, 3, 14, 6, 13, 10, 12, 6]
	Time taken saving stuff: 0.09s

=== episode:125 Env-steps-taken:64224
 	picked: 62 |actions: {0: 441, 1: 438, 2: 416, 3: 423, 4: 430, 5: 507, 6: 352, 7: 451, 8: 624}
episode: 125/2000 -> reward: 81.94791666666666, steps:4082, time-taken: 1.74min, time-elasped: 223.38min
-> berries picked: 62 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3399 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [331, 418, 285, 435, 372, 459, 411, 460, 228]
	| approx positives in sample 512: 91
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 12, 6, 6, 15, 14, 10, 10, 12]
	Time taken saving stuff: 0.00s

=== episode:126 Env-steps-taken:50304
 	picked: 7 |actions: {0: 91, 1: 78, 2: 27, 3: 37, 4: 25, 5: 27, 6: 57, 7: 92, 8: 59}
episode: 126/2000 -> reward: 11.598958333333334, steps:493, time-taken: 0.53min, time-elasped: 223.92min
-> berries picked: 7 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3398 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [334, 418, 282, 435, 372, 456, 411, 463, 227]
	| approx positives in sample 512: 88
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 10, 8, 5, 11, 10, 13, 11, 5]
	Time taken saving stuff: 0.11s

=== episode:127 Env-steps-taken:51264
 	picked: 10 |actions: {0: 32, 1: 148, 2: 91, 3: 105, 4: 66, 5: 55, 6: 60, 7: 63, 8: 151}
episode: 127/2000 -> reward: 16.427083333333336, steps:771, time-taken: 0.59min, time-elasped: 224.51min
-> berries picked: 10 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3400 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [333, 419, 284, 436, 372, 455, 412, 462, 227]
	| approx positives in sample 512: 95
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 10, 13, 15, 9, 10, 8, 6, 12]
	Time taken saving stuff: 0.00s

=== episode:128 Env-steps-taken:49920
 	picked: 6 |actions: {0: 53, 1: 123, 2: 38, 3: 33, 4: 27, 5: 32, 6: 39, 7: 43, 8: 196}
episode: 128/2000 -> reward: 9.656250000000002, steps:584, time-taken: 0.66min, time-elasped: 225.17min
-> berries picked: 6 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3401 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [333, 422, 285, 434, 372, 454, 412, 462, 227]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 15, 8, 9, 6, 15, 16, 18, 13]
	Time taken saving stuff: 0.11s

=== episode:129 Env-steps-taken:68160
 	picked: 72 |actions: {0: 459, 1: 590, 2: 524, 3: 500, 4: 554, 5: 484, 6: 548, 7: 484, 8: 663}
episode: 129/2000 -> reward: 100.48958333333324, steps:4806, time-taken: 2.30min, time-elasped: 227.48min
-> berries picked: 72 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3414 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [339, 422, 286, 438, 375, 458, 408, 460, 228]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 11, 12, 16, 12, 16, 8, 13, 19]
	Time taken saving stuff: 0.01s

=== episode:130 Env-steps-taken:57600
 	picked: 36 |actions: {0: 526, 1: 446, 2: 257, 3: 265, 4: 292, 5: 276, 6: 251, 7: 398, 8: 617}
episode: 130/2000 -> reward: 47.93750000000003, steps:3328, time-taken: 1.89min, time-elasped: 229.37min
-> berries picked: 36 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3413 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [339, 423, 285, 438, 376, 459, 406, 461, 226]
	| approx positives in sample 512: 87
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 8, 10, 11, 7, 9, 13, 13, 9]
	Time taken saving stuff: 0.07s

=== episode:13 Env-steps-taken:55680
 	picked: 28 |actions: {0: 143, 1: 182, 2: 239, 3: 50, 4: 20, 5: 13, 6: 11, 7: 79, 8: 241}

==================================================
eval-episode: 130 -> reward: 39.39583333333334, steps: 978.0, wall-time: 39.84s
-> berries picked: 28 of 800 | patches-visited: [1, 4] | juice left:-0.00
==================================================


=== episode:131 Env-steps-taken:61152
 	picked: 50 |actions: {0: 405, 1: 575, 2: 1000, 3: 637, 4: 500, 5: 515, 6: 701, 7: 491, 8: 736}
episode: 131/2000 -> reward: 65.63541666666671, steps:5560, time-taken: 2.45min, time-elasped: 232.49min
-> berries picked: 50 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3396 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [334, 418, 278, 441, 376, 465, 403, 457, 224]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 15, 11, 11, 13, 14, 11, 12, 11]
	Time taken saving stuff: 0.01s

=== episode:132 Env-steps-taken:53760
 	picked: 19 |actions: {0: 123, 1: 162, 2: 167, 3: 125, 4: 182, 5: 129, 6: 109, 7: 204, 8: 203}
episode: 132/2000 -> reward: 28.911458333333332, steps:1404, time-taken: 0.80min, time-elasped: 233.30min
-> berries picked: 19 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3397 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [334, 419, 280, 438, 379, 465, 406, 455, 221]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 7, 7, 11, 12, 20, 13, 17, 15]
	Time taken saving stuff: 0.02s

=== episode:133 Env-steps-taken:65280
 	picked: 69 |actions: {0: 443, 1: 557, 2: 548, 3: 461, 4: 567, 5: 411, 6: 521, 7: 584, 8: 648}
episode: 133/2000 -> reward: 88.04687499999999, steps:4740, time-taken: 2.47min, time-elasped: 235.77min
-> berries picked: 69 of 800 | patches-visited: [0, 1, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3407 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [336, 424, 284, 438, 382, 466, 407, 446, 224]
	| approx positives in sample 512: 99
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 12, 12, 10, 10, 11, 8, 11, 17]
	Time taken saving stuff: 0.01s

=== episode:134 Env-steps-taken:71136
 	picked: 76 |actions: {0: 428, 1: 512, 2: 564, 3: 490, 4: 534, 5: 493, 6: 549, 7: 413, 8: 607}
episode: 134/2000 -> reward: 117.14583333333323, steps:4590, time-taken: 2.12min, time-elasped: 237.90min
-> berries picked: 76 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3418 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [330, 420, 281, 444, 382, 477, 407, 451, 226]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 10, 7, 13, 9, 17, 12, 8, 14]
	Time taken saving stuff: 0.02s

=== episode:135 Env-steps-taken:54336
 	picked: 22 |actions: {0: 202, 1: 121, 2: 122, 3: 125, 4: 120, 5: 142, 6: 148, 7: 185, 8: 192}
episode: 135/2000 -> reward: 32.73958333333333, steps:1357, time-taken: 0.98min, time-elasped: 238.88min
-> berries picked: 22 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3430 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [334, 420, 282, 441, 380, 482, 410, 453, 228]
	| approx positives in sample 512: 93
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 12, 8, 11, 9, 13, 12, 10, 11]
	Time taken saving stuff: 0.01s

=== episode:136 Env-steps-taken:63936
 	picked: 54 |actions: {0: 325, 1: 399, 2: 387, 3: 391, 4: 276, 5: 367, 6: 338, 7: 397, 8: 457}
episode: 136/2000 -> reward: 80.90624999999999, steps:3337, time-taken: 1.58min, time-elasped: 240.46min
-> berries picked: 54 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3434 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [334, 421, 279, 435, 385, 483, 411, 458, 228]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 13, 8, 15, 11, 15, 15, 21, 16]
	Time taken saving stuff: 0.06s

=== episode:137 Env-steps-taken:59520
 	picked: 46 |actions: {0: 358, 1: 597, 2: 716, 3: 545, 4: 517, 5: 406, 6: 414, 7: 531, 8: 669}
episode: 137/2000 -> reward: 57.36458333333337, steps:4753, time-taken: 2.09min, time-elasped: 242.55min
-> berries picked: 46 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3399 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [327, 416, 275, 428, 387, 479, 408, 451, 228]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 9, 4, 13, 6, 10, 15, 20, 14]
	Time taken saving stuff: 0.01s

=== episode:138 Env-steps-taken:73440
 	picked: 89 |actions: {0: 679, 1: 665, 2: 713, 3: 632, 4: 579, 5: 447, 6: 553, 7: 567, 8: 752}
episode: 138/2000 -> reward: 128.40104166666654, steps:5587, time-taken: 3.09min, time-elasped: 245.64min
-> berries picked: 89 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3425 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [337, 414, 275, 427, 394, 490, 408, 449, 231]
	| approx positives in sample 512: 74
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 11, 10, 9, 9, 8, 9, 7, 5]
	Time taken saving stuff: 0.09s

=== episode:139 Env-steps-taken:67968
 	picked: 77 |actions: {0: 616, 1: 550, 2: 430, 3: 456, 4: 487, 5: 440, 6: 511, 7: 585, 8: 547}
episode: 139/2000 -> reward: 100.58854166666657, steps:4622, time-taken: 2.24min, time-elasped: 247.89min
-> berries picked: 77 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3438 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [337, 416, 274, 427, 390, 498, 406, 457, 233]
	| approx positives in sample 512: 75
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 9, 5, 11, 8, 8, 8, 7, 10]
	Time taken saving stuff: 0.00s

=== episode:140 Env-steps-taken:73440
 	picked: 88 |actions: {0: 471, 1: 777, 2: 500, 3: 594, 4: 507, 5: 433, 6: 608, 7: 596, 8: 717}
episode: 140/2000 -> reward: 128.4583333333332, steps:5203, time-taken: 2.41min, time-elasped: 250.30min
-> berries picked: 88 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3449 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [336, 415, 279, 430, 387, 501, 408, 459, 234]
	| approx positives in sample 512: 92
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 13, 7, 11, 11, 6, 17, 8, 11]
	Time taken saving stuff: 0.05s

=== episode:14 Env-steps-taken:82848
 	picked: 129 |actions: {0: 334, 1: 759, 2: 241, 3: 1322, 4: 436, 5: 251, 6: 188, 7: 1107, 8: 937}

==================================================
eval-episode: 140 -> reward: 174.22395833333346, steps: 5575.0, wall-time: 48.24s
-> berries picked: 129 of 800 | patches-visited: [0, 1, 7] | juice left:-0.00
==================================================


=== episode:141 Env-steps-taken:59808
 	picked: 44 |actions: {0: 356, 1: 708, 2: 348, 3: 337, 4: 317, 5: 284, 6: 364, 7: 459, 8: 724}
episode: 141/2000 -> reward: 59.97916666666672, steps:3897, time-taken: 1.76min, time-elasped: 252.87min
-> berries picked: 44 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3452 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [333, 418, 280, 434, 390, 499, 408, 456, 234]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 13, 5, 12, 11, 13, 11, 16, 10]
	Time taken saving stuff: 0.02s

=== episode:142 Env-steps-taken:60192
 	picked: 45 |actions: {0: 358, 1: 390, 2: 242, 3: 285, 4: 233, 5: 173, 6: 310, 7: 280, 8: 353}
episode: 142/2000 -> reward: 60.92187500000006, steps:2624, time-taken: 1.37min, time-elasped: 254.24min
-> berries picked: 45 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3470 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [339, 419, 282, 429, 394, 500, 412, 460, 235]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 14, 6, 6, 14, 14, 20, 16, 11]
	Time taken saving stuff: 0.00s

=== episode:143 Env-steps-taken:66240
 	picked: 68 |actions: {0: 348, 1: 555, 2: 403, 3: 319, 4: 420, 5: 343, 6: 528, 7: 520, 8: 573}
episode: 143/2000 -> reward: 92.10416666666661, steps:4009, time-taken: 2.21min, time-elasped: 256.46min
-> berries picked: 68 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3484 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [340, 420, 282, 428, 390, 500, 417, 467, 240]
	| approx positives in sample 512: 93
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 12, 3, 9, 9, 17, 10, 12, 11]
	Time taken saving stuff: 0.10s

=== episode:144 Env-steps-taken:53280
 	picked: 19 |actions: {0: 67, 1: 162, 2: 169, 3: 97, 4: 130, 5: 81, 6: 69, 7: 69, 8: 157}
episode: 144/2000 -> reward: 26.411458333333336, steps:1001, time-taken: 0.74min, time-elasped: 257.20min
-> berries picked: 19 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3492 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [341, 422, 285, 426, 390, 501, 416, 470, 241]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 15, 3, 11, 4, 10, 9, 14, 16]
	Time taken saving stuff: 0.00s

=== episode:145 Env-steps-taken:63840
 	picked: 62 |actions: {0: 540, 1: 620, 2: 568, 3: 457, 4: 497, 5: 380, 6: 537, 7: 609, 8: 620}
episode: 145/2000 -> reward: 78.94791666666667, steps:4828, time-taken: 2.62min, time-elasped: 259.83min
-> berries picked: 62 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3490 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [344, 423, 282, 433, 393, 495, 412, 466, 242]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 19, 6, 6, 10, 14, 10, 20, 7]
	Time taken saving stuff: 0.03s

=== episode:146 Env-steps-taken:69312
 	picked: 78 |actions: {0: 575, 1: 557, 2: 627, 3: 558, 4: 455, 5: 495, 6: 701, 7: 729, 8: 616}
episode: 146/2000 -> reward: 107.53124999999989, steps:5313, time-taken: 1.96min, time-elasped: 261.79min
-> berries picked: 78 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3493 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [347, 421, 285, 433, 391, 489, 419, 468, 240]
	| approx positives in sample 512: 101
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 5, 7, 11, 19, 13, 12, 10, 13]
	Time taken saving stuff: 0.00s

=== episode:147 Env-steps-taken:63648
 	picked: 55 |actions: {0: 328, 1: 502, 2: 448, 3: 288, 4: 306, 5: 317, 6: 420, 7: 349, 8: 369}
episode: 147/2000 -> reward: 78.34895833333334, steps:3327, time-taken: 1.38min, time-elasped: 263.18min
-> berries picked: 55 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3510 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [351, 425, 285, 437, 389, 490, 421, 472, 240]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 18, 11, 13, 11, 12, 13, 6, 11]
	Time taken saving stuff: 0.11s

=== episode:148 Env-steps-taken:68832
 	picked: 76 |actions: {0: 458, 1: 696, 2: 759, 3: 532, 4: 476, 5: 451, 6: 785, 7: 551, 8: 478}
episode: 148/2000 -> reward: 105.14583333333323, steps:5186, time-taken: 2.07min, time-elasped: 265.25min
-> berries picked: 76 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3538 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [353, 433, 284, 440, 394, 492, 424, 475, 243]
	| approx positives in sample 512: 84
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 11, 6, 7, 4, 14, 16, 8, 10]
	Time taken saving stuff: 0.00s

=== episode:149 Env-steps-taken:53568
 	picked: 22 |actions: {0: 130, 1: 177, 2: 89, 3: 97, 4: 121, 5: 130, 6: 167, 7: 155, 8: 180}
episode: 149/2000 -> reward: 28.739583333333332, steps:1246, time-taken: 0.68min, time-elasped: 265.93min
-> berries picked: 22 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3547 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [355, 435, 284, 441, 395, 494, 427, 473, 243]
	| approx positives in sample 512: 99
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 6, 7, 11, 7, 16, 16, 17, 10]
	Time taken saving stuff: 0.11s

=== episode:150 Env-steps-taken:59424
 	picked: 46 |actions: {0: 458, 1: 699, 2: 636, 3: 426, 4: 376, 5: 317, 6: 631, 7: 499, 8: 632}
episode: 150/2000 -> reward: 56.86458333333338, steps:4674, time-taken: 1.59min, time-elasped: 267.52min
-> berries picked: 46 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3539 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [356, 436, 282, 439, 394, 488, 425, 475, 244]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 11, 4, 10, 9, 6, 17, 14, 13]
	Time taken saving stuff: 0.05s

=== episode:15 Env-steps-taken:56736
 	picked: 32 |actions: {0: 127, 1: 768, 2: 304, 3: 204, 4: 12, 5: 54, 6: 446, 7: 120, 8: 819}

==================================================
eval-episode: 150 -> reward: 42.72395833333336, steps: 2854.0, wall-time: 30.79s
-> berries picked: 32 of 800 | patches-visited: [1, 6] | juice left:-0.00
==================================================


=== episode:151 Env-steps-taken:62496
 	picked: 46 |actions: {0: 274, 1: 293, 2: 228, 3: 295, 4: 447, 5: 255, 6: 384, 7: 225, 8: 372}
episode: 151/2000 -> reward: 73.86458333333334, steps:2773, time-taken: 1.18min, time-elasped: 269.22min
-> berries picked: 46 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3541 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [354, 434, 279, 444, 395, 491, 425, 474, 245]
	| approx positives in sample 512: 85
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 8, 6, 17, 9, 9, 8, 10, 12]
	Time taken saving stuff: 0.11s

=== episode:152 Env-steps-taken:68256
 	picked: 70 |actions: {0: 546, 1: 893, 2: 572, 3: 523, 4: 519, 5: 496, 6: 682, 7: 632, 8: 558}
episode: 152/2000 -> reward: 103.48958333333324, steps:5421, time-taken: 2.15min, time-elasped: 271.37min
-> berries picked: 70 of 800 | patches-visited: [0, 4, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3548 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [358, 437, 280, 451, 393, 493, 421, 469, 246]
	| approx positives in sample 512: 99
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 12, 12, 9, 11, 15, 9, 13, 10]
	Time taken saving stuff: 0.01s

=== episode:153 Env-steps-taken:68736
 	picked: 72 |actions: {0: 478, 1: 792, 2: 534, 3: 544, 4: 471, 5: 455, 6: 631, 7: 531, 8: 565}
episode: 153/2000 -> reward: 104.87499999999991, steps:5001, time-taken: 1.99min, time-elasped: 273.37min
-> berries picked: 72 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3572 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [354, 441, 281, 459, 393, 491, 432, 473, 248]
	| approx positives in sample 512: 78
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 7, 6, 14, 8, 8, 12, 9, 10]
	Time taken saving stuff: 0.00s

=== episode:154 Env-steps-taken:67488
 	picked: 73 |actions: {0: 552, 1: 865, 2: 559, 3: 521, 4: 520, 5: 417, 6: 719, 7: 664, 8: 617}
episode: 154/2000 -> reward: 98.31770833333324, steps:5434, time-taken: 2.07min, time-elasped: 275.43min
-> berries picked: 73 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3597 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [357, 451, 284, 462, 392, 494, 434, 475, 248]
	| approx positives in sample 512: 92
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 15, 10, 11, 7, 15, 7, 5, 12]
	Time taken saving stuff: 0.02s

=== episode:155 Env-steps-taken:57888
 	picked: 33 |actions: {0: 224, 1: 379, 2: 325, 3: 297, 4: 250, 5: 230, 6: 270, 7: 334, 8: 608}
episode: 155/2000 -> reward: 51.60937500000003, steps:2917, time-taken: 1.30min, time-elasped: 276.74min
-> berries picked: 33 of 800 | patches-visited: [0, 4, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3587 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [355, 446, 285, 459, 393, 493, 431, 474, 251]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 11, 5, 15, 10, 17, 11, 10, 9]
	Time taken saving stuff: 0.00s

=== episode:156 Env-steps-taken:63744
 	picked: 64 |actions: {0: 522, 1: 748, 2: 662, 3: 514, 4: 441, 5: 499, 6: 786, 7: 667, 8: 698}
episode: 156/2000 -> reward: 78.33333333333331, steps:5537, time-taken: 2.05min, time-elasped: 278.79min
-> berries picked: 64 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3583 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [358, 442, 287, 455, 399, 486, 429, 473, 254]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 12, 7, 7, 12, 11, 8, 12, 13]
	Time taken saving stuff: 0.09s

=== episode:157 Env-steps-taken:63744
 	picked: 55 |actions: {0: 339, 1: 400, 2: 336, 3: 275, 4: 330, 5: 301, 6: 490, 7: 433, 8: 372}
episode: 157/2000 -> reward: 79.84895833333333, steps:3276, time-taken: 1.41min, time-elasped: 280.20min
-> berries picked: 55 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3599 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [367, 449, 282, 453, 404, 485, 430, 472, 257]
	| approx positives in sample 512: 80
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 10, 11, 8, 2, 10, 12, 10, 7]
	Time taken saving stuff: 0.00s

=== episode:158 Env-steps-taken:58176
 	picked: 42 |actions: {0: 373, 1: 908, 2: 678, 3: 422, 4: 395, 5: 426, 6: 742, 7: 705, 8: 640}
episode: 158/2000 -> reward: 50.593750000000036, steps:5289, time-taken: 1.92min, time-elasped: 282.12min
-> berries picked: 42 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3589 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [364, 448, 275, 456, 404, 486, 429, 470, 257]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 11, 11, 10, 9, 11, 8, 18, 9]
	Time taken saving stuff: 0.11s

=== episode:159 Env-steps-taken:58080
 	picked: 33 |actions: {0: 264, 1: 248, 2: 174, 3: 129, 4: 143, 5: 194, 6: 297, 7: 269, 8: 226}
episode: 159/2000 -> reward: 51.60937500000002, steps:1944, time-taken: 0.93min, time-elasped: 283.05min
-> berries picked: 33 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3593 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [368, 455, 278, 450, 404, 482, 426, 472, 258]
	| approx positives in sample 512: 87
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 8, 8, 12, 8, 8, 9, 16, 6]
	Time taken saving stuff: 0.00s

=== episode:160 Env-steps-taken:59712
 	picked: 47 |actions: {0: 245, 1: 480, 2: 492, 3: 362, 4: 363, 5: 447, 6: 466, 7: 391, 8: 562}
episode: 160/2000 -> reward: 58.30729166666672, steps:3808, time-taken: 1.51min, time-elasped: 284.57min
-> berries picked: 47 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3590 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [365, 456, 280, 455, 406, 479, 423, 468, 258]
	| approx positives in sample 512: 93
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 15, 7, 9, 9, 11, 6, 8, 15]
	Time taken saving stuff: 0.13s

=== episode:16 Env-steps-taken:74208
 	picked: 96 |actions: {0: 1029, 1: 243, 2: 925, 3: 110, 4: 269, 5: 422, 6: 95, 7: 523, 8: 1508}

==================================================
eval-episode: 160 -> reward: 131.11458333333317, steps: 5124.0, wall-time: 38.99s
-> berries picked: 96 of 800 | patches-visited: [0, 1] | juice left:-0.00
==================================================


=== episode:161 Env-steps-taken:60960
 	picked: 53 |actions: {0: 457, 1: 477, 2: 578, 3: 353, 4: 293, 5: 385, 6: 505, 7: 499, 8: 328}
episode: 161/2000 -> reward: 65.46354166666673, steps:3875, time-taken: 1.55min, time-elasped: 286.78min
-> berries picked: 53 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3599 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [368, 462, 283, 455, 409, 468, 424, 472, 258]
	| approx positives in sample 512: 85
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 15, 6, 9, 9, 5, 8, 10, 16]
	Time taken saving stuff: 0.00s

=== episode:162 Env-steps-taken:73728
 	picked: 89 |actions: {0: 602, 1: 602, 2: 826, 3: 462, 4: 466, 5: 694, 6: 676, 7: 574, 8: 690}
episode: 162/2000 -> reward: 129.01562499999986, steps:5592, time-taken: 2.14min, time-elasped: 288.92min
-> berries picked: 89 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3628 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [374, 469, 286, 447, 407, 476, 433, 475, 261]
	| approx positives in sample 512: 95
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 7, 9, 13, 9, 9, 9, 15, 12]
	Time taken saving stuff: 0.09s

=== episode:163 Env-steps-taken:71424
 	picked: 89 |actions: {0: 649, 1: 806, 2: 879, 3: 519, 4: 580, 5: 606, 6: 694, 7: 666, 8: 612}
episode: 163/2000 -> reward: 117.51562499999983, steps:6011, time-taken: 2.34min, time-elasped: 291.27min
-> berries picked: 89 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3629 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [371, 466, 294, 446, 405, 471, 434, 480, 262]
	| approx positives in sample 512: 89
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 9, 10, 5, 17, 7, 7, 7, 14]
	Time taken saving stuff: 0.01s

=== episode:164 Env-steps-taken:63936
 	picked: 61 |actions: {0: 419, 1: 520, 2: 530, 3: 477, 4: 469, 5: 444, 6: 775, 7: 431, 8: 904}
episode: 164/2000 -> reward: 80.50520833333333, steps:4969, time-taken: 1.87min, time-elasped: 293.15min
-> berries picked: 61 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3625 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [374, 466, 290, 445, 403, 473, 437, 475, 262]
	| approx positives in sample 512: 94
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 17, 8, 13, 7, 8, 17, 8, 8]
	Time taken saving stuff: 0.09s

=== episode:165 Env-steps-taken:54816
 	picked: 27 |actions: {0: 267, 1: 288, 2: 140, 3: 112, 4: 139, 5: 184, 6: 356, 7: 331, 8: 368}
episode: 165/2000 -> reward: 33.95312499999999, steps:2185, time-taken: 0.96min, time-elasped: 294.11min
-> berries picked: 27 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3626 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [378, 466, 286, 443, 402, 472, 439, 477, 263]
	| approx positives in sample 512: 93
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 10, 3, 9, 8, 11, 12, 16, 17]
	Time taken saving stuff: 0.00s

=== episode:166 Env-steps-taken:63360
 	picked: 54 |actions: {0: 415, 1: 479, 2: 497, 3: 263, 4: 472, 5: 575, 6: 484, 7: 336, 8: 318}
episode: 166/2000 -> reward: 78.90625, steps:3839, time-taken: 1.62min, time-elasped: 295.73min
-> berries picked: 54 of 800 | patches-visited: [0, 3, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3642 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [382, 462, 286, 446, 403, 480, 439, 482, 262]
	| approx positives in sample 512: 88
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 11, 5, 6, 12, 11, 12, 12, 7]
	Time taken saving stuff: 0.03s

=== episode:167 Env-steps-taken:59616
 	picked: 47 |actions: {0: 377, 1: 489, 2: 345, 3: 343, 4: 342, 5: 328, 6: 367, 7: 416, 8: 382}
episode: 167/2000 -> reward: 57.807291666666714, steps:3389, time-taken: 1.29min, time-elasped: 297.02min
-> berries picked: 47 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3637 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [383, 464, 278, 449, 402, 479, 441, 481, 260]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 11, 7, 10, 11, 9, 13, 15, 14]
	Time taken saving stuff: 0.01s

=== episode:168 Env-steps-taken:60000
 	picked: 50 |actions: {0: 298, 1: 614, 2: 763, 3: 476, 4: 483, 5: 514, 6: 584, 7: 509, 8: 460}
episode: 168/2000 -> reward: 59.63541666666673, steps:4701, time-taken: 1.80min, time-elasped: 298.82min
-> berries picked: 50 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3638 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [383, 458, 284, 448, 407, 479, 439, 482, 258]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 9, 5, 14, 10, 10, 17, 16, 16]
	Time taken saving stuff: 0.00s

=== episode:169 Env-steps-taken:56832
 	picked: 33 |actions: {0: 305, 1: 387, 2: 396, 3: 256, 4: 278, 5: 339, 6: 327, 7: 229, 8: 299}
episode: 169/2000 -> reward: 45.109375000000014, steps:2816, time-taken: 1.35min, time-elasped: 300.17min
-> berries picked: 33 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3631 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [381, 454, 285, 446, 409, 482, 432, 483, 259]
	| approx positives in sample 512: 99
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 11, 11, 14, 14, 10, 14, 8, 9]
	Time taken saving stuff: 0.11s

=== episode:170 Env-steps-taken:58656
 	picked: 38 |actions: {0: 444, 1: 595, 2: 924, 3: 425, 4: 471, 5: 350, 6: 499, 7: 397, 8: 710}
episode: 170/2000 -> reward: 52.93750000000004, steps:4815, time-taken: 1.87min, time-elasped: 302.04min
-> berries picked: 38 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3605 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [380, 448, 276, 444, 408, 480, 427, 482, 260]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 13, 14, 8, 11, 5, 17, 10, 14]
	Time taken saving stuff: 0.09s

=== episode:17 Env-steps-taken:54720
 	picked: 24 |actions: {0: 69, 1: 227, 2: 2195, 3: 69, 4: 22, 5: 41, 6: 2163, 7: 108, 8: 81}

==================================================
eval-episode: 170 -> reward: 33.625, steps: 4975.0, wall-time: 39.82s
-> berries picked: 24 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:171 Env-steps-taken:59328
 	picked: 46 |actions: {0: 280, 1: 459, 2: 441, 3: 368, 4: 363, 5: 218, 6: 246, 7: 383, 8: 374}
episode: 171/2000 -> reward: 56.36458333333337, steps:3132, time-taken: 1.22min, time-elasped: 303.93min
-> berries picked: 46 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3612 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [380, 453, 277, 443, 407, 481, 429, 482, 260]
	| approx positives in sample 512: 82
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 12, 9, 9, 10, 11, 9, 5, 8]
	Time taken saving stuff: 0.08s

=== episode:172 Env-steps-taken:66624
 	picked: 71 |actions: {0: 549, 1: 652, 2: 681, 3: 462, 4: 522, 5: 539, 6: 637, 7: 708, 8: 556}
episode: 172/2000 -> reward: 93.9322916666666, steps:5306, time-taken: 2.07min, time-elasped: 306.01min
-> berries picked: 71 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3617 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [381, 448, 274, 446, 413, 481, 430, 481, 263]
	| approx positives in sample 512: 94
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 10, 8, 11, 14, 11, 8, 13, 11]
	Time taken saving stuff: 0.09s

=== episode:173 Env-steps-taken:59712
 	picked: 41 |actions: {0: 424, 1: 453, 2: 410, 3: 309, 4: 396, 5: 297, 6: 372, 7: 494, 8: 553}
episode: 173/2000 -> reward: 59.6510416666667, steps:3708, time-taken: 1.51min, time-elasped: 307.53min
-> berries picked: 41 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3616 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [384, 449, 273, 446, 410, 481, 431, 477, 265]
	| approx positives in sample 512: 95
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 15, 3, 12, 13, 10, 9, 11, 15]
	Time taken saving stuff: 0.00s

=== episode:174 Env-steps-taken:56736
 	picked: 31 |actions: {0: 238, 1: 306, 2: 298, 3: 167, 4: 194, 5: 203, 6: 160, 7: 219, 8: 229}
episode: 174/2000 -> reward: 44.72395833333336, steps:2014, time-taken: 1.01min, time-elasped: 308.53min
-> berries picked: 31 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3616 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [387, 454, 276, 439, 413, 478, 430, 475, 264]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 15, 6, 15, 14, 9, 10, 15, 16]
	Time taken saving stuff: 0.00s

=== episode:175 Env-steps-taken:62592
 	picked: 49 |actions: {0: 393, 1: 452, 2: 409, 3: 295, 4: 296, 5: 309, 6: 378, 7: 551, 8: 356}
episode: 175/2000 -> reward: 74.19270833333334, steps:3439, time-taken: 1.49min, time-elasped: 310.03min
-> berries picked: 49 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3626 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [394, 454, 275, 435, 418, 476, 432, 478, 264]
	| approx positives in sample 512: 90
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 9, 9, 8, 14, 7, 12, 9, 16]
	Time taken saving stuff: 0.11s

=== episode:176 Env-steps-taken:55872
 	picked: 28 |actions: {0: 171, 1: 163, 2: 205, 3: 172, 4: 145, 5: 161, 6: 133, 7: 196, 8: 106}
episode: 176/2000 -> reward: 37.51041666666667, steps:1452, time-taken: 0.82min, time-elasped: 310.86min
-> berries picked: 28 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3609 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [394, 447, 270, 426, 419, 477, 433, 479, 264]
	| approx positives in sample 512: 92
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 11, 10, 11, 10, 11, 5, 11, 17]
	Time taken saving stuff: 0.00s

=== episode:177 Env-steps-taken:52992
 	picked: 19 |actions: {0: 158, 1: 218, 2: 285, 3: 114, 4: 155, 5: 186, 6: 402, 7: 256, 8: 308}
episode: 177/2000 -> reward: 25.911458333333325, steps:2082, time-taken: 0.97min, time-elasped: 311.83min
-> berries picked: 19 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3579 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [391, 440, 265, 420, 419, 474, 428, 477, 265]
	| approx positives in sample 512: 90
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 8, 7, 7, 9, 9, 7, 15, 19]
	Time taken saving stuff: 0.00s

=== episode:178 Env-steps-taken:60480
 	picked: 44 |actions: {0: 520, 1: 617, 2: 659, 3: 422, 4: 465, 5: 453, 6: 499, 7: 640, 8: 534}
episode: 178/2000 -> reward: 62.47916666666673, steps:4809, time-taken: 1.90min, time-elasped: 313.73min
-> berries picked: 44 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3525 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [387, 435, 258, 403, 414, 466, 425, 475, 262]
	| approx positives in sample 512: 101
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 11, 14, 8, 9, 11, 13, 16, 16]
	Time taken saving stuff: 0.03s

=== episode:179 Env-steps-taken:52224
 	picked: 14 |actions: {0: 113, 1: 87, 2: 136, 3: 60, 4: 57, 5: 61, 6: 65, 7: 116, 8: 44}
episode: 179/2000 -> reward: 21.25520833333333, steps:739, time-taken: 0.52min, time-elasped: 314.25min
-> berries picked: 14 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3525 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [388, 434, 257, 401, 415, 466, 426, 477, 261]
	| approx positives in sample 512: 91
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 9, 7, 8, 12, 13, 15, 8, 14]
	Time taken saving stuff: 0.01s

=== episode:180 Env-steps-taken:55488
 	picked: 26 |actions: {0: 180, 1: 210, 2: 179, 3: 151, 4: 139, 5: 167, 6: 189, 7: 173, 8: 115}
episode: 180/2000 -> reward: 37.567708333333336, steps:1503, time-taken: 0.75min, time-elasped: 315.01min
-> berries picked: 26 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3528 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [393, 435, 258, 402, 416, 467, 427, 474, 256]
	| approx positives in sample 512: 94
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 11, 3, 6, 15, 12, 13, 8, 16]
	Time taken saving stuff: 0.06s

=== episode:18 Env-steps-taken:52800
 	picked: 17 |actions: {0: 114, 1: 626, 2: 1235, 3: 8, 4: 96, 5: 11, 6: 22, 7: 885, 8: 1803}

==================================================
eval-episode: 180 -> reward: 24.02604166666667, steps: 4800.0, wall-time: 36.06s
-> berries picked: 17 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:181 Env-steps-taken:59328
 	picked: 43 |actions: {0: 422, 1: 508, 2: 298, 3: 261, 4: 249, 5: 254, 6: 286, 7: 345, 8: 434}
episode: 181/2000 -> reward: 58.536458333333364, steps:3057, time-taken: 1.32min, time-elasped: 316.93min
-> berries picked: 43 of 800 | patches-visited: [0, 3, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3520 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [396, 426, 254, 398, 418, 469, 430, 473, 256]
	| approx positives in sample 512: 101
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 7, 9, 10, 11, 17, 13, 11, 15]
	Time taken saving stuff: 0.04s

=== episode:182 Env-steps-taken:59136
 	picked: 38 |actions: {0: 253, 1: 319, 2: 221, 3: 181, 4: 201, 5: 203, 6: 260, 7: 258, 8: 229}
episode: 182/2000 -> reward: 56.82291666666671, steps:2125, time-taken: 1.09min, time-elasped: 318.02min
-> berries picked: 38 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3524 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [401, 429, 252, 392, 417, 471, 431, 474, 257]
	| approx positives in sample 512: 87
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 8, 5, 11, 9, 8, 17, 9, 7]
	Time taken saving stuff: 0.01s

=== episode:183 Env-steps-taken:59136
 	picked: 41 |actions: {0: 266, 1: 255, 2: 283, 3: 218, 4: 265, 5: 203, 6: 275, 7: 303, 8: 383}
episode: 183/2000 -> reward: 56.6510416666667, steps:2451, time-taken: 1.13min, time-elasped: 319.16min
-> berries picked: 41 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3529 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [403, 430, 251, 387, 419, 471, 436, 473, 259]
	| approx positives in sample 512: 95
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 8, 6, 7, 19, 9, 8, 13, 17]
	Time taken saving stuff: 0.10s

=== episode:184 Env-steps-taken:56160
 	picked: 31 |actions: {0: 255, 1: 176, 2: 203, 3: 205, 4: 162, 5: 176, 6: 224, 7: 284, 8: 263}
episode: 184/2000 -> reward: 41.72395833333335, steps:1948, time-taken: 0.97min, time-elasped: 320.13min
-> berries picked: 31 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3535 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [404, 429, 252, 386, 419, 471, 439, 475, 260]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 20, 5, 11, 9, 10, 12, 20, 15]
	Time taken saving stuff: 0.00s

=== episode:185 Env-steps-taken:51072
 	picked: 13 |actions: {0: 66, 1: 100, 2: 128, 3: 134, 4: 116, 5: 168, 6: 119, 7: 183, 8: 209}
episode: 185/2000 -> reward: 15.255208333333332, steps:1223, time-taken: 0.72min, time-elasped: 320.85min
-> berries picked: 13 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3534 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [404, 430, 253, 385, 420, 469, 438, 475, 260]
	| approx positives in sample 512: 101
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 7, 7, 15, 15, 10, 13, 9, 20]
	Time taken saving stuff: 0.11s

=== episode:186 Env-steps-taken:64320
 	picked: 58 |actions: {0: 631, 1: 448, 2: 377, 3: 321, 4: 365, 5: 551, 6: 535, 7: 751, 8: 798}
episode: 186/2000 -> reward: 82.67708333333331, steps:4777, time-taken: 1.82min, time-elasped: 322.67min
-> berries picked: 58 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3536 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [407, 430, 251, 379, 421, 466, 439, 482, 261]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 15, 6, 10, 9, 11, 9, 14, 8]
	Time taken saving stuff: 0.00s

=== episode:187 Env-steps-taken:65376
 	picked: 71 |actions: {0: 583, 1: 354, 2: 462, 3: 434, 4: 438, 5: 420, 6: 769, 7: 540, 8: 536}
episode: 187/2000 -> reward: 87.4322916666666, steps:4536, time-taken: 1.77min, time-elasped: 324.44min
-> berries picked: 71 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3549 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [406, 431, 246, 384, 424, 467, 444, 485, 262]
	| approx positives in sample 512: 94
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 7, 6, 14, 14, 8, 10, 10, 14]
	Time taken saving stuff: 0.11s

=== episode:188 Env-steps-taken:62784
 	picked: 58 |actions: {0: 436, 1: 324, 2: 251, 3: 233, 4: 277, 5: 301, 6: 414, 7: 373, 8: 357}
episode: 188/2000 -> reward: 75.734375, steps:2966, time-taken: 1.25min, time-elasped: 325.70min
-> berries picked: 58 of 800 | patches-visited: [0, 2, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3573 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [411, 435, 247, 382, 424, 475, 448, 487, 264]
	| approx positives in sample 512: 83
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 14, 8, 6, 9, 9, 5, 9, 15]
	Time taken saving stuff: 0.10s

=== episode:189 Env-steps-taken:58464
 	picked: 39 |actions: {0: 396, 1: 336, 2: 318, 3: 183, 4: 210, 5: 299, 6: 408, 7: 369, 8: 404}
episode: 189/2000 -> reward: 53.26562500000003, steps:2923, time-taken: 1.31min, time-elasped: 327.02min
-> berries picked: 39 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3583 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [412, 440, 250, 378, 427, 478, 448, 486, 264]
	| approx positives in sample 512: 84
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 12, 6, 11, 5, 8, 10, 15, 8]
	Time taken saving stuff: 0.12s

=== episode:190 Env-steps-taken:55200
 	picked: 26 |actions: {0: 207, 1: 210, 2: 193, 3: 181, 4: 228, 5: 252, 6: 413, 7: 499, 8: 475}
episode: 190/2000 -> reward: 36.010416666666664, steps:2658, time-taken: 1.12min, time-elasped: 328.14min
-> berries picked: 26 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3569 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [405, 438, 248, 380, 425, 475, 447, 488, 263]
	| approx positives in sample 512: 90
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 10, 7, 12, 10, 11, 7, 12, 15]
	Time taken saving stuff: 0.05s

=== episode:19 Env-steps-taken:74400
 	picked: 99 |actions: {0: 480, 1: 397, 2: 347, 3: 79, 4: 554, 5: 190, 6: 1032, 7: 629, 8: 822}

==================================================
eval-episode: 190 -> reward: 133.8281249999999, steps: 4530.0, wall-time: 39.38s
-> berries picked: 99 of 800 | patches-visited: [1, 2, 5] | juice left:-0.00
==================================================


=== episode:191 Env-steps-taken:61920
 	picked: 53 |actions: {0: 456, 1: 285, 2: 365, 3: 306, 4: 393, 5: 382, 6: 481, 7: 608, 8: 409}
episode: 191/2000 -> reward: 69.46354166666671, steps:3685, time-taken: 1.53min, time-elasped: 330.33min
-> berries picked: 53 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3586 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [408, 438, 245, 382, 429, 478, 450, 493, 263]
	| approx positives in sample 512: 83
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 10, 6, 1, 13, 15, 8, 7, 12]
	Time taken saving stuff: 0.00s

=== episode:192 Env-steps-taken:62784
 	picked: 56 |actions: {0: 426, 1: 295, 2: 393, 3: 316, 4: 267, 5: 334, 6: 513, 7: 332, 8: 422}
episode: 192/2000 -> reward: 74.79166666666667, steps:3298, time-taken: 1.30min, time-elasped: 331.63min
-> berries picked: 56 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3605 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [408, 431, 245, 385, 431, 486, 456, 496, 267]
	| approx positives in sample 512: 92
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 15, 6, 10, 7, 12, 10, 11, 13]
	Time taken saving stuff: 0.09s

=== episode:193 Env-steps-taken:63168
 	picked: 57 |actions: {0: 500, 1: 356, 2: 408, 3: 349, 4: 425, 5: 539, 6: 826, 7: 614, 8: 715}
episode: 193/2000 -> reward: 76.734375, steps:4732, time-taken: 1.87min, time-elasped: 333.50min
-> berries picked: 57 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3612 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [402, 429, 243, 383, 431, 492, 460, 501, 271]
	| approx positives in sample 512: 93
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 10, 9, 14, 9, 6, 14, 7, 10]
	Time taken saving stuff: 0.00s

=== episode:194 Env-steps-taken:63072
 	picked: 54 |actions: {0: 520, 1: 451, 2: 370, 3: 425, 4: 391, 5: 445, 6: 411, 7: 460, 8: 743}
episode: 194/2000 -> reward: 76.40625000000001, steps:4216, time-taken: 1.73min, time-elasped: 335.23min
-> berries picked: 54 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3629 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [408, 434, 245, 383, 430, 494, 462, 500, 273]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 14, 4, 5, 16, 10, 12, 18, 17]
	Time taken saving stuff: 0.00s

=== episode:195 Env-steps-taken:63840
 	picked: 57 |actions: {0: 546, 1: 392, 2: 415, 3: 323, 4: 417, 5: 393, 6: 470, 7: 486, 8: 552}
episode: 195/2000 -> reward: 80.234375, steps:3994, time-taken: 1.57min, time-elasped: 336.81min
-> berries picked: 57 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3635 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [408, 434, 244, 384, 430, 495, 461, 504, 275]
	| approx positives in sample 512: 77
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 8, 2, 7, 11, 12, 8, 10, 10]
	Time taken saving stuff: 0.10s

=== episode:196 Env-steps-taken:54816
 	picked: 23 |actions: {0: 144, 1: 73, 2: 98, 3: 127, 4: 250, 5: 118, 6: 262, 7: 215, 8: 119}
episode: 196/2000 -> reward: 35.18229166666667, steps:1406, time-taken: 0.77min, time-elasped: 337.58min
-> berries picked: 23 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3625 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [407, 433, 240, 381, 431, 494, 458, 507, 274]
	| approx positives in sample 512: 99
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 8, 10, 13, 11, 10, 9, 8, 17]
	Time taken saving stuff: 0.10s

=== episode:197 Env-steps-taken:60192
 	picked: 46 |actions: {0: 333, 1: 296, 2: 237, 3: 157, 4: 225, 5: 321, 6: 531, 7: 309, 8: 279}
episode: 197/2000 -> reward: 62.86458333333339, steps:2688, time-taken: 1.17min, time-elasped: 338.76min
-> berries picked: 46 of 800 | patches-visited: [0, 3, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3637 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [413, 434, 239, 377, 433, 496, 465, 506, 274]
	| approx positives in sample 512: 94
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 9, 4, 10, 10, 14, 5, 18, 11]
	Time taken saving stuff: 0.00s

=== episode:198 Env-steps-taken:57504
 	picked: 34 |actions: {0: 300, 1: 162, 2: 160, 3: 203, 4: 172, 5: 190, 6: 337, 7: 212, 8: 220}
episode: 198/2000 -> reward: 48.55208333333334, steps:1956, time-taken: 0.93min, time-elasped: 339.69min
-> berries picked: 34 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3641 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [414, 433, 237, 374, 433, 498, 469, 507, 276]
	| approx positives in sample 512: 96
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 9, 8, 9, 6, 13, 11, 17, 11]
	Time taken saving stuff: 0.00s

=== episode:199 Env-steps-taken:55968
 	picked: 27 |actions: {0: 265, 1: 176, 2: 259, 3: 216, 4: 163, 5: 190, 6: 296, 7: 138, 8: 199}
episode: 199/2000 -> reward: 39.95312500000001, steps:1902, time-taken: 1.01min, time-elasped: 340.70min
-> berries picked: 27 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3642 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [416, 434, 235, 375, 430, 501, 467, 508, 276]
	| approx positives in sample 512: 87
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 8, 6, 14, 10, 13, 7, 7, 15]
	Time taken saving stuff: 0.10s

=== episode:200 Env-steps-taken:70560
 	picked: 78 |actions: {0: 514, 1: 428, 2: 539, 3: 447, 4: 462, 5: 522, 6: 770, 7: 791, 8: 630}
episode: 200/2000 -> reward: 114.6458333333332, steps:5103, time-taken: 2.07min, time-elasped: 342.77min
-> berries picked: 78 of 800 | patches-visited: [0, 5, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3647 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [412, 431, 232, 371, 424, 506, 484, 510, 277]
	| approx positives in sample 512: 87
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 15, 7, 7, 3, 6, 14, 10, 16]
	Time taken saving stuff: 0.05s

=== episode:20 Env-steps-taken:58944
 	picked: 42 |actions: {0: 151, 1: 217, 2: 161, 3: 66, 4: 122, 5: 82, 6: 573, 7: 182, 8: 390}

==================================================
eval-episode: 200 -> reward: 53.70833333333337, steps: 1944.0, wall-time: 26.68s
-> berries picked: 42 of 800 | patches-visited: [0, 1] | juice left:-0.00
==================================================


=== episode:201 Env-steps-taken:59040
 	picked: 44 |actions: {0: 410, 1: 318, 2: 455, 3: 471, 4: 376, 5: 521, 6: 904, 7: 495, 8: 584}
episode: 201/2000 -> reward: 55.9791666666667, steps:4534, time-taken: 1.67min, time-elasped: 344.90min
-> berries picked: 44 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3617 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [408, 421, 232, 371, 418, 504, 480, 504, 279]
	| approx positives in sample 512: 79
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 6, 5, 7, 9, 8, 10, 11, 11]
	Time taken saving stuff: 0.00s

=== episode:202 Env-steps-taken:60480
 	picked: 46 |actions: {0: 427, 1: 323, 2: 388, 3: 242, 4: 343, 5: 316, 6: 341, 7: 383, 8: 414}
episode: 202/2000 -> reward: 63.4791666666667, steps:3177, time-taken: 1.44min, time-elasped: 346.34min
-> berries picked: 46 of 800 | patches-visited: [0, 1, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3613 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [409, 416, 231, 370, 417, 504, 480, 501, 285]
	| approx positives in sample 512: 79
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 8, 6, 4, 7, 7, 14, 12, 13]
	Time taken saving stuff: 0.02s

=== episode:203 Env-steps-taken:64800
 	picked: 59 |actions: {0: 495, 1: 484, 2: 450, 3: 434, 4: 689, 5: 521, 6: 711, 7: 880, 8: 720}
episode: 203/2000 -> reward: 85.11979166666666, steps:5384, time-taken: 2.02min, time-elasped: 348.36min
-> berries picked: 59 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3584 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [409, 414, 222, 367, 419, 500, 476, 490, 287]
	| approx positives in sample 512: 88
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 12, 6, 6, 16, 10, 10, 7, 13]
	Time taken saving stuff: 0.00s

=== episode:204 Env-steps-taken:59616
 	picked: 47 |actions: {0: 747, 1: 528, 2: 708, 3: 588, 4: 434, 5: 507, 6: 908, 7: 517, 8: 483}
episode: 204/2000 -> reward: 57.80729166666672, steps:5420, time-taken: 2.08min, time-elasped: 350.44min
-> berries picked: 47 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3563 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [407, 417, 229, 356, 415, 490, 471, 489, 289]
	| approx positives in sample 512: 78
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 12, 2, 8, 7, 15, 5, 14, 10]
	Time taken saving stuff: 0.11s

=== episode:205 Env-steps-taken:58176
 	picked: 38 |actions: {0: 300, 1: 277, 2: 195, 3: 179, 4: 225, 5: 214, 6: 360, 7: 308, 8: 261}
episode: 205/2000 -> reward: 51.822916666666686, steps:2319, time-taken: 1.12min, time-elasped: 351.57min
-> berries picked: 38 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3568 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [407, 416, 232, 358, 415, 488, 473, 489, 290]
	| approx positives in sample 512: 79
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 9, 6, 5, 8, 9, 7, 13, 13]
	Time taken saving stuff: 0.00s

=== episode:206 Env-steps-taken:60096
 	picked: 45 |actions: {0: 389, 1: 390, 2: 214, 3: 281, 4: 256, 5: 249, 6: 419, 7: 375, 8: 422}
episode: 206/2000 -> reward: 61.42187500000006, steps:2995, time-taken: 1.25min, time-elasped: 352.82min
-> berries picked: 45 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3564 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [404, 416, 234, 359, 415, 484, 475, 487, 290]
	| approx positives in sample 512: 89
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 8, 7, 11, 8, 10, 10, 14, 12]
	Time taken saving stuff: 0.10s

=== episode:207 Env-steps-taken:64992
 	picked: 63 |actions: {0: 626, 1: 485, 2: 439, 3: 400, 4: 484, 5: 494, 6: 574, 7: 820, 8: 759}
episode: 207/2000 -> reward: 85.89062499999996, steps:5081, time-taken: 1.93min, time-elasped: 354.75min
-> berries picked: 63 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3537 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [395, 407, 233, 358, 414, 476, 479, 483, 292]
	| approx positives in sample 512: 82
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 7, 5, 8, 10, 8, 8, 13, 16]
	Time taken saving stuff: 0.00s

=== episode:208 Env-steps-taken:61152
 	picked: 47 |actions: {0: 311, 1: 348, 2: 392, 3: 368, 4: 359, 5: 332, 6: 724, 7: 586, 8: 335}
episode: 208/2000 -> reward: 65.8072916666667, steps:3755, time-taken: 1.55min, time-elasped: 356.31min
-> berries picked: 47 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3523 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [386, 411, 229, 356, 411, 477, 481, 478, 294]
	| approx positives in sample 512: 94
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 12, 8, 13, 6, 11, 10, 10, 17]
	Time taken saving stuff: 0.01s

=== episode:209 Env-steps-taken:63840
 	picked: 63 |actions: {0: 492, 1: 427, 2: 398, 3: 363, 4: 353, 5: 329, 6: 569, 7: 540, 8: 341}
episode: 209/2000 -> reward: 79.89062499999996, steps:3812, time-taken: 1.52min, time-elasped: 357.83min
-> berries picked: 63 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3541 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [386, 417, 235, 355, 407, 477, 483, 486, 295]
	| approx positives in sample 512: 83
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 8, 10, 14, 9, 6, 8, 6, 13]
	Time taken saving stuff: 0.00s

=== episode:210 Env-steps-taken:65856
 	picked: 63 |actions: {0: 693, 1: 519, 2: 450, 3: 387, 4: 380, 5: 384, 6: 740, 7: 817, 8: 788}
episode: 210/2000 -> reward: 90.39062499999994, steps:5158, time-taken: 1.89min, time-elasped: 359.72min
-> berries picked: 63 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3534 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [384, 417, 235, 346, 409, 475, 488, 483, 297]
	| approx positives in sample 512: 82
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [2, 10, 4, 6, 14, 10, 11, 9, 16]
	Time taken saving stuff: 0.05s

=== episode:21 Env-steps-taken:64512
 	picked: 62 |actions: {0: 849, 1: 228, 2: 1179, 3: 202, 4: 645, 5: 920, 6: 473, 7: 550, 8: 228}

==================================================
eval-episode: 210 -> reward: 83.44791666666663, steps: 5274.0, wall-time: 40.41s
-> berries picked: 62 of 800 | patches-visited: [1, 2] | juice left:-0.00
==================================================


=== episode:211 Env-steps-taken:52704
 	picked: 18 |actions: {0: 340, 1: 244, 2: 213, 3: 161, 4: 255, 5: 273, 6: 240, 7: 275, 8: 175}
episode: 211/2000 -> reward: 23.468749999999996, steps:2176, time-taken: 0.95min, time-elasped: 361.34min
-> berries picked: 18 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3529 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [381, 417, 236, 347, 410, 476, 484, 481, 297]
	| approx positives in sample 512: 90
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 21, 4, 6, 8, 9, 13, 11, 13]
	Time taken saving stuff: 0.11s

=== episode:212 Env-steps-taken:61920
 	picked: 50 |actions: {0: 501, 1: 495, 2: 440, 3: 305, 4: 392, 5: 380, 6: 706, 7: 482, 8: 360}
episode: 212/2000 -> reward: 70.63541666666669, steps:4061, time-taken: 1.68min, time-elasped: 363.03min
-> berries picked: 50 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3537 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [378, 422, 240, 345, 412, 477, 485, 481, 297]
	| approx positives in sample 512: 94
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 16, 6, 9, 9, 8, 13, 11, 10]
	Time taken saving stuff: 0.00s

=== episode:213 Env-steps-taken:58656
 	picked: 37 |actions: {0: 469, 1: 448, 2: 444, 3: 396, 4: 304, 5: 303, 6: 409, 7: 489, 8: 355}
episode: 213/2000 -> reward: 53.38020833333336, steps:3617, time-taken: 1.40min, time-elasped: 364.43min
-> berries picked: 37 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3522 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [375, 422, 236, 347, 408, 476, 482, 477, 299]
	| approx positives in sample 512: 81
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 13, 5, 10, 9, 10, 9, 5, 7]
	Time taken saving stuff: 0.02s

=== episode:214 Env-steps-taken:50976
 	picked: 12 |actions: {0: 123, 1: 149, 2: 104, 3: 92, 4: 77, 5: 120, 6: 163, 7: 199, 8: 213}
episode: 214/2000 -> reward: 15.812500000000002, steps:1240, time-taken: 0.73min, time-elasped: 365.16min
-> berries picked: 12 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3520 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [374, 422, 235, 347, 406, 477, 482, 477, 300]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 14, 7, 11, 16, 3, 7, 14, 16]
	Time taken saving stuff: 0.00s

=== episode:215 Env-steps-taken:55584
 	picked: 26 |actions: {0: 326, 1: 299, 2: 256, 3: 176, 4: 208, 5: 194, 6: 256, 7: 366, 8: 179}
episode: 215/2000 -> reward: 39.01041666666668, steps:2260, time-taken: 1.05min, time-elasped: 366.22min
-> berries picked: 26 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3526 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [380, 424, 237, 347, 403, 478, 480, 476, 301]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 10, 5, 13, 11, 12, 14, 7, 23]
	Time taken saving stuff: 0.00s

=== episode:216 Env-steps-taken:57696
 	picked: 33 |actions: {0: 302, 1: 204, 2: 202, 3: 150, 4: 181, 5: 187, 6: 274, 7: 304, 8: 173}
episode: 216/2000 -> reward: 49.60937500000003, steps:1977, time-taken: 0.93min, time-elasped: 367.15min
-> berries picked: 33 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3548 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [380, 424, 239, 349, 406, 483, 486, 479, 302]
	| approx positives in sample 512: 91
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 8, 8, 2, 11, 7, 19, 17, 11]
	Time taken saving stuff: 0.00s

=== episode:217 Env-steps-taken:60960
 	picked: 44 |actions: {0: 407, 1: 403, 2: 316, 3: 338, 4: 342, 5: 359, 6: 597, 7: 830, 8: 615}
episode: 217/2000 -> reward: 65.9791666666667, steps:4207, time-taken: 1.70min, time-elasped: 368.86min
-> berries picked: 44 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3561 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [385, 423, 239, 350, 414, 481, 485, 481, 303]
	| approx positives in sample 512: 99
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 9, 3, 8, 13, 14, 14, 12, 16]
	Time taken saving stuff: 0.11s

=== episode:218 Env-steps-taken:48672
 	picked: 4 |actions: {0: 60, 1: 65, 2: 44, 3: 29, 4: 42, 5: 39, 6: 126, 7: 79, 8: 157}
episode: 218/2000 -> reward: 3.2708333333333335, steps:641, time-taken: 0.46min, time-elasped: 369.32min
-> berries picked: 4 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3561 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [385, 422, 240, 350, 413, 482, 485, 482, 302]
	| approx positives in sample 512: 83
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 9, 4, 10, 9, 8, 9, 12, 12]
	Time taken saving stuff: 0.01s

=== episode:219 Env-steps-taken:54048
 	picked: 21 |actions: {0: 188, 1: 134, 2: 149, 3: 60, 4: 82, 5: 114, 6: 114, 7: 193, 8: 75}
episode: 219/2000 -> reward: 30.296874999999993, steps:1109, time-taken: 0.69min, time-elasped: 370.01min
-> berries picked: 21 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3573 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [391, 424, 242, 351, 414, 482, 486, 481, 302]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 6, 6, 10, 11, 10, 20, 14, 11]
	Time taken saving stuff: 0.09s

=== episode:220 Env-steps-taken:51648
 	picked: 12 |actions: {0: 251, 1: 240, 2: 178, 3: 166, 4: 228, 5: 204, 6: 347, 7: 326, 8: 286}
episode: 220/2000 -> reward: 18.3125, steps:2226, time-taken: 0.96min, time-elasped: 370.98min
-> berries picked: 12 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3559 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [390, 421, 239, 348, 416, 481, 486, 476, 302]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 7, 5, 5, 10, 17, 7, 12, 20]
	Time taken saving stuff: 0.05s

=== episode:22 Env-steps-taken:67104
 	picked: 66 |actions: {0: 627, 1: 313, 2: 316, 3: 103, 4: 74, 5: 71, 6: 213, 7: 384, 8: 223}

==================================================
eval-episode: 220 -> reward: 97.83333333333329, steps: 2324.0, wall-time: 34.08s
-> berries picked: 66 of 800 | patches-visited: [1, 2, 3, 5] | juice left:-0.00
==================================================


=== episode:221 Env-steps-taken:50592
 	picked: 11 |actions: {0: 203, 1: 120, 2: 151, 3: 111, 4: 140, 5: 128, 6: 242, 7: 279, 8: 337}
episode: 221/2000 -> reward: 12.869791666666666, steps:1711, time-taken: 0.82min, time-elasped: 372.37min
-> berries picked: 11 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3549 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [388, 420, 239, 346, 417, 479, 485, 474, 301]
	| approx positives in sample 512: 88
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 12, 3, 8, 17, 8, 13, 9, 15]
	Time taken saving stuff: 0.10s

=== episode:222 Env-steps-taken:55488
 	picked: 27 |actions: {0: 156, 1: 158, 2: 219, 3: 136, 4: 149, 5: 263, 6: 292, 7: 251, 8: 98}
episode: 222/2000 -> reward: 37.453125, steps:1722, time-taken: 0.91min, time-elasped: 373.28min
-> berries picked: 27 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3559 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [386, 419, 237, 345, 421, 481, 492, 477, 301]
	| approx positives in sample 512: 92
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 7, 4, 11, 9, 12, 13, 9, 17]
	Time taken saving stuff: 0.00s

=== episode:223 Env-steps-taken:56544
 	picked: 28 |actions: {0: 232, 1: 286, 2: 285, 3: 142, 4: 227, 5: 178, 6: 314, 7: 385, 8: 143}
episode: 223/2000 -> reward: 43.89583333333335, steps:2192, time-taken: 1.02min, time-elasped: 374.31min
-> berries picked: 28 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3552 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [387, 417, 229, 345, 420, 482, 490, 479, 303]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 13, 4, 9, 7, 8, 17, 16, 18]
	Time taken saving stuff: 0.03s

=== episode:224 Env-steps-taken:55296
 	picked: 28 |actions: {0: 198, 1: 184, 2: 141, 3: 129, 4: 176, 5: 216, 6: 259, 7: 248, 8: 160}
episode: 224/2000 -> reward: 37.395833333333336, steps:1711, time-taken: 0.85min, time-elasped: 375.16min
-> berries picked: 28 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3562 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [389, 414, 233, 343, 422, 485, 491, 480, 305]
	| approx positives in sample 512: 85
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 6, 7, 5, 13, 12, 5, 16, 13]
	Time taken saving stuff: 0.00s

=== episode:225 Env-steps-taken:57888
 	picked: 41 |actions: {0: 661, 1: 516, 2: 735, 3: 495, 4: 482, 5: 445, 6: 795, 7: 582, 8: 513}
episode: 225/2000 -> reward: 49.1510416666667, steps:5224, time-taken: 1.82min, time-elasped: 376.98min
-> berries picked: 41 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3547 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [389, 408, 232, 341, 421, 489, 488, 477, 302]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 16, 4, 11, 9, 20, 12, 10, 16]
	Time taken saving stuff: 0.02s

=== episode:226 Env-steps-taken:52224
 	picked: 16 |actions: {0: 179, 1: 139, 2: 166, 3: 135, 4: 144, 5: 146, 6: 182, 7: 320, 8: 323}
episode: 226/2000 -> reward: 21.08333333333333, steps:1734, time-taken: 0.82min, time-elasped: 377.80min
-> berries picked: 16 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3545 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [388, 408, 232, 340, 419, 488, 493, 476, 301]
	| approx positives in sample 512: 90
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 8, 6, 3, 5, 16, 17, 6, 24]
	Time taken saving stuff: 0.00s

=== episode:227 Env-steps-taken:48768
 	picked: 3 |actions: {0: 12, 1: 31, 2: 12, 3: 14, 4: 14, 5: 12, 6: 17, 7: 38, 8: 45}
episode: 227/2000 -> reward: 3.828125, steps:195, time-taken: 0.35min, time-elasped: 378.15min
-> berries picked: 3 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3547 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [387, 409, 233, 340, 419, 489, 493, 476, 301]
	| approx positives in sample 512: 84
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 5, 7, 7, 8, 10, 12, 12, 12]
	Time taken saving stuff: 0.01s

=== episode:228 Env-steps-taken:55104
 	picked: 25 |actions: {0: 220, 1: 225, 2: 139, 3: 128, 4: 138, 5: 166, 6: 187, 7: 179, 8: 169}
episode: 228/2000 -> reward: 35.56770833333333, steps:1551, time-taken: 0.75min, time-elasped: 378.90min
-> berries picked: 25 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3553 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [390, 411, 236, 343, 416, 489, 492, 475, 301]
	| approx positives in sample 512: 82
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 7, 3, 11, 5, 11, 12, 7, 17]
	Time taken saving stuff: 0.00s

=== episode:229 Env-steps-taken:49920
 	picked: 6 |actions: {0: 46, 1: 41, 2: 40, 3: 27, 4: 26, 5: 57, 6: 128, 7: 98, 8: 100}
episode: 229/2000 -> reward: 9.656250000000002, steps:563, time-taken: 0.58min, time-elasped: 379.48min
-> berries picked: 6 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3554 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [391, 410, 236, 343, 416, 491, 491, 475, 301]
	| approx positives in sample 512: 94
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 13, 8, 9, 9, 11, 9, 15, 13]
	Time taken saving stuff: 0.10s

=== episode:230 Env-steps-taken:55872
 	picked: 32 |actions: {0: 261, 1: 202, 2: 212, 3: 165, 4: 146, 5: 183, 6: 205, 7: 409, 8: 216}
episode: 230/2000 -> reward: 40.16666666666667, steps:1999, time-taken: 0.92min, time-elasped: 380.40min
-> berries picked: 32 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3559 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [390, 413, 240, 342, 417, 493, 485, 474, 305]
	| approx positives in sample 512: 81
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 6, 11, 9, 7, 6, 13, 11, 10]
	Time taken saving stuff: 0.06s

=== episode:23 Env-steps-taken:52128
 	picked: 15 |actions: {0: 20, 1: 109, 2: 75, 3: 43, 4: 65, 5: 32, 6: 102, 7: 15, 8: 39}

==================================================
eval-episode: 230 -> reward: 20.640624999999996, steps: 500.0, wall-time: 18.85s
-> berries picked: 15 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:231 Env-steps-taken:54720
 	picked: 25 |actions: {0: 332, 1: 362, 2: 286, 3: 235, 4: 201, 5: 248, 6: 355, 7: 534, 8: 312}
episode: 231/2000 -> reward: 33.56770833333333, steps:2865, time-taken: 1.20min, time-elasped: 381.92min
-> berries picked: 25 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3531 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [380, 411, 235, 338, 415, 491, 482, 479, 300]
	| approx positives in sample 512: 83
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 7, 7, 9, 9, 7, 11, 12, 11]
	Time taken saving stuff: 0.00s

=== episode:232 Env-steps-taken:48480
 	picked: 2 |actions: {0: 25, 1: 18, 2: 9, 3: 9, 4: 12, 5: 15, 6: 14, 7: 115, 8: 60}
episode: 232/2000 -> reward: 2.385416666666666, steps:277, time-taken: 0.39min, time-elasped: 382.31min
-> berries picked: 2 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3525 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [381, 410, 235, 337, 414, 490, 481, 477, 300]
	| approx positives in sample 512: 83
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 10, 5, 8, 9, 11, 13, 8, 8]
	Time taken saving stuff: 0.01s

=== episode:233 Env-steps-taken:50208
 	picked: 7 |actions: {0: 32, 1: 60, 2: 31, 3: 21, 4: 45, 5: 52, 6: 29, 7: 73, 8: 36}
episode: 233/2000 -> reward: 11.098958333333336, steps:379, time-taken: 0.45min, time-elasped: 382.76min
-> berries picked: 7 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3528 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [381, 412, 234, 337, 415, 490, 482, 478, 299]
	| approx positives in sample 512: 85
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 12, 6, 11, 9, 6, 10, 12, 12]
	Time taken saving stuff: 0.00s

=== episode:234 Env-steps-taken:52704
 	picked: 16 |actions: {0: 132, 1: 260, 2: 150, 3: 131, 4: 165, 5: 105, 6: 309, 7: 250, 8: 179}
episode: 234/2000 -> reward: 23.583333333333332, steps:1681, time-taken: 0.82min, time-elasped: 383.58min
-> berries picked: 16 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3523 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [382, 409, 235, 334, 415, 488, 484, 478, 298]
	| approx positives in sample 512: 77
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 16, 4, 2, 5, 13, 9, 8, 15]
	Time taken saving stuff: 0.01s

=== episode:235 Env-steps-taken:54336
 	picked: 22 |actions: {0: 159, 1: 244, 2: 171, 3: 129, 4: 67, 5: 110, 6: 107, 7: 228, 8: 165}
episode: 235/2000 -> reward: 31.73958333333333, steps:1380, time-taken: 0.67min, time-elasped: 384.25min
-> berries picked: 22 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3526 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [379, 413, 238, 335, 411, 489, 480, 483, 298]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 13, 9, 14, 10, 12, 12, 6, 15]
	Time taken saving stuff: 0.01s

=== episode:236 Env-steps-taken:50304
 	picked: 9 |actions: {0: 586, 1: 367, 2: 460, 3: 378, 4: 517, 5: 640, 6: 573, 7: 565, 8: 488}
episode: 236/2000 -> reward: 11.484375000000002, steps:4574, time-taken: 1.72min, time-elasped: 385.97min
-> berries picked: 9 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3495 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [375, 406, 229, 330, 409, 491, 479, 479, 297]
	| approx positives in sample 512: 90
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 6, 4, 13, 10, 11, 16, 15, 11]
	Time taken saving stuff: 0.10s

=== episode:237 Env-steps-taken:49632
 	picked: 6 |actions: {0: 66, 1: 89, 2: 34, 3: 32, 4: 48, 5: 60, 6: 60, 7: 124, 8: 39}
episode: 237/2000 -> reward: 8.156249999999998, steps:552, time-taken: 0.41min, time-elasped: 386.39min
-> berries picked: 6 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3499 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [376, 406, 228, 330, 409, 493, 479, 481, 297]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 7, 3, 12, 18, 10, 12, 9, 20]
	Time taken saving stuff: 0.00s

=== episode:238 Env-steps-taken:54720
 	picked: 22 |actions: {0: 200, 1: 149, 2: 115, 3: 165, 4: 122, 5: 112, 6: 140, 7: 283, 8: 244}
episode: 238/2000 -> reward: 34.739583333333336, steps:1530, time-taken: 0.80min, time-elasped: 387.20min
-> berries picked: 22 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3509 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [376, 408, 229, 329, 411, 493, 476, 488, 299]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 9, 6, 6, 13, 11, 11, 16, 11]
	Time taken saving stuff: 0.00s

=== episode:239 Env-steps-taken:55200
 	picked: 26 |actions: {0: 189, 1: 179, 2: 137, 3: 125, 4: 109, 5: 128, 6: 193, 7: 252, 8: 178}
episode: 239/2000 -> reward: 35.567708333333336, steps:1490, time-taken: 0.78min, time-elasped: 387.98min
-> berries picked: 26 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3517 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [377, 407, 229, 331, 411, 495, 477, 488, 302]
	| approx positives in sample 512: 93
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 8, 9, 7, 14, 16, 6, 13, 15]
	Time taken saving stuff: 0.00s

=== episode:240 Env-steps-taken:52416
 	picked: 15 |actions: {0: 184, 1: 277, 2: 140, 3: 97, 4: 112, 5: 129, 6: 157, 7: 118, 8: 197}
episode: 240/2000 -> reward: 22.140624999999996, steps:1411, time-taken: 0.73min, time-elasped: 388.71min
-> berries picked: 15 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3519 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [375, 412, 231, 327, 409, 496, 478, 487, 304]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 11, 3, 8, 9, 14, 9, 12, 18]
	Time taken saving stuff: 0.05s

=== episode:24 Env-steps-taken:51744
 	picked: 13 |actions: {0: 15, 1: 79, 2: 55, 3: 50, 4: 7, 5: 10, 6: 13, 7: 10, 8: 88}

==================================================
eval-episode: 240 -> reward: 18.755208333333332, steps: 327.0, wall-time: 18.75s
-> berries picked: 13 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:241 Env-steps-taken:55296
 	picked: 25 |actions: {0: 230, 1: 239, 2: 152, 3: 181, 4: 67, 5: 121, 6: 201, 7: 142, 8: 195}
episode: 241/2000 -> reward: 38.56770833333334, steps:1528, time-taken: 1.10min, time-elasped: 390.13min
-> berries picked: 25 of 800 | patches-visited: [0, 4, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3531 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [376, 415, 231, 330, 409, 496, 476, 490, 308]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 12, 9, 8, 9, 12, 9, 12, 18]
	Time taken saving stuff: 0.01s

=== episode:242 Env-steps-taken:61920
 	picked: 46 |actions: {0: 214, 1: 270, 2: 288, 3: 201, 4: 206, 5: 172, 6: 263, 7: 403, 8: 250}
episode: 242/2000 -> reward: 70.86458333333336, steps:2267, time-taken: 1.17min, time-elasped: 391.31min
-> berries picked: 46 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3558 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [382, 416, 236, 334, 407, 499, 481, 491, 312]
	| approx positives in sample 512: 95
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 3, 5, 9, 8, 10, 17, 16, 16]
	Time taken saving stuff: 0.00s

=== episode:25 Env-steps-taken:59136
 	picked: 38 |actions: {0: 422, 1: 42, 2: 458, 3: 186, 4: 61, 5: 136, 6: 298, 7: 165, 8: 551}
evalEpisode: 0 -> reward: 56.8229166666667 steps: 2319
-> berries picked: 38 of 800 | patches-visited: [1, 2] | juice left:-0.00
