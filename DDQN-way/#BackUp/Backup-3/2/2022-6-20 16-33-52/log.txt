copied Agent.py to .temp\2022-6-20 16-33-52/pyfiles-backup
copied debugging.py to .temp\2022-6-20 16-33-52/pyfiles-backup/agent_utils/debugging
copied debugging_utils.py to .temp\2022-6-20 16-33-52/pyfiles-backup/agent_utils/debugging
copied __init__.py to .temp\2022-6-20 16-33-52/pyfiles-backup/agent_utils/debugging

copied fubar.py to .temp\2022-6-20 16-33-52/pyfiles-backup/agent_utils/exploration_subroutines
copied random_exploration.py to .temp\2022-6-20 16-33-52/pyfiles-backup/agent_utils/exploration_subroutines
copied random_exploration_v1.py to .temp\2022-6-20 16-33-52/pyfiles-backup/agent_utils/exploration_subroutines
copied skipsteps.py to .temp\2022-6-20 16-33-52/pyfiles-backup/agent_utils/exploration_subroutines/utils
copied __init__.py to .temp\2022-6-20 16-33-52/pyfiles-backup/agent_utils/exploration_subroutines/utils

copied __init__.py to .temp\2022-6-20 16-33-52/pyfiles-backup/agent_utils/exploration_subroutines

copied patch_discovery.py to .temp\2022-6-20 16-33-52/pyfiles-backup/agent_utils/intrinsic_rewards
copied __init__.py to .temp\2022-6-20 16-33-52/pyfiles-backup/agent_utils/intrinsic_rewards

copied plots.py to .temp\2022-6-20 16-33-52/pyfiles-backup/agent_utils/misc
copied printing.py to .temp\2022-6-20 16-33-52/pyfiles-backup/agent_utils/misc
copied __init__.py to .temp\2022-6-20 16-33-52/pyfiles-backup/agent_utils/misc

copied make_net.py to .temp\2022-6-20 16-33-52/pyfiles-backup/agent_utils/nn_utils
copied __init__.py to .temp\2022-6-20 16-33-52/pyfiles-backup/agent_utils/nn_utils

copied berry_worth_function.py to .temp\2022-6-20 16-33-52/pyfiles-backup/agent_utils/state_utils
copied sectorized_states.py to .temp\2022-6-20 16-33-52/pyfiles-backup/agent_utils/state_utils
copied __init__.py to .temp\2022-6-20 16-33-52/pyfiles-backup/agent_utils/state_utils

copied __init__.py to .temp\2022-6-20 16-33-52/pyfiles-backup/agent_utils

copied ensemble.py to .temp\2022-6-20 16-33-52/pyfiles-backup
copied eval.py to .temp\2022-6-20 16-33-52/pyfiles-backup
copied train.py to .temp\2022-6-20 16-33-52/pyfiles-backup
copied utils.py to .temp\2022-6-20 16-33-52/pyfiles-backup/utils/copyfiles
copied __init__.py to .temp\2022-6-20 16-33-52/pyfiles-backup/utils/copyfiles

copied random_env.py to .temp\2022-6-20 16-33-52/pyfiles-backup/utils/env_generation
copied __init__.py to .temp\2022-6-20 16-33-52/pyfiles-backup/utils/env_generation

copied utils.py to .temp\2022-6-20 16-33-52/pyfiles-backup/utils/printing
copied __init__.py to .temp\2022-6-20 16-33-52/pyfiles-backup/utils/printing

copied env_picture.py to .temp\2022-6-20 16-33-52/pyfiles-backup/utils/visualization
copied graphs.py to .temp\2022-6-20 16-33-52/pyfiles-backup/utils/visualization
copied __init__.py to .temp\2022-6-20 16-33-52/pyfiles-backup/utils/visualization

copied __init__.py to .temp\2022-6-20 16-33-52/pyfiles-backup/utils


random_train_env
getBabyEnv :
	 logDir : .temp\2022-6-20 16-33-52
	 initial_juice : 0.5
	 end_on_boundary_hit : False
	 penalize_boundary_hit : False
	 allow_no_action : False
	 no_action_threshold : 0.7
	 add_exploration : True
	 field_size : (20000, 20000)
	 initial_pos_around_berry : True
	 nberries : 80
	 num_patches : 10
	 patch_size : (2600, 2600)
	 patch_with_agent_at_center : True
	 sampling_type : 0
	 seperation : 2400
	 show : False
	 spawn_radius : 100


Agent :
	 self : <Agent.Agent object at 0x000002139DF85F88>
	 berryField : <BerryFieldEnv instance>
	 mode : train
	 angle : 45
	 persistence : 0.8
	 worth_offset : 0.05
	 noise : 0.01
	 nstep_transition : [1]
	 positive_emphasis : 0
	 skipStep : 10
	 reward_patch_discovery : True
	 add_exploration : True
	 time_memory_factor : 0.5
	 time_memory_exp : 1.0
	 time_memory_sizes : [50, 100, 200]
	 render : False
	 debug : False
	 debugDir : .temp
	 device : cuda


total-params:  2034
rewards scaled by 2/(berryField.REWARD_RATE*MAXSIZE)
rewards are clipped between 0 and 2
Exploration subroutine as an action
p_action: 7
Rewarding patch discovery
rewards scaled by 2/(berryField.REWARD_RATE*MAXSIZE)
rewards are clipped between 0 and 2
Exploration subroutine as an action
p_action: 5
Rewarding patch discovery
net(
  (feedforward): ModuleList(
    (0): Linear(in_features=39, out_features=32, bias=True)
    (1): LeakyReLU(negative_slope=0.1)
    (2): Linear(in_features=32, out_features=16, bias=True)
    (3): LeakyReLU(negative_slope=0.1)
  )
  (final_stage): ModuleList(
    (0): Linear(in_features=16, out_features=8, bias=True)
    (1): LeakyReLU(negative_slope=0.1)
  )
  (valueL): Linear(in_features=8, out_features=1, bias=True)
  (actadvs): Linear(in_features=8, out_features=9, bias=True)
)
PrioritizedBuffer of type replace-min
optim = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005
    weight_decay: 0
), num_gradient_steps= 25
optimizing the online-model after every 100 actions
batch size=512, gamma=0.9, alpha=0.95
polyak_tau=0.1, update_freq=5

=== episode:0 Env-steps-taken:48384
 	picked: 1 |actions: {0: 58, 1: 41, 2: 52, 3: 43, 4: 56, 5: 56, 6: 444, 7: 40, 8: 47}
episode: 0/2000 -> reward: 2.4427083333333344, steps:837, time-taken: 0.59min, time-elasped: 0.59min
-> berries picked: 1 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2 | amount-filled: 1.40%
	| action-stats:  [6, 8] [1, 1]
	| approx positives in sample 512: 11
	| approx action-dist in sample 512: [6, 8] [9, 2]
	Time taken saving stuff: 0.06s

=== episode:0 Env-steps-taken:48384
 	picked: 1 |actions: {0: 0, 1: 0, 2: 0, 3: 0, 4: 20, 5: 0, 6: 4379, 7: 0, 8: 0}

==================================================
eval-episode: 0 -> reward: 1.9427083333333341, steps: 4399.0, wall-time: 28.17s
-> berries picked: 1 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:1 Env-steps-taken:49248
 	picked: 6 |actions: {0: 123, 1: 297, 2: 135, 3: 277, 4: 658, 5: 112, 6: 334, 7: 151, 8: 188}
episode: 1/2000 -> reward: 6.656249999999999, steps:2275, time-taken: 1.25min, time-elasped: 2.31min
-> berries picked: 6 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 9 | amount-filled: 5.19%
	| action-stats:  [3, 4, 5, 6, 8] [1, 4, 1, 1, 2]
	| approx positives in sample 512: 14
	| approx action-dist in sample 512: [3, 4, 5, 6, 8] [2, 4, 3, 3, 2]
	Time taken saving stuff: 0.01s

=== episode:2 Env-steps-taken:53760
 	picked: 21 |actions: {0: 384, 1: 320, 2: 194, 3: 406, 4: 817, 5: 331, 6: 363, 7: 557, 8: 211}
episode: 2/2000 -> reward: 28.796874999999993, steps:3583, time-taken: 1.76min, time-elasped: 4.08min
-> berries picked: 21 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 30 | amount-filled: 11.16%
	| action-stats:  [0, 3, 4, 5, 6, 7, 8] [2, 5, 7, 4, 5, 5, 2]
	| approx positives in sample 512: 24
	| approx action-dist in sample 512: [0, 3, 4, 5, 6, 7] [2, 3, 6, 1, 5, 7]
	Time taken saving stuff: 0.01s

=== episode:3 Env-steps-taken:50880
 	picked: 10 |actions: {0: 226, 1: 174, 2: 119, 3: 242, 4: 478, 5: 236, 6: 204, 7: 265, 8: 97}
episode: 3/2000 -> reward: 14.427083333333336, steps:2041, time-taken: 1.17min, time-elasped: 5.25min
-> berries picked: 10 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 40 | amount-filled: 14.56%
	| action-stats:  [0, 3, 4, 5, 6, 7, 8] [4, 5, 8, 7, 6, 8, 2]
	| approx positives in sample 512: 30
	| approx action-dist in sample 512: [0, 4, 5, 6, 7] [1, 7, 7, 11, 4]
	Time taken saving stuff: 0.08s

=== episode:4 Env-steps-taken:50976
 	picked: 8 |actions: {0: 64, 1: 75, 2: 52, 3: 192, 4: 283, 5: 297, 6: 93, 7: 67, 8: 62}
episode: 4/2000 -> reward: 13.598958333333337, steps:1185, time-taken: 0.80min, time-elasped: 6.06min
-> berries picked: 8 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 48 | amount-filled: 16.54%
	| action-stats:  [0, 3, 4, 5, 6, 7, 8] [4, 8, 10, 8, 7, 8, 3]
	| approx positives in sample 512: 28
	| approx action-dist in sample 512: [0, 3, 4, 5, 6, 7] [1, 6, 6, 8, 5, 2]
	Time taken saving stuff: 0.02s

=== episode:5 Env-steps-taken:50496
 	picked: 8 |actions: {0: 300, 1: 423, 2: 341, 3: 527, 4: 550, 5: 440, 6: 651, 7: 426, 8: 299}
episode: 5/2000 -> reward: 13.041666666666668, steps:3957, time-taken: 1.92min, time-elasped: 7.97min
-> berries picked: 8 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 57 | amount-filled: 23.13%
	| action-stats:  [0, 3, 4, 5, 6, 7, 8] [4, 11, 10, 12, 8, 8, 4]
	| approx positives in sample 512: 32
	| approx action-dist in sample 512: [0, 3, 4, 5, 6, 7, 8] [1, 9, 4, 8, 5, 2, 3]
	Time taken saving stuff: 0.00s

=== episode:6 Env-steps-taken:55488
 	picked: 24 |actions: {0: 460, 1: 676, 2: 284, 3: 665, 4: 536, 5: 469, 6: 1139, 7: 378, 8: 438}
episode: 6/2000 -> reward: 37.62500000000001, steps:5045, time-taken: 2.38min, time-elasped: 10.35min
-> berries picked: 24 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 81 | amount-filled: 31.54%
	| action-stats:  [0, 1, 3, 4, 5, 6, 7, 8] [4, 1, 20, 14, 14, 10, 11, 7]
	| approx positives in sample 512: 20
	| approx action-dist in sample 512: [1, 3, 4, 5, 7, 8] [3, 8, 3, 3, 2, 1]
	Time taken saving stuff: 0.01s

=== episode:7 Env-steps-taken:57792
 	picked: 33 |actions: {0: 246, 1: 330, 2: 232, 3: 613, 4: 473, 5: 515, 6: 551, 7: 413, 8: 943}
episode: 7/2000 -> reward: 47.66666666666669, steps:4316, time-taken: 2.11min, time-elasped: 12.47min
-> berries picked: 33 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 114 | amount-filled: 38.73%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 2, 1, 28, 21, 19, 11, 14, 13]
	| approx positives in sample 512: 27
	| approx action-dist in sample 512: [1, 3, 4, 5, 6, 8] [1, 8, 6, 8, 1, 3]
	Time taken saving stuff: 0.00s

=== episode:8 Env-steps-taken:53088
 	picked: 21 |actions: {0: 253, 1: 203, 2: 230, 3: 393, 4: 633, 5: 570, 6: 402, 7: 212, 8: 870}
episode: 8/2000 -> reward: 25.796874999999996, steps:3766, time-taken: 1.99min, time-elasped: 14.46min
-> berries picked: 21 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 136 | amount-filled: 45.01%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 2, 1, 31, 25, 24, 13, 15, 20]
	| approx positives in sample 512: 46
	| approx action-dist in sample 512: [0, 1, 3, 4, 5, 6, 7, 8] [3, 1, 12, 8, 13, 4, 1, 4]
	Time taken saving stuff: 0.00s

=== episode:9 Env-steps-taken:52032
 	picked: 17 |actions: {0: 263, 1: 214, 2: 219, 3: 275, 4: 456, 5: 825, 6: 302, 7: 220, 8: 1048}
episode: 9/2000 -> reward: 20.52604166666666, steps:3822, time-taken: 1.86min, time-elasped: 16.32min
-> berries picked: 17 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 154 | amount-filled: 51.38%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 3, 1, 33, 29, 28, 13, 17, 25]
	| approx positives in sample 512: 30
	| approx action-dist in sample 512: [1, 3, 4, 5, 6, 7, 8] [2, 7, 5, 9, 1, 2, 4]
	Time taken saving stuff: 0.02s

=== episode:10 Env-steps-taken:49632
 	picked: 6 |actions: {0: 187, 1: 278, 2: 118, 3: 131, 4: 191, 5: 179, 6: 281, 7: 127, 8: 537}
episode: 10/2000 -> reward: 8.65625, steps:2029, time-taken: 1.18min, time-elasped: 17.50min
-> berries picked: 6 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 161 | amount-filled: 54.76%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 4, 1, 34, 31, 29, 14, 17, 26]
	| approx positives in sample 512: 37
	| approx action-dist in sample 512: [0, 1, 3, 4, 5, 6, 7, 8] [1, 3, 6, 12, 9, 1, 3, 2]
	Time taken saving stuff: 0.16s

=== episode:1 Env-steps-taken:49152
 	picked: 5 |actions: {0: 5, 1: 574, 2: 0, 3: 28, 4: 86, 5: 9, 6: 35, 7: 32, 8: 681}

==================================================
eval-episode: 10 -> reward: 6.213541666666666, steps: 1450.0, wall-time: 30.93s
-> berries picked: 5 of 800 | patches-visited: [1, 8] | juice left:-0.00
==================================================


=== episode:11 Env-steps-taken:52704
 	picked: 17 |actions: {0: 227, 1: 230, 2: 122, 3: 218, 4: 257, 5: 254, 6: 258, 7: 151, 8: 438}
episode: 11/2000 -> reward: 24.026041666666668, steps:2155, time-taken: 1.36min, time-elasped: 19.38min
-> berries picked: 17 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 179 | amount-filled: 58.35%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 4, 3, 36, 32, 33, 18, 17, 30]
	| approx positives in sample 512: 36
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [1, 2, 1, 4, 8, 11, 2, 3, 4]
	Time taken saving stuff: 0.01s

=== episode:12 Env-steps-taken:53568
 	picked: 19 |actions: {0: 242, 1: 500, 2: 174, 3: 217, 4: 283, 5: 334, 6: 284, 7: 203, 8: 708}
episode: 12/2000 -> reward: 28.41145833333333, steps:2945, time-taken: 1.54min, time-elasped: 20.92min
-> berries picked: 19 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 199 | amount-filled: 63.26%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 5, 3, 39, 35, 37, 21, 19, 34]
	| approx positives in sample 512: 31
	| approx action-dist in sample 512: [0, 1, 3, 4, 5, 7, 8] [1, 2, 5, 6, 7, 4, 6]
	Time taken saving stuff: 0.01s

=== episode:13 Env-steps-taken:55968
 	picked: 27 |actions: {0: 270, 1: 524, 2: 305, 3: 301, 4: 381, 5: 590, 6: 312, 7: 389, 8: 525}
episode: 13/2000 -> reward: 39.95312500000001, steps:3597, time-taken: 1.94min, time-elasped: 22.87min
-> berries picked: 27 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 226 | amount-filled: 69.25%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 5, 4, 41, 45, 43, 25, 22, 35]
	| approx positives in sample 512: 36
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [1, 4, 2, 3, 6, 7, 4, 3, 6]
	Time taken saving stuff: 0.10s

=== episode:14 Env-steps-taken:54528
 	picked: 20 |actions: {0: 228, 1: 315, 2: 171, 3: 250, 4: 299, 5: 301, 6: 341, 7: 433, 8: 715}
episode: 14/2000 -> reward: 32.96875000000001, steps:3053, time-taken: 1.52min, time-elasped: 24.39min
-> berries picked: 20 of 800 | patches-visited: [0, 3, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 247 | amount-filled: 74.34%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 7, 5, 43, 47, 48, 30, 22, 37]
	| approx positives in sample 512: 26
	| approx action-dist in sample 512: [1, 3, 4, 5, 6, 7, 8] [1, 4, 6, 5, 1, 4, 5]
	Time taken saving stuff: 0.00s

=== episode:15 Env-steps-taken:48960
 	picked: 3 |actions: {0: 70, 1: 71, 2: 88, 3: 44, 4: 138, 5: 54, 6: 67, 7: 53, 8: 194}
episode: 15/2000 -> reward: 4.828125, steps:779, time-taken: 0.76min, time-elasped: 25.15min
-> berries picked: 3 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 250 | amount-filled: 75.64%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 7, 5, 43, 50, 48, 30, 22, 37]
	| approx positives in sample 512: 34
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [1, 2, 1, 5, 8, 7, 5, 3, 2]
	Time taken saving stuff: 0.01s

=== episode:16 Env-steps-taken:51072
 	picked: 10 |actions: {0: 514, 1: 504, 2: 419, 3: 300, 4: 276, 5: 277, 6: 282, 7: 481, 8: 792}
episode: 16/2000 -> reward: 15.927083333333334, steps:3845, time-taken: 1.89min, time-elasped: 27.04min
-> berries picked: 10 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 261 | amount-filled: 82.05%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 8, 5, 43, 51, 52, 32, 23, 38]
	| approx positives in sample 512: 34
	| approx action-dist in sample 512: [0, 1, 3, 4, 5, 6, 7, 8] [1, 2, 1, 6, 12, 4, 3, 5]
	Time taken saving stuff: 0.10s

=== episode:17 Env-steps-taken:56448
 	picked: 30 |actions: {0: 550, 1: 493, 2: 640, 3: 279, 4: 511, 5: 290, 6: 296, 7: 610, 8: 469}
episode: 17/2000 -> reward: 42.781250000000014, steps:4138, time-taken: 2.12min, time-elasped: 29.16min
-> berries picked: 30 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 292 | amount-filled: 88.95%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 10, 7, 45, 55, 59, 33, 30, 42]
	| approx positives in sample 512: 22
	| approx action-dist in sample 512: [0, 1, 3, 4, 5, 6, 7, 8] [4, 2, 4, 3, 5, 2, 1, 1]
	Time taken saving stuff: 0.13s

=== episode:18 Env-steps-taken:49728
 	picked: 6 |actions: {0: 19, 1: 34, 2: 119, 3: 17, 4: 53, 5: 38, 6: 25, 7: 32, 8: 26}
episode: 18/2000 -> reward: 8.656249999999998, steps:363, time-taken: 0.58min, time-elasped: 29.75min
-> berries picked: 6 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 298 | amount-filled: 89.55%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 11, 7, 45, 59, 60, 33, 30, 42]
	| approx positives in sample 512: 35
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [2, 1, 2, 6, 7, 9, 3, 1, 4]
	Time taken saving stuff: 0.09s

=== episode:19 Env-steps-taken:54720
 	picked: 21 |actions: {0: 171, 1: 544, 2: 476, 3: 176, 4: 311, 5: 211, 6: 164, 7: 305, 8: 216}
episode: 19/2000 -> reward: 33.796875, steps:2574, time-taken: 1.43min, time-elasped: 31.19min
-> berries picked: 21 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 319 | amount-filled: 93.84%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 17, 11, 46, 64, 62, 34, 32, 42]
	| approx positives in sample 512: 33
	| approx action-dist in sample 512: [0, 1, 3, 4, 5, 6, 8] [3, 3, 3, 6, 11, 4, 3]
	Time taken saving stuff: 0.09s

=== episode:20 Env-steps-taken:55488
 	picked: 29 |actions: {0: 419, 1: 764, 2: 949, 3: 387, 4: 510, 5: 483, 6: 468, 7: 594, 8: 471}
episode: 20/2000 -> reward: 37.33854166666667, steps:5045, time-taken: 2.34min, time-elasped: 33.53min
-> berries picked: 29 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 346 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 24, 15, 48, 72, 65, 34, 34, 42]
	| approx positives in sample 512: 25
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 7, 8] [2, 3, 3, 2, 5, 2, 5, 3]
	Time taken saving stuff: 0.17s

=== episode:2 Env-steps-taken:65568
 	picked: 60 |actions: {0: 45, 1: 635, 2: 2347, 3: 119, 4: 532, 5: 372, 6: 1372, 7: 387, 8: 152}

==================================================
eval-episode: 20 -> reward: 88.56249999999997, steps: 5961.0, wall-time: 53.12s
-> berries picked: 60 of 800 | patches-visited: [1, 6] | juice left:-0.00
==================================================


=== episode:21 Env-steps-taken:52992
 	picked: 18 |actions: {0: 371, 1: 711, 2: 913, 3: 297, 4: 572, 5: 315, 6: 659, 7: 700, 8: 280}
episode: 21/2000 -> reward: 24.968750000000004, steps:4818, time-taken: 2.33min, time-elasped: 36.75min
-> berries picked: 18 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 360 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 26, 19, 48, 75, 68, 35, 35, 42]
	| approx positives in sample 512: 36
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [1, 4, 3, 4, 4, 12, 3, 3, 2]
	Time taken saving stuff: 0.11s

=== episode:22 Env-steps-taken:55104
 	picked: 25 |actions: {0: 218, 1: 274, 2: 589, 3: 167, 4: 186, 5: 220, 6: 187, 7: 321, 8: 114}
episode: 22/2000 -> reward: 36.067708333333336, steps:2276, time-taken: 1.30min, time-elasped: 38.06min
-> berries picked: 25 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 385 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 28, 22, 48, 79, 75, 36, 39, 45]
	| approx positives in sample 512: 37
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [2, 4, 3, 4, 8, 7, 3, 2, 4]
	Time taken saving stuff: 0.01s

=== episode:23 Env-steps-taken:52320
 	picked: 17 |actions: {0: 234, 1: 298, 2: 1231, 3: 272, 4: 396, 5: 416, 6: 561, 7: 539, 8: 232}
episode: 23/2000 -> reward: 21.52604166666666, steps:4179, time-taken: 1.90min, time-elasped: 39.96min
-> berries picked: 17 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 401 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 29, 26, 49, 85, 79, 35, 40, 45]
	| approx positives in sample 512: 36
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 7, 8] [2, 6, 1, 3, 8, 9, 4, 3]
	Time taken saving stuff: 0.01s

=== episode:24 Env-steps-taken:56928
 	picked: 33 |actions: {0: 477, 1: 418, 2: 731, 3: 287, 4: 535, 5: 365, 6: 487, 7: 573, 8: 265}
episode: 24/2000 -> reward: 45.109375000000014, steps:4138, time-taken: 1.94min, time-elasped: 41.91min
-> berries picked: 33 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 433 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 31, 29, 51, 96, 83, 37, 43, 46]
	| approx positives in sample 512: 40
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7, 8] [6, 3, 4, 9, 6, 4, 5, 3]
	Time taken saving stuff: 0.10s

=== episode:25 Env-steps-taken:61824
 	picked: 49 |actions: {0: 375, 1: 344, 2: 446, 3: 290, 4: 370, 5: 328, 6: 212, 7: 610, 8: 217}
episode: 25/2000 -> reward: 69.69270833333336, steps:3192, time-taken: 1.70min, time-elasped: 43.61min
-> berries picked: 49 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 483 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [22, 37, 33, 53, 107, 91, 43, 49, 48]
	| approx positives in sample 512: 41
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 1, 2, 1, 9, 5, 6, 5, 7]
	Time taken saving stuff: 0.02s

=== episode:26 Env-steps-taken:60384
 	picked: 46 |actions: {0: 488, 1: 404, 2: 596, 3: 248, 4: 496, 5: 385, 6: 225, 7: 539, 8: 190}
episode: 26/2000 -> reward: 61.86458333333339, steps:3571, time-taken: 1.65min, time-elasped: 45.27min
-> berries picked: 46 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 525 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [24, 44, 38, 56, 120, 97, 43, 55, 48]
	| approx positives in sample 512: 43
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [2, 5, 1, 3, 8, 7, 8, 6, 3]
	Time taken saving stuff: 0.08s

=== episode:27 Env-steps-taken:64896
 	picked: 59 |actions: {0: 663, 1: 438, 2: 907, 3: 355, 4: 765, 5: 571, 6: 324, 7: 694, 8: 323}
episode: 27/2000 -> reward: 85.11979166666666, steps:5040, time-taken: 2.49min, time-elasped: 47.76min
-> berries picked: 59 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 584 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [27, 49, 48, 56, 135, 115, 44, 61, 49]
	| approx positives in sample 512: 39
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 7, 8] [3, 1, 6, 1, 12, 8, 5, 3]
	Time taken saving stuff: 0.04s

=== episode:28 Env-steps-taken:65280
 	picked: 61 |actions: {0: 650, 1: 550, 2: 824, 3: 335, 4: 665, 5: 437, 6: 334, 7: 635, 8: 352}
episode: 28/2000 -> reward: 83.11979166666666, steps:4782, time-taken: 2.37min, time-elasped: 50.14min
-> berries picked: 61 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 641 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [28, 54, 58, 56, 159, 122, 47, 65, 52]
	| approx positives in sample 512: 33
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 1, 1, 3, 10, 6, 2, 4, 2]
	Time taken saving stuff: 0.09s

=== episode:29 Env-steps-taken:60384
 	picked: 46 |actions: {0: 277, 1: 415, 2: 468, 3: 221, 4: 351, 5: 247, 6: 198, 7: 407, 8: 230}
episode: 29/2000 -> reward: 61.864583333333385, steps:2814, time-taken: 1.60min, time-elasped: 51.75min
-> berries picked: 46 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 686 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [35, 63, 60, 58, 172, 127, 48, 70, 53]
	| approx positives in sample 512: 51
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 7, 8] [1, 9, 6, 4, 14, 7, 7, 3]
	Time taken saving stuff: 0.09s

=== episode:30 Env-steps-taken:62880
 	picked: 46 |actions: {0: 658, 1: 532, 2: 418, 3: 267, 4: 589, 5: 310, 6: 248, 7: 491, 8: 240}
episode: 30/2000 -> reward: 75.86458333333333, steps:3753, time-taken: 1.94min, time-elasped: 53.70min
-> berries picked: 46 of 800 | patches-visited: [0, 1, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 732 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [40, 71, 67, 60, 182, 132, 49, 75, 56]
	| approx positives in sample 512: 45
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 7, 4, 3, 8, 9, 2, 5, 3]
	Time taken saving stuff: 0.17s

=== episode:3 Env-steps-taken:56640
 	picked: 29 |actions: {0: 134, 1: 126, 2: 803, 3: 1111, 4: 750, 5: 57, 6: 49, 7: 2119, 8: 1}

==================================================
eval-episode: 30 -> reward: 43.33854166666668, steps: 5150.0, wall-time: 54.05s
-> berries picked: 29 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:31 Env-steps-taken:64512
 	picked: 59 |actions: {0: 700, 1: 556, 2: 879, 3: 513, 4: 677, 5: 447, 6: 460, 7: 608, 8: 348}
episode: 31/2000 -> reward: 83.11979166666664, steps:5188, time-taken: 2.40min, time-elasped: 57.01min
-> berries picked: 59 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 789 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [47, 74, 72, 66, 195, 135, 58, 84, 58]
	| approx positives in sample 512: 45
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [2, 1, 6, 3, 14, 6, 3, 5, 5]
	Time taken saving stuff: 0.00s

=== episode:32 Env-steps-taken:57792
 	picked: 34 |actions: {0: 444, 1: 292, 2: 436, 3: 389, 4: 342, 5: 261, 6: 367, 7: 324, 8: 264}
episode: 32/2000 -> reward: 49.052083333333364, steps:3119, time-taken: 1.79min, time-elasped: 58.81min
-> berries picked: 34 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 815 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [53, 77, 75, 65, 197, 145, 60, 84, 59]
	| approx positives in sample 512: 59
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 6, 1, 5, 10, 11, 8, 5, 4]
	Time taken saving stuff: 0.02s

=== episode:33 Env-steps-taken:67488
 	picked: 69 |actions: {0: 644, 1: 566, 2: 755, 3: 459, 4: 550, 5: 456, 6: 556, 7: 731, 8: 437}
episode: 33/2000 -> reward: 98.04687499999994, steps:5154, time-taken: 2.49min, time-elasped: 61.30min
-> berries picked: 69 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 878 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [63, 79, 84, 69, 205, 154, 65, 98, 61]
	| approx positives in sample 512: 46
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 3, 7, 3, 9, 5, 1, 11, 3]
	Time taken saving stuff: 0.01s

=== episode:34 Env-steps-taken:62976
 	picked: 59 |actions: {0: 733, 1: 459, 2: 676, 3: 447, 4: 506, 5: 460, 6: 619, 7: 518, 8: 598}
episode: 34/2000 -> reward: 74.61979166666669, steps:5016, time-taken: 2.45min, time-elasped: 63.76min
-> berries picked: 59 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 932 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [73, 84, 88, 71, 220, 168, 64, 102, 62]
	| approx positives in sample 512: 53
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 7, 3, 2, 13, 8, 3, 5, 6]
	Time taken saving stuff: 0.10s

=== episode:35 Env-steps-taken:56160
 	picked: 27 |actions: {0: 393, 1: 397, 2: 550, 3: 297, 4: 221, 5: 275, 6: 292, 7: 338, 8: 302}
episode: 35/2000 -> reward: 41.453125000000014, steps:3065, time-taken: 1.69min, time-elasped: 65.45min
-> berries picked: 27 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 955 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [80, 84, 94, 72, 221, 172, 64, 105, 63]
	| approx positives in sample 512: 54
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 6, 8, 3, 13, 7, 2, 3, 7]
	Time taken saving stuff: 0.09s

=== episode:36 Env-steps-taken:57600
 	picked: 33 |actions: {0: 331, 1: 194, 2: 509, 3: 292, 4: 292, 5: 257, 6: 365, 7: 322, 8: 318}
episode: 36/2000 -> reward: 48.60937500000002, steps:2880, time-taken: 1.56min, time-elasped: 67.01min
-> berries picked: 33 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 984 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [82, 86, 99, 72, 229, 175, 66, 109, 66]
	| approx positives in sample 512: 55
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 5, 5, 3, 17, 6, 1, 6, 5]
	Time taken saving stuff: 0.11s

=== episode:37 Env-steps-taken:65280
 	picked: 69 |actions: {0: 979, 1: 508, 2: 744, 3: 650, 4: 532, 5: 492, 6: 769, 7: 654, 8: 607}
episode: 37/2000 -> reward: 86.04687499999994, steps:5935, time-taken: 2.86min, time-elasped: 69.88min
-> berries picked: 69 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1046 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [94, 91, 105, 76, 239, 184, 73, 116, 68]
	| approx positives in sample 512: 61
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 5, 10, 6, 12, 8, 5, 5, 3]
	Time taken saving stuff: 0.10s

=== episode:38 Env-steps-taken:67776
 	picked: 73 |actions: {0: 777, 1: 396, 2: 661, 3: 362, 4: 462, 5: 584, 6: 785, 7: 574, 8: 631}
episode: 38/2000 -> reward: 99.31770833333326, steps:5232, time-taken: 2.47min, time-elasped: 72.35min
-> berries picked: 73 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1108 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [107, 99, 109, 77, 249, 193, 77, 125, 72]
	| approx positives in sample 512: 73
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 6, 13, 7, 13, 11, 3, 7, 3]
	Time taken saving stuff: 0.08s

=== episode:39 Env-steps-taken:67296
 	picked: 69 |actions: {0: 684, 1: 464, 2: 888, 3: 529, 4: 458, 5: 616, 6: 615, 7: 614, 8: 536}
episode: 39/2000 -> reward: 97.04687499999994, steps:5404, time-taken: 2.74min, time-elasped: 75.09min
-> berries picked: 69 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1169 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [116, 104, 121, 79, 258, 201, 81, 134, 75]
	| approx positives in sample 512: 67
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 7, 5, 7, 9, 10, 5, 8, 4]
	Time taken saving stuff: 0.02s

=== episode:40 Env-steps-taken:64704
 	picked: 60 |actions: {0: 580, 1: 339, 2: 583, 3: 394, 4: 404, 5: 653, 6: 432, 7: 456, 8: 540}
episode: 40/2000 -> reward: 84.06249999999997, steps:4381, time-taken: 2.21min, time-elasped: 77.31min
-> berries picked: 60 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1225 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [129, 110, 129, 78, 266, 206, 86, 143, 78]
	| approx positives in sample 512: 76
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 6, 13, 4, 13, 10, 2, 9, 6]
	Time taken saving stuff: 0.14s

=== episode:4 Env-steps-taken:55776
 	picked: 26 |actions: {0: 158, 1: 185, 2: 98, 3: 1956, 4: 34, 5: 35, 6: 59, 7: 1903, 8: 190}

==================================================
eval-episode: 40 -> reward: 39.510416666666664, steps: 4618.0, wall-time: 45.18s
-> berries picked: 26 of 800 | patches-visited: [1, 7] | juice left:-0.00
==================================================


=== episode:41 Env-steps-taken:67104
 	picked: 69 |actions: {0: 630, 1: 697, 2: 756, 3: 688, 4: 494, 5: 575, 6: 527, 7: 612, 8: 541}
episode: 41/2000 -> reward: 96.04687499999997, steps:5520, time-taken: 2.74min, time-elasped: 80.81min
-> berries picked: 69 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1282 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [140, 116, 135, 80, 273, 217, 89, 153, 79]
	| approx positives in sample 512: 77
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 8, 10, 2, 19, 10, 7, 9, 2]
	Time taken saving stuff: 0.05s

=== episode:42 Env-steps-taken:64992
 	picked: 69 |actions: {0: 727, 1: 887, 2: 565, 3: 507, 4: 398, 5: 861, 6: 649, 7: 757, 8: 540}
episode: 42/2000 -> reward: 84.54687499999997, steps:5891, time-taken: 2.80min, time-elasped: 83.61min
-> berries picked: 69 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1340 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [153, 130, 139, 80, 280, 223, 89, 167, 79]
	| approx positives in sample 512: 61
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 12, 6, 3, 12, 5, 3, 9, 3]
	Time taken saving stuff: 0.01s

=== episode:43 Env-steps-taken:62784
 	picked: 60 |actions: {0: 596, 1: 613, 2: 549, 3: 540, 4: 545, 5: 877, 6: 684, 7: 710, 8: 594}
episode: 43/2000 -> reward: 73.56250000000001, steps:5708, time-taken: 2.72min, time-elasped: 86.33min
-> berries picked: 60 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1386 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [156, 136, 140, 83, 285, 228, 95, 183, 80]
	| approx positives in sample 512: 82
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 4, 12, 6, 14, 13, 5, 9, 5]
	Time taken saving stuff: 0.10s

=== episode:44 Env-steps-taken:72864
 	picked: 90 |actions: {0: 533, 1: 670, 2: 761, 3: 537, 4: 584, 5: 853, 6: 808, 7: 772, 8: 645}
episode: 44/2000 -> reward: 124.84374999999986, steps:6163, time-taken: 2.96min, time-elasped: 89.30min
-> berries picked: 90 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1458 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [166, 146, 144, 83, 303, 233, 99, 203, 81]
	| approx positives in sample 512: 71
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 9, 6, 2, 13, 12, 4, 8, 1]
	Time taken saving stuff: 0.02s

=== episode:45 Env-steps-taken:61152
 	picked: 54 |actions: {0: 394, 1: 487, 2: 631, 3: 355, 4: 455, 5: 617, 6: 504, 7: 413, 8: 579}
episode: 45/2000 -> reward: 65.90625000000006, steps:4435, time-taken: 2.30min, time-elasped: 91.61min
-> berries picked: 54 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1507 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [176, 156, 151, 84, 312, 236, 100, 209, 83]
	| approx positives in sample 512: 76
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 10, 11, 5, 13, 9, 7, 12, 4]
	Time taken saving stuff: 0.01s

=== episode:46 Env-steps-taken:65664
 	picked: 67 |actions: {0: 428, 1: 632, 2: 605, 3: 395, 4: 629, 5: 540, 6: 849, 7: 566, 8: 541}
episode: 46/2000 -> reward: 88.66145833333329, steps:5185, time-taken: 3.65min, time-elasped: 95.26min
-> berries picked: 67 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1562 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [181, 162, 156, 85, 320, 240, 106, 224, 88]
	| approx positives in sample 512: 74
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 5, 12, 5, 14, 12, 2, 10, 5]
	Time taken saving stuff: 0.01s

=== episode:47 Env-steps-taken:64320
 	picked: 67 |actions: {0: 445, 1: 663, 2: 596, 3: 453, 4: 460, 5: 1040, 6: 830, 7: 613, 8: 669}
episode: 47/2000 -> reward: 81.16145833333333, steps:5769, time-taken: 2.67min, time-elasped: 97.93min
-> berries picked: 67 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1609 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [188, 167, 159, 86, 325, 246, 113, 236, 89]
	| approx positives in sample 512: 83
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 15, 2, 6, 18, 9, 4, 17, 2]
	Time taken saving stuff: 0.00s

=== episode:48 Env-steps-taken:63552
 	picked: 62 |actions: {0: 389, 1: 577, 2: 545, 3: 473, 4: 528, 5: 816, 6: 560, 7: 553, 8: 484}
episode: 48/2000 -> reward: 77.44791666666664, steps:4925, time-taken: 2.29min, time-elasped: 100.23min
-> berries picked: 62 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1657 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [192, 171, 162, 93, 331, 254, 116, 247, 91]
	| approx positives in sample 512: 95
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 10, 10, 7, 12, 15, 3, 12, 7]
	Time taken saving stuff: 0.01s

=== episode:49 Env-steps-taken:66528
 	picked: 71 |actions: {0: 447, 1: 613, 2: 825, 3: 561, 4: 548, 5: 634, 6: 658, 7: 554, 8: 508}
episode: 49/2000 -> reward: 92.93229166666661, steps:5348, time-taken: 2.52min, time-elasped: 102.75min
-> berries picked: 71 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1713 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [197, 179, 171, 95, 340, 259, 120, 260, 92]
	| approx positives in sample 512: 79
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 7, 7, 4, 22, 10, 9, 4, 5]
	Time taken saving stuff: 0.00s

=== episode:50 Env-steps-taken:62208
 	picked: 63 |actions: {0: 511, 1: 676, 2: 520, 3: 380, 4: 421, 5: 709, 6: 655, 7: 509, 8: 542}
episode: 50/2000 -> reward: 70.390625, steps:4923, time-taken: 2.37min, time-elasped: 105.12min
-> berries picked: 63 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1761 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [212, 186, 174, 98, 344, 265, 120, 267, 95]
	| approx positives in sample 512: 75
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 7, 10, 5, 12, 7, 6, 15, 5]
	Time taken saving stuff: 0.06s

=== episode:5 Env-steps-taken:82848
 	picked: 132 |actions: {0: 346, 1: 781, 2: 1259, 3: 170, 4: 755, 5: 732, 6: 947, 7: 611, 8: 503}

==================================================
eval-episode: 50 -> reward: 174.93750000000014, steps: 6104.0, wall-time: 52.06s
-> berries picked: 132 of 800 | patches-visited: [1, 5, 9] | juice left:-0.00
==================================================


=== episode:51 Env-steps-taken:74400
 	picked: 94 |actions: {0: 635, 1: 822, 2: 809, 3: 528, 4: 599, 5: 583, 6: 1009, 7: 571, 8: 654}
episode: 51/2000 -> reward: 131.34374999999986, steps:6210, time-taken: 2.80min, time-elasped: 108.79min
-> berries picked: 94 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1830 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [226, 193, 178, 104, 362, 269, 131, 269, 98]
	| approx positives in sample 512: 91
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 8, 11, 11, 15, 9, 10, 11, 7]
	Time taken saving stuff: 0.00s

=== episode:52 Env-steps-taken:72576
 	picked: 83 |actions: {0: 671, 1: 937, 2: 878, 3: 515, 4: 528, 5: 703, 6: 831, 7: 641, 8: 603}
episode: 52/2000 -> reward: 119.91666666666654, steps:6307, time-taken: 3.97min, time-elasped: 112.77min
-> berries picked: 83 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1884 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [239, 205, 181, 107, 371, 269, 137, 276, 99]
	| approx positives in sample 512: 76
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 14, 11, 6, 8, 3, 4, 14, 5]
	Time taken saving stuff: 0.01s

=== episode:53 Env-steps-taken:68640
 	picked: 74 |actions: {0: 583, 1: 731, 2: 842, 3: 573, 4: 535, 5: 826, 6: 765, 7: 635, 8: 460}
episode: 53/2000 -> reward: 102.87499999999991, steps:5950, time-taken: 2.91min, time-elasped: 115.73min
-> berries picked: 74 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1933 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [252, 207, 185, 115, 366, 283, 142, 284, 99]
	| approx positives in sample 512: 96
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 14, 13, 11, 9, 10, 5, 16, 5]
	Time taken saving stuff: 0.01s

=== episode:54 Env-steps-taken:63936
 	picked: 60 |actions: {0: 466, 1: 483, 2: 635, 3: 425, 4: 370, 5: 847, 6: 679, 7: 481, 8: 452}
episode: 54/2000 -> reward: 77.67708333333334, steps:4838, time-taken: 2.23min, time-elasped: 117.96min
-> berries picked: 60 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 1979 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [257, 213, 187, 124, 368, 293, 146, 291, 100]
	| approx positives in sample 512: 85
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 11, 11, 8, 14, 10, 3, 13, 5]
	Time taken saving stuff: 0.01s

=== episode:55 Env-steps-taken:62496
 	picked: 52 |actions: {0: 427, 1: 625, 2: 691, 3: 613, 4: 869, 5: 730, 6: 722, 7: 536, 8: 469}
episode: 55/2000 -> reward: 72.52083333333337, steps:5682, time-taken: 2.49min, time-elasped: 120.45min
-> berries picked: 52 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2022 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [259, 216, 188, 129, 378, 302, 154, 294, 102]
	| approx positives in sample 512: 82
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 15, 9, 3, 18, 8, 2, 7, 10]
	Time taken saving stuff: 0.00s

=== episode:56 Env-steps-taken:62208
 	picked: 50 |actions: {0: 324, 1: 398, 2: 426, 3: 337, 4: 383, 5: 477, 6: 550, 7: 376, 8: 453}
episode: 56/2000 -> reward: 71.63541666666666, steps:3724, time-taken: 1.81min, time-elasped: 122.27min
-> berries picked: 50 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2062 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [263, 222, 190, 135, 388, 308, 155, 296, 105]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 10, 13, 8, 15, 15, 9, 10, 9]
	Time taken saving stuff: 0.00s

=== episode:57 Env-steps-taken:62016
 	picked: 58 |actions: {0: 474, 1: 551, 2: 704, 3: 585, 4: 614, 5: 968, 6: 636, 7: 453, 8: 587}
episode: 57/2000 -> reward: 69.67708333333334, steps:5572, time-taken: 2.52min, time-elasped: 124.79min
-> berries picked: 58 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2097 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [265, 224, 192, 141, 395, 316, 160, 298, 106]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 23, 13, 5, 19, 15, 10, 11, 10]
	Time taken saving stuff: 0.11s

=== episode:58 Env-steps-taken:64512
 	picked: 65 |actions: {0: 500, 1: 533, 2: 613, 3: 644, 4: 647, 5: 776, 6: 519, 7: 461, 8: 566}
episode: 58/2000 -> reward: 82.27604166666666, steps:5259, time-taken: 2.32min, time-elasped: 127.12min
-> berries picked: 65 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2139 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [270, 227, 195, 147, 404, 327, 159, 301, 109]
	| approx positives in sample 512: 92
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 15, 13, 7, 10, 7, 5, 17, 5]
	Time taken saving stuff: 0.01s

=== episode:59 Env-steps-taken:51168
 	picked: 10 |actions: {0: 116, 1: 181, 2: 130, 3: 139, 4: 132, 5: 109, 6: 106, 7: 89, 8: 135}
episode: 59/2000 -> reward: 15.927083333333337, steps:1137, time-taken: 0.75min, time-elasped: 127.88min
-> berries picked: 10 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2138 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [269, 228, 196, 148, 404, 326, 160, 298, 109]
	| approx positives in sample 512: 95
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 12, 17, 4, 17, 12, 7, 9, 8]
	Time taken saving stuff: 0.01s

=== episode:60 Env-steps-taken:64608
 	picked: 62 |actions: {0: 440, 1: 518, 2: 935, 3: 691, 4: 717, 5: 670, 6: 527, 7: 498, 8: 618}
episode: 60/2000 -> reward: 81.00520833333329, steps:5614, time-taken: 2.54min, time-elasped: 130.42min
-> berries picked: 62 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2183 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [272, 231, 198, 158, 414, 332, 166, 303, 109]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 14, 16, 9, 21, 9, 7, 17, 8]
	Time taken saving stuff: 0.06s

=== episode:6 Env-steps-taken:66624
 	picked: 72 |actions: {0: 733, 1: 120, 2: 1630, 3: 116, 4: 334, 5: 1310, 6: 596, 7: 438, 8: 243}

==================================================
eval-episode: 60 -> reward: 93.37499999999996, steps: 5520.0, wall-time: 49.04s
-> berries picked: 72 of 800 | patches-visited: [0, 1] | juice left:-0.00
==================================================


=== episode:61 Env-steps-taken:62688
 	picked: 54 |actions: {0: 353, 1: 410, 2: 545, 3: 416, 4: 691, 5: 503, 6: 554, 7: 271, 8: 276}
episode: 61/2000 -> reward: 74.40625, steps:4019, time-taken: 1.76min, time-elasped: 133.00min
-> berries picked: 54 of 800 | patches-visited: [0, 8, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2225 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [275, 232, 202, 159, 427, 341, 172, 304, 113]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 14, 10, 9, 17, 14, 8, 21, 6]
	Time taken saving stuff: 0.11s

=== episode:62 Env-steps-taken:70080
 	picked: 85 |actions: {0: 616, 1: 663, 2: 734, 3: 554, 4: 701, 5: 605, 6: 583, 7: 546, 8: 479}
episode: 62/2000 -> reward: 110.24479166666656, steps:5481, time-taken: 2.36min, time-elasped: 135.37min
-> berries picked: 85 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2288 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [292, 232, 207, 164, 438, 353, 175, 311, 116]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 15, 15, 13, 19, 12, 13, 11, 11]
	Time taken saving stuff: 0.01s

=== episode:63 Env-steps-taken:62304
 	picked: 56 |actions: {0: 450, 1: 541, 2: 823, 3: 547, 4: 886, 5: 797, 6: 567, 7: 481, 8: 515}
episode: 63/2000 -> reward: 71.29166666666669, steps:5607, time-taken: 2.21min, time-elasped: 137.58min
-> berries picked: 56 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2322 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [304, 232, 209, 168, 445, 360, 176, 311, 117]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 19, 13, 11, 20, 13, 9, 17, 6]
	Time taken saving stuff: 0.11s

=== episode:64 Env-steps-taken:58752
 	picked: 40 |actions: {0: 483, 1: 578, 2: 641, 3: 476, 4: 794, 5: 535, 6: 588, 7: 424, 8: 586}
episode: 64/2000 -> reward: 53.70833333333337, steps:5105, time-taken: 2.22min, time-elasped: 139.81min
-> berries picked: 40 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2342 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [309, 232, 208, 167, 450, 365, 179, 314, 118]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [21, 22, 12, 10, 15, 8, 9, 12, 7]
	Time taken saving stuff: 0.10s

=== episode:65 Env-steps-taken:69024
 	picked: 83 |actions: {0: 705, 1: 626, 2: 715, 3: 412, 4: 847, 5: 724, 6: 727, 7: 651, 8: 429}
episode: 65/2000 -> reward: 105.24479166666657, steps:5836, time-taken: 2.45min, time-elasped: 142.26min
-> berries picked: 83 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2400 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [317, 235, 211, 171, 462, 376, 184, 325, 119]
	| approx positives in sample 512: 84
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 14, 14, 7, 8, 7, 6, 8, 9]
	Time taken saving stuff: 0.09s

=== episode:66 Env-steps-taken:55488
 	picked: 24 |actions: {0: 124, 1: 149, 2: 237, 3: 175, 4: 231, 5: 123, 6: 128, 7: 167, 8: 126}
episode: 66/2000 -> reward: 38.125000000000014, steps:1460, time-taken: 0.85min, time-elasped: 143.12min
-> berries picked: 24 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2419 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [319, 236, 211, 173, 468, 377, 184, 330, 121]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 13, 12, 9, 15, 17, 9, 14, 8]
	Time taken saving stuff: 0.02s

=== episode:67 Env-steps-taken:64800
 	picked: 65 |actions: {0: 503, 1: 595, 2: 631, 3: 516, 4: 1213, 5: 636, 6: 524, 7: 577, 8: 561}
episode: 67/2000 -> reward: 83.8333333333333, steps:5756, time-taken: 2.35min, time-elasped: 145.48min
-> berries picked: 65 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2447 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [324, 239, 212, 174, 476, 380, 181, 337, 124]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 16, 14, 6, 15, 19, 7, 5, 10]
	Time taken saving stuff: 0.09s

=== episode:68 Env-steps-taken:49536
 	picked: 8 |actions: {0: 137, 1: 213, 2: 179, 3: 218, 4: 231, 5: 115, 6: 191, 7: 95, 8: 238}
episode: 68/2000 -> reward: 7.541666666666667, steps:1617, time-taken: 0.90min, time-elasped: 146.38min
-> berries picked: 8 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2446 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [326, 239, 212, 176, 475, 375, 181, 338, 124]
	| approx positives in sample 512: 101
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 9, 15, 9, 15, 13, 8, 11, 6]
	Time taken saving stuff: 0.00s

=== episode:69 Env-steps-taken:63744
 	picked: 54 |actions: {0: 343, 1: 318, 2: 421, 3: 365, 4: 494, 5: 459, 6: 350, 7: 370, 8: 257}
episode: 69/2000 -> reward: 79.40624999999999, steps:3377, time-taken: 1.65min, time-elasped: 148.03min
-> berries picked: 54 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2476 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [332, 242, 212, 183, 479, 380, 179, 343, 126]
	| approx positives in sample 512: 99
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 16, 5, 5, 16, 12, 6, 16, 8]
	Time taken saving stuff: 0.11s

=== episode:70 Env-steps-taken:66528
 	picked: 66 |actions: {0: 413, 1: 512, 2: 586, 3: 442, 4: 645, 5: 564, 6: 428, 7: 423, 8: 469}
episode: 70/2000 -> reward: 93.71874999999996, steps:4482, time-taken: 2.04min, time-elasped: 150.08min
-> berries picked: 66 of 800 | patches-visited: [0, 5, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2512 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [338, 249, 213, 188, 484, 378, 182, 350, 130]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 15, 12, 10, 21, 10, 7, 15, 7]
	Time taken saving stuff: 0.13s

=== episode:7 Env-steps-taken:51360
 	picked: 11 |actions: {0: 57, 1: 40, 2: 58, 3: 2203, 4: 69, 5: 10, 6: 4, 7: 2211, 8: 18}

==================================================
eval-episode: 70 -> reward: 16.869791666666668, steps: 4670.0, wall-time: 44.50s
-> berries picked: 11 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:71 Env-steps-taken:61824
 	picked: 50 |actions: {0: 558, 1: 619, 2: 774, 3: 516, 4: 978, 5: 578, 6: 495, 7: 519, 8: 549}
episode: 71/2000 -> reward: 69.1354166666667, steps:5586, time-taken: 2.36min, time-elasped: 153.18min
-> berries picked: 50 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2519 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [339, 252, 216, 193, 489, 375, 185, 341, 129]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 12, 15, 11, 17, 15, 5, 12, 8]
	Time taken saving stuff: 0.06s

=== episode:72 Env-steps-taken:63648
 	picked: 52 |actions: {0: 645, 1: 643, 2: 880, 3: 495, 4: 806, 5: 713, 6: 608, 7: 474, 8: 517}
episode: 72/2000 -> reward: 76.75000000000001, steps:5781, time-taken: 3.28min, time-elasped: 156.47min
-> berries picked: 52 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2522 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [340, 258, 218, 196, 482, 371, 189, 339, 129]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 13, 19, 11, 21, 10, 7, 19, 11]
	Time taken saving stuff: 0.01s

=== episode:73 Env-steps-taken:70464
 	picked: 80 |actions: {0: 587, 1: 693, 2: 884, 3: 632, 4: 735, 5: 726, 6: 587, 7: 624, 8: 643}
episode: 73/2000 -> reward: 112.03124999999987, steps:6111, time-taken: 8.25min, time-elasped: 164.73min
-> berries picked: 80 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2574 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [351, 266, 222, 197, 489, 376, 193, 346, 134]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 21, 14, 13, 20, 16, 6, 17, 5]
	Time taken saving stuff: 0.01s

=== episode:74 Env-steps-taken:63648
 	picked: 60 |actions: {0: 412, 1: 576, 2: 688, 3: 476, 4: 826, 5: 526, 6: 430, 7: 477, 8: 557}
episode: 74/2000 -> reward: 78.0625, steps:4968, time-taken: 1.75min, time-elasped: 166.49min
-> berries picked: 60 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2585 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [350, 272, 224, 201, 492, 375, 196, 338, 137]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 16, 20, 12, 15, 15, 5, 8, 17]
	Time taken saving stuff: 0.00s

=== episode:75 Env-steps-taken:72672
 	picked: 84 |actions: {0: 585, 1: 695, 2: 769, 3: 408, 4: 626, 5: 554, 6: 435, 7: 574, 8: 357}
episode: 75/2000 -> reward: 123.80208333333323, steps:5003, time-taken: 2.12min, time-elasped: 168.61min
-> berries picked: 84 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2631 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [358, 280, 230, 206, 500, 381, 200, 337, 139]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 19, 9, 10, 22, 11, 6, 10, 5]
	Time taken saving stuff: 0.01s

=== episode:76 Env-steps-taken:71520
 	picked: 84 |actions: {0: 562, 1: 708, 2: 448, 3: 397, 4: 637, 5: 629, 6: 662, 7: 553, 8: 501}
episode: 76/2000 -> reward: 118.18749999999989, steps:5097, time-taken: 2.33min, time-elasped: 170.94min
-> berries picked: 84 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2688 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [373, 293, 233, 208, 503, 389, 204, 343, 142]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 19, 12, 10, 16, 13, 7, 11, 14]
	Time taken saving stuff: 0.10s

=== episode:77 Env-steps-taken:65184
 	picked: 63 |actions: {0: 444, 1: 402, 2: 417, 3: 350, 4: 594, 5: 466, 6: 539, 7: 406, 8: 543}
episode: 77/2000 -> reward: 84.44791666666663, steps:4161, time-taken: 2.01min, time-elasped: 172.96min
-> berries picked: 63 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2717 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [377, 299, 233, 212, 505, 390, 209, 348, 144]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 22, 16, 11, 12, 11, 10, 9, 4]
	Time taken saving stuff: 0.01s

=== episode:78 Env-steps-taken:63168
 	picked: 52 |actions: {0: 362, 1: 408, 2: 528, 3: 411, 4: 420, 5: 309, 6: 443, 7: 319, 8: 345}
episode: 78/2000 -> reward: 76.52083333333334, steps:3545, time-taken: 1.70min, time-elasped: 174.66min
-> berries picked: 52 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2721 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [380, 299, 235, 214, 504, 385, 205, 352, 147]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 18, 14, 9, 18, 12, 6, 16, 8]
	Time taken saving stuff: 0.02s

=== episode:79 Env-steps-taken:67104
 	picked: 76 |actions: {0: 596, 1: 588, 2: 564, 3: 464, 4: 602, 5: 549, 6: 785, 7: 629, 8: 543}
episode: 79/2000 -> reward: 95.64583333333326, steps:5320, time-taken: 2.28min, time-elasped: 176.95min
-> berries picked: 76 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2743 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [386, 305, 233, 222, 498, 385, 212, 352, 150]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [27, 12, 13, 6, 17, 15, 5, 13, 2]
	Time taken saving stuff: 0.09s

=== episode:80 Env-steps-taken:64224
 	picked: 61 |actions: {0: 354, 1: 493, 2: 434, 3: 425, 4: 498, 5: 508, 6: 624, 7: 474, 8: 448}
episode: 80/2000 -> reward: 80.61979166666666, steps:4258, time-taken: 2.02min, time-elasped: 178.97min
-> berries picked: 61 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2768 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [393, 310, 231, 226, 503, 382, 220, 351, 152]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 17, 25, 8, 11, 14, 7, 7, 5]
	Time taken saving stuff: 0.15s

=== episode:8 Env-steps-taken:69408
 	picked: 80 |actions: {0: 457, 1: 541, 2: 411, 3: 211, 4: 286, 5: 97, 6: 732, 7: 362, 8: 792}

==================================================
eval-episode: 80 -> reward: 107.41666666666653, steps: 3889.0, wall-time: 38.63s
-> berries picked: 80 of 800 | patches-visited: [1, 4] | juice left:-0.00
==================================================


=== episode:81 Env-steps-taken:56064
 	picked: 30 |actions: {0: 267, 1: 230, 2: 321, 3: 205, 4: 240, 5: 212, 6: 281, 7: 226, 8: 207}
episode: 81/2000 -> reward: 40.28125000000002, steps:2189, time-taken: 1.07min, time-elasped: 180.69min
-> berries picked: 30 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2769 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [395, 313, 235, 227, 501, 381, 218, 347, 152]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 18, 14, 12, 18, 15, 7, 7, 5]
	Time taken saving stuff: 0.00s

=== episode:82 Env-steps-taken:64800
 	picked: 62 |actions: {0: 413, 1: 813, 2: 622, 3: 497, 4: 626, 5: 600, 6: 566, 7: 481, 8: 461}
episode: 82/2000 -> reward: 83.94791666666666, steps:5079, time-taken: 2.04min, time-elasped: 182.74min
-> berries picked: 62 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2776 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [388, 325, 239, 230, 500, 383, 216, 343, 152]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 30, 15, 13, 22, 9, 9, 11, 7]
	Time taken saving stuff: 0.00s

=== episode:83 Env-steps-taken:62976
 	picked: 56 |actions: {0: 426, 1: 623, 2: 512, 3: 364, 4: 534, 5: 413, 6: 381, 7: 395, 8: 417}
episode: 83/2000 -> reward: 75.29166666666667, steps:4065, time-taken: 1.93min, time-elasped: 184.67min
-> berries picked: 56 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2795 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [389, 331, 244, 236, 501, 382, 213, 343, 156]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 20, 15, 8, 7, 9, 5, 14, 7]
	Time taken saving stuff: 0.00s

=== episode:84 Env-steps-taken:68544
 	picked: 73 |actions: {0: 440, 1: 675, 2: 579, 3: 490, 4: 562, 5: 668, 6: 481, 7: 519, 8: 541}
episode: 84/2000 -> reward: 102.93229166666659, steps:4955, time-taken: 2.28min, time-elasped: 186.95min
-> berries picked: 73 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2810 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [391, 343, 245, 243, 498, 386, 205, 341, 158]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 20, 13, 8, 8, 16, 5, 8, 10]
	Time taken saving stuff: 0.02s

=== episode:85 Env-steps-taken:64608
 	picked: 57 |actions: {0: 349, 1: 396, 2: 328, 3: 313, 4: 267, 5: 484, 6: 263, 7: 487, 8: 342}
episode: 85/2000 -> reward: 83.73437499999997, steps:3229, time-taken: 1.52min, time-elasped: 188.47min
-> berries picked: 57 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2826 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [390, 351, 248, 246, 499, 381, 204, 345, 162]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 23, 11, 11, 14, 13, 11, 10, 11]
	Time taken saving stuff: 0.01s

=== episode:86 Env-steps-taken:65664
 	picked: 63 |actions: {0: 462, 1: 597, 2: 506, 3: 378, 4: 444, 5: 515, 6: 461, 7: 527, 8: 317}
episode: 86/2000 -> reward: 88.39062499999997, steps:4207, time-taken: 1.89min, time-elasped: 190.37min
-> berries picked: 63 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2837 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [393, 359, 252, 249, 497, 379, 198, 343, 167]
	| approx positives in sample 512: 99
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 23, 6, 9, 18, 9, 4, 6, 14]
	Time taken saving stuff: 0.09s

=== episode:87 Env-steps-taken:65664
 	picked: 65 |actions: {0: 451, 1: 708, 2: 546, 3: 535, 4: 614, 5: 751, 6: 441, 7: 470, 8: 520}
episode: 87/2000 -> reward: 88.77604166666661, steps:5036, time-taken: 2.31min, time-elasped: 192.68min
-> berries picked: 65 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2851 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [389, 366, 259, 256, 494, 380, 198, 341, 168]
	| approx positives in sample 512: 84
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 16, 10, 8, 12, 8, 5, 6, 4]
	Time taken saving stuff: 0.10s

=== episode:88 Env-steps-taken:78048
 	picked: 114 |actions: {0: 678, 1: 687, 2: 885, 3: 668, 4: 876, 5: 870, 6: 700, 7: 730, 8: 516}
episode: 88/2000 -> reward: 148.52604166666663, steps:6610, time-taken: 2.92min, time-elasped: 195.61min
-> berries picked: 114 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2891 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [393, 371, 270, 264, 502, 391, 196, 334, 170]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 21, 20, 6, 15, 9, 6, 12, 12]
	Time taken saving stuff: 0.02s

=== episode:89 Env-steps-taken:71904
 	picked: 93 |actions: {0: 654, 1: 750, 2: 629, 3: 532, 4: 639, 5: 769, 6: 695, 7: 795, 8: 549}
episode: 89/2000 -> reward: 117.72916666666656, steps:6012, time-taken: 2.64min, time-elasped: 198.26min
-> berries picked: 93 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2921 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [398, 379, 275, 270, 496, 392, 203, 336, 172]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 23, 14, 10, 21, 11, 5, 4, 12]
	Time taken saving stuff: 0.08s

=== episode:90 Env-steps-taken:61728
 	picked: 51 |actions: {0: 424, 1: 700, 2: 576, 3: 424, 4: 397, 5: 468, 6: 516, 7: 672, 8: 378}
episode: 90/2000 -> reward: 68.57812500000003, steps:4555, time-taken: 2.01min, time-elasped: 200.27min
-> berries picked: 51 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2922 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [396, 380, 280, 271, 503, 386, 202, 333, 171]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 27, 19, 10, 15, 9, 10, 10, 14]
	Time taken saving stuff: 0.15s

=== episode:9 Env-steps-taken:67872
 	picked: 72 |actions: {0: 289, 1: 444, 2: 184, 3: 617, 4: 183, 5: 357, 6: 171, 7: 720, 8: 377}

==================================================
eval-episode: 90 -> reward: 98.98958333333324, steps: 3342.0, wall-time: 43.84s
-> berries picked: 72 of 800 | patches-visited: [1, 6] | juice left:-0.00
==================================================


=== episode:91 Env-steps-taken:64992
 	picked: 63 |actions: {0: 431, 1: 730, 2: 564, 3: 551, 4: 475, 5: 745, 6: 460, 7: 607, 8: 359}
episode: 91/2000 -> reward: 85.39062499999996, steps:4922, time-taken: 2.21min, time-elasped: 203.22min
-> berries picked: 63 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2931 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [395, 387, 285, 269, 505, 384, 202, 331, 173]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 18, 15, 12, 17, 20, 4, 7, 13]
	Time taken saving stuff: 0.01s

=== episode:92 Env-steps-taken:61824
 	picked: 57 |actions: {0: 385, 1: 420, 2: 400, 3: 451, 4: 494, 5: 734, 6: 344, 7: 391, 8: 436}
episode: 92/2000 -> reward: 69.23437500000001, steps:4055, time-taken: 1.90min, time-elasped: 205.12min
-> berries picked: 57 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2931 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [386, 390, 291, 275, 502, 383, 199, 328, 177]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 28, 17, 10, 16, 13, 10, 7, 11]
	Time taken saving stuff: 0.09s

=== episode:93 Env-steps-taken:70560
 	picked: 78 |actions: {0: 544, 1: 767, 2: 546, 3: 644, 4: 609, 5: 831, 6: 493, 7: 594, 8: 518}
episode: 93/2000 -> reward: 113.53124999999989, steps:5546, time-taken: 2.45min, time-elasped: 207.58min
-> berries picked: 78 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2937 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [384, 399, 292, 281, 494, 382, 199, 325, 181]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 23, 19, 7, 11, 12, 2, 9, 12]
	Time taken saving stuff: 0.07s

=== episode:94 Env-steps-taken:62784
 	picked: 65 |actions: {0: 395, 1: 525, 2: 517, 3: 489, 4: 607, 5: 761, 6: 459, 7: 576, 8: 392}
episode: 94/2000 -> reward: 73.27604166666667, steps:4721, time-taken: 2.04min, time-elasped: 209.62min
-> berries picked: 65 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2935 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [379, 400, 294, 286, 495, 384, 202, 316, 179]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 32, 21, 15, 22, 16, 5, 11, 8]
	Time taken saving stuff: 0.13s

=== episode:95 Env-steps-taken:66816
 	picked: 72 |actions: {0: 486, 1: 729, 2: 582, 3: 455, 4: 492, 5: 563, 6: 392, 7: 642, 8: 467}
episode: 95/2000 -> reward: 94.37499999999994, steps:4808, time-taken: 2.26min, time-elasped: 211.88min
-> berries picked: 72 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2946 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [382, 411, 301, 290, 488, 381, 200, 314, 179]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 22, 21, 12, 17, 10, 2, 6, 10]
	Time taken saving stuff: 0.09s

=== episode:96 Env-steps-taken:58176
 	picked: 35 |actions: {0: 312, 1: 480, 2: 363, 3: 293, 4: 424, 5: 497, 6: 387, 7: 276, 8: 456}
episode: 96/2000 -> reward: 51.994791666666686, steps:3488, time-taken: 1.61min, time-elasped: 213.49min
-> berries picked: 35 of 800 | patches-visited: [0, 2, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2938 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [372, 412, 306, 294, 487, 376, 200, 310, 181]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 24, 20, 10, 10, 10, 8, 4, 8]
	Time taken saving stuff: 0.02s

=== episode:97 Env-steps-taken:61248
 	picked: 50 |actions: {0: 368, 1: 409, 2: 315, 3: 349, 4: 509, 5: 445, 6: 341, 7: 335, 8: 239}
episode: 97/2000 -> reward: 66.63541666666671, steps:3310, time-taken: 1.52min, time-elasped: 215.02min
-> berries picked: 50 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2952 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [371, 416, 305, 303, 489, 377, 199, 309, 183]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 28, 20, 10, 17, 12, 4, 8, 5]
	Time taken saving stuff: 0.09s

=== episode:98 Env-steps-taken:72960
 	picked: 89 |actions: {0: 606, 1: 717, 2: 517, 3: 502, 4: 732, 5: 769, 6: 682, 7: 717, 8: 538}
episode: 98/2000 -> reward: 125.9010416666665, steps:5780, time-taken: 2.54min, time-elasped: 217.57min
-> berries picked: 89 of 800 | patches-visited: [0, 2, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2959 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [357, 417, 310, 309, 487, 377, 207, 311, 184]
	| approx positives in sample 512: 94
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 20, 18, 3, 11, 6, 5, 10, 9]
	Time taken saving stuff: 0.09s

=== episode:99 Env-steps-taken:69984
 	picked: 84 |actions: {0: 435, 1: 424, 2: 543, 3: 522, 4: 698, 5: 540, 6: 530, 7: 636, 8: 510}
episode: 99/2000 -> reward: 110.18749999999987, steps:4838, time-taken: 2.19min, time-elasped: 219.75min
-> berries picked: 84 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2973 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [352, 418, 317, 315, 487, 379, 214, 305, 186]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 22, 18, 14, 10, 9, 7, 6, 14]
	Time taken saving stuff: 0.09s

=== episode:100 Env-steps-taken:53280
 	picked: 19 |actions: {0: 393, 1: 196, 2: 189, 3: 156, 4: 210, 5: 254, 6: 223, 7: 336, 8: 400}
episode: 100/2000 -> reward: 26.411458333333332, steps:2357, time-taken: 1.34min, time-elasped: 221.10min
-> berries picked: 19 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2964 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [352, 418, 317, 314, 481, 374, 217, 306, 185]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 23, 11, 17, 17, 6, 7, 9, 12]
	Time taken saving stuff: 0.06s

=== episode:10 Env-steps-taken:59328
 	picked: 39 |actions: {0: 70, 1: 92, 2: 82, 3: 87, 4: 201, 5: 157, 6: 195, 7: 227, 8: 253}

==================================================
eval-episode: 100 -> reward: 57.265625000000036, steps: 1364.0, wall-time: 26.86s
-> berries picked: 39 of 800 | patches-visited: [1, 3] | juice left:-0.00
==================================================


=== episode:101 Env-steps-taken:55872
 	picked: 27 |actions: {0: 198, 1: 226, 2: 255, 3: 150, 4: 306, 5: 212, 6: 290, 7: 234, 8: 187}
episode: 101/2000 -> reward: 39.45312500000001, steps:2058, time-taken: 1.16min, time-elasped: 222.71min
-> berries picked: 27 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2975 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [350, 422, 320, 314, 484, 374, 218, 306, 187]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 26, 20, 15, 13, 8, 7, 12, 9]
	Time taken saving stuff: 0.00s

=== episode:102 Env-steps-taken:62112
 	picked: 50 |actions: {0: 325, 1: 257, 2: 302, 3: 385, 4: 428, 5: 426, 6: 309, 7: 365, 8: 261}
episode: 102/2000 -> reward: 71.13541666666669, steps:3058, time-taken: 1.66min, time-elasped: 224.37min
-> berries picked: 50 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 2992 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [350, 426, 327, 318, 481, 373, 223, 306, 188]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 30, 14, 10, 10, 11, 7, 8, 10]
	Time taken saving stuff: 0.00s

=== episode:103 Env-steps-taken:72768
 	picked: 87 |actions: {0: 585, 1: 509, 2: 662, 3: 547, 4: 810, 5: 723, 6: 498, 7: 595, 8: 581}
episode: 103/2000 -> reward: 122.57291666666652, steps:5510, time-taken: 2.45min, time-elasped: 226.83min
-> berries picked: 87 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3019 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [359, 431, 333, 325, 480, 376, 230, 297, 188]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 18, 18, 13, 16, 14, 4, 5, 8]
	Time taken saving stuff: 0.01s

=== episode:104 Env-steps-taken:63744
 	picked: 52 |actions: {0: 310, 1: 254, 2: 313, 3: 268, 4: 314, 5: 444, 6: 268, 7: 431, 8: 235}
episode: 104/2000 -> reward: 79.52083333333331, steps:2837, time-taken: 1.45min, time-elasped: 228.27min
-> berries picked: 52 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3045 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [359, 433, 338, 327, 483, 377, 238, 299, 191]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 21, 20, 8, 12, 14, 3, 9, 10]
	Time taken saving stuff: 0.10s

=== episode:105 Env-steps-taken:60576
 	picked: 49 |actions: {0: 662, 1: 337, 2: 480, 3: 490, 4: 585, 5: 493, 6: 527, 7: 509, 8: 422}
episode: 105/2000 -> reward: 62.36458333333337, steps:4505, time-taken: 2.12min, time-elasped: 230.40min
-> berries picked: 49 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3045 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [358, 437, 335, 332, 480, 372, 244, 294, 193]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 22, 20, 14, 13, 12, 4, 5, 14]
	Time taken saving stuff: 0.02s

=== episode:106 Env-steps-taken:70944
 	picked: 86 |actions: {0: 738, 1: 678, 2: 542, 3: 453, 4: 541, 5: 548, 6: 494, 7: 672, 8: 673}
episode: 106/2000 -> reward: 115.57291666666653, steps:5339, time-taken: 2.39min, time-elasped: 232.78min
-> berries picked: 86 of 800 | patches-visited: [0, 3, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3062 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [353, 443, 341, 340, 479, 368, 244, 299, 195]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [18, 22, 22, 11, 13, 11, 10, 9, 7]
	Time taken saving stuff: 0.10s

=== episode:107 Env-steps-taken:60384
 	picked: 45 |actions: {0: 264, 1: 245, 2: 320, 3: 300, 4: 263, 5: 304, 6: 323, 7: 317, 8: 382}
episode: 107/2000 -> reward: 62.42187500000004, steps:2718, time-taken: 1.39min, time-elasped: 234.18min
-> berries picked: 45 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3077 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [345, 445, 352, 343, 478, 364, 249, 303, 198]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [16, 18, 17, 7, 14, 11, 8, 8, 16]
	Time taken saving stuff: 0.08s

=== episode:108 Env-steps-taken:65376
 	picked: 58 |actions: {0: 518, 1: 395, 2: 406, 3: 328, 4: 342, 5: 623, 6: 478, 7: 525, 8: 488}
episode: 108/2000 -> reward: 88.17708333333331, steps:4103, time-taken: 2.02min, time-elasped: 236.20min
-> berries picked: 58 of 800 | patches-visited: [0, 6, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3105 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [348, 447, 355, 347, 473, 365, 258, 310, 202]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 20, 20, 9, 10, 11, 8, 8, 7]
	Time taken saving stuff: 0.11s

=== episode:109 Env-steps-taken:65376
 	picked: 63 |actions: {0: 465, 1: 309, 2: 377, 3: 442, 4: 437, 5: 417, 6: 423, 7: 425, 8: 397}
episode: 109/2000 -> reward: 85.50520833333333, steps:3692, time-taken: 1.77min, time-elasped: 237.97min
-> berries picked: 63 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3136 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [348, 450, 354, 361, 477, 365, 264, 314, 203]
	| approx positives in sample 512: 101
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 19, 18, 12, 10, 14, 8, 5, 7]
	Time taken saving stuff: 0.08s

=== episode:110 Env-steps-taken:71520
 	picked: 86 |actions: {0: 687, 1: 579, 2: 561, 3: 577, 4: 602, 5: 751, 6: 569, 7: 791, 8: 464}
episode: 110/2000 -> reward: 118.57291666666653, steps:5581, time-taken: 2.39min, time-elasped: 240.36min
-> berries picked: 86 of 800 | patches-visited: [0, 2, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3149 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [340, 454, 359, 368, 471, 363, 265, 325, 204]
	| approx positives in sample 512: 99
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 20, 8, 7, 9, 11, 12, 9, 16]
	Time taken saving stuff: 0.15s

=== episode:11 Env-steps-taken:56544
 	picked: 29 |actions: {0: 149, 1: 105, 2: 166, 3: 12, 4: 97, 5: 22, 6: 111, 7: 160, 8: 98}

==================================================
eval-episode: 110 -> reward: 42.838541666666686, steps: 920.0, wall-time: 31.73s
-> berries picked: 29 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:111 Env-steps-taken:63840
 	picked: 56 |actions: {0: 429, 1: 255, 2: 391, 3: 423, 4: 289, 5: 568, 6: 369, 7: 374, 8: 354}
episode: 111/2000 -> reward: 79.29166666666667, steps:3452, time-taken: 1.70min, time-elasped: 242.59min
-> berries picked: 56 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3159 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [340, 457, 361, 367, 468, 367, 267, 330, 202]
	| approx positives in sample 512: 101
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 18, 17, 13, 10, 12, 7, 5, 5]
	Time taken saving stuff: 0.00s

=== episode:112 Env-steps-taken:58656
 	picked: 42 |actions: {0: 233, 1: 222, 2: 325, 3: 247, 4: 227, 5: 417, 6: 343, 7: 318, 8: 295}
episode: 112/2000 -> reward: 53.093750000000036, steps:2627, time-taken: 1.37min, time-elasped: 243.97min
-> berries picked: 42 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3173 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [337, 457, 361, 367, 469, 374, 271, 333, 204]
	| approx positives in sample 512: 101
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 22, 16, 13, 7, 7, 8, 3, 13]
	Time taken saving stuff: 0.00s

=== episode:113 Env-steps-taken:75072
 	picked: 97 |actions: {0: 600, 1: 520, 2: 705, 3: 524, 4: 550, 5: 683, 6: 672, 7: 765, 8: 699}
episode: 113/2000 -> reward: 135.94270833333326, steps:5718, time-taken: 2.61min, time-elasped: 246.58min
-> berries picked: 97 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3184 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [332, 457, 368, 376, 472, 370, 274, 332, 203]
	| approx positives in sample 512: 101
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 21, 13, 4, 9, 16, 12, 6, 13]
	Time taken saving stuff: 0.11s

=== episode:114 Env-steps-taken:71616
 	picked: 85 |actions: {0: 535, 1: 496, 2: 644, 3: 521, 4: 490, 5: 639, 6: 591, 7: 476, 8: 422}
episode: 114/2000 -> reward: 118.6302083333332, steps:4814, time-taken: 2.22min, time-elasped: 248.80min
-> berries picked: 85 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3203 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [333, 458, 371, 378, 474, 369, 282, 331, 207]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 18, 17, 13, 13, 18, 7, 7, 12]
	Time taken saving stuff: 0.08s

=== episode:115 Env-steps-taken:71616
 	picked: 92 |actions: {0: 676, 1: 438, 2: 753, 3: 508, 4: 486, 5: 619, 6: 541, 7: 734, 8: 507}
episode: 115/2000 -> reward: 118.7864583333332, steps:5262, time-taken: 2.39min, time-elasped: 251.19min
-> berries picked: 92 of 800 | patches-visited: [0, 1, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3226 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [326, 469, 383, 387, 477, 361, 284, 331, 208]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 17, 15, 6, 18, 11, 9, 7, 15]
	Time taken saving stuff: 0.01s

=== episode:116 Env-steps-taken:60768
 	picked: 47 |actions: {0: 322, 1: 344, 2: 286, 3: 297, 4: 236, 5: 381, 6: 243, 7: 229, 8: 311}
episode: 116/2000 -> reward: 63.80729166666671, steps:2649, time-taken: 1.36min, time-elasped: 252.55min
-> berries picked: 47 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3233 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [328, 470, 391, 387, 473, 358, 286, 329, 211]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 24, 22, 12, 12, 12, 4, 10, 11]
	Time taken saving stuff: 0.10s

=== episode:117 Env-steps-taken:65184
 	picked: 64 |actions: {0: 424, 1: 421, 2: 483, 3: 524, 4: 656, 5: 587, 6: 408, 7: 503, 8: 654}
episode: 117/2000 -> reward: 86.33333333333331, steps:4660, time-taken: 2.19min, time-elasped: 254.75min
-> berries picked: 64 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3222 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [320, 474, 391, 387, 464, 359, 287, 325, 215]
	| approx positives in sample 512: 80
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 5, 12, 13, 10, 12, 12, 4, 8]
	Time taken saving stuff: 0.01s

=== episode:118 Env-steps-taken:64896
 	picked: 59 |actions: {0: 362, 1: 393, 2: 525, 3: 479, 4: 407, 5: 561, 6: 401, 7: 431, 8: 392}
episode: 118/2000 -> reward: 85.11979166666663, steps:3951, time-taken: 1.90min, time-elasped: 256.65min
-> berries picked: 59 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3226 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [316, 476, 390, 392, 459, 365, 291, 322, 215]
	| approx positives in sample 512: 94
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 15, 20, 7, 11, 11, 6, 5, 10]
	Time taken saving stuff: 0.10s

=== episode:119 Env-steps-taken:62400
 	picked: 53 |actions: {0: 289, 1: 354, 2: 279, 3: 288, 4: 272, 5: 427, 6: 336, 7: 357, 8: 238}
episode: 119/2000 -> reward: 72.46354166666667, steps:2840, time-taken: 1.56min, time-elasped: 258.21min
-> berries picked: 53 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3250 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [314, 477, 391, 395, 459, 374, 296, 329, 215]
	| approx positives in sample 512: 96
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 14, 18, 13, 12, 7, 10, 6, 8]
	Time taken saving stuff: 0.09s

=== episode:120 Env-steps-taken:60288
 	picked: 46 |actions: {0: 265, 1: 321, 2: 308, 3: 395, 4: 349, 5: 368, 6: 282, 7: 290, 8: 450}
episode: 120/2000 -> reward: 61.36458333333339, steps:3028, time-taken: 1.53min, time-elasped: 259.74min
-> berries picked: 46 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3263 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [315, 485, 390, 395, 465, 373, 296, 327, 217]
	| approx positives in sample 512: 87
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 14, 7, 12, 10, 11, 9, 4, 12]
	Time taken saving stuff: 0.12s

=== episode:12 Env-steps-taken:56256
 	picked: 28 |actions: {0: 119, 1: 212, 2: 84, 3: 96, 4: 31, 5: 127, 6: 77, 7: 86, 8: 166}

==================================================
eval-episode: 120 -> reward: 41.39583333333334, steps: 998.0, wall-time: 33.99s
-> berries picked: 28 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:121 Env-steps-taken:55584
 	picked: 22 |actions: {0: 147, 1: 234, 2: 138, 3: 113, 4: 89, 5: 108, 6: 112, 7: 137, 8: 237}
episode: 121/2000 -> reward: 38.739583333333336, steps:1315, time-taken: 0.90min, time-elasped: 261.21min
-> berries picked: 22 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3266 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [313, 489, 390, 398, 464, 370, 294, 330, 218]
	| approx positives in sample 512: 95
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 23, 8, 9, 14, 7, 10, 7, 12]
	Time taken saving stuff: 0.01s

=== episode:122 Env-steps-taken:75936
 	picked: 98 |actions: {0: 728, 1: 936, 2: 578, 3: 663, 4: 505, 5: 911, 6: 786, 7: 737, 8: 507}
episode: 122/2000 -> reward: 140.38541666666663, steps:6351, time-taken: 2.96min, time-elasped: 264.18min
-> berries picked: 98 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3255 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [301, 494, 387, 399, 454, 374, 296, 333, 217]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [19, 17, 11, 10, 14, 3, 6, 10, 17]
	Time taken saving stuff: 0.01s

=== episode:123 Env-steps-taken:49824
 	picked: 8 |actions: {0: 65, 1: 56, 2: 32, 3: 43, 4: 32, 5: 41, 6: 42, 7: 71, 8: 82}
episode: 123/2000 -> reward: 9.041666666666668, steps:464, time-taken: 0.53min, time-elasped: 264.71min
-> berries picked: 8 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3258 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [303, 493, 386, 399, 454, 374, 297, 335, 217]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 15, 12, 11, 10, 7, 8, 10, 13]
	Time taken saving stuff: 0.00s

=== episode:124 Env-steps-taken:57888
 	picked: 38 |actions: {0: 410, 1: 453, 2: 361, 3: 383, 4: 332, 5: 406, 6: 282, 7: 329, 8: 214}
episode: 124/2000 -> reward: 49.32291666666669, steps:3170, time-taken: 1.57min, time-elasped: 266.28min
-> berries picked: 38 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3258 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [303, 493, 390, 400, 458, 369, 296, 333, 216]
	| approx positives in sample 512: 83
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 11, 10, 14, 8, 11, 8, 7, 7]
	Time taken saving stuff: 0.00s

=== episode:125 Env-steps-taken:61344
 	picked: 47 |actions: {0: 288, 1: 411, 2: 315, 3: 360, 4: 286, 5: 468, 6: 268, 7: 367, 8: 226}
episode: 125/2000 -> reward: 67.30729166666671, steps:2989, time-taken: 1.46min, time-elasped: 267.74min
-> berries picked: 47 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3276 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [303, 494, 395, 402, 460, 368, 296, 340, 218]
	| approx positives in sample 512: 78
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 9, 7, 7, 13, 7, 8, 11, 10]
	Time taken saving stuff: 0.02s

=== episode:126 Env-steps-taken:75168
 	picked: 98 |actions: {0: 747, 1: 793, 2: 619, 3: 759, 4: 635, 5: 567, 6: 530, 7: 631, 8: 733}
episode: 126/2000 -> reward: 136.88541666666657, steps:6014, time-taken: 2.85min, time-elasped: 270.59min
-> berries picked: 98 of 800 | patches-visited: [0, 4, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3317 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [306, 494, 398, 419, 465, 370, 301, 342, 222]
	| approx positives in sample 512: 101
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 19, 10, 4, 15, 13, 10, 8, 12]
	Time taken saving stuff: 0.02s

=== episode:127 Env-steps-taken:68736
 	picked: 82 |actions: {0: 509, 1: 775, 2: 751, 3: 665, 4: 688, 5: 695, 6: 480, 7: 473, 8: 516}
episode: 127/2000 -> reward: 103.80208333333324, steps:5552, time-taken: 2.41min, time-elasped: 273.00min
-> berries picked: 82 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3339 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [305, 500, 400, 429, 464, 374, 302, 340, 225]
	| approx positives in sample 512: 99
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 9, 14, 7, 12, 13, 11, 7, 13]
	Time taken saving stuff: 0.09s

=== episode:128 Env-steps-taken:77664
 	picked: 102 |actions: {0: 709, 1: 985, 2: 608, 3: 719, 4: 782, 5: 774, 6: 720, 7: 817, 8: 591}
episode: 128/2000 -> reward: 149.15624999999997, steps:6705, time-taken: 3.10min, time-elasped: 276.11min
-> berries picked: 102 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3368 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [313, 501, 403, 436, 463, 377, 305, 344, 226]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 24, 15, 13, 9, 11, 9, 7, 7]
	Time taken saving stuff: 0.10s

=== episode:129 Env-steps-taken:57888
 	picked: 33 |actions: {0: 208, 1: 272, 2: 163, 3: 178, 4: 301, 5: 193, 6: 224, 7: 283, 8: 163}
episode: 129/2000 -> reward: 50.10937500000003, steps:1985, time-taken: 1.18min, time-elasped: 277.29min
-> berries picked: 33 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3377 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [310, 498, 404, 435, 465, 379, 309, 349, 228]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 16, 16, 13, 14, 7, 6, 12, 5]
	Time taken saving stuff: 0.01s

=== episode:130 Env-steps-taken:66720
 	picked: 76 |actions: {0: 417, 1: 586, 2: 298, 3: 413, 4: 555, 5: 523, 6: 486, 7: 500, 8: 264}
episode: 130/2000 -> reward: 93.64583333333324, steps:4042, time-taken: 1.93min, time-elasped: 279.23min
-> berries picked: 76 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3415 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [312, 502, 401, 437, 474, 383, 315, 361, 230]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 15, 15, 15, 13, 12, 13, 7, 14]
	Time taken saving stuff: 0.16s

=== episode:13 Env-steps-taken:59520
 	picked: 46 |actions: {0: 298, 1: 724, 2: 344, 3: 65, 4: 401, 5: 1102, 6: 83, 7: 208, 8: 700}

==================================================
eval-episode: 130 -> reward: 57.86458333333337, steps: 3925.0, wall-time: 38.42s
-> berries picked: 46 of 800 | patches-visited: [1, 5] | juice left:-0.00
==================================================


=== episode:131 Env-steps-taken:60384
 	picked: 47 |actions: {0: 281, 1: 502, 2: 291, 3: 346, 4: 520, 5: 469, 6: 300, 7: 549, 8: 527}
episode: 131/2000 -> reward: 61.42187500000006, steps:3785, time-taken: 1.93min, time-elasped: 281.80min
-> berries picked: 47 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3393 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [312, 487, 395, 436, 479, 381, 310, 364, 229]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 12, 8, 10, 13, 11, 7, 13, 13]
	Time taken saving stuff: 0.00s

=== episode:132 Env-steps-taken:69216
 	picked: 75 |actions: {0: 380, 1: 437, 2: 334, 3: 420, 4: 599, 5: 453, 6: 432, 7: 557, 8: 283}
episode: 132/2000 -> reward: 106.7031249999999, steps:3895, time-taken: 1.94min, time-elasped: 283.74min
-> berries picked: 75 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3431 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [313, 487, 395, 443, 486, 388, 320, 369, 230]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 11, 17, 17, 18, 8, 8, 17, 10]
	Time taken saving stuff: 0.02s

=== episode:133 Env-steps-taken:67104
 	picked: 70 |actions: {0: 522, 1: 644, 2: 495, 3: 581, 4: 660, 5: 683, 6: 393, 7: 485, 8: 430}
episode: 133/2000 -> reward: 95.48958333333324, steps:4893, time-taken: 2.27min, time-elasped: 286.01min
-> berries picked: 70 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3432 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [310, 479, 395, 447, 493, 386, 322, 370, 230]
	| approx positives in sample 512: 84
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 9, 11, 17, 13, 7, 4, 8, 10]
	Time taken saving stuff: 0.09s

=== episode:134 Env-steps-taken:57504
 	picked: 37 |actions: {0: 332, 1: 266, 2: 241, 3: 193, 4: 403, 5: 371, 6: 241, 7: 292, 8: 276}
episode: 134/2000 -> reward: 47.880208333333364, steps:2615, time-taken: 1.50min, time-elasped: 287.51min
-> berries picked: 37 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3428 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [309, 476, 391, 450, 492, 389, 319, 372, 230]
	| approx positives in sample 512: 100
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 13, 15, 8, 16, 16, 5, 3, 15]
	Time taken saving stuff: 0.09s

=== episode:135 Env-steps-taken:62112
 	picked: 52 |actions: {0: 327, 1: 411, 2: 452, 3: 448, 4: 705, 5: 846, 6: 493, 7: 423, 8: 622}
episode: 135/2000 -> reward: 70.63541666666669, steps:4727, time-taken: 2.05min, time-elasped: 289.57min
-> berries picked: 52 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3420 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [302, 470, 391, 453, 492, 386, 326, 369, 231]
	| approx positives in sample 512: 92
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 8, 13, 12, 11, 16, 9, 7, 9]
	Time taken saving stuff: 0.10s

=== episode:136 Env-steps-taken:54912
 	picked: 27 |actions: {0: 209, 1: 228, 2: 201, 3: 192, 4: 192, 5: 152, 6: 102, 7: 130, 8: 149}
episode: 136/2000 -> reward: 34.953125, steps:1555, time-taken: 0.90min, time-elasped: 290.47min
-> berries picked: 27 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3421 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [296, 473, 390, 460, 492, 388, 323, 365, 234]
	| approx positives in sample 512: 89
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 12, 6, 9, 18, 7, 11, 9, 9]
	Time taken saving stuff: 0.10s

=== episode:137 Env-steps-taken:55200
 	picked: 24 |actions: {0: 101, 1: 96, 2: 158, 3: 170, 4: 114, 5: 146, 6: 117, 7: 81, 8: 112}
episode: 137/2000 -> reward: 36.12500000000001, steps:1095, time-taken: 0.74min, time-elasped: 291.21min
-> berries picked: 24 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3419 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [295, 467, 393, 461, 494, 386, 325, 364, 234]
	| approx positives in sample 512: 90
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 14, 7, 10, 18, 7, 8, 5, 14]
	Time taken saving stuff: 0.10s

=== episode:138 Env-steps-taken:61344
 	picked: 48 |actions: {0: 299, 1: 256, 2: 426, 3: 289, 4: 408, 5: 239, 6: 304, 7: 234, 8: 426}
episode: 138/2000 -> reward: 67.75000000000003, steps:2881, time-taken: 1.51min, time-elasped: 292.73min
-> berries picked: 48 of 800 | patches-visited: [0, 5, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3414 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [291, 456, 395, 463, 500, 388, 323, 362, 236]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 12, 10, 15, 18, 6, 8, 9, 8]
	Time taken saving stuff: 0.09s

=== episode:139 Env-steps-taken:59040
 	picked: 39 |actions: {0: 267, 1: 330, 2: 262, 3: 276, 4: 294, 5: 266, 6: 369, 7: 418, 8: 354}
episode: 139/2000 -> reward: 53.880208333333364, steps:2836, time-taken: 1.47min, time-elasped: 294.20min
-> berries picked: 39 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3394 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [291, 438, 392, 462, 498, 386, 330, 360, 237]
	| approx positives in sample 512: 86
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 15, 6, 8, 9, 6, 13, 9, 9]
	Time taken saving stuff: 0.09s

=== episode:140 Env-steps-taken:69216
 	picked: 75 |actions: {0: 442, 1: 591, 2: 441, 3: 507, 4: 460, 5: 322, 6: 505, 7: 559, 8: 402}
episode: 140/2000 -> reward: 107.20312499999989, steps:4229, time-taken: 2.00min, time-elasped: 296.21min
-> berries picked: 75 of 800 | patches-visited: [0, 3, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3400 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [288, 424, 394, 471, 499, 389, 334, 360, 241]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 11, 12, 10, 12, 13, 8, 14, 15]
	Time taken saving stuff: 0.16s

=== episode:14 Env-steps-taken:68832
 	picked: 75 |actions: {0: 179, 1: 1193, 2: 469, 3: 332, 4: 284, 5: 1372, 6: 192, 7: 426, 8: 561}

==================================================
eval-episode: 140 -> reward: 104.7031249999999, steps: 5008.0, wall-time: 42.95s
-> berries picked: 75 of 800 | patches-visited: [1, 8] | juice left:-0.00
==================================================


=== episode:141 Env-steps-taken:53664
 	picked: 18 |actions: {0: 81, 1: 103, 2: 89, 3: 135, 4: 95, 5: 63, 6: 59, 7: 135, 8: 127}
episode: 141/2000 -> reward: 28.46874999999999, steps:887, time-taken: 0.74min, time-elasped: 297.68min
-> berries picked: 18 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3399 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [288, 424, 395, 471, 501, 387, 331, 361, 241]
	| approx positives in sample 512: 101
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 11, 14, 10, 18, 8, 8, 10, 14]
	Time taken saving stuff: 0.00s

=== episode:142 Env-steps-taken:71040
 	picked: 80 |actions: {0: 583, 1: 768, 2: 589, 3: 544, 4: 608, 5: 547, 6: 440, 7: 559, 8: 581}
episode: 142/2000 -> reward: 115.91666666666654, steps:5219, time-taken: 2.37min, time-elasped: 300.05min
-> berries picked: 80 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3382 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [287, 418, 404, 468, 494, 378, 332, 360, 241]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 6, 11, 8, 15, 15, 8, 14, 11]
	Time taken saving stuff: 0.01s

=== episode:143 Env-steps-taken:72000
 	picked: 88 |actions: {0: 534, 1: 579, 2: 562, 3: 575, 4: 553, 5: 542, 6: 423, 7: 606, 8: 504}
episode: 143/2000 -> reward: 120.45833333333319, steps:4878, time-taken: 2.26min, time-elasped: 302.30min
-> berries picked: 88 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3386 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [290, 414, 402, 473, 490, 370, 338, 366, 243]
	| approx positives in sample 512: 101
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 13, 8, 17, 9, 8, 11, 10, 15]
	Time taken saving stuff: 0.00s

=== episode:144 Env-steps-taken:67104
 	picked: 70 |actions: {0: 518, 1: 779, 2: 459, 3: 482, 4: 380, 5: 570, 6: 394, 7: 751, 8: 710}
episode: 144/2000 -> reward: 94.04687499999991, steps:5043, time-taken: 2.36min, time-elasped: 304.67min
-> berries picked: 70 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3362 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [288, 405, 402, 473, 486, 360, 340, 367, 241]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 11, 18, 12, 12, 16, 11, 6, 13]
	Time taken saving stuff: 0.00s

=== episode:145 Env-steps-taken:68448
 	picked: 77 |actions: {0: 567, 1: 570, 2: 491, 3: 531, 4: 584, 5: 678, 6: 385, 7: 571, 8: 541}
episode: 145/2000 -> reward: 102.58854166666659, steps:4918, time-taken: 2.42min, time-elasped: 307.09min
-> berries picked: 77 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3360 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [280, 398, 403, 476, 489, 359, 341, 370, 244]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 13, 9, 15, 10, 7, 9, 11, 18]
	Time taken saving stuff: 0.09s

=== episode:146 Env-steps-taken:62784
 	picked: 59 |actions: {0: 354, 1: 617, 2: 383, 3: 446, 4: 539, 5: 423, 6: 374, 7: 456, 8: 555}
episode: 146/2000 -> reward: 72.67708333333334, steps:4147, time-taken: 2.02min, time-elasped: 309.11min
-> berries picked: 59 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3350 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [275, 393, 402, 482, 490, 351, 340, 373, 244]
	| approx positives in sample 512: 93
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 9, 10, 8, 12, 12, 8, 9, 15]
	Time taken saving stuff: 0.02s

=== episode:147 Env-steps-taken:61056
 	picked: 50 |actions: {0: 326, 1: 406, 2: 479, 3: 484, 4: 394, 5: 541, 6: 392, 7: 387, 8: 532}
episode: 147/2000 -> reward: 65.63541666666673, steps:3941, time-taken: 2.02min, time-elasped: 311.13min
-> berries picked: 50 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3332 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [270, 385, 405, 475, 491, 347, 340, 373, 246]
	| approx positives in sample 512: 90
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 12, 10, 12, 12, 10, 8, 10, 9]
	Time taken saving stuff: 0.00s

=== episode:148 Env-steps-taken:53664
 	picked: 21 |actions: {0: 112, 1: 120, 2: 132, 3: 169, 4: 145, 5: 154, 6: 161, 7: 187, 8: 142}
episode: 148/2000 -> reward: 28.296874999999993, steps:1322, time-taken: 0.99min, time-elasped: 312.13min
-> berries picked: 21 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3330 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [271, 381, 407, 476, 489, 344, 342, 375, 245]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 9, 19, 15, 14, 7, 11, 10, 17]
	Time taken saving stuff: 0.01s

=== episode:149 Env-steps-taken:51456
 	picked: 12 |actions: {0: 93, 1: 69, 2: 54, 3: 59, 4: 49, 5: 37, 6: 62, 7: 94, 8: 83}
episode: 149/2000 -> reward: 17.3125, steps:600, time-taken: 0.76min, time-elasped: 312.89min
-> berries picked: 12 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3332 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [271, 382, 409, 477, 490, 343, 341, 374, 245]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 11, 9, 19, 5, 10, 11, 11, 12]
	Time taken saving stuff: 0.09s

=== episode:150 Env-steps-taken:62400
 	picked: 56 |actions: {0: 341, 1: 418, 2: 289, 3: 313, 4: 293, 5: 383, 6: 330, 7: 313, 8: 403}
episode: 150/2000 -> reward: 72.29166666666667, steps:3083, time-taken: 1.58min, time-elasped: 314.47min
-> berries picked: 56 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3332 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [271, 382, 408, 473, 486, 348, 343, 376, 245]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 12, 12, 16, 22, 11, 7, 8, 9]
	Time taken saving stuff: 0.06s

=== episode:15 Env-steps-taken:74496
 	picked: 98 |actions: {0: 337, 1: 393, 2: 391, 3: 413, 4: 220, 5: 658, 6: 187, 7: 429, 8: 220}

==================================================
eval-episode: 150 -> reward: 132.49999999999991, steps: 3248.0, wall-time: 45.82s
-> berries picked: 98 of 800 | patches-visited: [1, 3] | juice left:-0.00
==================================================


=== episode:151 Env-steps-taken:72768
 	picked: 88 |actions: {0: 590, 1: 551, 2: 516, 3: 601, 4: 605, 5: 603, 6: 560, 7: 545, 8: 463}
episode: 151/2000 -> reward: 124.45833333333317, steps:5034, time-taken: 2.39min, time-elasped: 317.63min
-> berries picked: 88 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3334 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [273, 374, 407, 477, 484, 348, 346, 378, 247]
	| approx positives in sample 512: 81
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 15, 7, 7, 8, 7, 9, 7, 14]
	Time taken saving stuff: 0.01s

=== episode:152 Env-steps-taken:66720
 	picked: 65 |actions: {0: 429, 1: 354, 2: 401, 3: 393, 4: 378, 5: 421, 6: 355, 7: 303, 8: 432}
episode: 152/2000 -> reward: 94.83333333333326, steps:3466, time-taken: 1.75min, time-elasped: 319.38min
-> berries picked: 65 of 800 | patches-visited: [0, 5, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3346 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [271, 370, 407, 478, 483, 353, 350, 381, 253]
	| approx positives in sample 512: 89
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 9, 7, 11, 14, 12, 9, 10, 8]
	Time taken saving stuff: 0.02s

=== episode:153 Env-steps-taken:63456
 	picked: 56 |actions: {0: 471, 1: 337, 2: 444, 3: 433, 4: 526, 5: 436, 6: 389, 7: 366, 8: 573}
episode: 153/2000 -> reward: 77.79166666666667, steps:3975, time-taken: 1.90min, time-elasped: 321.28min
-> berries picked: 56 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3331 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [271, 361, 397, 481, 478, 357, 352, 379, 255]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 10, 12, 8, 17, 12, 10, 15, 12]
	Time taken saving stuff: 0.09s

=== episode:154 Env-steps-taken:61920
 	picked: 45 |actions: {0: 313, 1: 308, 2: 347, 3: 225, 4: 281, 5: 231, 6: 221, 7: 304, 8: 316}
episode: 154/2000 -> reward: 70.42187500000001, steps:2546, time-taken: 1.46min, time-elasped: 322.74min
-> berries picked: 45 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3346 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [272, 362, 399, 486, 478, 353, 359, 381, 256]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 8, 9, 18, 17, 13, 13, 8, 15]
	Time taken saving stuff: 0.01s

=== episode:155 Env-steps-taken:73344
 	picked: 95 |actions: {0: 675, 1: 572, 2: 550, 3: 664, 4: 675, 5: 701, 6: 472, 7: 674, 8: 519}
episode: 155/2000 -> reward: 125.11458333333317, steps:5502, time-taken: 2.57min, time-elasped: 325.31min
-> berries picked: 95 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3364 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [272, 353, 398, 492, 484, 367, 365, 378, 255]
	| approx positives in sample 512: 89
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 7, 16, 12, 8, 8, 12, 7, 13]
	Time taken saving stuff: 0.01s

=== episode:156 Env-steps-taken:58464
 	picked: 40 |actions: {0: 263, 1: 319, 2: 359, 3: 252, 4: 254, 5: 271, 6: 227, 7: 253, 8: 300}
episode: 156/2000 -> reward: 52.70833333333336, steps:2498, time-taken: 1.30min, time-elasped: 326.61min
-> berries picked: 40 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3363 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [275, 359, 399, 492, 478, 370, 358, 375, 257]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 10, 11, 19, 15, 6, 12, 6, 19]
	Time taken saving stuff: 0.01s

=== episode:157 Env-steps-taken:64512
 	picked: 57 |actions: {0: 311, 1: 251, 2: 411, 3: 478, 4: 404, 5: 381, 6: 260, 7: 282, 8: 317}
episode: 157/2000 -> reward: 81.79166666666667, steps:3095, time-taken: 1.56min, time-elasped: 328.17min
-> berries picked: 57 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3379 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [272, 354, 404, 497, 488, 374, 359, 372, 259]
	| approx positives in sample 512: 99
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 11, 9, 17, 9, 8, 17, 10, 6]
	Time taken saving stuff: 0.00s

=== episode:158 Env-steps-taken:66912
 	picked: 69 |actions: {0: 448, 1: 473, 2: 471, 3: 452, 4: 423, 5: 414, 6: 371, 7: 383, 8: 479}
episode: 158/2000 -> reward: 95.04687499999993, steps:3914, time-taken: 1.83min, time-elasped: 330.00min
-> berries picked: 69 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3395 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [271, 357, 409, 496, 492, 376, 359, 374, 261]
	| approx positives in sample 512: 99
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 8, 14, 15, 15, 7, 12, 8, 11]
	Time taken saving stuff: 0.10s

=== episode:159 Env-steps-taken:59520
 	picked: 38 |actions: {0: 192, 1: 233, 2: 169, 3: 230, 4: 297, 5: 218, 6: 208, 7: 287, 8: 250}
episode: 159/2000 -> reward: 58.3229166666667, steps:2084, time-taken: 1.27min, time-elasped: 331.27min
-> berries picked: 38 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3401 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [272, 357, 411, 495, 496, 377, 360, 371, 262]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 8, 15, 9, 15, 11, 2, 12, 13]
	Time taken saving stuff: 0.10s

=== episode:160 Env-steps-taken:69888
 	picked: 73 |actions: {0: 375, 1: 480, 2: 379, 3: 450, 4: 393, 5: 519, 6: 532, 7: 425, 8: 705}
episode: 160/2000 -> reward: 110.31770833333321, steps:4258, time-taken: 2.02min, time-elasped: 333.30min
-> berries picked: 73 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3439 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [276, 360, 415, 500, 503, 377, 366, 376, 266]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 3, 9, 15, 9, 19, 12, 11, 18]
	Time taken saving stuff: 0.15s

=== episode:16 Env-steps-taken:59136
 	picked: 38 |actions: {0: 104, 1: 134, 2: 216, 3: 162, 4: 513, 5: 68, 6: 48, 7: 92, 8: 850}

==================================================
eval-episode: 160 -> reward: 56.32291666666671, steps: 2187.0, wall-time: 34.73s
-> berries picked: 38 of 800 | patches-visited: [1, 4] | juice left:-0.00
==================================================


=== episode:161 Env-steps-taken:68832
 	picked: 70 |actions: {0: 451, 1: 505, 2: 373, 3: 403, 4: 418, 5: 370, 6: 387, 7: 457, 8: 517}
episode: 161/2000 -> reward: 103.04687499999993, steps:3881, time-taken: 1.94min, time-elasped: 335.82min
-> berries picked: 70 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3471 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [282, 361, 420, 504, 509, 378, 369, 382, 266]
	| approx positives in sample 512: 93
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 11, 13, 9, 11, 6, 11, 16, 11]
	Time taken saving stuff: 0.10s

=== episode:162 Env-steps-taken:71520
 	picked: 86 |actions: {0: 682, 1: 540, 2: 753, 3: 629, 4: 746, 5: 521, 6: 615, 7: 731, 8: 743}
episode: 162/2000 -> reward: 118.07291666666653, steps:5960, time-taken: 2.65min, time-elasped: 338.48min
-> berries picked: 86 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3476 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [285, 352, 420, 499, 512, 380, 371, 389, 268]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 13, 7, 7, 20, 13, 11, 20, 14]
	Time taken saving stuff: 0.07s

=== episode:163 Env-steps-taken:61536
 	picked: 46 |actions: {0: 300, 1: 348, 2: 368, 3: 216, 4: 228, 5: 319, 6: 268, 7: 261, 8: 337}
episode: 163/2000 -> reward: 68.36458333333336, steps:2645, time-taken: 1.35min, time-elasped: 339.83min
-> berries picked: 46 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3492 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [288, 358, 422, 499, 512, 383, 372, 389, 269]
	| approx positives in sample 512: 100
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 7, 5, 15, 18, 15, 9, 9, 9]
	Time taken saving stuff: 0.00s

=== episode:164 Env-steps-taken:63264
 	picked: 55 |actions: {0: 384, 1: 409, 2: 513, 3: 406, 4: 442, 5: 426, 6: 290, 7: 430, 8: 535}
episode: 164/2000 -> reward: 77.34895833333333, steps:3835, time-taken: 1.87min, time-elasped: 341.70min
-> berries picked: 55 of 800 | patches-visited: [0, 2, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3500 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [287, 353, 425, 502, 516, 383, 373, 392, 269]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 15, 8, 11, 14, 11, 8, 7, 19]
	Time taken saving stuff: 0.01s

=== episode:165 Env-steps-taken:64320
 	picked: 54 |actions: {0: 275, 1: 345, 2: 349, 3: 393, 4: 429, 5: 356, 6: 299, 7: 283, 8: 347}
episode: 165/2000 -> reward: 82.40624999999999, steps:3076, time-taken: 1.56min, time-elasped: 343.26min
-> berries picked: 54 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3521 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [282, 357, 427, 507, 520, 387, 372, 398, 271]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 16, 17, 13, 15, 20, 9, 7, 8]
	Time taken saving stuff: 0.01s

=== episode:166 Env-steps-taken:62688
 	picked: 51 |actions: {0: 332, 1: 262, 2: 261, 3: 242, 4: 284, 5: 308, 6: 273, 7: 246, 8: 260}
episode: 166/2000 -> reward: 74.078125, steps:2468, time-taken: 1.38min, time-elasped: 344.65min
-> berries picked: 51 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3547 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [287, 356, 429, 510, 524, 390, 376, 402, 273]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 12, 6, 15, 13, 15, 17, 10, 6]
	Time taken saving stuff: 0.10s

=== episode:167 Env-steps-taken:56544
 	picked: 29 |actions: {0: 254, 1: 229, 2: 323, 3: 182, 4: 198, 5: 166, 6: 200, 7: 149, 8: 323}
episode: 167/2000 -> reward: 43.838541666666686, steps:2024, time-taken: 1.18min, time-elasped: 345.84min
-> berries picked: 29 of 800 | patches-visited: [0, 1, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3561 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [288, 360, 433, 512, 522, 391, 377, 403, 275]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 7, 6, 18, 24, 9, 11, 15, 18]
	Time taken saving stuff: 0.08s

=== episode:168 Env-steps-taken:57024
 	picked: 30 |actions: {0: 131, 1: 155, 2: 212, 3: 195, 4: 156, 5: 170, 6: 137, 7: 99, 8: 164}
episode: 168/2000 -> reward: 45.28125000000002, steps:1419, time-taken: 1.04min, time-elasped: 346.89min
-> berries picked: 30 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3578 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [287, 361, 440, 518, 525, 390, 380, 401, 276]
	| approx positives in sample 512: 99
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [2, 15, 11, 18, 12, 7, 11, 11, 12]
	Time taken saving stuff: 0.00s

=== episode:169 Env-steps-taken:58656
 	picked: 38 |actions: {0: 192, 1: 249, 2: 273, 3: 198, 4: 231, 5: 214, 6: 176, 7: 155, 8: 271}
episode: 169/2000 -> reward: 53.32291666666671, steps:1959, time-taken: 1.25min, time-elasped: 348.13min
-> berries picked: 38 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3591 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [287, 361, 445, 522, 527, 389, 383, 401, 276]
	| approx positives in sample 512: 94
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 7, 11, 13, 10, 14, 11, 12, 8]
	Time taken saving stuff: 0.01s

=== episode:170 Env-steps-taken:62592
 	picked: 52 |actions: {0: 334, 1: 330, 2: 386, 3: 496, 4: 459, 5: 461, 6: 371, 7: 319, 8: 748}
episode: 170/2000 -> reward: 73.52083333333334, steps:3904, time-taken: 1.90min, time-elasped: 350.04min
-> berries picked: 52 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3604 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [283, 361, 445, 530, 532, 393, 386, 397, 277]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 8, 17, 14, 17, 8, 13, 6, 12]
	Time taken saving stuff: 0.05s

=== episode:17 Env-steps-taken:71040
 	picked: 88 |actions: {0: 408, 1: 206, 2: 145, 3: 311, 4: 457, 5: 281, 6: 164, 7: 431, 8: 386}

==================================================
eval-episode: 170 -> reward: 115.45833333333319, steps: 2789.0, wall-time: 44.91s
-> berries picked: 88 of 800 | patches-visited: [1, 5] | juice left:-0.00
==================================================


=== episode:171 Env-steps-taken:77280
 	picked: 103 |actions: {0: 525, 1: 656, 2: 637, 3: 724, 4: 910, 5: 813, 6: 556, 7: 650, 8: 785}
episode: 171/2000 -> reward: 147.0989583333333, steps:6256, time-taken: 2.84min, time-elasped: 353.64min
-> berries picked: 103 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3614 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [278, 351, 449, 532, 538, 406, 381, 397, 282]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 6, 13, 17, 14, 15, 9, 13, 10]
	Time taken saving stuff: 0.09s

=== episode:172 Env-steps-taken:61056
 	picked: 46 |actions: {0: 250, 1: 444, 2: 366, 3: 403, 4: 378, 5: 393, 6: 299, 7: 346, 8: 362}
episode: 172/2000 -> reward: 65.36458333333337, steps:3241, time-taken: 1.77min, time-elasped: 355.41min
-> berries picked: 46 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3624 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [277, 352, 449, 537, 530, 412, 383, 401, 283]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 9, 17, 10, 15, 6, 11, 11, 14]
	Time taken saving stuff: 0.01s

=== episode:173 Env-steps-taken:59712
 	picked: 43 |actions: {0: 311, 1: 245, 2: 299, 3: 256, 4: 328, 5: 259, 6: 224, 7: 209, 8: 265}
episode: 173/2000 -> reward: 59.036458333333385, steps:2396, time-taken: 1.57min, time-elasped: 356.99min
-> berries picked: 43 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3644 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [282, 357, 454, 536, 531, 415, 390, 396, 283]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 9, 11, 14, 15, 10, 7, 11, 17]
	Time taken saving stuff: 0.01s

=== episode:174 Env-steps-taken:65856
 	picked: 62 |actions: {0: 473, 1: 391, 2: 319, 3: 397, 4: 377, 5: 447, 6: 340, 7: 456, 8: 572}
episode: 174/2000 -> reward: 90.44791666666663, steps:3772, time-taken: 1.99min, time-elasped: 358.98min
-> berries picked: 62 of 800 | patches-visited: [0, 4, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3667 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [289, 361, 454, 540, 530, 418, 391, 399, 285]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 18, 17, 13, 21, 13, 13, 10, 10]
	Time taken saving stuff: 0.01s

=== episode:175 Env-steps-taken:63072
 	picked: 53 |actions: {0: 276, 1: 338, 2: 249, 3: 384, 4: 244, 5: 301, 6: 217, 7: 305, 8: 423}
episode: 175/2000 -> reward: 74.52083333333334, steps:2737, time-taken: 1.42min, time-elasped: 360.40min
-> berries picked: 53 of 800 | patches-visited: [0, 3, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3681 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [294, 360, 458, 538, 533, 421, 392, 397, 288]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 7, 9, 12, 23, 18, 9, 15, 13]
	Time taken saving stuff: 0.09s

=== episode:176 Env-steps-taken:59712
 	picked: 43 |actions: {0: 274, 1: 293, 2: 317, 3: 323, 4: 283, 5: 248, 6: 336, 7: 239, 8: 284}
episode: 176/2000 -> reward: 59.036458333333385, steps:2597, time-taken: 1.45min, time-elasped: 361.86min
-> berries picked: 43 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3692 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [295, 360, 460, 542, 535, 419, 392, 401, 288]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 8, 11, 10, 21, 10, 10, 10, 13]
	Time taken saving stuff: 0.09s

=== episode:177 Env-steps-taken:58848
 	picked: 39 |actions: {0: 312, 1: 284, 2: 235, 3: 354, 4: 266, 5: 265, 6: 347, 7: 256, 8: 443}
episode: 177/2000 -> reward: 54.765625000000036, steps:2762, time-taken: 1.51min, time-elasped: 363.37min
-> berries picked: 39 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3698 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [293, 360, 456, 546, 536, 421, 396, 401, 289]
	| approx positives in sample 512: 90
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 8, 12, 15, 8, 8, 7, 14, 14]
	Time taken saving stuff: 0.00s

=== episode:178 Env-steps-taken:62496
 	picked: 50 |actions: {0: 299, 1: 357, 2: 419, 3: 602, 4: 553, 5: 437, 6: 343, 7: 300, 8: 564}
episode: 178/2000 -> reward: 73.1354166666667, steps:3874, time-taken: 1.81min, time-elasped: 365.18min
-> berries picked: 50 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3704 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [290, 358, 458, 545, 540, 426, 398, 400, 289]
	| approx positives in sample 512: 94
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 3, 7, 8, 16, 16, 12, 10, 14]
	Time taken saving stuff: 0.00s

=== episode:179 Env-steps-taken:55392
 	picked: 29 |actions: {0: 219, 1: 290, 2: 224, 3: 231, 4: 346, 5: 187, 6: 212, 7: 231, 8: 200}
episode: 179/2000 -> reward: 36.83854166666666, steps:2140, time-taken: 1.26min, time-elasped: 366.44min
-> berries picked: 29 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3712 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [291, 358, 458, 549, 543, 424, 399, 401, 289]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 9, 12, 17, 17, 13, 9, 4, 16]
	Time taken saving stuff: 0.01s

=== episode:180 Env-steps-taken:64128
 	picked: 54 |actions: {0: 297, 1: 234, 2: 277, 3: 419, 4: 414, 5: 371, 6: 286, 7: 372, 8: 284}
episode: 180/2000 -> reward: 81.40625, steps:2954, time-taken: 1.50min, time-elasped: 367.95min
-> berries picked: 54 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3730 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [291, 358, 458, 550, 546, 429, 404, 402, 292]
	| approx positives in sample 512: 93
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 6, 6, 19, 12, 12, 12, 9, 8]
	Time taken saving stuff: 0.06s

=== episode:18 Env-steps-taken:49248
 	picked: 5 |actions: {0: 34, 1: 2201, 2: 4, 3: 10, 4: 7, 5: 2194, 6: 11, 7: 16, 8: 1}

==================================================
eval-episode: 180 -> reward: 6.213541666666666, steps: 4478.0, wall-time: 45.94s
-> berries picked: 5 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:181 Env-steps-taken:53280
 	picked: 19 |actions: {0: 131, 1: 62, 2: 81, 3: 116, 4: 117, 5: 174, 6: 101, 7: 142, 8: 115}
episode: 181/2000 -> reward: 26.41145833333332, steps:1039, time-taken: 0.74min, time-elasped: 369.46min
-> berries picked: 19 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3737 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [292, 358, 459, 551, 544, 430, 407, 404, 292]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 9, 18, 16, 16, 7, 11, 15, 13]
	Time taken saving stuff: 0.02s

=== episode:182 Env-steps-taken:62592
 	picked: 58 |actions: {0: 366, 1: 420, 2: 343, 3: 459, 4: 545, 5: 379, 6: 338, 7: 375, 8: 635}
episode: 182/2000 -> reward: 73.17708333333337, steps:3860, time-taken: 1.94min, time-elasped: 371.40min
-> berries picked: 58 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3748 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [291, 367, 458, 554, 540, 433, 407, 404, 294]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 11, 14, 13, 17, 5, 13, 11, 19]
	Time taken saving stuff: 0.09s

=== episode:183 Env-steps-taken:58368
 	picked: 41 |actions: {0: 321, 1: 358, 2: 290, 3: 372, 4: 343, 5: 266, 6: 211, 7: 220, 8: 259}
episode: 183/2000 -> reward: 50.208333333333364, steps:2640, time-taken: 1.59min, time-elasped: 373.00min
-> berries picked: 41 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3746 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [290, 364, 459, 553, 541, 432, 408, 402, 297]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 11, 10, 14, 10, 12, 14, 9, 18]
	Time taken saving stuff: 0.02s

=== episode:184 Env-steps-taken:58368
 	picked: 37 |actions: {0: 187, 1: 155, 2: 138, 3: 186, 4: 269, 5: 305, 6: 206, 7: 158, 8: 218}
episode: 184/2000 -> reward: 52.38020833333336, steps:1822, time-taken: 1.07min, time-elasped: 374.07min
-> berries picked: 37 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3766 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [294, 364, 462, 551, 547, 437, 410, 404, 297]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 11, 16, 18, 13, 18, 12, 6, 15]
	Time taken saving stuff: 0.11s

=== episode:185 Env-steps-taken:65760
 	picked: 57 |actions: {0: 530, 1: 392, 2: 421, 3: 380, 4: 391, 5: 439, 6: 482, 7: 380, 8: 432}
episode: 185/2000 -> reward: 89.73437499999997, steps:3847, time-taken: 1.97min, time-elasped: 376.05min
-> berries picked: 57 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3767 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [291, 358, 467, 543, 545, 442, 413, 411, 297]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 17, 15, 13, 13, 14, 10, 7, 9]
	Time taken saving stuff: 0.08s

=== episode:186 Env-steps-taken:50112
 	picked: 6 |actions: {0: 25, 1: 21, 2: 56, 3: 67, 4: 105, 5: 39, 6: 32, 7: 27, 8: 58}
episode: 186/2000 -> reward: 10.656250000000002, steps:430, time-taken: 0.50min, time-elasped: 376.55min
-> berries picked: 6 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3769 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [291, 358, 466, 544, 545, 442, 414, 411, 298]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 15, 12, 14, 14, 9, 11, 9, 16]
	Time taken saving stuff: 0.01s

=== episode:187 Env-steps-taken:58176
 	picked: 36 |actions: {0: 163, 1: 244, 2: 163, 3: 207, 4: 201, 5: 203, 6: 211, 7: 168, 8: 310}
episode: 187/2000 -> reward: 51.43750000000003, steps:1870, time-taken: 1.19min, time-elasped: 377.75min
-> berries picked: 36 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3770 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [289, 357, 466, 542, 544, 447, 417, 409, 299]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 10, 15, 14, 10, 13, 12, 9, 17]
	Time taken saving stuff: 0.00s

=== episode:188 Env-steps-taken:70944
 	picked: 77 |actions: {0: 393, 1: 293, 2: 440, 3: 436, 4: 424, 5: 449, 6: 635, 7: 374, 8: 476}
episode: 188/2000 -> reward: 116.08854166666654, steps:3920, time-taken: 1.98min, time-elasped: 379.73min
-> berries picked: 77 of 800 | patches-visited: [0, 3, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3782 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [285, 357, 464, 541, 549, 453, 422, 409, 302]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 12, 15, 13, 10, 13, 8, 8, 10]
	Time taken saving stuff: 0.01s

=== episode:189 Env-steps-taken:55776
 	picked: 26 |actions: {0: 156, 1: 149, 2: 166, 3: 204, 4: 168, 5: 174, 6: 191, 7: 128, 8: 198}
episode: 189/2000 -> reward: 39.01041666666667, steps:1534, time-taken: 0.91min, time-elasped: 380.65min
-> berries picked: 26 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3783 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [284, 359, 465, 541, 546, 455, 421, 410, 302]
	| approx positives in sample 512: 94
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 10, 9, 9, 17, 15, 9, 6, 8]
	Time taken saving stuff: 0.10s

=== episode:190 Env-steps-taken:56736
 	picked: 34 |actions: {0: 219, 1: 170, 2: 221, 3: 255, 4: 313, 5: 273, 6: 288, 7: 166, 8: 196}
episode: 190/2000 -> reward: 44.05208333333335, steps:2101, time-taken: 1.10min, time-elasped: 381.75min
-> berries picked: 34 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3781 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [285, 355, 460, 543, 547, 454, 422, 411, 304]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 5, 17, 18, 9, 8, 10, 13, 14]
	Time taken saving stuff: 0.06s

=== episode:19 Env-steps-taken:57888
 	picked: 32 |actions: {0: 55, 1: 42, 2: 149, 3: 104, 4: 178, 5: 148, 6: 77, 7: 31, 8: 170}

==================================================
eval-episode: 190 -> reward: 48.281250000000014, steps: 954.0, wall-time: 36.42s
-> berries picked: 32 of 800 | patches-visited: [0, 1] | juice left:-0.00
==================================================


=== episode:191 Env-steps-taken:70272
 	picked: 84 |actions: {0: 613, 1: 778, 2: 601, 3: 642, 4: 607, 5: 598, 6: 697, 7: 565, 8: 633}
episode: 191/2000 -> reward: 111.6874999999999, steps:5734, time-taken: 2.72min, time-elasped: 385.08min
-> berries picked: 84 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3779 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [278, 360, 458, 539, 545, 463, 421, 408, 307]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 7, 12, 16, 14, 17, 13, 12, 17]
	Time taken saving stuff: 0.10s

=== episode:192 Env-steps-taken:49632
 	picked: 6 |actions: {0: 31, 1: 36, 2: 56, 3: 76, 4: 68, 5: 45, 6: 52, 7: 38, 8: 55}
episode: 192/2000 -> reward: 8.15625, steps:457, time-taken: 0.40min, time-elasped: 385.49min
-> berries picked: 6 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3780 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [277, 360, 460, 537, 546, 464, 422, 407, 307]
	| approx positives in sample 512: 99
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 8, 9, 10, 16, 12, 9, 7, 16]
	Time taken saving stuff: 0.09s

=== episode:193 Env-steps-taken:63264
 	picked: 54 |actions: {0: 422, 1: 317, 2: 370, 3: 364, 4: 605, 5: 430, 6: 379, 7: 421, 8: 491}
episode: 193/2000 -> reward: 76.40625, steps:3799, time-taken: 1.95min, time-elasped: 387.44min
-> berries picked: 54 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3791 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [279, 362, 455, 541, 546, 467, 422, 411, 308]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 12, 9, 20, 12, 19, 14, 8, 14]
	Time taken saving stuff: 0.09s

=== episode:194 Env-steps-taken:50304
 	picked: 9 |actions: {0: 68, 1: 32, 2: 86, 3: 34, 4: 108, 5: 72, 6: 67, 7: 61, 8: 150}
episode: 194/2000 -> reward: 11.484375, steps:678, time-taken: 0.53min, time-elasped: 387.98min
-> berries picked: 9 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3790 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [278, 361, 456, 540, 549, 467, 423, 408, 308]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 6, 9, 14, 15, 18, 17, 4, 10]
	Time taken saving stuff: 0.08s

=== episode:195 Env-steps-taken:61536
 	picked: 53 |actions: {0: 378, 1: 356, 2: 438, 3: 349, 4: 573, 5: 679, 6: 436, 7: 341, 8: 521}
episode: 195/2000 -> reward: 67.46354166666673, steps:4071, time-taken: 1.95min, time-elasped: 389.93min
-> berries picked: 53 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3778 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [273, 359, 452, 538, 545, 470, 428, 406, 307]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 8, 13, 16, 20, 12, 13, 7, 15]
	Time taken saving stuff: 0.10s

=== episode:196 Env-steps-taken:55488
 	picked: 26 |actions: {0: 93, 1: 111, 2: 120, 3: 179, 4: 249, 5: 200, 6: 121, 7: 93, 8: 140}
episode: 196/2000 -> reward: 37.51041666666667, steps:1306, time-taken: 0.91min, time-elasped: 390.85min
-> berries picked: 26 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3788 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [273, 357, 455, 539, 552, 469, 428, 408, 307]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [17, 6, 13, 11, 13, 12, 17, 11, 14]
	Time taken saving stuff: 0.09s

=== episode:197 Env-steps-taken:58080
 	picked: 34 |actions: {0: 277, 1: 248, 2: 331, 3: 281, 4: 302, 5: 191, 6: 335, 7: 235, 8: 219}
episode: 197/2000 -> reward: 50.552083333333364, steps:2419, time-taken: 1.35min, time-elasped: 392.21min
-> berries picked: 34 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3788 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [273, 350, 451, 538, 554, 470, 433, 415, 304]
	| approx positives in sample 512: 90
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 8, 6, 14, 16, 8, 3, 8, 14]
	Time taken saving stuff: 0.09s

=== episode:198 Env-steps-taken:55776
 	picked: 28 |actions: {0: 242, 1: 227, 2: 263, 3: 238, 4: 199, 5: 291, 6: 225, 7: 191, 8: 201}
episode: 198/2000 -> reward: 38.89583333333335, steps:2077, time-taken: 1.12min, time-elasped: 393.33min
-> berries picked: 28 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3790 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [275, 352, 452, 541, 555, 468, 431, 410, 306]
	| approx positives in sample 512: 99
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 5, 10, 11, 19, 14, 10, 13, 11]
	Time taken saving stuff: 0.03s

=== episode:199 Env-steps-taken:49248
 	picked: 6 |actions: {0: 45, 1: 53, 2: 78, 3: 56, 4: 85, 5: 75, 6: 54, 7: 33, 8: 174}
episode: 199/2000 -> reward: 6.656249999999997, steps:653, time-taken: 0.63min, time-elasped: 393.96min
-> berries picked: 6 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3790 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [275, 350, 453, 542, 555, 468, 431, 409, 307]
	| approx positives in sample 512: 100
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 6, 13, 12, 6, 18, 11, 10, 16]
	Time taken saving stuff: 0.08s

=== episode:200 Env-steps-taken:70848
 	picked: 86 |actions: {0: 578, 1: 521, 2: 637, 3: 595, 4: 564, 5: 637, 6: 587, 7: 490, 8: 435}
episode: 200/2000 -> reward: 114.57291666666653, steps:5044, time-taken: 2.43min, time-elasped: 396.39min
-> berries picked: 86 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3801 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [279, 348, 449, 547, 560, 467, 431, 410, 310]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 6, 14, 11, 20, 12, 10, 12, 13]
	Time taken saving stuff: 0.15s

=== episode:20 Env-steps-taken:51936
 	picked: 13 |actions: {0: 2289, 1: 51, 2: 20, 3: 9, 4: 2223, 5: 16, 6: 24, 7: 90, 8: 0}

==================================================
eval-episode: 200 -> reward: 19.755208333333336, steps: 4722.0, wall-time: 41.54s
-> berries picked: 13 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:201 Env-steps-taken:48576
 	picked: 3 |actions: {0: 25, 1: 34, 2: 27, 3: 32, 4: 32, 5: 36, 6: 17, 7: 21, 8: 133}
episode: 201/2000 -> reward: 2.828124999999999, steps:357, time-taken: 0.55min, time-elasped: 397.64min
-> berries picked: 3 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3799 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [279, 348, 448, 546, 560, 468, 430, 409, 311]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 8, 9, 14, 18, 19, 13, 9, 5]
	Time taken saving stuff: 0.00s

=== episode:202 Env-steps-taken:53952
 	picked: 21 |actions: {0: 251, 1: 136, 2: 149, 3: 121, 4: 178, 5: 152, 6: 174, 7: 177, 8: 207}
episode: 202/2000 -> reward: 29.796874999999996, steps:1545, time-taken: 1.03min, time-elasped: 398.67min
-> berries picked: 21 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3790 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [281, 348, 444, 542, 561, 468, 426, 410, 310]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 6, 10, 18, 10, 10, 8, 16, 20]
	Time taken saving stuff: 0.01s

=== episode:203 Env-steps-taken:56544
 	picked: 31 |actions: {0: 260, 1: 214, 2: 278, 3: 252, 4: 418, 5: 354, 6: 235, 7: 200, 8: 436}
episode: 203/2000 -> reward: 42.723958333333364, steps:2647, time-taken: 1.43min, time-elasped: 400.11min
-> berries picked: 31 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3786 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [280, 350, 444, 537, 558, 467, 429, 409, 312]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 12, 13, 12, 10, 17, 10, 7, 12]
	Time taken saving stuff: 0.02s

=== episode:204 Env-steps-taken:62112
 	picked: 51 |actions: {0: 383, 1: 318, 2: 247, 3: 294, 4: 280, 5: 396, 6: 252, 7: 301, 8: 441}
episode: 204/2000 -> reward: 71.07812500000001, steps:2912, time-taken: 1.51min, time-elasped: 401.63min
-> berries picked: 51 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3807 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [283, 352, 446, 541, 561, 469, 428, 411, 316]
	| approx positives in sample 512: 99
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 10, 10, 11, 15, 13, 8, 12, 14]
	Time taken saving stuff: 0.02s

=== episode:205 Env-steps-taken:60480
 	picked: 46 |actions: {0: 325, 1: 400, 2: 341, 3: 306, 4: 490, 5: 541, 6: 449, 7: 395, 8: 564}
episode: 205/2000 -> reward: 62.86458333333339, steps:3811, time-taken: 1.88min, time-elasped: 403.51min
-> berries picked: 46 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3790 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [280, 348, 436, 541, 562, 475, 426, 406, 316]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 15, 12, 12, 16, 13, 15, 11, 14]
	Time taken saving stuff: 0.02s

=== episode:206 Env-steps-taken:59232
 	picked: 37 |actions: {0: 368, 1: 331, 2: 313, 3: 303, 4: 403, 5: 225, 6: 215, 7: 221, 8: 447}
episode: 206/2000 -> reward: 56.880208333333364, steps:2826, time-taken: 1.41min, time-elasped: 404.92min
-> berries picked: 37 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3799 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [282, 348, 441, 543, 563, 476, 428, 403, 315]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 7, 9, 15, 13, 17, 9, 11, 18]
	Time taken saving stuff: 0.02s

=== episode:207 Env-steps-taken:58656
 	picked: 35 |actions: {0: 223, 1: 357, 2: 260, 3: 205, 4: 293, 5: 171, 6: 217, 7: 161, 8: 157}
episode: 207/2000 -> reward: 53.494791666666686, steps:2044, time-taken: 1.20min, time-elasped: 406.12min
-> berries picked: 35 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3818 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [287, 353, 443, 546, 565, 474, 430, 406, 314]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 10, 14, 14, 19, 13, 6, 11, 15]
	Time taken saving stuff: 0.01s

=== episode:208 Env-steps-taken:62880
 	picked: 55 |actions: {0: 375, 1: 415, 2: 368, 3: 388, 4: 529, 5: 312, 6: 309, 7: 271, 8: 256}
episode: 208/2000 -> reward: 74.84895833333333, steps:3223, time-taken: 1.60min, time-elasped: 407.73min
-> berries picked: 55 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3835 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [286, 353, 448, 547, 570, 473, 429, 412, 317]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 14, 16, 16, 16, 17, 16, 10, 14]
	Time taken saving stuff: 0.09s

=== episode:209 Env-steps-taken:66240
 	picked: 64 |actions: {0: 452, 1: 424, 2: 570, 3: 532, 4: 926, 5: 755, 6: 524, 7: 413, 8: 768}
episode: 209/2000 -> reward: 91.83333333333329, steps:5364, time-taken: 2.51min, time-elasped: 410.24min
-> berries picked: 64 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3826 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [280, 355, 446, 548, 562, 476, 433, 408, 318]
	| approx positives in sample 512: 88
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 9, 9, 11, 15, 12, 8, 9, 8]
	Time taken saving stuff: 0.08s

=== episode:210 Env-steps-taken:66624
 	picked: 66 |actions: {0: 482, 1: 389, 2: 573, 3: 460, 4: 405, 5: 486, 6: 454, 7: 402, 8: 485}
episode: 210/2000 -> reward: 93.71874999999996, steps:4136, time-taken: 1.94min, time-elasped: 412.19min
-> berries picked: 66 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3838 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [283, 355, 447, 548, 563, 482, 428, 412, 320]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 15, 6, 19, 13, 17, 12, 15, 10]
	Time taken saving stuff: 0.05s

=== episode:21 Env-steps-taken:52416
 	picked: 17 |actions: {0: 383, 1: 0, 2: 899, 3: 81, 4: 54, 5: 807, 6: 27, 7: 365, 8: 3}

==================================================
eval-episode: 210 -> reward: 22.526041666666664, steps: 2619.0, wall-time: 33.13s
-> berries picked: 17 of 800 | patches-visited: [1, 8] | juice left:-0.00
==================================================


=== episode:211 Env-steps-taken:60096
 	picked: 42 |actions: {0: 334, 1: 248, 2: 373, 3: 345, 4: 407, 5: 431, 6: 286, 7: 244, 8: 365}
episode: 211/2000 -> reward: 61.093750000000036, steps:3033, time-taken: 1.50min, time-elasped: 414.24min
-> berries picked: 42 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3840 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [280, 353, 442, 554, 564, 486, 429, 410, 322]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 10, 9, 12, 18, 11, 9, 11, 20]
	Time taken saving stuff: 0.00s

=== episode:212 Env-steps-taken:66240
 	picked: 60 |actions: {0: 471, 1: 405, 2: 401, 3: 513, 4: 394, 5: 483, 6: 331, 7: 278, 8: 412}
episode: 212/2000 -> reward: 92.06249999999996, steps:3688, time-taken: 1.81min, time-elasped: 416.05min
-> berries picked: 60 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3853 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [286, 350, 443, 565, 566, 490, 425, 402, 326]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 7, 14, 16, 16, 8, 9, 3, 18]
	Time taken saving stuff: 0.01s

=== episode:213 Env-steps-taken:66912
 	picked: 66 |actions: {0: 460, 1: 392, 2: 497, 3: 592, 4: 554, 5: 646, 6: 494, 7: 554, 8: 617}
episode: 213/2000 -> reward: 95.21874999999994, steps:4806, time-taken: 2.37min, time-elasped: 418.43min
-> berries picked: 66 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3869 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [287, 351, 445, 563, 572, 495, 427, 404, 325]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 15, 16, 8, 13, 12, 13, 17, 23]
	Time taken saving stuff: 0.00s

=== episode:214 Env-steps-taken:53664
 	picked: 19 |actions: {0: 146, 1: 108, 2: 235, 3: 187, 4: 294, 5: 232, 6: 176, 7: 148, 8: 304}
episode: 214/2000 -> reward: 28.91145833333334, steps:1830, time-taken: 1.04min, time-elasped: 419.47min
-> berries picked: 19 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3867 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [286, 347, 441, 559, 574, 500, 429, 404, 327]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 9, 11, 22, 10, 8, 9, 10, 18]
	Time taken saving stuff: 0.01s

=== episode:215 Env-steps-taken:52416
 	picked: 16 |actions: {0: 124, 1: 156, 2: 139, 3: 163, 4: 186, 5: 176, 6: 81, 7: 112, 8: 162}
episode: 215/2000 -> reward: 22.08333333333333, steps:1299, time-taken: 0.97min, time-elasped: 420.44min
-> berries picked: 16 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3866 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [286, 345, 439, 559, 577, 501, 429, 403, 327]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 8, 8, 13, 16, 7, 13, 10, 16]
	Time taken saving stuff: 0.00s

=== episode:216 Env-steps-taken:65184
 	picked: 55 |actions: {0: 365, 1: 385, 2: 344, 3: 317, 4: 438, 5: 380, 6: 391, 7: 359, 8: 480}
episode: 216/2000 -> reward: 86.8489583333333, steps:3459, time-taken: 1.72min, time-elasped: 422.16min
-> berries picked: 55 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3896 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [287, 354, 440, 565, 584, 502, 430, 406, 328]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 10, 10, 14, 16, 13, 6, 16, 21]
	Time taken saving stuff: 0.12s

=== episode:217 Env-steps-taken:52224
 	picked: 15 |actions: {0: 92, 1: 77, 2: 104, 3: 129, 4: 190, 5: 90, 6: 80, 7: 72, 8: 72}
episode: 217/2000 -> reward: 21.140625, steps:906, time-taken: 0.72min, time-elasped: 422.88min
-> berries picked: 15 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3900 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [288, 353, 443, 567, 581, 502, 430, 408, 328]
	| approx positives in sample 512: 101
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 10, 12, 11, 8, 12, 10, 14, 16]
	Time taken saving stuff: 0.07s

=== episode:218 Env-steps-taken:54144
 	picked: 20 |actions: {0: 177, 1: 128, 2: 118, 3: 115, 4: 130, 5: 156, 6: 155, 7: 205, 8: 231}
episode: 218/2000 -> reward: 30.854166666666657, steps:1415, time-taken: 1.00min, time-elasped: 423.88min
-> berries picked: 20 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3906 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [286, 353, 442, 567, 580, 505, 434, 411, 328]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 12, 12, 14, 11, 16, 11, 10, 20]
	Time taken saving stuff: 0.01s

=== episode:219 Env-steps-taken:48864
 	picked: 5 |actions: {0: 43, 1: 32, 2: 92, 3: 45, 4: 91, 5: 42, 6: 59, 7: 43, 8: 112}
episode: 219/2000 -> reward: 4.213541666666666, steps:559, time-taken: 0.51min, time-elasped: 424.39min
-> berries picked: 5 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3906 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [285, 353, 442, 568, 581, 504, 434, 411, 328]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 11, 17, 11, 13, 10, 12, 10, 11]
	Time taken saving stuff: 0.02s

=== episode:220 Env-steps-taken:63072
 	picked: 54 |actions: {0: 349, 1: 326, 2: 337, 3: 418, 4: 323, 5: 462, 6: 376, 7: 373, 8: 523}
episode: 220/2000 -> reward: 75.96354166666667, steps:3487, time-taken: 1.79min, time-elasped: 426.19min
-> berries picked: 54 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3929 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [287, 355, 444, 572, 578, 515, 434, 415, 329]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 12, 12, 10, 18, 21, 10, 6, 16]
	Time taken saving stuff: 0.17s

=== episode:22 Env-steps-taken:51456
 	picked: 13 |actions: {0: 2, 1: 33, 2: 20, 3: 49, 4: 92, 5: 98, 6: 11, 7: 4, 8: 188}

==================================================
eval-episode: 220 -> reward: 17.755208333333336, steps: 497.0, wall-time: 29.90s
-> berries picked: 13 of 800 | patches-visited: [0, 1] | juice left:-0.00
==================================================


=== episode:221 Env-steps-taken:59424
 	picked: 42 |actions: {0: 284, 1: 264, 2: 308, 3: 260, 4: 419, 5: 338, 6: 347, 7: 248, 8: 451}
episode: 221/2000 -> reward: 58.09375000000004, steps:2919, time-taken: 1.48min, time-elasped: 428.17min
-> berries picked: 42 of 800 | patches-visited: [0, 4, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3947 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [288, 353, 447, 574, 578, 522, 434, 418, 333]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 6, 16, 17, 22, 16, 11, 9, 14]
	Time taken saving stuff: 0.09s

=== episode:222 Env-steps-taken:56832
 	picked: 27 |actions: {0: 252, 1: 162, 2: 189, 3: 156, 4: 308, 5: 271, 6: 209, 7: 199, 8: 440}
episode: 222/2000 -> reward: 44.953125000000014, steps:2186, time-taken: 1.30min, time-elasped: 429.48min
-> berries picked: 27 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3944 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [287, 354, 446, 569, 583, 524, 431, 416, 334]
	| approx positives in sample 512: 99
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 5, 13, 16, 14, 14, 9, 10, 10]
	Time taken saving stuff: 0.11s

=== episode:223 Env-steps-taken:53280
 	picked: 22 |actions: {0: 181, 1: 210, 2: 142, 3: 221, 4: 132, 5: 190, 6: 175, 7: 160, 8: 283}
episode: 223/2000 -> reward: 26.23958333333333, steps:1694, time-taken: 0.94min, time-elasped: 430.42min
-> berries picked: 22 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3955 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [288, 354, 447, 572, 587, 526, 432, 415, 334]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 12, 10, 12, 19, 14, 9, 10, 15]
	Time taken saving stuff: 0.01s

=== episode:224 Env-steps-taken:58272
 	picked: 37 |actions: {0: 237, 1: 233, 2: 250, 3: 253, 4: 396, 5: 308, 6: 292, 7: 254, 8: 278}
episode: 224/2000 -> reward: 51.880208333333364, steps:2501, time-taken: 1.47min, time-elasped: 431.89min
-> berries picked: 37 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3961 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [285, 356, 447, 572, 592, 529, 434, 410, 336]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 11, 17, 12, 17, 15, 9, 11, 11]
	Time taken saving stuff: 0.02s

=== episode:225 Env-steps-taken:68832
 	picked: 69 |actions: {0: 480, 1: 323, 2: 426, 3: 395, 4: 522, 5: 426, 6: 536, 7: 389, 8: 340}
episode: 225/2000 -> reward: 105.04687499999991, steps:3837, time-taken: 1.98min, time-elasped: 433.88min
-> berries picked: 69 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3974 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [285, 354, 448, 572, 593, 538, 437, 410, 337]
	| approx positives in sample 512: 100
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 12, 11, 16, 15, 11, 10, 9, 10]
	Time taken saving stuff: 0.12s

=== episode:226 Env-steps-taken:48384
 	picked: 2 |actions: {0: 13, 1: 10, 2: 19, 3: 16, 4: 41, 5: 28, 6: 19, 7: 13, 8: 48}
episode: 226/2000 -> reward: 1.8854166666666667, steps:207, time-taken: 0.60min, time-elasped: 434.48min
-> berries picked: 2 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3972 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [284, 354, 448, 570, 593, 538, 438, 410, 337]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 14, 7, 11, 18, 11, 14, 10, 20]
	Time taken saving stuff: 0.01s

=== episode:227 Env-steps-taken:58464
 	picked: 35 |actions: {0: 298, 1: 166, 2: 344, 3: 220, 4: 358, 5: 283, 6: 331, 7: 308, 8: 288}
episode: 227/2000 -> reward: 52.99479166666669, steps:2596, time-taken: 1.33min, time-elasped: 435.80min
-> berries picked: 35 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3977 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [283, 352, 447, 573, 594, 542, 433, 414, 339]
	| approx positives in sample 512: 101
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 10, 12, 10, 8, 14, 8, 11, 17]
	Time taken saving stuff: 0.00s

=== episode:228 Env-steps-taken:59616
 	picked: 44 |actions: {0: 244, 1: 196, 2: 290, 3: 272, 4: 250, 5: 286, 6: 262, 7: 193, 8: 313}
episode: 228/2000 -> reward: 58.479166666666714, steps:2306, time-taken: 1.28min, time-elasped: 437.09min
-> berries picked: 44 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3979 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [276, 351, 450, 576, 595, 548, 428, 415, 340]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 11, 12, 13, 13, 13, 9, 9, 19]
	Time taken saving stuff: 0.07s

=== episode:229 Env-steps-taken:55296
 	picked: 27 |actions: {0: 104, 1: 68, 2: 89, 3: 141, 4: 154, 5: 164, 6: 208, 7: 92, 8: 111}
episode: 229/2000 -> reward: 36.453125, steps:1131, time-taken: 0.76min, time-elasped: 437.85min
-> berries picked: 27 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3996 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [276, 350, 451, 576, 598, 551, 433, 418, 343]
	| approx positives in sample 512: 96
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 11, 6, 7, 17, 5, 24, 9, 13]
	Time taken saving stuff: 0.09s

=== episode:230 Env-steps-taken:61920
 	picked: 49 |actions: {0: 250, 1: 155, 2: 328, 3: 285, 4: 417, 5: 323, 6: 389, 7: 385, 8: 332}
episode: 230/2000 -> reward: 70.19270833333334, steps:2864, time-taken: 1.52min, time-elasped: 439.38min
-> berries picked: 49 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4005 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [273, 348, 454, 578, 600, 554, 434, 420, 344]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 5, 13, 15, 12, 17, 9, 12, 12]
	Time taken saving stuff: 0.15s

=== episode:23 Env-steps-taken:53376
 	picked: 18 |actions: {0: 87, 1: 34, 2: 2222, 3: 31, 4: 59, 5: 54, 6: 2248, 7: 112, 8: 6}

==================================================
eval-episode: 230 -> reward: 26.968749999999996, steps: 4853.0, wall-time: 45.97s
-> berries picked: 18 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:231 Env-steps-taken:60864
 	picked: 46 |actions: {0: 286, 1: 196, 2: 244, 3: 245, 4: 364, 5: 351, 6: 257, 7: 304, 8: 281}
episode: 231/2000 -> reward: 64.86458333333337, steps:2528, time-taken: 1.38min, time-elasped: 441.53min
-> berries picked: 46 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4021 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [275, 346, 449, 582, 604, 557, 437, 426, 345]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 12, 11, 14, 17, 10, 7, 15, 9]
	Time taken saving stuff: 0.10s

=== episode:232 Env-steps-taken:59328
 	picked: 41 |actions: {0: 285, 1: 275, 2: 412, 3: 401, 4: 511, 5: 423, 6: 334, 7: 288, 8: 551}
episode: 232/2000 -> reward: 56.651041666666714, steps:3480, time-taken: 1.66min, time-elasped: 443.19min
-> berries picked: 41 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4011 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [272, 343, 450, 584, 608, 558, 434, 418, 344]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 8, 14, 21, 17, 20, 9, 14, 13]
	Time taken saving stuff: 0.01s

=== episode:233 Env-steps-taken:58560
 	picked: 38 |actions: {0: 243, 1: 284, 2: 274, 3: 270, 4: 330, 5: 307, 6: 352, 7: 292, 8: 387}
episode: 233/2000 -> reward: 53.32291666666671, steps:2739, time-taken: 1.58min, time-elasped: 444.78min
-> berries picked: 38 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4006 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [271, 340, 446, 581, 606, 563, 435, 418, 346]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 6, 11, 15, 16, 24, 6, 7, 17]
	Time taken saving stuff: 0.10s

=== episode:234 Env-steps-taken:59520
 	picked: 43 |actions: {0: 271, 1: 209, 2: 405, 3: 248, 4: 387, 5: 498, 6: 366, 7: 369, 8: 410}
episode: 234/2000 -> reward: 57.536458333333364, steps:3163, time-taken: 1.63min, time-elasped: 446.41min
-> berries picked: 43 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3997 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [268, 335, 446, 581, 608, 568, 434, 414, 343]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 13, 10, 18, 13, 21, 10, 11, 12]
	Time taken saving stuff: 0.02s

=== episode:235 Env-steps-taken:51744
 	picked: 12 |actions: {0: 99, 1: 48, 2: 59, 3: 61, 4: 82, 5: 38, 6: 72, 7: 100, 8: 124}
episode: 235/2000 -> reward: 18.8125, steps:683, time-taken: 0.68min, time-elasped: 447.09min
-> berries picked: 12 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3992 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [268, 332, 445, 580, 608, 568, 433, 414, 344]
	| approx positives in sample 512: 82
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 11, 7, 11, 13, 9, 11, 10, 5]
	Time taken saving stuff: 0.01s

=== episode:236 Env-steps-taken:51264
 	picked: 11 |actions: {0: 180, 1: 107, 2: 113, 3: 95, 4: 182, 5: 102, 6: 123, 7: 152, 8: 274}
episode: 236/2000 -> reward: 16.36979166666667, steps:1328, time-taken: 0.78min, time-elasped: 447.87min
-> berries picked: 11 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3985 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [269, 329, 442, 580, 605, 569, 433, 414, 344]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 11, 10, 18, 20, 19, 11, 12, 17]
	Time taken saving stuff: 0.10s

=== episode:237 Env-steps-taken:55008
 	picked: 24 |actions: {0: 126, 1: 104, 2: 115, 3: 110, 4: 193, 5: 141, 6: 182, 7: 136, 8: 136}
episode: 237/2000 -> reward: 35.12500000000001, steps:1243, time-taken: 1.00min, time-elasped: 448.87min
-> berries picked: 24 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3992 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [267, 332, 440, 579, 606, 573, 438, 414, 343]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 11, 6, 20, 20, 16, 13, 7, 14]
	Time taken saving stuff: 0.10s

=== episode:238 Env-steps-taken:50880
 	picked: 9 |actions: {0: 90, 1: 74, 2: 82, 3: 72, 4: 115, 5: 108, 6: 70, 7: 148, 8: 113}
episode: 238/2000 -> reward: 14.484375000000002, steps:872, time-taken: 0.70min, time-elasped: 449.58min
-> berries picked: 9 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 3996 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [267, 334, 441, 580, 607, 574, 439, 412, 342]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 6, 13, 17, 14, 18, 13, 10, 17]
	Time taken saving stuff: 0.08s

=== episode:239 Env-steps-taken:63648
 	picked: 59 |actions: {0: 410, 1: 325, 2: 512, 3: 322, 4: 428, 5: 498, 6: 444, 7: 317, 8: 457}
episode: 239/2000 -> reward: 78.61979166666664, steps:3713, time-taken: 1.78min, time-elasped: 451.36min
-> berries picked: 59 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4011 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [260, 326, 450, 583, 615, 580, 439, 413, 345]
	| approx positives in sample 512: 88
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 7, 14, 10, 9, 11, 7, 9, 13]
	Time taken saving stuff: 0.12s

=== episode:240 Env-steps-taken:66912
 	picked: 72 |actions: {0: 427, 1: 377, 2: 362, 3: 368, 4: 506, 5: 553, 6: 640, 7: 588, 8: 605}
episode: 240/2000 -> reward: 94.93229166666661, steps:4426, time-taken: 2.15min, time-elasped: 453.52min
-> berries picked: 72 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4029 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [254, 323, 449, 590, 611, 588, 447, 418, 349]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 11, 10, 16, 15, 13, 12, 13, 20]
	Time taken saving stuff: 0.07s

=== episode:24 Env-steps-taken:63456
 	picked: 53 |actions: {0: 267, 1: 104, 2: 118, 3: 311, 4: 189, 5: 294, 6: 302, 7: 212, 8: 234}

==================================================
eval-episode: 240 -> reward: 77.96354166666666, steps: 2031.0, wall-time: 36.87s
-> berries picked: 53 of 800 | patches-visited: [1, 4] | juice left:-0.00
==================================================


=== episode:241 Env-steps-taken:52512
 	picked: 17 |actions: {0: 129, 1: 60, 2: 98, 3: 92, 4: 86, 5: 146, 6: 155, 7: 119, 8: 236}
episode: 241/2000 -> reward: 23.026041666666657, steps:1121, time-taken: 0.81min, time-elasped: 454.95min
-> berries picked: 17 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4036 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [254, 322, 448, 591, 611, 593, 447, 420, 350]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 9, 12, 9, 11, 17, 15, 15, 13]
	Time taken saving stuff: 0.01s

=== episode:242 Env-steps-taken:66528
 	picked: 62 |actions: {0: 384, 1: 300, 2: 492, 3: 290, 4: 360, 5: 484, 6: 429, 7: 446, 8: 568}
episode: 242/2000 -> reward: 93.44791666666661, steps:3753, time-taken: 1.82min, time-elasped: 456.77min
-> berries picked: 62 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4028 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [248, 313, 449, 588, 613, 595, 451, 420, 351]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 9, 8, 9, 19, 14, 11, 12, 19]
	Time taken saving stuff: 0.00s

=== episode:243 Env-steps-taken:72960
 	picked: 85 |actions: {0: 522, 1: 499, 2: 430, 3: 436, 4: 626, 5: 677, 6: 653, 7: 678, 8: 714}
episode: 243/2000 -> reward: 126.13020833333317, steps:5235, time-taken: 2.45min, time-elasped: 459.23min
-> berries picked: 85 of 800 | patches-visited: [0, 4, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4028 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [245, 303, 450, 595, 621, 596, 448, 418, 352]
	| approx positives in sample 512: 91
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 4, 8, 16, 17, 14, 4, 6, 14]
	Time taken saving stuff: 0.02s

=== episode:244 Env-steps-taken:53856
 	picked: 21 |actions: {0: 155, 1: 228, 2: 213, 3: 195, 4: 363, 5: 295, 6: 354, 7: 262, 8: 342}
episode: 244/2000 -> reward: 29.296874999999996, steps:2407, time-taken: 1.32min, time-elasped: 460.55min
-> berries picked: 21 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4015 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [240, 300, 448, 594, 619, 595, 450, 415, 354]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 14, 14, 13, 17, 12, 14, 9, 25]
	Time taken saving stuff: 0.00s

=== episode:245 Env-steps-taken:52704
 	picked: 20 |actions: {0: 121, 1: 109, 2: 86, 3: 116, 4: 162, 5: 177, 6: 145, 7: 153, 8: 155}
episode: 245/2000 -> reward: 23.354166666666664, steps:1224, time-taken: 0.94min, time-elasped: 461.49min
-> berries picked: 20 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4022 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [243, 299, 445, 591, 622, 599, 449, 421, 353]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 5, 10, 19, 30, 15, 14, 6, 12]
	Time taken saving stuff: 0.00s

=== episode:246 Env-steps-taken:56832
 	picked: 28 |actions: {0: 134, 1: 119, 2: 160, 3: 116, 4: 223, 5: 166, 6: 254, 7: 172, 8: 172}
episode: 246/2000 -> reward: 44.39583333333336, steps:1516, time-taken: 0.99min, time-elasped: 462.49min
-> berries picked: 28 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4026 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [244, 302, 443, 593, 617, 599, 453, 423, 352]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 11, 11, 13, 18, 14, 7, 12, 19]
	Time taken saving stuff: 0.10s

=== episode:247 Env-steps-taken:64416
 	picked: 58 |actions: {0: 361, 1: 325, 2: 320, 3: 320, 4: 537, 5: 368, 6: 474, 7: 423, 8: 405}
episode: 247/2000 -> reward: 82.67708333333331, steps:3533, time-taken: 1.88min, time-elasped: 464.37min
-> berries picked: 58 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4023 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [245, 297, 446, 592, 612, 601, 454, 425, 351]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 11, 19, 16, 16, 17, 6, 8, 13]
	Time taken saving stuff: 0.02s

=== episode:248 Env-steps-taken:57312
 	picked: 32 |actions: {0: 291, 1: 279, 2: 230, 3: 185, 4: 343, 5: 319, 6: 633, 7: 290, 8: 475}
episode: 248/2000 -> reward: 46.66666666666668, steps:3045, time-taken: 1.55min, time-elasped: 465.93min
-> berries picked: 32 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4002 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [243, 296, 438, 594, 604, 600, 450, 426, 351]
	| approx positives in sample 512: 94
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 8, 9, 17, 11, 16, 7, 12, 10]
	Time taken saving stuff: 0.01s

=== episode:249 Env-steps-taken:56832
 	picked: 26 |actions: {0: 83, 1: 159, 2: 116, 3: 142, 4: 160, 5: 157, 6: 116, 7: 122, 8: 147}
episode: 249/2000 -> reward: 44.51041666666668, steps:1202, time-taken: 0.80min, time-elasped: 466.73min
-> berries picked: 26 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4011 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [242, 296, 439, 595, 607, 600, 452, 426, 354]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 9, 9, 11, 15, 17, 15, 16, 18]
	Time taken saving stuff: 0.09s

=== episode:250 Env-steps-taken:62400
 	picked: 52 |actions: {0: 369, 1: 458, 2: 432, 3: 404, 4: 842, 5: 402, 6: 598, 7: 556, 8: 681}
episode: 250/2000 -> reward: 72.52083333333334, steps:4742, time-taken: 2.23min, time-elasped: 468.97min
-> berries picked: 52 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4002 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [239, 291, 438, 592, 608, 598, 452, 430, 354]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 5, 11, 22, 16, 9, 11, 12, 14]
	Time taken saving stuff: 0.06s

=== episode:25 Env-steps-taken:53664
 	picked: 21 |actions: {0: 72, 1: 90, 2: 5, 3: 61, 4: 30, 5: 19, 6: 91, 7: 95, 8: 135}

==================================================
eval-episode: 250 -> reward: 28.29687499999999, steps: 598.0, wall-time: 30.14s
-> berries picked: 21 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:251 Env-steps-taken:63744
 	picked: 57 |actions: {0: 268, 1: 288, 2: 231, 3: 279, 4: 411, 5: 391, 6: 536, 7: 379, 8: 445}
episode: 251/2000 -> reward: 79.234375, steps:3228, time-taken: 1.68min, time-elasped: 471.16min
-> berries picked: 57 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4023 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [244, 296, 436, 594, 609, 605, 453, 429, 357]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 12, 7, 11, 19, 14, 11, 14, 13]
	Time taken saving stuff: 0.01s

=== episode:252 Env-steps-taken:54144
 	picked: 21 |actions: {0: 106, 1: 188, 2: 106, 3: 79, 4: 106, 5: 167, 6: 220, 7: 112, 8: 99}
episode: 252/2000 -> reward: 30.796874999999996, steps:1183, time-taken: 0.85min, time-elasped: 472.01min
-> berries picked: 21 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4024 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [245, 294, 434, 592, 610, 605, 456, 432, 356]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 10, 15, 16, 19, 11, 16, 13, 10]
	Time taken saving stuff: 0.01s

=== episode:253 Env-steps-taken:53472
 	picked: 19 |actions: {0: 116, 1: 184, 2: 192, 3: 170, 4: 267, 5: 139, 6: 161, 7: 109, 8: 263}
episode: 253/2000 -> reward: 27.911458333333332, steps:1601, time-taken: 1.01min, time-elasped: 473.03min
-> berries picked: 19 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4020 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [243, 295, 432, 591, 612, 601, 458, 432, 356]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 8, 17, 19, 8, 18, 13, 12, 7]
	Time taken saving stuff: 0.11s

=== episode:254 Env-steps-taken:52608
 	picked: 17 |actions: {0: 127, 1: 111, 2: 88, 3: 103, 4: 148, 5: 118, 6: 134, 7: 142, 8: 158}
episode: 254/2000 -> reward: 23.02604166666666, steps:1129, time-taken: 0.76min, time-elasped: 473.79min
-> berries picked: 17 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4027 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [241, 296, 434, 592, 611, 604, 460, 435, 354]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 7, 13, 11, 15, 12, 16, 12, 18]
	Time taken saving stuff: 0.01s

=== episode:255 Env-steps-taken:56832
 	picked: 28 |actions: {0: 254, 1: 272, 2: 171, 3: 213, 4: 349, 5: 382, 6: 385, 7: 252, 8: 480}
episode: 255/2000 -> reward: 44.39583333333335, steps:2758, time-taken: 1.39min, time-elasped: 475.18min
-> berries picked: 28 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4025 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [241, 298, 432, 596, 609, 600, 461, 433, 355]
	| approx positives in sample 512: 100
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [2, 9, 10, 14, 14, 9, 9, 16, 17]
	Time taken saving stuff: 0.01s

=== episode:256 Env-steps-taken:60192
 	picked: 44 |actions: {0: 277, 1: 210, 2: 155, 3: 163, 4: 188, 5: 309, 6: 373, 7: 260, 8: 264}
episode: 256/2000 -> reward: 61.47916666666672, steps:2199, time-taken: 1.20min, time-elasped: 476.38min
-> berries picked: 44 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4029 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [242, 293, 433, 592, 611, 606, 461, 435, 356]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 8, 13, 11, 19, 13, 7, 9, 12]
	Time taken saving stuff: 0.01s

=== episode:257 Env-steps-taken:57504
 	picked: 34 |actions: {0: 176, 1: 144, 2: 121, 3: 198, 4: 235, 5: 282, 6: 259, 7: 173, 8: 232}
episode: 257/2000 -> reward: 48.05208333333336, steps:1820, time-taken: 1.19min, time-elasped: 477.57min
-> berries picked: 34 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4042 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [245, 293, 431, 593, 614, 611, 464, 435, 356]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 3, 17, 13, 21, 19, 4, 15, 22]
	Time taken saving stuff: 0.00s

=== episode:258 Env-steps-taken:70272
 	picked: 78 |actions: {0: 640, 1: 607, 2: 446, 3: 411, 4: 685, 5: 521, 6: 878, 7: 543, 8: 757}
episode: 258/2000 -> reward: 110.08854166666654, steps:5488, time-taken: 2.53min, time-elasped: 480.11min
-> berries picked: 78 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4070 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [248, 295, 438, 597, 618, 612, 474, 429, 359]
	| approx positives in sample 512: 95
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 6, 9, 9, 10, 9, 12, 10, 26]
	Time taken saving stuff: 0.00s

=== episode:259 Env-steps-taken:57312
 	picked: 34 |actions: {0: 284, 1: 240, 2: 175, 3: 156, 4: 221, 5: 212, 6: 312, 7: 205, 8: 330}
episode: 259/2000 -> reward: 47.052083333333364, steps:2135, time-taken: 1.18min, time-elasped: 481.29min
-> berries picked: 34 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4086 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [248, 295, 441, 596, 618, 616, 479, 433, 360]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 7, 8, 17, 17, 17, 12, 14, 12]
	Time taken saving stuff: 0.01s

=== episode:260 Env-steps-taken:52608
 	picked: 17 |actions: {0: 70, 1: 85, 2: 33, 3: 75, 4: 143, 5: 60, 6: 121, 7: 99, 8: 151}
episode: 260/2000 -> reward: 23.026041666666664, steps:837, time-taken: 0.68min, time-elasped: 481.98min
-> berries picked: 17 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4091 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [244, 297, 439, 596, 619, 617, 479, 439, 361]
	| approx positives in sample 512: 95
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [2, 8, 8, 13, 7, 21, 8, 10, 18]
	Time taken saving stuff: 0.16s

=== episode:26 Env-steps-taken:65568
 	picked: 64 |actions: {0: 160, 1: 233, 2: 215, 3: 105, 4: 2997, 5: 161, 6: 170, 7: 232, 8: 520}

==================================================
eval-episode: 260 -> reward: 88.33333333333329, steps: 4793.0, wall-time: 38.99s
-> berries picked: 64 of 800 | patches-visited: [1, 4] | juice left:-0.00
==================================================


=== episode:261 Env-steps-taken:56832
 	picked: 31 |actions: {0: 163, 1: 242, 2: 144, 3: 194, 4: 366, 5: 250, 6: 317, 7: 200, 8: 248}
episode: 261/2000 -> reward: 42.781250000000014, steps:2124, time-taken: 1.28min, time-elasped: 483.91min
-> berries picked: 31 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4084 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [248, 294, 432, 594, 620, 616, 479, 439, 362]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 4, 9, 11, 13, 10, 11, 10, 22]
	Time taken saving stuff: 0.00s

=== episode:262 Env-steps-taken:49632
 	picked: 5 |actions: {0: 81, 1: 63, 2: 71, 3: 65, 4: 80, 5: 79, 6: 42, 7: 62, 8: 101}
episode: 262/2000 -> reward: 8.213541666666666, steps:644, time-taken: 0.60min, time-elasped: 484.52min
-> berries picked: 5 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4079 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [247, 295, 431, 595, 618, 613, 480, 439, 361]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 8, 10, 13, 15, 16, 13, 14, 15]
	Time taken saving stuff: 0.07s

=== episode:263 Env-steps-taken:65568
 	picked: 64 |actions: {0: 343, 1: 343, 2: 329, 3: 362, 4: 705, 5: 468, 6: 600, 7: 383, 8: 680}
episode: 263/2000 -> reward: 88.3333333333333, steps:4213, time-taken: 1.94min, time-elasped: 486.46min
-> berries picked: 64 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4063 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [248, 286, 430, 591, 614, 618, 480, 433, 363]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 7, 10, 16, 15, 22, 11, 9, 21]
	Time taken saving stuff: 0.02s

=== episode:264 Env-steps-taken:57120
 	picked: 34 |actions: {0: 237, 1: 212, 2: 170, 3: 259, 4: 267, 5: 424, 6: 555, 7: 286, 8: 445}
episode: 264/2000 -> reward: 46.05208333333336, steps:2855, time-taken: 1.53min, time-elasped: 488.00min
-> berries picked: 34 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4048 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [251, 279, 424, 587, 610, 620, 478, 435, 364]
	| approx positives in sample 512: 87
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 3, 12, 14, 12, 13, 7, 8, 14]
	Time taken saving stuff: 0.01s

=== episode:265 Env-steps-taken:68640
 	picked: 71 |actions: {0: 368, 1: 484, 2: 334, 3: 369, 4: 603, 5: 543, 6: 456, 7: 454, 8: 503}
episode: 265/2000 -> reward: 103.93229166666657, steps:4114, time-taken: 2.05min, time-elasped: 490.05min
-> berries picked: 71 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4063 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [255, 282, 424, 586, 615, 626, 477, 434, 364]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 10, 12, 14, 11, 9, 14, 10, 21]
	Time taken saving stuff: 0.01s

=== episode:266 Env-steps-taken:55296
 	picked: 22 |actions: {0: 109, 1: 93, 2: 112, 3: 95, 4: 260, 5: 193, 6: 201, 7: 141, 8: 233}
episode: 266/2000 -> reward: 37.23958333333334, steps:1437, time-taken: 0.89min, time-elasped: 490.95min
-> berries picked: 22 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4076 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [254, 279, 426, 585, 616, 632, 482, 435, 367]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 5, 3, 7, 14, 15, 5, 14, 24]
	Time taken saving stuff: 0.11s

=== episode:267 Env-steps-taken:63072
 	picked: 61 |actions: {0: 431, 1: 431, 2: 539, 3: 403, 4: 630, 5: 595, 6: 762, 7: 507, 8: 619}
episode: 267/2000 -> reward: 75.00520833333331, steps:4917, time-taken: 2.25min, time-elasped: 493.20min
-> berries picked: 61 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4067 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [253, 283, 422, 580, 616, 634, 484, 431, 364]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 5, 14, 12, 16, 23, 11, 11, 16]
	Time taken saving stuff: 0.09s

=== episode:268 Env-steps-taken:64320
 	picked: 56 |actions: {0: 343, 1: 475, 2: 343, 3: 328, 4: 396, 5: 512, 6: 510, 7: 368, 8: 376}
episode: 268/2000 -> reward: 82.29166666666664, steps:3651, time-taken: 1.96min, time-elasped: 495.16min
-> berries picked: 56 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4072 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [256, 278, 425, 581, 618, 636, 486, 426, 366]
	| approx positives in sample 512: 88
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 6, 7, 9, 12, 12, 14, 9, 15]
	Time taken saving stuff: 0.01s

=== episode:269 Env-steps-taken:54048
 	picked: 23 |actions: {0: 113, 1: 143, 2: 186, 3: 159, 4: 242, 5: 177, 6: 162, 7: 127, 8: 296}
episode: 269/2000 -> reward: 31.182291666666668, steps:1605, time-taken: 0.98min, time-elasped: 496.14min
-> berries picked: 23 of 800 | patches-visited: [0, 7, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4079 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [253, 277, 426, 582, 623, 636, 486, 426, 370]
	| approx positives in sample 512: 101
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 6, 13, 10, 12, 10, 14, 10, 19]
	Time taken saving stuff: 0.00s

=== episode:270 Env-steps-taken:63552
 	picked: 61 |actions: {0: 249, 1: 295, 2: 303, 3: 317, 4: 579, 5: 339, 6: 401, 7: 306, 8: 319}
episode: 270/2000 -> reward: 77.50520833333333, steps:3108, time-taken: 1.60min, time-elasped: 497.74min
-> berries picked: 61 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4088 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [248, 274, 429, 584, 631, 637, 490, 426, 369]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 7, 11, 17, 16, 17, 11, 8, 17]
	Time taken saving stuff: 0.12s

=== episode:27 Env-steps-taken:48864
 	picked: 3 |actions: {0: 0, 1: 0, 2: 0, 3: 0, 4: 6, 5: 8, 6: 9, 7: 3, 8: 74}

==================================================
eval-episode: 270 -> reward: 4.328125, steps: 100.0, wall-time: 29.72s
-> berries picked: 3 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:271 Env-steps-taken:63552
 	picked: 56 |actions: {0: 469, 1: 344, 2: 389, 3: 433, 4: 318, 5: 375, 6: 430, 7: 393, 8: 310}
episode: 271/2000 -> reward: 78.29166666666667, steps:3461, time-taken: 1.80min, time-elasped: 500.04min
-> berries picked: 56 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4087 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [253, 272, 426, 587, 629, 634, 491, 426, 369]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 4, 12, 12, 20, 18, 14, 12, 10]
	Time taken saving stuff: 0.02s

=== episode:272 Env-steps-taken:64224
 	picked: 61 |actions: {0: 331, 1: 296, 2: 425, 3: 358, 4: 580, 5: 544, 6: 424, 7: 320, 8: 481}
episode: 272/2000 -> reward: 81.50520833333333, steps:3759, time-taken: 1.92min, time-elasped: 501.96min
-> berries picked: 61 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4098 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [253, 268, 433, 585, 632, 635, 496, 424, 372]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 11, 10, 17, 11, 17, 12, 11, 17]
	Time taken saving stuff: 0.00s

=== episode:273 Env-steps-taken:65568
 	picked: 60 |actions: {0: 268, 1: 301, 2: 392, 3: 332, 4: 508, 5: 534, 6: 433, 7: 328, 8: 413}
episode: 273/2000 -> reward: 89.06249999999994, steps:3509, time-taken: 1.88min, time-elasped: 503.84min
-> berries picked: 60 of 800 | patches-visited: [0, 3, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4111 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [249, 270, 437, 591, 638, 634, 497, 421, 374]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 11, 14, 12, 19, 21, 8, 11, 19]
	Time taken saving stuff: 0.12s

=== episode:274 Env-steps-taken:66624
 	picked: 71 |actions: {0: 443, 1: 423, 2: 490, 3: 382, 4: 710, 5: 396, 6: 637, 7: 655, 8: 654}
episode: 274/2000 -> reward: 92.9322916666666, steps:4790, time-taken: 2.06min, time-elasped: 505.91min
-> berries picked: 71 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4120 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [249, 269, 438, 584, 641, 631, 504, 427, 377]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 3, 6, 21, 17, 16, 11, 12, 14]
	Time taken saving stuff: 0.02s

=== episode:275 Env-steps-taken:69120
 	picked: 75 |actions: {0: 465, 1: 448, 2: 465, 3: 479, 4: 737, 5: 365, 6: 437, 7: 379, 8: 534}
episode: 275/2000 -> reward: 104.81770833333323, steps:4309, time-taken: 1.95min, time-elasped: 507.86min
-> berries picked: 75 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4128 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [247, 268, 436, 584, 647, 632, 504, 431, 379]
	| approx positives in sample 512: 90
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 5, 12, 7, 9, 8, 20, 8, 18]
	Time taken saving stuff: 0.02s

=== episode:276 Env-steps-taken:67296
 	picked: 72 |actions: {0: 470, 1: 589, 2: 440, 3: 395, 4: 688, 5: 724, 6: 881, 7: 621, 8: 673}
episode: 276/2000 -> reward: 96.37499999999993, steps:5481, time-taken: 2.34min, time-elasped: 510.21min
-> berries picked: 72 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4126 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [238, 273, 435, 585, 643, 637, 508, 430, 377]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 9, 17, 14, 12, 14, 5, 8, 20]
	Time taken saving stuff: 0.00s

=== episode:277 Env-steps-taken:58656
 	picked: 32 |actions: {0: 194, 1: 252, 2: 218, 3: 195, 4: 309, 5: 192, 6: 252, 7: 225, 8: 330}
episode: 277/2000 -> reward: 54.1666666666667, steps:2167, time-taken: 1.30min, time-elasped: 511.51min
-> berries picked: 32 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4132 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [240, 278, 435, 582, 639, 638, 509, 431, 380]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 10, 15, 13, 11, 17, 14, 9, 23]
	Time taken saving stuff: 0.00s

=== episode:278 Env-steps-taken:59904
 	picked: 43 |actions: {0: 187, 1: 244, 2: 247, 3: 194, 4: 291, 5: 225, 6: 270, 7: 224, 8: 208}
episode: 278/2000 -> reward: 59.53645833333337, steps:2090, time-taken: 1.17min, time-elasped: 512.68min
-> berries picked: 43 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4150 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [246, 276, 439, 582, 641, 640, 510, 434, 382]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 14, 10, 8, 12, 21, 11, 12, 19]
	Time taken saving stuff: 0.00s

=== episode:279 Env-steps-taken:75072
 	picked: 99 |actions: {0: 628, 1: 699, 2: 555, 3: 522, 4: 942, 5: 712, 6: 880, 7: 780, 8: 590}
episode: 279/2000 -> reward: 135.82812499999991, steps:6308, time-taken: 2.75min, time-elasped: 515.43min
-> berries picked: 99 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4183 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [249, 275, 441, 578, 649, 645, 516, 447, 383]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [2, 6, 14, 12, 23, 11, 11, 16, 16]
	Time taken saving stuff: 0.00s

=== episode:280 Env-steps-taken:61248
 	picked: 51 |actions: {0: 407, 1: 389, 2: 337, 3: 216, 4: 526, 5: 363, 6: 392, 7: 477, 8: 304}
episode: 280/2000 -> reward: 65.69270833333339, steps:3411, time-taken: 1.71min, time-elasped: 517.15min
-> berries picked: 51 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4194 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [250, 277, 440, 576, 652, 644, 517, 453, 385]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 11, 10, 19, 18, 14, 12, 13, 15]
	Time taken saving stuff: 0.06s

=== episode:28 Env-steps-taken:86400
 	picked: 141 |actions: {0: 314, 1: 584, 2: 269, 3: 361, 4: 668, 5: 429, 6: 973, 7: 448, 8: 555}

==================================================
eval-episode: 280 -> reward: 192.03645833333354, steps: 4601.0, wall-time: 131.43s
-> berries picked: 141 of 800 | patches-visited: [1, 5, 9] | juice left:-0.00
==================================================


=== episode:281 Env-steps-taken:63840
 	picked: 63 |actions: {0: 373, 1: 553, 2: 395, 3: 396, 4: 697, 5: 534, 6: 499, 7: 344, 8: 379}
episode: 281/2000 -> reward: 78.50520833333333, steps:4170, time-taken: 5.07min, time-elasped: 524.41min
-> berries picked: 63 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4203 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [249, 274, 442, 579, 653, 648, 522, 450, 386]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 8, 8, 22, 22, 16, 13, 12, 20]
	Time taken saving stuff: 0.09s

=== episode:282 Env-steps-taken:59424
 	picked: 42 |actions: {0: 226, 1: 241, 2: 258, 3: 228, 4: 451, 5: 390, 6: 383, 7: 280, 8: 295}
episode: 282/2000 -> reward: 57.09375000000004, steps:2752, time-taken: 1.15min, time-elasped: 525.57min
-> berries picked: 42 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4214 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [250, 270, 443, 578, 658, 656, 524, 450, 385]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 8, 11, 15, 21, 17, 9, 15, 12]
	Time taken saving stuff: 0.10s

=== episode:283 Env-steps-taken:61248
 	picked: 49 |actions: {0: 317, 1: 211, 2: 291, 3: 201, 4: 295, 5: 362, 6: 362, 7: 283, 8: 218}
episode: 283/2000 -> reward: 66.69270833333337, steps:2540, time-taken: 1.17min, time-elasped: 526.74min
-> berries picked: 49 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4235 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [248, 266, 452, 581, 660, 657, 529, 454, 388]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 6, 26, 16, 20, 21, 10, 16, 12]
	Time taken saving stuff: 0.01s

=== episode:284 Env-steps-taken:60384
 	picked: 42 |actions: {0: 276, 1: 344, 2: 307, 3: 258, 4: 420, 5: 350, 6: 459, 7: 399, 8: 458}
episode: 284/2000 -> reward: 62.59375000000006, steps:3271, time-taken: 1.47min, time-elasped: 528.21min
-> berries picked: 42 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4241 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [249, 263, 453, 580, 659, 660, 531, 456, 390]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 7, 12, 14, 18, 16, 16, 15, 18]
	Time taken saving stuff: 0.02s

=== episode:285 Env-steps-taken:57024
 	picked: 33 |actions: {0: 160, 1: 227, 2: 167, 3: 182, 4: 248, 5: 292, 6: 209, 7: 169, 8: 132}
episode: 285/2000 -> reward: 45.109375000000014, steps:1786, time-taken: 1.12min, time-elasped: 529.33min
-> berries picked: 33 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4249 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [248, 262, 454, 580, 665, 665, 532, 454, 389]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 12, 9, 20, 14, 12, 13, 11, 16]
	Time taken saving stuff: 0.09s

=== episode:286 Env-steps-taken:65376
 	picked: 64 |actions: {0: 457, 1: 626, 2: 371, 3: 347, 4: 625, 5: 652, 6: 1037, 7: 521, 8: 680}
episode: 286/2000 -> reward: 86.83333333333329, steps:5316, time-taken: 2.34min, time-elasped: 531.67min
-> berries picked: 64 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4219 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [243, 261, 441, 570, 656, 667, 537, 454, 390]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 6, 12, 21, 15, 19, 13, 13, 18]
	Time taken saving stuff: 0.11s

=== episode:287 Env-steps-taken:61632
 	picked: 53 |actions: {0: 427, 1: 599, 2: 452, 3: 388, 4: 945, 5: 692, 6: 664, 7: 662, 8: 752}
episode: 287/2000 -> reward: 67.96354166666671, steps:5581, time-taken: 2.40min, time-elasped: 534.08min
-> berries picked: 53 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4206 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [237, 257, 436, 566, 654, 670, 541, 455, 390]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 6, 13, 10, 14, 20, 10, 12, 16]
	Time taken saving stuff: 0.01s

=== episode:288 Env-steps-taken:72192
 	picked: 90 |actions: {0: 566, 1: 529, 2: 539, 3: 489, 4: 795, 5: 740, 6: 891, 7: 616, 8: 539}
episode: 288/2000 -> reward: 121.34374999999984, steps:5704, time-taken: 2.66min, time-elasped: 536.74min
-> berries picked: 90 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4215 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [236, 255, 434, 565, 650, 673, 550, 462, 390]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 5, 9, 18, 19, 19, 15, 9, 19]
	Time taken saving stuff: 0.02s

=== episode:289 Env-steps-taken:64512
 	picked: 61 |actions: {0: 412, 1: 329, 2: 333, 3: 319, 4: 452, 5: 512, 6: 719, 7: 476, 8: 490}
episode: 289/2000 -> reward: 81.06249999999997, steps:4042, time-taken: 1.84min, time-elasped: 538.59min
-> berries picked: 61 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4214 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [235, 255, 433, 566, 648, 673, 551, 463, 390]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 3, 10, 9, 17, 22, 8, 11, 17]
	Time taken saving stuff: 0.01s

=== episode:290 Env-steps-taken:54432
 	picked: 23 |actions: {0: 158, 1: 105, 2: 98, 3: 117, 4: 256, 5: 175, 6: 180, 7: 123, 8: 83}
episode: 290/2000 -> reward: 32.18229166666666, steps:1295, time-taken: 0.88min, time-elasped: 539.47min
-> berries picked: 23 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4219 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [239, 254, 436, 567, 645, 673, 552, 464, 389]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 8, 5, 9, 15, 18, 13, 12, 23]
	Time taken saving stuff: 0.17s

=== episode:29 Env-steps-taken:49248
 	picked: 5 |actions: {0: 20, 1: 3, 2: 2218, 3: 0, 4: 6, 5: 9, 6: 2208, 7: 14, 8: 0}

==================================================
eval-episode: 290 -> reward: 6.213541666666667, steps: 4478.0, wall-time: 47.78s
-> berries picked: 5 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:291 Env-steps-taken:63360
 	picked: 49 |actions: {0: 169, 1: 234, 2: 211, 3: 198, 4: 359, 5: 355, 6: 380, 7: 301, 8: 183}
episode: 291/2000 -> reward: 77.19270833333336, steps:2390, time-taken: 1.21min, time-elasped: 541.49min
-> berries picked: 49 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4235 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [236, 258, 440, 566, 646, 680, 555, 466, 388]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 13, 11, 17, 10, 19, 6, 15, 18]
	Time taken saving stuff: 0.09s

=== episode:292 Env-steps-taken:58368
 	picked: 37 |actions: {0: 488, 1: 830, 2: 397, 3: 361, 4: 388, 5: 293, 6: 797, 7: 853, 8: 822}
episode: 292/2000 -> reward: 51.88020833333336, steps:5229, time-taken: 2.40min, time-elasped: 543.90min
-> berries picked: 37 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4194 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [235, 259, 429, 564, 634, 671, 547, 468, 387]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [15, 9, 9, 12, 17, 19, 8, 9, 15]
	Time taken saving stuff: 0.07s

=== episode:293 Env-steps-taken:60384
 	picked: 45 |actions: {0: 222, 1: 387, 2: 416, 3: 274, 4: 450, 5: 406, 6: 557, 7: 291, 8: 343}
episode: 293/2000 -> reward: 61.92187500000006, steps:3346, time-taken: 1.65min, time-elasped: 545.55min
-> berries picked: 45 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4199 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [235, 258, 426, 564, 630, 681, 547, 470, 388]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 6, 12, 9, 14, 19, 11, 13, 11]
	Time taken saving stuff: 0.10s

=== episode:294 Env-steps-taken:62496
 	picked: 55 |actions: {0: 266, 1: 432, 2: 293, 3: 238, 4: 347, 5: 284, 6: 451, 7: 302, 8: 279}
episode: 294/2000 -> reward: 72.84895833333334, steps:2892, time-taken: 1.48min, time-elasped: 547.04min
-> berries picked: 55 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4203 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [235, 257, 427, 567, 629, 678, 551, 470, 389]
	| approx positives in sample 512: 83
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 8, 5, 9, 14, 14, 9, 6, 12]
	Time taken saving stuff: 0.10s

=== episode:295 Env-steps-taken:68064
 	picked: 76 |actions: {0: 457, 1: 792, 2: 557, 3: 411, 4: 821, 5: 487, 6: 624, 7: 657, 8: 533}
episode: 295/2000 -> reward: 100.64583333333324, steps:5339, time-taken: 2.42min, time-elasped: 549.46min
-> berries picked: 76 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4201 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [234, 261, 426, 572, 626, 673, 546, 473, 390]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 14, 11, 15, 13, 15, 14, 7, 16]
	Time taken saving stuff: 0.08s

=== episode:296 Env-steps-taken:60288
 	picked: 42 |actions: {0: 221, 1: 235, 2: 282, 3: 289, 4: 414, 5: 390, 6: 308, 7: 234, 8: 328}
episode: 296/2000 -> reward: 62.09375000000004, steps:2701, time-taken: 1.39min, time-elasped: 550.86min
-> berries picked: 42 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4192 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [227, 253, 426, 573, 626, 679, 549, 472, 387]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 10, 10, 9, 20, 15, 17, 10, 24]
	Time taken saving stuff: 0.08s

=== episode:297 Env-steps-taken:58080
 	picked: 37 |actions: {0: 272, 1: 223, 2: 276, 3: 206, 4: 154, 5: 281, 6: 260, 7: 154, 8: 216}
episode: 297/2000 -> reward: 50.38020833333336, steps:2042, time-taken: 1.23min, time-elasped: 552.09min
-> berries picked: 37 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4200 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [228, 252, 429, 571, 629, 678, 550, 474, 389]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 6, 10, 16, 13, 12, 10, 10, 19]
	Time taken saving stuff: 0.03s

=== episode:298 Env-steps-taken:51648
 	picked: 12 |actions: {0: 82, 1: 66, 2: 92, 3: 78, 4: 53, 5: 88, 6: 45, 7: 45, 8: 80}
episode: 298/2000 -> reward: 18.3125, steps:629, time-taken: 0.65min, time-elasped: 552.75min
-> berries picked: 12 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4210 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [229, 256, 429, 573, 632, 679, 550, 473, 389]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 8, 11, 17, 15, 20, 7, 15, 21]
	Time taken saving stuff: 0.02s

=== episode:299 Env-steps-taken:63840
 	picked: 51 |actions: {0: 258, 1: 294, 2: 329, 3: 285, 4: 373, 5: 385, 6: 561, 7: 265, 8: 327}
episode: 299/2000 -> reward: 80.078125, steps:3077, time-taken: 1.54min, time-elasped: 554.29min
-> berries picked: 51 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4208 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [228, 253, 428, 566, 636, 679, 554, 473, 391]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 5, 13, 8, 13, 15, 18, 13, 13]
	Time taken saving stuff: 0.00s

=== episode:300 Env-steps-taken:56448
 	picked: 29 |actions: {0: 133, 1: 209, 2: 217, 3: 165, 4: 207, 5: 146, 6: 261, 7: 197, 8: 200}
episode: 300/2000 -> reward: 41.45312500000002, steps:1735, time-taken: 1.00min, time-elasped: 555.29min
-> berries picked: 29 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4209 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [229, 254, 427, 563, 636, 681, 554, 474, 391]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 2, 8, 12, 16, 17, 13, 8, 21]
	Time taken saving stuff: 0.15s

=== episode:30 Env-steps-taken:58560
 	picked: 36 |actions: {0: 56, 1: 159, 2: 112, 3: 140, 4: 116, 5: 273, 6: 100, 7: 128, 8: 256}

==================================================
eval-episode: 300 -> reward: 52.93750000000003, steps: 1340.0, wall-time: 30.21s
-> berries picked: 36 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:301 Env-steps-taken:64512
 	picked: 58 |actions: {0: 338, 1: 356, 2: 452, 3: 292, 4: 411, 5: 374, 6: 391, 7: 320, 8: 297}
episode: 301/2000 -> reward: 81.23437499999999, steps:3231, time-taken: 1.67min, time-elasped: 557.47min
-> berries picked: 58 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4193 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [230, 253, 420, 559, 637, 684, 549, 468, 393]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 6, 6, 14, 24, 13, 17, 10, 17]
	Time taken saving stuff: 0.06s

=== episode:302 Env-steps-taken:62208
 	picked: 56 |actions: {0: 334, 1: 316, 2: 392, 3: 306, 4: 479, 5: 587, 6: 617, 7: 346, 8: 578}
episode: 302/2000 -> reward: 70.7916666666667, steps:3955, time-taken: 1.92min, time-elasped: 559.39min
-> berries picked: 56 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4177 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [234, 249, 419, 552, 641, 684, 540, 468, 390]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 11, 10, 8, 12, 14, 11, 7, 22]
	Time taken saving stuff: 0.10s

=== episode:303 Env-steps-taken:64128
 	picked: 63 |actions: {0: 422, 1: 497, 2: 556, 3: 328, 4: 526, 5: 385, 6: 449, 7: 469, 8: 524}
episode: 303/2000 -> reward: 80.890625, steps:4156, time-taken: 2.05min, time-elasped: 561.44min
-> berries picked: 63 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4172 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [239, 255, 424, 551, 636, 683, 536, 460, 388]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 7, 12, 17, 18, 12, 8, 12, 18]
	Time taken saving stuff: 0.09s

=== episode:304 Env-steps-taken:67776
 	picked: 68 |actions: {0: 383, 1: 403, 2: 467, 3: 290, 4: 558, 5: 439, 6: 417, 7: 386, 8: 359}
episode: 304/2000 -> reward: 99.6041666666666, steps:3702, time-taken: 1.83min, time-elasped: 563.28min
-> berries picked: 68 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4187 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [237, 258, 431, 556, 640, 679, 536, 462, 388]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 10, 11, 26, 11, 14, 13, 8, 10]
	Time taken saving stuff: 0.10s

=== episode:305 Env-steps-taken:59232
 	picked: 44 |actions: {0: 263, 1: 346, 2: 371, 3: 273, 4: 380, 5: 447, 6: 265, 7: 306, 8: 394}
episode: 305/2000 -> reward: 55.979166666666714, steps:3045, time-taken: 1.57min, time-elasped: 564.85min
-> berries picked: 44 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4176 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [241, 259, 421, 557, 644, 674, 533, 459, 388]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 7, 14, 16, 15, 22, 10, 6, 19]
	Time taken saving stuff: 0.09s

=== episode:306 Env-steps-taken:61440
 	picked: 45 |actions: {0: 193, 1: 327, 2: 278, 3: 229, 4: 306, 5: 235, 6: 226, 7: 211, 8: 177}
episode: 306/2000 -> reward: 67.42187500000003, steps:2182, time-taken: 1.25min, time-elasped: 566.11min
-> berries picked: 45 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4165 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [243, 255, 424, 563, 642, 674, 529, 449, 386]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 3, 13, 17, 11, 14, 11, 8, 16]
	Time taken saving stuff: 0.00s

=== episode:307 Env-steps-taken:63744
 	picked: 60 |actions: {0: 530, 1: 414, 2: 326, 3: 410, 4: 442, 5: 497, 6: 645, 7: 450, 8: 659}
episode: 307/2000 -> reward: 78.5625, steps:4373, time-taken: 2.05min, time-elasped: 568.16min
-> berries picked: 60 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4166 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [251, 257, 421, 562, 640, 671, 527, 450, 387]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 6, 11, 13, 11, 20, 12, 12, 14]
	Time taken saving stuff: 0.02s

=== episode:308 Env-steps-taken:64416
 	picked: 60 |actions: {0: 433, 1: 471, 2: 336, 3: 344, 4: 483, 5: 335, 6: 509, 7: 318, 8: 415}
episode: 308/2000 -> reward: 82.5625, steps:3644, time-taken: 1.95min, time-elasped: 570.11min
-> berries picked: 60 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4175 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [254, 258, 426, 566, 632, 672, 527, 453, 387]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 4, 9, 12, 21, 21, 8, 11, 12]
	Time taken saving stuff: 0.01s

=== episode:309 Env-steps-taken:60960
 	picked: 44 |actions: {0: 313, 1: 255, 2: 267, 3: 215, 4: 290, 5: 293, 6: 300, 7: 339, 8: 252}
episode: 309/2000 -> reward: 63.53645833333338, steps:2524, time-taken: 1.42min, time-elasped: 571.53min
-> berries picked: 44 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4170 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [251, 259, 425, 563, 628, 672, 527, 455, 390]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 9, 15, 12, 15, 18, 10, 16, 20]
	Time taken saving stuff: 0.08s

=== episode:310 Env-steps-taken:63648
 	picked: 55 |actions: {0: 561, 1: 489, 2: 437, 3: 408, 4: 620, 5: 593, 6: 558, 7: 481, 8: 531}
episode: 310/2000 -> reward: 78.8489583333333, steps:4678, time-taken: 2.31min, time-elasped: 573.85min
-> berries picked: 55 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4153 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [250, 259, 422, 564, 627, 663, 524, 454, 390]
	| approx positives in sample 512: 94
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 2, 11, 8, 17, 17, 10, 9, 12]
	Time taken saving stuff: 0.15s

=== episode:31 Env-steps-taken:55392
 	picked: 29 |actions: {0: 239, 1: 90, 2: 41, 3: 21, 4: 147, 5: 79, 6: 66, 7: 121, 8: 217}

==================================================
eval-episode: 310 -> reward: 36.838541666666664, steps: 1021.0, wall-time: 27.93s
-> berries picked: 29 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:311 Env-steps-taken:56736
 	picked: 30 |actions: {0: 247, 1: 359, 2: 411, 3: 240, 4: 748, 5: 392, 6: 342, 7: 495, 8: 587}
episode: 311/2000 -> reward: 43.78125000000002, steps:3821, time-taken: 1.86min, time-elasped: 576.18min
-> berries picked: 30 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4135 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [251, 260, 426, 561, 625, 659, 519, 444, 390]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 11, 15, 14, 14, 11, 17, 16, 18]
	Time taken saving stuff: 0.01s

=== episode:312 Env-steps-taken:72672
 	picked: 92 |actions: {0: 429, 1: 617, 2: 569, 3: 476, 4: 810, 5: 641, 6: 604, 7: 499, 8: 562}
episode: 312/2000 -> reward: 123.34374999999983, steps:5207, time-taken: 2.56min, time-elasped: 578.75min
-> berries picked: 92 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4135 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [251, 265, 428, 567, 616, 651, 520, 442, 395]
	| approx positives in sample 512: 101
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 4, 9, 17, 12, 13, 8, 14, 15]
	Time taken saving stuff: 0.01s

=== episode:313 Env-steps-taken:74496
 	picked: 93 |actions: {0: 498, 1: 732, 2: 657, 3: 553, 4: 895, 5: 766, 6: 644, 7: 622, 8: 624}
episode: 313/2000 -> reward: 131.7864583333332, steps:5991, time-taken: 2.85min, time-elasped: 581.60min
-> berries picked: 93 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4149 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [254, 261, 432, 570, 617, 651, 520, 446, 398]
	| approx positives in sample 512: 90
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 7, 9, 8, 16, 14, 9, 11, 11]
	Time taken saving stuff: 0.09s

=== episode:314 Env-steps-taken:65280
 	picked: 70 |actions: {0: 491, 1: 531, 2: 470, 3: 392, 4: 897, 5: 836, 6: 534, 7: 398, 8: 724}
episode: 314/2000 -> reward: 85.98958333333329, steps:5273, time-taken: 2.35min, time-elasped: 583.95min
-> berries picked: 70 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4138 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [250, 256, 435, 572, 608, 654, 522, 444, 397]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 10, 7, 17, 12, 14, 6, 10, 14]
	Time taken saving stuff: 0.11s

=== episode:315 Env-steps-taken:48576
 	picked: 3 |actions: {0: 28, 1: 40, 2: 50, 3: 35, 4: 34, 5: 66, 6: 30, 7: 31, 8: 182}
episode: 315/2000 -> reward: 2.8281249999999996, steps:496, time-taken: 0.62min, time-elasped: 584.58min
-> berries picked: 3 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4134 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [250, 256, 434, 572, 607, 654, 522, 442, 397]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 1, 10, 16, 17, 12, 11, 10, 19]
	Time taken saving stuff: 0.10s

=== episode:316 Env-steps-taken:63552
 	picked: 62 |actions: {0: 234, 1: 377, 2: 255, 3: 291, 4: 364, 5: 293, 6: 415, 7: 277, 8: 323}
episode: 316/2000 -> reward: 77.94791666666666, steps:2829, time-taken: 1.50min, time-elasped: 586.08min
-> berries picked: 62 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4156 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [250, 260, 433, 577, 610, 654, 526, 447, 399]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 7, 8, 16, 11, 28, 11, 11, 21]
	Time taken saving stuff: 0.02s

=== episode:317 Env-steps-taken:49632
 	picked: 5 |actions: {0: 65, 1: 69, 2: 41, 3: 54, 4: 78, 5: 62, 6: 71, 7: 50, 8: 134}
episode: 317/2000 -> reward: 8.213541666666666, steps:624, time-taken: 0.65min, time-elasped: 586.74min
-> berries picked: 5 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4147 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [249, 261, 430, 576, 610, 652, 523, 447, 399]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 5, 19, 14, 14, 11, 12, 9, 22]
	Time taken saving stuff: 0.01s

=== episode:318 Env-steps-taken:51456
 	picked: 12 |actions: {0: 63, 1: 122, 2: 82, 3: 75, 4: 61, 5: 44, 6: 25, 7: 45, 8: 120}
episode: 318/2000 -> reward: 17.312500000000004, steps:637, time-taken: 0.78min, time-elasped: 587.52min
-> berries picked: 12 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4153 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [248, 261, 435, 576, 608, 653, 525, 448, 399]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 8, 14, 9, 16, 17, 15, 10, 16]
	Time taken saving stuff: 0.10s

=== episode:319 Env-steps-taken:55488
 	picked: 29 |actions: {0: 207, 1: 284, 2: 200, 3: 171, 4: 221, 5: 196, 6: 246, 7: 151, 8: 190}
episode: 319/2000 -> reward: 37.33854166666668, steps:1866, time-taken: 1.16min, time-elasped: 588.69min
-> berries picked: 29 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4135 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [250, 263, 436, 576, 601, 638, 525, 448, 398]
	| approx positives in sample 512: 90
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 7, 10, 10, 14, 13, 6, 11, 15]
	Time taken saving stuff: 0.00s

=== episode:320 Env-steps-taken:61728
 	picked: 46 |actions: {0: 299, 1: 316, 2: 286, 3: 256, 4: 473, 5: 319, 6: 245, 7: 249, 8: 242}
episode: 320/2000 -> reward: 68.86458333333337, steps:2685, time-taken: 1.39min, time-elasped: 590.08min
-> berries picked: 46 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4128 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [252, 268, 432, 570, 596, 639, 524, 450, 397]
	| approx positives in sample 512: 100
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 8, 8, 12, 20, 13, 9, 9, 13]
	Time taken saving stuff: 0.08s

=== episode:32 Env-steps-taken:61344
 	picked: 51 |actions: {0: 217, 1: 720, 2: 127, 3: 40, 4: 320, 5: 679, 6: 133, 7: 184, 8: 11}

==================================================
eval-episode: 320 -> reward: 67.07812500000003, steps: 2431.0, wall-time: 37.07s
-> berries picked: 51 of 800 | patches-visited: [1, 3] | juice left:-0.00
==================================================


=== episode:321 Env-steps-taken:68160
 	picked: 75 |actions: {0: 321, 1: 471, 2: 404, 3: 356, 4: 505, 5: 374, 6: 583, 7: 426, 8: 295}
episode: 321/2000 -> reward: 100.81770833333324, steps:3735, time-taken: 1.94min, time-elasped: 592.64min
-> berries picked: 75 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4142 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [253, 270, 438, 570, 592, 630, 528, 462, 399]
	| approx positives in sample 512: 88
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 13, 9, 7, 10, 12, 8, 8, 14]
	Time taken saving stuff: 0.01s

=== episode:322 Env-steps-taken:56160
 	picked: 27 |actions: {0: 149, 1: 156, 2: 202, 3: 176, 4: 289, 5: 206, 6: 110, 7: 147, 8: 240}
episode: 322/2000 -> reward: 41.453125, steps:1675, time-taken: 1.12min, time-elasped: 593.76min
-> berries picked: 27 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4144 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [253, 271, 438, 576, 596, 624, 526, 461, 399]
	| approx positives in sample 512: 99
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [13, 5, 10, 17, 10, 12, 7, 11, 14]
	Time taken saving stuff: 0.01s

=== episode:323 Env-steps-taken:60192
 	picked: 42 |actions: {0: 192, 1: 349, 2: 312, 3: 223, 4: 420, 5: 213, 6: 201, 7: 201, 8: 285}
episode: 323/2000 -> reward: 61.09375000000005, steps:2396, time-taken: 1.31min, time-elasped: 595.08min
-> berries picked: 42 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4147 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [251, 270, 445, 582, 597, 617, 524, 463, 398]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 10, 12, 16, 15, 13, 7, 6, 18]
	Time taken saving stuff: 0.03s

=== episode:324 Env-steps-taken:58368
 	picked: 34 |actions: {0: 188, 1: 295, 2: 241, 3: 152, 4: 221, 5: 245, 6: 282, 7: 207, 8: 228}
episode: 324/2000 -> reward: 52.55208333333337, steps:2059, time-taken: 1.23min, time-elasped: 596.31min
-> berries picked: 34 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4146 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [249, 270, 448, 585, 595, 616, 520, 464, 399]
	| approx positives in sample 512: 92
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [2, 6, 11, 15, 12, 14, 7, 11, 14]
	Time taken saving stuff: 0.12s

=== episode:325 Env-steps-taken:67488
 	picked: 74 |actions: {0: 327, 1: 578, 2: 439, 3: 371, 4: 776, 5: 593, 6: 510, 7: 535, 8: 333}
episode: 325/2000 -> reward: 97.76041666666659, steps:4462, time-taken: 2.22min, time-elasped: 598.54min
-> berries picked: 74 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4154 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [250, 278, 451, 585, 593, 609, 519, 470, 399]
	| approx positives in sample 512: 101
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 8, 12, 12, 11, 13, 10, 10, 16]
	Time taken saving stuff: 0.10s

=== episode:326 Env-steps-taken:60576
 	picked: 42 |actions: {0: 275, 1: 297, 2: 277, 3: 328, 4: 562, 5: 406, 6: 583, 7: 245, 8: 326}
episode: 326/2000 -> reward: 63.59375000000004, steps:3299, time-taken: 1.63min, time-elasped: 600.17min
-> berries picked: 42 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4136 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [248, 276, 450, 591, 580, 600, 517, 472, 402]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 11, 7, 12, 9, 21, 3, 9, 22]
	Time taken saving stuff: 0.01s

=== episode:327 Env-steps-taken:65376
 	picked: 66 |actions: {0: 585, 1: 744, 2: 388, 3: 394, 4: 826, 5: 600, 6: 734, 7: 439, 8: 494}
episode: 327/2000 -> reward: 87.21874999999996, steps:5204, time-taken: 2.44min, time-elasped: 602.62min
-> berries picked: 66 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4122 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [252, 275, 454, 584, 573, 592, 519, 472, 401]
	| approx positives in sample 512: 88
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 7, 11, 10, 6, 15, 9, 7, 13]
	Time taken saving stuff: 0.00s

=== episode:328 Env-steps-taken:51552
 	picked: 12 |actions: {0: 46, 1: 79, 2: 67, 3: 54, 4: 116, 5: 86, 6: 59, 7: 38, 8: 111}
episode: 328/2000 -> reward: 17.8125, steps:656, time-taken: 0.82min, time-elasped: 603.44min
-> berries picked: 12 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4129 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [251, 275, 456, 583, 575, 597, 518, 472, 402]
	| approx positives in sample 512: 92
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 10, 9, 12, 10, 10, 14, 6, 16]
	Time taken saving stuff: 0.00s

=== episode:329 Env-steps-taken:70560
 	picked: 79 |actions: {0: 500, 1: 632, 2: 456, 3: 424, 4: 722, 5: 506, 6: 569, 7: 552, 8: 386}
episode: 329/2000 -> reward: 113.4739583333332, steps:4747, time-taken: 2.14min, time-elasped: 605.59min
-> berries picked: 79 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4137 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [254, 281, 459, 586, 565, 590, 520, 480, 402]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 13, 8, 16, 18, 9, 9, 12, 16]
	Time taken saving stuff: 0.00s

=== episode:330 Env-steps-taken:48192
 	picked: 1 |actions: {0: 15, 1: 22, 2: 14, 3: 16, 4: 80, 5: 21, 6: 18, 7: 12, 8: 73}
episode: 330/2000 -> reward: 0.9427083333333334, steps:271, time-taken: 0.63min, time-elasped: 606.22min
-> berries picked: 1 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4135 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [254, 281, 459, 586, 564, 590, 520, 478, 403]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 8, 15, 9, 15, 10, 10, 17, 18]
	Time taken saving stuff: 0.05s

=== episode:33 Env-steps-taken:74400
 	picked: 97 |actions: {0: 526, 1: 572, 2: 167, 3: 183, 4: 1253, 5: 100, 6: 347, 7: 340, 8: 52}

==================================================
eval-episode: 330 -> reward: 132.9427083333332, steps: 3540.0, wall-time: 45.40s
-> berries picked: 97 of 800 | patches-visited: [1, 2, 3] | juice left:-0.00
==================================================


=== episode:331 Env-steps-taken:68256
 	picked: 72 |actions: {0: 390, 1: 475, 2: 414, 3: 412, 4: 593, 5: 409, 6: 532, 7: 445, 8: 307}
episode: 331/2000 -> reward: 101.8749999999999, steps:3977, time-taken: 1.96min, time-elasped: 608.94min
-> berries picked: 72 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4153 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [252, 281, 458, 591, 571, 594, 527, 477, 402]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 9, 12, 11, 10, 15, 11, 12, 16]
	Time taken saving stuff: 0.11s

=== episode:332 Env-steps-taken:62304
 	picked: 51 |actions: {0: 158, 1: 232, 2: 236, 3: 208, 4: 386, 5: 336, 6: 297, 7: 194, 8: 192}
episode: 332/2000 -> reward: 71.69270833333336, steps:2239, time-taken: 1.28min, time-elasped: 610.23min
-> berries picked: 51 of 800 | patches-visited: [0, 5, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4169 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [250, 282, 462, 591, 575, 595, 532, 477, 405]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 10, 10, 13, 14, 21, 12, 17, 19]
	Time taken saving stuff: 0.02s

=== episode:333 Env-steps-taken:67392
 	picked: 68 |actions: {0: 345, 1: 438, 2: 369, 3: 316, 4: 472, 5: 428, 6: 518, 7: 467, 8: 249}
episode: 333/2000 -> reward: 97.6041666666666, steps:3602, time-taken: 1.81min, time-elasped: 612.04min
-> berries picked: 68 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4174 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [249, 284, 463, 589, 575, 593, 537, 479, 405]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 3, 9, 14, 11, 26, 10, 15, 15]
	Time taken saving stuff: 0.02s

=== episode:334 Env-steps-taken:53952
 	picked: 24 |actions: {0: 105, 1: 91, 2: 165, 3: 188, 4: 181, 5: 154, 6: 162, 7: 135, 8: 146}
episode: 334/2000 -> reward: 29.624999999999993, steps:1327, time-taken: 0.85min, time-elasped: 612.89min
-> berries picked: 24 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4180 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [249, 280, 464, 595, 575, 592, 539, 480, 406]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 6, 16, 15, 11, 8, 16, 14, 19]
	Time taken saving stuff: 0.01s

=== episode:335 Env-steps-taken:60768
 	picked: 43 |actions: {0: 306, 1: 278, 2: 378, 3: 322, 4: 423, 5: 466, 6: 398, 7: 407, 8: 360}
episode: 335/2000 -> reward: 62.59375000000004, steps:3338, time-taken: 1.77min, time-elasped: 614.66min
-> berries picked: 43 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4171 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [252, 277, 462, 587, 576, 590, 538, 481, 408]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 6, 8, 24, 12, 13, 11, 11, 12]
	Time taken saving stuff: 0.01s

=== episode:336 Env-steps-taken:71232
 	picked: 87 |actions: {0: 418, 1: 663, 2: 460, 3: 379, 4: 505, 5: 476, 6: 562, 7: 366, 8: 451}
episode: 336/2000 -> reward: 114.57291666666653, steps:4280, time-taken: 2.09min, time-elasped: 616.75min
-> berries picked: 87 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4201 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [251, 285, 473, 591, 581, 587, 541, 482, 410]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 11, 10, 16, 11, 12, 12, 11, 17]
	Time taken saving stuff: 0.01s

=== episode:337 Env-steps-taken:59424
 	picked: 40 |actions: {0: 221, 1: 356, 2: 327, 3: 267, 4: 378, 5: 285, 6: 409, 7: 321, 8: 356}
episode: 337/2000 -> reward: 57.70833333333338, steps:2920, time-taken: 1.54min, time-elasped: 618.29min
-> berries picked: 40 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4203 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [250, 286, 471, 594, 579, 588, 540, 483, 412]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 10, 17, 14, 12, 16, 15, 17, 15]
	Time taken saving stuff: 0.10s

=== episode:338 Env-steps-taken:57312
 	picked: 40 |actions: {0: 142, 1: 249, 2: 193, 3: 199, 4: 317, 5: 188, 6: 194, 7: 142, 8: 268}
episode: 338/2000 -> reward: 46.70833333333335, steps:1892, time-taken: 1.20min, time-elasped: 619.49min
-> berries picked: 40 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4220 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [253, 286, 476, 597, 582, 589, 539, 484, 414]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 15, 13, 15, 15, 17, 7, 5, 19]
	Time taken saving stuff: 0.10s

=== episode:339 Env-steps-taken:69792
 	picked: 89 |actions: {0: 557, 1: 607, 2: 574, 3: 521, 4: 780, 5: 881, 6: 717, 7: 504, 8: 599}
episode: 339/2000 -> reward: 108.90104166666654, steps:5740, time-taken: 2.58min, time-elasped: 622.08min
-> berries picked: 89 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4234 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [255, 288, 474, 600, 586, 588, 546, 481, 416]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 8, 14, 7, 10, 14, 7, 11, 17]
	Time taken saving stuff: 0.10s

=== episode:340 Env-steps-taken:67872
 	picked: 80 |actions: {0: 534, 1: 649, 2: 467, 3: 558, 4: 693, 5: 646, 6: 655, 7: 455, 8: 670}
episode: 340/2000 -> reward: 99.41666666666657, steps:5327, time-taken: 2.47min, time-elasped: 624.56min
-> berries picked: 80 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4251 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [261, 294, 475, 608, 579, 587, 544, 485, 418]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 13, 12, 15, 13, 16, 14, 18, 15]
	Time taken saving stuff: 0.15s

=== episode:34 Env-steps-taken:67296
 	picked: 73 |actions: {0: 271, 1: 1923, 2: 45, 3: 225, 4: 175, 5: 1968, 6: 127, 7: 513, 8: 140}

==================================================
eval-episode: 340 -> reward: 96.81770833333326, steps: 5387.0, wall-time: 47.26s
-> berries picked: 73 of 800 | patches-visited: [1, 5] | juice left:-0.00
==================================================


=== episode:341 Env-steps-taken:61920
 	picked: 56 |actions: {0: 497, 1: 513, 2: 445, 3: 517, 4: 776, 5: 950, 6: 664, 7: 415, 8: 589}
episode: 341/2000 -> reward: 69.29166666666667, steps:5366, time-taken: 2.39min, time-elasped: 627.74min
-> berries picked: 56 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4247 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [258, 296, 471, 615, 576, 591, 542, 482, 416]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 8, 7, 20, 16, 11, 9, 12, 13]
	Time taken saving stuff: 0.09s

=== episode:342 Env-steps-taken:60864
 	picked: 51 |actions: {0: 324, 1: 306, 2: 267, 3: 248, 4: 328, 5: 423, 6: 292, 7: 281, 8: 166}
episode: 342/2000 -> reward: 64.57812500000004, steps:2635, time-taken: 1.49min, time-elasped: 629.23min
-> berries picked: 51 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4265 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [259, 294, 470, 617, 578, 602, 545, 481, 419]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 8, 3, 23, 13, 17, 11, 10, 16]
	Time taken saving stuff: 0.09s

=== episode:343 Env-steps-taken:70368
 	picked: 81 |actions: {0: 557, 1: 563, 2: 470, 3: 518, 4: 719, 5: 741, 6: 687, 7: 538, 8: 692}
episode: 343/2000 -> reward: 112.85937499999989, steps:5485, time-taken: 2.63min, time-elasped: 631.87min
-> berries picked: 81 of 800 | patches-visited: [0, 2, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4276 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [267, 292, 461, 619, 578, 606, 551, 479, 423]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 8, 6, 17, 14, 9, 13, 9, 23]
	Time taken saving stuff: 0.10s

=== episode:344 Env-steps-taken:68736
 	picked: 70 |actions: {0: 441, 1: 432, 2: 356, 3: 367, 4: 584, 5: 425, 6: 537, 7: 347, 8: 362}
episode: 344/2000 -> reward: 104.98958333333324, steps:3851, time-taken: 2.03min, time-elasped: 633.90min
-> berries picked: 70 of 800 | patches-visited: [0, 2, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4294 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [261, 294, 463, 617, 588, 605, 558, 481, 427]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 12, 11, 12, 11, 10, 12, 13, 21]
	Time taken saving stuff: 0.00s

=== episode:345 Env-steps-taken:73248
 	picked: 92 |actions: {0: 466, 1: 711, 2: 554, 3: 680, 4: 690, 5: 703, 6: 631, 7: 470, 8: 421}
episode: 345/2000 -> reward: 127.22916666666652, steps:5326, time-taken: 3.20min, time-elasped: 637.11min
-> berries picked: 92 of 800 | patches-visited: [0, 1, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4307 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [259, 291, 466, 614, 590, 608, 562, 485, 432]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 6, 17, 12, 14, 13, 9, 15, 22]
	Time taken saving stuff: 0.01s

=== episode:346 Env-steps-taken:69120
 	picked: 79 |actions: {0: 460, 1: 545, 2: 366, 3: 360, 4: 662, 5: 535, 6: 488, 7: 473, 8: 423}
episode: 346/2000 -> reward: 106.47395833333323, steps:4312, time-taken: 2.61min, time-elasped: 639.72min
-> berries picked: 79 of 800 | patches-visited: [0, 3, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4334 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [263, 290, 460, 616, 597, 614, 566, 494, 434]
	| approx positives in sample 512: 101
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 8, 11, 13, 14, 15, 15, 5, 11]
	Time taken saving stuff: 0.00s

=== episode:347 Env-steps-taken:62112
 	picked: 51 |actions: {0: 400, 1: 407, 2: 334, 3: 253, 4: 289, 5: 328, 6: 387, 7: 456, 8: 406}
episode: 347/2000 -> reward: 71.078125, steps:3260, time-taken: 1.85min, time-elasped: 641.58min
-> berries picked: 51 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4334 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [269, 290, 465, 613, 596, 605, 564, 497, 435]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 2, 11, 19, 14, 17, 9, 16, 18]
	Time taken saving stuff: 0.00s

=== episode:348 Env-steps-taken:60960
 	picked: 47 |actions: {0: 261, 1: 404, 2: 298, 3: 308, 4: 460, 5: 455, 6: 344, 7: 311, 8: 353}
episode: 348/2000 -> reward: 65.30729166666671, steps:3194, time-taken: 2.04min, time-elasped: 643.62min
-> berries picked: 47 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4338 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [272, 291, 461, 613, 599, 606, 567, 496, 433]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 6, 12, 17, 10, 15, 12, 7, 21]
	Time taken saving stuff: 0.01s

=== episode:349 Env-steps-taken:60864
 	picked: 47 |actions: {0: 251, 1: 357, 2: 343, 3: 311, 4: 609, 5: 321, 6: 304, 7: 288, 8: 254}
episode: 349/2000 -> reward: 64.30729166666671, steps:3038, time-taken: 1.76min, time-elasped: 645.39min
-> berries picked: 47 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4333 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [270, 289, 460, 614, 598, 606, 567, 496, 433]
	| approx positives in sample 512: 99
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 11, 15, 11, 10, 15, 5, 11, 14]
	Time taken saving stuff: 0.01s

=== episode:350 Env-steps-taken:58464
 	picked: 38 |actions: {0: 217, 1: 254, 2: 241, 3: 286, 4: 245, 5: 256, 6: 280, 7: 271, 8: 166}
episode: 350/2000 -> reward: 52.32291666666669, steps:2216, time-taken: 1.34min, time-elasped: 646.73min
-> berries picked: 38 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4344 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [274, 288, 459, 617, 601, 605, 570, 497, 433]
	| approx positives in sample 512: 99
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 9, 6, 13, 9, 12, 11, 8, 19]
	Time taken saving stuff: 0.05s

=== episode:35 Env-steps-taken:59232
 	picked: 46 |actions: {0: 188, 1: 343, 2: 86, 3: 134, 4: 757, 5: 109, 6: 292, 7: 116, 8: 492}

==================================================
eval-episode: 350 -> reward: 55.86458333333337, steps: 2517.0, wall-time: 37.17s
-> berries picked: 46 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:351 Env-steps-taken:60096
 	picked: 39 |actions: {0: 210, 1: 194, 2: 197, 3: 268, 4: 298, 5: 309, 6: 276, 7: 225, 8: 176}
episode: 351/2000 -> reward: 61.26562500000005, steps:2153, time-taken: 1.33min, time-elasped: 648.69min
-> berries picked: 39 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4350 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [274, 283, 462, 615, 600, 607, 578, 496, 435]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 8, 12, 11, 10, 16, 14, 14, 12]
	Time taken saving stuff: 0.10s

=== episode:352 Env-steps-taken:53664
 	picked: 20 |actions: {0: 98, 1: 143, 2: 100, 3: 139, 4: 200, 5: 132, 6: 178, 7: 119, 8: 188}
episode: 352/2000 -> reward: 28.354166666666664, steps:1297, time-taken: 0.92min, time-elasped: 649.61min
-> berries picked: 20 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4349 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [269, 285, 464, 616, 595, 609, 581, 494, 436]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 8, 13, 19, 18, 10, 11, 6, 16]
	Time taken saving stuff: 0.09s

=== episode:353 Env-steps-taken:69504
 	picked: 78 |actions: {0: 415, 1: 469, 2: 447, 3: 607, 4: 523, 5: 447, 6: 621, 7: 477, 8: 338}
episode: 353/2000 -> reward: 108.03124999999987, steps:4344, time-taken: 2.27min, time-elasped: 651.89min
-> berries picked: 78 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4359 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [274, 275, 473, 617, 596, 611, 578, 499, 436]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 10, 14, 14, 12, 15, 13, 9, 23]
	Time taken saving stuff: 0.09s

=== episode:354 Env-steps-taken:49344
 	picked: 4 |actions: {0: 13, 1: 9, 2: 21, 3: 50, 4: 14, 5: 30, 6: 9, 7: 10, 8: 46}
episode: 354/2000 -> reward: 6.770833333333333, steps:202, time-taken: 0.47min, time-elasped: 652.37min
-> berries picked: 4 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4356 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [274, 273, 475, 617, 595, 611, 577, 498, 436]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 8, 5, 12, 20, 15, 13, 13, 16]
	Time taken saving stuff: 0.10s

=== episode:355 Env-steps-taken:68832
 	picked: 77 |actions: {0: 519, 1: 828, 2: 368, 3: 486, 4: 731, 5: 430, 6: 889, 7: 499, 8: 491}
episode: 355/2000 -> reward: 105.08854166666657, steps:5241, time-taken: 2.56min, time-elasped: 654.93min
-> berries picked: 77 of 800 | patches-visited: [0, 3, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4372 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [287, 276, 471, 613, 599, 611, 586, 496, 433]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 8, 8, 7, 19, 22, 9, 10, 20]
	Time taken saving stuff: 0.10s

=== episode:356 Env-steps-taken:69408
 	picked: 80 |actions: {0: 451, 1: 556, 2: 396, 3: 490, 4: 467, 5: 479, 6: 753, 7: 556, 8: 514}
episode: 356/2000 -> reward: 107.41666666666656, steps:4662, time-taken: 2.32min, time-elasped: 657.25min
-> berries picked: 80 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4401 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [291, 278, 472, 614, 596, 612, 596, 506, 436]
	| approx positives in sample 512: 89
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 4, 8, 8, 12, 19, 7, 14, 11]
	Time taken saving stuff: 0.01s

=== episode:357 Env-steps-taken:59520
 	picked: 41 |actions: {0: 237, 1: 296, 2: 245, 3: 260, 4: 448, 5: 254, 6: 358, 7: 303, 8: 390}
episode: 357/2000 -> reward: 58.151041666666714, steps:2791, time-taken: 1.50min, time-elasped: 658.75min
-> berries picked: 41 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4405 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [289, 278, 474, 616, 596, 611, 594, 509, 438]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 14, 18, 14, 9, 19, 13, 15, 21]
	Time taken saving stuff: 0.00s

=== episode:358 Env-steps-taken:64704
 	picked: 54 |actions: {0: 313, 1: 329, 2: 382, 3: 348, 4: 434, 5: 302, 6: 424, 7: 444, 8: 207}
episode: 358/2000 -> reward: 84.40624999999999, steps:3183, time-taken: 1.77min, time-elasped: 660.52min
-> berries picked: 54 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4417 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [293, 281, 471, 617, 598, 612, 593, 512, 440]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 5, 13, 15, 18, 14, 11, 8, 15]
	Time taken saving stuff: 0.10s

=== episode:359 Env-steps-taken:61344
 	picked: 51 |actions: {0: 304, 1: 358, 2: 329, 3: 312, 4: 627, 5: 300, 6: 393, 7: 282, 8: 479}
episode: 359/2000 -> reward: 65.63541666666671, steps:3384, time-taken: 1.67min, time-elasped: 662.19min
-> berries picked: 51 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4433 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [295, 285, 470, 620, 603, 613, 597, 509, 441]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 5, 9, 11, 16, 22, 9, 15, 12]
	Time taken saving stuff: 0.02s

=== episode:360 Env-steps-taken:49440
 	picked: 5 |actions: {0: 25, 1: 33, 2: 48, 3: 54, 4: 36, 5: 39, 6: 30, 7: 16, 8: 92}
episode: 360/2000 -> reward: 7.213541666666666, steps:373, time-taken: 0.56min, time-elasped: 662.75min
-> berries picked: 5 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4429 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [295, 286, 469, 620, 601, 613, 596, 508, 441]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 11, 12, 17, 14, 9, 17, 10, 14]
	Time taken saving stuff: 0.05s

=== episode:36 Env-steps-taken:56352
 	picked: 34 |actions: {0: 198, 1: 72, 2: 158, 3: 84, 4: 174, 5: 54, 6: 43, 7: 235, 8: 124}

==================================================
eval-episode: 360 -> reward: 42.05208333333334, steps: 1142.0, wall-time: 38.01s
-> berries picked: 34 of 800 | patches-visited: [1, 5] | juice left:-0.00
==================================================


=== episode:361 Env-steps-taken:57024
 	picked: 32 |actions: {0: 293, 1: 220, 2: 252, 3: 242, 4: 334, 5: 236, 6: 249, 7: 238, 8: 227}
episode: 361/2000 -> reward: 45.16666666666669, steps:2291, time-taken: 1.45min, time-elasped: 664.83min
-> berries picked: 32 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4420 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [289, 287, 470, 619, 601, 612, 594, 506, 442]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 9, 15, 16, 15, 16, 23, 5, 23]
	Time taken saving stuff: 0.10s

=== episode:362 Env-steps-taken:58080
 	picked: 36 |actions: {0: 352, 1: 257, 2: 283, 3: 249, 4: 502, 5: 405, 6: 254, 7: 250, 8: 421}
episode: 362/2000 -> reward: 50.49479166666669, steps:2973, time-taken: 1.74min, time-elasped: 666.58min
-> berries picked: 36 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4426 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [290, 290, 475, 617, 599, 617, 590, 506, 442]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 9, 6, 11, 14, 15, 20, 14, 17]
	Time taken saving stuff: 0.10s

=== episode:363 Env-steps-taken:64896
 	picked: 60 |actions: {0: 615, 1: 651, 2: 579, 3: 487, 4: 645, 5: 609, 6: 848, 7: 573, 8: 622}
episode: 363/2000 -> reward: 85.06249999999999, steps:5629, time-taken: 2.81min, time-elasped: 669.39min
-> berries picked: 60 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4426 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [286, 288, 481, 621, 600, 614, 591, 502, 443]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 9, 10, 17, 8, 16, 16, 8, 19]
	Time taken saving stuff: 0.26s

=== episode:364 Env-steps-taken:68352
 	picked: 72 |actions: {0: 629, 1: 575, 2: 468, 3: 489, 4: 692, 5: 528, 6: 596, 7: 430, 8: 326}
episode: 364/2000 -> reward: 102.37499999999993, steps:4733, time-taken: 2.44min, time-elasped: 671.84min
-> berries picked: 72 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4450 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [289, 288, 478, 625, 596, 624, 593, 510, 447]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 3, 12, 19, 14, 23, 18, 11, 22]
	Time taken saving stuff: 0.01s

=== episode:365 Env-steps-taken:60192
 	picked: 44 |actions: {0: 273, 1: 173, 2: 247, 3: 242, 4: 405, 5: 270, 6: 246, 7: 284, 8: 306}
episode: 365/2000 -> reward: 61.97916666666672, steps:2446, time-taken: 1.44min, time-elasped: 673.29min
-> berries picked: 44 of 800 | patches-visited: [0, 2, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4465 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [289, 288, 478, 629, 600, 627, 591, 515, 448]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 9, 12, 16, 22, 13, 13, 7, 15]
	Time taken saving stuff: 0.10s

=== episode:366 Env-steps-taken:62400
 	picked: 55 |actions: {0: 471, 1: 369, 2: 412, 3: 429, 4: 481, 5: 360, 6: 596, 7: 397, 8: 392}
episode: 366/2000 -> reward: 71.84895833333334, steps:3907, time-taken: 1.89min, time-elasped: 675.18min
-> berries picked: 55 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4465 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [291, 286, 478, 630, 599, 623, 588, 522, 448]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [1, 4, 11, 16, 12, 15, 14, 8, 16]
	Time taken saving stuff: 0.03s

=== episode:367 Env-steps-taken:69408
 	picked: 73 |actions: {0: 384, 1: 297, 2: 418, 3: 296, 4: 551, 5: 476, 6: 534, 7: 442, 8: 367}
episode: 367/2000 -> reward: 107.81770833333324, steps:3765, time-taken: 1.93min, time-elasped: 677.11min
-> berries picked: 73 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4485 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [292, 283, 477, 629, 604, 628, 594, 531, 447]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 6, 8, 19, 12, 17, 16, 6, 22]
	Time taken saving stuff: 0.03s

=== episode:368 Env-steps-taken:61920
 	picked: 53 |actions: {0: 528, 1: 431, 2: 413, 3: 401, 4: 542, 5: 528, 6: 881, 7: 539, 8: 532}
episode: 368/2000 -> reward: 69.4635416666667, steps:4795, time-taken: 2.26min, time-elasped: 679.38min
-> berries picked: 53 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4485 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [289, 281, 475, 626, 600, 632, 601, 535, 446]
	| approx positives in sample 512: 101
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 8, 6, 13, 11, 10, 9, 14, 20]
	Time taken saving stuff: 0.09s

=== episode:369 Env-steps-taken:60096
 	picked: 42 |actions: {0: 471, 1: 383, 2: 329, 3: 289, 4: 315, 5: 234, 6: 478, 7: 294, 8: 347}
episode: 369/2000 -> reward: 60.59375000000004, steps:3140, time-taken: 1.68min, time-elasped: 681.06min
-> berries picked: 42 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4499 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [291, 286, 479, 629, 598, 631, 602, 536, 447]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 9, 15, 8, 18, 20, 11, 17, 8]
	Time taken saving stuff: 0.10s

=== episode:370 Env-steps-taken:57792
 	picked: 36 |actions: {0: 186, 1: 163, 2: 154, 3: 181, 4: 309, 5: 212, 6: 226, 7: 159, 8: 270}
episode: 370/2000 -> reward: 48.93750000000003, steps:1860, time-taken: 1.15min, time-elasped: 682.22min
-> berries picked: 36 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4510 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [294, 288, 474, 628, 602, 637, 604, 536, 447]
	| approx positives in sample 512: 96
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 5, 12, 12, 17, 9, 17, 8, 9]
	Time taken saving stuff: 0.05s

=== episode:37 Env-steps-taken:57888
 	picked: 37 |actions: {0: 77, 1: 197, 2: 83, 3: 154, 4: 250, 5: 104, 6: 177, 7: 43, 8: 208}

==================================================
eval-episode: 370 -> reward: 49.88020833333336, steps: 1293.0, wall-time: 32.52s
-> berries picked: 37 of 800 | patches-visited: [0, 1] | juice left:-0.00
==================================================


=== episode:371 Env-steps-taken:55872
 	picked: 30 |actions: {0: 107, 1: 180, 2: 118, 3: 209, 4: 241, 5: 161, 6: 306, 7: 160, 8: 193}
episode: 371/2000 -> reward: 39.78125, steps:1675, time-taken: 0.98min, time-elasped: 683.75min
-> berries picked: 30 of 800 | patches-visited: [0, 3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4517 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [293, 289, 471, 628, 604, 641, 606, 537, 448]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 7, 7, 12, 15, 8, 14, 15, 20]
	Time taken saving stuff: 0.10s

=== episode:372 Env-steps-taken:56640
 	picked: 33 |actions: {0: 197, 1: 150, 2: 133, 3: 151, 4: 240, 5: 248, 6: 295, 7: 254, 8: 184}
episode: 372/2000 -> reward: 43.60937500000003, steps:1852, time-taken: 1.02min, time-elasped: 684.77min
-> berries picked: 33 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4525 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [292, 291, 468, 626, 601, 643, 614, 541, 449]
	| approx positives in sample 512: 96
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 12, 13, 11, 12, 10, 16, 5, 12]
	Time taken saving stuff: 0.01s

=== episode:373 Env-steps-taken:67680
 	picked: 71 |actions: {0: 384, 1: 505, 2: 462, 3: 604, 4: 568, 5: 486, 6: 817, 7: 428, 8: 533}
episode: 373/2000 -> reward: 99.4322916666666, steps:4787, time-taken: 2.36min, time-elasped: 687.13min
-> berries picked: 71 of 800 | patches-visited: [0, 4, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4541 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [286, 289, 469, 631, 603, 643, 622, 546, 452]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 8, 14, 17, 14, 12, 12, 15, 16]
	Time taken saving stuff: 0.01s

=== episode:374 Env-steps-taken:61056
 	picked: 48 |actions: {0: 346, 1: 400, 2: 340, 3: 226, 4: 406, 5: 264, 6: 423, 7: 316, 8: 335}
episode: 374/2000 -> reward: 65.25000000000004, steps:3056, time-taken: 1.84min, time-elasped: 688.98min
-> berries picked: 48 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4554 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [287, 289, 475, 628, 606, 640, 622, 553, 454]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 6, 7, 11, 15, 17, 13, 13, 19]
	Time taken saving stuff: 0.01s

=== episode:375 Env-steps-taken:52128
 	picked: 16 |actions: {0: 65, 1: 151, 2: 81, 3: 74, 4: 217, 5: 98, 6: 138, 7: 85, 8: 38}
episode: 375/2000 -> reward: 20.58333333333333, steps:947, time-taken: 0.76min, time-elasped: 689.74min
-> berries picked: 16 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4559 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [287, 292, 473, 631, 605, 640, 621, 556, 454]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 7, 10, 19, 6, 17, 12, 14, 17]
	Time taken saving stuff: 0.10s

=== episode:376 Env-steps-taken:69504
 	picked: 78 |actions: {0: 617, 1: 320, 2: 397, 3: 344, 4: 468, 5: 495, 6: 512, 7: 529, 8: 292}
episode: 376/2000 -> reward: 108.0312499999999, steps:3974, time-taken: 2.12min, time-elasped: 691.86min
-> berries picked: 78 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4576 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [296, 286, 481, 629, 603, 641, 620, 566, 454]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 3, 10, 12, 16, 20, 17, 18, 19]
	Time taken saving stuff: 0.10s

=== episode:377 Env-steps-taken:67872
 	picked: 72 |actions: {0: 556, 1: 310, 2: 442, 3: 357, 4: 425, 5: 445, 6: 600, 7: 531, 8: 437}
episode: 377/2000 -> reward: 98.98958333333327, steps:4103, time-taken: 2.20min, time-elasped: 694.07min
-> berries picked: 72 of 800 | patches-visited: [0, 1, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4579 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [292, 285, 479, 626, 600, 657, 616, 569, 455]
	| approx positives in sample 512: 100
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 10, 12, 8, 8, 17, 13, 8, 17]
	Time taken saving stuff: 0.03s

=== episode:378 Env-steps-taken:63072
 	picked: 54 |actions: {0: 607, 1: 339, 2: 360, 3: 285, 4: 441, 5: 325, 6: 581, 7: 357, 8: 392}
episode: 378/2000 -> reward: 76.40625000000001, steps:3687, time-taken: 1.81min, time-elasped: 695.88min
-> berries picked: 54 of 800 | patches-visited: [0, 2, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4579 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [294, 286, 478, 624, 604, 651, 617, 570, 455]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 3, 12, 12, 11, 11, 17, 7, 17]
	Time taken saving stuff: 0.03s

=== episode:379 Env-steps-taken:62208
 	picked: 56 |actions: {0: 350, 1: 301, 2: 300, 3: 420, 4: 500, 5: 423, 6: 407, 7: 429, 8: 349}
episode: 379/2000 -> reward: 71.29166666666669, steps:3479, time-taken: 1.67min, time-elasped: 697.56min
-> berries picked: 56 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4578 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [287, 285, 477, 628, 606, 653, 619, 568, 455]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 11, 10, 10, 13, 18, 12, 18, 20]
	Time taken saving stuff: 0.01s

=== episode:380 Env-steps-taken:52320
 	picked: 15 |actions: {0: 93, 1: 60, 2: 108, 3: 77, 4: 89, 5: 91, 6: 47, 7: 64, 8: 139}
episode: 380/2000 -> reward: 21.640625, steps:768, time-taken: 0.62min, time-elasped: 698.18min
-> berries picked: 15 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4572 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [285, 286, 478, 627, 603, 651, 622, 565, 455]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [11, 4, 10, 9, 12, 13, 8, 19, 16]
	Time taken saving stuff: 0.15s

=== episode:38 Env-steps-taken:92928
 	picked: 169 |actions: {0: 435, 1: 441, 2: 680, 3: 942, 4: 842, 5: 525, 6: 727, 7: 1511, 8: 960}

==================================================
eval-episode: 380 -> reward: 225.43229166666717, steps: 7063.0, wall-time: 59.40s
-> berries picked: 169 of 800 | patches-visited: [1, 2, 3, 9] | juice left:-0.00
==================================================


=== episode:381 Env-steps-taken:65376
 	picked: 71 |actions: {0: 435, 1: 424, 2: 641, 3: 332, 4: 722, 5: 579, 6: 580, 7: 452, 8: 515}
episode: 381/2000 -> reward: 86.4322916666666, steps:4680, time-taken: 2.22min, time-elasped: 701.40min
-> berries picked: 71 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4584 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [281, 286, 479, 626, 610, 658, 622, 566, 456]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 8, 11, 12, 15, 15, 13, 13, 15]
	Time taken saving stuff: 0.10s

=== episode:382 Env-steps-taken:66720
 	picked: 67 |actions: {0: 357, 1: 368, 2: 453, 3: 309, 4: 447, 5: 402, 6: 467, 7: 408, 8: 406}
episode: 382/2000 -> reward: 94.16145833333326, steps:3617, time-taken: 2.15min, time-elasped: 703.56min
-> berries picked: 67 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4582 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [285, 289, 473, 619, 603, 666, 618, 573, 456]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 4, 11, 16, 10, 19, 19, 16, 20]
	Time taken saving stuff: 0.02s

=== episode:383 Env-steps-taken:58656
 	picked: 36 |actions: {0: 200, 1: 146, 2: 165, 3: 172, 4: 332, 5: 198, 6: 270, 7: 167, 8: 131}
episode: 383/2000 -> reward: 53.937500000000036, steps:1781, time-taken: 1.15min, time-elasped: 704.71min
-> berries picked: 36 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4594 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [282, 289, 473, 622, 605, 668, 621, 577, 457]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 4, 14, 17, 11, 9, 14, 8, 21]
	Time taken saving stuff: 0.03s

=== episode:384 Env-steps-taken:65376
 	picked: 65 |actions: {0: 538, 1: 399, 2: 529, 3: 356, 4: 428, 5: 374, 6: 532, 7: 503, 8: 343}
episode: 384/2000 -> reward: 85.33333333333331, steps:4002, time-taken: 2.03min, time-elasped: 706.74min
-> berries picked: 65 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4610 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [280, 293, 474, 621, 605, 672, 624, 582, 459]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [5, 10, 8, 14, 11, 18, 19, 8, 26]
	Time taken saving stuff: 0.10s

=== episode:385 Env-steps-taken:69504
 	picked: 78 |actions: {0: 567, 1: 466, 2: 515, 3: 549, 4: 802, 5: 667, 6: 596, 7: 756, 8: 472}
episode: 385/2000 -> reward: 108.03124999999989, steps:5390, time-taken: 2.48min, time-elasped: 709.23min
-> berries picked: 78 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4616 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [278, 287, 477, 625, 605, 674, 625, 586, 459]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 10, 13, 11, 10, 13, 11, 8, 23]
	Time taken saving stuff: 0.01s

=== episode:386 Env-steps-taken:69024
 	picked: 72 |actions: {0: 427, 1: 402, 2: 795, 3: 548, 4: 692, 5: 476, 6: 574, 7: 450, 8: 408}
episode: 386/2000 -> reward: 105.8749999999999, steps:4772, time-taken: 2.19min, time-elasped: 711.42min
-> berries picked: 72 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4615 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [275, 292, 486, 624, 604, 673, 619, 583, 459]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 7, 10, 17, 10, 14, 10, 13, 19]
	Time taken saving stuff: 0.10s

=== episode:387 Env-steps-taken:51936
 	picked: 13 |actions: {0: 194, 1: 116, 2: 139, 3: 123, 4: 214, 5: 261, 6: 208, 7: 130, 8: 294}
episode: 387/2000 -> reward: 18.312499999999996, steps:1679, time-taken: 1.17min, time-elasped: 712.59min
-> berries picked: 13 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4605 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [274, 294, 483, 618, 604, 671, 619, 582, 460]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 12, 12, 14, 16, 11, 13, 12, 16]
	Time taken saving stuff: 0.03s

=== episode:388 Env-steps-taken:62880
 	picked: 58 |actions: {0: 429, 1: 341, 2: 445, 3: 522, 4: 410, 5: 349, 6: 459, 7: 445, 8: 267}
episode: 388/2000 -> reward: 74.17708333333334, steps:3667, time-taken: 1.67min, time-elasped: 714.26min
-> berries picked: 58 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4592 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [278, 290, 484, 619, 598, 670, 616, 577, 460]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 9, 6, 16, 12, 19, 9, 8, 14]
	Time taken saving stuff: 0.01s

=== episode:389 Env-steps-taken:62976
 	picked: 58 |actions: {0: 448, 1: 445, 2: 603, 3: 668, 4: 395, 5: 581, 6: 571, 7: 604, 8: 338}
episode: 389/2000 -> reward: 72.79166666666669, steps:4653, time-taken: 2.18min, time-elasped: 716.44min
-> berries picked: 58 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4592 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [275, 290, 487, 625, 592, 673, 618, 573, 459]
	| approx positives in sample 512: 95
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [8, 7, 5, 10, 9, 10, 14, 16, 16]
	Time taken saving stuff: 0.00s

=== episode:390 Env-steps-taken:57600
 	picked: 38 |actions: {0: 261, 1: 187, 2: 286, 3: 202, 4: 257, 5: 185, 6: 396, 7: 168, 8: 207}
episode: 390/2000 -> reward: 47.82291666666671, steps:2149, time-taken: 1.25min, time-elasped: 717.69min
-> berries picked: 38 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4598 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [274, 289, 486, 624, 594, 675, 620, 576, 460]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 8, 10, 19, 12, 15, 10, 10, 20]
	Time taken saving stuff: 0.07s

=== episode:39 Env-steps-taken:57120
 	picked: 30 |actions: {0: 28, 1: 83, 2: 104, 3: 243, 4: 239, 5: 119, 6: 92, 7: 131, 8: 34}

==================================================
eval-episode: 390 -> reward: 46.28125000000002, steps: 1073.0, wall-time: 31.62s
-> berries picked: 30 of 800 | patches-visited: [0, 1] | juice left:-0.00
==================================================


=== episode:391 Env-steps-taken:73920
 	picked: 95 |actions: {0: 551, 1: 549, 2: 659, 3: 682, 4: 734, 5: 535, 6: 648, 7: 714, 8: 447}
episode: 391/2000 -> reward: 129.67187499999986, steps:5519, time-taken: 2.59min, time-elasped: 720.81min
-> berries picked: 95 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4533 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [270, 288, 476, 619, 582, 651, 614, 573, 460]
	| approx positives in sample 512: 95
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 2, 9, 14, 10, 12, 23, 9, 9]
	Time taken saving stuff: 0.16s

=== episode:392 Env-steps-taken:64224
 	picked: 63 |actions: {0: 443, 1: 494, 2: 645, 3: 573, 4: 542, 5: 567, 6: 554, 7: 460, 8: 443}
episode: 392/2000 -> reward: 80.890625, steps:4721, time-taken: 2.22min, time-elasped: 723.04min
-> berries picked: 63 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4513 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [268, 288, 473, 625, 574, 644, 611, 569, 461]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [10, 12, 14, 9, 13, 18, 13, 12, 17]
	Time taken saving stuff: 0.08s

=== episode:393 Env-steps-taken:69600
 	picked: 83 |actions: {0: 494, 1: 650, 2: 839, 3: 719, 4: 578, 5: 592, 6: 623, 7: 699, 8: 487}
episode: 393/2000 -> reward: 108.74479166666654, steps:5681, time-taken: 2.71min, time-elasped: 725.76min
-> berries picked: 83 of 800 | patches-visited: [0, 2, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4485 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [270, 300, 472, 620, 570, 631, 596, 567, 459]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [7, 7, 9, 13, 11, 20, 9, 12, 10]
	Time taken saving stuff: 0.02s

=== episode:394 Env-steps-taken:63072
 	picked: 56 |actions: {0: 333, 1: 416, 2: 559, 3: 520, 4: 344, 5: 458, 6: 459, 7: 517, 8: 345}
episode: 394/2000 -> reward: 75.79166666666666, steps:3951, time-taken: 2.01min, time-elasped: 727.77min
-> berries picked: 56 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4483 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [275, 294, 473, 618, 571, 626, 598, 567, 461]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [9, 9, 12, 13, 14, 16, 3, 12, 18]
	Time taken saving stuff: 0.10s

=== episode:395 Env-steps-taken:63456
 	picked: 55 |actions: {0: 226, 1: 265, 2: 459, 3: 291, 4: 388, 5: 372, 6: 497, 7: 397, 8: 302}
episode: 395/2000 -> reward: 77.34895833333334, steps:3197, time-taken: 1.61min, time-elasped: 729.38min
-> berries picked: 55 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4498 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [276, 294, 471, 617, 571, 627, 607, 569, 466]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 7, 7, 16, 13, 17, 10, 12, 16]
	Time taken saving stuff: 0.01s

=== episode:396 Env-steps-taken:51456
 	picked: 11 |actions: {0: 59, 1: 78, 2: 95, 3: 60, 4: 43, 5: 63, 6: 53, 7: 127, 8: 91}
episode: 396/2000 -> reward: 17.369791666666668, steps:669, time-taken: 0.73min, time-elasped: 730.11min
-> berries picked: 11 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4496 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [275, 295, 471, 619, 570, 625, 605, 570, 466]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [3, 8, 7, 17, 11, 11, 10, 12, 18]
	Time taken saving stuff: 0.00s

=== episode:397 Env-steps-taken:56832
 	picked: 30 |actions: {0: 164, 1: 217, 2: 265, 3: 243, 4: 204, 5: 179, 6: 220, 7: 184, 8: 199}
episode: 397/2000 -> reward: 44.281250000000014, steps:1875, time-taken: 1.22min, time-elasped: 731.33min
-> berries picked: 30 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4500 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [278, 296, 474, 617, 571, 623, 607, 567, 467]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [4, 8, 8, 12, 11, 13, 20, 12, 19]
	Time taken saving stuff: 0.10s

=== episode:398 Env-steps-taken:61344
 	picked: 54 |actions: {0: 322, 1: 308, 2: 424, 3: 405, 4: 449, 5: 487, 6: 342, 7: 498, 8: 260}
episode: 398/2000 -> reward: 64.46354166666674, steps:3495, time-taken: 1.88min, time-elasped: 733.22min
-> berries picked: 54 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4501 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [282, 295, 478, 620, 564, 625, 606, 565, 466]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 5, 11, 13, 16, 14, 12, 21, 12]
	Time taken saving stuff: 0.08s

=== episode:399 Env-steps-taken:67392
 	picked: 70 |actions: {0: 358, 1: 610, 2: 592, 3: 558, 4: 555, 5: 575, 6: 528, 7: 558, 8: 393}
episode: 399/2000 -> reward: 97.98958333333327, steps:4727, time-taken: 2.29min, time-elasped: 735.51min
-> berries picked: 70 of 800 | patches-visited: [0, 3, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4503 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [282, 301, 484, 618, 556, 624, 603, 566, 469]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [12, 8, 11, 10, 15, 14, 17, 15, 24]
	Time taken saving stuff: 0.11s

=== episode:400 Env-steps-taken:64512
 	picked: 65 |actions: {0: 501, 1: 764, 2: 858, 3: 559, 4: 615, 5: 492, 6: 487, 7: 700, 8: 797}
episode: 400/2000 -> reward: 82.27604166666663, steps:5773, time-taken: 2.65min, time-elasped: 738.17min
-> berries picked: 65 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4479 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [281, 302, 486, 617, 553, 610, 597, 566, 467]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [6, 8, 12, 13, 11, 10, 12, 14, 16]
	Time taken saving stuff: 0.15s

=== episode:40 Env-steps-taken:54912
 	picked: 28 |actions: {0: 192, 1: 90, 2: 200, 3: 83, 4: 65, 5: 129, 6: 107, 7: 36, 8: 243}

==================================================
eval-episode: 400 -> reward: 34.395833333333336, steps: 1145.0, wall-time: 36.99s
-> berries picked: 28 of 800 | patches-visited: [1] | juice left:-0.00
==================================================


=== episode:401 Env-steps-taken:60672
 	picked: 42 |actions: {0: 140, 1: 187, 2: 328, 3: 173, 4: 213, 5: 258, 6: 172, 7: 179, 8: 121}
episode: 401/2000 -> reward: 64.1510416666667, steps:1771, time-taken: 1.06min, time-elasped: 739.85min
-> berries picked: 42 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 0
	| positive-in-buffer: 4502 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7, 8] [281, 308, 489, 623, 552, 611, 595, 573, 470]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7, 8] [14, 8, 11, 13, 6, 14, 12, 13, 14]
	Time taken saving stuff: 0.03s
