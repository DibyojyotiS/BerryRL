getBabyEnv :
	 logDir : .temp\2022-5-26 20-15-58
	 initial_juice : 0.5
	 end_on_boundary_hit : False
	 penalize_boundary_hit : False
	 allow_no_action : False
	 no_action_threshold : 0.7
	 field_size : (20000, 20000)
	 initial_pos_around_berry : True
	 living_cost : True
	 nberries : 80
	 num_patches : 10
	 patch_size : (2600, 2600)
	 show : False
	 spawn_radius : 100


with living cost, rewards scaled by 1/(berry_env.REWARD_RATE*MAXSIZE)
Agent :
	 self : <Agent.Agent object at 0x000001D58CE67048>
	 berryField : <BerryFieldEnv instance>
	 mode : train
	 field_grid_size : (40, 40)
	 angle : 45
	 persistence : 0.8
	 worth_offset : 0.0
	 noise : 0.01
	 state_transition_mode : single
	 positive_emphasis : True
	 emphasis_mode : replace
	 memory_alpha : 0.9965
	 time_memory_delta : 0.01
	 time_memory_exp : 1
	 reward_patch_discovery : True
	 disjoint : False
	 debug : False
	 debugDir : .temp


state_transition_mode is not 'all'. The state-transitions being appended 
            every action will be as [[state, action, sum-reward, nextState, done]] where:
            state is the one the model has taken action on,
            sum-reward is the sum of the rewards in the skip-trajectory,
            nextState is the new state after the action was repeated at most skip-steps times,
            done is wether the terminal state was reached.
Rewarding the agent for discovering new patches
agent now aware of total-juice
total-params:  5281
net(
  (feedforward): ModuleList(
    (0): Linear(in_features=39, out_features=16, bias=True)
    (1): LeakyReLU(negative_slope=0.1)
    (2): Linear(in_features=16, out_features=8, bias=True)
    (3): LeakyReLU(negative_slope=0.1)
  )
  (memory_conv): ModuleList(
    (0): Conv2d(1, 8, kernel_size=(4, 4), stride=(2, 2), padding=(3, 3))
    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (2): LeakyReLU(negative_slope=0.1)
    (3): Conv2d(8, 8, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))
    (4): LeakyReLU(negative_slope=0.1)
    (5): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): LeakyReLU(negative_slope=0.1)
  )
  (final_stage): ModuleList(
    (0): Linear(in_features=136, out_features=16, bias=True)
    (1): LeakyReLU(negative_slope=0.1)
    (2): Linear(in_features=16, out_features=16, bias=True)
    (3): LeakyReLU(negative_slope=0.1)
  )
  (valueL): Linear(in_features=16, out_features=1, bias=True)
  (actadvs): Linear(in_features=16, out_features=8, bias=True)
)
lr used = 0.00001, num_gradient_steps= 500
optimizing the online-model after every 2000 actions (skipSteps=10)
batch size=512, gamma=0.8, alpha=0.95
polyak_tau=0.1, update_freq=10
Using greedy strategy as evalExplortionStrategy.
episode: 0/2000 -> reward: -124.99999999999204, steps:48000, time-taken: 1.63min, time-elasped: 1.64min
-> berries picked: 0 of 800 | patches-visited: [8] | positive-in-buffer: 0 | amount-filled: 8.73%
	| epsilon: 0.49959780237162366
	| action-stats:  [] []
	| approx positives in sample 512: 0
	| approx action-dist in sample 512: [] []
	Time taken saving stuff: 11.73s
episode: 1/2000 -> reward: -124.99999999999203, steps:48096, time-taken: 1.71min, time-elasped: 3.54min
-> berries picked: 1 of 800 | patches-visited: [3] | positive-in-buffer: 1 | amount-filled: 17.47%
	| epsilon: 0.4991959282691119
	| action-stats:  [3] [1]
	| approx positives in sample 512: 0
	| approx action-dist in sample 512: [] []
	Time taken saving stuff: 0.07s
episode: 2/2000 -> reward: -124.99999999999204, steps:48000, time-taken: 1.84min, time-elasped: 5.38min
-> berries picked: 0 of 800 | patches-visited: [3] | positive-in-buffer: 1 | amount-filled: 26.20%
	| epsilon: 0.498794377432222
	| action-stats:  [3] [1]
	| approx positives in sample 512: 0
	| approx action-dist in sample 512: [] []
	Time taken saving stuff: 0.01s
episode: 3/2000 -> reward: -124.99999999999174, steps:48960, time-taken: 2.15min, time-elasped: 7.53min
-> berries picked: 4 of 800 | patches-visited: [0, 2, 5] | positive-in-buffer: 7 | amount-filled: 35.10%
	| epsilon: 0.4983931496009206
	| action-stats:  [3, 4, 6] [4, 1, 2]
	| approx positives in sample 512: 8
	| approx action-dist in sample 512: [3, 4, 6] [3, 2, 3]
	Time taken saving stuff: 15.02s
episode: 4/2000 -> reward: -124.99999999999201, steps:49728, time-taken: 1.80min, time-elasped: 9.58min
-> berries picked: 5 of 800 | patches-visited: [5] | positive-in-buffer: 12 | amount-filled: 44.15%
	| epsilon: 0.4979922445153836
	| action-stats:  [3, 4, 6] [7, 2, 3]
	| approx positives in sample 512: 6
	| approx action-dist in sample 512: [3, 4, 6] [1, 2, 3]
	Time taken saving stuff: 0.07s
episode: 5/2000 -> reward: -124.99999999999187, steps:48384, time-taken: 2.21min, time-elasped: 11.80min
-> berries picked: 1 of 800 | patches-visited: [2, 3, 4] | positive-in-buffer: 15 | amount-filled: 52.94%
	| epsilon: 0.4975916619159958
	| action-stats:  [1, 3, 4, 6] [1, 9, 2, 3]
	| approx positives in sample 512: 9
	| approx action-dist in sample 512: [3, 6] [7, 2]
	Time taken saving stuff: 0.11s
episode: 6/2000 -> reward: -124.99999999999204, steps:48000, time-taken: 1.85min, time-elasped: 13.66min
-> berries picked: 0 of 800 | patches-visited: [6] | positive-in-buffer: 15 | amount-filled: 61.67%
	| epsilon: 0.4971914015433509
	| action-stats:  [1, 3, 4, 6] [1, 9, 2, 3]
	| approx positives in sample 512: 4
	| approx action-dist in sample 512: [3, 6] [3, 1]
	Time taken saving stuff: 11.61s
episode: 7/2000 -> reward: -124.99999999999203, steps:49344, time-taken: 2.03min, time-elasped: 15.88min
-> berries picked: 5 of 800 | patches-visited: [6] | positive-in-buffer: 20 | amount-filled: 70.64%
	| epsilon: 0.49679146313825123
	| action-stats:  [1, 3, 4, 6] [1, 9, 7, 3]
	| approx positives in sample 512: 6
	| approx action-dist in sample 512: [4, 6] [4, 2]
	Time taken saving stuff: 0.02s
episode: 8/2000 -> reward: -124.99999999999177, steps:50400, time-taken: 2.08min, time-elasped: 17.96min
-> berries picked: 7 of 800 | patches-visited: [0, 3] | positive-in-buffer: 28 | amount-filled: 79.81%
	| epsilon: 0.49639184644170764
	| action-stats:  [1, 3, 4, 5, 6] [1, 9, 14, 1, 3]
	| approx positives in sample 512: 6
	| approx action-dist in sample 512: [1, 3, 4, 5] [1, 2, 2, 1]
	Time taken saving stuff: 0.01s
episode: 9/2000 -> reward: -124.99999999999208, steps:48960, time-taken: 2.04min, time-elasped: 20.01min
-> berries picked: 5 of 800 | patches-visited: [3, 7] | positive-in-buffer: 34 | amount-filled: 88.71%
	| epsilon: 0.49599255119493924
	| action-stats:  [1, 2, 3, 4, 5, 6, 7] [1, 1, 9, 16, 2, 4, 1]
	| approx positives in sample 512: 14
	| approx action-dist in sample 512: [3, 4, 6, 7] [5, 6, 2, 1]
	Time taken saving stuff: 15.57s
episode: 10/2000 -> reward: -124.99999999999203, steps:48192, time-taken: 1.81min, time-elasped: 22.08min
-> berries picked: 1 of 800 | patches-visited: [0] | positive-in-buffer: 35 | amount-filled: 97.47%
	| epsilon: 0.49559357713937335
	| action-stats:  [1, 2, 3, 4, 5, 6, 7] [1, 1, 9, 17, 2, 4, 1]
	| approx positives in sample 512: 12
	| approx action-dist in sample 512: [3, 4, 6] [1, 10, 1]
	Time taken saving stuff: 0.01s
episode: 11/2000 -> reward: -124.99999999999103, steps:50880, time-taken: 2.19min, time-elasped: 24.27min
-> berries picked: 12 of 800 | patches-visited: [0, 2, 4, 6] | positive-in-buffer: 50 | amount-filled: 100.00%
	| epsilon: 0.4951949240166454
	| action-stats:  [1, 2, 3, 4, 5, 6, 7] [4, 1, 10, 24, 4, 6, 1]
	| approx positives in sample 512: 22
	| approx action-dist in sample 512: [1, 3, 4, 6, 7] [3, 6, 7, 4, 2]
	Time taken saving stuff: 0.00s
episode: 12/2000 -> reward: -124.99999999999201, steps:48192, time-taken: 1.99min, time-elasped: 26.26min
-> berries picked: 1 of 800 | patches-visited: [7] | positive-in-buffer: 51 | amount-filled: 100.00%
	| epsilon: 0.4947965915685984
	| action-stats:  [1, 2, 3, 4, 5, 6, 7] [5, 1, 10, 24, 4, 6, 1]
	| approx positives in sample 512: 15
	| approx action-dist in sample 512: [1, 3, 4, 5, 6] [2, 2, 8, 2, 1]
	Time taken saving stuff: 11.62s
episode: 13/2000 -> reward: -124.99999999999157, steps:49728, time-taken: 2.09min, time-elasped: 28.55min
-> berries picked: 10 of 800 | patches-visited: [6, 7] | positive-in-buffer: 62 | amount-filled: 100.00%
	| epsilon: 0.4943985795372832
	| action-stats:  [1, 2, 3, 4, 5, 6, 7] [6, 2, 14, 27, 4, 7, 2]
	| approx positives in sample 512: 14
	| approx action-dist in sample 512: [2, 4, 5, 6] [1, 9, 2, 2]
	Time taken saving stuff: 0.00s
episode: 14/2000 -> reward: -124.99999999999206, steps:50976, time-taken: 2.11min, time-elasped: 30.66min
-> berries picked: 12 of 800 | patches-visited: [2, 4] | positive-in-buffer: 74 | amount-filled: 100.00%
	| epsilon: 0.4940008876649582
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1, 7, 5, 19, 28, 4, 8, 2]
	| approx positives in sample 512: 7
	| approx action-dist in sample 512: [3, 4, 6, 7] [3, 1, 1, 2]
	Time taken saving stuff: 0.06s
episode: 15/2000 -> reward: -124.9999999999919, steps:48960, time-taken: 1.92min, time-elasped: 32.58min
-> berries picked: 3 of 800 | patches-visited: [4] | positive-in-buffer: 77 | amount-filled: 100.00%
	| epsilon: 0.4936035156940889
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1, 7, 7, 19, 28, 4, 9, 2]
	| approx positives in sample 512: 11
	| approx action-dist in sample 512: [1, 3, 4, 5, 6] [1, 3, 4, 1, 2]
	Time taken saving stuff: 15.42s
episode: 16/2000 -> reward: -124.999999999992, steps:50400, time-taken: 1.93min, time-elasped: 34.78min
-> berries picked: 8 of 800 | patches-visited: [6, 7] | positive-in-buffer: 86 | amount-filled: 100.00%
	| epsilon: 0.49320646336734814
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1, 7, 9, 20, 30, 5, 11, 3]
	| approx positives in sample 512: 13
	| approx action-dist in sample 512: [1, 2, 3, 4, 6] [1, 2, 3, 5, 2]
	Time taken saving stuff: 0.02s
episode: 17/2000 -> reward: -124.99999999999208, steps:49344, time-taken: 2.07min, time-elasped: 36.85min
-> berries picked: 5 of 800 | patches-visited: [6, 9] | positive-in-buffer: 92 | amount-filled: 100.00%
	| epsilon: 0.49280973042761567
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2, 7, 11, 20, 30, 5, 13, 4]
	| approx positives in sample 512: 24
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6] [3, 1, 3, 8, 5, 4]
	Time taken saving stuff: 0.01s
episode: 18/2000 -> reward: -124.999999999992, steps:50112, time-taken: 1.98min, time-elasped: 38.84min
-> berries picked: 8 of 800 | patches-visited: [7] | positive-in-buffer: 100 | amount-filled: 100.00%
	| epsilon: 0.49241331661797816
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2, 7, 14, 21, 30, 5, 17, 4]
	| approx positives in sample 512: 19
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7] [3, 2, 2, 7, 1, 3, 1]
	Time taken saving stuff: 11.95s
episode: 19/2000 -> reward: -124.9999999999904, steps:55008, time-taken: 2.15min, time-elasped: 41.19min
-> berries picked: 27 of 800 | patches-visited: [4, 6] | positive-in-buffer: 128 | amount-filled: 100.00%
	| epsilon: 0.4920172216817288
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [7, 9, 28, 23, 32, 5, 19, 5]
	| approx positives in sample 512: 11
	| approx action-dist in sample 512: [0, 2, 4, 5, 6] [1, 2, 4, 1, 3]
	Time taken saving stuff: 0.01s
episode: 20/2000 -> reward: -124.99999999999115, steps:52320, time-taken: 2.10min, time-elasped: 43.29min
-> berries picked: 17 of 800 | patches-visited: [1, 2, 4, 9] | positive-in-buffer: 148 | amount-filled: 100.00%
	| epsilon: 0.4916214453623674
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [15, 9, 35, 24, 34, 6, 20, 5]
	| approx positives in sample 512: 24
	| approx action-dist in sample 512: [0, 1, 2, 4, 5, 6] [1, 2, 6, 6, 2, 7]
	Time taken saving stuff: 0.11s
episode: 21/2000 -> reward: -124.99999999999177, steps:54528, time-taken: 2.06min, time-elasped: 45.36min
-> berries picked: 25 of 800 | patches-visited: [3, 4] | positive-in-buffer: 173 | amount-filled: 100.00%
	| epsilon: 0.4912259874036
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [19, 12, 41, 31, 36, 7, 22, 5]
	| approx positives in sample 512: 22
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 2, 5, 3, 5, 1, 2, 1]
	Time taken saving stuff: 14.92s
episode: 22/2000 -> reward: -124.99999999999073, steps:54144, time-taken: 2.19min, time-elasped: 47.80min
-> berries picked: 22 of 800 | patches-visited: [4] | positive-in-buffer: 195 | amount-filled: 100.00%
	| epsilon: 0.4908308475493389
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [20, 14, 45, 40, 36, 7, 28, 5]
	| approx positives in sample 512: 20
	| approx action-dist in sample 512: [1, 2, 3, 4, 6, 7] [2, 4, 4, 4, 5, 1]
	Time taken saving stuff: 0.10s
episode: 23/2000 -> reward: -124.9999999999923, steps:53664, time-taken: 2.08min, time-elasped: 49.88min
-> berries picked: 18 of 800 | patches-visited: [0, 8] | positive-in-buffer: 214 | amount-filled: 100.00%
	| epsilon: 0.49043602554370236
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [22, 17, 50, 43, 37, 9, 31, 5]
	| approx positives in sample 512: 21
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6] [3, 4, 4, 4, 3, 1, 2]
	Time taken saving stuff: 0.01s
episode: 24/2000 -> reward: -124.99999999999102, steps:56352, time-taken: 2.18min, time-elasped: 52.06min
-> berries picked: 30 of 800 | patches-visited: [4] | positive-in-buffer: 244 | amount-filled: 100.00%
	| epsilon: 0.4900415211310144
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [24, 22, 51, 53, 37, 12, 37, 8]
	| approx positives in sample 512: 21
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 6] [4, 6, 4, 4, 2, 1]
	Time taken saving stuff: 11.90s
episode: 25/2000 -> reward: -124.99999999999206, steps:53088, time-taken: 2.07min, time-elasped: 54.33min
-> berries picked: 20 of 800 | patches-visited: [6] | positive-in-buffer: 264 | amount-filled: 100.00%
	| epsilon: 0.48964733405580474
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [25, 24, 52, 62, 37, 12, 40, 12]
	| approx positives in sample 512: 23
	| approx action-dist in sample 512: [1, 2, 3, 4, 6, 7] [1, 6, 3, 4, 8, 1]
	Time taken saving stuff: 0.01s
episode: 26/2000 -> reward: -124.99999999999238, steps:53952, time-taken: 2.20min, time-elasped: 56.53min
-> berries picked: 23 of 800 | patches-visited: [5] | positive-in-buffer: 287 | amount-filled: 100.00%
	| epsilon: 0.4892534640628087
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [27, 24, 54, 70, 38, 13, 46, 15]
	| approx positives in sample 512: 20
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 2, 6, 3, 3, 1, 3, 1]
	Time taken saving stuff: 0.01s
episode: 27/2000 -> reward: -124.99999999998941, steps:60384, time-taken: 2.27min, time-elasped: 58.81min
-> berries picked: 44 of 800 | patches-visited: [8, 9] | positive-in-buffer: 332 | amount-filled: 100.00%
	| epsilon: 0.48885991089696673
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [30, 31, 58, 84, 40, 13, 57, 19]
	| approx positives in sample 512: 22
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 6, 7] [4, 4, 4, 3, 3, 3, 1]
	Time taken saving stuff: 15.29s
episode: 28/2000 -> reward: -124.99999999999204, steps:48384, time-taken: 1.95min, time-elasped: 61.01min
-> berries picked: 1 of 800 | patches-visited: [4] | positive-in-buffer: 333 | amount-filled: 100.00%
	| epsilon: 0.48846667430342466
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [30, 31, 58, 85, 40, 13, 57, 19]
	| approx positives in sample 512: 35
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 1, 7, 8, 5, 1, 7, 3]
	Time taken saving stuff: 0.06s
episode: 29/2000 -> reward: -124.99999999998957, steps:61728, time-taken: 2.28min, time-elasped: 63.30min
-> berries picked: 47 of 800 | patches-visited: [4, 5] | positive-in-buffer: 380 | amount-filled: 100.00%
	| epsilon: 0.4880737540275333
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [36, 44, 63, 97, 40, 13, 66, 21]
	| approx positives in sample 512: 24
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 6, 7] [2, 3, 4, 8, 2, 3, 2]
	Time taken saving stuff: 0.01s
episode: 30/2000 -> reward: -124.99999999999253, steps:50688, time-taken: 2.06min, time-elasped: 65.37min
-> berries picked: 10 of 800 | patches-visited: [0, 8] | positive-in-buffer: 390 | amount-filled: 100.00%
	| epsilon: 0.48768114981484806
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [38, 44, 64, 101, 40, 14, 67, 22]
	| approx positives in sample 512: 42
	| approx action-dist in sample 512: [0, 2, 3, 5, 6, 7] [6, 13, 13, 3, 5, 2]
	Time taken saving stuff: 11.75s
episode: 31/2000 -> reward: -124.99999999999032, steps:53472, time-taken: 1.98min, time-elasped: 67.54min
-> berries picked: 18 of 800 | patches-visited: [5] | positive-in-buffer: 408 | amount-filled: 100.00%
	| epsilon: 0.4872888614111293
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [39, 49, 64, 106, 43, 15, 68, 24]
	| approx positives in sample 512: 40
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 9, 6, 7, 6, 1, 4, 4]
	Time taken saving stuff: 0.00s
episode: 32/2000 -> reward: -124.99999999999032, steps:57984, time-taken: 2.16min, time-elasped: 69.70min
-> berries picked: 35 of 800 | patches-visited: [3, 4] | positive-in-buffer: 444 | amount-filled: 100.00%
	| epsilon: 0.4868968885623418
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [40, 60, 67, 113, 46, 15, 77, 26]
	| approx positives in sample 512: 33
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 4, 6, 6, 2, 1, 10, 2]
	Time taken saving stuff: 0.09s
episode: 33/2000 -> reward: -124.99999999999302, steps:57984, time-taken: 2.13min, time-elasped: 71.84min
-> berries picked: 34 of 800 | patches-visited: [3, 5] | positive-in-buffer: 479 | amount-filled: 100.00%
	| epsilon: 0.4865052310146546
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [42, 67, 73, 122, 47, 16, 83, 29]
	| approx positives in sample 512: 29
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 7, 1, 5, 1, 1, 10, 1]
	Time taken saving stuff: 15.05s
episode: 34/2000 -> reward: -124.99999999999216, steps:52320, time-taken: 1.89min, time-elasped: 73.99min
-> berries picked: 15 of 800 | patches-visited: [2] | positive-in-buffer: 493 | amount-filled: 100.00%
	| epsilon: 0.4861138885144411
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [43, 72, 73, 127, 48, 16, 84, 30]
	| approx positives in sample 512: 42
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 7, 3, 10, 6, 1, 7, 3]
	Time taken saving stuff: 0.06s
episode: 35/2000 -> reward: -124.99999999999203, steps:49920, time-taken: 2.11min, time-elasped: 76.10min
-> berries picked: 10 of 800 | patches-visited: [4] | positive-in-buffer: 502 | amount-filled: 100.00%
	| epsilon: 0.4857228608082785
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [43, 76, 74, 128, 48, 16, 86, 31]
	| approx positives in sample 512: 45
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 9, 7, 15, 1, 1, 8, 2]
	Time taken saving stuff: 0.00s
episode: 36/2000 -> reward: -124.99999999999204, steps:52608, time-taken: 2.07min, time-elasped: 78.17min
-> berries picked: 15 of 800 | patches-visited: [7] | positive-in-buffer: 517 | amount-filled: 100.00%
	| epsilon: 0.48533214764294796
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [46, 80, 75, 132, 49, 17, 87, 31]
	| approx positives in sample 512: 43
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 4, 6, 10, 6, 3, 9, 2]
	Time taken saving stuff: 11.83s
episode: 37/2000 -> reward: -124.99999999999244, steps:53280, time-taken: 2.00min, time-elasped: 80.37min
-> berries picked: 18 of 800 | patches-visited: [0, 1] | positive-in-buffer: 536 | amount-filled: 100.00%
	| epsilon: 0.4849417487654344
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [51, 80, 80, 136, 49, 20, 87, 33]
	| approx positives in sample 512: 62
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 11, 12, 13, 4, 2, 12, 4]
	Time taken saving stuff: 0.00s
episode: 38/2000 -> reward: -124.99999999999041, steps:54528, time-taken: 2.00min, time-elasped: 82.37min
-> berries picked: 22 of 800 | patches-visited: [0, 1, 6] | positive-in-buffer: 560 | amount-filled: 100.00%
	| epsilon: 0.48455166392292615
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [57, 84, 83, 143, 50, 21, 88, 34]
	| approx positives in sample 512: 47
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 9, 7, 12, 5, 3, 5, 2]
	Time taken saving stuff: 0.09s
episode: 39/2000 -> reward: -124.9999999999916, steps:56256, time-taken: 2.04min, time-elasped: 84.41min
-> berries picked: 31 of 800 | patches-visited: [8] | positive-in-buffer: 590 | amount-filled: 100.00%
	| epsilon: 0.4841618928628149
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [63, 87, 85, 152, 54, 27, 88, 34]
	| approx positives in sample 512: 50
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 7, 5, 11, 5, 2, 11, 2]
	Time taken saving stuff: 15.12s
episode: 40/2000 -> reward: -124.99999999998933, steps:61536, time-taken: 2.20min, time-elasped: 86.87min
-> berries picked: 53 of 800 | patches-visited: [3, 5] | positive-in-buffer: 644 | amount-filled: 100.00%
	| epsilon: 0.4837724353326957
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [67, 95, 88, 162, 59, 41, 92, 40]
	| approx positives in sample 512: 40
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 9, 6, 12, 3, 2, 4, 1]
	Time taken saving stuff: 0.09s
episode: 41/2000 -> reward: -124.99999999999265, steps:61056, time-taken: 2.16min, time-elasped: 89.04min
-> berries picked: 48 of 800 | patches-visited: [1] | positive-in-buffer: 692 | amount-filled: 100.00%
	| epsilon: 0.4833832910803664
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [71, 104, 90, 173, 69, 47, 96, 42]
	| approx positives in sample 512: 45
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 8, 3, 12, 4, 1, 9, 4]
	Time taken saving stuff: 0.10s
episode: 42/2000 -> reward: -124.99999999999069, steps:59904, time-taken: 2.12min, time-elasped: 91.16min
-> berries picked: 45 of 800 | patches-visited: [1, 6] | positive-in-buffer: 738 | amount-filled: 100.00%
	| epsilon: 0.48299445985382783
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [73, 114, 92, 184, 78, 50, 102, 45]
	| approx positives in sample 512: 47
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 9, 6, 6, 5, 2, 8, 6]
	Time taken saving stuff: 11.90s
episode: 43/2000 -> reward: -124.99999999999233, steps:56256, time-taken: 2.10min, time-elasped: 93.46min
-> berries picked: 29 of 800 | patches-visited: [2] | positive-in-buffer: 767 | amount-filled: 100.00%
	| epsilon: 0.4826059414012836
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [74, 125, 94, 191, 82, 51, 104, 46]
	| approx positives in sample 512: 54
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 11, 5, 11, 11, 4, 8, 2]
	Time taken saving stuff: 0.07s
episode: 44/2000 -> reward: -124.99999999999265, steps:60576, time-taken: 2.18min, time-elasped: 95.64min
-> berries picked: 45 of 800 | patches-visited: [1, 9] | positive-in-buffer: 812 | amount-filled: 100.00%
	| epsilon: 0.4822177354711398
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [74, 137, 97, 195, 94, 53, 109, 53]
	| approx positives in sample 512: 38
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 6, 7] [2, 6, 7, 7, 4, 9, 3]
	Time taken saving stuff: 0.08s
episode: 45/2000 -> reward: -124.99999999999156, steps:64800, time-taken: 2.16min, time-elasped: 97.80min
-> berries picked: 70 of 800 | patches-visited: [0] | positive-in-buffer: 881 | amount-filled: 100.00%
	| epsilon: 0.4818298418120048
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [81, 149, 100, 212, 103, 57, 114, 65]
	| approx positives in sample 512: 59
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 12, 8, 7, 5, 6, 5, 7]
	Time taken saving stuff: 15.36s
episode: 46/2000 -> reward: -124.99999999999292, steps:59808, time-taken: 2.16min, time-elasped: 100.22min
-> berries picked: 42 of 800 | patches-visited: [3] | positive-in-buffer: 923 | amount-filled: 100.00%
	| epsilon: 0.4814422601726893
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [81, 159, 103, 230, 108, 58, 117, 67]
	| approx positives in sample 512: 58
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 12, 12, 11, 5, 5, 8, 3]
	Time taken saving stuff: 0.02s
episode: 47/2000 -> reward: -124.99999999998818, steps:69504, time-taken: 3.09min, time-elasped: 103.32min
-> berries picked: 82 of 800 | patches-visited: [0, 9] | positive-in-buffer: 1005 | amount-filled: 100.00%
	| epsilon: 0.48105499030220616
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [90, 169, 106, 248, 123, 73, 125, 71]
	| approx positives in sample 512: 99
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 19, 7, 17, 10, 14, 11, 4]
	Time taken saving stuff: 0.01s
episode: 48/2000 -> reward: -124.99999999999176, steps:62304, time-taken: 2.24min, time-elasped: 105.56min
-> berries picked: 52 of 800 | patches-visited: [5] | positive-in-buffer: 1056 | amount-filled: 100.00%
	| epsilon: 0.48066803194976987
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [92, 181, 112, 256, 127, 81, 131, 76]
	| approx positives in sample 512: 54
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 12, 3, 7, 8, 4, 13, 4]
	Time taken saving stuff: 11.85s
episode: 49/2000 -> reward: -124.99999999999238, steps:61056, time-taken: 1.99min, time-elasped: 107.74min
-> berries picked: 47 of 800 | patches-visited: [8] | positive-in-buffer: 1102 | amount-filled: 100.00%
	| epsilon: 0.4802813848647968
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [92, 194, 118, 265, 132, 85, 136, 80]
	| approx positives in sample 512: 70
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 13, 8, 16, 12, 2, 10, 3]
	Time taken saving stuff: 0.11s
episode: 50/2000 -> reward: -124.99999999998926, steps:72384, time-taken: 3.08min, time-elasped: 110.82min
-> berries picked: 90 of 800 | patches-visited: [3, 7] | positive-in-buffer: 1193 | amount-filled: 100.00%
	| epsilon: 0.479895048796905
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [101, 204, 124, 292, 142, 105, 139, 86]
	| approx positives in sample 512: 93
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 14, 11, 24, 10, 8, 9, 10]
	Time taken saving stuff: 0.08s
episode: 51/2000 -> reward: -124.99999999999311, steps:58176, time-taken: 2.27min, time-elasped: 113.09min
-> berries picked: 39 of 800 | patches-visited: [4] | positive-in-buffer: 1231 | amount-filled: 100.00%
	| epsilon: 0.4795090234959137
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [102, 211, 124, 307, 145, 110, 142, 90]
	| approx positives in sample 512: 75
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 16, 4, 11, 9, 13, 9, 9]
	Time taken saving stuff: 15.89s
episode: 52/2000 -> reward: -124.99999999999206, steps:62496, time-taken: 2.22min, time-elasped: 115.58min
-> berries picked: 55 of 800 | patches-visited: [1, 2] | positive-in-buffer: 1286 | amount-filled: 100.00%
	| epsilon: 0.47912330871184344
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [103, 218, 137, 317, 152, 112, 148, 99]
	| approx positives in sample 512: 61
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 15, 6, 13, 11, 5, 2, 5]
	Time taken saving stuff: 0.02s
episode: 53/2000 -> reward: -124.999999999992, steps:55104, time-taken: 2.12min, time-elasped: 117.70min
-> berries picked: 24 of 800 | patches-visited: [5] | positive-in-buffer: 1310 | amount-filled: 100.00%
	| epsilon: 0.478737904194916
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [104, 223, 137, 325, 155, 114, 148, 104]
	| approx positives in sample 512: 79
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 11, 10, 19, 12, 8, 8, 4]
	Time taken saving stuff: 0.01s
episode: 54/2000 -> reward: -124.99999999999156, steps:58848, time-taken: 2.21min, time-elasped: 119.91min
-> berries picked: 34 of 800 | patches-visited: [0, 5] | positive-in-buffer: 1345 | amount-filled: 100.00%
	| epsilon: 0.4783528096955539
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [104, 232, 137, 331, 159, 122, 150, 110]
	| approx positives in sample 512: 87
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 9, 12, 20, 7, 9, 9, 10]
	Time taken saving stuff: 11.79s
episode: 55/2000 -> reward: -124.99999999998707, steps:75264, time-taken: 3.04min, time-elasped: 123.15min
-> berries picked: 100 of 800 | patches-visited: [3, 8] | positive-in-buffer: 1445 | amount-filled: 100.00%
	| epsilon: 0.4779680249643805
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [108, 253, 138, 356, 173, 137, 154, 126]
	| approx positives in sample 512: 95
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 19, 8, 19, 10, 8, 16, 6]
	Time taken saving stuff: 0.10s
episode: 56/2000 -> reward: -124.99999999999126, steps:73440, time-taken: 3.09min, time-elasped: 126.25min
-> berries picked: 87 of 800 | patches-visited: [1, 5, 7, 8] | positive-in-buffer: 1535 | amount-filled: 100.00%
	| epsilon: 0.4775835497522197
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [116, 261, 143, 385, 184, 153, 156, 137]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 29, 10, 18, 12, 14, 7, 9]
	Time taken saving stuff: 0.08s
episode: 57/2000 -> reward: -124.99999999999028, steps:84288, time-taken: 3.28min, time-elasped: 129.54min
-> berries picked: 130 of 800 | patches-visited: [3, 6, 7] | positive-in-buffer: 1667 | amount-filled: 100.00%
	| epsilon: 0.4771993838100959
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [127, 277, 152, 423, 211, 171, 157, 149]
	| approx positives in sample 512: 88
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 21, 11, 18, 5, 7, 7, 13]
	Time taken saving stuff: 15.50s
episode: 58/2000 -> reward: -124.99999999998545, steps:76800, time-taken: 3.12min, time-elasped: 132.92min
-> berries picked: 110 of 800 | patches-visited: [1, 4, 7] | positive-in-buffer: 1777 | amount-filled: 100.00%
	| epsilon: 0.4768155268892338
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [127, 296, 157, 460, 228, 182, 161, 166]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 25, 8, 21, 14, 6, 9, 14]
	Time taken saving stuff: 0.01s
episode: 59/2000 -> reward: -124.99999999998603, steps:83328, time-taken: 3.18min, time-elasped: 136.10min
-> berries picked: 137 of 800 | patches-visited: [3, 9] | positive-in-buffer: 1915 | amount-filled: 100.00%
	| epsilon: 0.4764319787410581
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [131, 321, 164, 493, 251, 201, 168, 186]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 19, 5, 20, 11, 10, 8, 15]
	Time taken saving stuff: 0.02s
episode: 60/2000 -> reward: -124.99999999999154, steps:64896, time-taken: 2.18min, time-elasped: 138.29min
-> berries picked: 68 of 800 | patches-visited: [4] | positive-in-buffer: 1983 | amount-filled: 100.00%
	| epsilon: 0.4760487391171935
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [133, 337, 165, 510, 259, 217, 173, 189]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 25, 9, 21, 8, 12, 13, 18]
	Time taken saving stuff: 11.96s
episode: 61/2000 -> reward: -124.99999999998755, steps:73152, time-taken: 3.02min, time-elasped: 141.51min
-> berries picked: 91 of 800 | patches-visited: [3, 6] | positive-in-buffer: 2074 | amount-filled: 100.00%
	| epsilon: 0.47566580776946454
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [138, 353, 167, 546, 265, 232, 179, 194]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 21, 6, 31, 13, 17, 11, 5]
	Time taken saving stuff: 0.02s
episode: 62/2000 -> reward: -124.99999999999183, steps:64608, time-taken: 2.08min, time-elasped: 143.59min
-> berries picked: 59 of 800 | patches-visited: [9] | positive-in-buffer: 2133 | amount-filled: 100.00%
	| epsilon: 0.47528318444989537
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [140, 362, 169, 564, 268, 251, 180, 199]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 20, 11, 29, 14, 9, 7, 8]
	Time taken saving stuff: 0.00s
episode: 63/2000 -> reward: -124.99999999999326, steps:63264, time-taken: 2.10min, time-elasped: 145.70min
-> berries picked: 54 of 800 | patches-visited: [1] | positive-in-buffer: 2186 | amount-filled: 100.00%
	| epsilon: 0.4749008689107096
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [142, 369, 169, 585, 272, 262, 182, 205]
	| approx positives in sample 512: 90
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 13, 8, 19, 9, 21, 3, 7]
	Time taken saving stuff: 14.86s
episode: 64/2000 -> reward: -124.99999999998852, steps:78144, time-taken: 3.01min, time-elasped: 148.96min
-> berries picked: 121 of 800 | patches-visited: [0, 4, 8] | positive-in-buffer: 2309 | amount-filled: 100.00%
	| epsilon: 0.4745188609043301
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [149, 388, 170, 610, 292, 287, 186, 227]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 27, 9, 36, 11, 10, 10, 11]
	Time taken saving stuff: 0.01s
episode: 65/2000 -> reward: -124.99999999998685, steps:86880, time-taken: 3.33min, time-elasped: 152.29min
-> berries picked: 147 of 800 | patches-visited: [2, 7, 9] | positive-in-buffer: 2458 | amount-filled: 100.00%
	| epsilon: 0.474137160183379
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [154, 420, 180, 656, 309, 303, 196, 240]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 19, 4, 29, 12, 17, 12, 4]
	Time taken saving stuff: 0.02s
episode: 66/2000 -> reward: -124.9999999999929, steps:63840, time-taken: 2.19min, time-elasped: 154.49min
-> berries picked: 61 of 800 | patches-visited: [0] | positive-in-buffer: 2519 | amount-filled: 100.00%
	| epsilon: 0.4737557665006773
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [155, 430, 183, 676, 321, 314, 198, 242]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 28, 9, 31, 19, 13, 9, 11]
	Time taken saving stuff: 12.12s
episode: 67/2000 -> reward: -124.9999999999904, steps:66528, time-taken: 2.78min, time-elasped: 157.47min
-> berries picked: 70 of 800 | patches-visited: [9] | positive-in-buffer: 2589 | amount-filled: 100.00%
	| epsilon: 0.4733746796092449
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [157, 450, 188, 691, 330, 324, 200, 249]
	| approx positives in sample 512: 210
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 37, 17, 56, 31, 21, 18, 18]
	Time taken saving stuff: 0.05s
episode: 68/2000 -> reward: -124.99999999999125, steps:61248, time-taken: 2.09min, time-elasped: 159.56min
-> berries picked: 46 of 800 | patches-visited: [6] | positive-in-buffer: 2635 | amount-filled: 100.00%
	| epsilon: 0.47299389926230045
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [157, 457, 188, 707, 333, 341, 201, 251]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 14, 6, 31, 14, 18, 10, 12]
	Time taken saving stuff: 0.09s
episode: 69/2000 -> reward: -124.99999999999324, steps:61824, time-taken: 2.10min, time-elasped: 161.66min
-> berries picked: 55 of 800 | patches-visited: [4] | positive-in-buffer: 2688 | amount-filled: 100.00%
	| epsilon: 0.4726134252132609
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [158, 465, 192, 729, 343, 344, 202, 255]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 21, 8, 35, 16, 13, 11, 7]
	Time taken saving stuff: 15.05s
episode: 70/2000 -> reward: -124.99999999998704, steps:70368, time-taken: 2.96min, time-elasped: 164.87min
-> berries picked: 77 of 800 | patches-visited: [0, 5] | positive-in-buffer: 2766 | amount-filled: 100.00%
	| epsilon: 0.4722332572157417
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [161, 483, 197, 751, 351, 354, 207, 262]
	| approx positives in sample 512: 177
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 37, 11, 46, 17, 24, 13, 19]
	Time taken saving stuff: 0.01s
episode: 71/2000 -> reward: -124.99999999999363, steps:73440, time-taken: 2.99min, time-elasped: 167.86min
-> berries picked: 84 of 800 | patches-visited: [1, 8] | positive-in-buffer: 2851 | amount-filled: 100.00%
	| epsilon: 0.4718533950235565
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [162, 502, 206, 779, 356, 367, 208, 271]
	| approx positives in sample 512: 163
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 21, 15, 37, 23, 29, 12, 16]
	Time taken saving stuff: 0.11s
episode: 72/2000 -> reward: -124.99999999999254, steps:64608, time-taken: 2.30min, time-elasped: 170.17min
-> berries picked: 77 of 800 | patches-visited: [4] | positive-in-buffer: 2927 | amount-filled: 100.00%
	| epsilon: 0.47147383839071694
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [165, 518, 210, 809, 361, 380, 212, 272]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 26, 6, 28, 13, 15, 13, 5]
	Time taken saving stuff: 11.46s
episode: 73/2000 -> reward: -124.99999999998494, steps:83712, time-taken: 3.09min, time-elasped: 173.45min
-> berries picked: 136 of 800 | patches-visited: [4, 9] | positive-in-buffer: 3064 | amount-filled: 100.00%
	| epsilon: 0.4710945870714325
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [172, 554, 221, 845, 373, 397, 216, 286]
	| approx positives in sample 512: 146
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 30, 9, 42, 13, 26, 6, 11]
	Time taken saving stuff: 0.10s
episode: 74/2000 -> reward: -124.99999999999295, steps:64224, time-taken: 2.27min, time-elasped: 175.73min
-> berries picked: 64 of 800 | patches-visited: [6] | positive-in-buffer: 3128 | amount-filled: 100.00%
	| epsilon: 0.47071564082011036
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [176, 562, 228, 864, 377, 405, 217, 299]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 18, 9, 28, 14, 22, 10, 9]
	Time taken saving stuff: 0.00s
episode: 75/2000 -> reward: -124.99999999998924, steps:73248, time-taken: 2.98min, time-elasped: 178.71min
-> berries picked: 87 of 800 | patches-visited: [1, 6, 9] | positive-in-buffer: 3217 | amount-filled: 100.00%
	| epsilon: 0.47033699939135537
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [178, 581, 231, 897, 386, 417, 221, 306]
	| approx positives in sample 512: 175
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 35, 15, 50, 16, 22, 10, 21]
	Time taken saving stuff: 15.52s
episode: 76/2000 -> reward: -124.99999999999207, steps:65472, time-taken: 2.68min, time-elasped: 181.64min
-> berries picked: 73 of 800 | patches-visited: [9] | positive-in-buffer: 3289 | amount-filled: 100.00%
	| epsilon: 0.4699586625399697
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [183, 597, 234, 928, 386, 427, 223, 311]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 27, 5, 29, 16, 11, 13, 7]
	Time taken saving stuff: 0.01s
episode: 77/2000 -> reward: -124.99999999999397, steps:65088, time-taken: 2.15min, time-elasped: 183.80min
-> berries picked: 67 of 800 | patches-visited: [1] | positive-in-buffer: 3356 | amount-filled: 100.00%
	| epsilon: 0.46958063002095274
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [185, 614, 236, 953, 389, 436, 228, 315]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 18, 14, 29, 17, 22, 9, 6]
	Time taken saving stuff: 0.01s
episode: 78/2000 -> reward: -124.99999999999193, steps:66048, time-taken: 2.82min, time-elasped: 186.61min
-> berries picked: 74 of 800 | patches-visited: [2] | positive-in-buffer: 3430 | amount-filled: 100.00%
	| epsilon: 0.46920290158950095
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [186, 635, 244, 970, 396, 446, 230, 323]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 33, 15, 56, 28, 23, 17, 17]
	Time taken saving stuff: 11.69s
episode: 79/2000 -> reward: -124.9999999999869, steps:79200, time-taken: 3.23min, time-elasped: 190.05min
-> berries picked: 116 of 800 | patches-visited: [0, 2] | positive-in-buffer: 3547 | amount-filled: 100.00%
	| epsilon: 0.46882547700100774
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [192, 651, 250, 1014, 412, 463, 233, 332]
	| approx positives in sample 512: 154
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 29, 14, 43, 19, 15, 10, 16]
	Time taken saving stuff: 0.10s
episode: 80/2000 -> reward: -124.99999999998943, steps:74016, time-taken: 3.00min, time-elasped: 193.05min
-> berries picked: 108 of 800 | patches-visited: [4, 8] | positive-in-buffer: 3656 | amount-filled: 100.00%
	| epsilon: 0.4684483560110633
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [195, 668, 258, 1054, 428, 476, 237, 340]
	| approx positives in sample 512: 174
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 27, 12, 47, 28, 16, 17, 19]
	Time taken saving stuff: 0.01s
episode: 81/2000 -> reward: -124.99999999999251, steps:64128, time-taken: 2.32min, time-elasped: 195.38min
-> berries picked: 62 of 800 | patches-visited: [2] | positive-in-buffer: 3718 | amount-filled: 100.00%
	| epsilon: 0.46807153837545445
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [197, 677, 263, 1066, 437, 485, 241, 352]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 30, 10, 40, 23, 15, 7, 18]
	Time taken saving stuff: 15.14s
episode: 82/2000 -> reward: -124.99999999999133, steps:63456, time-taken: 2.01min, time-elasped: 197.64min
-> berries picked: 66 of 800 | patches-visited: [1] | positive-in-buffer: 3783 | amount-filled: 100.00%
	| epsilon: 0.4676950238501643
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [200, 692, 267, 1086, 442, 496, 245, 355]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 29, 10, 32, 10, 10, 9, 12]
	Time taken saving stuff: 0.10s
episode: 83/2000 -> reward: -124.99999999998704, steps:78432, time-taken: 3.29min, time-elasped: 200.92min
-> berries picked: 128 of 800 | patches-visited: [6, 9] | positive-in-buffer: 3912 | amount-filled: 100.00%
	| epsilon: 0.46731881219137245
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [206, 721, 276, 1127, 454, 513, 245, 370]
	| approx positives in sample 512: 160
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 21, 8, 60, 22, 18, 9, 15]
	Time taken saving stuff: 0.01s
episode: 84/2000 -> reward: -124.99999999999186, steps:65472, time-taken: 2.20min, time-elasped: 203.13min
-> berries picked: 70 of 800 | patches-visited: [9] | positive-in-buffer: 3982 | amount-filled: 100.00%
	| epsilon: 0.4669429031554544
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [208, 739, 282, 1146, 461, 523, 249, 374]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 19, 10, 36, 21, 16, 9, 14]
	Time taken saving stuff: 12.16s
episode: 85/2000 -> reward: -124.99999999998872, steps:71712, time-taken: 3.03min, time-elasped: 206.37min
-> berries picked: 89 of 800 | patches-visited: [2, 3] | positive-in-buffer: 4072 | amount-filled: 100.00%
	| epsilon: 0.4665672964989819
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [211, 757, 287, 1176, 470, 539, 252, 380]
	| approx positives in sample 512: 168
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 37, 11, 48, 15, 14, 12, 19]
	Time taken saving stuff: 0.10s
episode: 86/2000 -> reward: -124.99999999999247, steps:65760, time-taken: 2.19min, time-elasped: 208.57min
-> berries picked: 63 of 800 | patches-visited: [0] | positive-in-buffer: 4135 | amount-filled: 100.00%
	| epsilon: 0.4661919919787222
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [214, 772, 293, 1192, 475, 549, 255, 385]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 27, 9, 32, 18, 19, 5, 10]
	Time taken saving stuff: 0.01s
episode: 87/2000 -> reward: -124.99999999998745, steps:76320, time-taken: 3.03min, time-elasped: 211.60min
-> berries picked: 98 of 800 | patches-visited: [5, 7] | positive-in-buffer: 4233 | amount-filled: 100.00%
	| epsilon: 0.4658169893516384
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [214, 784, 298, 1218, 492, 570, 264, 393]
	| approx positives in sample 512: 161
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 29, 12, 42, 27, 20, 11, 14]
	Time taken saving stuff: 15.18s
episode: 88/2000 -> reward: -124.9999999999914, steps:64896, time-taken: 2.14min, time-elasped: 214.00min
-> berries picked: 76 of 800 | patches-visited: [1] | positive-in-buffer: 4308 | amount-filled: 100.00%
	| epsilon: 0.46544228837488916
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [222, 799, 301, 1236, 499, 581, 270, 400]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 28, 12, 36, 15, 10, 11, 13]
	Time taken saving stuff: 0.02s
episode: 89/2000 -> reward: -124.99999999999258, steps:72384, time-taken: 3.06min, time-elasped: 217.07min
-> berries picked: 93 of 800 | patches-visited: [4, 7] | positive-in-buffer: 4402 | amount-filled: 100.00%
	| epsilon: 0.4650678888058283
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [229, 817, 309, 1263, 504, 597, 275, 408]
	| approx positives in sample 512: 194
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 38, 7, 50, 21, 31, 16, 21]
	Time taken saving stuff: 0.10s
episode: 90/2000 -> reward: -124.99999999999284, steps:67872, time-taken: 3.06min, time-elasped: 220.13min
-> berries picked: 75 of 800 | patches-visited: [0] | positive-in-buffer: 4477 | amount-filled: 100.00%
	| epsilon: 0.4646937904020049
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [233, 833, 319, 1285, 509, 605, 278, 415]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 41, 15, 51, 36, 33, 13, 20]
	Time taken saving stuff: 12.28s
episode: 91/2000 -> reward: -124.99999999998772, steps:78624, time-taken: 3.10min, time-elasped: 223.43min
-> berries picked: 125 of 800 | patches-visited: [0, 7] | positive-in-buffer: 4603 | amount-filled: 100.00%
	| epsilon: 0.4643199929211631
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [243, 847, 338, 1319, 518, 631, 283, 424]
	| approx positives in sample 512: 160
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 33, 5, 47, 17, 18, 10, 22]
	Time taken saving stuff: 0.02s
episode: 92/2000 -> reward: -124.9999999999907, steps:84864, time-taken: 3.38min, time-elasped: 226.81min
-> berries picked: 144 of 800 | patches-visited: [2, 5, 6] | positive-in-buffer: 4748 | amount-filled: 100.00%
	| epsilon: 0.4639464961212419
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [249, 877, 346, 1367, 535, 647, 289, 438]
	| approx positives in sample 512: 160
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 29, 12, 51, 20, 17, 8, 18]
	Time taken saving stuff: 0.01s
episode: 93/2000 -> reward: -124.99999999998711, steps:72288, time-taken: 3.18min, time-elasped: 229.99min
-> berries picked: 92 of 800 | patches-visited: [2, 9] | positive-in-buffer: 4841 | amount-filled: 100.00%
	| epsilon: 0.463573299760375
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [250, 896, 355, 1402, 540, 659, 294, 445]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 31, 20, 54, 25, 30, 24, 20]
	Time taken saving stuff: 14.84s
episode: 94/2000 -> reward: -124.99999999999359, steps:67008, time-taken: 2.69min, time-elasped: 232.94min
-> berries picked: 73 of 800 | patches-visited: [6] | positive-in-buffer: 4914 | amount-filled: 100.00%
	| epsilon: 0.4632004035968905
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [254, 901, 363, 1431, 549, 671, 295, 450]
	| approx positives in sample 512: 243
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 48, 23, 73, 19, 32, 17, 22]
	Time taken saving stuff: 0.07s
episode: 95/2000 -> reward: -124.9999999999918, steps:63648, time-taken: 2.32min, time-elasped: 235.26min
-> berries picked: 55 of 800 | patches-visited: [5] | positive-in-buffer: 4968 | amount-filled: 100.00%
	| epsilon: 0.4628278073893113
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [258, 908, 365, 1448, 558, 675, 300, 456]
	| approx positives in sample 512: 156
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 28, 9, 52, 23, 25, 8, 9]
	Time taken saving stuff: 0.02s
episode: 96/2000 -> reward: -124.99999999999157, steps:59136, time-taken: 1.97min, time-elasped: 237.23min
-> berries picked: 40 of 800 | patches-visited: [2] | positive-in-buffer: 5005 | amount-filled: 100.00%
	| epsilon: 0.4624555108963541
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [260, 915, 368, 1462, 563, 679, 301, 457]
	| approx positives in sample 512: 178
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 35, 10, 43, 21, 23, 13, 24]
	Time taken saving stuff: 11.78s
episode: 97/2000 -> reward: -124.99999999999065, steps:79680, time-taken: 3.06min, time-elasped: 240.48min
-> berries picked: 120 of 800 | patches-visited: [1, 6] | positive-in-buffer: 5125 | amount-filled: 100.00%
	| epsilon: 0.4620835138769299
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [265, 942, 375, 1495, 569, 701, 310, 468]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 19, 8, 43, 21, 13, 17, 17]
	Time taken saving stuff: 0.00s
episode: 98/2000 -> reward: -124.99999999999231, steps:62304, time-taken: 2.18min, time-elasped: 242.67min
-> berries picked: 59 of 800 | patches-visited: [0] | positive-in-buffer: 5184 | amount-filled: 100.00%
	| epsilon: 0.4617118160901437
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [270, 951, 380, 1508, 575, 709, 312, 479]
	| approx positives in sample 512: 178
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 26, 12, 48, 25, 30, 15, 12]
	Time taken saving stuff: 0.01s
episode: 99/2000 -> reward: -124.99999999999025, steps:81600, time-taken: 3.12min, time-elasped: 245.78min
-> berries picked: 135 of 800 | patches-visited: [1, 8] | positive-in-buffer: 5320 | amount-filled: 100.00%
	| epsilon: 0.4613404172952942
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [278, 974, 393, 1548, 590, 719, 322, 496]
	| approx positives in sample 512: 185
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 42, 11, 42, 25, 26, 9, 22]
	Time taken saving stuff: 18.18s
episode: 100/2000 -> reward: -124.99999999998622, steps:76224, time-taken: 3.12min, time-elasped: 249.22min
-> berries picked: 106 of 800 | patches-visited: [0, 2] | positive-in-buffer: 5424 | amount-filled: 100.00%
	| epsilon: 0.46096931725187357
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [288, 996, 396, 1580, 597, 732, 326, 509]
	| approx positives in sample 512: 186
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 40, 13, 53, 12, 33, 11, 17]
	Time taken saving stuff: 0.11s
episode: 101/2000 -> reward: -124.99999999998722, steps:81024, time-taken: 3.17min, time-elasped: 252.39min
-> berries picked: 129 of 800 | patches-visited: [1, 9] | positive-in-buffer: 5553 | amount-filled: 100.00%
	| epsilon: 0.4605985157195676
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [296, 1019, 407, 1627, 605, 746, 332, 521]
	| approx positives in sample 512: 163
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 32, 6, 50, 19, 19, 9, 18]
	Time taken saving stuff: 0.01s
episode: 102/2000 -> reward: -124.99999999999352, steps:81984, time-taken: 3.24min, time-elasped: 255.63min
-> berries picked: 145 of 800 | patches-visited: [4, 8] | positive-in-buffer: 5697 | amount-filled: 100.00%
	| epsilon: 0.4602280124582555
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [298, 1044, 414, 1680, 614, 769, 339, 539]
	| approx positives in sample 512: 185
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 34, 15, 57, 20, 19, 11, 20]
	Time taken saving stuff: 11.75s
episode: 103/2000 -> reward: -124.9999999999918, steps:67488, time-taken: 2.78min, time-elasped: 258.61min
-> berries picked: 80 of 800 | patches-visited: [0] | positive-in-buffer: 5777 | amount-filled: 100.00%
	| epsilon: 0.45985780722800934
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [307, 1056, 420, 1700, 625, 781, 344, 544]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 47, 12, 61, 25, 25, 19, 16]
	Time taken saving stuff: 0.06s
episode: 104/2000 -> reward: -124.99999999998508, steps:83424, time-taken: 3.32min, time-elasped: 261.93min
-> berries picked: 134 of 800 | patches-visited: [1, 4] | positive-in-buffer: 5911 | amount-filled: 100.00%
	| epsilon: 0.4594878997890945
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [325, 1064, 435, 1736, 636, 795, 353, 567]
	| approx positives in sample 512: 165
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 33, 15, 43, 17, 22, 9, 17]
	Time taken saving stuff: 0.05s
episode: 105/2000 -> reward: -124.99999999999238, steps:64032, time-taken: 2.28min, time-elasped: 264.21min
-> berries picked: 63 of 800 | patches-visited: [3] | positive-in-buffer: 5971 | amount-filled: 100.00%
	| epsilon: 0.4591182899019689
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [327, 1077, 443, 1749, 646, 800, 356, 573]
	| approx positives in sample 512: 165
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 31, 5, 42, 16, 29, 13, 16]
	Time taken saving stuff: 14.68s
episode: 106/2000 -> reward: -124.99999999999115, steps:67392, time-taken: 2.95min, time-elasped: 267.40min
-> berries picked: 77 of 800 | patches-visited: [8, 9] | positive-in-buffer: 6047 | amount-filled: 100.00%
	| epsilon: 0.45874897732728337
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [335, 1091, 446, 1773, 656, 809, 359, 578]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 53, 6, 63, 20, 34, 18, 14]
	Time taken saving stuff: 0.00s
episode: 107/2000 -> reward: -124.99999999999288, steps:64896, time-taken: 2.20min, time-elasped: 269.61min
-> berries picked: 69 of 800 | patches-visited: [0] | positive-in-buffer: 6114 | amount-filled: 100.00%
	| epsilon: 0.45837996182588114
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [335, 1102, 453, 1787, 668, 824, 360, 585]
	| approx positives in sample 512: 174
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 27, 14, 48, 23, 21, 16, 19]
	Time taken saving stuff: 0.11s
episode: 108/2000 -> reward: -124.9999999999917, steps:66240, time-taken: 2.99min, time-elasped: 272.60min
-> berries picked: 79 of 800 | patches-visited: [2] | positive-in-buffer: 6193 | amount-filled: 100.00%
	| epsilon: 0.45801124315879793
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [338, 1113, 461, 1810, 682, 837, 361, 591]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 33, 13, 57, 30, 32, 22, 20]
	Time taken saving stuff: 11.93s
episode: 109/2000 -> reward: -124.99999999998418, steps:85248, time-taken: 3.32min, time-elasped: 276.13min
-> berries picked: 130 of 800 | patches-visited: [0, 1, 5, 9] | positive-in-buffer: 6325 | amount-filled: 100.00%
	| epsilon: 0.4576428210872616
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [342, 1131, 471, 1847, 696, 865, 369, 604]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 24, 11, 30, 30, 26, 6, 13]
	Time taken saving stuff: 0.01s
episode: 110/2000 -> reward: -124.99999999999199, steps:83520, time-taken: 3.19min, time-elasped: 279.32min
-> berries picked: 133 of 800 | patches-visited: [1, 6, 9] | positive-in-buffer: 6460 | amount-filled: 100.00%
	| epsilon: 0.4572746953726921
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [349, 1152, 482, 1893, 709, 884, 374, 617]
	| approx positives in sample 512: 168
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 37, 15, 39, 23, 18, 9, 17]
	Time taken saving stuff: 0.01s
episode: 111/2000 -> reward: -124.99999999999137, steps:84960, time-taken: 3.17min, time-elasped: 282.49min
-> berries picked: 132 of 800 | patches-visited: [4, 9] | positive-in-buffer: 6591 | amount-filled: 100.00%
	| epsilon: 0.4569068657767013
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [355, 1176, 496, 1926, 722, 898, 385, 633]
	| approx positives in sample 512: 174
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 32, 14, 53, 17, 21, 12, 16]
	Time taken saving stuff: 14.63s
episode: 112/2000 -> reward: -124.99999999999213, steps:63360, time-taken: 2.03min, time-elasped: 284.77min
-> berries picked: 66 of 800 | patches-visited: [5] | positive-in-buffer: 6655 | amount-filled: 100.00%
	| epsilon: 0.4565393320610928
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [360, 1189, 501, 1946, 726, 907, 388, 638]
	| approx positives in sample 512: 191
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 33, 11, 53, 17, 31, 17, 21]
	Time taken saving stuff: 0.01s
episode: 113/2000 -> reward: -124.99999999999193, steps:61728, time-taken: 2.06min, time-elasped: 286.83min
-> berries picked: 58 of 800 | patches-visited: [7] | positive-in-buffer: 6712 | amount-filled: 100.00%
	| epsilon: 0.45617209398786185
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [366, 1195, 504, 1960, 738, 915, 391, 643]
	| approx positives in sample 512: 174
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 28, 7, 44, 25, 24, 14, 17]
	Time taken saving stuff: 0.11s
episode: 114/2000 -> reward: -124.99999999999326, steps:67392, time-taken: 3.02min, time-elasped: 289.86min
-> berries picked: 77 of 800 | patches-visited: [6] | positive-in-buffer: 6787 | amount-filled: 100.00%
	| epsilon: 0.4558051513191951
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [368, 1211, 511, 1979, 747, 929, 395, 647]
	| approx positives in sample 512: 241
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 49, 18, 67, 28, 33, 8, 25]
	Time taken saving stuff: 11.70s
episode: 115/2000 -> reward: -124.99999999998651, steps:77088, time-taken: 3.07min, time-elasped: 293.13min
-> berries picked: 106 of 800 | patches-visited: [1, 7] | positive-in-buffer: 6894 | amount-filled: 100.00%
	| epsilon: 0.45543850381747053
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [381, 1227, 518, 2006, 761, 945, 402, 654]
	| approx positives in sample 512: 188
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 28, 13, 57, 16, 27, 10, 26]
	Time taken saving stuff: 0.01s
episode: 116/2000 -> reward: -124.99999999999223, steps:62400, time-taken: 2.11min, time-elasped: 295.25min
-> berries picked: 49 of 800 | patches-visited: [1] | positive-in-buffer: 6941 | amount-filled: 100.00%
	| epsilon: 0.4550721512452572
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [386, 1233, 522, 2027, 765, 948, 403, 657]
	| approx positives in sample 512: 185
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 32, 17, 44, 19, 28, 16, 22]
	Time taken saving stuff: 0.01s
episode: 117/2000 -> reward: -124.99999999999214, steps:57696, time-taken: 2.12min, time-elasped: 297.37min
-> berries picked: 39 of 800 | patches-visited: [1] | positive-in-buffer: 6980 | amount-filled: 100.00%
	| epsilon: 0.4547060933653153
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [388, 1239, 529, 2039, 770, 951, 404, 660]
	| approx positives in sample 512: 180
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 32, 18, 48, 23, 24, 12, 14]
	Time taken saving stuff: 15.16s
episode: 118/2000 -> reward: -124.99999999999069, steps:65376, time-taken: 2.15min, time-elasped: 299.78min
-> berries picked: 61 of 800 | patches-visited: [3] | positive-in-buffer: 7040 | amount-filled: 100.00%
	| epsilon: 0.4543403299405957
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [392, 1246, 539, 2058, 773, 962, 405, 665]
	| approx positives in sample 512: 156
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 25, 8, 36, 21, 32, 16, 12]
	Time taken saving stuff: 0.10s
episode: 119/2000 -> reward: -124.99999999999282, steps:66624, time-taken: 2.78min, time-elasped: 302.56min
-> berries picked: 78 of 800 | patches-visited: [7] | positive-in-buffer: 7117 | amount-filled: 100.00%
	| epsilon: 0.45397486073424004
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [400, 1256, 548, 2078, 780, 976, 410, 669]
	| approx positives in sample 512: 236
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 48, 19, 64, 28, 27, 17, 19]
	Time taken saving stuff: 0.09s
episode: 120/2000 -> reward: -124.99999999999052, steps:80544, time-taken: 3.31min, time-elasped: 305.87min
-> berries picked: 131 of 800 | patches-visited: [2, 9] | positive-in-buffer: 7246 | amount-filled: 100.00%
	| epsilon: 0.4536096855095805
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [408, 1283, 559, 2104, 793, 995, 417, 687]
	| approx positives in sample 512: 192
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 43, 16, 39, 17, 24, 15, 29]
	Time taken saving stuff: 11.74s
episode: 121/2000 -> reward: -124.99999999999241, steps:83520, time-taken: 3.09min, time-elasped: 309.16min
-> berries picked: 141 of 800 | patches-visited: [0, 3] | positive-in-buffer: 7385 | amount-filled: 100.00%
	| epsilon: 0.4532448040301395
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [414, 1301, 570, 2142, 806, 1014, 430, 708]
	| approx positives in sample 512: 171
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 27, 6, 45, 20, 33, 12, 19]
	Time taken saving stuff: 0.05s
episode: 122/2000 -> reward: -124.99999999998815, steps:83232, time-taken: 3.28min, time-elasped: 312.45min
-> berries picked: 144 of 800 | patches-visited: [2, 6, 7] | positive-in-buffer: 7528 | amount-filled: 100.00%
	| epsilon: 0.45288021605962986
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [425, 1325, 578, 2179, 818, 1030, 436, 737]
	| approx positives in sample 512: 161
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 32, 14, 35, 18, 20, 10, 20]
	Time taken saving stuff: 0.02s
episode: 123/2000 -> reward: -124.9999999999905, steps:66240, time-taken: 2.91min, time-elasped: 315.36min
-> berries picked: 76 of 800 | patches-visited: [7, 8] | positive-in-buffer: 7600 | amount-filled: 100.00%
	| epsilon: 0.4525159213619544
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [430, 1332, 586, 2198, 832, 1039, 439, 744]
	| approx positives in sample 512: 242
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 40, 18, 64, 33, 37, 7, 27]
	Time taken saving stuff: 14.94s
episode: 124/2000 -> reward: -124.99999999999197, steps:67776, time-taken: 2.97min, time-elasped: 318.58min
-> berries picked: 77 of 800 | patches-visited: [3, 4] | positive-in-buffer: 7675 | amount-filled: 100.00%
	| epsilon: 0.4521519197012058
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [438, 1342, 590, 2213, 840, 1051, 442, 759]
	| approx positives in sample 512: 233
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 40, 19, 57, 26, 35, 15, 25]
	Time taken saving stuff: 0.01s
episode: 125/2000 -> reward: -124.99999999999218, steps:61824, time-taken: 2.19min, time-elasped: 320.77min
-> berries picked: 58 of 800 | patches-visited: [1] | positive-in-buffer: 7733 | amount-filled: 100.00%
	| epsilon: 0.45178821084166654
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [442, 1346, 595, 2231, 846, 1057, 448, 768]
	| approx positives in sample 512: 170
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 39, 13, 47, 15, 22, 12, 16]
	Time taken saving stuff: 0.12s
episode: 126/2000 -> reward: -124.99999999999083, steps:77856, time-taken: 3.25min, time-elasped: 324.02min
-> berries picked: 111 of 800 | patches-visited: [2, 4] | positive-in-buffer: 7844 | amount-filled: 100.00%
	| epsilon: 0.4514247945478087
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [452, 1364, 606, 2264, 858, 1071, 451, 778]
	| approx positives in sample 512: 204
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 42, 9, 58, 17, 31, 10, 22]
	Time taken saving stuff: 12.00s
episode: 127/2000 -> reward: -124.99999999998558, steps:83904, time-taken: 3.12min, time-elasped: 327.35min
-> berries picked: 145 of 800 | patches-visited: [3, 4] | positive-in-buffer: 7985 | amount-filled: 100.00%
	| epsilon: 0.4510616705842939
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [465, 1373, 618, 2303, 869, 1092, 468, 797]
	| approx positives in sample 512: 162
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 25, 14, 44, 22, 21, 16, 14]
	Time taken saving stuff: 0.05s
episode: 128/2000 -> reward: -124.99999999998569, steps:83904, time-taken: 3.21min, time-elasped: 330.56min
-> berries picked: 137 of 800 | patches-visited: [2, 8] | positive-in-buffer: 8120 | amount-filled: 100.00%
	| epsilon: 0.450698838715973
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [481, 1383, 630, 2327, 890, 1117, 475, 817]
	| approx positives in sample 512: 186
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 27, 19, 49, 19, 29, 10, 21]
	Time taken saving stuff: 0.02s
episode: 129/2000 -> reward: -124.99999999998477, steps:81216, time-taken: 3.32min, time-elasped: 333.88min
-> berries picked: 135 of 800 | patches-visited: [0, 2] | positive-in-buffer: 8253 | amount-filled: 100.00%
	| epsilon: 0.45033629870788594
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [495, 1407, 640, 2355, 906, 1137, 477, 836]
	| approx positives in sample 512: 197
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 35, 10, 52, 20, 26, 16, 23]
	Time taken saving stuff: 15.57s
episode: 130/2000 -> reward: -124.9999999999862, steps:80064, time-taken: 3.08min, time-elasped: 337.22min
-> berries picked: 127 of 800 | patches-visited: [0, 3] | positive-in-buffer: 8380 | amount-filled: 100.00%
	| epsilon: 0.4499740503252617
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [503, 1431, 648, 2387, 921, 1153, 490, 847]
	| approx positives in sample 512: 186
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 35, 11, 51, 25, 23, 14, 19]
	Time taken saving stuff: 0.10s
episode: 131/2000 -> reward: -124.99999999999208, steps:66144, time-taken: 2.99min, time-elasped: 340.21min
-> berries picked: 71 of 800 | patches-visited: [6] | positive-in-buffer: 8449 | amount-filled: 100.00%
	| epsilon: 0.4496120933335183
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [508, 1438, 650, 2403, 931, 1167, 494, 858]
	| approx positives in sample 512: 250
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 47, 20, 57, 25, 37, 13, 29]
	Time taken saving stuff: 0.00s
episode: 132/2000 -> reward: -124.99999999999208, steps:59232, time-taken: 2.15min, time-elasped: 342.37min
-> berries picked: 42 of 800 | patches-visited: [3] | positive-in-buffer: 8489 | amount-filled: 100.00%
	| epsilon: 0.4492504274982622
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [509, 1449, 650, 2413, 937, 1169, 500, 862]
	| approx positives in sample 512: 196
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 38, 16, 57, 13, 30, 14, 21]
	Time taken saving stuff: 11.72s
episode: 133/2000 -> reward: -124.99999999999213, steps:58752, time-taken: 1.97min, time-elasped: 344.54min
-> berries picked: 39 of 800 | patches-visited: [5] | positive-in-buffer: 8523 | amount-filled: 100.00%
	| epsilon: 0.4488890525852885
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [513, 1452, 650, 2423, 940, 1174, 503, 868]
	| approx positives in sample 512: 185
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 33, 9, 61, 17, 20, 13, 22]
	Time taken saving stuff: 0.01s
episode: 134/2000 -> reward: -124.99999999999199, steps:60672, time-taken: 2.07min, time-elasped: 346.61min
-> berries picked: 54 of 800 | patches-visited: [7] | positive-in-buffer: 8576 | amount-filled: 100.00%
	| epsilon: 0.4485279683605807
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [518, 1460, 656, 2435, 950, 1179, 507, 871]
	| approx positives in sample 512: 199
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 38, 18, 43, 26, 23, 11, 24]
	Time taken saving stuff: 0.09s
episode: 135/2000 -> reward: -124.99999999998658, steps:77856, time-taken: 3.04min, time-elasped: 349.66min
-> berries picked: 116 of 800 | patches-visited: [1, 5] | positive-in-buffer: 8687 | amount-filled: 100.00%
	| epsilon: 0.4481671745903105
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [530, 1467, 669, 2454, 967, 1200, 511, 889]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 36, 15, 58, 28, 31, 12, 20]
	Time taken saving stuff: 14.88s
episode: 136/2000 -> reward: -124.99999999998825, steps:74304, time-taken: 3.16min, time-elasped: 353.06min
-> berries picked: 98 of 800 | patches-visited: [3, 9] | positive-in-buffer: 8779 | amount-filled: 100.00%
	| epsilon: 0.4478066710408379
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [541, 1478, 685, 2467, 981, 1212, 516, 899]
	| approx positives in sample 512: 223
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 50, 17, 64, 29, 29, 11, 13]
	Time taken saving stuff: 0.01s
episode: 137/2000 -> reward: -124.99999999998357, steps:87360, time-taken: 3.46min, time-elasped: 356.53min
-> berries picked: 149 of 800 | patches-visited: [3, 7] | positive-in-buffer: 8914 | amount-filled: 100.00%
	| epsilon: 0.4474464574787104
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [559, 1489, 697, 2485, 1006, 1229, 524, 925]
	| approx positives in sample 512: 171
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 35, 9, 44, 19, 25, 14, 16]
	Time taken saving stuff: 0.09s
episode: 138/2000 -> reward: -124.99999999999203, steps:62688, time-taken: 2.08min, time-elasped: 358.61min
-> berries picked: 63 of 800 | patches-visited: [5] | positive-in-buffer: 8975 | amount-filled: 100.00%
	| epsilon: 0.44708653367066375
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [562, 1495, 702, 2499, 1014, 1240, 529, 934]
	| approx positives in sample 512: 188
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 32, 17, 48, 21, 23, 15, 17]
	Time taken saving stuff: 11.71s
episode: 139/2000 -> reward: -124.99999999998491, steps:82272, time-taken: 3.48min, time-elasped: 362.29min
-> berries picked: 136 of 800 | patches-visited: [0, 4] | positive-in-buffer: 9101 | amount-filled: 100.00%
	| epsilon: 0.4467268993836211
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [574, 1506, 708, 2526, 1037, 1267, 533, 950]
	| approx positives in sample 512: 198
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 29, 15, 43, 36, 26, 10, 25]
	Time taken saving stuff: 0.09s
episode: 140/2000 -> reward: -124.99999999998475, steps:84672, time-taken: 3.41min, time-elasped: 365.71min
-> berries picked: 140 of 800 | patches-visited: [5, 6] | positive-in-buffer: 9234 | amount-filled: 100.00%
	| epsilon: 0.4463675543846931
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [583, 1525, 718, 2565, 1049, 1286, 541, 967]
	| approx positives in sample 512: 180
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 27, 10, 52, 21, 30, 16, 15]
	Time taken saving stuff: 0.09s
episode: 141/2000 -> reward: -124.99999999999164, steps:65664, time-taken: 2.39min, time-elasped: 368.10min
-> berries picked: 67 of 800 | patches-visited: [6] | positive-in-buffer: 9298 | amount-filled: 100.00%
	| epsilon: 0.44600849844117774
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [588, 1535, 721, 2580, 1056, 1297, 546, 975]
	| approx positives in sample 512: 180
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 26, 13, 43, 24, 35, 7, 23]
	Time taken saving stuff: 18.66s
episode: 142/2000 -> reward: -124.99999999999172, steps:61824, time-taken: 1.97min, time-elasped: 370.38min
-> berries picked: 54 of 800 | patches-visited: [6] | positive-in-buffer: 9348 | amount-filled: 100.00%
	| epsilon: 0.4456497313205603
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [592, 1546, 722, 2586, 1063, 1304, 547, 988]
	| approx positives in sample 512: 185
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 26, 20, 58, 18, 22, 9, 19]
	Time taken saving stuff: 0.02s
episode: 143/2000 -> reward: -124.99999999999204, steps:54336, time-taken: 2.01min, time-elasped: 372.39min
-> berries picked: 23 of 800 | patches-visited: [0] | positive-in-buffer: 9368 | amount-filled: 100.00%
	| epsilon: 0.44529125279051296
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [593, 1552, 723, 2587, 1068, 1307, 548, 990]
	| approx positives in sample 512: 206
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 35, 13, 59, 20, 34, 6, 24]
	Time taken saving stuff: 0.01s
episode: 144/2000 -> reward: -124.99999999998609, steps:79488, time-taken: 3.47min, time-elasped: 375.87min
-> berries picked: 110 of 800 | patches-visited: [1, 6] | positive-in-buffer: 9477 | amount-filled: 100.00%
	| epsilon: 0.4449330626188948
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [606, 1570, 728, 2606, 1085, 1323, 558, 1001]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 35, 13, 54, 31, 36, 17, 18]
	Time taken saving stuff: 11.84s
episode: 145/2000 -> reward: -124.99999999999181, steps:64992, time-taken: 2.36min, time-elasped: 378.43min
-> berries picked: 69 of 800 | patches-visited: [3] | positive-in-buffer: 9535 | amount-filled: 100.00%
	| epsilon: 0.44457516057375174
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [614, 1577, 739, 2615, 1089, 1331, 559, 1011]
	| approx positives in sample 512: 193
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 26, 13, 47, 26, 31, 9, 28]
	Time taken saving stuff: 0.01s
episode: 146/2000 -> reward: -124.99999999998536, steps:82176, time-taken: 3.37min, time-elasped: 381.80min
-> berries picked: 127 of 800 | patches-visited: [2, 5] | positive-in-buffer: 9643 | amount-filled: 100.00%
	| epsilon: 0.4442175464233162
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [620, 1591, 750, 2636, 1105, 1353, 564, 1024]
	| approx positives in sample 512: 192
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 31, 18, 48, 28, 25, 12, 23]
	Time taken saving stuff: 0.03s
episode: 147/2000 -> reward: -124.99999999998685, steps:79968, time-taken: 3.18min, time-elasped: 384.98min
-> berries picked: 124 of 800 | patches-visited: [0, 4] | positive-in-buffer: 9743 | amount-filled: 100.00%
	| epsilon: 0.44386021993600694
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [626, 1610, 761, 2650, 1118, 1362, 574, 1042]
	| approx positives in sample 512: 197
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 31, 20, 51, 23, 30, 12, 19]
	Time taken saving stuff: 15.66s
episode: 148/2000 -> reward: -124.99999999998943, steps:68832, time-taken: 3.12min, time-elasped: 388.36min
-> berries picked: 74 of 800 | patches-visited: [0, 9] | positive-in-buffer: 9788 | amount-filled: 100.00%
	| epsilon: 0.4435031808804292
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [631, 1619, 766, 2645, 1131, 1371, 578, 1047]
	| approx positives in sample 512: 240
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 49, 14, 59, 32, 36, 10, 23]
	Time taken saving stuff: 0.01s
episode: 149/2000 -> reward: -124.99999999998902, steps:67392, time-taken: 3.12min, time-elasped: 391.49min
-> berries picked: 78 of 800 | patches-visited: [4] | positive-in-buffer: 9848 | amount-filled: 100.00%
	| epsilon: 0.44314642902537427
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [637, 1631, 773, 2652, 1140, 1374, 585, 1056]
	| approx positives in sample 512: 248
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 43, 15, 59, 28, 32, 15, 35]
	Time taken saving stuff: 0.07s
episode: 150/2000 -> reward: -124.99999999999304, steps:65664, time-taken: 2.30min, time-elasped: 393.79min
-> berries picked: 75 of 800 | patches-visited: [9] | positive-in-buffer: 9872 | amount-filled: 100.00%
	| epsilon: 0.4427899641398194
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [645, 1634, 778, 2639, 1141, 1384, 590, 1061]
	| approx positives in sample 512: 191
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 33, 16, 55, 23, 25, 9, 20]
	Time taken saving stuff: 12.23s
episode: 151/2000 -> reward: -124.99999999998892, steps:74688, time-taken: 3.21min, time-elasped: 397.21min
-> berries picked: 101 of 800 | patches-visited: [1, 2] | positive-in-buffer: 9952 | amount-filled: 100.00%
	| epsilon: 0.44243378599292765
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [652, 1641, 787, 2656, 1153, 1393, 594, 1076]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 34, 18, 60, 34, 27, 14, 33]
	Time taken saving stuff: 0.10s
episode: 152/2000 -> reward: -124.99999999999204, steps:64032, time-taken: 2.15min, time-elasped: 399.36min
-> berries picked: 65 of 800 | patches-visited: [9] | positive-in-buffer: 10009 | amount-filled: 100.00%
	| epsilon: 0.4420778943540478
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [654, 1648, 793, 2676, 1155, 1400, 599, 1084]
	| approx positives in sample 512: 199
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 45, 14, 54, 16, 31, 9, 19]
	Time taken saving stuff: 0.01s
episode: 153/2000 -> reward: -124.99999999998543, steps:79200, time-taken: 3.46min, time-elasped: 402.83min
-> berries picked: 113 of 800 | patches-visited: [5, 7, 9] | positive-in-buffer: 10087 | amount-filled: 100.00%
	| epsilon: 0.4417222889927142
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [662, 1657, 796, 2700, 1164, 1415, 599, 1094]
	| approx positives in sample 512: 182
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 34, 11, 53, 22, 27, 7, 26]
	Time taken saving stuff: 15.45s
episode: 154/2000 -> reward: -124.99999999998768, steps:66720, time-taken: 3.06min, time-elasped: 406.15min
-> berries picked: 69 of 800 | patches-visited: [1, 8] | positive-in-buffer: 10120 | amount-filled: 100.00%
	| epsilon: 0.4413669696786466
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [663, 1658, 801, 2698, 1177, 1427, 604, 1092]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 31, 17, 59, 31, 41, 14, 23]
	Time taken saving stuff: 0.00s
episode: 155/2000 -> reward: -124.9999999999917, steps:64128, time-taken: 2.31min, time-elasped: 408.46min
-> berries picked: 59 of 800 | patches-visited: [6] | positive-in-buffer: 10056 | amount-filled: 100.00%
	| epsilon: 0.4410119361817498
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [662, 1661, 762, 2670, 1185, 1421, 607, 1088]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 33, 12, 52, 26, 32, 10, 19]
	Time taken saving stuff: 0.10s
episode: 156/2000 -> reward: -124.99999999998902, steps:64032, time-taken: 2.78min, time-elasped: 411.25min
-> berries picked: 63 of 800 | patches-visited: [0] | positive-in-buffer: 10055 | amount-filled: 100.00%
	| epsilon: 0.44065718827211386
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [670, 1666, 766, 2663, 1192, 1404, 608, 1086]
	| approx positives in sample 512: 192
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 31, 9, 45, 24, 28, 9, 27]
	Time taken saving stuff: 12.45s
episode: 157/2000 -> reward: -124.99999999998994, steps:64608, time-taken: 2.22min, time-elasped: 413.67min
-> berries picked: 61 of 800 | patches-visited: [1, 8] | positive-in-buffer: 10062 | amount-filled: 100.00%
	| epsilon: 0.44030272572001383
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [657, 1667, 770, 2671, 1187, 1415, 605, 1090]
	| approx positives in sample 512: 179
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 27, 15, 48, 21, 21, 12, 21]
	Time taken saving stuff: 0.01s
episode: 158/2000 -> reward: -124.9999999999931, steps:65664, time-taken: 2.36min, time-elasped: 416.04min
-> berries picked: 59 of 800 | patches-visited: [3, 4, 8] | positive-in-buffer: 10011 | amount-filled: 100.00%
	| epsilon: 0.43994854829590935
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [660, 1674, 768, 2667, 1136, 1410, 606, 1090]
	| approx positives in sample 512: 187
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 30, 15, 41, 22, 29, 16, 20]
	Time taken saving stuff: 0.10s
episode: 159/2000 -> reward: -124.99999999998748, steps:62112, time-taken: 2.48min, time-elasped: 418.52min
-> berries picked: 53 of 800 | patches-visited: [7, 9] | positive-in-buffer: 9973 | amount-filled: 100.00%
	| epsilon: 0.43959465577044493
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [665, 1670, 739, 2649, 1141, 1414, 599, 1096]
	| approx positives in sample 512: 210
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 37, 13, 54, 27, 33, 10, 23]
	Time taken saving stuff: 15.83s
episode: 160/2000 -> reward: -124.9999999999894, steps:61920, time-taken: 2.47min, time-elasped: 421.26min
-> berries picked: 53 of 800 | patches-visited: [6, 7] | positive-in-buffer: 9998 | amount-filled: 100.00%
	| epsilon: 0.43924104791444935
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [670, 1677, 744, 2650, 1143, 1423, 589, 1102]
	| approx positives in sample 512: 182
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 39, 20, 37, 20, 24, 5, 23]
	Time taken saving stuff: 0.11s
episode: 161/2000 -> reward: -124.99999999999281, steps:64704, time-taken: 2.42min, time-elasped: 423.68min
-> berries picked: 62 of 800 | patches-visited: [7] | positive-in-buffer: 9985 | amount-filled: 100.00%
	| epsilon: 0.4388877244989359
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [666, 1671, 747, 2663, 1157, 1424, 557, 1100]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 38, 13, 57, 22, 20, 11, 26]
	Time taken saving stuff: 0.01s
episode: 162/2000 -> reward: -124.99999999998614, steps:83136, time-taken: 3.73min, time-elasped: 427.41min
-> berries picked: 142 of 800 | patches-visited: [3, 9] | positive-in-buffer: 10074 | amount-filled: 100.00%
	| epsilon: 0.438534685295102
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [646, 1685, 758, 2692, 1182, 1427, 568, 1116]
	| approx positives in sample 512: 189
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 35, 11, 48, 23, 27, 9, 19]
	Time taken saving stuff: 11.87s
episode: 163/2000 -> reward: -124.99999999999191, steps:64032, time-taken: 2.39min, time-elasped: 430.00min
-> berries picked: 73 of 800 | patches-visited: [4] | positive-in-buffer: 10107 | amount-filled: 100.00%
	| epsilon: 0.4381819300743291
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [653, 1691, 760, 2705, 1189, 1425, 575, 1109]
	| approx positives in sample 512: 193
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 40, 5, 33, 30, 32, 11, 33]
	Time taken saving stuff: 0.02s
episode: 164/2000 -> reward: -124.9999999999913, steps:65472, time-taken: 2.37min, time-elasped: 432.37min
-> berries picked: 78 of 800 | patches-visited: [6] | positive-in-buffer: 10125 | amount-filled: 100.00%
	| epsilon: 0.43782945860818256
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [659, 1693, 758, 2705, 1203, 1426, 575, 1106]
	| approx positives in sample 512: 186
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 32, 12, 44, 23, 24, 16, 25]
	Time taken saving stuff: 0.02s
episode: 165/2000 -> reward: -124.9999999999922, steps:66432, time-taken: 3.14min, time-elasped: 435.52min
-> berries picked: 76 of 800 | patches-visited: [7] | positive-in-buffer: 10138 | amount-filled: 100.00%
	| epsilon: 0.4374772706684116
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [664, 1693, 761, 2700, 1208, 1429, 579, 1104]
	| approx positives in sample 512: 241
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 57, 15, 47, 23, 33, 20, 28]
	Time taken saving stuff: 15.73s
episode: 166/2000 -> reward: -124.99999999998596, steps:83520, time-taken: 3.57min, time-elasped: 439.35min
-> berries picked: 136 of 800 | patches-visited: [7, 9] | positive-in-buffer: 10250 | amount-filled: 100.00%
	| epsilon: 0.4371253660269488
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [677, 1706, 769, 2720, 1236, 1430, 596, 1116]
	| approx positives in sample 512: 197
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 34, 17, 37, 32, 26, 13, 26]
	Time taken saving stuff: 0.09s
episode: 167/2000 -> reward: -124.99999999998543, steps:84192, time-taken: 3.48min, time-elasped: 442.84min
-> berries picked: 140 of 800 | patches-visited: [1, 5] | positive-in-buffer: 10259 | amount-filled: 100.00%
	| epsilon: 0.43677374445591044
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [688, 1706, 773, 2717, 1238, 1427, 593, 1117]
	| approx positives in sample 512: 199
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 41, 15, 49, 23, 29, 12, 21]
	Time taken saving stuff: 0.09s
episode: 168/2000 -> reward: -124.99999999998961, steps:67008, time-taken: 3.13min, time-elasped: 445.98min
-> berries picked: 79 of 800 | patches-visited: [3] | positive-in-buffer: 10189 | amount-filled: 100.00%
	| epsilon: 0.436422405727596
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [692, 1690, 759, 2696, 1245, 1411, 589, 1107]
	| approx positives in sample 512: 249
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 54, 19, 51, 30, 28, 12, 39]
	Time taken saving stuff: 11.82s
episode: 169/2000 -> reward: -124.99999999999342, steps:66240, time-taken: 3.14min, time-elasped: 449.31min
-> berries picked: 73 of 800 | patches-visited: [2] | positive-in-buffer: 10195 | amount-filled: 100.00%
	| epsilon: 0.4360713496144882
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [696, 1694, 753, 2694, 1249, 1406, 593, 1110]
	| approx positives in sample 512: 262
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 53, 20, 58, 34, 37, 16, 31]
	Time taken saving stuff: 0.00s
episode: 170/2000 -> reward: -124.99999999999127, steps:66336, time-taken: 3.24min, time-elasped: 452.56min
-> berries picked: 64 of 800 | patches-visited: [5] | positive-in-buffer: 10169 | amount-filled: 100.00%
	| epsilon: 0.43572057588925256
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [698, 1688, 749, 2676, 1247, 1400, 600, 1111]
	| approx positives in sample 512: 256
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 37, 17, 51, 35, 41, 13, 40]
	Time taken saving stuff: 0.06s
episode: 171/2000 -> reward: -124.99999999998352, steps:81408, time-taken: 3.30min, time-elasped: 455.86min
-> berries picked: 118 of 800 | patches-visited: [3, 5] | positive-in-buffer: 10212 | amount-filled: 100.00%
	| epsilon: 0.43537008432473767
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [703, 1671, 751, 2682, 1261, 1408, 604, 1132]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 40, 13, 50, 31, 30, 14, 22]
	Time taken saving stuff: 15.10s
episode: 172/2000 -> reward: -124.99999999999149, steps:61344, time-taken: 2.86min, time-elasped: 458.98min
-> berries picked: 51 of 800 | patches-visited: [1, 3] | positive-in-buffer: 10180 | amount-filled: 100.00%
	| epsilon: 0.43501987469397485
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [695, 1657, 750, 2679, 1263, 1404, 601, 1131]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 37, 12, 48, 26, 41, 14, 23]
	Time taken saving stuff: 0.06s
episode: 173/2000 -> reward: -124.99999999999288, steps:62592, time-taken: 2.56min, time-elasped: 461.54min
-> berries picked: 54 of 800 | patches-visited: [2] | positive-in-buffer: 10172 | amount-filled: 100.00%
	| epsilon: 0.4346699467701779
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [692, 1659, 743, 2666, 1261, 1407, 610, 1134]
	| approx positives in sample 512: 185
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 29, 12, 45, 18, 31, 16, 27]
	Time taken saving stuff: 0.10s
episode: 174/2000 -> reward: -124.99999999998731, steps:80640, time-taken: 4.07min, time-elasped: 465.61min
-> berries picked: 130 of 800 | patches-visited: [0, 9] | positive-in-buffer: 10252 | amount-filled: 100.00%
	| epsilon: 0.434320300326743
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [698, 1674, 756, 2682, 1274, 1420, 612, 1136]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 43, 16, 46, 27, 31, 8, 25]
	Time taken saving stuff: 12.73s
episode: 175/2000 -> reward: -124.99999999999206, steps:70848, time-taken: 4.96min, time-elasped: 470.79min
-> berries picked: 88 of 800 | patches-visited: [0, 3] | positive-in-buffer: 10301 | amount-filled: 100.00%
	| epsilon: 0.4339709351372488
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [695, 1683, 759, 2692, 1289, 1424, 618, 1141]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 38, 14, 45, 34, 31, 18, 23]
	Time taken saving stuff: 0.02s
episode: 176/2000 -> reward: -124.9999999999878, steps:66336, time-taken: 3.59min, time-elasped: 474.38min
-> berries picked: 74 of 800 | patches-visited: [4] | positive-in-buffer: 10332 | amount-filled: 100.00%
	| epsilon: 0.4336218509754559
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [701, 1690, 759, 2696, 1297, 1421, 623, 1145]
	| approx positives in sample 512: 241
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 47, 18, 55, 28, 47, 4, 26]
	Time taken saving stuff: 0.12s
episode: 177/2000 -> reward: -124.99999999998681, steps:75264, time-taken: 3.85min, time-elasped: 478.24min
-> berries picked: 120 of 800 | patches-visited: [0, 7] | positive-in-buffer: 10386 | amount-filled: 100.00%
	| epsilon: 0.43327304761530694
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [700, 1689, 760, 2712, 1308, 1437, 629, 1151]
	| approx positives in sample 512: 237
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 48, 13, 56, 40, 30, 11, 28]
	Time taken saving stuff: 12.43s
episode: 178/2000 -> reward: -124.99999999998543, steps:84288, time-taken: 4.75min, time-elasped: 483.20min
-> berries picked: 137 of 800 | patches-visited: [1, 6] | positive-in-buffer: 10467 | amount-filled: 100.00%
	| epsilon: 0.4329245248309264
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [704, 1695, 769, 2738, 1326, 1452, 631, 1152]
	| approx positives in sample 512: 202
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 33, 12, 42, 22, 37, 13, 24]
	Time taken saving stuff: 0.03s
episode: 179/2000 -> reward: -124.99999999998715, steps:78336, time-taken: 4.20min, time-elasped: 487.40min
-> berries picked: 123 of 800 | patches-visited: [4, 6] | positive-in-buffer: 10542 | amount-filled: 100.00%
	| epsilon: 0.4325762823966205
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [716, 1695, 772, 2754, 1343, 1466, 636, 1160]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 38, 17, 47, 30, 34, 16, 21]
	Time taken saving stuff: 0.01s
episode: 180/2000 -> reward: -124.99999999998249, steps:90528, time-taken: 4.36min, time-elasped: 491.77min
-> berries picked: 154 of 800 | patches-visited: [2, 6, 9] | positive-in-buffer: 10653 | amount-filled: 100.00%
	| epsilon: 0.432228320086877
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [724, 1714, 782, 2764, 1354, 1484, 653, 1178]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 45, 11, 51, 35, 27, 14, 25]
	Time taken saving stuff: 14.08s
episode: 181/2000 -> reward: -124.99999999998782, steps:92160, time-taken: 4.19min, time-elasped: 496.19min
-> berries picked: 165 of 800 | patches-visited: [5, 6, 8] | positive-in-buffer: 10739 | amount-filled: 100.00%
	| epsilon: 0.4318806376763649
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [739, 1718, 791, 2780, 1366, 1514, 658, 1173]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 34, 18, 41, 27, 42, 28, 26]
	Time taken saving stuff: 0.11s
episode: 182/2000 -> reward: -124.99999999999207, steps:64896, time-taken: 2.14min, time-elasped: 498.34min
-> berries picked: 58 of 800 | patches-visited: [0] | positive-in-buffer: 10767 | amount-filled: 100.00%
	| epsilon: 0.43153323493993473
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [742, 1723, 790, 2781, 1373, 1520, 662, 1176]
	| approx positives in sample 512: 198
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 35, 15, 35, 26, 27, 16, 31]
	Time taken saving stuff: 0.03s
episode: 183/2000 -> reward: -124.99999999998847, steps:66624, time-taken: 3.04min, time-elasped: 501.38min
-> berries picked: 65 of 800 | patches-visited: [5] | positive-in-buffer: 10814 | amount-filled: 100.00%
	| epsilon: 0.43118611165261794
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [747, 1733, 790, 2790, 1377, 1529, 665, 1183]
	| approx positives in sample 512: 242
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 44, 14, 39, 36, 41, 19, 32]
	Time taken saving stuff: 12.93s
episode: 184/2000 -> reward: -124.9999999999922, steps:65376, time-taken: 2.45min, time-elasped: 504.05min
-> berries picked: 77 of 800 | patches-visited: [7] | positive-in-buffer: 10856 | amount-filled: 100.00%
	| epsilon: 0.43083926758962693
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [749, 1740, 794, 2799, 1381, 1535, 670, 1188]
	| approx positives in sample 512: 193
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 36, 17, 33, 23, 30, 15, 23]
	Time taken saving stuff: 0.09s
episode: 185/2000 -> reward: -124.99999999999224, steps:69600, time-taken: 3.21min, time-elasped: 507.26min
-> berries picked: 78 of 800 | patches-visited: [5] | positive-in-buffer: 10916 | amount-filled: 100.00%
	| epsilon: 0.4304927025263551
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [757, 1740, 798, 2809, 1389, 1549, 681, 1193]
	| approx positives in sample 512: 242
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 39, 21, 34, 37, 37, 17, 31]
	Time taken saving stuff: 0.00s
episode: 186/2000 -> reward: -124.99999999999241, steps:64224, time-taken: 2.26min, time-elasped: 509.53min
-> berries picked: 63 of 800 | patches-visited: [6] | positive-in-buffer: 10954 | amount-filled: 100.00%
	| epsilon: 0.43014641623837624
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [761, 1752, 804, 2803, 1393, 1557, 682, 1202]
	| approx positives in sample 512: 205
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 32, 25, 34, 25, 29, 11, 32]
	Time taken saving stuff: 12.36s
episode: 187/2000 -> reward: -124.999999999992, steps:63072, time-taken: 2.28min, time-elasped: 512.01min
-> berries picked: 60 of 800 | patches-visited: [8] | positive-in-buffer: 10997 | amount-filled: 100.00%
	| epsilon: 0.4298004085014449
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [763, 1765, 807, 2809, 1395, 1563, 684, 1211]
	| approx positives in sample 512: 201
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 34, 15, 44, 19, 38, 14, 23]
	Time taken saving stuff: 0.01s
episode: 188/2000 -> reward: -124.99999999998782, steps:77472, time-taken: 3.37min, time-elasped: 515.39min
-> berries picked: 113 of 800 | patches-visited: [2, 5] | positive-in-buffer: 11063 | amount-filled: 100.00%
	| epsilon: 0.429454679091496
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [767, 1777, 821, 2806, 1404, 1576, 686, 1226]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 41, 20, 52, 25, 33, 5, 30]
	Time taken saving stuff: 0.01s
episode: 189/2000 -> reward: -124.99999999998808, steps:57888, time-taken: 2.45min, time-elasped: 517.84min
-> berries picked: 36 of 800 | patches-visited: [5] | positive-in-buffer: 11064 | amount-filled: 100.00%
	| epsilon: 0.42910922778464455
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [770, 1779, 821, 2795, 1399, 1584, 686, 1230]
	| approx positives in sample 512: 205
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 37, 16, 36, 24, 35, 15, 24]
	Time taken saving stuff: 12.35s
episode: 190/2000 -> reward: -124.99999999999226, steps:66144, time-taken: 3.56min, time-elasped: 521.62min
-> berries picked: 74 of 800 | patches-visited: [6] | positive-in-buffer: 11101 | amount-filled: 100.00%
	| epsilon: 0.4287640543571858
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [780, 1784, 823, 2799, 1399, 1597, 687, 1232]
	| approx positives in sample 512: 264
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 34, 21, 50, 33, 58, 20, 35]
	Time taken saving stuff: 0.01s
episode: 191/2000 -> reward: -124.9999999999878, steps:72960, time-taken: 3.93min, time-elasped: 525.55min
-> berries picked: 88 of 800 | patches-visited: [2, 8] | positive-in-buffer: 11130 | amount-filled: 100.00%
	| epsilon: 0.4284191585855949
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [795, 1787, 829, 2777, 1404, 1609, 693, 1236]
	| approx positives in sample 512: 239
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 31, 22, 46, 30, 44, 20, 28]
	Time taken saving stuff: 0.01s
episode: 192/2000 -> reward: -124.99999999999278, steps:82272, time-taken: 4.73min, time-elasped: 530.29min
-> berries picked: 138 of 800 | patches-visited: [0, 3] | positive-in-buffer: 11209 | amount-filled: 100.00%
	| epsilon: 0.42807454024652664
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [806, 1800, 843, 2770, 1422, 1630, 695, 1243]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 49, 14, 51, 11, 35, 21, 26]
	Time taken saving stuff: 15.06s
episode: 193/2000 -> reward: -124.99999999999159, steps:66720, time-taken: 3.74min, time-elasped: 534.28min
-> berries picked: 80 of 800 | patches-visited: [2] | positive-in-buffer: 11253 | amount-filled: 100.00%
	| epsilon: 0.42773019911681576
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [813, 1807, 847, 2770, 1417, 1649, 704, 1246]
	| approx positives in sample 512: 230
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 40, 13, 41, 20, 54, 20, 26]
	Time taken saving stuff: 0.09s
episode: 194/2000 -> reward: -124.99999999998695, steps:85824, time-taken: 4.61min, time-elasped: 538.90min
-> berries picked: 147 of 800 | patches-visited: [0, 7] | positive-in-buffer: 11350 | amount-filled: 100.00%
	| epsilon: 0.42738613497347633
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [831, 1828, 855, 2779, 1418, 1667, 708, 1264]
	| approx positives in sample 512: 205
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 34, 16, 41, 23, 25, 15, 30]
	Time taken saving stuff: 0.07s
episode: 195/2000 -> reward: -124.99999999998852, steps:71136, time-taken: 4.08min, time-elasped: 542.98min
-> berries picked: 85 of 800 | patches-visited: [0, 1] | positive-in-buffer: 11403 | amount-filled: 100.00%
	| epsilon: 0.4270423475937018
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [836, 1834, 858, 2778, 1424, 1678, 720, 1275]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 44, 12, 39, 20, 35, 18, 31]
	Time taken saving stuff: 12.94s
episode: 196/2000 -> reward: -124.99999999999183, steps:64992, time-taken: 2.92min, time-elasped: 546.11min
-> berries picked: 64 of 800 | patches-visited: [2] | positive-in-buffer: 11427 | amount-filled: 100.00%
	| epsilon: 0.4266988367548649
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [842, 1841, 862, 2771, 1422, 1684, 729, 1276]
	| approx positives in sample 512: 193
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 34, 17, 41, 26, 29, 13, 23]
	Time taken saving stuff: 0.03s
episode: 197/2000 -> reward: -124.99999999998889, steps:77760, time-taken: 4.60min, time-elasped: 550.71min
-> berries picked: 110 of 800 | patches-visited: [3, 7] | positive-in-buffer: 11503 | amount-filled: 100.00%
	| epsilon: 0.4263556022345174
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [851, 1852, 875, 2776, 1433, 1700, 734, 1282]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 37, 17, 47, 15, 50, 15, 25]
	Time taken saving stuff: 0.01s
episode: 198/2000 -> reward: -124.99999999998907, steps:73440, time-taken: 3.17min, time-elasped: 553.89min
-> berries picked: 104 of 800 | patches-visited: [4, 6] | positive-in-buffer: 11566 | amount-filled: 100.00%
	| epsilon: 0.42601264381039006
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [860, 1864, 883, 2780, 1441, 1715, 737, 1286]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 45, 24, 36, 23, 32, 12, 36]
	Time taken saving stuff: 18.86s
episode: 199/2000 -> reward: -124.9999999999921, steps:55872, time-taken: 2.17min, time-elasped: 556.38min
-> berries picked: 28 of 800 | patches-visited: [2] | positive-in-buffer: 11566 | amount-filled: 100.00%
	| epsilon: 0.4256699612603923
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [862, 1866, 884, 2772, 1436, 1719, 740, 1287]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 30, 17, 44, 30, 37, 18, 29]
	Time taken saving stuff: 0.09s
episode: 200/2000 -> reward: -124.99999999999288, steps:64320, time-taken: 2.43min, time-elasped: 558.81min
-> berries picked: 75 of 800 | patches-visited: [8] | positive-in-buffer: 11609 | amount-filled: 100.00%
	| epsilon: 0.4253275543626124
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [868, 1870, 896, 2773, 1438, 1731, 741, 1292]
	| approx positives in sample 512: 196
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 28, 15, 43, 18, 35, 16, 27]
	Time taken saving stuff: 0.02s
episode: 201/2000 -> reward: -124.99999999998921, steps:76512, time-taken: 3.53min, time-elasped: 562.34min
-> berries picked: 109 of 800 | patches-visited: [0, 2, 8] | positive-in-buffer: 11680 | amount-filled: 100.00%
	| epsilon: 0.4249854228953169
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [871, 1890, 902, 2773, 1445, 1752, 741, 1306]
	| approx positives in sample 512: 243
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 48, 19, 38, 28, 35, 15, 38]
	Time taken saving stuff: 12.32s
episode: 202/2000 -> reward: -124.99999999999027, steps:66048, time-taken: 3.12min, time-elasped: 565.67min
-> berries picked: 63 of 800 | patches-visited: [0, 5] | positive-in-buffer: 11708 | amount-filled: 100.00%
	| epsilon: 0.42464356663695085
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [874, 1900, 903, 2765, 1443, 1764, 742, 1317]
	| approx positives in sample 512: 235
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 40, 18, 37, 29, 39, 24, 23]
	Time taken saving stuff: 0.03s
episode: 203/2000 -> reward: -124.99999999998919, steps:71424, time-taken: 3.68min, time-elasped: 569.35min
-> berries picked: 92 of 800 | patches-visited: [0, 5] | positive-in-buffer: 11758 | amount-filled: 100.00%
	| epsilon: 0.42430198536613756
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [879, 1919, 905, 2760, 1447, 1778, 748, 1322]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 38, 18, 40, 28, 27, 21, 35]
	Time taken saving stuff: 0.01s
episode: 204/2000 -> reward: -124.99999999999089, steps:72096, time-taken: 3.74min, time-elasped: 573.10min
-> berries picked: 93 of 800 | patches-visited: [3, 5] | positive-in-buffer: 11800 | amount-filled: 100.00%
	| epsilon: 0.4239606788616783
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [886, 1929, 913, 2760, 1446, 1786, 749, 1331]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 38, 15, 47, 31, 28, 12, 38]
	Time taken saving stuff: 15.76s
episode: 205/2000 -> reward: -124.99999999999059, steps:65280, time-taken: 3.01min, time-elasped: 576.37min
-> berries picked: 63 of 800 | patches-visited: [1, 3] | positive-in-buffer: 11833 | amount-filled: 100.00%
	| epsilon: 0.4236196469025523
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [898, 1937, 917, 2749, 1452, 1796, 752, 1332]
	| approx positives in sample 512: 203
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 31, 16, 47, 23, 35, 18, 18]
	Time taken saving stuff: 0.03s
episode: 206/2000 -> reward: -124.99999999999179, steps:65856, time-taken: 2.84min, time-elasped: 579.22min
-> berries picked: 71 of 800 | patches-visited: [0] | positive-in-buffer: 11876 | amount-filled: 100.00%
	| epsilon: 0.4232788892679167
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [899, 1944, 922, 2746, 1455, 1815, 754, 1341]
	| approx positives in sample 512: 193
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 48, 12, 30, 25, 34, 9, 20]
	Time taken saving stuff: 0.01s
episode: 207/2000 -> reward: -124.99999999999321, steps:58080, time-taken: 2.72min, time-elasped: 581.94min
-> berries picked: 40 of 800 | patches-visited: [6] | positive-in-buffer: 11902 | amount-filled: 100.00%
	| epsilon: 0.42293840573710606
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [903, 1945, 925, 2752, 1461, 1818, 755, 1343]
	| approx positives in sample 512: 201
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 42, 22, 31, 22, 30, 16, 23]
	Time taken saving stuff: 13.22s
episode: 208/2000 -> reward: -124.99999999999305, steps:61248, time-taken: 2.81min, time-elasped: 584.98min
-> berries picked: 60 of 800 | patches-visited: [9] | positive-in-buffer: 11939 | amount-filled: 100.00%
	| epsilon: 0.42259819608963256
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [910, 1947, 927, 2760, 1466, 1822, 764, 1343]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 44, 12, 38, 15, 43, 21, 25]
	Time taken saving stuff: 0.03s
episode: 209/2000 -> reward: -124.99999999998911, steps:81600, time-taken: 4.32min, time-elasped: 589.30min
-> berries picked: 146 of 800 | patches-visited: [0, 2] | positive-in-buffer: 12038 | amount-filled: 100.00%
	| epsilon: 0.42225826010518586
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [925, 1956, 935, 2768, 1487, 1841, 769, 1357]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 34, 18, 33, 24, 45, 9, 31]
	Time taken saving stuff: 0.08s
episode: 210/2000 -> reward: -124.9999999999923, steps:82368, time-taken: 4.09min, time-elasped: 593.39min
-> berries picked: 138 of 800 | patches-visited: [3, 7, 8] | positive-in-buffer: 12114 | amount-filled: 100.00%
	| epsilon: 0.4219185975636326
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [936, 1966, 942, 2774, 1490, 1861, 774, 1371]
	| approx positives in sample 512: 197
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 41, 14, 39, 26, 34, 7, 22]
	Time taken saving stuff: 16.38s
episode: 211/2000 -> reward: -124.99999999998592, steps:78336, time-taken: 4.20min, time-elasped: 597.87min
-> berries picked: 118 of 800 | patches-visited: [2, 9] | positive-in-buffer: 12181 | amount-filled: 100.00%
	| epsilon: 0.4215792082450167
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [941, 1976, 951, 2766, 1505, 1878, 777, 1387]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 44, 19, 34, 18, 49, 17, 29]
	Time taken saving stuff: 0.01s
episode: 212/2000 -> reward: -124.99999999999247, steps:66240, time-taken: 3.78min, time-elasped: 601.65min
-> berries picked: 76 of 800 | patches-visited: [5] | positive-in-buffer: 12217 | amount-filled: 100.00%
	| epsilon: 0.42124009192955886
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [946, 1981, 951, 2769, 1512, 1890, 779, 1389]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 39, 21, 34, 21, 46, 15, 24]
	Time taken saving stuff: 0.01s
episode: 213/2000 -> reward: -124.99999999999362, steps:67104, time-taken: 3.65min, time-elasped: 605.30min
-> berries picked: 80 of 800 | patches-visited: [2] | positive-in-buffer: 12258 | amount-filled: 100.00%
	| epsilon: 0.4209012483976567
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [957, 1986, 957, 2765, 1519, 1899, 781, 1394]
	| approx positives in sample 512: 239
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 41, 27, 41, 26, 41, 16, 23]
	Time taken saving stuff: 16.22s
episode: 214/2000 -> reward: -124.99999999999145, steps:71136, time-taken: 4.17min, time-elasped: 609.75min
-> berries picked: 89 of 800 | patches-visited: [0, 9] | positive-in-buffer: 12311 | amount-filled: 100.00%
	| epsilon: 0.42056267742988435
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [964, 1993, 964, 2762, 1525, 1913, 790, 1400]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 42, 22, 42, 23, 36, 23, 17]
	Time taken saving stuff: 0.03s
episode: 215/2000 -> reward: -124.99999999998481, steps:85728, time-taken: 5.64min, time-elasped: 615.40min
-> berries picked: 153 of 800 | patches-visited: [2, 7] | positive-in-buffer: 12418 | amount-filled: 100.00%
	| epsilon: 0.42022437880699254
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [975, 2006, 980, 2769, 1538, 1937, 797, 1416]
	| approx positives in sample 512: 199
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 37, 18, 33, 20, 41, 12, 21]
	Time taken saving stuff: 0.19s
episode: 216/2000 -> reward: -124.99999999999254, steps:62784, time-taken: 3.53min, time-elasped: 618.93min
-> berries picked: 63 of 800 | patches-visited: [0] | positive-in-buffer: 12446 | amount-filled: 100.00%
	| epsilon: 0.41988635230990834
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [978, 2012, 985, 2763, 1547, 1942, 798, 1421]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 44, 14, 27, 20, 31, 15, 27]
	Time taken saving stuff: 15.46s
episode: 217/2000 -> reward: -124.9999999999921, steps:54048, time-taken: 2.26min, time-elasped: 621.45min
-> berries picked: 22 of 800 | patches-visited: [5] | positive-in-buffer: 12462 | amount-filled: 100.00%
	| epsilon: 0.4195485977197351
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [984, 2014, 987, 2763, 1546, 1947, 800, 1421]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 33, 20, 46, 27, 38, 20, 18]
	Time taken saving stuff: 0.01s
episode: 218/2000 -> reward: -124.99999999999184, steps:64608, time-taken: 2.57min, time-elasped: 624.02min
-> berries picked: 62 of 800 | patches-visited: [6, 7] | positive-in-buffer: 12503 | amount-filled: 100.00%
	| epsilon: 0.4192111148177521
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [995, 2017, 995, 2764, 1548, 1960, 800, 1424]
	| approx positives in sample 512: 193
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 34, 16, 29, 22, 26, 13, 29]
	Time taken saving stuff: 0.18s
episode: 219/2000 -> reward: -124.99999999999352, steps:62784, time-taken: 2.37min, time-elasped: 626.40min
-> berries picked: 53 of 800 | patches-visited: [1, 6] | positive-in-buffer: 12538 | amount-filled: 100.00%
	| epsilon: 0.4188739033854147
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [999, 2024, 995, 2766, 1551, 1967, 803, 1433]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 29, 18, 36, 24, 32, 15, 32]
	Time taken saving stuff: 15.38s
episode: 220/2000 -> reward: -124.99999999998911, steps:71808, time-taken: 3.18min, time-elasped: 629.84min
-> berries picked: 97 of 800 | patches-visited: [2, 6] | positive-in-buffer: 12607 | amount-filled: 100.00%
	| epsilon: 0.418536963204354
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1011, 2030, 1004, 2767, 1559, 1985, 809, 1442]
	| approx positives in sample 512: 244
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 46, 19, 28, 32, 51, 19, 35]
	Time taken saving stuff: 0.00s
episode: 221/2000 -> reward: -124.99999999999223, steps:65760, time-taken: 2.32min, time-elasped: 632.16min
-> berries picked: 65 of 800 | patches-visited: [4] | positive-in-buffer: 12626 | amount-filled: 100.00%
	| epsilon: 0.41820029405637676
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1018, 2039, 1009, 2755, 1557, 1988, 811, 1449]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 40, 18, 34, 26, 38, 9, 26]
	Time taken saving stuff: 0.10s
episode: 222/2000 -> reward: -124.99999999999018, steps:72480, time-taken: 3.38min, time-elasped: 635.55min
-> berries picked: 101 of 800 | patches-visited: [0, 4] | positive-in-buffer: 12701 | amount-filled: 100.00%
	| epsilon: 0.4178638957234653
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1032, 2049, 1018, 2762, 1568, 2001, 815, 1456]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 41, 25, 33, 30, 33, 17, 31]
	Time taken saving stuff: 15.11s
episode: 223/2000 -> reward: -124.99999999999274, steps:67008, time-taken: 3.01min, time-elasped: 638.81min
-> berries picked: 72 of 800 | patches-visited: [5] | positive-in-buffer: 12730 | amount-filled: 100.00%
	| epsilon: 0.41752776798777713
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1046, 2056, 1024, 2742, 1570, 2016, 815, 1461]
	| approx positives in sample 512: 256
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 46, 34, 36, 25, 40, 19, 33]
	Time taken saving stuff: 0.10s
episode: 224/2000 -> reward: -124.9999999999886, steps:83136, time-taken: 3.57min, time-elasped: 642.38min
-> berries picked: 138 of 800 | patches-visited: [4, 7] | positive-in-buffer: 12814 | amount-filled: 100.00%
	| epsilon: 0.41719191063164524
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1058, 2070, 1035, 2740, 1584, 2026, 825, 1476]
	| approx positives in sample 512: 208
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 36, 22, 33, 27, 42, 11, 26]
	Time taken saving stuff: 0.01s
episode: 225/2000 -> reward: -124.99999999998478, steps:86592, time-taken: 3.45min, time-elasped: 645.83min
-> berries picked: 145 of 800 | patches-visited: [2, 5] | positive-in-buffer: 12906 | amount-filled: 100.00%
	| epsilon: 0.41685632343757756
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1080, 2085, 1043, 2742, 1588, 2055, 828, 1485]
	| approx positives in sample 512: 207
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 37, 19, 34, 26, 37, 13, 24]
	Time taken saving stuff: 12.61s
episode: 226/2000 -> reward: -124.99999999998748, steps:84096, time-taken: 4.11min, time-elasped: 650.15min
-> berries picked: 133 of 800 | patches-visited: [0, 4, 5] | positive-in-buffer: 12990 | amount-filled: 100.00%
	| epsilon: 0.416521006188257
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1100, 2103, 1054, 2745, 1589, 2075, 832, 1492]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 46, 12, 32, 23, 35, 12, 25]
	Time taken saving stuff: 0.01s
episode: 227/2000 -> reward: -124.9999999999867, steps:82656, time-taken: 5.02min, time-elasped: 655.17min
-> berries picked: 135 of 800 | patches-visited: [2, 8] | positive-in-buffer: 13087 | amount-filled: 100.00%
	| epsilon: 0.41618595866654134
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1119, 2118, 1060, 2749, 1600, 2101, 839, 1501]
	| approx positives in sample 512: 207
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 47, 16, 29, 16, 34, 13, 28]
	Time taken saving stuff: 0.02s
episode: 228/2000 -> reward: -124.99999999998302, steps:83424, time-taken: 3.85min, time-elasped: 659.03min
-> berries picked: 130 of 800 | patches-visited: [4, 6, 9] | positive-in-buffer: 13161 | amount-filled: 100.00%
	| epsilon: 0.4158511806554629
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1130, 2135, 1069, 2759, 1597, 2116, 842, 1513]
	| approx positives in sample 512: 210
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 38, 19, 27, 20, 50, 13, 21]
	Time taken saving stuff: 15.47s
episode: 229/2000 -> reward: -124.99999999998903, steps:88896, time-taken: 4.32min, time-elasped: 663.61min
-> berries picked: 153 of 800 | patches-visited: [0, 5, 8] | positive-in-buffer: 13242 | amount-filled: 100.00%
	| epsilon: 0.41551667193822867
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1143, 2147, 1081, 2745, 1619, 2132, 849, 1526]
	| approx positives in sample 512: 236
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 38, 23, 46, 33, 40, 13, 21]
	Time taken saving stuff: 0.24s
episode: 230/2000 -> reward: -124.999999999987, steps:74112, time-taken: 3.20min, time-elasped: 666.81min
-> berries picked: 106 of 800 | patches-visited: [5, 8] | positive-in-buffer: 13305 | amount-filled: 100.00%
	| epsilon: 0.4151824322982199
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1153, 2158, 1088, 2742, 1633, 2144, 855, 1532]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 48, 21, 35, 24, 46, 15, 21]
	Time taken saving stuff: 0.03s
episode: 231/2000 -> reward: -124.99999999999244, steps:66528, time-taken: 3.11min, time-elasped: 669.93min
-> berries picked: 78 of 800 | patches-visited: [7] | positive-in-buffer: 13337 | amount-filled: 100.00%
	| epsilon: 0.4148484615189922
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1158, 2170, 1094, 2735, 1637, 2150, 856, 1537]
	| approx positives in sample 512: 253
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 37, 21, 44, 28, 48, 11, 36]
	Time taken saving stuff: 12.78s
episode: 232/2000 -> reward: -124.99999999999184, steps:66528, time-taken: 3.29min, time-elasped: 673.44min
-> berries picked: 76 of 800 | patches-visited: [0] | positive-in-buffer: 13367 | amount-filled: 100.00%
	| epsilon: 0.4145147593842752
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1166, 2186, 1095, 2728, 1637, 2155, 861, 1539]
	| approx positives in sample 512: 242
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 51, 18, 43, 29, 42, 19, 24]
	Time taken saving stuff: 0.01s
episode: 233/2000 -> reward: -124.99999999998708, steps:79872, time-taken: 3.39min, time-elasped: 676.83min
-> berries picked: 124 of 800 | patches-visited: [4, 8] | positive-in-buffer: 13439 | amount-filled: 100.00%
	| epsilon: 0.4141813256779725
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1183, 2203, 1108, 2723, 1645, 2169, 865, 1543]
	| approx positives in sample 512: 205
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 44, 16, 33, 17, 35, 15, 28]
	Time taken saving stuff: 0.01s
episode: 234/2000 -> reward: -124.99999999999247, steps:64992, time-taken: 2.68min, time-elasped: 679.52min
-> berries picked: 68 of 800 | patches-visited: [2] | positive-in-buffer: 13469 | amount-filled: 100.00%
	| epsilon: 0.4138481601841616
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1194, 2214, 1111, 2713, 1645, 2178, 867, 1547]
	| approx positives in sample 512: 189
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 38, 15, 29, 19, 36, 13, 21]
	Time taken saving stuff: 15.20s
episode: 235/2000 -> reward: -124.9999999999874, steps:76512, time-taken: 3.63min, time-elasped: 683.40min
-> berries picked: 99 of 800 | patches-visited: [3, 8] | positive-in-buffer: 13548 | amount-filled: 100.00%
	| epsilon: 0.41351526268709365
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1199, 2223, 1117, 2724, 1663, 2197, 872, 1553]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 52, 19, 25, 25, 34, 17, 32]
	Time taken saving stuff: 0.01s
episode: 236/2000 -> reward: -124.99999999999211, steps:65952, time-taken: 2.20min, time-elasped: 685.61min
-> berries picked: 71 of 800 | patches-visited: [1] | positive-in-buffer: 13576 | amount-filled: 100.00%
	| epsilon: 0.41318263297119334
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1200, 2237, 1121, 2715, 1660, 2210, 877, 1556]
	| approx positives in sample 512: 190
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 37, 20, 29, 18, 29, 12, 26]
	Time taken saving stuff: 0.01s
episode: 237/2000 -> reward: -124.999999999991, steps:78624, time-taken: 3.36min, time-elasped: 688.97min
-> berries picked: 116 of 800 | patches-visited: [2, 3, 5] | positive-in-buffer: 13667 | amount-filled: 100.00%
	| epsilon: 0.41285027082105874
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1219, 2255, 1123, 2735, 1669, 2227, 879, 1560]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 37, 13, 47, 18, 39, 13, 24]
	Time taken saving stuff: 12.25s
episode: 238/2000 -> reward: -124.99999999998828, steps:76992, time-taken: 3.26min, time-elasped: 692.43min
-> berries picked: 109 of 800 | patches-visited: [2, 7] | positive-in-buffer: 13728 | amount-filled: 100.00%
	| epsilon: 0.41251817602146124
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1232, 2281, 1129, 2723, 1672, 2240, 887, 1564]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 47, 15, 36, 17, 34, 12, 28]
	Time taken saving stuff: 0.01s
episode: 239/2000 -> reward: -124.99999999998784, steps:75648, time-taken: 3.24min, time-elasped: 695.68min
-> berries picked: 98 of 800 | patches-visited: [5, 9] | positive-in-buffer: 13790 | amount-filled: 100.00%
	| epsilon: 0.4121863483573453
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1236, 2299, 1132, 2721, 1682, 2261, 890, 1569]
	| approx positives in sample 512: 242
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 51, 17, 45, 18, 44, 16, 29]
	Time taken saving stuff: 0.10s
episode: 240/2000 -> reward: -124.99999999999201, steps:60768, time-taken: 2.12min, time-elasped: 697.80min
-> berries picked: 47 of 800 | patches-visited: [3] | positive-in-buffer: 13809 | amount-filled: 100.00%
	| epsilon: 0.41185478761382843
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1239, 2305, 1133, 2722, 1680, 2264, 894, 1572]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 38, 10, 32, 27, 37, 14, 28]
	Time taken saving stuff: 15.20s
episode: 241/2000 -> reward: -124.99999999998903, steps:69792, time-taken: 3.17min, time-elasped: 701.22min
-> berries picked: 82 of 800 | patches-visited: [4, 7] | positive-in-buffer: 13850 | amount-filled: 100.00%
	| epsilon: 0.411523493576201
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1248, 2313, 1141, 2710, 1683, 2278, 898, 1579]
	| approx positives in sample 512: 244
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 34, 24, 37, 33, 37, 20, 30]
	Time taken saving stuff: 0.11s
episode: 242/2000 -> reward: -124.9999999999879, steps:79872, time-taken: 3.49min, time-elasped: 704.71min
-> berries picked: 123 of 800 | patches-visited: [2, 3, 8] | positive-in-buffer: 13916 | amount-filled: 100.00%
	| epsilon: 0.41119246602992604
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1253, 2332, 1145, 2707, 1694, 2293, 905, 1587]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 41, 15, 25, 28, 36, 17, 27]
	Time taken saving stuff: 0.03s
episode: 243/2000 -> reward: -124.99999999998545, steps:76320, time-taken: 3.17min, time-elasped: 707.88min
-> berries picked: 109 of 800 | patches-visited: [4, 6] | positive-in-buffer: 13985 | amount-filled: 100.00%
	| epsilon: 0.4108617047606391
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1265, 2354, 1148, 2694, 1705, 2308, 910, 1601]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 43, 22, 36, 15, 35, 19, 28]
	Time taken saving stuff: 11.78s
episode: 244/2000 -> reward: -124.999999999992, steps:64416, time-taken: 2.43min, time-elasped: 710.51min
-> berries picked: 73 of 800 | patches-visited: [4] | positive-in-buffer: 14019 | amount-filled: 100.00%
	| epsilon: 0.41053120955414835
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1269, 2360, 1150, 2691, 1706, 2326, 912, 1605]
	| approx positives in sample 512: 199
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 31, 21, 35, 23, 25, 20, 31]
	Time taken saving stuff: 0.01s
episode: 245/2000 -> reward: -124.99999999998703, steps:79392, time-taken: 3.10min, time-elasped: 713.62min
-> berries picked: 130 of 800 | patches-visited: [3, 9] | positive-in-buffer: 14103 | amount-filled: 100.00%
	| epsilon: 0.4102009801964341
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1280, 2374, 1154, 2693, 1718, 2347, 917, 1620]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 34, 20, 48, 28, 38, 15, 23]
	Time taken saving stuff: 0.03s
episode: 246/2000 -> reward: -124.99999999999216, steps:64416, time-taken: 2.34min, time-elasped: 715.96min
-> berries picked: 69 of 800 | patches-visited: [5] | positive-in-buffer: 14128 | amount-filled: 100.00%
	| epsilon: 0.40987101647364876
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1284, 2384, 1154, 2692, 1716, 2357, 921, 1620]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 46, 17, 25, 18, 36, 15, 34]
	Time taken saving stuff: 15.59s
episode: 247/2000 -> reward: -124.99999999998633, steps:81696, time-taken: 2.98min, time-elasped: 719.20min
-> berries picked: 134 of 800 | patches-visited: [5, 6] | positive-in-buffer: 14225 | amount-filled: 100.00%
	| epsilon: 0.409541318172117
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1291, 2406, 1164, 2693, 1727, 2385, 924, 1635]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 42, 21, 34, 21, 47, 10, 24]
	Time taken saving stuff: 0.09s
episode: 248/2000 -> reward: -124.99999999999196, steps:64512, time-taken: 2.26min, time-elasped: 721.47min
-> berries picked: 65 of 800 | patches-visited: [6] | positive-in-buffer: 14225 | amount-filled: 100.00%
	| epsilon: 0.4092118850783351
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1299, 2417, 1167, 2669, 1724, 2384, 929, 1636]
	| approx positives in sample 512: 207
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 38, 16, 30, 17, 33, 20, 33]
	Time taken saving stuff: 0.01s
episode: 249/2000 -> reward: -124.999999999986, steps:82752, time-taken: 3.39min, time-elasped: 724.85min
-> berries picked: 134 of 800 | patches-visited: [2, 8] | positive-in-buffer: 14311 | amount-filled: 100.00%
	| epsilon: 0.4088827169789713
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1311, 2441, 1173, 2675, 1723, 2409, 935, 1644]
	| approx positives in sample 512: 226
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 36, 19, 31, 21, 45, 24, 34]
	Time taken saving stuff: 12.86s
episode: 250/2000 -> reward: -124.99999999999122, steps:60480, time-taken: 2.22min, time-elasped: 727.29min
-> berries picked: 42 of 800 | patches-visited: [0] | positive-in-buffer: 14343 | amount-filled: 100.00%
	| epsilon: 0.40855381366086524
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1313, 2451, 1173, 2680, 1727, 2414, 937, 1648]
	| approx positives in sample 512: 239
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 47, 23, 31, 29, 40, 20, 27]
	Time taken saving stuff: 0.01s
episode: 251/2000 -> reward: -124.99999999998712, steps:77760, time-taken: 3.23min, time-elasped: 730.52min
-> berries picked: 118 of 800 | patches-visited: [5, 7] | positive-in-buffer: 14408 | amount-filled: 100.00%
	| epsilon: 0.4082251749110282
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1323, 2466, 1179, 2671, 1732, 2430, 942, 1665]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 55, 19, 22, 17, 52, 18, 29]
	Time taken saving stuff: 0.10s
episode: 252/2000 -> reward: -124.99999999999201, steps:61536, time-taken: 2.18min, time-elasped: 732.71min
-> berries picked: 63 of 800 | patches-visited: [4] | positive-in-buffer: 14422 | amount-filled: 100.00%
	| epsilon: 0.4078968005166428
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1329, 2470, 1179, 2656, 1728, 2444, 947, 1669]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 31, 21, 26, 24, 47, 11, 28]
	Time taken saving stuff: 15.38s
episode: 253/2000 -> reward: -124.99999999999154, steps:59232, time-taken: 2.13min, time-elasped: 735.09min
-> berries picked: 39 of 800 | patches-visited: [0] | positive-in-buffer: 14435 | amount-filled: 100.00%
	| epsilon: 0.4075686902650626
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1335, 2475, 1180, 2646, 1733, 2450, 946, 1670]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 47, 17, 41, 25, 27, 13, 25]
	Time taken saving stuff: 0.02s
episode: 254/2000 -> reward: -124.99999999998579, steps:80544, time-taken: 3.40min, time-elasped: 738.49min
-> berries picked: 124 of 800 | patches-visited: [2, 7, 8, 9] | positive-in-buffer: 14503 | amount-filled: 100.00%
	| epsilon: 0.4072408439438125
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1345, 2494, 1188, 2635, 1733, 2469, 953, 1686]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 47, 20, 31, 20, 30, 21, 28]
	Time taken saving stuff: 0.01s
episode: 255/2000 -> reward: -124.99999999999153, steps:65280, time-taken: 2.29min, time-elasped: 740.79min
-> berries picked: 61 of 800 | patches-visited: [2] | positive-in-buffer: 14536 | amount-filled: 100.00%
	| epsilon: 0.40691326134058814
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1348, 2509, 1189, 2625, 1737, 2477, 958, 1693]
	| approx positives in sample 512: 194
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 32, 11, 24, 19, 48, 12, 27]
	Time taken saving stuff: 12.31s
episode: 256/2000 -> reward: -124.99999999998488, steps:79488, time-taken: 3.33min, time-elasped: 744.32min
-> berries picked: 126 of 800 | patches-visited: [1, 4] | positive-in-buffer: 14609 | amount-filled: 100.00%
	| epsilon: 0.406585942243256
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1371, 2524, 1195, 2628, 1733, 2488, 964, 1706]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 40, 16, 29, 24, 41, 13, 33]
	Time taken saving stuff: 0.01s
episode: 257/2000 -> reward: -124.99999999999292, steps:59616, time-taken: 2.17min, time-elasped: 746.50min
-> berries picked: 45 of 800 | patches-visited: [0] | positive-in-buffer: 14622 | amount-filled: 100.00%
	| epsilon: 0.40625888643985325
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1370, 2533, 1197, 2624, 1735, 2489, 965, 1709]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 51, 23, 23, 23, 40, 16, 27]
	Time taken saving stuff: 0.01s
episode: 258/2000 -> reward: -124.99999999999076, steps:57888, time-taken: 2.18min, time-elasped: 748.68min
-> berries picked: 35 of 800 | patches-visited: [5] | positive-in-buffer: 14624 | amount-filled: 100.00%
	| epsilon: 0.4059320937185874
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1372, 2537, 1200, 2613, 1735, 2491, 965, 1711]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 45, 27, 26, 20, 48, 11, 23]
	Time taken saving stuff: 15.09s
episode: 259/2000 -> reward: -124.99999999998526, steps:81792, time-taken: 3.29min, time-elasped: 752.23min
-> berries picked: 129 of 800 | patches-visited: [4, 5] | positive-in-buffer: 14719 | amount-filled: 100.00%
	| epsilon: 0.40560556386783647
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1389, 2560, 1205, 2616, 1744, 2515, 970, 1720]
	| approx positives in sample 512: 202
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 40, 19, 30, 20, 35, 15, 21]
	Time taken saving stuff: 0.03s
episode: 260/2000 -> reward: -124.99999999999112, steps:65664, time-taken: 2.37min, time-elasped: 754.60min
-> berries picked: 77 of 800 | patches-visited: [0] | positive-in-buffer: 14742 | amount-filled: 100.00%
	| epsilon: 0.4052792966761487
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1395, 2566, 1208, 2609, 1742, 2522, 974, 1726]
	| approx positives in sample 512: 234
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 48, 20, 33, 29, 39, 14, 24]
	Time taken saving stuff: 0.01s
episode: 261/2000 -> reward: -124.99999999999163, steps:57696, time-taken: 2.28min, time-elasped: 756.88min
-> berries picked: 30 of 800 | patches-visited: [7] | positive-in-buffer: 14745 | amount-filled: 100.00%
	| epsilon: 0.4049532919322424
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1397, 2571, 1210, 2600, 1741, 2522, 975, 1729]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 32, 21, 34, 25, 41, 22, 24]
	Time taken saving stuff: 12.24s
episode: 262/2000 -> reward: -124.99999999998793, steps:79776, time-taken: 3.26min, time-elasped: 760.34min
-> berries picked: 114 of 800 | patches-visited: [2, 7, 9] | positive-in-buffer: 14800 | amount-filled: 100.00%
	| epsilon: 0.40462754942500573
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1408, 2589, 1219, 2586, 1744, 2532, 986, 1736]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 44, 14, 33, 28, 35, 15, 36]
	Time taken saving stuff: 0.01s
episode: 263/2000 -> reward: -124.99999999999264, steps:59328, time-taken: 2.13min, time-elasped: 762.47min
-> berries picked: 36 of 800 | patches-visited: [9] | positive-in-buffer: 14813 | amount-filled: 100.00%
	| epsilon: 0.4043020689434968
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1412, 2594, 1221, 2575, 1747, 2536, 987, 1741]
	| approx positives in sample 512: 235
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 41, 17, 36, 28, 45, 21, 29]
	Time taken saving stuff: 0.04s
episode: 264/2000 -> reward: -124.99999999999216, steps:66048, time-taken: 3.06min, time-elasped: 765.53min
-> berries picked: 78 of 800 | patches-visited: [3] | positive-in-buffer: 14843 | amount-filled: 100.00%
	| epsilon: 0.40397685027694336
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1419, 2608, 1227, 2566, 1745, 2541, 992, 1745]
	| approx positives in sample 512: 246
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 45, 20, 32, 25, 46, 18, 33]
	Time taken saving stuff: 15.62s
episode: 265/2000 -> reward: -124.99999999999012, steps:76416, time-taken: 3.23min, time-elasped: 769.03min
-> berries picked: 112 of 800 | patches-visited: [0, 2] | positive-in-buffer: 14894 | amount-filled: 100.00%
	| epsilon: 0.4036518932147427
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1432, 2633, 1230, 2558, 1742, 2549, 997, 1753]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 49, 18, 31, 22, 46, 16, 32]
	Time taken saving stuff: 0.11s
episode: 266/2000 -> reward: -124.99999999999311, steps:67968, time-taken: 3.10min, time-elasped: 772.13min
-> berries picked: 79 of 800 | patches-visited: [8] | positive-in-buffer: 14928 | amount-filled: 100.00%
	| epsilon: 0.4033271975464615
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1446, 2644, 1234, 2552, 1741, 2556, 1000, 1755]
	| approx positives in sample 512: 237
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 49, 22, 37, 24, 42, 17, 23]
	Time taken saving stuff: 0.00s
episode: 267/2000 -> reward: -124.9999999999939, steps:63744, time-taken: 2.27min, time-elasped: 774.40min
-> berries picked: 62 of 800 | patches-visited: [8] | positive-in-buffer: 14945 | amount-filled: 100.00%
	| epsilon: 0.4030027630618358
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1455, 2648, 1239, 2534, 1745, 2561, 1002, 1761]
	| approx positives in sample 512: 205
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 45, 15, 33, 16, 34, 20, 23]
	Time taken saving stuff: 12.11s
episode: 268/2000 -> reward: -124.9999999999917, steps:63936, time-taken: 2.25min, time-elasped: 776.85min
-> berries picked: 69 of 800 | patches-visited: [4] | positive-in-buffer: 14983 | amount-filled: 100.00%
	| epsilon: 0.4026785895507707
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1460, 2661, 1240, 2536, 1748, 2567, 1009, 1762]
	| approx positives in sample 512: 207
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 47, 12, 34, 23, 33, 16, 24]
	Time taken saving stuff: 0.01s
episode: 269/2000 -> reward: -124.99999999998684, steps:77376, time-taken: 3.18min, time-elasped: 780.03min
-> berries picked: 102 of 800 | patches-visited: [1, 7] | positive-in-buffer: 15051 | amount-filled: 100.00%
	| epsilon: 0.4023546768033402
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1468, 2681, 1247, 2537, 1756, 2579, 1013, 1770]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 41, 12, 32, 17, 52, 13, 28]
	Time taken saving stuff: 0.03s
episode: 270/2000 -> reward: -124.9999999999929, steps:59808, time-taken: 2.21min, time-elasped: 782.24min
-> berries picked: 42 of 800 | patches-visited: [4, 6] | positive-in-buffer: 15073 | amount-filled: 100.00%
	| epsilon: 0.4020310246097873
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1473, 2691, 1251, 2532, 1751, 2582, 1018, 1775]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 42, 20, 26, 16, 25, 21, 38]
	Time taken saving stuff: 15.37s
episode: 271/2000 -> reward: -124.99999999999241, steps:62400, time-taken: 2.21min, time-elasped: 784.71min
-> berries picked: 58 of 800 | patches-visited: [3] | positive-in-buffer: 15090 | amount-filled: 100.00%
	| epsilon: 0.4017076327605238
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1478, 2696, 1257, 2522, 1751, 2583, 1022, 1781]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 33, 24, 29, 24, 37, 20, 26]
	Time taken saving stuff: 0.03s
episode: 272/2000 -> reward: -124.99999999998947, steps:70176, time-taken: 3.04min, time-elasped: 787.75min
-> berries picked: 91 of 800 | patches-visited: [2, 5] | positive-in-buffer: 15126 | amount-filled: 100.00%
	| epsilon: 0.4013845010461299
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1492, 2708, 1258, 2514, 1749, 2590, 1026, 1789]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 45, 15, 37, 20, 54, 10, 26]
	Time taken saving stuff: 0.00s
episode: 273/2000 -> reward: -124.99999999999186, steps:66048, time-taken: 2.94min, time-elasped: 790.69min
-> berries picked: 66 of 800 | patches-visited: [0, 4] | positive-in-buffer: 15159 | amount-filled: 100.00%
	| epsilon: 0.40106162925735434
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1502, 2722, 1260, 2514, 1745, 2594, 1029, 1793]
	| approx positives in sample 512: 249
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 57, 19, 30, 30, 40, 17, 30]
	Time taken saving stuff: 12.05s
episode: 274/2000 -> reward: -124.99999999998494, steps:81024, time-taken: 3.34min, time-elasped: 794.23min
-> berries picked: 130 of 800 | patches-visited: [6, 7, 9] | positive-in-buffer: 15237 | amount-filled: 100.00%
	| epsilon: 0.40073901718511423
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1516, 2735, 1268, 2514, 1757, 2610, 1032, 1805]
	| approx positives in sample 512: 235
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 37, 22, 32, 27, 40, 12, 38]
	Time taken saving stuff: 0.01s
episode: 275/2000 -> reward: -124.99999999999194, steps:53760, time-taken: 2.08min, time-elasped: 796.32min
-> berries picked: 21 of 800 | patches-visited: [0, 5] | positive-in-buffer: 15226 | amount-filled: 100.00%
	| epsilon: 0.4004166646204948
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1519, 2736, 1269, 2507, 1750, 2607, 1033, 1805]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 49, 11, 33, 23, 27, 14, 33]
	Time taken saving stuff: 0.11s
episode: 276/2000 -> reward: -124.99999999999183, steps:62208, time-taken: 2.35min, time-elasped: 798.67min
-> berries picked: 56 of 800 | patches-visited: [9] | positive-in-buffer: 15236 | amount-filled: 100.00%
	| epsilon: 0.40009457135474935
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1534, 2740, 1271, 2490, 1748, 2608, 1038, 1807]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 46, 20, 29, 18, 39, 16, 26]
	Time taken saving stuff: 15.21s
episode: 277/2000 -> reward: -124.9999999999915, steps:58752, time-taken: 2.23min, time-elasped: 801.16min
-> berries picked: 42 of 800 | patches-visited: [6] | positive-in-buffer: 15247 | amount-filled: 100.00%
	| epsilon: 0.3997727371792991
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1538, 2746, 1278, 2474, 1746, 2612, 1045, 1808]
	| approx positives in sample 512: 202
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 31, 19, 21, 32, 36, 12, 30]
	Time taken saving stuff: 0.11s
episode: 278/2000 -> reward: -124.99999999999243, steps:64512, time-taken: 2.21min, time-elasped: 803.38min
-> berries picked: 74 of 800 | patches-visited: [6] | positive-in-buffer: 15268 | amount-filled: 100.00%
	| epsilon: 0.39945116188573304
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1542, 2751, 1280, 2474, 1747, 2614, 1051, 1809]
	| approx positives in sample 512: 207
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 39, 16, 37, 18, 42, 22, 18]
	Time taken saving stuff: 0.01s
episode: 279/2000 -> reward: -124.99999999998766, steps:83520, time-taken: 3.44min, time-elasped: 806.82min
-> berries picked: 126 of 800 | patches-visited: [0, 2, 5, 7] | positive-in-buffer: 15360 | amount-filled: 100.00%
	| epsilon: 0.39912984526580786
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1564, 2761, 1290, 2478, 1746, 2639, 1065, 1817]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 31, 17, 29, 23, 42, 17, 34]
	Time taken saving stuff: 12.65s
episode: 280/2000 -> reward: -124.99999999998903, steps:73344, time-taken: 3.21min, time-elasped: 810.25min
-> berries picked: 97 of 800 | patches-visited: [1, 6] | positive-in-buffer: 15419 | amount-filled: 100.00%
	| epsilon: 0.3988087871114476
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1578, 2771, 1294, 2477, 1750, 2656, 1071, 1822]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 44, 17, 30, 23, 42, 14, 25]
	Time taken saving stuff: 0.00s
episode: 281/2000 -> reward: -124.99999999999308, steps:72192, time-taken: 3.16min, time-elasped: 813.41min
-> berries picked: 89 of 800 | patches-visited: [1, 7] | positive-in-buffer: 15455 | amount-filled: 100.00%
	| epsilon: 0.3984879872147439
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1592, 2786, 1295, 2468, 1752, 2656, 1077, 1829]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 48, 20, 28, 24, 34, 14, 34]
	Time taken saving stuff: 0.03s
episode: 282/2000 -> reward: -124.99999999998496, steps:73344, time-taken: 3.35min, time-elasped: 816.76min
-> berries picked: 96 of 800 | patches-visited: [5, 9] | positive-in-buffer: 15493 | amount-filled: 100.00%
	| epsilon: 0.3981674453679554
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1596, 2799, 1298, 2464, 1758, 2661, 1085, 1832]
	| approx positives in sample 512: 241
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 55, 24, 34, 20, 36, 17, 36]
	Time taken saving stuff: 15.29s
episode: 283/2000 -> reward: -124.99999999999028, steps:66240, time-taken: 3.20min, time-elasped: 820.21min
-> berries picked: 72 of 800 | patches-visited: [3] | positive-in-buffer: 15525 | amount-filled: 100.00%
	| epsilon: 0.3978471613635081
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1601, 2808, 1303, 2453, 1756, 2675, 1089, 1840]
	| approx positives in sample 512: 246
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 46, 26, 31, 24, 48, 19, 34]
	Time taken saving stuff: 0.02s
episode: 284/2000 -> reward: -124.99999999998857, steps:73632, time-taken: 3.24min, time-elasped: 823.45min
-> berries picked: 97 of 800 | patches-visited: [4, 8] | positive-in-buffer: 15556 | amount-filled: 100.00%
	| epsilon: 0.3975271349939948
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1619, 2813, 1307, 2446, 1751, 2680, 1093, 1847]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 43, 14, 27, 25, 44, 18, 31]
	Time taken saving stuff: 0.01s
episode: 285/2000 -> reward: -124.9999999999886, steps:68832, time-taken: 3.11min, time-elasped: 826.57min
-> berries picked: 78 of 800 | patches-visited: [1, 5] | positive-in-buffer: 15579 | amount-filled: 100.00%
	| epsilon: 0.39720736605217516
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1631, 2818, 1314, 2430, 1747, 2691, 1095, 1853]
	| approx positives in sample 512: 239
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 43, 19, 21, 26, 50, 19, 31]
	Time taken saving stuff: 11.95s
episode: 286/2000 -> reward: -124.99999999999203, steps:52512, time-taken: 2.01min, time-elasped: 828.78min
-> berries picked: 12 of 800 | patches-visited: [0] | positive-in-buffer: 15573 | amount-filled: 100.00%
	| epsilon: 0.39688785433097556
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1633, 2819, 1313, 2422, 1743, 2692, 1095, 1856]
	| approx positives in sample 512: 244
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 42, 28, 36, 18, 45, 22, 31]
	Time taken saving stuff: 0.00s
episode: 287/2000 -> reward: -124.9999999999921, steps:65760, time-taken: 2.21min, time-elasped: 830.99min
-> berries picked: 66 of 800 | patches-visited: [5] | positive-in-buffer: 15570 | amount-filled: 100.00%
	| epsilon: 0.396568599623489
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1643, 2830, 1307, 2410, 1732, 2691, 1096, 1861]
	| approx positives in sample 512: 203
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 41, 20, 28, 22, 34, 13, 27]
	Time taken saving stuff: 0.10s
episode: 288/2000 -> reward: -124.99999999998826, steps:74688, time-taken: 3.15min, time-elasped: 834.15min
-> berries picked: 99 of 800 | patches-visited: [2, 4] | positive-in-buffer: 15646 | amount-filled: 100.00%
	| epsilon: 0.3962496017229748
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1653, 2845, 1313, 2416, 1746, 2699, 1110, 1864]
	| approx positives in sample 512: 243
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 59, 15, 25, 28, 42, 11, 32]
	Time taken saving stuff: 15.24s
episode: 289/2000 -> reward: -124.99999999998856, steps:78912, time-taken: 3.31min, time-elasped: 837.71min
-> berries picked: 126 of 800 | patches-visited: [8, 9] | positive-in-buffer: 15722 | amount-filled: 100.00%
	| epsilon: 0.39593086042285874
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1670, 2866, 1318, 2420, 1748, 2711, 1120, 1869]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 45, 12, 25, 31, 37, 16, 29]
	Time taken saving stuff: 0.11s
episode: 290/2000 -> reward: -124.9999999999917, steps:54720, time-taken: 2.03min, time-elasped: 839.75min
-> berries picked: 27 of 800 | patches-visited: [2] | positive-in-buffer: 15715 | amount-filled: 100.00%
	| epsilon: 0.39561237551673256
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1674, 2864, 1319, 2407, 1746, 2710, 1121, 1874]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 36, 22, 27, 17, 31, 22, 30]
	Time taken saving stuff: 0.01s
episode: 291/2000 -> reward: -124.99999999999237, steps:64416, time-taken: 2.27min, time-elasped: 842.03min
-> berries picked: 63 of 800 | patches-visited: [5] | positive-in-buffer: 15715 | amount-filled: 100.00%
	| epsilon: 0.3952941467983543
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1680, 2859, 1318, 2400, 1740, 2712, 1127, 1879]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 41, 18, 24, 22, 37, 15, 32]
	Time taken saving stuff: 11.82s
episode: 292/2000 -> reward: -124.99999999999243, steps:61056, time-taken: 2.36min, time-elasped: 844.59min
-> berries picked: 49 of 800 | patches-visited: [1, 8] | positive-in-buffer: 15702 | amount-filled: 100.00%
	| epsilon: 0.3949761740616476
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1684, 2860, 1316, 2395, 1725, 2706, 1135, 1881]
	| approx positives in sample 512: 206
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 46, 20, 30, 18, 30, 18, 27]
	Time taken saving stuff: 0.01s
episode: 293/2000 -> reward: -124.99999999999146, steps:72288, time-taken: 3.17min, time-elasped: 847.76min
-> berries picked: 89 of 800 | patches-visited: [2, 7, 8] | positive-in-buffer: 15766 | amount-filled: 100.00%
	| epsilon: 0.3946584571007021
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1690, 2877, 1317, 2400, 1732, 2723, 1140, 1887]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 39, 19, 30, 17, 51, 17, 35]
	Time taken saving stuff: 0.24s
episode: 294/2000 -> reward: -124.99999999998538, steps:88896, time-taken: 4.12min, time-elasped: 851.89min
-> berries picked: 159 of 800 | patches-visited: [1, 2, 4] | positive-in-buffer: 15876 | amount-filled: 100.00%
	| epsilon: 0.394340995709773
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1711, 2902, 1321, 2403, 1739, 2741, 1155, 1904]
	| approx positives in sample 512: 240
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 45, 18, 34, 22, 43, 21, 31]
	Time taken saving stuff: 15.31s
episode: 295/2000 -> reward: -124.99999999998504, steps:79488, time-taken: 3.38min, time-elasped: 855.53min
-> berries picked: 113 of 800 | patches-visited: [1, 5, 7] | positive-in-buffer: 15933 | amount-filled: 100.00%
	| epsilon: 0.3940237896832809
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1723, 2915, 1325, 2398, 1740, 2749, 1166, 1917]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 46, 20, 19, 25, 39, 23, 24]
	Time taken saving stuff: 0.10s
episode: 296/2000 -> reward: -124.99999999999206, steps:55968, time-taken: 2.06min, time-elasped: 857.59min
-> berries picked: 28 of 800 | patches-visited: [4] | positive-in-buffer: 15925 | amount-filled: 100.00%
	| epsilon: 0.393706838815812
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1724, 2916, 1325, 2394, 1731, 2747, 1169, 1919]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 44, 18, 36, 22, 37, 19, 26]
	Time taken saving stuff: 0.01s
episode: 297/2000 -> reward: -124.9999999999929, steps:75936, time-taken: 3.27min, time-elasped: 860.86min
-> berries picked: 105 of 800 | patches-visited: [2, 8] | positive-in-buffer: 15940 | amount-filled: 100.00%
	| epsilon: 0.39339014290211743
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1725, 2921, 1330, 2378, 1725, 2761, 1169, 1931]
	| approx positives in sample 512: 240
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 55, 13, 24, 18, 41, 21, 35]
	Time taken saving stuff: 12.61s
episode: 298/2000 -> reward: -124.99999999998967, steps:71232, time-taken: 3.25min, time-elasped: 864.32min
-> berries picked: 95 of 800 | patches-visited: [6, 9] | positive-in-buffer: 15975 | amount-filled: 100.00%
	| epsilon: 0.3930737017371137
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1727, 2930, 1330, 2378, 1728, 2774, 1171, 1937]
	| approx positives in sample 512: 240
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 47, 21, 31, 27, 36, 17, 27]
	Time taken saving stuff: 0.01s
episode: 299/2000 -> reward: -124.99999999998826, steps:66528, time-taken: 3.05min, time-elasped: 867.37min
-> berries picked: 68 of 800 | patches-visited: [0, 1] | positive-in-buffer: 15999 | amount-filled: 100.00%
	| epsilon: 0.3927575151158822
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1738, 2919, 1336, 2379, 1727, 2779, 1177, 1944]
	| approx positives in sample 512: 235
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 45, 14, 35, 20, 38, 16, 38]
	Time taken saving stuff: 0.09s
episode: 300/2000 -> reward: -124.99999999999118, steps:70752, time-taken: 3.30min, time-elasped: 870.68min
-> berries picked: 80 of 800 | patches-visited: [3, 8] | positive-in-buffer: 16029 | amount-filled: 100.00%
	| epsilon: 0.39244158283366903
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1740, 2927, 1341, 2377, 1719, 2794, 1182, 1949]
	| approx positives in sample 512: 250
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 57, 15, 31, 25, 41, 20, 30]
	Time taken saving stuff: 15.60s
episode: 301/2000 -> reward: -124.9999999999883, steps:75936, time-taken: 3.23min, time-elasped: 874.17min
-> berries picked: 114 of 800 | patches-visited: [7, 8] | positive-in-buffer: 16060 | amount-filled: 100.00%
	| epsilon: 0.3921259046858851
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1747, 2930, 1346, 2370, 1719, 2802, 1187, 1959]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 41, 27, 24, 26, 48, 13, 27]
	Time taken saving stuff: 0.10s
episode: 302/2000 -> reward: -124.99999999998825, steps:74880, time-taken: 3.22min, time-elasped: 877.40min
-> berries picked: 97 of 800 | patches-visited: [0, 1, 9] | positive-in-buffer: 16074 | amount-filled: 100.00%
	| epsilon: 0.39181048046810596
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1754, 2923, 1348, 2351, 1719, 2812, 1201, 1966]
	| approx positives in sample 512: 255
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 32, 24, 35, 17, 65, 25, 32]
	Time taken saving stuff: 0.01s
episode: 303/2000 -> reward: -124.9999999999918, steps:60480, time-taken: 2.30min, time-elasped: 879.70min
-> berries picked: 44 of 800 | patches-visited: [8] | positive-in-buffer: 16098 | amount-filled: 100.00%
	| epsilon: 0.3914953099760714
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1759, 2922, 1353, 2351, 1724, 2815, 1204, 1970]
	| approx positives in sample 512: 197
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 40, 16, 22, 15, 36, 17, 26]
	Time taken saving stuff: 11.85s
episode: 304/2000 -> reward: -124.9999999999929, steps:69024, time-taken: 3.01min, time-elasped: 882.91min
-> berries picked: 78 of 800 | patches-visited: [1, 3] | positive-in-buffer: 16053 | amount-filled: 100.00%
	| epsilon: 0.39118039300568574
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1755, 2899, 1348, 2341, 1724, 2811, 1207, 1968]
	| approx positives in sample 512: 237
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 35, 35, 30, 14, 37, 24, 36]
	Time taken saving stuff: 0.00s
episode: 305/2000 -> reward: -124.99999999999167, steps:60960, time-taken: 2.08min, time-elasped: 884.99min
-> berries picked: 47 of 800 | patches-visited: [5] | positive-in-buffer: 16071 | amount-filled: 100.00%
	| epsilon: 0.39086572935301733
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1756, 2903, 1349, 2342, 1723, 2816, 1209, 1973]
	| approx positives in sample 512: 207
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 30, 29, 34, 16, 30, 16, 22]
	Time taken saving stuff: 0.11s
episode: 306/2000 -> reward: -124.99999999998884, steps:71520, time-taken: 3.17min, time-elasped: 888.16min
-> berries picked: 87 of 800 | patches-visited: [1, 3, 8] | positive-in-buffer: 16107 | amount-filled: 100.00%
	| epsilon: 0.3905513188142986
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1765, 2894, 1356, 2347, 1721, 2824, 1217, 1983]
	| approx positives in sample 512: 239
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 45, 21, 24, 19, 42, 18, 39]
	Time taken saving stuff: 15.43s
episode: 307/2000 -> reward: -124.99999999998369, steps:82080, time-taken: 3.47min, time-elasped: 891.90min
-> berries picked: 121 of 800 | patches-visited: [1, 2, 8, 9] | positive-in-buffer: 16155 | amount-filled: 100.00%
	| epsilon: 0.3902371611859259
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1783, 2900, 1364, 2330, 1720, 2838, 1222, 1998]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 49, 21, 16, 19, 43, 22, 18]
	Time taken saving stuff: 0.03s
episode: 308/2000 -> reward: -124.9999999999919, steps:56256, time-taken: 2.17min, time-elasped: 894.06min
-> berries picked: 28 of 800 | patches-visited: [3, 9] | positive-in-buffer: 16154 | amount-filled: 100.00%
	| epsilon: 0.3899232562644593
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1782, 2899, 1363, 2323, 1719, 2842, 1226, 2000]
	| approx positives in sample 512: 203
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 35, 14, 31, 13, 37, 15, 26]
	Time taken saving stuff: 0.01s
episode: 309/2000 -> reward: -124.999999999994, steps:58752, time-taken: 2.16min, time-elasped: 896.22min
-> berries picked: 41 of 800 | patches-visited: [6] | positive-in-buffer: 16120 | amount-filled: 100.00%
	| epsilon: 0.38960960384662263
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1790, 2875, 1362, 2308, 1713, 2839, 1232, 2001]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 42, 23, 19, 25, 41, 16, 30]
	Time taken saving stuff: 12.00s
episode: 310/2000 -> reward: -124.99999999999143, steps:70080, time-taken: 3.11min, time-elasped: 899.53min
-> berries picked: 73 of 800 | patches-visited: [1, 2, 4, 6] | positive-in-buffer: 16148 | amount-filled: 100.00%
	| epsilon: 0.3892962037293031
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1792, 2874, 1366, 2305, 1712, 2845, 1236, 2018]
	| approx positives in sample 512: 240
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 44, 19, 29, 19, 41, 24, 36]
	Time taken saving stuff: 0.01s
episode: 311/2000 -> reward: -124.99999999999186, steps:56928, time-taken: 2.09min, time-elasped: 901.62min
-> berries picked: 32 of 800 | patches-visited: [4] | positive-in-buffer: 16130 | amount-filled: 100.00%
	| epsilon: 0.38898305570955144
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1793, 2868, 1366, 2298, 1702, 2847, 1238, 2018]
	| approx positives in sample 512: 233
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 40, 14, 20, 21, 54, 21, 38]
	Time taken saving stuff: 0.01s
episode: 312/2000 -> reward: -124.99999999999174, steps:64512, time-taken: 2.18min, time-elasped: 903.80min
-> berries picked: 58 of 800 | patches-visited: [5] | positive-in-buffer: 16095 | amount-filled: 100.00%
	| epsilon: 0.3886701595845815
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1785, 2840, 1365, 2288, 1699, 2855, 1243, 2020]
	| approx positives in sample 512: 226
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 48, 13, 27, 22, 41, 19, 25]
	Time taken saving stuff: 15.11s
episode: 313/2000 -> reward: -124.99999999999234, steps:67008, time-taken: 3.10min, time-elasped: 907.16min
-> berries picked: 71 of 800 | patches-visited: [1, 9] | positive-in-buffer: 16125 | amount-filled: 100.00%
	| epsilon: 0.38835751515177036
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1794, 2842, 1367, 2284, 1701, 2860, 1253, 2024]
	| approx positives in sample 512: 240
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 42, 19, 25, 14, 56, 21, 37]
	Time taken saving stuff: 0.03s
episode: 314/2000 -> reward: -124.99999999999201, steps:55488, time-taken: 2.00min, time-elasped: 909.16min
-> berries picked: 24 of 800 | patches-visited: [4] | positive-in-buffer: 16147 | amount-filled: 100.00%
	| epsilon: 0.38804512220865806
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1799, 2843, 1370, 2288, 1702, 2862, 1255, 2028]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 38, 18, 25, 14, 41, 25, 41]
	Time taken saving stuff: 0.00s
episode: 315/2000 -> reward: -124.99999999999162, steps:67104, time-taken: 3.07min, time-elasped: 912.24min
-> berries picked: 65 of 800 | patches-visited: [0, 2] | positive-in-buffer: 16179 | amount-filled: 100.00%
	| epsilon: 0.3877329805529474
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1807, 2847, 1373, 2294, 1698, 2866, 1262, 2032]
	| approx positives in sample 512: 258
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 38, 24, 26, 20, 50, 28, 37]
	Time taken saving stuff: 12.09s
episode: 316/2000 -> reward: -124.99999999999005, steps:72192, time-taken: 3.23min, time-elasped: 915.67min
-> berries picked: 99 of 800 | patches-visited: [6, 7] | positive-in-buffer: 16203 | amount-filled: 100.00%
	| epsilon: 0.387421089982504
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1810, 2849, 1379, 2293, 1691, 2872, 1267, 2042]
	| approx positives in sample 512: 251
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 42, 22, 30, 24, 45, 18, 37]
	Time taken saving stuff: 0.00s
episode: 317/2000 -> reward: -124.99999999998538, steps:90624, time-taken: 4.45min, time-elasped: 920.12min
-> berries picked: 146 of 800 | patches-visited: [0, 4, 6, 8] | positive-in-buffer: 16274 | amount-filled: 100.00%
	| epsilon: 0.3871094502953562
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1828, 2862, 1394, 2287, 1686, 2886, 1275, 2056]
	| approx positives in sample 512: 245
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 41, 20, 33, 20, 44, 18, 42]
	Time taken saving stuff: 0.09s
episode: 318/2000 -> reward: -124.99999999999143, steps:54720, time-taken: 2.20min, time-elasped: 922.33min
-> berries picked: 23 of 800 | patches-visited: [2] | positive-in-buffer: 16259 | amount-filled: 100.00%
	| epsilon: 0.38679806128969446
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1831, 2855, 1395, 2277, 1680, 2888, 1276, 2057]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 36, 15, 20, 21, 46, 20, 33]
	Time taken saving stuff: 15.22s
episode: 319/2000 -> reward: -124.99999999999042, steps:73344, time-taken: 3.23min, time-elasped: 925.81min
-> berries picked: 100 of 800 | patches-visited: [6, 8] | positive-in-buffer: 16256 | amount-filled: 100.00%
	| epsilon: 0.3864869227638719
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1842, 2856, 1397, 2258, 1670, 2889, 1281, 2063]
	| approx positives in sample 512: 264
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 40, 25, 30, 26, 57, 25, 32]
	Time taken saving stuff: 0.10s
episode: 320/2000 -> reward: -124.99999999998556, steps:78912, time-taken: 3.33min, time-elasped: 929.14min
-> berries picked: 116 of 800 | patches-visited: [2, 9] | positive-in-buffer: 16291 | amount-filled: 100.00%
	| epsilon: 0.3861760345164037
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1840, 2863, 1400, 2271, 1664, 2900, 1284, 2069]
	| approx positives in sample 512: 234
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 48, 18, 28, 19, 43, 22, 28]
	Time taken saving stuff: 0.01s
episode: 321/2000 -> reward: -124.99999999999153, steps:66912, time-taken: 3.27min, time-elasped: 932.42min
-> berries picked: 74 of 800 | patches-visited: [0, 3] | positive-in-buffer: 16281 | amount-filled: 100.00%
	| epsilon: 0.38586539634596717
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1844, 2858, 1407, 2258, 1657, 2905, 1284, 2068]
	| approx positives in sample 512: 264
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 39, 24, 31, 26, 56, 25, 41]
	Time taken saving stuff: 12.95s
episode: 322/2000 -> reward: -124.99999999998894, steps:70272, time-taken: 3.69min, time-elasped: 936.33min
-> berries picked: 86 of 800 | patches-visited: [4, 5] | positive-in-buffer: 16322 | amount-filled: 100.00%
	| epsilon: 0.38555500805140147
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1855, 2862, 1415, 2259, 1653, 2924, 1285, 2069]
	| approx positives in sample 512: 248
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 43, 16, 35, 28, 58, 24, 22]
	Time taken saving stuff: 0.03s
episode: 323/2000 -> reward: -124.9999999999889, steps:78144, time-taken: 3.88min, time-elasped: 940.21min
-> berries picked: 113 of 800 | patches-visited: [1, 4, 8] | positive-in-buffer: 16386 | amount-filled: 100.00%
	| epsilon: 0.3852448694317077
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1864, 2879, 1421, 2268, 1651, 2938, 1292, 2073]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 32, 24, 32, 19, 49, 19, 19]
	Time taken saving stuff: 0.09s
episode: 324/2000 -> reward: -124.99999999999105, steps:70368, time-taken: 3.67min, time-elasped: 943.89min
-> berries picked: 81 of 800 | patches-visited: [0, 3, 7] | positive-in-buffer: 16383 | amount-filled: 100.00%
	| epsilon: 0.38493498028604856
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1864, 2887, 1417, 2249, 1649, 2939, 1299, 2079]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 40, 18, 21, 23, 43, 12, 44]
	Time taken saving stuff: 16.41s
episode: 325/2000 -> reward: -124.99999999999208, steps:59904, time-taken: 2.54min, time-elasped: 946.71min
-> berries picked: 40 of 800 | patches-visited: [0, 9] | positive-in-buffer: 16367 | amount-filled: 100.00%
	| epsilon: 0.3846253404137483
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1870, 2884, 1420, 2234, 1644, 2930, 1306, 2079]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 47, 18, 30, 18, 46, 16, 27]
	Time taken saving stuff: 0.08s
episode: 326/2000 -> reward: -124.99999999998913, steps:82752, time-taken: 4.66min, time-elasped: 951.38min
-> berries picked: 128 of 800 | patches-visited: [0, 4, 8] | positive-in-buffer: 16415 | amount-filled: 100.00%
	| epsilon: 0.3843159496142926
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1879, 2896, 1424, 2235, 1643, 2940, 1312, 2086]
	| approx positives in sample 512: 239
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 42, 24, 27, 13, 55, 32, 23]
	Time taken saving stuff: 0.02s
episode: 327/2000 -> reward: -124.99999999999352, steps:65376, time-taken: 2.59min, time-elasped: 953.97min
-> berries picked: 56 of 800 | patches-visited: [3, 6, 7] | positive-in-buffer: 16444 | amount-filled: 100.00%
	| epsilon: 0.3840068076873285
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1886, 2904, 1425, 2242, 1637, 2945, 1317, 2088]
	| approx positives in sample 512: 203
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 39, 13, 18, 23, 43, 14, 30]
	Time taken saving stuff: 12.70s
episode: 328/2000 -> reward: -124.99999999998647, steps:71328, time-taken: 3.93min, time-elasped: 958.12min
-> berries picked: 86 of 800 | patches-visited: [4, 5, 8] | positive-in-buffer: 16481 | amount-filled: 100.00%
	| epsilon: 0.38369791443266404
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1888, 2913, 1435, 2234, 1636, 2956, 1321, 2098]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 37, 20, 25, 21, 37, 21, 36]
	Time taken saving stuff: 0.10s
episode: 329/2000 -> reward: -124.99999999998904, steps:76992, time-taken: 3.87min, time-elasped: 961.99min
-> berries picked: 100 of 800 | patches-visited: [0, 4, 5, 9] | positive-in-buffer: 16555 | amount-filled: 100.00%
	| epsilon: 0.38338926965026854
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1899, 2928, 1449, 2243, 1631, 2970, 1324, 2111]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 36, 19, 17, 22, 66, 15, 31]
	Time taken saving stuff: 0.12s
episode: 330/2000 -> reward: -124.99999999999245, steps:65184, time-taken: 2.70min, time-elasped: 964.69min
-> berries picked: 61 of 800 | patches-visited: [7, 8] | positive-in-buffer: 16554 | amount-filled: 100.00%
	| epsilon: 0.383080873140272
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1899, 2929, 1456, 2232, 1621, 2975, 1327, 2115]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 40, 12, 30, 24, 35, 18, 35]
	Time taken saving stuff: 16.78s
episode: 331/2000 -> reward: -124.99999999999203, steps:48672, time-taken: 2.18min, time-elasped: 967.16min
-> berries picked: 2 of 800 | patches-visited: [1] | positive-in-buffer: 16468 | amount-filled: 100.00%
	| epsilon: 0.38277272470296525
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1888, 2918, 1446, 2210, 1613, 2966, 1324, 2103]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [36, 32, 24, 29, 19, 38, 16, 35]
	Time taken saving stuff: 0.10s
episode: 332/2000 -> reward: -124.99999999999038, steps:70176, time-taken: 3.75min, time-elasped: 970.91min
-> berries picked: 75 of 800 | patches-visited: [0, 8] | positive-in-buffer: 16534 | amount-filled: 100.00%
	| epsilon: 0.3824648241387999
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1889, 2931, 1460, 2227, 1619, 2970, 1330, 2108]
	| approx positives in sample 512: 248
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 37, 23, 25, 13, 65, 17, 37]
	Time taken saving stuff: 0.01s
episode: 333/2000 -> reward: -124.99999999999217, steps:69024, time-taken: 4.00min, time-elasped: 974.91min
-> berries picked: 77 of 800 | patches-visited: [0, 4, 8] | positive-in-buffer: 16574 | amount-filled: 100.00%
	| epsilon: 0.38215717124838794
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1898, 2943, 1468, 2228, 1609, 2977, 1336, 2115]
	| approx positives in sample 512: 243
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 44, 15, 19, 26, 50, 22, 36]
	Time taken saving stuff: 13.36s
episode: 334/2000 -> reward: -124.99999999999248, steps:59040, time-taken: 3.08min, time-elasped: 978.22min
-> berries picked: 48 of 800 | patches-visited: [2] | positive-in-buffer: 16581 | amount-filled: 100.00%
	| epsilon: 0.3818497658325017
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1898, 2943, 1471, 2228, 1603, 2980, 1342, 2116]
	| approx positives in sample 512: 210
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 35, 18, 24, 16, 42, 25, 29]
	Time taken saving stuff: 0.01s
episode: 335/2000 -> reward: -124.99999999999412, steps:59808, time-taken: 2.30min, time-elasped: 980.52min
-> berries picked: 40 of 800 | patches-visited: [8] | positive-in-buffer: 16550 | amount-filled: 100.00%
	| epsilon: 0.38154260769207393
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1895, 2937, 1477, 2214, 1596, 2972, 1343, 2116]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 56, 19, 22, 18, 43, 17, 27]
	Time taken saving stuff: 0.10s
episode: 336/2000 -> reward: -124.99999999999189, steps:58656, time-taken: 2.15min, time-elasped: 982.68min
-> berries picked: 37 of 800 | patches-visited: [3, 5] | positive-in-buffer: 16561 | amount-filled: 100.00%
	| epsilon: 0.3812356966281974
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1895, 2942, 1480, 2213, 1594, 2978, 1343, 2116]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 48, 15, 21, 20, 47, 12, 31]
	Time taken saving stuff: 15.30s
episode: 337/2000 -> reward: -124.99999999999208, steps:53280, time-taken: 2.28min, time-elasped: 985.22min
-> berries picked: 19 of 800 | patches-visited: [9] | positive-in-buffer: 16520 | amount-filled: 100.00%
	| epsilon: 0.3809290324421249
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1888, 2937, 1472, 2208, 1592, 2968, 1345, 2110]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 48, 18, 22, 21, 38, 27, 30]
	Time taken saving stuff: 0.03s
episode: 338/2000 -> reward: -124.99999999999334, steps:64320, time-taken: 2.82min, time-elasped: 988.04min
-> berries picked: 65 of 800 | patches-visited: [2] | positive-in-buffer: 16547 | amount-filled: 100.00%
	| epsilon: 0.38062261493526905
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1887, 2948, 1476, 2213, 1590, 2969, 1351, 2113]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 42, 26, 16, 22, 35, 21, 29]
	Time taken saving stuff: 0.01s
episode: 339/2000 -> reward: -124.99999999999093, steps:63072, time-taken: 2.68min, time-elasped: 990.72min
-> berries picked: 56 of 800 | patches-visited: [2] | positive-in-buffer: 16590 | amount-filled: 100.00%
	| epsilon: 0.38031644390920233
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1891, 2955, 1478, 2220, 1596, 2981, 1352, 2117]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 33, 21, 25, 20, 36, 24, 38]
	Time taken saving stuff: 13.11s
episode: 340/2000 -> reward: -124.99999999998906, steps:66528, time-taken: 5.16min, time-elasped: 996.11min
-> berries picked: 71 of 800 | patches-visited: [3, 7] | positive-in-buffer: 16624 | amount-filled: 100.00%
	| epsilon: 0.3800105191656567
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1893, 2970, 1484, 2218, 1595, 2986, 1356, 2122]
	| approx positives in sample 512: 264
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 39, 32, 25, 29, 51, 29, 40]
	Time taken saving stuff: 0.11s
episode: 341/2000 -> reward: -124.99999999999197, steps:60576, time-taken: 2.30min, time-elasped: 998.41min
-> berries picked: 44 of 800 | patches-visited: [4] | positive-in-buffer: 16621 | amount-filled: 100.00%
	| epsilon: 0.37970484050652376
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1895, 2971, 1485, 2223, 1586, 2985, 1355, 2121]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 35, 20, 24, 25, 34, 19, 37]
	Time taken saving stuff: 0.01s
episode: 342/2000 -> reward: -124.99999999999399, steps:62304, time-taken: 3.25min, time-elasped: 1001.67min
-> berries picked: 49 of 800 | patches-visited: [0, 2] | positive-in-buffer: 16494 | amount-filled: 100.00%
	| epsilon: 0.3793994077338543
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1879, 2955, 1469, 2189, 1578, 2974, 1343, 2107]
	| approx positives in sample 512: 196
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 39, 16, 14, 20, 37, 16, 30]
	Time taken saving stuff: 15.56s
episode: 343/2000 -> reward: -124.99999999999349, steps:70080, time-taken: 3.00min, time-elasped: 1004.94min
-> berries picked: 76 of 800 | patches-visited: [7, 8] | positive-in-buffer: 16545 | amount-filled: 100.00%
	| epsilon: 0.37909422064985837
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1886, 2976, 1471, 2196, 1580, 2983, 1345, 2108]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 54, 12, 24, 10, 50, 14, 44]
	Time taken saving stuff: 0.01s
episode: 344/2000 -> reward: -124.99999999998889, steps:67296, time-taken: 3.77min, time-elasped: 1008.71min
-> berries picked: 67 of 800 | patches-visited: [0, 1, 7] | positive-in-buffer: 16602 | amount-filled: 100.00%
	| epsilon: 0.3787892790569053
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1894, 2986, 1482, 2205, 1579, 2986, 1351, 2119]
	| approx positives in sample 512: 256
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 46, 24, 20, 35, 50, 13, 41]
	Time taken saving stuff: 0.02s
episode: 345/2000 -> reward: -124.99999999998514, steps:70368, time-taken: 3.35min, time-elasped: 1012.06min
-> berries picked: 84 of 800 | patches-visited: [3, 7] | positive-in-buffer: 16644 | amount-filled: 100.00%
	| epsilon: 0.37848458275752317
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1898, 2986, 1489, 2206, 1581, 3001, 1356, 2127]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 31, 24, 30, 21, 44, 22, 29]
	Time taken saving stuff: 49.16s
episode: 346/2000 -> reward: -124.99999999998671, steps:78432, time-taken: 6.30min, time-elasped: 1019.19min
-> berries picked: 117 of 800 | patches-visited: [5, 8] | positive-in-buffer: 16681 | amount-filled: 100.00%
	| epsilon: 0.378180131554399
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1902, 3011, 1493, 2197, 1578, 3006, 1360, 2134]
	| approx positives in sample 512: 198
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 36, 18, 26, 17, 39, 14, 25]
	Time taken saving stuff: 0.04s
episode: 347/2000 -> reward: -124.99999999998573, steps:67968, time-taken: 6.19min, time-elasped: 1025.38min
-> berries picked: 74 of 800 | patches-visited: [0, 8] | positive-in-buffer: 16731 | amount-filled: 100.00%
	| epsilon: 0.37787592525037855
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1907, 3013, 1504, 2210, 1577, 3015, 1369, 2136]
	| approx positives in sample 512: 243
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 33, 17, 28, 22, 55, 24, 36]
	Time taken saving stuff: 0.01s
episode: 348/2000 -> reward: -124.99999999999226, steps:62112, time-taken: 4.54min, time-elasped: 1029.92min
-> berries picked: 51 of 800 | patches-visited: [2] | positive-in-buffer: 16743 | amount-filled: 100.00%
	| epsilon: 0.3775719636484661
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1910, 3025, 1503, 2200, 1579, 3015, 1373, 2138]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [36, 39, 20, 26, 21, 41, 22, 22]
	Time taken saving stuff: 14.86s
episode: 349/2000 -> reward: -124.99999999998542, steps:85056, time-taken: 6.50min, time-elasped: 1036.67min
-> berries picked: 133 of 800 | patches-visited: [2, 3, 4, 8] | positive-in-buffer: 16728 | amount-filled: 100.00%
	| epsilon: 0.37726824655182456
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1911, 3015, 1501, 2198, 1566, 3013, 1382, 2142]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 36, 24, 22, 20, 48, 19, 30]
	Time taken saving stuff: 0.01s
episode: 350/2000 -> reward: -124.99999999999193, steps:66048, time-taken: 5.98min, time-elasped: 1042.65min
-> berries picked: 62 of 800 | patches-visited: [4, 7] | positive-in-buffer: 16750 | amount-filled: 100.00%
	| epsilon: 0.37696477376377485
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1913, 3030, 1512, 2183, 1565, 3020, 1385, 2142]
	| approx positives in sample 512: 264
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 47, 23, 39, 17, 44, 17, 46]
	Time taken saving stuff: 0.09s
episode: 351/2000 -> reward: -124.99999999998914, steps:79968, time-taken: 6.25min, time-elasped: 1048.90min
-> berries picked: 124 of 800 | patches-visited: [6, 7] | positive-in-buffer: 16803 | amount-filled: 100.00%
	| epsilon: 0.3766615450877964
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1914, 3044, 1525, 2186, 1564, 3028, 1392, 2150]
	| approx positives in sample 512: 240
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 40, 18, 27, 22, 45, 20, 33]
	Time taken saving stuff: 15.97s
episode: 352/2000 -> reward: -124.99999999999237, steps:66912, time-taken: 6.02min, time-elasped: 1055.20min
-> berries picked: 70 of 800 | patches-visited: [1] | positive-in-buffer: 16819 | amount-filled: 100.00%
	| epsilon: 0.3763585603275267
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1916, 3042, 1529, 2175, 1568, 3031, 1401, 2157]
	| approx positives in sample 512: 250
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 39, 27, 28, 18, 60, 22, 26]
	Time taken saving stuff: 0.04s
episode: 353/2000 -> reward: -124.9999999999899, steps:64224, time-taken: 4.45min, time-elasped: 1059.65min
-> berries picked: 63 of 800 | patches-visited: [2, 8] | positive-in-buffer: 16846 | amount-filled: 100.00%
	| epsilon: 0.37605581928676096
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1924, 3044, 1537, 2168, 1564, 3039, 1408, 2162]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 39, 22, 19, 14, 42, 16, 32]
	Time taken saving stuff: 0.01s
episode: 354/2000 -> reward: -124.99999999999366, steps:66048, time-taken: 5.98min, time-elasped: 1065.63min
-> berries picked: 64 of 800 | patches-visited: [0, 7] | positive-in-buffer: 16820 | amount-filled: 100.00%
	| epsilon: 0.3757533217694525
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1923, 3036, 1534, 2162, 1556, 3032, 1414, 2163]
	| approx positives in sample 512: 247
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 35, 34, 23, 15, 56, 19, 37]
	Time taken saving stuff: 12.72s
episode: 355/2000 -> reward: -124.99999999998775, steps:66912, time-taken: 6.18min, time-elasped: 1072.03min
-> berries picked: 75 of 800 | patches-visited: [2, 3] | positive-in-buffer: 16868 | amount-filled: 100.00%
	| epsilon: 0.3754510675797121
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1930, 3043, 1542, 2165, 1558, 3040, 1420, 2170]
	| approx positives in sample 512: 250
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 41, 31, 27, 24, 39, 26, 37]
	Time taken saving stuff: 0.01s
episode: 356/2000 -> reward: -124.99999999999382, steps:68256, time-taken: 5.69min, time-elasped: 1077.72min
-> berries picked: 72 of 800 | patches-visited: [6, 7, 9] | positive-in-buffer: 16890 | amount-filled: 100.00%
	| epsilon: 0.3751490565218082
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1934, 3049, 1550, 2168, 1549, 3043, 1423, 2174]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 40, 25, 21, 15, 42, 22, 31]
	Time taken saving stuff: 0.10s
episode: 357/2000 -> reward: -124.99999999998992, steps:68256, time-taken: 6.29min, time-elasped: 1084.02min
-> berries picked: 77 of 800 | patches-visited: [1, 2] | positive-in-buffer: 16906 | amount-filled: 100.00%
	| epsilon: 0.37484728840016684
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1938, 3046, 1558, 2162, 1544, 3048, 1429, 2181]
	| approx positives in sample 512: 256
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 51, 21, 24, 20, 52, 21, 39]
	Time taken saving stuff: 15.65s
episode: 358/2000 -> reward: -124.99999999999028, steps:55488, time-taken: 4.04min, time-elasped: 1088.33min
-> berries picked: 26 of 800 | patches-visited: [1, 7] | positive-in-buffer: 16899 | amount-filled: 100.00%
	| epsilon: 0.37454576301937115
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1935, 3046, 1559, 2153, 1540, 3051, 1430, 2185]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 42, 21, 22, 13, 39, 25, 35]
	Time taken saving stuff: 0.10s
episode: 359/2000 -> reward: -124.99999999999214, steps:62400, time-taken: 4.22min, time-elasped: 1092.55min
-> berries picked: 59 of 800 | patches-visited: [3] | positive-in-buffer: 16915 | amount-filled: 100.00%
	| epsilon: 0.37424448018416157
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1934, 3043, 1566, 2157, 1537, 3057, 1436, 2185]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 43, 16, 27, 13, 47, 24, 31]
	Time taken saving stuff: 0.01s
episode: 360/2000 -> reward: -124.99999999999204, steps:52128, time-taken: 3.66min, time-elasped: 1096.22min
-> berries picked: 15 of 800 | patches-visited: [0] | positive-in-buffer: 16789 | amount-filled: 100.00%
	| epsilon: 0.37394343969943555
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1908, 3030, 1546, 2135, 1534, 3045, 1428, 2163]
	| approx positives in sample 512: 233
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 34, 26, 25, 20, 42, 23, 31]
	Time taken saving stuff: 12.28s
episode: 361/2000 -> reward: -124.99999999998771, steps:79104, time-taken: 5.95min, time-elasped: 1102.37min
-> berries picked: 123 of 800 | patches-visited: [6, 8] | positive-in-buffer: 16880 | amount-filled: 100.00%
	| epsilon: 0.37364264137024755
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1915, 3059, 1558, 2148, 1538, 3061, 1431, 2170]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 41, 19, 30, 12, 44, 16, 39]
	Time taken saving stuff: 0.01s
episode: 362/2000 -> reward: -124.99999999999052, steps:69216, time-taken: 6.22min, time-elasped: 1108.60min
-> berries picked: 79 of 800 | patches-visited: [3, 6, 7] | positive-in-buffer: 16887 | amount-filled: 100.00%
	| epsilon: 0.37334208500180877
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1926, 3063, 1559, 2133, 1524, 3069, 1436, 2177]
	| approx positives in sample 512: 250
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 46, 10, 31, 23, 43, 25, 47]
	Time taken saving stuff: 0.21s
episode: 363/2000 -> reward: -124.99999999999035, steps:60288, time-taken: 3.75min, time-elasped: 1112.35min
-> berries picked: 48 of 800 | patches-visited: [1] | positive-in-buffer: 16912 | amount-filled: 100.00%
	| epsilon: 0.3730417703994872
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1926, 3074, 1566, 2137, 1525, 3064, 1442, 2178]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 43, 26, 23, 17, 46, 18, 29]
	Time taken saving stuff: 16.03s
episode: 364/2000 -> reward: -124.99999999999224, steps:56352, time-taken: 2.66min, time-elasped: 1115.29min
-> berries picked: 33 of 800 | patches-visited: [3] | positive-in-buffer: 16855 | amount-filled: 100.00%
	| epsilon: 0.37274169736880725
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1923, 3071, 1559, 2121, 1523, 3048, 1438, 2172]
	| approx positives in sample 512: 223
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 40, 21, 19, 15, 47, 26, 39]
	Time taken saving stuff: 0.10s
episode: 365/2000 -> reward: -124.99999999999379, steps:70848, time-taken: 4.93min, time-elasped: 1120.22min
-> berries picked: 84 of 800 | patches-visited: [1, 9] | positive-in-buffer: 16857 | amount-filled: 100.00%
	| epsilon: 0.37244186571544985
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1906, 3073, 1574, 2118, 1515, 3056, 1441, 2174]
	| approx positives in sample 512: 241
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 42, 22, 25, 22, 45, 22, 37]
	Time taken saving stuff: 0.01s
episode: 366/2000 -> reward: -124.99999999998664, steps:76128, time-taken: 5.52min, time-elasped: 1125.74min
-> berries picked: 96 of 800 | patches-visited: [1, 6] | positive-in-buffer: 16912 | amount-filled: 100.00%
	| epsilon: 0.37214227524525223
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1911, 3086, 1586, 2118, 1514, 3069, 1446, 2182]
	| approx positives in sample 512: 236
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 54, 14, 18, 10, 37, 30, 42]
	Time taken saving stuff: 13.08s
episode: 367/2000 -> reward: -124.99999999999149, steps:62016, time-taken: 3.00min, time-elasped: 1128.96min
-> berries picked: 51 of 800 | patches-visited: [3, 8] | positive-in-buffer: 16925 | amount-filled: 100.00%
	| epsilon: 0.3718429257642078
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1917, 3085, 1591, 2115, 1510, 3074, 1452, 2181]
	| approx positives in sample 512: 205
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 25, 21, 22, 15, 47, 28, 22]
	Time taken saving stuff: 0.01s
episode: 368/2000 -> reward: -124.99999999999193, steps:59328, time-taken: 2.99min, time-elasped: 1131.95min
-> berries picked: 44 of 800 | patches-visited: [1] | positive-in-buffer: 16911 | amount-filled: 100.00%
	| epsilon: 0.371543817078466
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1915, 3077, 1594, 2110, 1507, 3072, 1451, 2185]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 43, 19, 17, 16, 40, 17, 29]
	Time taken saving stuff: 0.04s
episode: 369/2000 -> reward: -124.99999999999366, steps:58368, time-taken: 3.11min, time-elasped: 1135.06min
-> berries picked: 38 of 800 | patches-visited: [1, 9] | positive-in-buffer: 16896 | amount-filled: 100.00%
	| epsilon: 0.37124494899433236
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1914, 3078, 1597, 2108, 1502, 3065, 1446, 2186]
	| approx positives in sample 512: 236
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 43, 19, 28, 17, 43, 30, 30]
	Time taken saving stuff: 15.16s
episode: 370/2000 -> reward: -124.99999999998758, steps:76224, time-taken: 5.81min, time-elasped: 1141.13min
-> berries picked: 103 of 800 | patches-visited: [2, 6, 8] | positive-in-buffer: 16932 | amount-filled: 100.00%
	| epsilon: 0.37094632131826794
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1916, 3087, 1599, 2115, 1504, 3077, 1449, 2185]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 33, 18, 25, 18, 45, 23, 42]
	Time taken saving stuff: 0.11s
episode: 371/2000 -> reward: -124.99999999998236, steps:80352, time-taken: 5.47min, time-elasped: 1146.60min
-> berries picked: 120 of 800 | patches-visited: [4, 9] | positive-in-buffer: 16999 | amount-filled: 100.00%
	| epsilon: 0.37064793385688966
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1925, 3105, 1613, 2111, 1502, 3094, 1455, 2194]
	| approx positives in sample 512: 237
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 39, 21, 28, 19, 50, 27, 24]
	Time taken saving stuff: 0.01s
episode: 372/2000 -> reward: -124.9999999999927, steps:61536, time-taken: 3.12min, time-elasped: 1149.72min
-> berries picked: 45 of 800 | patches-visited: [2, 9] | positive-in-buffer: 16938 | amount-filled: 100.00%
	| epsilon: 0.37034978641697
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1924, 3102, 1594, 2094, 1496, 3085, 1455, 2188]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 34, 32, 32, 14, 44, 23, 32]
	Time taken saving stuff: 15.46s
episode: 373/2000 -> reward: -124.99999999999213, steps:64320, time-taken: 3.65min, time-elasped: 1153.63min
-> berries picked: 61 of 800 | patches-visited: [8] | positive-in-buffer: 16901 | amount-filled: 100.00%
	| epsilon: 0.37005187880543683
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1922, 3092, 1594, 2085, 1488, 3073, 1458, 2189]
	| approx positives in sample 512: 211
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 36, 11, 28, 21, 44, 14, 26]
	Time taken saving stuff: 0.01s
episode: 374/2000 -> reward: -124.99999999999207, steps:61728, time-taken: 3.14min, time-elasped: 1156.78min
-> berries picked: 50 of 800 | patches-visited: [3] | positive-in-buffer: 16868 | amount-filled: 100.00%
	| epsilon: 0.3697542108293733
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1921, 3090, 1572, 2076, 1483, 3069, 1464, 2193]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 43, 12, 31, 15, 47, 16, 26]
	Time taken saving stuff: 0.09s
episode: 375/2000 -> reward: -124.99999999999004, steps:69216, time-taken: 5.82min, time-elasped: 1162.61min
-> berries picked: 75 of 800 | patches-visited: [0, 6, 8] | positive-in-buffer: 16897 | amount-filled: 100.00%
	| epsilon: 0.36945678229601786
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1916, 3098, 1582, 2088, 1479, 3073, 1467, 2194]
	| approx positives in sample 512: 250
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 43, 27, 29, 24, 47, 23, 38]
	Time taken saving stuff: 11.88s
episode: 376/2000 -> reward: -124.99999999999355, steps:69792, time-taken: 4.02min, time-elasped: 1166.83min
-> berries picked: 80 of 800 | patches-visited: [0, 8] | positive-in-buffer: 16939 | amount-filled: 100.00%
	| epsilon: 0.36915959301276385
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1924, 3115, 1585, 2091, 1472, 3080, 1473, 2199]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 39, 22, 35, 18, 43, 26, 22]
	Time taken saving stuff: 0.03s
episode: 377/2000 -> reward: -124.99999999998904, steps:69312, time-taken: 4.43min, time-elasped: 1171.26min
-> berries picked: 76 of 800 | patches-visited: [3, 7] | positive-in-buffer: 16961 | amount-filled: 100.00%
	| epsilon: 0.36886264278715963
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1930, 3121, 1586, 2092, 1460, 3088, 1479, 2205]
	| approx positives in sample 512: 243
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 36, 25, 29, 14, 50, 20, 35]
	Time taken saving stuff: 0.01s
episode: 378/2000 -> reward: -124.99999999999328, steps:67104, time-taken: 5.01min, time-elasped: 1176.28min
-> berries picked: 76 of 800 | patches-visited: [1, 3] | positive-in-buffer: 16987 | amount-filled: 100.00%
	| epsilon: 0.3685659314269084
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1929, 3126, 1594, 2093, 1457, 3092, 1485, 2211]
	| approx positives in sample 512: 248
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 36, 24, 31, 19, 45, 24, 41]
	Time taken saving stuff: 15.38s
episode: 379/2000 -> reward: -124.99999999999152, steps:81504, time-taken: 4.59min, time-elasped: 1181.12min
-> berries picked: 129 of 800 | patches-visited: [0, 6] | positive-in-buffer: 17031 | amount-filled: 100.00%
	| epsilon: 0.36826945873986794
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1936, 3150, 1598, 2084, 1458, 3096, 1495, 2214]
	| approx positives in sample 512: 210
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 39, 22, 24, 10, 40, 28, 24]
	Time taken saving stuff: 0.01s
episode: 380/2000 -> reward: -124.9999999999897, steps:77088, time-taken: 4.80min, time-elasped: 1185.92min
-> berries picked: 114 of 800 | patches-visited: [2, 3] | positive-in-buffer: 17071 | amount-filled: 100.00%
	| epsilon: 0.36797322453405074
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1938, 3151, 1614, 2082, 1452, 3111, 1504, 2219]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 30, 19, 15, 21, 47, 22, 39]
	Time taken saving stuff: 0.20s
episode: 381/2000 -> reward: -124.99999999999294, steps:75168, time-taken: 4.43min, time-elasped: 1190.36min
-> berries picked: 103 of 800 | patches-visited: [1, 7, 9] | positive-in-buffer: 17106 | amount-filled: 100.00%
	| epsilon: 0.3676772286176236
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1941, 3162, 1622, 2086, 1449, 3116, 1513, 2217]
	| approx positives in sample 512: 240
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 40, 25, 27, 17, 49, 21, 33]
	Time taken saving stuff: 15.18s
episode: 382/2000 -> reward: -124.99999999999166, steps:64224, time-taken: 3.43min, time-elasped: 1194.05min
-> berries picked: 61 of 800 | patches-visited: [2, 7] | positive-in-buffer: 17073 | amount-filled: 100.00%
	| epsilon: 0.3673814707989076
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1932, 3161, 1619, 2069, 1444, 3119, 1509, 2220]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 30, 26, 20, 15, 48, 24, 28]
	Time taken saving stuff: 0.03s
episode: 383/2000 -> reward: -124.99999999999311, steps:63552, time-taken: 3.46min, time-elasped: 1197.51min
-> berries picked: 53 of 800 | patches-visited: [0, 2, 7] | positive-in-buffer: 16993 | amount-filled: 100.00%
	| epsilon: 0.36708595088637813
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1930, 3140, 1615, 2055, 1427, 3109, 1501, 2216]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 28, 27, 26, 20, 44, 20, 28]
	Time taken saving stuff: 0.01s
episode: 384/2000 -> reward: -124.99999999999324, steps:65568, time-taken: 2.97min, time-elasped: 1200.48min
-> berries picked: 67 of 800 | patches-visited: [0] | positive-in-buffer: 16960 | amount-filled: 100.00%
	| epsilon: 0.3667906686886646
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1926, 3129, 1610, 2042, 1426, 3107, 1504, 2216]
	| approx positives in sample 512: 197
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 42, 18, 18, 9, 40, 18, 35]
	Time taken saving stuff: 11.94s
episode: 385/2000 -> reward: -124.99999999999201, steps:58368, time-taken: 3.82min, time-elasped: 1204.51min
-> berries picked: 36 of 800 | patches-visited: [4] | positive-in-buffer: 16850 | amount-filled: 100.00%
	| epsilon: 0.3664956240145503
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1922, 3116, 1596, 2026, 1397, 3088, 1499, 2206]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 39, 14, 26, 17, 41, 19, 42]
	Time taken saving stuff: 0.01s
episode: 386/2000 -> reward: -124.99999999998991, steps:72288, time-taken: 4.32min, time-elasped: 1208.83min
-> berries picked: 93 of 800 | patches-visited: [3, 4] | positive-in-buffer: 16911 | amount-filled: 100.00%
	| epsilon: 0.3662008166729724
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1933, 3126, 1607, 2034, 1400, 3095, 1504, 2212]
	| approx positives in sample 512: 234
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 46, 21, 28, 14, 52, 21, 20]
	Time taken saving stuff: 0.11s
episode: 387/2000 -> reward: -124.99999999999253, steps:67008, time-taken: 4.61min, time-elasped: 1213.44min
-> berries picked: 65 of 800 | patches-visited: [3, 8, 9] | positive-in-buffer: 16952 | amount-filled: 100.00%
	| epsilon: 0.3659062464730217
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1940, 3134, 1615, 2032, 1396, 3108, 1509, 2218]
	| approx positives in sample 512: 279
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 48, 43, 33, 16, 47, 29, 30]
	Time taken saving stuff: 15.63s
episode: 388/2000 -> reward: -124.99999999998364, steps:85920, time-taken: 5.24min, time-elasped: 1218.95min
-> berries picked: 139 of 800 | patches-visited: [1, 6, 8, 9] | positive-in-buffer: 17040 | amount-filled: 100.00%
	| epsilon: 0.36561191322394265
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1956, 3149, 1628, 2037, 1395, 3133, 1512, 2230]
	| approx positives in sample 512: 211
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 40, 19, 20, 15, 42, 26, 22]
	Time taken saving stuff: 0.10s
episode: 389/2000 -> reward: -124.99999999999224, steps:62880, time-taken: 3.00min, time-elasped: 1221.96min
-> berries picked: 55 of 800 | patches-visited: [7] | positive-in-buffer: 17052 | amount-filled: 100.00%
	| epsilon: 0.365317816735133
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1951, 3157, 1627, 2037, 1396, 3136, 1514, 2234]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 30, 17, 24, 18, 34, 25, 37]
	Time taken saving stuff: 0.01s
episode: 390/2000 -> reward: -124.99999999999156, steps:61344, time-taken: 3.67min, time-elasped: 1225.64min
-> berries picked: 49 of 800 | patches-visited: [0, 5, 8] | positive-in-buffer: 17057 | amount-filled: 100.00%
	| epsilon: 0.365023956816144
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1951, 3153, 1634, 2042, 1392, 3139, 1512, 2234]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 45, 23, 27, 6, 42, 11, 37]
	Time taken saving stuff: 15.23s
episode: 391/2000 -> reward: -124.99999999999282, steps:61536, time-taken: 3.59min, time-elasped: 1229.48min
-> berries picked: 48 of 800 | patches-visited: [4, 5, 6] | positive-in-buffer: 17049 | amount-filled: 100.00%
	| epsilon: 0.3647303332766801
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1950, 3156, 1629, 2043, 1387, 3136, 1517, 2231]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 34, 20, 27, 13, 43, 34, 29]
	Time taken saving stuff: 0.01s
episode: 392/2000 -> reward: -124.99999999999235, steps:57696, time-taken: 3.16min, time-elasped: 1232.64min
-> berries picked: 38 of 800 | patches-visited: [4, 8] | positive-in-buffer: 17003 | amount-filled: 100.00%
	| epsilon: 0.3644369459265985
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1944, 3150, 1620, 2034, 1375, 3133, 1518, 2229]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 41, 20, 23, 10, 43, 25, 31]
	Time taken saving stuff: 0.03s
episode: 393/2000 -> reward: -124.99999999999183, steps:63360, time-taken: 3.49min, time-elasped: 1236.13min
-> berries picked: 56 of 800 | patches-visited: [8] | positive-in-buffer: 17015 | amount-filled: 100.00%
	| epsilon: 0.3641437945759097
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1946, 3156, 1621, 2037, 1375, 3132, 1519, 2229]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 34, 18, 26, 15, 37, 12, 34]
	Time taken saving stuff: 15.37s
episode: 394/2000 -> reward: -124.99999999999298, steps:71232, time-taken: 5.00min, time-elasped: 1241.39min
-> berries picked: 87 of 800 | patches-visited: [2, 4, 7] | positive-in-buffer: 17010 | amount-filled: 100.00%
	| epsilon: 0.3638508790347769
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1955, 3148, 1630, 2040, 1364, 3122, 1523, 2228]
	| approx positives in sample 512: 246
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 49, 27, 25, 18, 34, 33, 39]
	Time taken saving stuff: 0.10s
episode: 395/2000 -> reward: -124.99999999999183, steps:62784, time-taken: 3.10min, time-elasped: 1244.50min
-> berries picked: 55 of 800 | patches-visited: [3] | positive-in-buffer: 17046 | amount-filled: 100.00%
	| epsilon: 0.36355819911351606
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1960, 3160, 1637, 2042, 1365, 3124, 1527, 2231]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 35, 17, 20, 16, 53, 23, 26]
	Time taken saving stuff: 0.01s
episode: 396/2000 -> reward: -124.99999999999173, steps:60576, time-taken: 3.18min, time-elasped: 1247.68min
-> berries picked: 46 of 800 | patches-visited: [2, 8] | positive-in-buffer: 17003 | amount-filled: 100.00%
	| epsilon: 0.36326575462259564
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1955, 3154, 1632, 2024, 1355, 3122, 1528, 2233]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 36, 23, 17, 14, 41, 22, 35]
	Time taken saving stuff: 15.30s
episode: 397/2000 -> reward: -124.99999999999253, steps:58848, time-taken: 3.30min, time-elasped: 1251.25min
-> berries picked: 36 of 800 | patches-visited: [1, 8] | positive-in-buffer: 16968 | amount-filled: 100.00%
	| epsilon: 0.36297354537263654
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1949, 3150, 1624, 2014, 1349, 3120, 1529, 2233]
	| approx positives in sample 512: 189
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 40, 17, 18, 14, 24, 25, 27]
	Time taken saving stuff: 0.01s
episode: 398/2000 -> reward: -124.99999999998889, steps:79680, time-taken: 4.84min, time-elasped: 1256.09min
-> berries picked: 107 of 800 | patches-visited: [3, 6, 9] | positive-in-buffer: 16998 | amount-filled: 100.00%
	| epsilon: 0.3626815711744121
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1960, 3154, 1630, 2010, 1342, 3128, 1538, 2236]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 43, 19, 24, 21, 42, 23, 26]
	Time taken saving stuff: 0.09s
episode: 399/2000 -> reward: -124.99999999999162, steps:60864, time-taken: 3.47min, time-elasped: 1259.56min
-> berries picked: 46 of 800 | patches-visited: [3, 9] | positive-in-buffer: 17024 | amount-filled: 100.00%
	| epsilon: 0.36238983183884776
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1961, 3156, 1635, 2010, 1342, 3140, 1540, 2240]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 37, 27, 20, 20, 43, 22, 27]
	Time taken saving stuff: 16.20s
episode: 400/2000 -> reward: -124.99999999999002, steps:75936, time-taken: 4.49min, time-elasped: 1264.32min
-> berries picked: 103 of 800 | patches-visited: [0, 8] | positive-in-buffer: 17020 | amount-filled: 100.00%
	| epsilon: 0.36209832717702123
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1958, 3161, 1643, 2000, 1334, 3135, 1545, 2244]
	| approx positives in sample 512: 250
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [39, 32, 19, 28, 11, 51, 35, 35]
	Time taken saving stuff: 0.03s
episode: 401/2000 -> reward: -124.99999999999335, steps:79680, time-taken: 4.36min, time-elasped: 1268.69min
-> berries picked: 102 of 800 | patches-visited: [1, 5, 7, 8] | positive-in-buffer: 17054 | amount-filled: 100.00%
	| epsilon: 0.36180705700016197
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1969, 3165, 1641, 1993, 1328, 3148, 1556, 2254]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 42, 16, 24, 11, 44, 21, 28]
	Time taken saving stuff: 0.04s
episode: 402/2000 -> reward: -124.99999999999218, steps:61056, time-taken: 2.90min, time-elasped: 1271.59min
-> berries picked: 44 of 800 | patches-visited: [1] | positive-in-buffer: 17040 | amount-filled: 100.00%
	| epsilon: 0.36151602111965137
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1967, 3164, 1639, 1993, 1322, 3142, 1560, 2253]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 37, 21, 27, 15, 45, 22, 31]
	Time taken saving stuff: 15.43s
episode: 403/2000 -> reward: -124.99999999998953, steps:71136, time-taken: 4.07min, time-elasped: 1275.93min
-> berries picked: 80 of 800 | patches-visited: [0, 5, 8] | positive-in-buffer: 17062 | amount-filled: 100.00%
	| epsilon: 0.3612252193470227
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1969, 3160, 1643, 1996, 1325, 3151, 1568, 2250]
	| approx positives in sample 512: 241
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 42, 24, 26, 13, 60, 15, 35]
	Time taken saving stuff: 0.11s
episode: 404/2000 -> reward: -124.99999999999157, steps:78048, time-taken: 4.08min, time-elasped: 1280.01min
-> berries picked: 105 of 800 | patches-visited: [0, 3, 6, 8] | positive-in-buffer: 17141 | amount-filled: 100.00%
	| epsilon: 0.3609346514939605
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1974, 3175, 1657, 2003, 1329, 3173, 1575, 2255]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 32, 17, 22, 19, 42, 27, 31]
	Time taken saving stuff: 0.03s
episode: 405/2000 -> reward: -124.99999999999503, steps:74304, time-taken: 4.54min, time-elasped: 1284.55min
-> berries picked: 93 of 800 | patches-visited: [7, 9] | positive-in-buffer: 17164 | amount-filled: 100.00%
	| epsilon: 0.360644317372301
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1974, 3184, 1655, 2011, 1326, 3176, 1583, 2255]
	| approx positives in sample 512: 230
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 37, 22, 24, 23, 41, 22, 39]
	Time taken saving stuff: 15.42s
episode: 406/2000 -> reward: -124.99999999998758, steps:70848, time-taken: 4.68min, time-elasped: 1289.49min
-> berries picked: 82 of 800 | patches-visited: [1, 2] | positive-in-buffer: 17181 | amount-filled: 100.00%
	| epsilon: 0.36035421679403196
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1970, 3190, 1657, 2013, 1328, 3179, 1590, 2254]
	| approx positives in sample 512: 243
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 49, 20, 29, 13, 41, 28, 39]
	Time taken saving stuff: 0.11s
episode: 407/2000 -> reward: -124.99999999999007, steps:72672, time-taken: 5.06min, time-elasped: 1294.55min
-> berries picked: 83 of 800 | patches-visited: [7, 8, 9] | positive-in-buffer: 17218 | amount-filled: 100.00%
	| epsilon: 0.360064349571292
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1978, 3189, 1664, 2010, 1323, 3199, 1596, 2259]
	| approx positives in sample 512: 239
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 42, 22, 27, 18, 50, 25, 28]
	Time taken saving stuff: 0.02s
episode: 408/2000 -> reward: -124.99999999999055, steps:79776, time-taken: 5.14min, time-elasped: 1299.69min
-> berries picked: 125 of 800 | patches-visited: [0, 1, 4, 9] | positive-in-buffer: 17251 | amount-filled: 100.00%
	| epsilon: 0.35977471551637114
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1982, 3203, 1674, 1993, 1319, 3211, 1605, 2264]
	| approx positives in sample 512: 245
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 49, 20, 23, 15, 40, 26, 43]
	Time taken saving stuff: 15.69s
episode: 409/2000 -> reward: -124.9999999999922, steps:59424, time-taken: 3.55min, time-elasped: 1303.51min
-> berries picked: 43 of 800 | patches-visited: [4] | positive-in-buffer: 17216 | amount-filled: 100.00%
	| epsilon: 0.3594853144417102
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1979, 3205, 1667, 1983, 1311, 3206, 1605, 2260]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 42, 15, 22, 19, 35, 24, 29]
	Time taken saving stuff: 0.03s
episode: 410/2000 -> reward: -124.99999999999132, steps:59424, time-taken: 3.51min, time-elasped: 1307.02min
-> berries picked: 42 of 800 | patches-visited: [5] | positive-in-buffer: 17157 | amount-filled: 100.00%
	| epsilon: 0.3591961461599011
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1972, 3201, 1657, 1978, 1303, 3199, 1596, 2251]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 47, 29, 22, 17, 35, 23, 24]
	Time taken saving stuff: 0.10s
episode: 411/2000 -> reward: -124.99999999999379, steps:69696, time-taken: 4.79min, time-elasped: 1311.82min
-> berries picked: 75 of 800 | patches-visited: [4, 8] | positive-in-buffer: 17171 | amount-filled: 100.00%
	| epsilon: 0.35890721048368623
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1976, 3213, 1659, 1971, 1298, 3202, 1600, 2252]
	| approx positives in sample 512: 245
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 44, 12, 31, 15, 56, 20, 37]
	Time taken saving stuff: 12.27s
episode: 412/2000 -> reward: -124.99999999999007, steps:62688, time-taken: 3.60min, time-elasped: 1315.63min
-> berries picked: 55 of 800 | patches-visited: [0, 8] | positive-in-buffer: 17153 | amount-filled: 100.00%
	| epsilon: 0.35861850722595884
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1974, 3214, 1662, 1953, 1291, 3209, 1601, 2249]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 40, 22, 19, 9, 40, 32, 23]
	Time taken saving stuff: 0.09s
episode: 413/2000 -> reward: -124.99999999999315, steps:60480, time-taken: 3.32min, time-elasped: 1318.96min
-> berries picked: 40 of 800 | patches-visited: [2, 3] | positive-in-buffer: 17081 | amount-filled: 100.00%
	| epsilon: 0.35833003619976256
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1962, 3196, 1660, 1931, 1283, 3204, 1603, 2242]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 28, 20, 19, 16, 59, 22, 37]
	Time taken saving stuff: 0.03s
episode: 414/2000 -> reward: -124.99999999999206, steps:58848, time-taken: 3.41min, time-elasped: 1322.37min
-> berries picked: 38 of 800 | patches-visited: [5] | positive-in-buffer: 17070 | amount-filled: 100.00%
	| epsilon: 0.35804179721829144
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1961, 3193, 1664, 1923, 1279, 3206, 1603, 2241]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 41, 18, 23, 14, 44, 14, 30]
	Time taken saving stuff: 15.26s
episode: 415/2000 -> reward: -124.99999999998948, steps:69312, time-taken: 5.37min, time-elasped: 1327.99min
-> berries picked: 82 of 800 | patches-visited: [2, 5] | positive-in-buffer: 17096 | amount-filled: 100.00%
	| epsilon: 0.3577537900948899
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1968, 3197, 1668, 1925, 1274, 3214, 1610, 2240]
	| approx positives in sample 512: 233
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 32, 30, 27, 11, 39, 25, 40]
	Time taken saving stuff: 0.03s
episode: 416/2000 -> reward: -124.99999999999113, steps:69600, time-taken: 5.23min, time-elasped: 1333.23min
-> berries picked: 78 of 800 | patches-visited: [3, 7] | positive-in-buffer: 17124 | amount-filled: 100.00%
	| epsilon: 0.3574660146430523
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1975, 3200, 1673, 1929, 1270, 3221, 1615, 2241]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 46, 23, 15, 13, 43, 27, 38]
	Time taken saving stuff: 0.02s
episode: 417/2000 -> reward: -124.99999999999211, steps:55872, time-taken: 3.71min, time-elasped: 1336.95min
-> berries picked: 36 of 800 | patches-visited: [2] | positive-in-buffer: 17117 | amount-filled: 100.00%
	| epsilon: 0.3571784706764231
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1976, 3202, 1672, 1922, 1266, 3220, 1616, 2243]
	| approx positives in sample 512: 262
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 44, 27, 20, 10, 60, 38, 31]
	Time taken saving stuff: 15.32s
episode: 418/2000 -> reward: -124.99999999999213, steps:57312, time-taken: 3.50min, time-elasped: 1340.70min
-> berries picked: 34 of 800 | patches-visited: [7] | positive-in-buffer: 17082 | amount-filled: 100.00%
	| epsilon: 0.35689115800879684
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1973, 3200, 1674, 1914, 1256, 3213, 1610, 2242]
	| approx positives in sample 512: 237
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 43, 20, 21, 17, 55, 23, 28]
	Time taken saving stuff: 0.04s
episode: 419/2000 -> reward: -124.99999999999203, steps:51744, time-taken: 3.29min, time-elasped: 1344.00min
-> berries picked: 13 of 800 | patches-visited: [0] | positive-in-buffer: 17055 | amount-filled: 100.00%
	| epsilon: 0.35660407645411757
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1971, 3195, 1674, 1903, 1256, 3208, 1612, 2236]
	| approx positives in sample 512: 230
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 28, 22, 21, 16, 52, 27, 32]
	Time taken saving stuff: 0.00s
episode: 420/2000 -> reward: -124.99999999999002, steps:68832, time-taken: 4.12min, time-elasped: 1348.12min
-> berries picked: 74 of 800 | patches-visited: [2, 7] | positive-in-buffer: 17111 | amount-filled: 100.00%
	| epsilon: 0.35631722582647923
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1977, 3212, 1684, 1912, 1258, 3213, 1617, 2238]
	| approx positives in sample 512: 250
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 39, 28, 22, 16, 52, 18, 46]
	Time taken saving stuff: 68.60s
episode: 421/2000 -> reward: -124.99999999998877, steps:79200, time-taken: 3.35min, time-elasped: 1352.62min
-> berries picked: 109 of 800 | patches-visited: [4, 6, 7, 9] | positive-in-buffer: 17127 | amount-filled: 100.00%
	| epsilon: 0.35603060594012514
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1981, 3216, 1686, 1903, 1250, 3233, 1622, 2236]
	| approx positives in sample 512: 208
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 25, 29, 16, 15, 56, 15, 26]
	Time taken saving stuff: 0.01s
episode: 422/2000 -> reward: -124.99999999999308, steps:57888, time-taken: 2.08min, time-elasped: 1354.70min
-> berries picked: 32 of 800 | patches-visited: [5, 7] | positive-in-buffer: 17066 | amount-filled: 100.00%
	| epsilon: 0.35574421660944816
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1969, 3202, 1687, 1892, 1245, 3226, 1615, 2230]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [37, 31, 26, 22, 12, 41, 23, 33]
	Time taken saving stuff: 0.11s
episode: 423/2000 -> reward: -124.99999999999204, steps:51360, time-taken: 1.97min, time-elasped: 1356.68min
-> berries picked: 13 of 800 | patches-visited: [7] | positive-in-buffer: 17047 | amount-filled: 100.00%
	| epsilon: 0.3554580576489903
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1969, 3201, 1686, 1884, 1245, 3224, 1609, 2229]
	| approx positives in sample 512: 236
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 42, 15, 19, 15, 51, 28, 31]
	Time taken saving stuff: 91.62s
episode: 424/2000 -> reward: -124.99999999998926, steps:69984, time-taken: 4.34min, time-elasped: 1362.55min
-> berries picked: 80 of 800 | patches-visited: [1, 7, 8] | positive-in-buffer: 17113 | amount-filled: 100.00%
	| epsilon: 0.35517212887344296
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1973, 3220, 1697, 1890, 1247, 3234, 1617, 2235]
	| approx positives in sample 512: 226
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 38, 18, 27, 20, 45, 17, 37]
	Time taken saving stuff: 0.09s
episode: 425/2000 -> reward: -124.99999999999312, steps:64224, time-taken: 3.65min, time-elasped: 1366.20min
-> berries picked: 57 of 800 | patches-visited: [0, 5, 8] | positive-in-buffer: 17148 | amount-filled: 100.00%
	| epsilon: 0.3548864300976464
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1978, 3225, 1704, 1888, 1245, 3244, 1624, 2240]
	| approx positives in sample 512: 202
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 38, 29, 15, 13, 38, 16, 32]
	Time taken saving stuff: 0.01s
episode: 426/2000 -> reward: -124.99999999998641, steps:77280, time-taken: 5.38min, time-elasped: 1371.58min
-> berries picked: 107 of 800 | patches-visited: [1, 9] | positive-in-buffer: 17178 | amount-filled: 100.00%
	| epsilon: 0.35460096113659
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1973, 3239, 1713, 1895, 1246, 3242, 1630, 2240]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 30, 19, 26, 16, 49, 32, 33]
	Time taken saving stuff: 17.87s
episode: 427/2000 -> reward: -124.99999999999321, steps:65280, time-taken: 3.74min, time-elasped: 1375.63min
-> berries picked: 59 of 800 | patches-visited: [2, 3] | positive-in-buffer: 17216 | amount-filled: 100.00%
	| epsilon: 0.35431572180541177
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1979, 3247, 1718, 1898, 1244, 3246, 1638, 2246]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 42, 27, 12, 15, 44, 17, 33]
	Time taken saving stuff: 0.01s
episode: 428/2000 -> reward: -124.99999999998846, steps:69792, time-taken: 5.38min, time-elasped: 1381.01min
-> berries picked: 74 of 800 | patches-visited: [0, 7] | positive-in-buffer: 17220 | amount-filled: 100.00%
	| epsilon: 0.3540307119193986
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1988, 3246, 1722, 1894, 1243, 3247, 1639, 2241]
	| approx positives in sample 512: 234
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 41, 24, 25, 10, 47, 31, 32]
	Time taken saving stuff: 0.03s
episode: 429/2000 -> reward: -124.99999999999308, steps:55104, time-taken: 3.71min, time-elasped: 1384.72min
-> berries picked: 24 of 800 | patches-visited: [8] | positive-in-buffer: 17231 | amount-filled: 100.00%
	| epsilon: 0.3537459312939859
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1988, 3249, 1723, 1899, 1239, 3250, 1641, 2242]
	| approx positives in sample 512: 269
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [42, 45, 33, 23, 19, 49, 29, 29]
	Time taken saving stuff: 15.96s
episode: 430/2000 -> reward: -124.99999999999211, steps:62496, time-taken: 3.56min, time-elasped: 1388.56min
-> berries picked: 52 of 800 | patches-visited: [4, 5] | positive-in-buffer: 17255 | amount-filled: 100.00%
	| epsilon: 0.35346137974475744
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1992, 3262, 1725, 1896, 1237, 3252, 1647, 2244]
	| approx positives in sample 512: 237
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 41, 22, 22, 15, 43, 27, 32]
	Time taken saving stuff: 0.09s
episode: 431/2000 -> reward: -124.99999999998987, steps:72192, time-taken: 5.54min, time-elasped: 1394.11min
-> berries picked: 91 of 800 | patches-visited: [0, 1, 4] | positive-in-buffer: 17232 | amount-filled: 100.00%
	| epsilon: 0.3531770570874455
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1989, 3259, 1728, 1892, 1229, 3248, 1649, 2238]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 34, 24, 20, 12, 52, 22, 27]
	Time taken saving stuff: 0.00s
episode: 432/2000 -> reward: -124.99999999999424, steps:69024, time-taken: 4.91min, time-elasped: 1399.02min
-> berries picked: 65 of 800 | patches-visited: [1, 6, 9] | positive-in-buffer: 17250 | amount-filled: 100.00%
	| epsilon: 0.3528929631379305
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1998, 3257, 1734, 1886, 1225, 3255, 1654, 2241]
	| approx positives in sample 512: 239
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 39, 21, 22, 15, 41, 36, 40]
	Time taken saving stuff: 13.11s
episode: 433/2000 -> reward: -124.99999999999483, steps:71232, time-taken: 4.96min, time-elasped: 1404.19min
-> berries picked: 87 of 800 | patches-visited: [3, 7] | positive-in-buffer: 17271 | amount-filled: 100.00%
	| epsilon: 0.35260909771224097
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2007, 3269, 1739, 1879, 1220, 3259, 1658, 2240]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 32, 25, 16, 13, 55, 27, 28]
	Time taken saving stuff: 0.00s
episode: 434/2000 -> reward: -124.9999999999907, steps:85056, time-taken: 4.39min, time-elasped: 1408.59min
-> berries picked: 126 of 800 | patches-visited: [0, 1, 2, 7] | positive-in-buffer: 17302 | amount-filled: 100.00%
	| epsilon: 0.3523254606265534
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2019, 3271, 1751, 1872, 1206, 3265, 1669, 2249]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 28, 21, 23, 20, 45, 17, 30]
	Time taken saving stuff: 0.06s
episode: 435/2000 -> reward: -124.99999999998896, steps:72480, time-taken: 3.74min, time-elasped: 1412.34min
-> berries picked: 94 of 800 | patches-visited: [3, 5, 7] | positive-in-buffer: 17248 | amount-filled: 100.00%
	| epsilon: 0.3520420516971922
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2009, 3262, 1734, 1864, 1202, 3263, 1669, 2245]
	| approx positives in sample 512: 253
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 37, 30, 23, 17, 54, 23, 37]
	Time taken saving stuff: 89.83s
episode: 436/2000 -> reward: -124.99999999998961, steps:61632, time-taken: 2.25min, time-elasped: 1416.10min
-> berries picked: 48 of 800 | patches-visited: [0, 3] | positive-in-buffer: 17285 | amount-filled: 100.00%
	| epsilon: 0.3517588707406295
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2013, 3269, 1742, 1865, 1206, 3269, 1672, 2249]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 42, 16, 17, 13, 46, 19, 25]
	Time taken saving stuff: 0.06s
episode: 437/2000 -> reward: -124.99999999999027, steps:67296, time-taken: 3.06min, time-elasped: 1419.15min
-> berries picked: 73 of 800 | patches-visited: [4, 6] | positive-in-buffer: 17270 | amount-filled: 100.00%
	| epsilon: 0.35147591757348506
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2005, 3275, 1744, 1856, 1201, 3266, 1676, 2247]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 38, 24, 16, 12, 46, 17, 34]
	Time taken saving stuff: 0.00s
episode: 438/2000 -> reward: -124.99999999999216, steps:61536, time-taken: 2.12min, time-elasped: 1421.28min
-> berries picked: 44 of 800 | patches-visited: [9] | positive-in-buffer: 17298 | amount-filled: 100.00%
	| epsilon: 0.3511931920125262
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2009, 3285, 1746, 1860, 1201, 3271, 1678, 2248]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 38, 17, 27, 14, 34, 21, 40]
	Time taken saving stuff: 42.85s
episode: 439/2000 -> reward: -124.99999999999145, steps:64128, time-taken: 2.10min, time-elasped: 1424.10min
-> berries picked: 54 of 800 | patches-visited: [1, 8, 9] | positive-in-buffer: 17274 | amount-filled: 100.00%
	| epsilon: 0.35091069387466745
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2002, 3270, 1754, 1852, 1195, 3274, 1683, 2244]
	| approx positives in sample 512: 207
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 34, 26, 16, 16, 42, 23, 29]
	Time taken saving stuff: 0.01s
episode: 440/2000 -> reward: -124.99999999999189, steps:57312, time-taken: 2.44min, time-elasped: 1426.54min
-> berries picked: 36 of 800 | patches-visited: [7] | positive-in-buffer: 17212 | amount-filled: 100.00%
	| epsilon: 0.3506284229769709
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1998, 3255, 1745, 1845, 1188, 3263, 1680, 2238]
	| approx positives in sample 512: 208
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 41, 17, 21, 12, 37, 23, 26]
	Time taken saving stuff: 0.11s
episode: 441/2000 -> reward: -124.99999999999088, steps:61248, time-taken: 2.52min, time-elasped: 1429.07min
-> berries picked: 45 of 800 | patches-visited: [2, 3, 6] | positive-in-buffer: 17253 | amount-filled: 100.00%
	| epsilon: 0.35034637913664557
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2004, 3261, 1747, 1852, 1188, 3276, 1684, 2241]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [36, 38, 20, 20, 13, 51, 12, 27]
	Time taken saving stuff: 13.01s
episode: 442/2000 -> reward: -124.99999999999204, steps:58464, time-taken: 2.18min, time-elasped: 1431.46min
-> berries picked: 42 of 800 | patches-visited: [2] | positive-in-buffer: 17161 | amount-filled: 100.00%
	| epsilon: 0.3500645621710476
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1995, 3249, 1739, 1831, 1179, 3262, 1680, 2226]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 27, 30, 14, 12, 47, 25, 36]
	Time taken saving stuff: 0.02s
episode: 443/2000 -> reward: -124.999999999992, steps:61536, time-taken: 2.40min, time-elasped: 1433.87min
-> berries picked: 45 of 800 | patches-visited: [1, 9] | positive-in-buffer: 17176 | amount-filled: 100.00%
	| epsilon: 0.34978297189768
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1999, 3255, 1745, 1829, 1174, 3266, 1681, 2227]
	| approx positives in sample 512: 206
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 38, 20, 16, 13, 36, 29, 32]
	Time taken saving stuff: 0.02s
episode: 444/2000 -> reward: -124.99999999999044, steps:61440, time-taken: 2.33min, time-elasped: 1436.20min
-> berries picked: 48 of 800 | patches-visited: [3] | positive-in-buffer: 17146 | amount-filled: 100.00%
	| epsilon: 0.3495016081341927
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2001, 3244, 1744, 1822, 1168, 3264, 1681, 2222]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 36, 25, 29, 16, 29, 21, 42]
	Time taken saving stuff: 14.84s
episode: 445/2000 -> reward: -124.99999999999294, steps:68448, time-taken: 2.95min, time-elasped: 1439.40min
-> berries picked: 78 of 800 | patches-visited: [2, 7, 8] | positive-in-buffer: 17152 | amount-filled: 100.00%
	| epsilon: 0.3492204706983821
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2002, 3240, 1744, 1819, 1159, 3270, 1691, 2227]
	| approx positives in sample 512: 247
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 42, 22, 28, 10, 56, 28, 33]
	Time taken saving stuff: 0.08s
episode: 446/2000 -> reward: -124.99999999998988, steps:66144, time-taken: 2.98min, time-elasped: 1442.39min
-> berries picked: 62 of 800 | patches-visited: [4, 6] | positive-in-buffer: 17197 | amount-filled: 100.00%
	| epsilon: 0.3489395594081914
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2006, 3247, 1749, 1824, 1163, 3279, 1696, 2233]
	| approx positives in sample 512: 251
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 51, 26, 25, 14, 52, 24, 33]
	Time taken saving stuff: 0.00s
episode: 447/2000 -> reward: -124.999999999992, steps:55680, time-taken: 2.06min, time-elasped: 1444.45min
-> berries picked: 25 of 800 | patches-visited: [7] | positive-in-buffer: 17214 | amount-filled: 100.00%
	| epsilon: 0.3486588740817101
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2008, 3255, 1751, 1824, 1163, 3282, 1698, 2233]
	| approx positives in sample 512: 238
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 37, 25, 29, 22, 47, 26, 32]
	Time taken saving stuff: 14.10s
episode: 448/2000 -> reward: -124.99999999999335, steps:63936, time-taken: 1.97min, time-elasped: 1446.66min
-> berries picked: 54 of 800 | patches-visited: [2, 6] | positive-in-buffer: 17213 | amount-filled: 100.00%
	| epsilon: 0.348378414537174
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2008, 3254, 1757, 1814, 1159, 3286, 1701, 2234]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 46, 17, 22, 11, 49, 20, 25]
	Time taken saving stuff: 0.01s
episode: 449/2000 -> reward: -124.99999999999199, steps:62496, time-taken: 2.07min, time-elasped: 1448.73min
-> berries picked: 54 of 800 | patches-visited: [3] | positive-in-buffer: 17182 | amount-filled: 100.00%
	| epsilon: 0.3480981805929653
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2007, 3250, 1760, 1810, 1148, 3289, 1697, 2221]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 39, 22, 28, 12, 52, 22, 20]
	Time taken saving stuff: 0.11s
episode: 450/2000 -> reward: -124.9999999999937, steps:72864, time-taken: 2.87min, time-elasped: 1451.61min
-> berries picked: 93 of 800 | patches-visited: [3, 9] | positive-in-buffer: 17212 | amount-filled: 100.00%
	| epsilon: 0.3478181720676121
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2013, 3250, 1763, 1808, 1150, 3296, 1702, 2230]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 40, 18, 20, 13, 41, 28, 35]
	Time taken saving stuff: 15.31s
episode: 451/2000 -> reward: -124.99999999999226, steps:71808, time-taken: 2.84min, time-elasped: 1454.71min
-> berries picked: 84 of 800 | patches-visited: [2, 6, 7] | positive-in-buffer: 17260 | amount-filled: 100.00%
	| epsilon: 0.34753838877978854
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2018, 3257, 1770, 1816, 1147, 3303, 1716, 2233]
	| approx positives in sample 512: 234
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 43, 28, 22, 11, 34, 28, 33]
	Time taken saving stuff: 0.02s
episode: 452/2000 -> reward: -124.999999999991, steps:71904, time-taken: 3.08min, time-elasped: 1457.79min
-> berries picked: 82 of 800 | patches-visited: [1, 3, 4, 9] | positive-in-buffer: 17241 | amount-filled: 100.00%
	| epsilon: 0.3472588305483146
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2025, 3235, 1768, 1801, 1136, 3311, 1723, 2242]
	| approx positives in sample 512: 244
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 55, 20, 28, 13, 42, 19, 36]
	Time taken saving stuff: 0.00s
episode: 453/2000 -> reward: -124.99999999998826, steps:80640, time-taken: 2.99min, time-elasped: 1460.78min
-> berries picked: 128 of 800 | patches-visited: [2, 4, 6] | positive-in-buffer: 17270 | amount-filled: 100.00%
	| epsilon: 0.3469794971921561
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2030, 3244, 1782, 1786, 1126, 3317, 1736, 2249]
	| approx positives in sample 512: 235
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [41, 44, 22, 18, 12, 41, 31, 26]
	Time taken saving stuff: 13.23s
episode: 454/2000 -> reward: -124.99999999999206, steps:58560, time-taken: 1.94min, time-elasped: 1462.95min
-> berries picked: 39 of 800 | patches-visited: [0] | positive-in-buffer: 17250 | amount-filled: 100.00%
	| epsilon: 0.3467003885304243
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2026, 3246, 1779, 1783, 1120, 3320, 1736, 2240]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 40, 33, 27, 13, 36, 19, 27]
	Time taken saving stuff: 0.01s
episode: 455/2000 -> reward: -124.99999999998747, steps:72768, time-taken: 3.09min, time-elasped: 1466.04min
-> berries picked: 87 of 800 | patches-visited: [0, 3, 5] | positive-in-buffer: 17255 | amount-filled: 100.00%
	| epsilon: 0.3464215043823761
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2035, 3237, 1776, 1778, 1114, 3332, 1743, 2240]
	| approx positives in sample 512: 226
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 33, 21, 24, 8, 55, 25, 27]
	Time taken saving stuff: 0.10s
episode: 456/2000 -> reward: -124.99999999999173, steps:57792, time-taken: 1.89min, time-elasped: 1467.93min
-> berries picked: 39 of 800 | patches-visited: [4, 8] | positive-in-buffer: 17280 | amount-filled: 100.00%
	| epsilon: 0.3461428445674138
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2042, 3244, 1779, 1778, 1113, 3337, 1744, 2243]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 37, 22, 18, 6, 36, 27, 37]
	Time taken saving stuff: 13.91s
episode: 457/2000 -> reward: -124.99999999999226, steps:62688, time-taken: 2.03min, time-elasped: 1470.20min
-> berries picked: 55 of 800 | patches-visited: [2] | positive-in-buffer: 17248 | amount-filled: 100.00%
	| epsilon: 0.3458644089050849
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2045, 3244, 1777, 1762, 1106, 3328, 1746, 2240]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [38, 29, 30, 19, 11, 30, 26, 32]
	Time taken saving stuff: 0.04s
episode: 458/2000 -> reward: -124.99999999999211, steps:58176, time-taken: 1.99min, time-elasped: 1472.20min
-> berries picked: 36 of 800 | patches-visited: [7, 8] | positive-in-buffer: 17194 | amount-filled: 100.00%
	| epsilon: 0.3455861972150821
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2036, 3230, 1773, 1752, 1102, 3321, 1746, 2234]
	| approx positives in sample 512: 208
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 26, 25, 20, 11, 39, 29, 31]
	Time taken saving stuff: 0.01s
episode: 459/2000 -> reward: -124.99999999999261, steps:74400, time-taken: 2.90min, time-elasped: 1475.11min
-> berries picked: 91 of 800 | patches-visited: [1, 3, 7] | positive-in-buffer: 17253 | amount-filled: 100.00%
	| epsilon: 0.3453082093172431
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2049, 3238, 1780, 1748, 1100, 3344, 1755, 2239]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 35, 19, 12, 13, 38, 27, 37]
	Time taken saving stuff: 15.06s
episode: 460/2000 -> reward: -124.99999999999208, steps:57024, time-taken: 1.98min, time-elasped: 1477.34min
-> berries picked: 33 of 800 | patches-visited: [6] | positive-in-buffer: 17262 | amount-filled: 100.00%
	| epsilon: 0.34503044503155056
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2051, 3240, 1780, 1747, 1098, 3348, 1758, 2240]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [46, 36, 28, 12, 14, 48, 20, 25]
	Time taken saving stuff: 0.01s
episode: 461/2000 -> reward: -124.99999999998677, steps:71136, time-taken: 2.90min, time-elasped: 1480.24min
-> berries picked: 88 of 800 | patches-visited: [2, 4, 9] | positive-in-buffer: 17281 | amount-filled: 100.00%
	| epsilon: 0.3447529041781319
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2058, 3251, 1779, 1742, 1095, 3352, 1763, 2241]
	| approx positives in sample 512: 241
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 42, 19, 22, 13, 50, 29, 34]
	Time taken saving stuff: 0.12s
episode: 462/2000 -> reward: -124.99999999999203, steps:57216, time-taken: 1.98min, time-elasped: 1482.22min
-> berries picked: 32 of 800 | patches-visited: [7] | positive-in-buffer: 17280 | amount-filled: 100.00%
	| epsilon: 0.3444755865772593
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2060, 3257, 1780, 1736, 1092, 3351, 1761, 2243]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 45, 23, 20, 12, 47, 25, 32]
	Time taken saving stuff: 12.54s
episode: 463/2000 -> reward: -124.99999999999199, steps:57024, time-taken: 2.00min, time-elasped: 1484.43min
-> berries picked: 36 of 800 | patches-visited: [8] | positive-in-buffer: 17188 | amount-filled: 100.00%
	| epsilon: 0.3441984920493495
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2052, 3235, 1771, 1718, 1086, 3340, 1753, 2233]
	| approx positives in sample 512: 211
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 36, 18, 19, 10, 36, 31, 28]
	Time taken saving stuff: 0.11s
episode: 464/2000 -> reward: -124.99999999999183, steps:73728, time-taken: 3.05min, time-elasped: 1487.48min
-> berries picked: 92 of 800 | patches-visited: [4, 5, 9] | positive-in-buffer: 17203 | amount-filled: 100.00%
	| epsilon: 0.34392162041496355
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2059, 3237, 1772, 1713, 1075, 3348, 1763, 2236]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 42, 22, 19, 16, 45, 27, 26]
	Time taken saving stuff: 0.00s
episode: 465/2000 -> reward: -124.99999999999325, steps:58464, time-taken: 2.03min, time-elasped: 1489.51min
-> berries picked: 36 of 800 | patches-visited: [1, 4] | positive-in-buffer: 17198 | amount-filled: 100.00%
	| epsilon: 0.3436449714948071
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2061, 3241, 1772, 1708, 1066, 3348, 1763, 2239]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 33, 31, 12, 18, 44, 25, 25]
	Time taken saving stuff: 15.41s
episode: 466/2000 -> reward: -124.99999999999147, steps:70560, time-taken: 2.84min, time-elasped: 1492.61min
-> berries picked: 79 of 800 | patches-visited: [5, 8, 9] | positive-in-buffer: 17213 | amount-filled: 100.00%
	| epsilon: 0.34336854510972975
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2068, 3258, 1775, 1695, 1063, 3352, 1766, 2236]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 39, 27, 13, 23, 40, 34, 28]
	Time taken saving stuff: 0.00s
episode: 467/2000 -> reward: -124.99999999999125, steps:69408, time-taken: 2.79min, time-elasped: 1495.40min
-> berries picked: 74 of 800 | patches-visited: [1, 9] | positive-in-buffer: 17268 | amount-filled: 100.00%
	| epsilon: 0.3430923410807254
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2077, 3268, 1778, 1700, 1062, 3364, 1779, 2240]
	| approx positives in sample 512: 263
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [38, 44, 33, 26, 12, 52, 23, 35]
	Time taken saving stuff: 0.25s
episode: 468/2000 -> reward: -124.99999999999078, steps:68640, time-taken: 3.00min, time-elasped: 1498.40min
-> berries picked: 82 of 800 | patches-visited: [1, 2, 6] | positive-in-buffer: 17310 | amount-filled: 100.00%
	| epsilon: 0.34281635922893194
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2080, 3277, 1788, 1701, 1060, 3374, 1783, 2247]
	| approx positives in sample 512: 241
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 34, 30, 17, 20, 55, 18, 34]
	Time taken saving stuff: 12.42s
episode: 469/2000 -> reward: -124.999999999992, steps:53088, time-taken: 1.83min, time-elasped: 1500.44min
-> berries picked: 19 of 800 | patches-visited: [3] | positive-in-buffer: 17289 | amount-filled: 100.00%
	| epsilon: 0.34254059937563097
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2079, 3272, 1789, 1690, 1053, 3374, 1784, 2248]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 32, 21, 10, 20, 54, 21, 30]
	Time taken saving stuff: 0.04s
episode: 470/2000 -> reward: -124.99999999999176, steps:59136, time-taken: 2.03min, time-elasped: 1502.47min
-> berries picked: 45 of 800 | patches-visited: [9] | positive-in-buffer: 17247 | amount-filled: 100.00%
	| epsilon: 0.342265061342248
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2080, 3261, 1782, 1691, 1046, 3360, 1782, 2245]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 28, 19, 19, 11, 45, 17, 42]
	Time taken saving stuff: 0.00s
episode: 471/2000 -> reward: -124.99999999998997, steps:65856, time-taken: 2.22min, time-elasped: 1504.70min
-> berries picked: 61 of 800 | patches-visited: [0, 4, 8] | positive-in-buffer: 17227 | amount-filled: 100.00%
	| epsilon: 0.3419897449503521
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2081, 3271, 1779, 1678, 1039, 3359, 1775, 2245]
	| approx positives in sample 512: 202
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [37, 30, 17, 17, 10, 51, 21, 19]
	Time taken saving stuff: 15.35s
episode: 472/2000 -> reward: -124.99999999999217, steps:58080, time-taken: 1.79min, time-elasped: 1506.75min
-> berries picked: 40 of 800 | patches-visited: [8] | positive-in-buffer: 17112 | amount-filled: 100.00%
	| epsilon: 0.341714650021656
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2075, 3235, 1772, 1656, 1024, 3346, 1773, 2231]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 45, 20, 17, 10, 47, 30, 25]
	Time taken saving stuff: 0.01s
episode: 473/2000 -> reward: -124.99999999999059, steps:67296, time-taken: 2.78min, time-elasped: 1509.53min
-> berries picked: 76 of 800 | patches-visited: [2, 9] | positive-in-buffer: 17170 | amount-filled: 100.00%
	| epsilon: 0.3414397763780157
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2077, 3252, 1776, 1667, 1026, 3353, 1785, 2234]
	| approx positives in sample 512: 266
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 43, 27, 30, 17, 53, 22, 41]
	Time taken saving stuff: 0.09s
episode: 474/2000 -> reward: -124.99999999999156, steps:63456, time-taken: 2.17min, time-elasped: 1511.70min
-> berries picked: 56 of 800 | patches-visited: [3, 6, 7] | positive-in-buffer: 17208 | amount-filled: 100.00%
	| epsilon: 0.34116512384143055
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2080, 3259, 1777, 1672, 1028, 3359, 1795, 2238]
	| approx positives in sample 512: 206
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 34, 27, 28, 9, 44, 18, 23]
	Time taken saving stuff: 12.27s
episode: 475/2000 -> reward: -124.99999999999531, steps:80256, time-taken: 3.04min, time-elasped: 1514.95min
-> berries picked: 112 of 800 | patches-visited: [5, 6, 7] | positive-in-buffer: 17261 | amount-filled: 100.00%
	| epsilon: 0.34089069223404306
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2088, 3271, 1783, 1667, 1029, 3369, 1809, 2245]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 41, 25, 15, 6, 37, 40, 17]
	Time taken saving stuff: 0.12s
episode: 476/2000 -> reward: -124.99999999999379, steps:61728, time-taken: 2.06min, time-elasped: 1517.01min
-> berries picked: 47 of 800 | patches-visited: [1, 3] | positive-in-buffer: 17292 | amount-filled: 100.00%
	| epsilon: 0.3406164813781389
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2090, 3285, 1785, 1663, 1027, 3373, 1816, 2253]
	| approx positives in sample 512: 199
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 39, 18, 23, 15, 34, 27, 20]
	Time taken saving stuff: 0.01s
episode: 477/2000 -> reward: -124.9999999999925, steps:64608, time-taken: 2.11min, time-elasped: 1519.12min
-> berries picked: 49 of 800 | patches-visited: [0, 3, 9] | positive-in-buffer: 17265 | amount-filled: 100.00%
	| epsilon: 0.3403424910961465
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2092, 3280, 1788, 1654, 1022, 3368, 1812, 2249]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 37, 13, 23, 8, 45, 21, 40]
	Time taken saving stuff: 14.87s
episode: 478/2000 -> reward: -124.99999999999137, steps:56640, time-taken: 1.94min, time-elasped: 1521.31min
-> berries picked: 29 of 800 | patches-visited: [0, 9] | positive-in-buffer: 17212 | amount-filled: 100.00%
	| epsilon: 0.3400687212106374
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2093, 3276, 1785, 1632, 1017, 3365, 1808, 2236]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [38, 37, 31, 14, 14, 40, 17, 36]
	Time taken saving stuff: 0.01s
episode: 479/2000 -> reward: -124.99999999999211, steps:62688, time-taken: 2.04min, time-elasped: 1523.36min
-> berries picked: 56 of 800 | patches-visited: [0, 7] | positive-in-buffer: 17258 | amount-filled: 100.00%
	| epsilon: 0.3397951715443256
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2098, 3292, 1792, 1637, 1023, 3370, 1810, 2236]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 31, 17, 25, 15, 45, 21, 25]
	Time taken saving stuff: 0.09s
episode: 480/2000 -> reward: -124.99999999999085, steps:71424, time-taken: 2.94min, time-elasped: 1526.31min
-> berries picked: 82 of 800 | patches-visited: [1, 3, 5] | positive-in-buffer: 17278 | amount-filled: 100.00%
	| epsilon: 0.3395218419200679
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2101, 3302, 1802, 1631, 1018, 3369, 1817, 2238]
	| approx positives in sample 512: 240
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 38, 25, 26, 11, 47, 22, 41]
	Time taken saving stuff: 12.35s
episode: 481/2000 -> reward: -124.99999999999146, steps:56064, time-taken: 2.03min, time-elasped: 1528.54min
-> berries picked: 26 of 800 | patches-visited: [2, 4] | positive-in-buffer: 17288 | amount-filled: 100.00%
	| epsilon: 0.3392487321608635
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2102, 3302, 1803, 1630, 1017, 3368, 1824, 2242]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 38, 26, 16, 16, 49, 26, 31]
	Time taken saving stuff: 0.10s
episode: 482/2000 -> reward: -124.99999999999203, steps:58752, time-taken: 2.09min, time-elasped: 1530.63min
-> berries picked: 41 of 800 | patches-visited: [1] | positive-in-buffer: 17263 | amount-filled: 100.00%
	| epsilon: 0.33897584208985393
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2099, 3296, 1802, 1626, 1011, 3363, 1825, 2241]
	| approx positives in sample 512: 207
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 31, 18, 18, 14, 41, 33, 30]
	Time taken saving stuff: 0.01s
episode: 483/2000 -> reward: -124.99999999999255, steps:64896, time-taken: 2.13min, time-elasped: 1532.77min
-> berries picked: 56 of 800 | patches-visited: [2, 8] | positive-in-buffer: 17249 | amount-filled: 100.00%
	| epsilon: 0.3387031715303231
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2101, 3284, 1807, 1627, 1008, 3363, 1821, 2238]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [41, 36, 18, 21, 15, 32, 25, 30]
	Time taken saving stuff: 15.23s
episode: 484/2000 -> reward: -124.99999999998974, steps:73920, time-taken: 2.90min, time-elasped: 1535.92min
-> berries picked: 99 of 800 | patches-visited: [4, 9] | positive-in-buffer: 17240 | amount-filled: 100.00%
	| epsilon: 0.33843072030569704
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2096, 3284, 1798, 1625, 1011, 3369, 1825, 2232]
	| approx positives in sample 512: 249
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 38, 29, 29, 11, 54, 37, 19]
	Time taken saving stuff: 0.00s
episode: 485/2000 -> reward: -124.99999999999208, steps:55584, time-taken: 2.02min, time-elasped: 1537.95min
-> berries picked: 27 of 800 | patches-visited: [2] | positive-in-buffer: 17256 | amount-filled: 100.00%
	| epsilon: 0.33815848823954375
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2098, 3288, 1799, 1628, 1012, 3370, 1827, 2234]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 37, 16, 9, 11, 53, 19, 38]
	Time taken saving stuff: 0.02s
episode: 486/2000 -> reward: -124.99999999999203, steps:54240, time-taken: 1.80min, time-elasped: 1539.75min
-> berries picked: 24 of 800 | patches-visited: [3] | positive-in-buffer: 17268 | amount-filled: 100.00%
	| epsilon: 0.3378864751555732
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2097, 3290, 1800, 1627, 1014, 3373, 1831, 2236]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 36, 21, 21, 13, 39, 29, 32]
	Time taken saving stuff: 12.44s
episode: 487/2000 -> reward: -124.99999999999203, steps:56352, time-taken: 1.93min, time-elasped: 1541.89min
-> berries picked: 29 of 800 | patches-visited: [1] | positive-in-buffer: 17271 | amount-filled: 100.00%
	| epsilon: 0.3376146808776372
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2095, 3292, 1799, 1619, 1014, 3375, 1834, 2243]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 44, 15, 19, 19, 42, 24, 30]
	Time taken saving stuff: 0.00s
episode: 488/2000 -> reward: -124.9999999999916, steps:64896, time-taken: 2.07min, time-elasped: 1543.96min
-> berries picked: 65 of 800 | patches-visited: [7] | positive-in-buffer: 17288 | amount-filled: 100.00%
	| epsilon: 0.33734310522972916
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2099, 3307, 1800, 1616, 1012, 3376, 1836, 2242]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 37, 26, 21, 8, 52, 20, 26]
	Time taken saving stuff: 0.01s
episode: 489/2000 -> reward: -124.99999999998863, steps:70080, time-taken: 3.27min, time-elasped: 1547.24min
-> berries picked: 73 of 800 | patches-visited: [2, 4, 5] | positive-in-buffer: 17293 | amount-filled: 100.00%
	| epsilon: 0.33707174803598416
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2106, 3305, 1802, 1605, 1010, 3374, 1850, 2241]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 35, 26, 18, 15, 40, 36, 29]
	Time taken saving stuff: 15.01s
episode: 490/2000 -> reward: -124.99999999999235, steps:52608, time-taken: 2.06min, time-elasped: 1549.55min
-> berries picked: 17 of 800 | patches-visited: [8] | positive-in-buffer: 17300 | amount-filled: 100.00%
	| epsilon: 0.33680060912067866
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2106, 3306, 1802, 1608, 1010, 3375, 1852, 2241]
	| approx positives in sample 512: 247
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [37, 38, 22, 27, 11, 53, 32, 27]
	Time taken saving stuff: 0.00s
episode: 491/2000 -> reward: -124.9999999999898, steps:74016, time-taken: 2.90min, time-elasped: 1552.45min
-> berries picked: 96 of 800 | patches-visited: [0, 4, 5, 7] | positive-in-buffer: 17375 | amount-filled: 100.00%
	| epsilon: 0.3365296883082306
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2117, 3325, 1808, 1613, 1012, 3387, 1866, 2247]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 41, 20, 15, 21, 47, 23, 20]
	Time taken saving stuff: 0.10s
episode: 492/2000 -> reward: -124.9999999999928, steps:62688, time-taken: 2.09min, time-elasped: 1554.55min
-> berries picked: 58 of 800 | patches-visited: [0, 1, 3] | positive-in-buffer: 17380 | amount-filled: 100.00%
	| epsilon: 0.336258985423199
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2118, 3326, 1806, 1613, 1014, 3392, 1868, 2243]
	| approx positives in sample 512: 205
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 32, 21, 15, 12, 38, 27, 33]
	Time taken saving stuff: 12.05s
episode: 493/2000 -> reward: -124.99999999999203, steps:55680, time-taken: 1.89min, time-elasped: 1556.65min
-> berries picked: 23 of 800 | patches-visited: [7] | positive-in-buffer: 17317 | amount-filled: 100.00%
	| epsilon: 0.3359885002902841
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2112, 3309, 1801, 1606, 1005, 3382, 1866, 2236]
	| approx positives in sample 512: 239
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [36, 44, 23, 19, 12, 51, 24, 30]
	Time taken saving stuff: 0.03s
episode: 494/2000 -> reward: -124.99999999999125, steps:72672, time-taken: 2.89min, time-elasped: 1559.55min
-> berries picked: 87 of 800 | patches-visited: [0, 1, 6] | positive-in-buffer: 17392 | amount-filled: 100.00%
	| epsilon: 0.33571823273432716
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2117, 3339, 1809, 1614, 1006, 3389, 1878, 2240]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 38, 24, 18, 7, 51, 21, 30]
	Time taken saving stuff: 0.00s
episode: 495/2000 -> reward: -124.99999999999231, steps:69312, time-taken: 3.04min, time-elasped: 1562.58min
-> berries picked: 73 of 800 | patches-visited: [0, 3, 4, 9] | positive-in-buffer: 17430 | amount-filled: 100.00%
	| epsilon: 0.3354481825803103
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2119, 3351, 1813, 1611, 1004, 3395, 1890, 2247]
	| approx positives in sample 512: 242
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 48, 28, 16, 13, 52, 28, 37]
	Time taken saving stuff: 15.18s
episode: 496/2000 -> reward: -124.99999999999021, steps:55968, time-taken: 2.18min, time-elasped: 1565.02min
-> berries picked: 30 of 800 | patches-visited: [1, 3] | positive-in-buffer: 17450 | amount-filled: 100.00%
	| epsilon: 0.3351783496533564
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2120, 3359, 1814, 1616, 1005, 3397, 1891, 2248]
	| approx positives in sample 512: 243
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 37, 20, 31, 11, 55, 35, 23]
	Time taken saving stuff: 0.01s
episode: 497/2000 -> reward: -124.99999999999201, steps:49536, time-taken: 1.96min, time-elasped: 1566.98min
-> berries picked: 7 of 800 | patches-visited: [7] | positive-in-buffer: 17384 | amount-filled: 100.00%
	| epsilon: 0.33490873377872904
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2113, 3342, 1803, 1607, 1004, 3394, 1878, 2243]
	| approx positives in sample 512: 249
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 44, 22, 23, 8, 47, 30, 45]
	Time taken saving stuff: 0.11s
episode: 498/2000 -> reward: -124.99999999999363, steps:66336, time-taken: 2.77min, time-elasped: 1569.75min
-> berries picked: 69 of 800 | patches-visited: [5, 7] | positive-in-buffer: 17433 | amount-filled: 100.00%
	| epsilon: 0.3346393347818324
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2118, 3352, 1812, 1606, 1006, 3403, 1889, 2247]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 41, 15, 25, 12, 57, 32, 22]
	Time taken saving stuff: 12.47s
episode: 499/2000 -> reward: -124.9999999999923, steps:58176, time-taken: 2.36min, time-elasped: 1572.32min
-> berries picked: 35 of 800 | patches-visited: [1] | positive-in-buffer: 17454 | amount-filled: 100.00%
	| epsilon: 0.33437015248821106
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2121, 3360, 1812, 1601, 1007, 3411, 1893, 2249]
	| approx positives in sample 512: 238
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 59, 21, 22, 11, 40, 18, 34]
	Time taken saving stuff: 0.10s
episode: 500/2000 -> reward: -124.99999999999204, steps:55296, time-taken: 1.91min, time-elasped: 1574.24min
-> berries picked: 27 of 800 | patches-visited: [1] | positive-in-buffer: 17348 | amount-filled: 100.00%
	| epsilon: 0.3341011867235499
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2107, 3337, 1798, 1589, 1001, 3393, 1892, 2231]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 49, 22, 18, 10, 38, 41, 31]
	Time taken saving stuff: 0.00s
episode: 501/2000 -> reward: -124.99999999999268, steps:55104, time-taken: 2.16min, time-elasped: 1576.40min
-> berries picked: 27 of 800 | patches-visited: [2, 7] | positive-in-buffer: 17359 | amount-filled: 100.00%
	| epsilon: 0.333832437313674
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2108, 3339, 1805, 1587, 1000, 3393, 1896, 2231]
	| approx positives in sample 512: 204
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 33, 28, 17, 10, 52, 23, 23]
	Time taken saving stuff: 15.14s
episode: 502/2000 -> reward: -124.9999999999936, steps:72192, time-taken: 2.82min, time-elasped: 1579.48min
-> berries picked: 85 of 800 | patches-visited: [4, 7, 8] | positive-in-buffer: 17369 | amount-filled: 100.00%
	| epsilon: 0.3335639040845487
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2109, 3344, 1799, 1576, 996, 3404, 1907, 2234]
	| approx positives in sample 512: 237
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 36, 17, 19, 4, 65, 33, 39]
	Time taken saving stuff: 0.01s
episode: 503/2000 -> reward: -124.99999999999254, steps:53184, time-taken: 2.12min, time-elasped: 1581.60min
-> berries picked: 20 of 800 | patches-visited: [8] | positive-in-buffer: 17384 | amount-filled: 100.00%
	| epsilon: 0.3332955868622792
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2111, 3346, 1801, 1579, 996, 3407, 1908, 2236]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 28, 22, 31, 12, 46, 21, 35]
	Time taken saving stuff: 0.01s
episode: 504/2000 -> reward: -124.99999999999203, steps:54432, time-taken: 1.91min, time-elasped: 1583.51min
-> berries picked: 25 of 800 | patches-visited: [4] | positive-in-buffer: 17364 | amount-filled: 100.00%
	| epsilon: 0.33302748547311056
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2114, 3344, 1798, 1577, 993, 3402, 1907, 2229]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 42, 30, 17, 10, 45, 22, 32]
	Time taken saving stuff: 12.18s
episode: 505/2000 -> reward: -124.99999999999227, steps:56928, time-taken: 2.01min, time-elasped: 1585.72min
-> berries picked: 34 of 800 | patches-visited: [2] | positive-in-buffer: 17344 | amount-filled: 100.00%
	| epsilon: 0.3327595997434277
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2113, 3343, 1793, 1572, 992, 3399, 1906, 2226]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 33, 16, 15, 9, 67, 26, 36]
	Time taken saving stuff: 0.02s
episode: 506/2000 -> reward: -124.9999999999929, steps:62688, time-taken: 2.10min, time-elasped: 1587.82min
-> berries picked: 53 of 800 | patches-visited: [2, 3] | positive-in-buffer: 17328 | amount-filled: 100.00%
	| epsilon: 0.33249192949975526
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2107, 3338, 1786, 1567, 987, 3405, 1907, 2231]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 45, 23, 11, 13, 45, 24, 33]
	Time taken saving stuff: 0.01s
episode: 507/2000 -> reward: -124.99999999998674, steps:65760, time-taken: 2.35min, time-elasped: 1590.17min
-> berries picked: 61 of 800 | patches-visited: [0, 1, 2] | positive-in-buffer: 17320 | amount-filled: 100.00%
	| epsilon: 0.3322244745687571
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2116, 3334, 1780, 1561, 983, 3407, 1916, 2223]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 38, 25, 18, 14, 44, 27, 32]
	Time taken saving stuff: 14.75s
episode: 508/2000 -> reward: -124.99999999998744, steps:63360, time-taken: 2.03min, time-elasped: 1592.44min
-> berries picked: 58 of 800 | patches-visited: [4, 8] | positive-in-buffer: 17298 | amount-filled: 100.00%
	| epsilon: 0.3319572347772368
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2119, 3321, 1777, 1562, 981, 3404, 1916, 2218]
	| approx positives in sample 512: 205
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 26, 16, 20, 12, 46, 24, 33]
	Time taken saving stuff: 0.01s
episode: 509/2000 -> reward: -124.99999999999046, steps:56928, time-taken: 2.28min, time-elasped: 1594.73min
-> berries picked: 42 of 800 | patches-visited: [5] | positive-in-buffer: 17298 | amount-filled: 100.00%
	| epsilon: 0.33169020995213727
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2116, 3313, 1776, 1561, 984, 3408, 1919, 2221]
	| approx positives in sample 512: 233
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [40, 46, 25, 16, 12, 44, 21, 29]
	Time taken saving stuff: 0.03s
episode: 510/2000 -> reward: -124.99999999999203, steps:54240, time-taken: 1.88min, time-elasped: 1596.61min
-> berries picked: 22 of 800 | patches-visited: [1] | positive-in-buffer: 17305 | amount-filled: 100.00%
	| epsilon: 0.3314233999205405
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2119, 3315, 1778, 1560, 980, 3408, 1925, 2220]
	| approx positives in sample 512: 211
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 32, 24, 13, 10, 35, 33, 35]
	Time taken saving stuff: 12.14s
episode: 511/2000 -> reward: -124.99999999998936, steps:66336, time-taken: 2.80min, time-elasped: 1599.61min
-> berries picked: 67 of 800 | patches-visited: [3, 7] | positive-in-buffer: 17352 | amount-filled: 100.00%
	| epsilon: 0.33115680450966756
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2126, 3323, 1781, 1562, 981, 3418, 1935, 2226]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 35, 24, 13, 11, 47, 28, 33]
	Time taken saving stuff: 0.08s
episode: 512/2000 -> reward: -124.9999999999932, steps:55584, time-taken: 2.17min, time-elasped: 1601.79min
-> berries picked: 32 of 800 | patches-visited: [0] | positive-in-buffer: 17351 | amount-filled: 100.00%
	| epsilon: 0.33089042354687864
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2128, 3324, 1782, 1560, 979, 3418, 1933, 2227]
	| approx positives in sample 512: 245
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 43, 21, 18, 14, 51, 30, 35]
	Time taken saving stuff: 0.00s
episode: 513/2000 -> reward: -124.99999999999146, steps:58656, time-taken: 2.08min, time-elasped: 1603.86min
-> berries picked: 34 of 800 | patches-visited: [6, 8] | positive-in-buffer: 17288 | amount-filled: 100.00%
	| epsilon: 0.3306242568596726
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2120, 3311, 1770, 1543, 978, 3411, 1936, 2219]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [37, 40, 22, 22, 13, 46, 31, 20]
	Time taken saving stuff: 15.29s
episode: 514/2000 -> reward: -124.99999999999203, steps:51936, time-taken: 2.06min, time-elasped: 1606.18min
-> berries picked: 14 of 800 | patches-visited: [5] | positive-in-buffer: 17217 | amount-filled: 100.00%
	| epsilon: 0.33035830427568735
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2118, 3295, 1760, 1533, 974, 3400, 1929, 2208]
	| approx positives in sample 512: 236
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [40, 30, 24, 21, 14, 49, 28, 30]
	Time taken saving stuff: 0.01s
episode: 515/2000 -> reward: -124.99999999999203, steps:59808, time-taken: 2.08min, time-elasped: 1608.26min
-> berries picked: 38 of 800 | patches-visited: [5] | positive-in-buffer: 17248 | amount-filled: 100.00%
	| epsilon: 0.3300925656226991
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2121, 3300, 1763, 1540, 975, 3404, 1936, 2209]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 35, 16, 14, 10, 56, 25, 31]
	Time taken saving stuff: 0.10s
episode: 516/2000 -> reward: -124.99999999998978, steps:73824, time-taken: 3.18min, time-elasped: 1611.44min
-> berries picked: 91 of 800 | patches-visited: [1, 5, 6] | positive-in-buffer: 17285 | amount-filled: 100.00%
	| epsilon: 0.3298270407286229
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2133, 3306, 1764, 1541, 974, 3404, 1949, 2214]
	| approx positives in sample 512: 233
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 32, 18, 27, 18, 50, 26, 38]
	Time taken saving stuff: 12.05s
episode: 517/2000 -> reward: -124.99999999999203, steps:53376, time-taken: 2.04min, time-elasped: 1613.69min
-> berries picked: 20 of 800 | patches-visited: [4] | positive-in-buffer: 17295 | amount-filled: 100.00%
	| epsilon: 0.3295617294215121
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2133, 3314, 1763, 1540, 973, 3405, 1952, 2215]
	| approx positives in sample 512: 226
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 34, 28, 18, 15, 41, 27, 39]
	Time taken saving stuff: 0.03s
episode: 518/2000 -> reward: -124.99999999999201, steps:52032, time-taken: 1.88min, time-elasped: 1615.56min
-> berries picked: 15 of 800 | patches-visited: [8] | positive-in-buffer: 17275 | amount-filled: 100.00%
	| epsilon: 0.3292966315295582
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2131, 3312, 1760, 1538, 972, 3400, 1951, 2211]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 37, 17, 20, 14, 51, 26, 28]
	Time taken saving stuff: 0.01s
episode: 519/2000 -> reward: -124.99999999999154, steps:57792, time-taken: 2.06min, time-elasped: 1617.63min
-> berries picked: 39 of 800 | patches-visited: [4, 5] | positive-in-buffer: 17287 | amount-filled: 100.00%
	| epsilon: 0.32903174688109116
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2134, 3311, 1758, 1541, 969, 3403, 1957, 2214]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 39, 13, 15, 9, 53, 27, 32]
	Time taken saving stuff: 15.16s
episode: 520/2000 -> reward: -124.99999999998678, steps:62688, time-taken: 2.25min, time-elasped: 1620.14min
-> berries picked: 59 of 800 | patches-visited: [2, 3] | positive-in-buffer: 17262 | amount-filled: 100.00%
	| epsilon: 0.328767075304579
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2130, 3313, 1746, 1536, 967, 3398, 1957, 2215]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 26, 18, 18, 10, 50, 40, 25]
	Time taken saving stuff: 0.01s
episode: 521/2000 -> reward: -124.99999999998894, steps:65088, time-taken: 2.31min, time-elasped: 1622.44min
-> berries picked: 61 of 800 | patches-visited: [1, 2] | positive-in-buffer: 17242 | amount-filled: 100.00%
	| epsilon: 0.32850261662862756
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2131, 3301, 1744, 1533, 964, 3409, 1953, 2207]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 35, 18, 23, 15, 47, 24, 32]
	Time taken saving stuff: 0.11s
episode: 522/2000 -> reward: -124.99999999999221, steps:52896, time-taken: 1.90min, time-elasped: 1624.35min
-> berries picked: 19 of 800 | patches-visited: [9] | positive-in-buffer: 17109 | amount-filled: 100.00%
	| epsilon: 0.32823837068198064
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2119, 3268, 1735, 1506, 957, 3392, 1944, 2188]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 38, 24, 19, 14, 43, 26, 31]
	Time taken saving stuff: 11.84s
episode: 523/2000 -> reward: -124.99999999999079, steps:71328, time-taken: 2.91min, time-elasped: 1627.46min
-> berries picked: 84 of 800 | patches-visited: [3, 4] | positive-in-buffer: 17168 | amount-filled: 100.00%
	| epsilon: 0.3279743372935198
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2123, 3281, 1742, 1512, 958, 3402, 1953, 2197]
	| approx positives in sample 512: 237
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 50, 17, 13, 18, 39, 34, 34]
	Time taken saving stuff: 0.03s
episode: 524/2000 -> reward: -124.99999999999332, steps:63168, time-taken: 2.11min, time-elasped: 1629.58min
-> berries picked: 57 of 800 | patches-visited: [1, 6] | positive-in-buffer: 17206 | amount-filled: 100.00%
	| epsilon: 0.32771051629226433
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2128, 3290, 1744, 1512, 959, 3410, 1961, 2202]
	| approx positives in sample 512: 190
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 34, 20, 14, 10, 34, 28, 23]
	Time taken saving stuff: 0.01s
episode: 525/2000 -> reward: -124.99999999999385, steps:67584, time-taken: 2.85min, time-elasped: 1632.43min
-> berries picked: 64 of 800 | patches-visited: [1, 5] | positive-in-buffer: 17182 | amount-filled: 100.00%
	| epsilon: 0.3274469075073709
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2134, 3283, 1737, 1508, 957, 3399, 1968, 2196]
	| approx positives in sample 512: 241
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 31, 25, 17, 15, 47, 32, 41]
	Time taken saving stuff: 15.06s
episode: 526/2000 -> reward: -124.99999999999274, steps:66816, time-taken: 2.83min, time-elasped: 1635.52min
-> berries picked: 66 of 800 | patches-visited: [4, 7] | positive-in-buffer: 17230 | amount-filled: 100.00%
	| epsilon: 0.3271835107681336
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2141, 3297, 1741, 1510, 957, 3405, 1972, 2207]
	| approx positives in sample 512: 240
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 39, 29, 19, 9, 56, 27, 31]
	Time taken saving stuff: 0.00s
episode: 527/2000 -> reward: -124.99999999998425, steps:84096, time-taken: 3.39min, time-elasped: 1638.91min
-> berries picked: 132 of 800 | patches-visited: [3, 6, 9] | positive-in-buffer: 17329 | amount-filled: 100.00%
	| epsilon: 0.32692032590398407
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2151, 3313, 1749, 1523, 962, 3419, 1985, 2227]
	| approx positives in sample 512: 207
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 32, 28, 16, 11, 40, 26, 26]
	Time taken saving stuff: 0.09s
episode: 528/2000 -> reward: -124.99999999999234, steps:56160, time-taken: 1.90min, time-elasped: 1640.81min
-> berries picked: 27 of 800 | patches-visited: [9] | positive-in-buffer: 17252 | amount-filled: 100.00%
	| epsilon: 0.32665735274449087
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2138, 3299, 1735, 1513, 960, 3406, 1986, 2215]
	| approx positives in sample 512: 236
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 40, 31, 20, 12, 45, 32, 31]
	Time taken saving stuff: 12.41s
episode: 529/2000 -> reward: -124.99999999999451, steps:79200, time-taken: 3.20min, time-elasped: 1644.23min
-> berries picked: 124 of 800 | patches-visited: [4, 6] | positive-in-buffer: 17341 | amount-filled: 100.00%
	| epsilon: 0.3263945911193598
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2144, 3326, 1749, 1515, 963, 3421, 1998, 2225]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 37, 22, 17, 11, 45, 32, 31]
	Time taken saving stuff: 0.01s
episode: 530/2000 -> reward: -124.99999999998818, steps:59616, time-taken: 2.28min, time-elasped: 1646.51min
-> berries picked: 45 of 800 | patches-visited: [2, 4] | positive-in-buffer: 17312 | amount-filled: 100.00%
	| epsilon: 0.32613204085843367
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2142, 3315, 1746, 1514, 957, 3421, 1992, 2225]
	| approx positives in sample 512: 234
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 52, 23, 14, 12, 38, 36, 27]
	Time taken saving stuff: 0.00s
episode: 531/2000 -> reward: -124.99999999999083, steps:61344, time-taken: 2.06min, time-elasped: 1648.57min
-> berries picked: 46 of 800 | patches-visited: [0, 4] | positive-in-buffer: 17269 | amount-filled: 100.00%
	| epsilon: 0.3258697017916921
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2141, 3303, 1738, 1509, 953, 3416, 1989, 2220]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 33, 25, 15, 11, 32, 29, 38]
	Time taken saving stuff: 15.52s
episode: 532/2000 -> reward: -124.99999999999253, steps:59808, time-taken: 1.98min, time-elasped: 1650.81min
-> berries picked: 46 of 800 | patches-visited: [5] | positive-in-buffer: 17142 | amount-filled: 100.00%
	| epsilon: 0.3256075737492514
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2135, 3261, 1715, 1485, 952, 3402, 1980, 2212]
	| approx positives in sample 512: 223
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 39, 20, 13, 9, 43, 30, 39]
	Time taken saving stuff: 0.11s
episode: 533/2000 -> reward: -124.99999999999348, steps:58656, time-taken: 2.12min, time-elasped: 1652.93min
-> berries picked: 40 of 800 | patches-visited: [9] | positive-in-buffer: 17096 | amount-filled: 100.00%
	| epsilon: 0.3253456565613648
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2130, 3252, 1706, 1477, 948, 3395, 1980, 2208]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 37, 15, 21, 18, 46, 30, 21]
	Time taken saving stuff: 0.10s
episode: 534/2000 -> reward: -124.99999999999332, steps:62880, time-taken: 2.14min, time-elasped: 1655.07min
-> berries picked: 56 of 800 | patches-visited: [6] | positive-in-buffer: 17090 | amount-filled: 100.00%
	| epsilon: 0.3250839500584218
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2131, 3244, 1706, 1478, 951, 3390, 1981, 2209]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 31, 22, 20, 13, 43, 30, 26]
	Time taken saving stuff: 11.89s
episode: 535/2000 -> reward: -124.9999999999936, steps:65376, time-taken: 2.19min, time-elasped: 1657.46min
-> berries picked: 55 of 800 | patches-visited: [1, 8] | positive-in-buffer: 17030 | amount-filled: 100.00%
	| epsilon: 0.32482245407094834
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2125, 3219, 1688, 1470, 946, 3389, 1981, 2212]
	| approx positives in sample 512: 194
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 35, 21, 13, 11, 35, 26, 26]
	Time taken saving stuff: 0.09s
episode: 536/2000 -> reward: -124.99999999999218, steps:57504, time-taken: 1.85min, time-elasped: 1659.32min
-> berries picked: 35 of 800 | patches-visited: [8] | positive-in-buffer: 16985 | amount-filled: 100.00%
	| epsilon: 0.3245611684296069
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2116, 3203, 1685, 1469, 943, 3380, 1981, 2208]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 36, 26, 19, 9, 46, 23, 30]
	Time taken saving stuff: 0.11s
episode: 537/2000 -> reward: -124.9999999999901, steps:76512, time-taken: 2.95min, time-elasped: 1662.27min
-> berries picked: 100 of 800 | patches-visited: [1, 2, 5, 7] | positive-in-buffer: 17069 | amount-filled: 100.00%
	| epsilon: 0.3243000929651961
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2119, 3217, 1694, 1484, 944, 3402, 1990, 2219]
	| approx positives in sample 512: 230
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 51, 21, 11, 13, 48, 24, 38]
	Time taken saving stuff: 15.10s
episode: 538/2000 -> reward: -124.99999999999179, steps:78912, time-taken: 3.15min, time-elasped: 1665.68min
-> berries picked: 112 of 800 | patches-visited: [1, 5, 9] | positive-in-buffer: 17128 | amount-filled: 100.00%
	| epsilon: 0.3240392275086504
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2127, 3227, 1693, 1490, 944, 3416, 2002, 2229]
	| approx positives in sample 512: 207
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 29, 25, 20, 6, 49, 26, 29]
	Time taken saving stuff: 0.10s
episode: 539/2000 -> reward: -124.99999999999204, steps:70080, time-taken: 2.98min, time-elasped: 1668.66min
-> berries picked: 74 of 800 | patches-visited: [4, 6] | positive-in-buffer: 17098 | amount-filled: 100.00%
	| epsilon: 0.32377857189104065
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2116, 3222, 1694, 1476, 940, 3412, 2003, 2235]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 40, 22, 15, 10, 50, 38, 24]
	Time taken saving stuff: 0.11s
episode: 540/2000 -> reward: -124.999999999983, steps:79968, time-taken: 3.15min, time-elasped: 1671.82min
-> berries picked: 128 of 800 | patches-visited: [5, 7] | positive-in-buffer: 17180 | amount-filled: 100.00%
	| epsilon: 0.3235181259435734
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2121, 3240, 1702, 1482, 942, 3428, 2018, 2247]
	| approx positives in sample 512: 208
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 44, 28, 15, 7, 37, 24, 23]
	Time taken saving stuff: 12.35s
episode: 541/2000 -> reward: -124.99999999999191, steps:62112, time-taken: 2.03min, time-elasped: 1674.06min
-> berries picked: 58 of 800 | patches-visited: [4] | positive-in-buffer: 17105 | amount-filled: 100.00%
	| epsilon: 0.3232578894975908
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2115, 3228, 1694, 1470, 937, 3407, 2017, 2237]
	| approx positives in sample 512: 195
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 37, 17, 18, 9, 38, 30, 27]
	Time taken saving stuff: 0.02s
episode: 542/2000 -> reward: -124.99999999999172, steps:62400, time-taken: 2.02min, time-elasped: 1676.09min
-> berries picked: 49 of 800 | patches-visited: [0] | positive-in-buffer: 16909 | amount-filled: 100.00%
	| epsilon: 0.32299786238457107
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2099, 3171, 1675, 1438, 916, 3381, 2002, 2227]
	| approx positives in sample 512: 194
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 33, 23, 8, 8, 47, 14, 31]
	Time taken saving stuff: 0.09s
episode: 543/2000 -> reward: -124.99999999998383, steps:81792, time-taken: 3.21min, time-elasped: 1679.30min
-> berries picked: 134 of 800 | patches-visited: [0, 5, 6] | positive-in-buffer: 16960 | amount-filled: 100.00%
	| epsilon: 0.3227380444361277
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2105, 3166, 1675, 1448, 913, 3393, 2015, 2245]
	| approx positives in sample 512: 208
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 35, 15, 18, 12, 43, 25, 35]
	Time taken saving stuff: 15.01s
episode: 544/2000 -> reward: -124.99999999999022, steps:58656, time-taken: 2.07min, time-elasped: 1681.62min
-> berries picked: 43 of 800 | patches-visited: [4] | positive-in-buffer: 16932 | amount-filled: 100.00%
	| epsilon: 0.3224784354840096
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2106, 3163, 1675, 1434, 910, 3393, 2010, 2241]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 36, 19, 17, 11, 46, 25, 33]
	Time taken saving stuff: 0.09s
episode: 545/2000 -> reward: -124.99999999999187, steps:63456, time-taken: 2.14min, time-elasped: 1683.76min
-> berries picked: 61 of 800 | patches-visited: [0] | positive-in-buffer: 16923 | amount-filled: 100.00%
	| epsilon: 0.32221903536010127
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2100, 3159, 1670, 1432, 910, 3394, 2012, 2246]
	| approx positives in sample 512: 192
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 33, 20, 14, 16, 41, 21, 26]
	Time taken saving stuff: 0.00s
episode: 546/2000 -> reward: -124.9999999999923, steps:66336, time-taken: 2.93min, time-elasped: 1686.69min
-> berries picked: 76 of 800 | patches-visited: [8] | positive-in-buffer: 16909 | amount-filled: 100.00%
	| epsilon: 0.3219598438964222
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2097, 3164, 1667, 1428, 907, 3391, 2013, 2242]
	| approx positives in sample 512: 261
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 55, 26, 13, 15, 65, 31, 30]
	Time taken saving stuff: 12.94s
episode: 547/2000 -> reward: -124.99999999999191, steps:60192, time-taken: 1.91min, time-elasped: 1688.82min
-> berries picked: 44 of 800 | patches-visited: [9] | positive-in-buffer: 16939 | amount-filled: 100.00%
	| epsilon: 0.32170086092512706
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2103, 3171, 1671, 1432, 908, 3391, 2016, 2247]
	| approx positives in sample 512: 193
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 28, 19, 12, 11, 52, 20, 32]
	Time taken saving stuff: 0.00s
episode: 548/2000 -> reward: -124.99999999999204, steps:54624, time-taken: 2.04min, time-elasped: 1690.86min
-> berries picked: 25 of 800 | patches-visited: [3] | positive-in-buffer: 16916 | amount-filled: 100.00%
	| epsilon: 0.3214420862785057
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2101, 3167, 1667, 1422, 905, 3393, 2017, 2244]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [38, 39, 14, 24, 8, 51, 30, 28]
	Time taken saving stuff: 0.03s
episode: 549/2000 -> reward: -124.99999999999298, steps:65088, time-taken: 2.23min, time-elasped: 1693.09min
-> berries picked: 67 of 800 | patches-visited: [4, 5] | positive-in-buffer: 16960 | amount-filled: 100.00%
	| epsilon: 0.3211835197889826
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2105, 3179, 1669, 1426, 906, 3400, 2019, 2256]
	| approx positives in sample 512: 210
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 41, 19, 11, 11, 48, 34, 29]
	Time taken saving stuff: 15.47s
episode: 550/2000 -> reward: -124.99999999998909, steps:81600, time-taken: 3.06min, time-elasped: 1696.41min
-> berries picked: 131 of 800 | patches-visited: [7, 8, 9] | positive-in-buffer: 16946 | amount-filled: 100.00%
	| epsilon: 0.3209251612891172
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2108, 3167, 1659, 1428, 905, 3400, 2024, 2255]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 27, 20, 21, 9, 41, 36, 31]
	Time taken saving stuff: 0.01s
episode: 551/2000 -> reward: -124.99999999999336, steps:83616, time-taken: 3.15min, time-elasped: 1699.57min
-> berries picked: 144 of 800 | patches-visited: [1, 7] | positive-in-buffer: 17026 | amount-filled: 100.00%
	| epsilon: 0.32066701061160363
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2118, 3182, 1662, 1434, 910, 3419, 2030, 2271]
	| approx positives in sample 512: 190
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 34, 14, 26, 7, 38, 23, 20]
	Time taken saving stuff: 0.01s
episode: 552/2000 -> reward: -124.99999999999201, steps:56256, time-taken: 2.03min, time-elasped: 1701.60min
-> berries picked: 30 of 800 | patches-visited: [2] | positive-in-buffer: 16890 | amount-filled: 100.00%
	| epsilon: 0.3204090675892706
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2099, 3145, 1658, 1412, 900, 3393, 2019, 2264]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 23, 24, 17, 12, 51, 29, 31]
	Time taken saving stuff: 12.05s
episode: 553/2000 -> reward: -124.9999999999936, steps:70560, time-taken: 2.97min, time-elasped: 1704.78min
-> berries picked: 92 of 800 | patches-visited: [4, 6] | positive-in-buffer: 16944 | amount-filled: 100.00%
	| epsilon: 0.3201513320550813
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2107, 3154, 1659, 1418, 907, 3402, 2030, 2267]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 41, 27, 15, 15, 43, 27, 36]
	Time taken saving stuff: 0.00s
episode: 554/2000 -> reward: -124.99999999999172, steps:66336, time-taken: 2.90min, time-elasped: 1707.68min
-> berries picked: 67 of 800 | patches-visited: [2] | positive-in-buffer: 16968 | amount-filled: 100.00%
	| epsilon: 0.3198938038421331
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2111, 3159, 1662, 1418, 904, 3406, 2037, 2271]
	| approx positives in sample 512: 238
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 36, 24, 13, 15, 50, 25, 40]
	Time taken saving stuff: 0.08s
episode: 555/2000 -> reward: -124.99999999999201, steps:56640, time-taken: 2.18min, time-elasped: 1709.86min
-> berries picked: 28 of 800 | patches-visited: [5, 8] | positive-in-buffer: 16964 | amount-filled: 100.00%
	| epsilon: 0.3196364827836579
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2112, 3153, 1662, 1417, 900, 3408, 2038, 2274]
	| approx positives in sample 512: 204
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 35, 14, 9, 7, 50, 22, 34]
	Time taken saving stuff: 15.16s
episode: 556/2000 -> reward: -124.99999999999204, steps:66432, time-taken: 2.76min, time-elasped: 1712.87min
-> berries picked: 73 of 800 | patches-visited: [8] | positive-in-buffer: 16914 | amount-filled: 100.00%
	| epsilon: 0.31937936871302164
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2111, 3136, 1647, 1415, 896, 3395, 2034, 2280]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 34, 21, 17, 11, 46, 25, 34]
	Time taken saving stuff: 0.19s
episode: 557/2000 -> reward: -124.99999999999014, steps:77280, time-taken: 3.08min, time-elasped: 1715.95min
-> berries picked: 107 of 800 | patches-visited: [3, 5, 8] | positive-in-buffer: 16974 | amount-filled: 100.00%
	| epsilon: 0.31912246146372425
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2114, 3159, 1654, 1418, 899, 3407, 2039, 2284]
	| approx positives in sample 512: 208
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 50, 12, 13, 12, 31, 36, 29]
	Time taken saving stuff: 0.00s
episode: 558/2000 -> reward: -124.99999999999186, steps:63360, time-taken: 2.38min, time-elasped: 1718.34min
-> berries picked: 58 of 800 | patches-visited: [8] | positive-in-buffer: 16957 | amount-filled: 100.00%
	| epsilon: 0.3188657608693996
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2115, 3156, 1650, 1407, 899, 3405, 2039, 2286]
	| approx positives in sample 512: 204
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 35, 21, 14, 14, 44, 24, 24]
	Time taken saving stuff: 12.62s
episode: 559/2000 -> reward: -124.99999999999386, steps:65952, time-taken: 2.11min, time-elasped: 1720.66min
-> berries picked: 74 of 800 | patches-visited: [2, 8] | positive-in-buffer: 16869 | amount-filled: 100.00%
	| epsilon: 0.3186092667638154
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2104, 3122, 1635, 1389, 896, 3401, 2034, 2288]
	| approx positives in sample 512: 206
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 41, 17, 8, 15, 51, 25, 28]
	Time taken saving stuff: 0.01s
episode: 560/2000 -> reward: -124.99999999999352, steps:64416, time-taken: 2.30min, time-elasped: 1722.97min
-> berries picked: 58 of 800 | patches-visited: [2, 7] | positive-in-buffer: 16841 | amount-filled: 100.00%
	| epsilon: 0.31835297898087317
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2103, 3112, 1632, 1382, 894, 3390, 2038, 2290]
	| approx positives in sample 512: 201
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 35, 12, 22, 6, 39, 31, 31]
	Time taken saving stuff: 0.10s
episode: 561/2000 -> reward: -124.99999999999203, steps:66528, time-taken: 2.86min, time-elasped: 1725.84min
-> berries picked: 67 of 800 | patches-visited: [9] | positive-in-buffer: 16848 | amount-filled: 100.00%
	| epsilon: 0.3180968973546079
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2102, 3110, 1635, 1380, 892, 3396, 2038, 2295]
	| approx positives in sample 512: 253
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [43, 43, 26, 16, 15, 46, 34, 30]
	Time taken saving stuff: 15.08s
episode: 562/2000 -> reward: -124.99999999999073, steps:78240, time-taken: 2.94min, time-elasped: 1729.03min
-> berries picked: 107 of 800 | patches-visited: [3, 9] | positive-in-buffer: 16926 | amount-filled: 100.00%
	| epsilon: 0.3178410217191881
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2109, 3129, 1641, 1388, 894, 3408, 2049, 2308]
	| approx positives in sample 512: 233
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 43, 25, 25, 15, 42, 23, 36]
	Time taken saving stuff: 0.11s
episode: 563/2000 -> reward: -124.99999999998664, steps:77568, time-taken: 3.12min, time-elasped: 1732.15min
-> berries picked: 124 of 800 | patches-visited: [1, 2] | positive-in-buffer: 16964 | amount-filled: 100.00%
	| epsilon: 0.31758535190891574
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2115, 3137, 1647, 1378, 893, 3415, 2059, 2320]
	| approx positives in sample 512: 241
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [40, 37, 21, 17, 13, 52, 23, 38]
	Time taken saving stuff: 0.01s
episode: 564/2000 -> reward: -124.99999999999228, steps:76992, time-taken: 3.17min, time-elasped: 1735.33min
-> berries picked: 108 of 800 | patches-visited: [1, 2, 8] | positive-in-buffer: 16961 | amount-filled: 100.00%
	| epsilon: 0.3173298877582261
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2120, 3133, 1646, 1367, 890, 3421, 2061, 2323]
	| approx positives in sample 512: 206
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 36, 17, 21, 10, 42, 29, 24]
	Time taken saving stuff: 11.93s
episode: 565/2000 -> reward: -124.99999999999189, steps:65472, time-taken: 2.14min, time-elasped: 1737.67min
-> berries picked: 74 of 800 | patches-visited: [0] | positive-in-buffer: 16926 | amount-filled: 100.00%
	| epsilon: 0.31707462910168754
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2119, 3113, 1641, 1353, 893, 3422, 2063, 2322]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 25, 18, 18, 11, 59, 20, 42]
	Time taken saving stuff: 0.00s
episode: 566/2000 -> reward: -124.99999999999358, steps:66720, time-taken: 2.93min, time-elasped: 1740.60min
-> berries picked: 75 of 800 | patches-visited: [3] | positive-in-buffer: 16831 | amount-filled: 100.00%
	| epsilon: 0.31681957577400155
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2107, 3089, 1618, 1352, 888, 3410, 2053, 2314]
	| approx positives in sample 512: 254
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 50, 24, 20, 11, 48, 26, 42]
	Time taken saving stuff: 0.17s
episode: 567/2000 -> reward: -124.99999999999585, steps:80736, time-taken: 2.99min, time-elasped: 1743.60min
-> berries picked: 123 of 800 | patches-visited: [2, 9] | positive-in-buffer: 16927 | amount-filled: 100.00%
	| epsilon: 0.31656472761000254
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2125, 3106, 1620, 1360, 896, 3428, 2059, 2333]
	| approx positives in sample 512: 226
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [37, 36, 16, 16, 9, 44, 33, 35]
	Time taken saving stuff: 15.23s
episode: 568/2000 -> reward: -124.99999999999221, steps:72864, time-taken: 2.84min, time-elasped: 1746.69min
-> berries picked: 90 of 800 | patches-visited: [1, 5] | positive-in-buffer: 16953 | amount-filled: 100.00%
	| epsilon: 0.31631008444465786
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2129, 3110, 1616, 1358, 892, 3431, 2070, 2347]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 42, 27, 18, 12, 46, 23, 29]
	Time taken saving stuff: 0.03s
episode: 569/2000 -> reward: -124.99999999999203, steps:65856, time-taken: 2.15min, time-elasped: 1748.85min
-> berries picked: 75 of 800 | patches-visited: [2] | positive-in-buffer: 16973 | amount-filled: 100.00%
	| epsilon: 0.3160556461130675
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2139, 3114, 1613, 1355, 889, 3441, 2074, 2348]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 37, 19, 21, 11, 36, 27, 35]
	Time taken saving stuff: 0.01s
episode: 570/2000 -> reward: -124.999999999992, steps:56640, time-taken: 2.18min, time-elasped: 1751.03min
-> berries picked: 34 of 800 | patches-visited: [5] | positive-in-buffer: 16855 | amount-filled: 100.00%
	| epsilon: 0.3158014124504643
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2129, 3092, 1578, 1330, 886, 3431, 2071, 2338]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 43, 19, 12, 13, 47, 28, 31]
	Time taken saving stuff: 11.54s
episode: 571/2000 -> reward: -124.99999999999163, steps:66720, time-taken: 2.67min, time-elasped: 1753.89min
-> berries picked: 69 of 800 | patches-visited: [6] | positive-in-buffer: 16902 | amount-filled: 100.00%
	| epsilon: 0.3155473832922133
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2137, 3103, 1579, 1334, 887, 3443, 2075, 2344]
	| approx positives in sample 512: 249
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 44, 21, 14, 17, 57, 39, 29]
	Time taken saving stuff: 0.00s
episode: 572/2000 -> reward: -124.99999999999174, steps:65568, time-taken: 2.18min, time-elasped: 1756.07min
-> berries picked: 69 of 800 | patches-visited: [7] | positive-in-buffer: 16938 | amount-filled: 100.00%
	| epsilon: 0.31529355847381235
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2139, 3112, 1579, 1332, 895, 3448, 2078, 2355]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 30, 14, 20, 9, 53, 22, 29]
	Time taken saving stuff: 0.09s
episode: 573/2000 -> reward: -124.99999999999196, steps:64512, time-taken: 2.12min, time-elasped: 1758.20min
-> berries picked: 66 of 800 | patches-visited: [0] | positive-in-buffer: 16804 | amount-filled: 100.00%
	| epsilon: 0.31503993783089135
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2132, 3076, 1552, 1309, 892, 3421, 2070, 2352]
	| approx positives in sample 512: 185
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 21, 10, 12, 13, 44, 31, 25]
	Time taken saving stuff: 14.82s
episode: 574/2000 -> reward: -124.99999999998435, steps:81216, time-taken: 3.16min, time-elasped: 1761.61min
-> berries picked: 130 of 800 | patches-visited: [1, 8] | positive-in-buffer: 16835 | amount-filled: 100.00%
	| epsilon: 0.3147865211992126
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2136, 3094, 1559, 1316, 896, 3417, 2067, 2350]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 38, 14, 23, 7, 49, 26, 35]
	Time taken saving stuff: 0.03s
episode: 575/2000 -> reward: -124.99999999999201, steps:60768, time-taken: 1.92min, time-elasped: 1763.53min
-> berries picked: 44 of 800 | patches-visited: [8] | positive-in-buffer: 16835 | amount-filled: 100.00%
	| epsilon: 0.31453330841467025
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2141, 3097, 1558, 1313, 895, 3413, 2067, 2351]
	| approx positives in sample 512: 204
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 28, 13, 13, 8, 42, 39, 28]
	Time taken saving stuff: 0.01s
episode: 576/2000 -> reward: -124.99999999999459, steps:68640, time-taken: 2.88min, time-elasped: 1766.41min
-> berries picked: 76 of 800 | patches-visited: [5, 6] | positive-in-buffer: 16810 | amount-filled: 100.00%
	| epsilon: 0.31428029931329077
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2140, 3093, 1544, 1308, 893, 3414, 2066, 2352]
	| approx positives in sample 512: 226
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [37, 26, 13, 18, 8, 50, 33, 41]
	Time taken saving stuff: 12.14s
episode: 577/2000 -> reward: -124.99999999999544, steps:83136, time-taken: 3.17min, time-elasped: 1769.79min
-> berries picked: 139 of 800 | patches-visited: [5, 8] | positive-in-buffer: 16909 | amount-filled: 100.00%
	| epsilon: 0.31402749373123234
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2154, 3119, 1545, 1314, 903, 3436, 2074, 2364]
	| approx positives in sample 512: 223
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 40, 14, 25, 10, 47, 27, 27]
	Time taken saving stuff: 0.01s
episode: 578/2000 -> reward: -124.99999999999191, steps:68832, time-taken: 2.75min, time-elasped: 1772.54min
-> berries picked: 78 of 800 | patches-visited: [5] | positive-in-buffer: 16813 | amount-filled: 100.00%
	| epsilon: 0.313774891504785
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2149, 3099, 1510, 1295, 896, 3422, 2081, 2361]
	| approx positives in sample 512: 238
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 37, 18, 12, 12, 73, 25, 31]
	Time taken saving stuff: 0.24s
episode: 579/2000 -> reward: -124.99999999999406, steps:80064, time-taken: 3.19min, time-elasped: 1775.74min
-> berries picked: 121 of 800 | patches-visited: [5, 7] | positive-in-buffer: 16907 | amount-filled: 100.00%
	| epsilon: 0.3135224924703705
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2164, 3120, 1513, 1300, 909, 3436, 2093, 2372]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 43, 13, 11, 14, 48, 27, 30]
	Time taken saving stuff: 15.14s
episode: 580/2000 -> reward: -124.99999999999183, steps:75648, time-taken: 2.87min, time-elasped: 1778.86min
-> berries picked: 97 of 800 | patches-visited: [6, 8] | positive-in-buffer: 16887 | amount-filled: 100.00%
	| epsilon: 0.3132702964645421
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2163, 3108, 1498, 1288, 904, 3448, 2099, 2379]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [41, 48, 12, 12, 12, 37, 28, 26]
	Time taken saving stuff: 0.02s
episode: 581/2000 -> reward: -124.99999999998906, steps:98976, time-taken: 4.24min, time-elasped: 1783.10min
-> berries picked: 208 of 800 | patches-visited: [3, 5, 7, 9] | positive-in-buffer: 17013 | amount-filled: 100.00%
	| epsilon: 0.31301830332398445
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2183, 3145, 1509, 1313, 910, 3467, 2106, 2380]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 41, 17, 12, 13, 39, 30, 39]
	Time taken saving stuff: 0.01s
episode: 582/2000 -> reward: -124.9999999999943, steps:80640, time-taken: 3.04min, time-elasped: 1786.14min
-> berries picked: 121 of 800 | patches-visited: [4, 9] | positive-in-buffer: 16933 | amount-filled: 100.00%
	| epsilon: 0.3127665128855139
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2188, 3127, 1471, 1285, 910, 3465, 2110, 2377]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 28, 14, 15, 8, 58, 39, 37]
	Time taken saving stuff: 12.50s
episode: 583/2000 -> reward: -124.99999999999109, steps:79296, time-taken: 2.90min, time-elasped: 1789.25min
-> berries picked: 119 of 800 | patches-visited: [4, 6] | positive-in-buffer: 16920 | amount-filled: 100.00%
	| epsilon: 0.31251492498607775
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2197, 3115, 1466, 1285, 906, 3452, 2115, 2384]
	| approx positives in sample 512: 207
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 40, 12, 14, 10, 35, 29, 46]
	Time taken saving stuff: 0.01s
episode: 584/2000 -> reward: -124.99999999998597, steps:73248, time-taken: 3.08min, time-elasped: 1792.33min
-> berries picked: 106 of 800 | patches-visited: [2, 8] | positive-in-buffer: 16941 | amount-filled: 100.00%
	| epsilon: 0.3122635394627545
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2198, 3129, 1464, 1292, 906, 3452, 2114, 2386]
	| approx positives in sample 512: 210
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 39, 21, 10, 7, 45, 30, 24]
	Time taken saving stuff: 0.09s
episode: 585/2000 -> reward: -124.99999999999386, steps:82752, time-taken: 3.06min, time-elasped: 1795.39min
-> berries picked: 140 of 800 | patches-visited: [2, 5] | positive-in-buffer: 17030 | amount-filled: 100.00%
	| epsilon: 0.31201235615275386
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2206, 3141, 1465, 1290, 921, 3469, 2126, 2412]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 36, 11, 18, 10, 45, 33, 28]
	Time taken saving stuff: 15.35s
episode: 586/2000 -> reward: -124.99999999998646, steps:97152, time-taken: 4.10min, time-elasped: 1799.75min
-> berries picked: 196 of 800 | patches-visited: [1, 2, 4] | positive-in-buffer: 17070 | amount-filled: 100.00%
	| epsilon: 0.3117613748934164
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2211, 3150, 1461, 1281, 934, 3483, 2136, 2414]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 59, 18, 20, 8, 42, 27, 28]
	Time taken saving stuff: 0.11s
episode: 587/2000 -> reward: -124.99999999999095, steps:73824, time-taken: 2.85min, time-elasped: 1802.60min
-> berries picked: 92 of 800 | patches-visited: [0, 8] | positive-in-buffer: 17097 | amount-filled: 100.00%
	| epsilon: 0.31151059552221344
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2218, 3160, 1459, 1280, 928, 3493, 2145, 2414]
	| approx positives in sample 512: 223
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [37, 40, 14, 17, 10, 47, 29, 29]
	Time taken saving stuff: 0.00s
episode: 588/2000 -> reward: -124.99999999999227, steps:85056, time-taken: 3.15min, time-elasped: 1805.75min
-> berries picked: 128 of 800 | patches-visited: [0, 2, 3] | positive-in-buffer: 17138 | amount-filled: 100.00%
	| epsilon: 0.3112600178767472
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2229, 3176, 1460, 1282, 922, 3502, 2148, 2419]
	| approx positives in sample 512: 191
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 24, 17, 15, 4, 49, 21, 33]
	Time taken saving stuff: 11.83s
episode: 589/2000 -> reward: -124.99999999999193, steps:60960, time-taken: 2.11min, time-elasped: 1808.06min
-> berries picked: 56 of 800 | patches-visited: [4] | positive-in-buffer: 16984 | amount-filled: 100.00%
	| epsilon: 0.3110096417947504
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2215, 3134, 1433, 1262, 913, 3479, 2143, 2405]
	| approx positives in sample 512: 201
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 32, 17, 16, 7, 26, 32, 42]
	Time taken saving stuff: 0.01s
episode: 590/2000 -> reward: -124.9999999999935, steps:74592, time-taken: 3.00min, time-elasped: 1811.07min
-> berries picked: 102 of 800 | patches-visited: [4, 8] | positive-in-buffer: 17032 | amount-filled: 100.00%
	| epsilon: 0.3107594671140863
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2226, 3141, 1435, 1264, 917, 3481, 2152, 2416]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 42, 17, 11, 11, 49, 26, 34]
	Time taken saving stuff: 0.10s
episode: 591/2000 -> reward: -124.99999999998938, steps:98688, time-taken: 4.00min, time-elasped: 1815.07min
-> berries picked: 202 of 800 | patches-visited: [0, 3, 9] | positive-in-buffer: 17133 | amount-filled: 100.00%
	| epsilon: 0.31050949367274877
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2242, 3168, 1433, 1269, 923, 3493, 2168, 2437]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 39, 12, 13, 9, 43, 32, 35]
	Time taken saving stuff: 14.95s
episode: 592/2000 -> reward: -124.99999999998847, steps:99840, time-taken: 4.14min, time-elasped: 1819.46min
-> berries picked: 195 of 800 | patches-visited: [1, 3, 4, 7] | positive-in-buffer: 17169 | amount-filled: 100.00%
	| epsilon: 0.31025972130886176
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2251, 3179, 1424, 1269, 923, 3504, 2174, 2445]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 31, 19, 9, 6, 43, 39, 37]
	Time taken saving stuff: 0.00s
episode: 593/2000 -> reward: -124.99999999999086, steps:76800, time-taken: 3.06min, time-elasped: 1822.52min
-> berries picked: 103 of 800 | patches-visited: [0, 1] | positive-in-buffer: 17114 | amount-filled: 100.00%
	| epsilon: 0.3100101498606795
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2251, 3161, 1401, 1259, 919, 3505, 2165, 2453]
	| approx positives in sample 512: 226
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [40, 27, 17, 12, 9, 51, 37, 33]
	Time taken saving stuff: 0.01s
episode: 594/2000 -> reward: -124.9999999999882, steps:84576, time-taken: 3.35min, time-elasped: 1825.87min
-> berries picked: 149 of 800 | patches-visited: [1, 4, 5, 6] | positive-in-buffer: 17156 | amount-filled: 100.00%
	| epsilon: 0.30976077916658634
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2262, 3171, 1403, 1255, 925, 3509, 2173, 2458]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [38, 29, 13, 10, 8, 50, 25, 27]
	Time taken saving stuff: 13.56s
episode: 595/2000 -> reward: -124.99999999999164, steps:65568, time-taken: 2.05min, time-elasped: 1828.15min
-> berries picked: 74 of 800 | patches-visited: [1] | positive-in-buffer: 17042 | amount-filled: 100.00%
	| epsilon: 0.3095116090650968
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2256, 3150, 1379, 1240, 918, 3481, 2161, 2457]
	| approx positives in sample 512: 193
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 35, 17, 12, 6, 42, 26, 28]
	Time taken saving stuff: 0.00s
episode: 596/2000 -> reward: -124.999999999992, steps:66048, time-taken: 2.84min, time-elasped: 1830.98min
-> berries picked: 70 of 800 | patches-visited: [6] | positive-in-buffer: 17035 | amount-filled: 100.00%
	| epsilon: 0.30926263939485493
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2260, 3146, 1379, 1236, 919, 3472, 2156, 2467]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 24, 19, 14, 14, 44, 42, 40]
	Time taken saving stuff: 0.06s
episode: 597/2000 -> reward: -124.99999999999442, steps:78528, time-taken: 3.01min, time-elasped: 1834.00min
-> berries picked: 111 of 800 | patches-visited: [0, 2, 4] | positive-in-buffer: 17115 | amount-filled: 100.00%
	| epsilon: 0.30901386999463487
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2268, 3171, 1384, 1241, 924, 3481, 2168, 2478]
	| approx positives in sample 512: 207
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 37, 18, 10, 12, 34, 29, 39]
	Time taken saving stuff: 12.12s
episode: 598/2000 -> reward: -124.99999999998028, steps:114624, time-taken: 4.98min, time-elasped: 1839.18min
-> berries picked: 262 of 800 | patches-visited: [0, 2, 4, 5] | positive-in-buffer: 17279 | amount-filled: 100.00%
	| epsilon: 0.3087653007033404
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2295, 3203, 1391, 1247, 936, 3524, 2178, 2505]
	| approx positives in sample 512: 250
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [36, 40, 8, 24, 14, 46, 37, 45]
	Time taken saving stuff: 0.03s
episode: 599/2000 -> reward: -124.99999999998994, steps:95232, time-taken: 4.22min, time-elasped: 1843.40min
-> berries picked: 198 of 800 | patches-visited: [1, 5, 7] | positive-in-buffer: 17343 | amount-filled: 100.00%
	| epsilon: 0.30851693136000485
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2306, 3232, 1390, 1248, 936, 3531, 2186, 2514]
	| approx positives in sample 512: 237
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 44, 9, 20, 13, 48, 26, 45]
	Time taken saving stuff: 0.01s
episode: 600/2000 -> reward: -124.99999999998707, steps:112416, time-taken: 5.01min, time-elasped: 1848.41min
-> berries picked: 247 of 800 | patches-visited: [0, 1, 2, 9] | positive-in-buffer: 17415 | amount-filled: 100.00%
	| epsilon: 0.308268761803791
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2332, 3257, 1386, 1246, 938, 3532, 2206, 2518]
	| approx positives in sample 512: 236
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [41, 46, 10, 13, 12, 45, 32, 37]
	Time taken saving stuff: 15.22s
episode: 601/2000 -> reward: -124.99999999998919, steps:94656, time-taken: 4.04min, time-elasped: 1852.71min
-> berries picked: 180 of 800 | patches-visited: [0, 1, 6] | positive-in-buffer: 17464 | amount-filled: 100.00%
	| epsilon: 0.308020791873991
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2333, 3246, 1385, 1249, 939, 3549, 2218, 2545]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 45, 15, 14, 13, 44, 23, 44]
	Time taken saving stuff: 0.01s
episode: 602/2000 -> reward: -124.99999999999157, steps:65184, time-taken: 2.17min, time-elasped: 1854.88min
-> berries picked: 69 of 800 | patches-visited: [2] | positive-in-buffer: 17402 | amount-filled: 100.00%
	| epsilon: 0.3077730214100263
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2334, 3237, 1375, 1243, 930, 3533, 2215, 2535]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 34, 13, 17, 19, 45, 26, 35]
	Time taken saving stuff: 0.11s
episode: 603/2000 -> reward: -124.99999999999456, steps:76512, time-taken: 2.98min, time-elasped: 1857.86min
-> berries picked: 104 of 800 | patches-visited: [7, 9] | positive-in-buffer: 17319 | amount-filled: 100.00%
	| epsilon: 0.3075254502514477
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2334, 3217, 1342, 1233, 920, 3524, 2215, 2534]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [38, 29, 13, 17, 12, 38, 43, 32]
	Time taken saving stuff: 11.85s
episode: 604/2000 -> reward: -124.9999999999908, steps:78144, time-taken: 3.12min, time-elasped: 1861.18min
-> berries picked: 119 of 800 | patches-visited: [3, 9] | positive-in-buffer: 17396 | amount-filled: 100.00%
	| epsilon: 0.3072780782379347
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2336, 3226, 1346, 1241, 927, 3546, 2225, 2549]
	| approx positives in sample 512: 206
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 42, 8, 14, 13, 49, 28, 27]
	Time taken saving stuff: 0.10s
episode: 605/2000 -> reward: -124.99999999999201, steps:52320, time-taken: 1.92min, time-elasped: 1863.11min
-> berries picked: 17 of 800 | patches-visited: [3] | positive-in-buffer: 17362 | amount-filled: 100.00%
	| epsilon: 0.30703090520929605
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2335, 3215, 1339, 1238, 926, 3540, 2219, 2550]
	| approx positives in sample 512: 247
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 31, 14, 19, 16, 61, 33, 41]
	Time taken saving stuff: 0.01s
episode: 606/2000 -> reward: -124.99999999999207, steps:66048, time-taken: 2.95min, time-elasped: 1866.06min
-> berries picked: 70 of 800 | patches-visited: [1] | positive-in-buffer: 17405 | amount-filled: 100.00%
	| epsilon: 0.3067839310054692
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2341, 3221, 1342, 1240, 931, 3549, 2227, 2554]
	| approx positives in sample 512: 241
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 53, 19, 15, 14, 49, 26, 36]
	Time taken saving stuff: 14.97s
episode: 607/2000 -> reward: -124.99999999999075, steps:92256, time-taken: 4.18min, time-elasped: 1870.50min
-> berries picked: 168 of 800 | patches-visited: [0, 1, 6] | positive-in-buffer: 17488 | amount-filled: 100.00%
	| epsilon: 0.3065371554665205
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2359, 3228, 1346, 1246, 930, 3572, 2243, 2564]
	| approx positives in sample 512: 239
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [37, 43, 12, 11, 14, 44, 31, 47]
	Time taken saving stuff: 0.01s
episode: 608/2000 -> reward: -124.99999999998522, steps:80928, time-taken: 3.12min, time-elasped: 1873.62min
-> berries picked: 125 of 800 | patches-visited: [0, 3] | positive-in-buffer: 17527 | amount-filled: 100.00%
	| epsilon: 0.30629057843264473
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2369, 3233, 1347, 1241, 939, 3577, 2252, 2569]
	| approx positives in sample 512: 230
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 38, 11, 18, 15, 39, 36, 38]
	Time taken saving stuff: 0.11s
episode: 609/2000 -> reward: -124.99999999998862, steps:86400, time-taken: 3.22min, time-elasped: 1876.84min
-> berries picked: 148 of 800 | patches-visited: [1, 6, 7] | positive-in-buffer: 17527 | amount-filled: 100.00%
	| epsilon: 0.3060441997441655
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2385, 3230, 1341, 1231, 933, 3573, 2257, 2577]
	| approx positives in sample 512: 206
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 34, 16, 12, 14, 39, 31, 34]
	Time taken saving stuff: 12.44s
episode: 610/2000 -> reward: -124.99999999999197, steps:67872, time-taken: 2.99min, time-elasped: 1880.03min
-> berries picked: 72 of 800 | patches-visited: [7] | positive-in-buffer: 17382 | amount-filled: 100.00%
	| epsilon: 0.30579801924153466
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2366, 3190, 1322, 1222, 939, 3547, 2237, 2559]
	| approx positives in sample 512: 240
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 52, 16, 9, 10, 48, 29, 42]
	Time taken saving stuff: 0.25s
episode: 611/2000 -> reward: -124.99999999999214, steps:66624, time-taken: 3.06min, time-elasped: 1883.10min
-> berries picked: 72 of 800 | patches-visited: [5] | positive-in-buffer: 17428 | amount-filled: 100.00%
	| epsilon: 0.3055520367653324
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2371, 3202, 1327, 1223, 946, 3548, 2243, 2568]
	| approx positives in sample 512: 245
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [42, 46, 15, 17, 18, 42, 25, 40]
	Time taken saving stuff: 0.00s
episode: 612/2000 -> reward: -124.99999999999137, steps:95136, time-taken: 4.09min, time-elasped: 1887.20min
-> berries picked: 188 of 800 | patches-visited: [3, 6, 8] | positive-in-buffer: 17560 | amount-filled: 100.00%
	| epsilon: 0.3053062521562672
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2394, 3220, 1332, 1230, 955, 3573, 2266, 2590]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [38, 34, 9, 14, 9, 41, 37, 40]
	Time taken saving stuff: 15.17s
episode: 613/2000 -> reward: -124.99999999999443, steps:88608, time-taken: 4.33min, time-elasped: 1891.78min
-> berries picked: 147 of 800 | patches-visited: [4, 8, 9] | positive-in-buffer: 17608 | amount-filled: 100.00%
	| epsilon: 0.30506066525517583
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2403, 3224, 1331, 1231, 957, 3590, 2268, 2604]
	| approx positives in sample 512: 239
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 44, 11, 19, 13, 56, 33, 37]
	Time taken saving stuff: 0.01s
episode: 614/2000 -> reward: -124.99999999998956, steps:103968, time-taken: 5.65min, time-elasped: 1897.44min
-> berries picked: 213 of 800 | patches-visited: [0, 1, 4, 7] | positive-in-buffer: 17692 | amount-filled: 100.00%
	| epsilon: 0.30481527590302276
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2424, 3245, 1324, 1236, 962, 3611, 2274, 2616]
	| approx positives in sample 512: 201
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [36, 33, 8, 18, 17, 36, 22, 31]
	Time taken saving stuff: 0.04s
episode: 615/2000 -> reward: -124.99999999999422, steps:83424, time-taken: 3.85min, time-elasped: 1901.29min
-> berries picked: 132 of 800 | patches-visited: [1, 4, 5] | positive-in-buffer: 17637 | amount-filled: 100.00%
	| epsilon: 0.30457008394090057
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2424, 3205, 1312, 1235, 968, 3603, 2269, 2621]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 38, 11, 19, 6, 42, 40, 34]
	Time taken saving stuff: 12.77s
episode: 616/2000 -> reward: -124.9999999999919, steps:62496, time-taken: 2.24min, time-elasped: 1903.74min
-> berries picked: 49 of 800 | patches-visited: [9] | positive-in-buffer: 17606 | amount-filled: 100.00%
	| epsilon: 0.30432508921002976
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2429, 3193, 1309, 1226, 964, 3597, 2268, 2620]
	| approx positives in sample 512: 210
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [36, 31, 12, 15, 10, 44, 35, 27]
	Time taken saving stuff: 0.11s
episode: 617/2000 -> reward: -124.99999999999166, steps:67296, time-taken: 3.16min, time-elasped: 1906.91min
-> berries picked: 75 of 800 | patches-visited: [6] | positive-in-buffer: 17551 | amount-filled: 100.00%
	| epsilon: 0.3040802915517584
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2431, 3183, 1285, 1223, 959, 3580, 2266, 2624]
	| approx positives in sample 512: 270
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [40, 48, 14, 23, 11, 64, 27, 43]
	Time taken saving stuff: 0.17s
episode: 618/2000 -> reward: -124.99999999999075, steps:75360, time-taken: 3.56min, time-elasped: 1910.47min
-> berries picked: 107 of 800 | patches-visited: [0, 5] | positive-in-buffer: 17626 | amount-filled: 100.00%
	| epsilon: 0.3038356908075622
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2438, 3198, 1289, 1229, 964, 3594, 2275, 2639]
	| approx positives in sample 512: 223
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 35, 13, 11, 9, 58, 33, 39]
	Time taken saving stuff: 13.14s
episode: 619/2000 -> reward: -124.9999999999866, steps:81984, time-taken: 4.54min, time-elasped: 1915.24min
-> berries picked: 121 of 800 | patches-visited: [0, 8] | positive-in-buffer: 17702 | amount-filled: 100.00%
	| epsilon: 0.3035912868190444
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2451, 3210, 1294, 1240, 969, 3608, 2280, 2650]
	| approx positives in sample 512: 236
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [55, 31, 7, 12, 9, 40, 44, 38]
	Time taken saving stuff: 0.10s
episode: 620/2000 -> reward: -124.99999999998411, steps:113184, time-taken: 5.64min, time-elasped: 1920.88min
-> berries picked: 246 of 800 | patches-visited: [0, 4, 5, 6, 8] | positive-in-buffer: 17768 | amount-filled: 100.00%
	| epsilon: 0.30334707942793576
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2453, 3207, 1294, 1242, 977, 3629, 2301, 2665]
	| approx positives in sample 512: 248
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 41, 13, 22, 14, 51, 31, 42]
	Time taken saving stuff: 0.17s
episode: 621/2000 -> reward: -124.99999999999231, steps:66720, time-taken: 3.54min, time-elasped: 1924.43min
-> berries picked: 67 of 800 | patches-visited: [4] | positive-in-buffer: 17724 | amount-filled: 100.00%
	| epsilon: 0.30310306847609414
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2452, 3194, 1296, 1237, 970, 3620, 2301, 2654]
	| approx positives in sample 512: 244
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [43, 47, 19, 19, 10, 37, 35, 34]
	Time taken saving stuff: 12.34s
episode: 622/2000 -> reward: -124.99999999999365, steps:78528, time-taken: 3.26min, time-elasped: 1927.89min
-> berries picked: 129 of 800 | patches-visited: [2, 6] | positive-in-buffer: 17781 | amount-filled: 100.00%
	| epsilon: 0.3028592538055048
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2453, 3193, 1303, 1242, 974, 3641, 2305, 2670]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [38, 46, 12, 18, 10, 46, 29, 32]
	Time taken saving stuff: 0.10s
episode: 623/2000 -> reward: -124.99999999999264, steps:64320, time-taken: 2.23min, time-elasped: 1930.13min
-> berries picked: 61 of 800 | patches-visited: [6, 8] | positive-in-buffer: 17659 | amount-filled: 100.00%
	| epsilon: 0.30261563525828
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2444, 3169, 1282, 1226, 962, 3615, 2298, 2663]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 45, 10, 14, 11, 47, 34, 28]
	Time taken saving stuff: 0.03s
episode: 624/2000 -> reward: -124.9999999999922, steps:71520, time-taken: 3.08min, time-elasped: 1933.21min
-> berries picked: 84 of 800 | patches-visited: [0, 7] | positive-in-buffer: 17621 | amount-filled: 100.00%
	| epsilon: 0.30237221267665904
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2440, 3155, 1275, 1221, 967, 3606, 2295, 2662]
	| approx positives in sample 512: 230
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 33, 24, 18, 12, 47, 33, 35]
	Time taken saving stuff: 11.86s
episode: 625/2000 -> reward: -124.99999999999173, steps:72384, time-taken: 3.34min, time-elasped: 1936.75min
-> berries picked: 93 of 800 | patches-visited: [0, 7] | positive-in-buffer: 17692 | amount-filled: 100.00%
	| epsilon: 0.3021289859030082
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2443, 3175, 1277, 1226, 976, 3615, 2305, 2675]
	| approx positives in sample 512: 238
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 38, 12, 17, 10, 57, 33, 41]
	Time taken saving stuff: 0.11s
episode: 626/2000 -> reward: -124.99999999999315, steps:67104, time-taken: 2.99min, time-elasped: 1939.74min
-> berries picked: 76 of 800 | patches-visited: [7, 8] | positive-in-buffer: 17734 | amount-filled: 100.00%
	| epsilon: 0.3018859547798203
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2450, 3176, 1278, 1224, 976, 3632, 2318, 2680]
	| approx positives in sample 512: 269
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 43, 15, 14, 21, 56, 38, 48]
	Time taken saving stuff: 0.08s
episode: 627/2000 -> reward: -124.99999999999211, steps:59328, time-taken: 2.25min, time-elasped: 1942.00min
-> berries picked: 44 of 800 | patches-visited: [1] | positive-in-buffer: 17755 | amount-filled: 100.00%
	| epsilon: 0.30164311914971514
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2450, 3176, 1277, 1228, 980, 3636, 2322, 2686]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 28, 14, 10, 12, 41, 34, 39]
	Time taken saving stuff: 11.93s
episode: 628/2000 -> reward: -124.99999999999193, steps:66432, time-taken: 3.17min, time-elasped: 1945.37min
-> berries picked: 64 of 800 | patches-visited: [1, 3] | positive-in-buffer: 17697 | amount-filled: 100.00%
	| epsilon: 0.301400478855439
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2446, 3166, 1277, 1224, 970, 3613, 2319, 2682]
	| approx positives in sample 512: 238
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [36, 36, 16, 15, 9, 56, 32, 38]
	Time taken saving stuff: 0.11s
episode: 629/2000 -> reward: -124.99999999999483, steps:73728, time-taken: 3.27min, time-elasped: 1948.64min
-> berries picked: 98 of 800 | patches-visited: [1, 3] | positive-in-buffer: 17764 | amount-filled: 100.00%
	| epsilon: 0.3011580337398647
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2452, 3180, 1279, 1231, 975, 3627, 2327, 2693]
	| approx positives in sample 512: 234
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 38, 13, 14, 8, 55, 31, 44]
	Time taken saving stuff: 0.02s
episode: 630/2000 -> reward: -124.99999999999204, steps:52416, time-taken: 2.18min, time-elasped: 1950.83min
-> berries picked: 15 of 800 | patches-visited: [8] | positive-in-buffer: 17752 | amount-filled: 100.00%
	| epsilon: 0.3009157836459914
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2450, 3181, 1278, 1230, 973, 3620, 2326, 2694]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 44, 17, 15, 9, 43, 30, 39]
	Time taken saving stuff: 11.85s
episode: 631/2000 -> reward: -124.99999999999238, steps:61824, time-taken: 2.34min, time-elasped: 1953.37min
-> berries picked: 54 of 800 | patches-visited: [7] | positive-in-buffer: 17759 | amount-filled: 100.00%
	| epsilon: 0.3006737284169446
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2449, 3179, 1277, 1230, 977, 3621, 2329, 2697]
	| approx positives in sample 512: 201
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 31, 11, 15, 11, 39, 34, 33]
	Time taken saving stuff: 0.09s
episode: 632/2000 -> reward: -124.999999999992, steps:57408, time-taken: 2.32min, time-elasped: 1955.68min
-> berries picked: 34 of 800 | patches-visited: [0] | positive-in-buffer: 17586 | amount-filled: 100.00%
	| epsilon: 0.30043186789597587
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2434, 3123, 1254, 1219, 961, 3582, 2324, 2689]
	| approx positives in sample 512: 207
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 28, 12, 25, 10, 45, 27, 35]
	Time taken saving stuff: 0.03s
episode: 633/2000 -> reward: -124.99999999999204, steps:57504, time-taken: 2.17min, time-elasped: 1957.86min
-> berries picked: 33 of 800 | patches-visited: [8] | positive-in-buffer: 17609 | amount-filled: 100.00%
	| epsilon: 0.300190201926463
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2437, 3128, 1254, 1222, 960, 3589, 2328, 2691]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 53, 9, 9, 11, 38, 37, 37]
	Time taken saving stuff: 11.89s
episode: 634/2000 -> reward: -124.99999999999203, steps:53568, time-taken: 2.02min, time-elasped: 1960.08min
-> berries picked: 19 of 800 | patches-visited: [8] | positive-in-buffer: 17606 | amount-filled: 100.00%
	| epsilon: 0.2999487303519097
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2436, 3125, 1251, 1221, 960, 3591, 2327, 2695]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [38, 30, 15, 15, 7, 46, 29, 42]
	Time taken saving stuff: 0.01s
episode: 635/2000 -> reward: -124.99999999999365, steps:78720, time-taken: 3.37min, time-elasped: 1963.45min
-> berries picked: 115 of 800 | patches-visited: [2, 4, 8] | positive-in-buffer: 17695 | amount-filled: 100.00%
	| epsilon: 0.2997074530159457
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2444, 3140, 1258, 1231, 963, 3613, 2343, 2703]
	| approx positives in sample 512: 226
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 39, 14, 8, 13, 45, 34, 38]
	Time taken saving stuff: 0.10s
episode: 636/2000 -> reward: -124.9999999999921, steps:55968, time-taken: 2.08min, time-elasped: 1965.54min
-> berries picked: 33 of 800 | patches-visited: [9] | positive-in-buffer: 17588 | amount-filled: 100.00%
	| epsilon: 0.2994663697623262
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2436, 3110, 1242, 1219, 962, 3588, 2336, 2695]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 28, 8, 15, 10, 49, 29, 49]
	Time taken saving stuff: 12.06s
episode: 637/2000 -> reward: -124.99999999999527, steps:75072, time-taken: 3.15min, time-elasped: 1968.89min
-> berries picked: 100 of 800 | patches-visited: [0, 1, 5, 6] | positive-in-buffer: 17645 | amount-filled: 100.00%
	| epsilon: 0.29922548043493247
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2450, 3124, 1247, 1225, 959, 3591, 2344, 2705]
	| approx positives in sample 512: 210
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 23, 7, 24, 10, 51, 32, 32]
	Time taken saving stuff: 0.12s
episode: 638/2000 -> reward: -124.99999999998334, steps:69600, time-taken: 3.15min, time-elasped: 1972.04min
-> berries picked: 80 of 800 | patches-visited: [6, 9] | positive-in-buffer: 17664 | amount-filled: 100.00%
	| epsilon: 0.2989847848777711
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2447, 3123, 1240, 1226, 965, 3604, 2346, 2713]
	| approx positives in sample 512: 235
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [40, 37, 10, 13, 13, 48, 40, 34]
	Time taken saving stuff: 0.00s
episode: 639/2000 -> reward: -124.99999999999179, steps:78720, time-taken: 3.14min, time-elasped: 1975.18min
-> berries picked: 109 of 800 | patches-visited: [0, 5, 6, 9] | positive-in-buffer: 17719 | amount-filled: 100.00%
	| epsilon: 0.2987442829349742
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2452, 3128, 1239, 1222, 967, 3627, 2358, 2726]
	| approx positives in sample 512: 238
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 33, 20, 11, 9, 54, 43, 33]
	Time taken saving stuff: 11.88s
episode: 640/2000 -> reward: -124.99999999999197, steps:61728, time-taken: 2.56min, time-elasped: 1977.94min
-> berries picked: 49 of 800 | patches-visited: [7] | positive-in-buffer: 17684 | amount-filled: 100.00%
	| epsilon: 0.2985039744507993
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2446, 3113, 1232, 1221, 967, 3620, 2358, 2727]
	| approx positives in sample 512: 208
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 36, 7, 9, 12, 42, 44, 30]
	Time taken saving stuff: 0.01s
episode: 641/2000 -> reward: -124.99999999999208, steps:57024, time-taken: 2.17min, time-elasped: 1980.11min
-> berries picked: 35 of 800 | patches-visited: [8] | positive-in-buffer: 17614 | amount-filled: 100.00%
	| epsilon: 0.2982638592696293
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2441, 3085, 1216, 1214, 967, 3609, 2355, 2727]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 30, 9, 14, 11, 49, 38, 45]
	Time taken saving stuff: 0.11s
episode: 642/2000 -> reward: -124.99999999999343, steps:84288, time-taken: 3.56min, time-elasped: 1983.67min
-> berries picked: 129 of 800 | patches-visited: [0, 3, 7] | positive-in-buffer: 17711 | amount-filled: 100.00%
	| epsilon: 0.29802393723597204
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2461, 3103, 1222, 1218, 974, 3623, 2370, 2740]
	| approx positives in sample 512: 199
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 36, 10, 17, 7, 41, 22, 38]
	Time taken saving stuff: 14.62s
episode: 643/2000 -> reward: -124.99999999999216, steps:75168, time-taken: 2.94min, time-elasped: 1986.86min
-> berries picked: 93 of 800 | patches-visited: [5, 9] | positive-in-buffer: 17669 | amount-filled: 100.00%
	| epsilon: 0.2977842081944607
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2453, 3079, 1214, 1217, 972, 3616, 2373, 2745]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [40, 39, 13, 14, 9, 43, 28, 30]
	Time taken saving stuff: 0.01s
episode: 644/2000 -> reward: -124.99999999999208, steps:61344, time-taken: 2.39min, time-elasped: 1989.25min
-> berries picked: 49 of 800 | patches-visited: [2] | positive-in-buffer: 17702 | amount-filled: 100.00%
	| epsilon: 0.2975446719898532
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2456, 3083, 1214, 1221, 973, 3624, 2380, 2751]
	| approx positives in sample 512: 226
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 35, 8, 9, 9, 48, 37, 53]
	Time taken saving stuff: 0.10s
episode: 645/2000 -> reward: -124.99999999999258, steps:71904, time-taken: 3.24min, time-elasped: 1992.50min
-> berries picked: 86 of 800 | patches-visited: [3, 5, 7] | positive-in-buffer: 17689 | amount-filled: 100.00%
	| epsilon: 0.29730532846703256
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2447, 3077, 1202, 1224, 971, 3623, 2387, 2758]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 32, 6, 19, 8, 51, 37, 46]
	Time taken saving stuff: 12.45s
episode: 646/2000 -> reward: -124.99999999999459, steps:66336, time-taken: 3.16min, time-elasped: 1995.86min
-> berries picked: 66 of 800 | patches-visited: [2, 6] | positive-in-buffer: 17741 | amount-filled: 100.00%
	| epsilon: 0.2970661774710064
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2451, 3081, 1204, 1232, 977, 3633, 2395, 2768]
	| approx positives in sample 512: 233
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 40, 14, 15, 8, 38, 40, 43]
	Time taken saving stuff: 0.03s
episode: 647/2000 -> reward: -124.99999999999201, steps:53376, time-taken: 2.08min, time-elasped: 1997.95min
-> berries picked: 20 of 800 | patches-visited: [1] | positive-in-buffer: 17756 | amount-filled: 100.00%
	| epsilon: 0.29682721884690705
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2452, 3083, 1206, 1234, 978, 3634, 2398, 2771]
	| approx positives in sample 512: 233
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 36, 10, 14, 9, 46, 32, 55]
	Time taken saving stuff: 0.01s
episode: 648/2000 -> reward: -124.99999999999203, steps:51744, time-taken: 2.05min, time-elasped: 2000.00min
-> berries picked: 13 of 800 | patches-visited: [0] | positive-in-buffer: 17733 | amount-filled: 100.00%
	| epsilon: 0.29658845243999155
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2448, 3077, 1202, 1230, 977, 3635, 2395, 2769]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 25, 9, 17, 10, 48, 37, 34]
	Time taken saving stuff: 11.59s
episode: 649/2000 -> reward: -124.9999999999916, steps:56256, time-taken: 2.28min, time-elasped: 2002.47min
-> berries picked: 29 of 800 | patches-visited: [8] | positive-in-buffer: 17754 | amount-filled: 100.00%
	| epsilon: 0.2963498780956412
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2450, 3084, 1204, 1233, 979, 3638, 2397, 2769]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [36, 30, 6, 10, 15, 41, 32, 51]
	Time taken saving stuff: 0.01s
episode: 650/2000 -> reward: -124.9999999999929, steps:67392, time-taken: 2.98min, time-elasped: 2005.46min
-> berries picked: 75 of 800 | patches-visited: [3, 8] | positive-in-buffer: 17702 | amount-filled: 100.00%
	| epsilon: 0.2961114956593618
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2447, 3067, 1204, 1229, 973, 3615, 2397, 2770]
	| approx positives in sample 512: 252
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [45, 38, 16, 17, 9, 50, 39, 38]
	Time taken saving stuff: 0.26s
episode: 651/2000 -> reward: -124.99999999999255, steps:69408, time-taken: 3.32min, time-elasped: 2008.79min
-> berries picked: 79 of 800 | patches-visited: [2, 5] | positive-in-buffer: 17736 | amount-filled: 100.00%
	| epsilon: 0.2958733049767835
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2454, 3068, 1205, 1228, 976, 3624, 2406, 2775]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 29, 14, 17, 15, 46, 36, 41]
	Time taken saving stuff: 12.14s
episode: 652/2000 -> reward: -124.99999999999203, steps:48672, time-taken: 1.99min, time-elasped: 2010.99min
-> berries picked: 2 of 800 | patches-visited: [0] | positive-in-buffer: 17705 | amount-filled: 100.00%
	| epsilon: 0.29563530589366044
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2451, 3061, 1201, 1227, 972, 3619, 2402, 2772]
	| approx positives in sample 512: 239
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 43, 10, 16, 16, 44, 36, 39]
	Time taken saving stuff: 0.02s
episode: 653/2000 -> reward: -124.99999999999108, steps:64416, time-taken: 2.23min, time-elasped: 2013.22min
-> berries picked: 55 of 800 | patches-visited: [2, 7] | positive-in-buffer: 17728 | amount-filled: 100.00%
	| epsilon: 0.29539749825587097
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2450, 3059, 1202, 1232, 974, 3624, 2406, 2781]
	| approx positives in sample 512: 198
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 29, 10, 17, 8, 36, 32, 39]
	Time taken saving stuff: 0.01s
episode: 654/2000 -> reward: -124.99999999999217, steps:67872, time-taken: 3.06min, time-elasped: 2016.28min
-> berries picked: 67 of 800 | patches-visited: [1, 5] | positive-in-buffer: 17577 | amount-filled: 100.00%
	| epsilon: 0.29515988190941733
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2439, 3021, 1192, 1218, 974, 3580, 2391, 2762]
	| approx positives in sample 512: 244
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 38, 16, 17, 14, 53, 43, 33]
	Time taken saving stuff: 12.53s
episode: 655/2000 -> reward: -124.9999999999916, steps:60000, time-taken: 2.25min, time-elasped: 2018.74min
-> berries picked: 43 of 800 | patches-visited: [7, 8] | positive-in-buffer: 17613 | amount-filled: 100.00%
	| epsilon: 0.2949224567004257
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2444, 3029, 1192, 1226, 977, 3583, 2397, 2765]
	| approx positives in sample 512: 210
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 27, 10, 12, 16, 38, 36, 38]
	Time taken saving stuff: 0.01s
episode: 656/2000 -> reward: -124.99999999999125, steps:60096, time-taken: 2.26min, time-elasped: 2021.00min
-> berries picked: 38 of 800 | patches-visited: [0, 2] | positive-in-buffer: 17586 | amount-filled: 100.00%
	| epsilon: 0.29468522247514606
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2434, 3026, 1193, 1222, 977, 3572, 2397, 2765]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 36, 15, 17, 8, 43, 28, 37]
	Time taken saving stuff: 0.02s
episode: 657/2000 -> reward: -124.99999999999135, steps:57024, time-taken: 2.07min, time-elasped: 2023.07min
-> berries picked: 34 of 800 | patches-visited: [1, 3] | positive-in-buffer: 17565 | amount-filled: 100.00%
	| epsilon: 0.29444817907995197
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2432, 3024, 1189, 1220, 977, 3560, 2397, 2766]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 39, 7, 8, 18, 47, 48, 35]
	Time taken saving stuff: 11.90s
episode: 658/2000 -> reward: -124.99999999999204, steps:55584, time-taken: 2.03min, time-elasped: 2025.30min
-> berries picked: 27 of 800 | patches-visited: [0] | positive-in-buffer: 17580 | amount-filled: 100.00%
	| epsilon: 0.29421132636134056
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2436, 3022, 1190, 1220, 978, 3562, 2398, 2774]
	| approx positives in sample 512: 195
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [39, 24, 9, 8, 7, 42, 26, 40]
	Time taken saving stuff: 0.10s
episode: 659/2000 -> reward: -124.99999999999207, steps:61248, time-taken: 2.29min, time-elasped: 2027.60min
-> berries picked: 45 of 800 | patches-visited: [0, 3] | positive-in-buffer: 17606 | amount-filled: 100.00%
	| epsilon: 0.2939746641659326
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2443, 3021, 1193, 1223, 982, 3563, 2404, 2777]
	| approx positives in sample 512: 194
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 36, 11, 18, 5, 36, 31, 33]
	Time taken saving stuff: 0.01s
episode: 660/2000 -> reward: -124.99999999999203, steps:59808, time-taken: 2.18min, time-elasped: 2029.79min
-> berries picked: 38 of 800 | patches-visited: [7] | positive-in-buffer: 17562 | amount-filled: 100.00%
	| epsilon: 0.2937381923404721
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2430, 3009, 1191, 1215, 978, 3558, 2404, 2777]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 30, 11, 15, 13, 45, 29, 42]
	Time taken saving stuff: 12.48s
episode: 661/2000 -> reward: -124.9999999999954, steps:75360, time-taken: 3.07min, time-elasped: 2033.07min
-> berries picked: 97 of 800 | patches-visited: [2, 7] | positive-in-buffer: 17601 | amount-filled: 100.00%
	| epsilon: 0.2935019107318263
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2438, 3003, 1190, 1214, 986, 3571, 2412, 2787]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [41, 25, 12, 16, 12, 54, 32, 37]
	Time taken saving stuff: 0.03s
episode: 662/2000 -> reward: -124.99999999999194, steps:59904, time-taken: 2.25min, time-elasped: 2035.32min
-> berries picked: 42 of 800 | patches-visited: [1, 5] | positive-in-buffer: 17627 | amount-filled: 100.00%
	| epsilon: 0.2932658191869858
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2437, 3006, 1192, 1224, 987, 3576, 2418, 2787]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 40, 8, 9, 16, 40, 37, 41]
	Time taken saving stuff: 0.05s
episode: 663/2000 -> reward: -124.99999999999201, steps:50880, time-taken: 2.02min, time-elasped: 2037.35min
-> berries picked: 9 of 800 | patches-visited: [8] | positive-in-buffer: 17495 | amount-filled: 100.00%
	| epsilon: 0.29302991755306407
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2424, 2980, 1186, 1214, 977, 3538, 2401, 2775]
	| approx positives in sample 512: 246
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 34, 21, 15, 3, 55, 38, 52]
	Time taken saving stuff: 11.85s
episode: 664/2000 -> reward: -124.99999999999042, steps:70848, time-taken: 3.05min, time-elasped: 2040.59min
-> berries picked: 79 of 800 | patches-visited: [2, 9] | positive-in-buffer: 17567 | amount-filled: 100.00%
	| epsilon: 0.29279420567729775
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2429, 2992, 1190, 1221, 987, 3548, 2408, 2792]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 34, 14, 11, 16, 41, 42, 41]
	Time taken saving stuff: 0.10s
episode: 665/2000 -> reward: -124.99999999999183, steps:61536, time-taken: 2.24min, time-elasped: 2042.84min
-> berries picked: 50 of 800 | patches-visited: [4, 6] | positive-in-buffer: 17602 | amount-filled: 100.00%
	| epsilon: 0.29255868340704627
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2429, 2999, 1193, 1225, 990, 3554, 2415, 2797]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 31, 9, 13, 12, 40, 41, 43]
	Time taken saving stuff: 0.02s
episode: 666/2000 -> reward: -124.99999999999208, steps:56448, time-taken: 2.25min, time-elasped: 2045.09min
-> berries picked: 32 of 800 | patches-visited: [0] | positive-in-buffer: 17515 | amount-filled: 100.00%
	| epsilon: 0.29232335058979186
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2405, 2984, 1186, 1220, 987, 3538, 2407, 2788]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 30, 16, 10, 9, 47, 32, 38]
	Time taken saving stuff: 14.21s
episode: 667/2000 -> reward: -124.99999999999203, steps:50976, time-taken: 2.01min, time-elasped: 2047.34min
-> berries picked: 11 of 800 | patches-visited: [2] | positive-in-buffer: 17521 | amount-filled: 100.00%
	| epsilon: 0.2920882070731394
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2405, 2985, 1186, 1221, 988, 3539, 2407, 2790]
	| approx positives in sample 512: 242
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [43, 21, 7, 16, 11, 49, 39, 56]
	Time taken saving stuff: 0.09s
episode: 668/2000 -> reward: -124.99999999999204, steps:71520, time-taken: 3.16min, time-elasped: 2050.50min
-> berries picked: 84 of 800 | patches-visited: [2, 5, 7] | positive-in-buffer: 17598 | amount-filled: 100.00%
	| epsilon: 0.2918532527048164
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2413, 3004, 1187, 1228, 993, 3551, 2421, 2801]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 34, 14, 15, 15, 41, 39, 37]
	Time taken saving stuff: 0.04s
episode: 669/2000 -> reward: -124.99999999999301, steps:62976, time-taken: 2.24min, time-elasped: 2052.73min
-> berries picked: 52 of 800 | patches-visited: [3, 4] | positive-in-buffer: 17617 | amount-filled: 100.00%
	| epsilon: 0.29161848733267276
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2416, 3002, 1191, 1230, 995, 3555, 2424, 2804]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 36, 13, 16, 12, 26, 34, 44]
	Time taken saving stuff: 12.14s
episode: 670/2000 -> reward: -124.9999999999869, steps:88320, time-taken: 4.24min, time-elasped: 2057.18min
-> berries picked: 138 of 800 | patches-visited: [0, 1, 3, 4, 8] | positive-in-buffer: 17585 | amount-filled: 100.00%
	| epsilon: 0.291383910804681
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2415, 2990, 1191, 1228, 998, 3527, 2423, 2813]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 32, 12, 9, 10, 47, 43, 44]
	Time taken saving stuff: 0.02s
episode: 671/2000 -> reward: -124.99999999999204, steps:58272, time-taken: 2.16min, time-elasped: 2059.34min
-> berries picked: 34 of 800 | patches-visited: [1] | positive-in-buffer: 17605 | amount-filled: 100.00%
	| epsilon: 0.29114952296893565
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2419, 2991, 1195, 1229, 999, 3533, 2426, 2813]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [40, 35, 14, 19, 13, 44, 37, 29]
	Time taken saving stuff: 0.09s
episode: 672/2000 -> reward: -124.99999999999277, steps:59040, time-taken: 2.18min, time-elasped: 2061.52min
-> berries picked: 37 of 800 | patches-visited: [6] | positive-in-buffer: 17508 | amount-filled: 100.00%
	| epsilon: 0.2909153236736537
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2408, 2961, 1184, 1217, 993, 3517, 2424, 2804]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [44, 31, 12, 12, 11, 41, 40, 41]
	Time taken saving stuff: 11.73s
episode: 673/2000 -> reward: -124.99999999999231, steps:60000, time-taken: 2.12min, time-elasped: 2063.84min
-> berries picked: 44 of 800 | patches-visited: [5] | positive-in-buffer: 17439 | amount-filled: 100.00%
	| epsilon: 0.2906813127671739
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2402, 2938, 1183, 1213, 986, 3490, 2423, 2804]
	| approx positives in sample 512: 211
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 33, 15, 15, 10, 46, 28, 36]
	Time taken saving stuff: 0.11s
episode: 674/2000 -> reward: -124.99999999999164, steps:70848, time-taken: 3.18min, time-elasped: 2067.03min
-> berries picked: 81 of 800 | patches-visited: [4, 8] | positive-in-buffer: 17422 | amount-filled: 100.00%
	| epsilon: 0.2904474900979574
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2399, 2928, 1183, 1220, 973, 3485, 2429, 2805]
	| approx positives in sample 512: 238
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 29, 13, 17, 15, 51, 41, 41]
	Time taken saving stuff: 0.03s
episode: 675/2000 -> reward: -124.99999999999383, steps:66144, time-taken: 3.29min, time-elasped: 2070.32min
-> berries picked: 64 of 800 | patches-visited: [0, 5] | positive-in-buffer: 17470 | amount-filled: 100.00%
	| epsilon: 0.29021385551458684
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2405, 2932, 1184, 1222, 981, 3495, 2435, 2816]
	| approx positives in sample 512: 252
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [36, 35, 14, 14, 12, 57, 30, 54]
	Time taken saving stuff: 12.69s
episode: 676/2000 -> reward: -124.99999999999199, steps:57600, time-taken: 2.09min, time-elasped: 2072.63min
-> berries picked: 32 of 800 | patches-visited: [5] | positive-in-buffer: 17483 | amount-filled: 100.00%
	| epsilon: 0.28998040886576704
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2406, 2932, 1185, 1222, 981, 3496, 2440, 2821]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [36, 22, 12, 13, 12, 29, 52, 36]
	Time taken saving stuff: 0.03s
episode: 677/2000 -> reward: -124.99999999999227, steps:73632, time-taken: 3.15min, time-elasped: 2075.78min
-> berries picked: 86 of 800 | patches-visited: [1, 2] | positive-in-buffer: 17470 | amount-filled: 100.00%
	| epsilon: 0.2897471500003242
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2407, 2927, 1179, 1220, 985, 3482, 2452, 2818]
	| approx positives in sample 512: 210
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 31, 14, 12, 11, 36, 38, 43]
	Time taken saving stuff: 0.11s
episode: 678/2000 -> reward: -124.99999999999224, steps:57504, time-taken: 2.35min, time-elasped: 2078.13min
-> berries picked: 31 of 800 | patches-visited: [6] | positive-in-buffer: 17478 | amount-filled: 100.00%
	| epsilon: 0.28951407876720636
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2404, 2928, 1179, 1225, 986, 3482, 2453, 2821]
	| approx positives in sample 512: 197
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 36, 12, 8, 13, 36, 29, 37]
	Time taken saving stuff: 12.48s
episode: 679/2000 -> reward: -124.99999999999251, steps:65280, time-taken: 2.45min, time-elasped: 2080.79min
-> berries picked: 68 of 800 | patches-visited: [0, 6, 7] | positive-in-buffer: 17453 | amount-filled: 100.00%
	| epsilon: 0.2892811950154829
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2396, 2930, 1180, 1228, 984, 3457, 2457, 2821]
	| approx positives in sample 512: 205
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 31, 8, 18, 7, 47, 33, 38]
	Time taken saving stuff: 0.02s
episode: 680/2000 -> reward: -124.99999999999201, steps:55680, time-taken: 2.07min, time-elasped: 2082.86min
-> berries picked: 27 of 800 | patches-visited: [8] | positive-in-buffer: 17369 | amount-filled: 100.00%
	| epsilon: 0.2890484985943447
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2383, 2909, 1174, 1220, 983, 3435, 2454, 2811]
	| approx positives in sample 512: 201
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 33, 8, 10, 13, 37, 43, 29]
	Time taken saving stuff: 0.12s
episode: 681/2000 -> reward: -124.99999999999204, steps:53856, time-taken: 2.05min, time-elasped: 2084.92min
-> berries picked: 20 of 800 | patches-visited: [9] | positive-in-buffer: 17387 | amount-filled: 100.00%
	| epsilon: 0.28881598935310393
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2383, 2909, 1174, 1223, 985, 3439, 2457, 2817]
	| approx positives in sample 512: 211
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 25, 11, 13, 15, 53, 26, 34]
	Time taken saving stuff: 12.01s
episode: 682/2000 -> reward: -124.99999999999196, steps:52992, time-taken: 2.05min, time-elasped: 2087.17min
-> berries picked: 17 of 800 | patches-visited: [8] | positive-in-buffer: 17402 | amount-filled: 100.00%
	| epsilon: 0.28858366714119393
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2383, 2914, 1174, 1225, 986, 3442, 2459, 2819]
	| approx positives in sample 512: 240
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 32, 8, 16, 16, 48, 51, 38]
	Time taken saving stuff: 0.03s
episode: 683/2000 -> reward: -124.99999999999203, steps:49728, time-taken: 2.07min, time-elasped: 2089.24min
-> berries picked: 6 of 800 | patches-visited: [7] | positive-in-buffer: 17404 | amount-filled: 100.00%
	| epsilon: 0.2883515318081693
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2383, 2913, 1174, 1226, 986, 3442, 2462, 2818]
	| approx positives in sample 512: 235
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [46, 24, 12, 16, 10, 45, 41, 41]
	Time taken saving stuff: 0.11s
episode: 684/2000 -> reward: -124.99999999999217, steps:60288, time-taken: 2.29min, time-elasped: 2091.54min
-> berries picked: 45 of 800 | patches-visited: [3, 9] | positive-in-buffer: 17443 | amount-filled: 100.00%
	| epsilon: 0.28811958320370545
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2383, 2921, 1178, 1232, 986, 3447, 2469, 2827]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 32, 10, 14, 14, 52, 31, 38]
	Time taken saving stuff: 12.31s
episode: 685/2000 -> reward: -124.99999999999133, steps:62208, time-taken: 2.42min, time-elasped: 2094.16min
-> berries picked: 50 of 800 | patches-visited: [0, 3] | positive-in-buffer: 17363 | amount-filled: 100.00%
	| epsilon: 0.2878878211775988
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2366, 2894, 1173, 1237, 986, 3422, 2467, 2818]
	| approx positives in sample 512: 211
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 26, 8, 12, 14, 44, 41, 32]
	Time taken saving stuff: 0.03s
episode: 686/2000 -> reward: -124.99999999999254, steps:65376, time-taken: 2.32min, time-elasped: 2096.49min
-> berries picked: 59 of 800 | patches-visited: [0, 1, 3] | positive-in-buffer: 17322 | amount-filled: 100.00%
	| epsilon: 0.2876562455797667
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2359, 2883, 1173, 1229, 981, 3403, 2472, 2822]
	| approx positives in sample 512: 202
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [37, 34, 7, 14, 8, 37, 36, 29]
	Time taken saving stuff: 0.07s
episode: 687/2000 -> reward: -124.99999999999193, steps:59616, time-taken: 2.40min, time-elasped: 2098.89min
-> berries picked: 39 of 800 | patches-visited: [6, 7] | positive-in-buffer: 17254 | amount-filled: 100.00%
	| epsilon: 0.28742485626024705
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2350, 2869, 1164, 1214, 975, 3389, 2471, 2822]
	| approx positives in sample 512: 203
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [37, 31, 7, 12, 12, 34, 26, 44]
	Time taken saving stuff: 12.60s
episode: 688/2000 -> reward: -124.99999999999197, steps:60000, time-taken: 2.21min, time-elasped: 2101.32min
-> berries picked: 48 of 800 | patches-visited: [8] | positive-in-buffer: 17292 | amount-filled: 100.00%
	| epsilon: 0.2871936530691985
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2355, 2872, 1166, 1217, 979, 3395, 2482, 2826]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 33, 18, 15, 11, 44, 33, 35]
	Time taken saving stuff: 0.10s
episode: 689/2000 -> reward: -124.99999999999203, steps:52128, time-taken: 2.08min, time-elasped: 2103.40min
-> berries picked: 15 of 800 | patches-visited: [0] | positive-in-buffer: 17268 | amount-filled: 100.00%
	| epsilon: 0.2869626358569002
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2351, 2859, 1166, 1215, 979, 3391, 2480, 2827]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 39, 10, 26, 11, 51, 29, 43]
	Time taken saving stuff: 0.10s
episode: 690/2000 -> reward: -124.99999999999349, steps:68736, time-taken: 3.28min, time-elasped: 2106.68min
-> berries picked: 74 of 800 | patches-visited: [2, 6, 8] | positive-in-buffer: 17332 | amount-filled: 100.00%
	| epsilon: 0.28673180447375163
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2354, 2862, 1177, 1225, 985, 3404, 2488, 2837]
	| approx positives in sample 512: 243
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [37, 44, 6, 22, 11, 50, 45, 28]
	Time taken saving stuff: 13.71s
episode: 691/2000 -> reward: -124.99999999999349, steps:74784, time-taken: 3.26min, time-elasped: 2110.17min
-> berries picked: 95 of 800 | patches-visited: [6, 8, 9] | positive-in-buffer: 17352 | amount-filled: 100.00%
	| epsilon: 0.2865011587702728
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2365, 2852, 1176, 1227, 983, 3407, 2494, 2848]
	| approx positives in sample 512: 230
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [36, 32, 14, 9, 9, 32, 44, 54]
	Time taken saving stuff: 0.10s
episode: 692/2000 -> reward: -124.99999999999278, steps:59712, time-taken: 2.30min, time-elasped: 2112.48min
-> berries picked: 40 of 800 | patches-visited: [8, 9] | positive-in-buffer: 17297 | amount-filled: 100.00%
	| epsilon: 0.2862706985971039
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2361, 2826, 1177, 1226, 971, 3398, 2495, 2843]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 29, 10, 9, 11, 40, 38, 52]
	Time taken saving stuff: 0.01s
episode: 693/2000 -> reward: -124.99999999999203, steps:60192, time-taken: 2.17min, time-elasped: 2114.65min
-> berries picked: 45 of 800 | patches-visited: [6, 9] | positive-in-buffer: 17175 | amount-filled: 100.00%
	| epsilon: 0.2860404238050051
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2346, 2800, 1175, 1211, 963, 3350, 2495, 2835]
	| approx positives in sample 512: 205
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 28, 13, 13, 8, 32, 34, 44]
	Time taken saving stuff: 12.30s
episode: 694/2000 -> reward: -124.99999999999294, steps:72000, time-taken: 3.38min, time-elasped: 2118.24min
-> berries picked: 82 of 800 | patches-visited: [0, 1, 4] | positive-in-buffer: 17186 | amount-filled: 100.00%
	| epsilon: 0.28581033424485686
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2342, 2792, 1176, 1211, 962, 3356, 2504, 2843]
	| approx positives in sample 512: 230
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [38, 26, 10, 18, 11, 46, 48, 33]
	Time taken saving stuff: 0.11s
episode: 695/2000 -> reward: -124.99999999999204, steps:55584, time-taken: 2.12min, time-elasped: 2120.36min
-> berries picked: 30 of 800 | patches-visited: [8] | positive-in-buffer: 17205 | amount-filled: 100.00%
	| epsilon: 0.2855804297676594
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2342, 2796, 1178, 1211, 962, 3359, 2508, 2849]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 32, 12, 13, 11, 42, 38, 41]
	Time taken saving stuff: 0.00s
episode: 696/2000 -> reward: -124.99999999999208, steps:57408, time-taken: 2.19min, time-elasped: 2122.55min
-> berries picked: 32 of 800 | patches-visited: [8] | positive-in-buffer: 17164 | amount-filled: 100.00%
	| epsilon: 0.2853507102245329
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2334, 2783, 1179, 1200, 958, 3346, 2511, 2853]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 22, 9, 19, 15, 40, 43, 47]
	Time taken saving stuff: 12.16s
episode: 697/2000 -> reward: -124.99999999999191, steps:66048, time-taken: 3.02min, time-elasped: 2125.78min
-> berries picked: 53 of 800 | patches-visited: [2, 5, 7] | positive-in-buffer: 17157 | amount-filled: 100.00%
	| epsilon: 0.2851211754667173
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2330, 2771, 1177, 1195, 953, 3345, 2526, 2860]
	| approx positives in sample 512: 253
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 42, 9, 18, 10, 57, 39, 44]
	Time taken saving stuff: 0.08s
episode: 698/2000 -> reward: -124.99999999999261, steps:72288, time-taken: 3.49min, time-elasped: 2129.27min
-> berries picked: 84 of 800 | patches-visited: [1, 2, 3, 7] | positive-in-buffer: 17223 | amount-filled: 100.00%
	| epsilon: 0.2848918253455721
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2335, 2780, 1187, 1203, 956, 3348, 2542, 2872]
	| approx positives in sample 512: 247
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 38, 16, 8, 11, 53, 46, 42]
	Time taken saving stuff: 0.10s
episode: 699/2000 -> reward: -124.99999999999349, steps:75552, time-taken: 3.40min, time-elasped: 2132.67min
-> berries picked: 97 of 800 | patches-visited: [1, 7, 9] | positive-in-buffer: 17251 | amount-filled: 100.00%
	| epsilon: 0.28466265971257654
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2334, 2781, 1195, 1211, 951, 3345, 2550, 2884]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 38, 11, 9, 20, 54, 33, 41]
	Time taken saving stuff: 12.82s
episode: 700/2000 -> reward: -124.9999999999934, steps:61728, time-taken: 2.29min, time-elasped: 2135.17min
-> berries picked: 47 of 800 | patches-visited: [3, 6] | positive-in-buffer: 17197 | amount-filled: 100.00%
	| epsilon: 0.2844336784193291
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2327, 2772, 1198, 1205, 945, 3320, 2552, 2878]
	| approx positives in sample 512: 233
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 32, 13, 15, 11, 45, 36, 47]
	Time taken saving stuff: 0.11s
episode: 701/2000 -> reward: -124.99999999999216, steps:58272, time-taken: 2.34min, time-elasped: 2137.52min
-> berries picked: 33 of 800 | patches-visited: [9] | positive-in-buffer: 17120 | amount-filled: 100.00%
	| epsilon: 0.2842048813175479
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2319, 2750, 1192, 1199, 944, 3291, 2553, 2872]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 23, 17, 17, 8, 45, 41, 44]
	Time taken saving stuff: 0.04s
episode: 702/2000 -> reward: -124.99999999999085, steps:75936, time-taken: 3.22min, time-elasped: 2140.75min
-> berries picked: 92 of 800 | patches-visited: [0, 2, 4, 5] | positive-in-buffer: 17200 | amount-filled: 100.00%
	| epsilon: 0.28397626825907013
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2320, 2757, 1195, 1210, 948, 3303, 2578, 2889]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 24, 11, 10, 9, 51, 52, 47]
	Time taken saving stuff: 12.33s
episode: 703/2000 -> reward: -124.99999999999515, steps:77280, time-taken: 3.20min, time-elasped: 2144.15min
-> berries picked: 104 of 800 | patches-visited: [0, 4, 7, 8] | positive-in-buffer: 17260 | amount-filled: 100.00%
	| epsilon: 0.2837478390958522
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2323, 2767, 1204, 1220, 946, 3310, 2589, 2901]
	| approx positives in sample 512: 237
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 35, 11, 13, 15, 36, 37, 56]
	Time taken saving stuff: 0.05s
episode: 704/2000 -> reward: -124.9999999999923, steps:53760, time-taken: 2.10min, time-elasped: 2146.26min
-> berries picked: 20 of 800 | patches-visited: [0, 3] | positive-in-buffer: 17177 | amount-filled: 100.00%
	| epsilon: 0.2835195936799697
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2311, 2751, 1197, 1205, 945, 3279, 2589, 2900]
	| approx positives in sample 512: 238
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 40, 7, 23, 12, 46, 39, 39]
	Time taken saving stuff: 0.11s
episode: 705/2000 -> reward: -124.99999999998903, steps:61632, time-taken: 2.34min, time-elasped: 2148.60min
-> berries picked: 52 of 800 | patches-visited: [2, 4] | positive-in-buffer: 17204 | amount-filled: 100.00%
	| epsilon: 0.2832915318636171
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2311, 2755, 1195, 1205, 943, 3288, 2597, 2910]
	| approx positives in sample 512: 197
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 30, 11, 13, 10, 33, 31, 36]
	Time taken saving stuff: 12.09s
episode: 706/2000 -> reward: -124.99999999999199, steps:51072, time-taken: 2.10min, time-elasped: 2150.91min
-> berries picked: 14 of 800 | patches-visited: [9] | positive-in-buffer: 17100 | amount-filled: 100.00%
	| epsilon: 0.2830636534991078
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2297, 2723, 1185, 1196, 941, 3269, 2588, 2901]
	| approx positives in sample 512: 237
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 29, 13, 19, 10, 44, 47, 45]
	Time taken saving stuff: 0.10s
episode: 707/2000 -> reward: -124.99999999999078, steps:58656, time-taken: 2.26min, time-elasped: 2153.18min
-> berries picked: 41 of 800 | patches-visited: [0, 3] | positive-in-buffer: 17132 | amount-filled: 100.00%
	| epsilon: 0.28283595843887405
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2302, 2725, 1189, 1201, 945, 3274, 2592, 2904]
	| approx positives in sample 512: 211
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [39, 25, 19, 12, 8, 38, 40, 30]
	Time taken saving stuff: 0.21s
episode: 708/2000 -> reward: -124.99999999998596, steps:64800, time-taken: 2.36min, time-elasped: 2155.55min
-> berries picked: 60 of 800 | patches-visited: [5, 7] | positive-in-buffer: 17145 | amount-filled: 100.00%
	| epsilon: 0.2826084465354667
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2308, 2723, 1189, 1210, 946, 3264, 2598, 2907]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 23, 21, 16, 11, 42, 34, 36]
	Time taken saving stuff: 12.57s
episode: 709/2000 -> reward: -124.99999999999196, steps:57984, time-taken: 2.35min, time-elasped: 2158.11min
-> berries picked: 32 of 800 | patches-visited: [0] | positive-in-buffer: 17061 | amount-filled: 100.00%
	| epsilon: 0.2823811176415553
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2303, 2692, 1178, 1204, 934, 3247, 2595, 2908]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 31, 16, 18, 11, 32, 43, 35]
	Time taken saving stuff: 0.01s
episode: 710/2000 -> reward: -124.99999999999203, steps:53472, time-taken: 2.14min, time-elasped: 2160.25min
-> berries picked: 21 of 800 | patches-visited: [0] | positive-in-buffer: 17058 | amount-filled: 100.00%
	| epsilon: 0.282153971609928
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2303, 2691, 1178, 1203, 935, 3242, 2595, 2911]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 36, 10, 14, 13, 31, 41, 41]
	Time taken saving stuff: 0.01s
episode: 711/2000 -> reward: -124.99999999999203, steps:49440, time-taken: 2.21min, time-elasped: 2162.47min
-> berries picked: 6 of 800 | patches-visited: [1] | positive-in-buffer: 17061 | amount-filled: 100.00%
	| epsilon: 0.28192700829349104
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2303, 2690, 1178, 1203, 934, 3243, 2597, 2913]
	| approx positives in sample 512: 248
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 28, 12, 21, 7, 36, 42, 68]
	Time taken saving stuff: 45.07s
episode: 712/2000 -> reward: -124.99999999999277, steps:61344, time-taken: 2.42min, time-elasped: 2165.64min
-> berries picked: 44 of 800 | patches-visited: [1, 7] | positive-in-buffer: 17085 | amount-filled: 100.00%
	| epsilon: 0.28170022754526924
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2302, 2691, 1182, 1203, 934, 3247, 2607, 2919]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 27, 10, 10, 13, 48, 39, 37]
	Time taken saving stuff: 0.01s
episode: 713/2000 -> reward: -124.99999999999173, steps:62496, time-taken: 2.33min, time-elasped: 2167.97min
-> berries picked: 55 of 800 | patches-visited: [1, 8] | positive-in-buffer: 17007 | amount-filled: 100.00%
	| epsilon: 0.2814736292184057
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2290, 2664, 1173, 1198, 929, 3229, 2606, 2918]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 34, 10, 11, 7, 32, 32, 42]
	Time taken saving stuff: 0.01s
episode: 714/2000 -> reward: -124.99999999999245, steps:65760, time-taken: 2.33min, time-elasped: 2170.31min
-> berries picked: 62 of 800 | patches-visited: [5, 9] | positive-in-buffer: 16983 | amount-filled: 100.00%
	| epsilon: 0.28124721316616147
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2284, 2654, 1173, 1201, 929, 3218, 2606, 2918]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 32, 9, 13, 9, 35, 32, 49]
	Time taken saving stuff: 33.62s
episode: 715/2000 -> reward: -124.9999999999938, steps:59232, time-taken: 2.27min, time-elasped: 2173.14min
-> berries picked: 37 of 800 | patches-visited: [0] | positive-in-buffer: 16946 | amount-filled: 100.00%
	| epsilon: 0.2810209792419157
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2274, 2647, 1166, 1199, 927, 3206, 2608, 2919]
	| approx positives in sample 512: 235
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [40, 32, 15, 12, 10, 38, 42, 46]
	Time taken saving stuff: 0.01s
episode: 716/2000 -> reward: -124.99999999999166, steps:61632, time-taken: 2.33min, time-elasped: 2175.47min
-> berries picked: 49 of 800 | patches-visited: [1, 7, 8] | positive-in-buffer: 16971 | amount-filled: 100.00%
	| epsilon: 0.28079492729916555
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2276, 2646, 1168, 1197, 931, 3207, 2618, 2928]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 30, 20, 16, 7, 37, 31, 43]
	Time taken saving stuff: 0.01s
episode: 717/2000 -> reward: -124.99999999999142, steps:70464, time-taken: 3.26min, time-elasped: 2178.74min
-> berries picked: 74 of 800 | patches-visited: [3, 5, 7, 8] | positive-in-buffer: 16965 | amount-filled: 100.00%
	| epsilon: 0.28056905719152586
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2266, 2642, 1168, 1199, 925, 3200, 2634, 2931]
	| approx positives in sample 512: 234
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 31, 13, 14, 10, 40, 47, 46]
	Time taken saving stuff: 15.40s
episode: 718/2000 -> reward: -124.99999999999119, steps:65184, time-taken: 2.40min, time-elasped: 2181.39min
-> berries picked: 65 of 800 | patches-visited: [0, 3, 8] | positive-in-buffer: 17021 | amount-filled: 100.00%
	| epsilon: 0.2803433687727294
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2268, 2653, 1172, 1199, 932, 3211, 2645, 2941]
	| approx positives in sample 512: 181
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 27, 9, 9, 10, 40, 33, 35]
	Time taken saving stuff: 0.01s
episode: 719/2000 -> reward: -124.999999999992, steps:54720, time-taken: 2.36min, time-elasped: 2183.76min
-> berries picked: 23 of 800 | patches-visited: [1] | positive-in-buffer: 16933 | amount-filled: 100.00%
	| epsilon: 0.2801178618966266
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2253, 2624, 1161, 1191, 929, 3202, 2644, 2929]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 35, 13, 11, 9, 36, 42, 50]
	Time taken saving stuff: 0.01s
episode: 720/2000 -> reward: -124.999999999992, steps:52512, time-taken: 2.05min, time-elasped: 2185.81min
-> berries picked: 15 of 800 | patches-visited: [7] | positive-in-buffer: 16946 | amount-filled: 100.00%
	| epsilon: 0.27989253641718526
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2253, 2624, 1162, 1194, 930, 3206, 2648, 2929]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 28, 13, 14, 13, 39, 37, 53]
	Time taken saving stuff: 11.81s
episode: 721/2000 -> reward: -124.99999999999329, steps:81696, time-taken: 3.90min, time-elasped: 2189.91min
-> berries picked: 118 of 800 | patches-visited: [0, 1, 3, 6, 7] | positive-in-buffer: 17043 | amount-filled: 100.00%
	| epsilon: 0.2796673921884908
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2266, 2643, 1169, 1203, 935, 3214, 2661, 2952]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 33, 9, 12, 9, 39, 37, 37]
	Time taken saving stuff: 0.01s
episode: 722/2000 -> reward: -124.99999999999203, steps:48864, time-taken: 2.64min, time-elasped: 2192.55min
-> berries picked: 3 of 800 | patches-visited: [5] | positive-in-buffer: 16968 | amount-filled: 100.00%
	| epsilon: 0.279442429064746
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2257, 2620, 1167, 1199, 932, 3192, 2651, 2950]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 29, 15, 17, 7, 40, 39, 54]
	Time taken saving stuff: 0.01s
episode: 723/2000 -> reward: -124.99999999999288, steps:53280, time-taken: 2.50min, time-elasped: 2195.05min
-> berries picked: 20 of 800 | patches-visited: [9] | positive-in-buffer: 16984 | amount-filled: 100.00%
	| epsilon: 0.2792176469002709
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2260, 2621, 1168, 1200, 932, 3197, 2654, 2952]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 24, 12, 8, 11, 46, 40, 54]
	Time taken saving stuff: 15.54s
episode: 724/2000 -> reward: -124.99999999999199, steps:52416, time-taken: 2.23min, time-elasped: 2197.55min
-> berries picked: 16 of 800 | patches-visited: [6] | positive-in-buffer: 16988 | amount-filled: 100.00%
	| epsilon: 0.27899304554950266
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2260, 2618, 1166, 1204, 933, 3198, 2655, 2954]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 23, 18, 18, 9, 42, 37, 55]
	Time taken saving stuff: 0.01s
episode: 725/2000 -> reward: -124.99999999999204, steps:59040, time-taken: 2.51min, time-elasped: 2200.06min
-> berries picked: 37 of 800 | patches-visited: [8] | positive-in-buffer: 16997 | amount-filled: 100.00%
	| epsilon: 0.27876862486699566
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2260, 2614, 1165, 1205, 931, 3203, 2661, 2958]
	| approx positives in sample 512: 205
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 37, 9, 7, 10, 45, 41, 37]
	Time taken saving stuff: 0.01s
episode: 726/2000 -> reward: -124.99999999999234, steps:62496, time-taken: 2.57min, time-elasped: 2202.63min
-> berries picked: 49 of 800 | patches-visited: [2, 6, 9] | positive-in-buffer: 16971 | amount-filled: 100.00%
	| epsilon: 0.27854438470742116
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2253, 2608, 1162, 1208, 931, 3186, 2665, 2958]
	| approx positives in sample 512: 202
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 23, 15, 14, 13, 23, 45, 44]
	Time taken saving stuff: 12.05s
episode: 727/2000 -> reward: -124.99999999999035, steps:57216, time-taken: 2.52min, time-elasped: 2205.36min
-> berries picked: 29 of 800 | patches-visited: [3] | positive-in-buffer: 16929 | amount-filled: 100.00%
	| epsilon: 0.27832032492556746
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2244, 2596, 1158, 1212, 922, 3182, 2659, 2956]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 32, 11, 20, 12, 36, 36, 47]
	Time taken saving stuff: 0.01s
episode: 728/2000 -> reward: -124.99999999999217, steps:51168, time-taken: 2.15min, time-elasped: 2207.51min
-> berries picked: 11 of 800 | patches-visited: [6] | positive-in-buffer: 16933 | amount-filled: 100.00%
	| epsilon: 0.2780964453763395
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2244, 2595, 1159, 1211, 924, 3182, 2660, 2958]
	| approx positives in sample 512: 235
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 32, 8, 11, 11, 47, 43, 52]
	Time taken saving stuff: 0.01s
episode: 729/2000 -> reward: -124.99999999999203, steps:55200, time-taken: 2.52min, time-elasped: 2210.03min
-> berries picked: 24 of 800 | patches-visited: [8] | positive-in-buffer: 16954 | amount-filled: 100.00%
	| epsilon: 0.27787274591475897
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2247, 2597, 1159, 1213, 925, 3186, 2664, 2963]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [39, 23, 10, 14, 7, 43, 36, 43]
	Time taken saving stuff: 15.46s
episode: 730/2000 -> reward: -124.99999999999201, steps:53472, time-taken: 2.10min, time-elasped: 2212.40min
-> berries picked: 22 of 800 | patches-visited: [1] | positive-in-buffer: 16956 | amount-filled: 100.00%
	| epsilon: 0.2776492263959643
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2247, 2596, 1163, 1212, 925, 3182, 2666, 2965]
	| approx positives in sample 512: 223
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 39, 14, 19, 7, 35, 55, 37]
	Time taken saving stuff: 0.01s
episode: 731/2000 -> reward: -124.99999999998307, steps:91776, time-taken: 4.43min, time-elasped: 2216.83min
-> berries picked: 152 of 800 | patches-visited: [0, 1, 3, 8] | positive-in-buffer: 17082 | amount-filled: 100.00%
	| epsilon: 0.27742588667521034
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2248, 2611, 1182, 1227, 931, 3202, 2694, 2987]
	| approx positives in sample 512: 240
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 35, 14, 21, 11, 47, 39, 44]
	Time taken saving stuff: 0.01s
episode: 732/2000 -> reward: -124.99999999999199, steps:57216, time-taken: 2.20min, time-elasped: 2219.03min
-> berries picked: 31 of 800 | patches-visited: [1] | positive-in-buffer: 17048 | amount-filled: 100.00%
	| epsilon: 0.2772027266078684
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2246, 2601, 1179, 1218, 925, 3196, 2695, 2988]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 26, 13, 15, 10, 29, 47, 45]
	Time taken saving stuff: 12.13s
episode: 733/2000 -> reward: -124.9999999999931, steps:58944, time-taken: 2.34min, time-elasped: 2221.58min
-> berries picked: 41 of 800 | patches-visited: [0, 7] | positive-in-buffer: 16973 | amount-filled: 100.00%
	| epsilon: 0.2769797460494261
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2235, 2566, 1173, 1213, 921, 3192, 2695, 2978]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [37, 27, 13, 13, 7, 33, 41, 44]
	Time taken saving stuff: 0.01s
episode: 734/2000 -> reward: -124.99999999999197, steps:59520, time-taken: 2.25min, time-elasped: 2223.83min
-> berries picked: 38 of 800 | patches-visited: [0] | positive-in-buffer: 16907 | amount-filled: 100.00%
	| epsilon: 0.2767569448554874
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2222, 2555, 1166, 1206, 917, 3178, 2689, 2974]
	| approx positives in sample 512: 199
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 24, 11, 13, 6, 46, 30, 39]
	Time taken saving stuff: 0.01s
episode: 735/2000 -> reward: -124.99999999999187, steps:54336, time-taken: 2.10min, time-elasped: 2225.94min
-> berries picked: 21 of 800 | patches-visited: [5] | positive-in-buffer: 16854 | amount-filled: 100.00%
	| epsilon: 0.2765343228817723
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2214, 2535, 1163, 1203, 913, 3164, 2688, 2974]
	| approx positives in sample 512: 236
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 31, 11, 13, 3, 62, 38, 50]
	Time taken saving stuff: 15.50s
episode: 736/2000 -> reward: -124.99999999999196, steps:55104, time-taken: 2.17min, time-elasped: 2228.37min
-> berries picked: 26 of 800 | patches-visited: [4] | positive-in-buffer: 16871 | amount-filled: 100.00%
	| epsilon: 0.2763118799841169
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2213, 2540, 1163, 1208, 915, 3161, 2693, 2978]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 20, 20, 12, 11, 44, 43, 39]
	Time taken saving stuff: 0.01s
episode: 737/2000 -> reward: -124.99999999998626, steps:67776, time-taken: 3.51min, time-elasped: 2231.88min
-> berries picked: 68 of 800 | patches-visited: [1, 7] | positive-in-buffer: 16880 | amount-filled: 100.00%
	| epsilon: 0.27608961601847326
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2212, 2534, 1165, 1205, 919, 3164, 2696, 2985]
	| approx positives in sample 512: 233
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 30, 7, 15, 9, 53, 38, 47]
	Time taken saving stuff: 0.00s
episode: 738/2000 -> reward: -124.99999999999217, steps:59328, time-taken: 2.24min, time-elasped: 2234.12min
-> berries picked: 41 of 800 | patches-visited: [6, 9] | positive-in-buffer: 16894 | amount-filled: 100.00%
	| epsilon: 0.2758675308409093
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2213, 2535, 1166, 1205, 922, 3167, 2698, 2988]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 34, 7, 13, 12, 37, 38, 42]
	Time taken saving stuff: 12.41s
episode: 739/2000 -> reward: -124.99999999999093, steps:64704, time-taken: 2.33min, time-elasped: 2236.67min
-> berries picked: 56 of 800 | patches-visited: [0, 4, 5] | positive-in-buffer: 16874 | amount-filled: 100.00%
	| epsilon: 0.27564562430760886
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2210, 2534, 1162, 1201, 917, 3165, 2697, 2988]
	| approx positives in sample 512: 211
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 19, 10, 24, 12, 37, 38, 39]
	Time taken saving stuff: 0.01s
episode: 740/2000 -> reward: -124.99999999999223, steps:56640, time-taken: 2.16min, time-elasped: 2238.83min
-> berries picked: 37 of 800 | patches-visited: [3] | positive-in-buffer: 16806 | amount-filled: 100.00%
	| epsilon: 0.2754238962748712
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2203, 2512, 1155, 1196, 914, 3150, 2696, 2980]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 38, 11, 14, 7, 42, 28, 51]
	Time taken saving stuff: 0.01s
episode: 741/2000 -> reward: -124.9999999999921, steps:56160, time-taken: 2.13min, time-elasped: 2240.97min
-> berries picked: 32 of 800 | patches-visited: [3] | positive-in-buffer: 16825 | amount-filled: 100.00%
	| epsilon: 0.27520234659911136
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2203, 2513, 1157, 1202, 918, 3150, 2698, 2984]
	| approx positives in sample 512: 202
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 21, 9, 11, 14, 41, 40, 41]
	Time taken saving stuff: 15.49s
episode: 742/2000 -> reward: -124.99999999999086, steps:66048, time-taken: 3.08min, time-elasped: 2244.31min
-> berries picked: 63 of 800 | patches-visited: [1, 8] | positive-in-buffer: 16864 | amount-filled: 100.00%
	| epsilon: 0.2749809751368598
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2206, 2521, 1161, 1206, 918, 3162, 2702, 2988]
	| approx positives in sample 512: 248
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 42, 14, 12, 17, 39, 39, 53]
	Time taken saving stuff: 0.01s
episode: 743/2000 -> reward: -124.99999999999203, steps:55680, time-taken: 2.25min, time-elasped: 2246.56min
-> berries picked: 28 of 800 | patches-visited: [9] | positive-in-buffer: 16888 | amount-filled: 100.00%
	| epsilon: 0.27475978174476245
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2207, 2528, 1165, 1207, 920, 3166, 2705, 2990]
	| approx positives in sample 512: 196
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 27, 8, 10, 6, 38, 36, 47]
	Time taken saving stuff: 0.01s
episode: 744/2000 -> reward: -124.99999999999217, steps:70272, time-taken: 3.22min, time-elasped: 2249.78min
-> berries picked: 81 of 800 | patches-visited: [0, 4] | positive-in-buffer: 16908 | amount-filled: 100.00%
	| epsilon: 0.2745387662795806
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2206, 2528, 1169, 1208, 926, 3171, 2704, 2996]
	| approx positives in sample 512: 238
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 27, 13, 20, 12, 48, 40, 51]
	Time taken saving stuff: 12.12s
episode: 745/2000 -> reward: -124.99999999999197, steps:57024, time-taken: 2.27min, time-elasped: 2252.25min
-> berries picked: 33 of 800 | patches-visited: [1, 4] | positive-in-buffer: 16902 | amount-filled: 100.00%
	| epsilon: 0.2743179285981906
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2204, 2527, 1169, 1208, 926, 3167, 2702, 2999]
	| approx positives in sample 512: 196
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 30, 14, 15, 9, 26, 39, 39]
	Time taken saving stuff: 0.01s
episode: 746/2000 -> reward: -124.99999999999527, steps:72096, time-taken: 3.18min, time-elasped: 2255.43min
-> berries picked: 83 of 800 | patches-visited: [2, 5, 6] | positive-in-buffer: 16878 | amount-filled: 100.00%
	| epsilon: 0.274097268557584
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2201, 2525, 1171, 1199, 927, 3153, 2692, 3010]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 23, 17, 13, 10, 30, 50, 51]
	Time taken saving stuff: 0.01s
episode: 747/2000 -> reward: -124.99999999998984, steps:84960, time-taken: 3.60min, time-elasped: 2259.04min
-> berries picked: 133 of 800 | patches-visited: [0, 3, 6, 9] | positive-in-buffer: 16966 | amount-filled: 100.00%
	| epsilon: 0.2738767860148674
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2205, 2529, 1181, 1213, 931, 3173, 2709, 3025]
	| approx positives in sample 512: 175
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 27, 10, 14, 7, 27, 28, 38]
	Time taken saving stuff: 15.50s
episode: 748/2000 -> reward: -124.99999999999459, steps:75648, time-taken: 3.51min, time-elasped: 2262.81min
-> berries picked: 97 of 800 | patches-visited: [2, 3, 7, 8] | positive-in-buffer: 16905 | amount-filled: 100.00%
	| epsilon: 0.2736564808272624
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2204, 2509, 1179, 1209, 924, 3135, 2706, 3039]
	| approx positives in sample 512: 208
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 25, 7, 7, 11, 51, 41, 41]
	Time taken saving stuff: 0.01s
episode: 749/2000 -> reward: -124.99999999999203, steps:55392, time-taken: 2.04min, time-elasped: 2264.85min
-> berries picked: 24 of 800 | patches-visited: [7] | positive-in-buffer: 16914 | amount-filled: 100.00%
	| epsilon: 0.2734363528521053
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2203, 2509, 1181, 1208, 925, 3136, 2709, 3043]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 32, 11, 20, 9, 41, 41, 36]
	Time taken saving stuff: 0.01s
episode: 750/2000 -> reward: -124.99999999999199, steps:55680, time-taken: 2.58min, time-elasped: 2267.44min
-> berries picked: 28 of 800 | patches-visited: [5] | positive-in-buffer: 16885 | amount-filled: 100.00%
	| epsilon: 0.2732164019468473
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2198, 2508, 1180, 1210, 921, 3119, 2710, 3039]
	| approx positives in sample 512: 208
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [36, 31, 13, 16, 9, 33, 34, 36]
	Time taken saving stuff: 11.98s
episode: 751/2000 -> reward: -124.99999999999277, steps:67680, time-taken: 3.05min, time-elasped: 2270.70min
-> berries picked: 69 of 800 | patches-visited: [2, 3, 7] | positive-in-buffer: 16861 | amount-filled: 100.00%
	| epsilon: 0.2729966279690543
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2193, 2496, 1179, 1210, 917, 3114, 2703, 3049]
	| approx positives in sample 512: 236
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 35, 11, 19, 8, 39, 41, 60]
	Time taken saving stuff: 0.01s
episode: 752/2000 -> reward: -124.99999999999272, steps:67392, time-taken: 3.20min, time-elasped: 2273.90min
-> berries picked: 68 of 800 | patches-visited: [2, 3] | positive-in-buffer: 16895 | amount-filled: 100.00%
	| epsilon: 0.27277703077640647
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2200, 2497, 1182, 1214, 919, 3120, 2710, 3053]
	| approx positives in sample 512: 243
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 31, 13, 14, 13, 39, 47, 52]
	Time taken saving stuff: 0.01s
episode: 753/2000 -> reward: -124.99999999999253, steps:59520, time-taken: 2.25min, time-elasped: 2276.15min
-> berries picked: 43 of 800 | patches-visited: [0, 1, 8] | positive-in-buffer: 16920 | amount-filled: 100.00%
	| epsilon: 0.2725576102266989
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2200, 2504, 1183, 1212, 920, 3127, 2715, 3059]
	| approx positives in sample 512: 189
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 22, 14, 16, 10, 36, 32, 38]
	Time taken saving stuff: 15.34s
episode: 754/2000 -> reward: -124.99999999999193, steps:58272, time-taken: 2.17min, time-elasped: 2278.58min
-> berries picked: 48 of 800 | patches-visited: [6] | positive-in-buffer: 16805 | amount-filled: 100.00%
	| epsilon: 0.2723383661778407
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2184, 2496, 1167, 1194, 909, 3099, 2707, 3049]
	| approx positives in sample 512: 211
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 22, 16, 6, 6, 45, 42, 46]
	Time taken saving stuff: 0.01s
episode: 755/2000 -> reward: -124.99999999999191, steps:57696, time-taken: 2.23min, time-elasped: 2280.81min
-> berries picked: 32 of 800 | patches-visited: [8] | positive-in-buffer: 16789 | amount-filled: 100.00%
	| epsilon: 0.27211929848785543
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2179, 2494, 1167, 1190, 906, 3091, 2708, 3054]
	| approx positives in sample 512: 195
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 27, 15, 13, 4, 38, 29, 36]
	Time taken saving stuff: 0.01s
episode: 756/2000 -> reward: -124.99999999999203, steps:51744, time-taken: 1.94min, time-elasped: 2282.76min
-> berries picked: 12 of 800 | patches-visited: [6] | positive-in-buffer: 16755 | amount-filled: 100.00%
	| epsilon: 0.27190040701488094
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2174, 2484, 1167, 1188, 902, 3084, 2705, 3051]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [37, 33, 15, 12, 7, 41, 31, 53]
	Time taken saving stuff: 12.19s
episode: 757/2000 -> reward: -124.99999999999197, steps:65184, time-taken: 2.29min, time-elasped: 2285.25min
-> berries picked: 59 of 800 | patches-visited: [1, 3] | positive-in-buffer: 16802 | amount-filled: 100.00%
	| epsilon: 0.2716816916171691
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2181, 2495, 1170, 1192, 902, 3094, 2711, 3057]
	| approx positives in sample 512: 196
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 23, 10, 8, 3, 36, 39, 42]
	Time taken saving stuff: 0.01s
episode: 758/2000 -> reward: -124.99999999999375, steps:68160, time-taken: 3.05min, time-elasped: 2288.31min
-> berries picked: 72 of 800 | patches-visited: [3, 5] | positive-in-buffer: 16739 | amount-filled: 100.00%
	| epsilon: 0.2714631521530857
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2164, 2489, 1167, 1187, 901, 3068, 2706, 3057]
	| approx positives in sample 512: 242
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 30, 12, 24, 7, 41, 48, 45]
	Time taken saving stuff: 0.01s
episode: 759/2000 -> reward: -124.9999999999919, steps:51456, time-taken: 2.40min, time-elasped: 2290.71min
-> berries picked: 11 of 800 | patches-visited: [7] | positive-in-buffer: 16745 | amount-filled: 100.00%
	| epsilon: 0.2712447884811106
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2165, 2488, 1167, 1188, 901, 3071, 2705, 3060]
	| approx positives in sample 512: 230
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 32, 14, 13, 13, 42, 56, 36]
	Time taken saving stuff: 19.10s
episode: 760/2000 -> reward: -124.99999999998819, steps:68064, time-taken: 3.20min, time-elasped: 2294.23min
-> berries picked: 74 of 800 | patches-visited: [7, 8] | positive-in-buffer: 16800 | amount-filled: 100.00%
	| epsilon: 0.27102660045983756
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2169, 2496, 1172, 1194, 911, 3082, 2709, 3067]
	| approx positives in sample 512: 246
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 27, 19, 14, 12, 51, 42, 48]
	Time taken saving stuff: 0.01s
episode: 761/2000 -> reward: -124.99999999998948, steps:91104, time-taken: 4.28min, time-elasped: 2298.51min
-> berries picked: 154 of 800 | patches-visited: [1, 2, 5, 7, 8, 9] | positive-in-buffer: 16823 | amount-filled: 100.00%
	| epsilon: 0.27080858794797386
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2163, 2501, 1175, 1194, 907, 3073, 2729, 3081]
	| approx positives in sample 512: 237
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 32, 16, 12, 11, 37, 44, 59]
	Time taken saving stuff: 0.01s
episode: 762/2000 -> reward: -124.99999999999098, steps:66144, time-taken: 3.23min, time-elasped: 2301.74min
-> berries picked: 63 of 800 | patches-visited: [4, 5] | positive-in-buffer: 16801 | amount-filled: 100.00%
	| epsilon: 0.2705907508043406
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2162, 2489, 1173, 1199, 905, 3059, 2730, 3084]
	| approx positives in sample 512: 246
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [39, 37, 17, 12, 6, 45, 38, 52]
	Time taken saving stuff: 12.18s
episode: 763/2000 -> reward: -124.99999999999378, steps:73344, time-taken: 3.14min, time-elasped: 2305.08min
-> berries picked: 91 of 800 | patches-visited: [0, 1, 4, 6] | positive-in-buffer: 16833 | amount-filled: 100.00%
	| epsilon: 0.2703730888878725
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2160, 2499, 1177, 1198, 904, 3063, 2734, 3098]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 29, 12, 16, 8, 40, 51, 48]
	Time taken saving stuff: 0.01s
episode: 764/2000 -> reward: -124.99999999999213, steps:57888, time-taken: 2.23min, time-elasped: 2307.32min
-> berries picked: 34 of 800 | patches-visited: [8] | positive-in-buffer: 16767 | amount-filled: 100.00%
	| epsilon: 0.2701556020576175
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2141, 2478, 1170, 1196, 905, 3055, 2728, 3094]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 26, 10, 12, 11, 47, 36, 46]
	Time taken saving stuff: 0.01s
episode: 765/2000 -> reward: -124.99999999999203, steps:49920, time-taken: 2.03min, time-elasped: 2309.36min
-> berries picked: 7 of 800 | patches-visited: [3] | positive-in-buffer: 16645 | amount-filled: 100.00%
	| epsilon: 0.2699382901727372
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2136, 2445, 1163, 1191, 896, 3018, 2713, 3083]
	| approx positives in sample 512: 230
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 36, 15, 13, 10, 32, 48, 49]
	Time taken saving stuff: 15.43s
episode: 766/2000 -> reward: -124.99999999999187, steps:53856, time-taken: 2.16min, time-elasped: 2311.78min
-> berries picked: 24 of 800 | patches-visited: [4] | positive-in-buffer: 16664 | amount-filled: 100.00%
	| epsilon: 0.2697211530925063
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2137, 2445, 1165, 1191, 901, 3023, 2714, 3088]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 35, 18, 14, 10, 37, 38, 41]
	Time taken saving stuff: 0.01s
episode: 767/2000 -> reward: -124.99999999999203, steps:54432, time-taken: 2.11min, time-elasped: 2313.89min
-> berries picked: 25 of 800 | patches-visited: [0] | positive-in-buffer: 16686 | amount-filled: 100.00%
	| epsilon: 0.26950419067631287
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2140, 2449, 1169, 1194, 901, 3024, 2717, 3092]
	| approx positives in sample 512: 236
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 26, 13, 18, 13, 33, 41, 59]
	Time taken saving stuff: 0.01s
episode: 768/2000 -> reward: -124.99999999999208, steps:57216, time-taken: 2.26min, time-elasped: 2316.15min
-> berries picked: 33 of 800 | patches-visited: [1, 6] | positive-in-buffer: 16698 | amount-filled: 100.00%
	| epsilon: 0.26928740278365787
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2140, 2447, 1169, 1192, 905, 3024, 2722, 3099]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 31, 16, 11, 8, 34, 43, 44]
	Time taken saving stuff: 11.90s
episode: 769/2000 -> reward: -124.9999999999929, steps:53088, time-taken: 2.28min, time-elasped: 2318.63min
-> berries picked: 18 of 800 | patches-visited: [1, 7] | positive-in-buffer: 16653 | amount-filled: 100.00%
	| epsilon: 0.26907078927415545
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2134, 2445, 1164, 1188, 901, 3012, 2714, 3095]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 29, 12, 15, 11, 39, 35, 54]
	Time taken saving stuff: 0.01s
episode: 770/2000 -> reward: -124.99999999999402, steps:64800, time-taken: 2.27min, time-elasped: 2320.91min
-> berries picked: 58 of 800 | patches-visited: [5, 6, 8] | positive-in-buffer: 16694 | amount-filled: 100.00%
	| epsilon: 0.2688543500075326
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2136, 2453, 1167, 1195, 907, 3014, 2720, 3102]
	| approx positives in sample 512: 196
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 25, 12, 8, 6, 34, 38, 47]
	Time taken saving stuff: 0.01s
episode: 771/2000 -> reward: -124.99999999999221, steps:81024, time-taken: 3.44min, time-elasped: 2324.35min
-> berries picked: 129 of 800 | patches-visited: [2, 6, 8] | positive-in-buffer: 16672 | amount-filled: 100.00%
	| epsilon: 0.2686380848436292
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2130, 2440, 1172, 1188, 905, 3008, 2721, 3108]
	| approx positives in sample 512: 197
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 27, 15, 19, 6, 18, 40, 49]
	Time taken saving stuff: 15.56s
episode: 772/2000 -> reward: -124.99999999999203, steps:55680, time-taken: 2.02min, time-elasped: 2326.63min
-> berries picked: 25 of 800 | patches-visited: [4] | positive-in-buffer: 16669 | amount-filled: 100.00%
	| epsilon: 0.26842199364239794
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2130, 2440, 1169, 1188, 903, 3005, 2719, 3115]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 28, 13, 11, 12, 30, 47, 51]
	Time taken saving stuff: 0.01s
episode: 773/2000 -> reward: -124.99999999999204, steps:52896, time-taken: 2.02min, time-elasped: 2328.65min
-> berries picked: 21 of 800 | patches-visited: [6] | positive-in-buffer: 16688 | amount-filled: 100.00%
	| epsilon: 0.26820607626390386
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2130, 2444, 1173, 1189, 904, 3009, 2721, 3118]
	| approx positives in sample 512: 243
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 30, 14, 13, 10, 53, 49, 45]
	Time taken saving stuff: 0.01s
episode: 774/2000 -> reward: -124.99999999999149, steps:56256, time-taken: 2.15min, time-elasped: 2330.80min
-> berries picked: 29 of 800 | patches-visited: [1, 5] | positive-in-buffer: 16710 | amount-filled: 100.00%
	| epsilon: 0.26799033256832494
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2131, 2448, 1176, 1190, 905, 3011, 2726, 3123]
	| approx positives in sample 512: 206
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 26, 18, 15, 7, 35, 27, 44]
	Time taken saving stuff: 12.17s
episode: 775/2000 -> reward: -124.99999999999183, steps:54048, time-taken: 2.31min, time-elasped: 2333.31min
-> berries picked: 24 of 800 | patches-visited: [2, 8] | positive-in-buffer: 16683 | amount-filled: 100.00%
	| epsilon: 0.2677747624159514
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2123, 2446, 1178, 1189, 905, 2998, 2722, 3122]
	| approx positives in sample 512: 202
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [37, 28, 16, 9, 6, 30, 28, 48]
	Time taken saving stuff: 0.01s
episode: 776/2000 -> reward: -124.99999999999184, steps:68928, time-taken: 3.43min, time-elasped: 2336.74min
-> berries picked: 83 of 800 | patches-visited: [4, 6] | positive-in-buffer: 16724 | amount-filled: 100.00%
	| epsilon: 0.26755936566718597
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2122, 2444, 1183, 1194, 908, 3013, 2730, 3130]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 25, 15, 13, 9, 39, 44, 43]
	Time taken saving stuff: 0.01s
episode: 777/2000 -> reward: -124.99999999999179, steps:60672, time-taken: 2.58min, time-elasped: 2339.33min
-> berries picked: 47 of 800 | patches-visited: [0, 6, 7] | positive-in-buffer: 16708 | amount-filled: 100.00%
	| epsilon: 0.26734414218254354
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2119, 2442, 1180, 1191, 909, 3007, 2729, 3131]
	| approx positives in sample 512: 199
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 32, 12, 17, 8, 32, 34, 46]
	Time taken saving stuff: 15.58s
episode: 778/2000 -> reward: -124.999999999992, steps:53184, time-taken: 2.14min, time-elasped: 2341.73min
-> berries picked: 19 of 800 | patches-visited: [9] | positive-in-buffer: 16594 | amount-filled: 100.00%
	| epsilon: 0.26712909182265127
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2098, 2415, 1172, 1181, 904, 2986, 2712, 3126]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 37, 10, 12, 9, 39, 34, 54]
	Time taken saving stuff: 0.00s
episode: 779/2000 -> reward: -124.99999999998735, steps:75936, time-taken: 3.52min, time-elasped: 2345.25min
-> berries picked: 94 of 800 | patches-visited: [7, 9] | positive-in-buffer: 16676 | amount-filled: 100.00%
	| epsilon: 0.2669142144482485
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2106, 2426, 1178, 1197, 913, 2999, 2720, 3137]
	| approx positives in sample 512: 208
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 36, 16, 13, 4, 31, 39, 44]
	Time taken saving stuff: 0.01s
episode: 780/2000 -> reward: -124.99999999999245, steps:65664, time-taken: 2.61min, time-elasped: 2347.86min
-> berries picked: 63 of 800 | patches-visited: [0, 3, 6, 7] | positive-in-buffer: 16689 | amount-filled: 100.00%
	| epsilon: 0.26669950992018643
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2108, 2426, 1182, 1195, 913, 2998, 2728, 3139]
	| approx positives in sample 512: 201
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 31, 12, 8, 7, 32, 42, 53]
	Time taken saving stuff: 12.40s
episode: 781/2000 -> reward: -124.99999999999486, steps:73728, time-taken: 3.44min, time-elasped: 2351.51min
-> berries picked: 84 of 800 | patches-visited: [1, 3] | positive-in-buffer: 16633 | amount-filled: 100.00%
	| epsilon: 0.2664849780994284
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2098, 2421, 1182, 1179, 915, 2985, 2718, 3135]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 33, 10, 17, 10, 39, 48, 45]
	Time taken saving stuff: 0.01s
episode: 782/2000 -> reward: -124.99999999999203, steps:56256, time-taken: 2.59min, time-elasped: 2354.10min
-> berries picked: 30 of 800 | patches-visited: [7] | positive-in-buffer: 16654 | amount-filled: 100.00%
	| epsilon: 0.2662706188470494
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2099, 2421, 1183, 1181, 917, 2993, 2723, 3137]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 24, 11, 22, 7, 33, 47, 37]
	Time taken saving stuff: 0.01s
episode: 783/2000 -> reward: -124.99999999999109, steps:58080, time-taken: 2.31min, time-elasped: 2356.41min
-> berries picked: 41 of 800 | patches-visited: [0, 5, 6] | positive-in-buffer: 16678 | amount-filled: 100.00%
	| epsilon: 0.26605643202423623
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2102, 2426, 1183, 1178, 919, 3002, 2729, 3139]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 27, 15, 15, 14, 45, 39, 46]
	Time taken saving stuff: 15.23s
episode: 784/2000 -> reward: -124.99999999999201, steps:54912, time-taken: 2.30min, time-elasped: 2358.97min
-> berries picked: 21 of 800 | patches-visited: [4] | positive-in-buffer: 16644 | amount-filled: 100.00%
	| epsilon: 0.2658424174922874
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2092, 2420, 1181, 1174, 920, 2993, 2724, 3140]
	| approx positives in sample 512: 211
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 29, 12, 12, 9, 39, 40, 45]
	Time taken saving stuff: 0.01s
episode: 785/2000 -> reward: -124.99999999999368, steps:66048, time-taken: 3.22min, time-elasped: 2362.19min
-> berries picked: 63 of 800 | patches-visited: [1, 6] | positive-in-buffer: 16656 | amount-filled: 100.00%
	| epsilon: 0.26562857511261295
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2098, 2423, 1183, 1177, 914, 2990, 2728, 3143]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 27, 16, 20, 13, 36, 33, 45]
	Time taken saving stuff: 0.00s
episode: 786/2000 -> reward: -124.99999999999152, steps:67104, time-taken: 3.33min, time-elasped: 2365.52min
-> berries picked: 74 of 800 | patches-visited: [3, 4] | positive-in-buffer: 16670 | amount-filled: 100.00%
	| epsilon: 0.26541490474673435
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2094, 2419, 1187, 1176, 914, 2990, 2733, 3157]
	| approx positives in sample 512: 249
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 38, 8, 17, 14, 50, 35, 60]
	Time taken saving stuff: 12.49s
episode: 787/2000 -> reward: -124.99999999999116, steps:75072, time-taken: 5.08min, time-elasped: 2370.81min
-> berries picked: 106 of 800 | patches-visited: [2, 6, 7, 9] | positive-in-buffer: 16695 | amount-filled: 100.00%
	| epsilon: 0.26520140625628463
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2093, 2432, 1191, 1177, 912, 2981, 2739, 3170]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 28, 15, 9, 9, 42, 37, 46]
	Time taken saving stuff: 0.01s
episode: 788/2000 -> reward: -124.99999999999068, steps:54336, time-taken: 3.63min, time-elasped: 2374.45min
-> berries picked: 23 of 800 | patches-visited: [2, 9] | positive-in-buffer: 16622 | amount-filled: 100.00%
	| epsilon: 0.26498807950300796
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2082, 2425, 1177, 1167, 907, 2968, 2727, 3169]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 27, 6, 12, 8, 38, 41, 49]
	Time taken saving stuff: 0.01s
episode: 789/2000 -> reward: -124.99999999999204, steps:54816, time-taken: 2.33min, time-elasped: 2376.78min
-> berries picked: 25 of 800 | patches-visited: [7] | positive-in-buffer: 16600 | amount-filled: 100.00%
	| epsilon: 0.26477492434875977
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2077, 2416, 1178, 1169, 905, 2962, 2721, 3172]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 33, 15, 9, 11, 47, 37, 53]
	Time taken saving stuff: 107.27s
episode: 790/2000 -> reward: -124.99999999999201, steps:50784, time-taken: 1.96min, time-elasped: 2380.53min
-> berries picked: 11 of 800 | patches-visited: [1] | positive-in-buffer: 16545 | amount-filled: 100.00%
	| epsilon: 0.2645619406555066
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2072, 2406, 1178, 1164, 902, 2941, 2711, 3171]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 32, 8, 11, 12, 44, 36, 47]
	Time taken saving stuff: 0.00s
episode: 791/2000 -> reward: -124.99999999999201, steps:66528, time-taken: 3.48min, time-elasped: 2384.01min
-> berries picked: 66 of 800 | patches-visited: [2, 4, 7] | positive-in-buffer: 16600 | amount-filled: 100.00%
	| epsilon: 0.26434912828532603
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2077, 2417, 1182, 1166, 905, 2947, 2722, 3184]
	| approx positives in sample 512: 246
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 30, 11, 19, 11, 44, 49, 57]
	Time taken saving stuff: 0.00s
episode: 792/2000 -> reward: -124.99999999999191, steps:63168, time-taken: 2.54min, time-elasped: 2386.54min
-> berries picked: 59 of 800 | patches-visited: [0, 1, 9] | positive-in-buffer: 16631 | amount-filled: 100.00%
	| epsilon: 0.26413648710040655
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2083, 2415, 1182, 1168, 914, 2953, 2728, 3188]
	| approx positives in sample 512: 192
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 21, 7, 13, 9, 32, 31, 47]
	Time taken saving stuff: 12.01s
episode: 793/2000 -> reward: -124.99999999999203, steps:50688, time-taken: 2.14min, time-elasped: 2388.89min
-> berries picked: 11 of 800 | patches-visited: [1] | positive-in-buffer: 16476 | amount-filled: 100.00%
	| epsilon: 0.2639240169630477
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2067, 2395, 1176, 1151, 911, 2900, 2704, 3172]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [40, 26, 15, 8, 10, 46, 32, 52]
	Time taken saving stuff: 0.01s
episode: 794/2000 -> reward: -124.99999999999193, steps:60096, time-taken: 2.44min, time-elasped: 2391.33min
-> berries picked: 45 of 800 | patches-visited: [9] | positive-in-buffer: 16512 | amount-filled: 100.00%
	| epsilon: 0.2637117177356595
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2069, 2398, 1178, 1154, 921, 2907, 2711, 3174]
	| approx positives in sample 512: 185
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 26, 11, 9, 10, 41, 33, 38]
	Time taken saving stuff: 0.01s
episode: 795/2000 -> reward: -124.99999999999382, steps:63456, time-taken: 2.71min, time-elasped: 2394.04min
-> berries picked: 55 of 800 | patches-visited: [1, 6] | positive-in-buffer: 16525 | amount-filled: 100.00%
	| epsilon: 0.26349958928076284
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2071, 2399, 1180, 1158, 920, 2904, 2713, 3180]
	| approx positives in sample 512: 186
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 33, 9, 12, 7, 25, 32, 45]
	Time taken saving stuff: 21.91s
episode: 796/2000 -> reward: -124.9999999999901, steps:67104, time-taken: 3.37min, time-elasped: 2397.79min
-> berries picked: 69 of 800 | patches-visited: [0, 7] | positive-in-buffer: 16494 | amount-filled: 100.00%
	| epsilon: 0.26328763146098916
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2062, 2400, 1180, 1154, 914, 2894, 2708, 3182]
	| approx positives in sample 512: 226
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 36, 9, 13, 12, 38, 40, 46]
	Time taken saving stuff: 0.01s
episode: 797/2000 -> reward: -124.99999999999194, steps:57792, time-taken: 2.35min, time-elasped: 2400.13min
-> berries picked: 35 of 800 | patches-visited: [5] | positive-in-buffer: 16512 | amount-filled: 100.00%
	| epsilon: 0.2630758441390803
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2065, 2399, 1181, 1156, 914, 2897, 2714, 3186]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 22, 13, 14, 13, 41, 43, 41]
	Time taken saving stuff: 0.01s
episode: 798/2000 -> reward: -124.99999999999316, steps:67008, time-taken: 4.14min, time-elasped: 2404.28min
-> berries picked: 70 of 800 | patches-visited: [3, 7] | positive-in-buffer: 16537 | amount-filled: 100.00%
	| epsilon: 0.2628642271778886
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2068, 2399, 1185, 1157, 918, 2900, 2721, 3189]
	| approx positives in sample 512: 254
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 28, 9, 18, 9, 41, 47, 77]
	Time taken saving stuff: 11.61s
episode: 799/2000 -> reward: -124.9999999999921, steps:59328, time-taken: 2.36min, time-elasped: 2406.83min
-> berries picked: 38 of 800 | patches-visited: [3, 5] | positive-in-buffer: 16563 | amount-filled: 100.00%
	| epsilon: 0.26265278044037677
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2071, 2403, 1188, 1161, 919, 2905, 2725, 3191]
	| approx positives in sample 512: 201
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 29, 14, 8, 11, 44, 37, 41]
	Time taken saving stuff: 0.01s
episode: 800/2000 -> reward: -124.99999999999262, steps:67968, time-taken: 3.56min, time-elasped: 2410.40min
-> berries picked: 64 of 800 | patches-visited: [1, 9] | positive-in-buffer: 16505 | amount-filled: 100.00%
	| epsilon: 0.2624415037896176
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2058, 2395, 1183, 1156, 916, 2887, 2723, 3187]
	| approx positives in sample 512: 241
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 33, 12, 14, 16, 36, 51, 51]
	Time taken saving stuff: 0.01s
episode: 801/2000 -> reward: -124.99999999999193, steps:64416, time-taken: 2.46min, time-elasped: 2412.86min
-> berries picked: 64 of 800 | patches-visited: [0, 9] | positive-in-buffer: 16555 | amount-filled: 100.00%
	| epsilon: 0.2622303970887942
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2062, 2404, 1186, 1161, 920, 2899, 2730, 3193]
	| approx positives in sample 512: 193
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 26, 14, 12, 6, 31, 34, 41]
	Time taken saving stuff: 14.84s
episode: 802/2000 -> reward: -124.99999999999218, steps:49344, time-taken: 2.33min, time-elasped: 2415.44min
-> berries picked: 4 of 800 | patches-visited: [3] | positive-in-buffer: 16448 | amount-filled: 100.00%
	| epsilon: 0.26201946020119965
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2051, 2385, 1178, 1149, 913, 2882, 2713, 3177]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 29, 10, 20, 4, 40, 39, 58]
	Time taken saving stuff: 0.01s
episode: 803/2000 -> reward: -124.99999999999208, steps:53568, time-taken: 2.07min, time-elasped: 2417.51min
-> berries picked: 18 of 800 | patches-visited: [3] | positive-in-buffer: 16464 | amount-filled: 100.00%
	| epsilon: 0.2618086929902369
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2053, 2388, 1178, 1148, 914, 2885, 2716, 3182]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 27, 15, 11, 8, 35, 56, 50]
	Time taken saving stuff: 0.00s
episode: 804/2000 -> reward: -124.99999999999203, steps:57984, time-taken: 2.35min, time-elasped: 2419.87min
-> berries picked: 35 of 800 | patches-visited: [1] | positive-in-buffer: 16493 | amount-filled: 100.00%
	| epsilon: 0.26159809531941897
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2057, 2391, 1183, 1150, 919, 2887, 2719, 3187]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 28, 18, 15, 16, 37, 28, 49]
	Time taken saving stuff: 11.77s
episode: 805/2000 -> reward: -124.99999999999267, steps:51936, time-taken: 2.64min, time-elasped: 2422.71min
-> berries picked: 19 of 800 | patches-visited: [2] | positive-in-buffer: 16504 | amount-filled: 100.00%
	| epsilon: 0.26138766705236843
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2058, 2392, 1184, 1153, 920, 2887, 2722, 3188]
	| approx positives in sample 512: 205
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 19, 18, 14, 9, 31, 35, 46]
	Time taken saving stuff: 0.00s
episode: 806/2000 -> reward: -124.99999999999197, steps:56352, time-taken: 2.32min, time-elasped: 2425.03min
-> berries picked: 30 of 800 | patches-visited: [5] | positive-in-buffer: 16527 | amount-filled: 100.00%
	| epsilon: 0.26117740805281786
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2061, 2394, 1187, 1157, 922, 2890, 2725, 3191]
	| approx positives in sample 512: 203
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 25, 12, 10, 2, 44, 27, 56]
	Time taken saving stuff: 0.01s
episode: 807/2000 -> reward: -124.9999999999917, steps:58848, time-taken: 2.21min, time-elasped: 2427.24min
-> berries picked: 40 of 800 | patches-visited: [7] | positive-in-buffer: 16542 | amount-filled: 100.00%
	| epsilon: 0.2609673181846093
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2058, 2397, 1186, 1163, 923, 2891, 2729, 3195]
	| approx positives in sample 512: 189
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 28, 11, 11, 13, 24, 43, 38]
	Time taken saving stuff: 15.04s
episode: 808/2000 -> reward: -124.99999999998937, steps:63936, time-taken: 2.40min, time-elasped: 2429.90min
-> berries picked: 61 of 800 | patches-visited: [3, 7] | positive-in-buffer: 16514 | amount-filled: 100.00%
	| epsilon: 0.2607573973116941
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2048, 2388, 1185, 1163, 929, 2882, 2727, 3192]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 25, 11, 15, 11, 29, 34, 58]
	Time taken saving stuff: 0.01s
episode: 809/2000 -> reward: -124.99999999998832, steps:76512, time-taken: 3.25min, time-elasped: 2433.16min
-> berries picked: 103 of 800 | patches-visited: [1, 4, 6] | positive-in-buffer: 16496 | amount-filled: 100.00%
	| epsilon: 0.2605476452981334
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2047, 2383, 1187, 1164, 918, 2873, 2723, 3201]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 28, 12, 14, 8, 34, 38, 51]
	Time taken saving stuff: 0.01s
episode: 810/2000 -> reward: -124.9999999999888, steps:78720, time-taken: 3.76min, time-elasped: 2436.92min
-> berries picked: 110 of 800 | patches-visited: [2, 5, 9] | positive-in-buffer: 16554 | amount-filled: 100.00%
	| epsilon: 0.2603380620080975
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2059, 2385, 1191, 1169, 919, 2885, 2730, 3216]
	| approx positives in sample 512: 191
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 18, 10, 12, 11, 21, 33, 60]
	Time taken saving stuff: 11.92s
episode: 811/2000 -> reward: -124.99999999999189, steps:61728, time-taken: 2.60min, time-elasped: 2439.72min
-> berries picked: 48 of 800 | patches-visited: [5, 8] | positive-in-buffer: 16433 | amount-filled: 100.00%
	| epsilon: 0.260128647305866
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2043, 2358, 1174, 1155, 914, 2864, 2710, 3215]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 23, 20, 13, 13, 30, 37, 54]
	Time taken saving stuff: 0.01s
episode: 812/2000 -> reward: -124.9999999999914, steps:63264, time-taken: 2.42min, time-elasped: 2442.15min
-> berries picked: 54 of 800 | patches-visited: [6, 7] | positive-in-buffer: 16464 | amount-filled: 100.00%
	| epsilon: 0.25991940105582767
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2047, 2367, 1178, 1157, 913, 2864, 2716, 3222]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 24, 9, 15, 12, 24, 44, 56]
	Time taken saving stuff: 0.01s
episode: 813/2000 -> reward: -124.99999999999245, steps:67008, time-taken: 3.07min, time-elasped: 2445.22min
-> berries picked: 67 of 800 | patches-visited: [1, 8] | positive-in-buffer: 16467 | amount-filled: 100.00%
	| epsilon: 0.2597103231224804
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2041, 2368, 1177, 1167, 915, 2860, 2715, 3224]
	| approx positives in sample 512: 248
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 35, 15, 21, 16, 36, 45, 56]
	Time taken saving stuff: 15.10s
episode: 814/2000 -> reward: -124.99999999999208, steps:62304, time-taken: 2.54min, time-elasped: 2448.02min
-> berries picked: 46 of 800 | patches-visited: [2, 9] | positive-in-buffer: 16500 | amount-filled: 100.00%
	| epsilon: 0.259501413370431
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2047, 2373, 1176, 1168, 920, 2862, 2716, 3238]
	| approx positives in sample 512: 205
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 21, 8, 14, 10, 38, 38, 54]
	Time taken saving stuff: 0.01s
episode: 815/2000 -> reward: -124.99999999998754, steps:83424, time-taken: 3.34min, time-elasped: 2451.36min
-> berries picked: 125 of 800 | patches-visited: [0, 4, 8, 9] | positive-in-buffer: 16563 | amount-filled: 100.00%
	| epsilon: 0.2592926716643952
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2057, 2381, 1179, 1174, 925, 2869, 2726, 3252]
	| approx positives in sample 512: 207
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 22, 13, 16, 7, 37, 30, 58]
	Time taken saving stuff: 0.01s
episode: 816/2000 -> reward: -124.9999999999916, steps:85824, time-taken: 5.22min, time-elasped: 2456.59min
-> berries picked: 142 of 800 | patches-visited: [1, 3, 7, 9] | positive-in-buffer: 16586 | amount-filled: 100.00%
	| epsilon: 0.2590840978691976
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2060, 2400, 1184, 1176, 935, 2839, 2725, 3267]
	| approx positives in sample 512: 186
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 21, 12, 7, 8, 30, 32, 43]
	Time taken saving stuff: 12.86s
episode: 817/2000 -> reward: -124.99999999999204, steps:57792, time-taken: 2.14min, time-elasped: 2458.94min
-> berries picked: 32 of 800 | patches-visited: [0] | positive-in-buffer: 16470 | amount-filled: 100.00%
	| epsilon: 0.2588756918497716
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2046, 2383, 1176, 1161, 923, 2807, 2712, 3262]
	| approx positives in sample 512: 202
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 34, 10, 12, 10, 30, 37, 46]
	Time taken saving stuff: 0.01s
episode: 818/2000 -> reward: -124.9999999999868, steps:73920, time-taken: 3.83min, time-elasped: 2462.78min
-> berries picked: 93 of 800 | patches-visited: [1, 2, 9] | positive-in-buffer: 16546 | amount-filled: 100.00%
	| epsilon: 0.25866745347115905
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2054, 2405, 1179, 1164, 934, 2819, 2720, 3271]
	| approx positives in sample 512: 244
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 39, 25, 14, 17, 30, 46, 50]
	Time taken saving stuff: 0.01s
episode: 819/2000 -> reward: -124.99999999999108, steps:69696, time-taken: 3.40min, time-elasped: 2466.18min
-> berries picked: 77 of 800 | patches-visited: [4, 5] | positive-in-buffer: 16579 | amount-filled: 100.00%
	| epsilon: 0.2584593825985106
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2055, 2399, 1186, 1172, 936, 2821, 2729, 3281]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 29, 10, 14, 9, 35, 45, 67]
	Time taken saving stuff: 15.59s
episode: 820/2000 -> reward: -124.99999999999223, steps:57504, time-taken: 2.17min, time-elasped: 2468.61min
-> berries picked: 34 of 800 | patches-visited: [0, 2] | positive-in-buffer: 16584 | amount-filled: 100.00%
	| epsilon: 0.2582514790970851
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2059, 2397, 1186, 1174, 935, 2820, 2729, 3284]
	| approx positives in sample 512: 197
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 31, 10, 12, 16, 31, 29, 40]
	Time taken saving stuff: 0.01s
episode: 821/2000 -> reward: -124.99999999999375, steps:56544, time-taken: 2.55min, time-elasped: 2471.16min
-> berries picked: 31 of 800 | patches-visited: [2] | positive-in-buffer: 16503 | amount-filled: 100.00%
	| epsilon: 0.25804374283225007
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2035, 2386, 1183, 1169, 925, 2805, 2726, 3274]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 31, 17, 14, 6, 36, 43, 54]
	Time taken saving stuff: 0.01s
episode: 822/2000 -> reward: -124.99999999999163, steps:70368, time-taken: 3.51min, time-elasped: 2474.67min
-> berries picked: 80 of 800 | patches-visited: [1, 6, 7] | positive-in-buffer: 16537 | amount-filled: 100.00%
	| epsilon: 0.25783617366948114
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2035, 2398, 1188, 1172, 928, 2805, 2727, 3284]
	| approx positives in sample 512: 240
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 25, 11, 21, 20, 57, 32, 51]
	Time taken saving stuff: 12.37s
episode: 823/2000 -> reward: -124.99999999999346, steps:74112, time-taken: 3.33min, time-elasped: 2478.21min
-> berries picked: 90 of 800 | patches-visited: [0, 1, 8] | positive-in-buffer: 16598 | amount-filled: 100.00%
	| epsilon: 0.2576287714743621
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2046, 2407, 1193, 1177, 934, 2817, 2732, 3292]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 24, 23, 11, 3, 30, 41, 60]
	Time taken saving stuff: 0.01s
episode: 824/2000 -> reward: -124.99999999999555, steps:82080, time-taken: 3.77min, time-elasped: 2481.99min
-> berries picked: 108 of 800 | patches-visited: [3, 4, 5, 9] | positive-in-buffer: 16631 | amount-filled: 100.00%
	| epsilon: 0.2574215361125851
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2047, 2408, 1197, 1179, 931, 2822, 2741, 3306]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 23, 12, 18, 20, 35, 32, 50]
	Time taken saving stuff: 0.01s
episode: 825/2000 -> reward: -124.99999999998818, steps:61056, time-taken: 2.30min, time-elasped: 2484.29min
-> berries picked: 50 of 800 | patches-visited: [6, 7] | positive-in-buffer: 16581 | amount-filled: 100.00%
	| epsilon: 0.2572144674499502
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2036, 2394, 1192, 1178, 931, 2802, 2739, 3309]
	| approx positives in sample 512: 207
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 24, 8, 18, 8, 28, 34, 60]
	Time taken saving stuff: 14.74s
episode: 826/2000 -> reward: -124.99999999999193, steps:66720, time-taken: 3.24min, time-elasped: 2487.78min
-> berries picked: 66 of 800 | patches-visited: [3, 4] | positive-in-buffer: 16563 | amount-filled: 100.00%
	| epsilon: 0.2570075653523653
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2033, 2397, 1193, 1183, 931, 2796, 2725, 3305]
	| approx positives in sample 512: 240
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 37, 12, 18, 14, 45, 41, 51]
	Time taken saving stuff: 0.00s
episode: 827/2000 -> reward: -124.99999999999248, steps:66336, time-taken: 3.45min, time-elasped: 2491.23min
-> berries picked: 66 of 800 | patches-visited: [3, 6] | positive-in-buffer: 16597 | amount-filled: 100.00%
	| epsilon: 0.2568008296858463
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2040, 2398, 1194, 1187, 934, 2803, 2731, 3310]
	| approx positives in sample 512: 242
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 33, 15, 17, 13, 45, 43, 54]
	Time taken saving stuff: 0.01s
episode: 828/2000 -> reward: -124.99999999999201, steps:61344, time-taken: 2.71min, time-elasped: 2493.94min
-> berries picked: 49 of 800 | patches-visited: [4] | positive-in-buffer: 16618 | amount-filled: 100.00%
	| epsilon: 0.2565942603165169
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2046, 2402, 1195, 1191, 938, 2802, 2731, 3313]
	| approx positives in sample 512: 204
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 29, 7, 19, 13, 31, 31, 42]
	Time taken saving stuff: 12.89s
episode: 829/2000 -> reward: -124.99999999999204, steps:50592, time-taken: 3.24min, time-elasped: 2497.40min
-> berries picked: 8 of 800 | patches-visited: [2] | positive-in-buffer: 16488 | amount-filled: 100.00%
	| epsilon: 0.2563878571106083
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2026, 2372, 1192, 1177, 933, 2769, 2715, 3304]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 25, 9, 14, 9, 35, 32, 69]
	Time taken saving stuff: 0.01s
episode: 830/2000 -> reward: -124.99999999999203, steps:50976, time-taken: 2.16min, time-elasped: 2499.56min
-> berries picked: 13 of 800 | patches-visited: [3] | positive-in-buffer: 16499 | amount-filled: 100.00%
	| epsilon: 0.25618161993445954
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2026, 2375, 1192, 1178, 934, 2772, 2716, 3306]
	| approx positives in sample 512: 230
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 26, 16, 20, 8, 39, 32, 57]
	Time taken saving stuff: 0.00s
episode: 831/2000 -> reward: -124.99999999999201, steps:50976, time-taken: 2.78min, time-elasped: 2502.35min
-> berries picked: 10 of 800 | patches-visited: [0] | positive-in-buffer: 16507 | amount-filled: 100.00%
	| epsilon: 0.25597554865451705
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2027, 2378, 1192, 1180, 934, 2771, 2718, 3307]
	| approx positives in sample 512: 246
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 30, 10, 17, 14, 36, 48, 65]
	Time taken saving stuff: 15.36s
episode: 832/2000 -> reward: -124.99999999999105, steps:70752, time-taken: 3.84min, time-elasped: 2506.45min
-> berries picked: 88 of 800 | patches-visited: [6, 9] | positive-in-buffer: 16566 | amount-filled: 100.00%
	| epsilon: 0.2557696431373347
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2037, 2387, 1198, 1188, 943, 2777, 2724, 3312]
	| approx positives in sample 512: 245
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 30, 21, 9, 7, 44, 46, 58]
	Time taken saving stuff: 0.01s
episode: 833/2000 -> reward: -124.99999999999389, steps:80256, time-taken: 4.36min, time-elasped: 2510.82min
-> berries picked: 121 of 800 | patches-visited: [0, 3, 4] | positive-in-buffer: 16624 | amount-filled: 100.00%
	| epsilon: 0.25556390324957373
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2043, 2398, 1203, 1194, 945, 2785, 2734, 3322]
	| approx positives in sample 512: 202
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 30, 10, 11, 14, 36, 38, 38]
	Time taken saving stuff: 0.01s
episode: 834/2000 -> reward: -124.99999999999217, steps:53184, time-taken: 3.05min, time-elasped: 2513.87min
-> berries picked: 19 of 800 | patches-visited: [9] | positive-in-buffer: 16542 | amount-filled: 100.00%
	| epsilon: 0.2553583288580026
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2034, 2379, 1200, 1186, 937, 2765, 2718, 3323]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 28, 13, 14, 14, 38, 38, 58]
	Time taken saving stuff: 13.00s
episode: 835/2000 -> reward: -124.99999999999437, steps:71424, time-taken: 3.82min, time-elasped: 2517.91min
-> berries picked: 89 of 800 | patches-visited: [5, 6] | positive-in-buffer: 16605 | amount-filled: 100.00%
	| epsilon: 0.2551529198294969
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2041, 2388, 1208, 1193, 945, 2774, 2723, 3333]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 45, 14, 13, 15, 32, 34, 41]
	Time taken saving stuff: 0.01s
episode: 836/2000 -> reward: -124.99999999999218, steps:60960, time-taken: 2.40min, time-elasped: 2520.31min
-> berries picked: 49 of 800 | patches-visited: [2] | positive-in-buffer: 16628 | amount-filled: 100.00%
	| epsilon: 0.25494767603103946
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2045, 2392, 1210, 1194, 947, 2773, 2727, 3340]
	| approx positives in sample 512: 194
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 22, 15, 10, 8, 19, 39, 55]
	Time taken saving stuff: 0.01s
episode: 837/2000 -> reward: -124.99999999999162, steps:62112, time-taken: 2.54min, time-elasped: 2522.86min
-> berries picked: 53 of 800 | patches-visited: [0, 7] | positive-in-buffer: 16553 | amount-filled: 100.00%
	| epsilon: 0.25474259732972
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2032, 2375, 1202, 1185, 947, 2759, 2717, 3336]
	| approx positives in sample 512: 194
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 19, 13, 10, 8, 29, 45, 45]
	Time taken saving stuff: 16.30s
episode: 838/2000 -> reward: -124.99999999999203, steps:50496, time-taken: 2.20min, time-elasped: 2525.33min
-> berries picked: 10 of 800 | patches-visited: [6] | positive-in-buffer: 16467 | amount-filled: 100.00%
	| epsilon: 0.2545376835927351
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2018, 2366, 1199, 1177, 940, 2741, 2703, 3323]
	| approx positives in sample 512: 235
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [38, 29, 18, 10, 9, 35, 36, 60]
	Time taken saving stuff: 0.01s
episode: 839/2000 -> reward: -124.99999999999203, steps:53088, time-taken: 2.29min, time-elasped: 2527.63min
-> berries picked: 20 of 800 | patches-visited: [4] | positive-in-buffer: 16486 | amount-filled: 100.00%
	| epsilon: 0.25433293468738827
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2021, 2369, 1202, 1177, 941, 2744, 2704, 3328]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [36, 34, 15, 13, 8, 39, 33, 41]
	Time taken saving stuff: 0.01s
episode: 840/2000 -> reward: -124.99999999999054, steps:73920, time-taken: 3.47min, time-elasped: 2531.09min
-> berries picked: 98 of 800 | patches-visited: [1, 6, 8] | positive-in-buffer: 16555 | amount-filled: 100.00%
	| epsilon: 0.2541283504810898
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2032, 2381, 1209, 1184, 946, 2756, 2715, 3332]
	| approx positives in sample 512: 223
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 27, 13, 11, 10, 44, 42, 47]
	Time taken saving stuff: 13.15s
episode: 841/2000 -> reward: -124.99999999999204, steps:54912, time-taken: 2.26min, time-elasped: 2533.57min
-> berries picked: 29 of 800 | patches-visited: [8] | positive-in-buffer: 16556 | amount-filled: 100.00%
	| epsilon: 0.2539239308413564
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2026, 2378, 1210, 1193, 945, 2759, 2711, 3334]
	| approx positives in sample 512: 187
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 32, 10, 12, 9, 25, 19, 49]
	Time taken saving stuff: 0.01s
episode: 842/2000 -> reward: -124.99999999999201, steps:57312, time-taken: 2.01min, time-elasped: 2535.59min
-> berries picked: 39 of 800 | patches-visited: [8] | positive-in-buffer: 16527 | amount-filled: 100.00%
	| epsilon: 0.2537196756358116
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2024, 2370, 1213, 1188, 952, 2738, 2705, 3337]
	| approx positives in sample 512: 203
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 23, 12, 14, 10, 33, 34, 47]
	Time taken saving stuff: 0.01s
episode: 843/2000 -> reward: -124.99999999999203, steps:59808, time-taken: 2.93min, time-elasped: 2538.52min
-> berries picked: 41 of 800 | patches-visited: [5] | positive-in-buffer: 16492 | amount-filled: 100.00%
	| epsilon: 0.25351558473218533
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2018, 2366, 1213, 1185, 954, 2723, 2698, 3335]
	| approx positives in sample 512: 211
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 26, 16, 12, 8, 28, 43, 54]
	Time taken saving stuff: 14.78s
episode: 844/2000 -> reward: -124.99999999999251, steps:63552, time-taken: 2.38min, time-elasped: 2541.15min
-> berries picked: 59 of 800 | patches-visited: [0] | positive-in-buffer: 16484 | amount-filled: 100.00%
	| epsilon: 0.2533116579983139
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2006, 2364, 1216, 1191, 956, 2710, 2701, 3340]
	| approx positives in sample 512: 207
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 22, 12, 13, 10, 36, 34, 62]
	Time taken saving stuff: 0.01s
episode: 845/2000 -> reward: -124.99999999999241, steps:62496, time-taken: 2.64min, time-elasped: 2543.79min
-> berries picked: 52 of 800 | patches-visited: [3, 5] | positive-in-buffer: 16439 | amount-filled: 100.00%
	| epsilon: 0.2531078953021399
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1999, 2365, 1217, 1181, 951, 2692, 2694, 3340]
	| approx positives in sample 512: 192
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 22, 15, 16, 8, 24, 28, 53]
	Time taken saving stuff: 0.01s
episode: 846/2000 -> reward: -124.9999999999923, steps:60672, time-taken: 2.37min, time-elasped: 2546.17min
-> berries picked: 48 of 800 | patches-visited: [7] | positive-in-buffer: 16452 | amount-filled: 100.00%
	| epsilon: 0.25290429651171226
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1999, 2364, 1222, 1188, 951, 2692, 2692, 3344]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 31, 17, 10, 11, 34, 32, 63]
	Time taken saving stuff: 12.29s
episode: 847/2000 -> reward: -124.99999999999109, steps:65856, time-taken: 2.39min, time-elasped: 2548.77min
-> berries picked: 70 of 800 | patches-visited: [0] | positive-in-buffer: 16477 | amount-filled: 100.00%
	| epsilon: 0.25270086149518584
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1998, 2368, 1226, 1189, 952, 2691, 2694, 3359]
	| approx positives in sample 512: 167
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 15, 7, 7, 10, 29, 33, 44]
	Time taken saving stuff: 0.01s
episode: 848/2000 -> reward: -124.99999999999162, steps:59808, time-taken: 2.37min, time-elasped: 2551.14min
-> berries picked: 41 of 800 | patches-visited: [0, 6] | positive-in-buffer: 16412 | amount-filled: 100.00%
	| epsilon: 0.2524975901208218
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1987, 2356, 1223, 1183, 949, 2675, 2687, 3352]
	| approx positives in sample 512: 181
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 29, 8, 8, 10, 27, 33, 48]
	Time taken saving stuff: 0.01s
episode: 849/2000 -> reward: -124.99999999999206, steps:60288, time-taken: 2.37min, time-elasped: 2553.52min
-> berries picked: 43 of 800 | patches-visited: [6] | positive-in-buffer: 16446 | amount-filled: 100.00%
	| epsilon: 0.25229448225698714
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1989, 2361, 1228, 1189, 949, 2680, 2693, 3357]
	| approx positives in sample 512: 207
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 32, 20, 13, 12, 30, 40, 37]
	Time taken saving stuff: 15.70s
episode: 850/2000 -> reward: -124.99999999999201, steps:58176, time-taken: 2.44min, time-elasped: 2556.22min
-> berries picked: 38 of 800 | patches-visited: [7] | positive-in-buffer: 16456 | amount-filled: 100.00%
	| epsilon: 0.25209153777215476
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1988, 2360, 1227, 1191, 950, 2682, 2696, 3362]
	| approx positives in sample 512: 203
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 36, 14, 12, 8, 33, 31, 45]
	Time taken saving stuff: 0.01s
episode: 851/2000 -> reward: -124.99999999999393, steps:63744, time-taken: 2.89min, time-elasped: 2559.11min
-> berries picked: 53 of 800 | patches-visited: [0, 3] | positive-in-buffer: 16487 | amount-filled: 100.00%
	| epsilon: 0.25188875653490334
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1990, 2365, 1230, 1195, 951, 2687, 2701, 3368]
	| approx positives in sample 512: 191
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 23, 10, 6, 7, 25, 35, 58]
	Time taken saving stuff: 0.01s
episode: 852/2000 -> reward: -124.99999999998847, steps:79200, time-taken: 3.37min, time-elasped: 2562.49min
-> berries picked: 123 of 800 | patches-visited: [1, 3, 5] | positive-in-buffer: 16459 | amount-filled: 100.00%
	| epsilon: 0.25168613841391735
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1978, 2339, 1230, 1195, 962, 2676, 2707, 3372]
	| approx positives in sample 512: 202
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 27, 17, 12, 7, 32, 42, 42]
	Time taken saving stuff: 11.90s
episode: 853/2000 -> reward: -124.99999999999368, steps:86112, time-taken: 3.77min, time-elasped: 2566.46min
-> berries picked: 142 of 800 | patches-visited: [1, 7, 9] | positive-in-buffer: 16552 | amount-filled: 100.00%
	| epsilon: 0.2514836832779868
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1990, 2346, 1243, 1208, 975, 2684, 2719, 3387]
	| approx positives in sample 512: 201
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 21, 7, 12, 7, 36, 31, 53]
	Time taken saving stuff: 0.01s
episode: 854/2000 -> reward: -124.99999999999203, steps:52032, time-taken: 2.02min, time-elasped: 2568.48min
-> berries picked: 14 of 800 | patches-visited: [4] | positive-in-buffer: 16437 | amount-filled: 100.00%
	| epsilon: 0.25128139099600727
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1982, 2322, 1235, 1200, 963, 2654, 2704, 3377]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 22, 10, 16, 10, 39, 33, 58]
	Time taken saving stuff: 0.01s
episode: 855/2000 -> reward: -124.99999999999201, steps:54048, time-taken: 2.42min, time-elasped: 2570.90min
-> berries picked: 20 of 800 | patches-visited: [5] | positive-in-buffer: 16448 | amount-filled: 100.00%
	| epsilon: 0.2510792614369799
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1981, 2323, 1235, 1202, 966, 2657, 2706, 3378]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 27, 17, 12, 7, 34, 42, 56]
	Time taken saving stuff: 15.38s
episode: 856/2000 -> reward: -124.99999999999203, steps:49440, time-taken: 1.89min, time-elasped: 2573.05min
-> berries picked: 4 of 800 | patches-visited: [5] | positive-in-buffer: 16448 | amount-filled: 100.00%
	| epsilon: 0.250877294470011
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1981, 2323, 1235, 1201, 967, 2656, 2706, 3379]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 30, 17, 19, 10, 39, 39, 55]
	Time taken saving stuff: 0.00s
episode: 857/2000 -> reward: -124.99999999999339, steps:60576, time-taken: 2.52min, time-elasped: 2575.58min
-> berries picked: 42 of 800 | patches-visited: [2] | positive-in-buffer: 16478 | amount-filled: 100.00%
	| epsilon: 0.25067548996431244
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1986, 2326, 1238, 1204, 971, 2661, 2712, 3380]
	| approx positives in sample 512: 201
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 38, 13, 12, 7, 27, 38, 46]
	Time taken saving stuff: 0.01s
episode: 858/2000 -> reward: -124.99999999999214, steps:63168, time-taken: 2.14min, time-elasped: 2577.72min
-> berries picked: 53 of 800 | patches-visited: [3, 6, 7] | positive-in-buffer: 16483 | amount-filled: 100.00%
	| epsilon: 0.25047384778920095
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1987, 2324, 1238, 1208, 970, 2661, 2707, 3388]
	| approx positives in sample 512: 196
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 29, 7, 16, 8, 32, 39, 41]
	Time taken saving stuff: 12.28s
episode: 859/2000 -> reward: -124.99999999999226, steps:54240, time-taken: 2.21min, time-elasped: 2580.13min
-> berries picked: 21 of 800 | patches-visited: [3] | positive-in-buffer: 16426 | amount-filled: 100.00%
	| epsilon: 0.2502723678140988
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1973, 2320, 1232, 1202, 967, 2644, 2704, 3384]
	| approx positives in sample 512: 223
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 33, 13, 15, 10, 28, 36, 64]
	Time taken saving stuff: 0.01s
episode: 860/2000 -> reward: -124.99999999999203, steps:56640, time-taken: 2.04min, time-elasped: 2582.17min
-> berries picked: 30 of 800 | patches-visited: [3] | positive-in-buffer: 16451 | amount-filled: 100.00%
	| epsilon: 0.2500710499085328
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1977, 2323, 1235, 1203, 969, 2649, 2706, 3389]
	| approx positives in sample 512: 211
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 25, 14, 6, 6, 33, 37, 62]
	Time taken saving stuff: 0.01s
episode: 861/2000 -> reward: -124.9999999999912, steps:77664, time-taken: 3.20min, time-elasped: 2585.38min
-> berries picked: 105 of 800 | patches-visited: [4, 8, 9] | positive-in-buffer: 16530 | amount-filled: 100.00%
	| epsilon: 0.24986989394213524
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1989, 2329, 1244, 1216, 974, 2657, 2715, 3406]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 28, 14, 14, 9, 32, 37, 61]
	Time taken saving stuff: 15.35s
episode: 862/2000 -> reward: -124.99999999999042, steps:65184, time-taken: 2.63min, time-elasped: 2588.26min
-> berries picked: 64 of 800 | patches-visited: [1, 6] | positive-in-buffer: 16535 | amount-filled: 100.00%
	| epsilon: 0.2496688997846429
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1989, 2328, 1242, 1220, 979, 2651, 2717, 3409]
	| approx positives in sample 512: 206
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 25, 15, 15, 12, 30, 34, 60]
	Time taken saving stuff: 0.01s
episode: 863/2000 -> reward: -124.99999999999109, steps:65088, time-taken: 2.33min, time-elasped: 2590.60min
-> berries picked: 66 of 800 | patches-visited: [4, 7] | positive-in-buffer: 16468 | amount-filled: 100.00%
	| epsilon: 0.2494680673058975
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1977, 2314, 1236, 1215, 976, 2634, 2704, 3412]
	| approx positives in sample 512: 186
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 32, 12, 11, 7, 28, 29, 39]
	Time taken saving stuff: 0.01s
episode: 864/2000 -> reward: -124.99999999999203, steps:60096, time-taken: 2.05min, time-elasped: 2592.64min
-> berries picked: 40 of 800 | patches-visited: [7] | positive-in-buffer: 16382 | amount-filled: 100.00%
	| epsilon: 0.24926739637584538
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1962, 2296, 1232, 1215, 974, 2602, 2694, 3407]
	| approx positives in sample 512: 190
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 21, 12, 15, 15, 26, 35, 40]
	Time taken saving stuff: 12.11s
episode: 865/2000 -> reward: -124.99999999999342, steps:68832, time-taken: 3.17min, time-elasped: 2596.02min
-> berries picked: 78 of 800 | patches-visited: [2, 7] | positive-in-buffer: 16439 | amount-filled: 100.00%
	| epsilon: 0.24906688686453757
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1966, 2304, 1238, 1217, 981, 2611, 2701, 3421]
	| approx positives in sample 512: 245
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 32, 20, 23, 9, 33, 38, 55]
	Time taken saving stuff: 0.00s
episode: 866/2000 -> reward: -124.99999999999203, steps:54336, time-taken: 2.20min, time-elasped: 2598.22min
-> berries picked: 22 of 800 | patches-visited: [0] | positive-in-buffer: 16452 | amount-filled: 100.00%
	| epsilon: 0.24886653864212957
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1969, 2307, 1239, 1218, 983, 2611, 2702, 3423]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 25, 12, 12, 11, 30, 41, 58]
	Time taken saving stuff: 0.00s
episode: 867/2000 -> reward: -124.99999999999199, steps:56352, time-taken: 2.05min, time-elasped: 2600.27min
-> berries picked: 31 of 800 | patches-visited: [5, 7] | positive-in-buffer: 16468 | amount-filled: 100.00%
	| epsilon: 0.2486663515788814
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1971, 2308, 1242, 1221, 984, 2615, 2700, 3427]
	| approx positives in sample 512: 206
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 36, 6, 14, 12, 31, 34, 53]
	Time taken saving stuff: 15.60s
episode: 868/2000 -> reward: -124.99999999999203, steps:53856, time-taken: 2.14min, time-elasped: 2602.68min
-> berries picked: 21 of 800 | patches-visited: [9] | positive-in-buffer: 16437 | amount-filled: 100.00%
	| epsilon: 0.24846632554515735
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1966, 2301, 1238, 1215, 982, 2609, 2695, 3431]
	| approx positives in sample 512: 211
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 15, 13, 15, 14, 44, 32, 43]
	Time taken saving stuff: 0.01s
episode: 869/2000 -> reward: -124.99999999998494, steps:91488, time-taken: 4.52min, time-elasped: 2607.19min
-> berries picked: 152 of 800 | patches-visited: [2, 5, 6, 8, 9] | positive-in-buffer: 16555 | amount-filled: 100.00%
	| epsilon: 0.24826646041142605
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1987, 2311, 1252, 1226, 987, 2627, 2701, 3464]
	| approx positives in sample 512: 244
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 30, 12, 17, 11, 45, 39, 61]
	Time taken saving stuff: 0.00s
episode: 870/2000 -> reward: -124.9999999999926, steps:85152, time-taken: 3.53min, time-elasped: 2610.73min
-> berries picked: 152 of 800 | patches-visited: [2, 5, 7] | positive-in-buffer: 16584 | amount-filled: 100.00%
	| epsilon: 0.24806675604826034
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1986, 2304, 1261, 1244, 993, 2628, 2695, 3473]
	| approx positives in sample 512: 192
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 18, 12, 12, 13, 32, 34, 47]
	Time taken saving stuff: 11.95s
episode: 871/2000 -> reward: -124.99999999999328, steps:64704, time-taken: 2.34min, time-elasped: 2613.27min
-> berries picked: 64 of 800 | patches-visited: [6, 7] | positive-in-buffer: 16494 | amount-filled: 100.00%
	| epsilon: 0.2478672123263371
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1977, 2287, 1255, 1234, 982, 2620, 2667, 3472]
	| approx positives in sample 512: 197
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [37, 20, 7, 14, 10, 32, 20, 57]
	Time taken saving stuff: 0.01s
episode: 872/2000 -> reward: -124.99999999999406, steps:66144, time-taken: 3.18min, time-elasped: 2616.45min
-> berries picked: 66 of 800 | patches-visited: [0, 8] | positive-in-buffer: 16501 | amount-filled: 100.00%
	| epsilon: 0.24766782911643728
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1979, 2276, 1262, 1233, 983, 2628, 2665, 3475]
	| approx positives in sample 512: 235
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 30, 10, 16, 11, 31, 42, 68]
	Time taken saving stuff: 0.00s
episode: 873/2000 -> reward: -124.99999999999238, steps:65280, time-taken: 2.35min, time-elasped: 2618.80min
-> berries picked: 65 of 800 | patches-visited: [3, 6, 8] | positive-in-buffer: 16541 | amount-filled: 100.00%
	| epsilon: 0.2474686062894458
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1981, 2279, 1263, 1239, 987, 2634, 2674, 3484]
	| approx positives in sample 512: 205
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 24, 16, 5, 12, 25, 43, 54]
	Time taken saving stuff: 15.23s
episode: 874/2000 -> reward: -124.99999999999135, steps:65952, time-taken: 2.22min, time-elasped: 2621.28min
-> berries picked: 66 of 800 | patches-visited: [3, 7] | positive-in-buffer: 16518 | amount-filled: 100.00%
	| epsilon: 0.24726954371635138
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1985, 2269, 1265, 1239, 990, 2627, 2661, 3482]
	| approx positives in sample 512: 185
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 29, 9, 14, 12, 25, 38, 42]
	Time taken saving stuff: 0.01s
episode: 875/2000 -> reward: -124.99999999999264, steps:65856, time-taken: 2.36min, time-elasped: 2623.64min
-> berries picked: 66 of 800 | patches-visited: [0, 7] | positive-in-buffer: 16504 | amount-filled: 100.00%
	| epsilon: 0.24707064126824654
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1987, 2262, 1268, 1229, 992, 2624, 2654, 3488]
	| approx positives in sample 512: 192
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 18, 14, 19, 8, 30, 34, 47]
	Time taken saving stuff: 0.01s
episode: 876/2000 -> reward: -124.99999999999203, steps:58272, time-taken: 2.07min, time-elasped: 2625.72min
-> berries picked: 40 of 800 | patches-visited: [8] | positive-in-buffer: 16457 | amount-filled: 100.00%
	| epsilon: 0.24687189881632754
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1981, 2252, 1266, 1224, 991, 2604, 2647, 3492]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 23, 16, 15, 11, 30, 32, 59]
	Time taken saving stuff: 11.96s
episode: 877/2000 -> reward: -124.99999999999203, steps:57504, time-taken: 2.21min, time-elasped: 2628.13min
-> berries picked: 33 of 800 | patches-visited: [2] | positive-in-buffer: 16485 | amount-filled: 100.00%
	| epsilon: 0.24667331623189417
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1984, 2257, 1268, 1226, 993, 2609, 2652, 3496]
	| approx positives in sample 512: 204
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 41, 5, 12, 9, 32, 34, 45]
	Time taken saving stuff: 0.01s
episode: 878/2000 -> reward: -124.99999999999889, steps:87456, time-taken: 3.32min, time-elasped: 2631.46min
-> berries picked: 143 of 800 | patches-visited: [3, 5, 8, 9] | positive-in-buffer: 16601 | amount-filled: 100.00%
	| epsilon: 0.24647489338634979
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2002, 2277, 1273, 1236, 998, 2630, 2663, 3522]
	| approx positives in sample 512: 186
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 28, 13, 11, 12, 23, 30, 45]
	Time taken saving stuff: 0.01s
episode: 879/2000 -> reward: -124.99999999999207, steps:54720, time-taken: 2.08min, time-elasped: 2633.55min
-> berries picked: 22 of 800 | patches-visited: [5] | positive-in-buffer: 16539 | amount-filled: 100.00%
	| epsilon: 0.2462766301512012
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1997, 2263, 1271, 1226, 1002, 2608, 2653, 3519]
	| approx positives in sample 512: 198
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 19, 14, 20, 9, 32, 37, 44]
	Time taken saving stuff: 15.50s
episode: 880/2000 -> reward: -124.99999999999204, steps:54912, time-taken: 2.02min, time-elasped: 2635.83min
-> berries picked: 31 of 800 | patches-visited: [0] | positive-in-buffer: 16565 | amount-filled: 100.00%
	| epsilon: 0.24607852639805852
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1999, 2266, 1272, 1229, 1004, 2616, 2654, 3525]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 28, 24, 15, 10, 34, 43, 44]
	Time taken saving stuff: 0.01s
episode: 881/2000 -> reward: -124.99999999999203, steps:55296, time-taken: 2.15min, time-elasped: 2637.98min
-> berries picked: 26 of 800 | patches-visited: [4] | positive-in-buffer: 16580 | amount-filled: 100.00%
	| epsilon: 0.24588058199863524
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2000, 2268, 1276, 1227, 1006, 2616, 2656, 3531]
	| approx positives in sample 512: 193
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 25, 12, 16, 6, 40, 30, 49]
	Time taken saving stuff: 0.01s
episode: 882/2000 -> reward: -124.99999999999204, steps:50496, time-taken: 1.91min, time-elasped: 2639.89min
-> berries picked: 7 of 800 | patches-visited: [6] | positive-in-buffer: 16577 | amount-filled: 100.00%
	| epsilon: 0.24568279682474797
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1999, 2268, 1278, 1227, 1006, 2614, 2655, 3530]
	| approx positives in sample 512: 201
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 26, 12, 15, 11, 20, 44, 53]
	Time taken saving stuff: 12.11s
episode: 883/2000 -> reward: -124.99999999999194, steps:67584, time-taken: 3.09min, time-elasped: 2643.19min
-> berries picked: 64 of 800 | patches-visited: [6, 7, 8] | positive-in-buffer: 16624 | amount-filled: 100.00%
	| epsilon: 0.2454851707483164
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2005, 2280, 1283, 1231, 1009, 2617, 2661, 3538]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 28, 8, 14, 7, 34, 32, 60]
	Time taken saving stuff: 0.01s
episode: 884/2000 -> reward: -124.99999999998997, steps:65376, time-taken: 2.37min, time-elasped: 2645.56min
-> berries picked: 63 of 800 | patches-visited: [3] | positive-in-buffer: 16675 | amount-filled: 100.00%
	| epsilon: 0.24528770364136337
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2016, 2279, 1291, 1238, 1012, 2624, 2665, 3550]
	| approx positives in sample 512: 190
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 24, 17, 13, 12, 26, 25, 42]
	Time taken saving stuff: 0.01s
episode: 885/2000 -> reward: -124.99999999999353, steps:60672, time-taken: 2.33min, time-elasped: 2647.90min
-> berries picked: 44 of 800 | patches-visited: [1, 5] | positive-in-buffer: 16579 | amount-filled: 100.00%
	| epsilon: 0.24509039537601449
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1998, 2254, 1280, 1233, 1005, 2608, 2657, 3544]
	| approx positives in sample 512: 207
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 24, 16, 11, 14, 29, 32, 59]
	Time taken saving stuff: 14.74s
episode: 886/2000 -> reward: -124.99999999999176, steps:60480, time-taken: 2.14min, time-elasped: 2650.29min
-> berries picked: 49 of 800 | patches-visited: [9] | positive-in-buffer: 16581 | amount-filled: 100.00%
	| epsilon: 0.24489324582449837
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1999, 2252, 1284, 1237, 1004, 2610, 2655, 3540]
	| approx positives in sample 512: 193
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 29, 7, 12, 8, 39, 29, 54]
	Time taken saving stuff: 0.01s
episode: 887/2000 -> reward: -124.99999999999201, steps:69408, time-taken: 3.15min, time-elasped: 2653.43min
-> berries picked: 71 of 800 | patches-visited: [4, 7, 9] | positive-in-buffer: 16598 | amount-filled: 100.00%
	| epsilon: 0.2446962548591464
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2007, 2258, 1283, 1234, 1005, 2602, 2655, 3554]
	| approx positives in sample 512: 242
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 35, 16, 13, 17, 34, 44, 57]
	Time taken saving stuff: 0.01s
episode: 888/2000 -> reward: -124.99999999999203, steps:53376, time-taken: 2.02min, time-elasped: 2655.46min
-> berries picked: 21 of 800 | patches-visited: [8] | positive-in-buffer: 16614 | amount-filled: 100.00%
	| epsilon: 0.24449942235239255
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2009, 2258, 1283, 1234, 1005, 2605, 2659, 3561]
	| approx positives in sample 512: 208
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 27, 15, 16, 8, 30, 39, 51]
	Time taken saving stuff: 12.32s
episode: 889/2000 -> reward: -124.99999999999221, steps:56928, time-taken: 2.14min, time-elasped: 2657.80min
-> berries picked: 35 of 800 | patches-visited: [0, 5] | positive-in-buffer: 16635 | amount-filled: 100.00%
	| epsilon: 0.24430274817677353
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2011, 2265, 1286, 1238, 1006, 2604, 2659, 3566]
	| approx positives in sample 512: 202
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 23, 6, 22, 14, 22, 40, 49]
	Time taken saving stuff: 0.01s
episode: 890/2000 -> reward: -124.99999999999203, steps:50688, time-taken: 1.98min, time-elasped: 2659.78min
-> berries picked: 8 of 800 | patches-visited: [9] | positive-in-buffer: 16585 | amount-filled: 100.00%
	| epsilon: 0.2441062322049285
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1999, 2258, 1281, 1236, 1000, 2594, 2652, 3565]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 32, 15, 12, 8, 36, 38, 56]
	Time taken saving stuff: 0.01s
episode: 891/2000 -> reward: -124.99999999999194, steps:64416, time-taken: 2.33min, time-elasped: 2662.11min
-> berries picked: 66 of 800 | patches-visited: [0] | positive-in-buffer: 16624 | amount-filled: 100.00%
	| epsilon: 0.24390987430959907
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2005, 2260, 1284, 1241, 1005, 2600, 2656, 3573]
	| approx positives in sample 512: 210
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 22, 14, 19, 13, 27, 41, 52]
	Time taken saving stuff: 15.28s
episode: 892/2000 -> reward: -124.99999999999206, steps:57408, time-taken: 2.04min, time-elasped: 2664.40min
-> berries picked: 36 of 800 | patches-visited: [0] | positive-in-buffer: 16483 | amount-filled: 100.00%
	| epsilon: 0.2437136743636293
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1985, 2225, 1278, 1235, 1000, 2566, 2634, 3560]
	| approx positives in sample 512: 192
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 28, 12, 9, 7, 26, 38, 52]
	Time taken saving stuff: 0.01s
episode: 893/2000 -> reward: -124.99999999999203, steps:54816, time-taken: 2.04min, time-elasped: 2666.45min
-> berries picked: 24 of 800 | patches-visited: [6] | positive-in-buffer: 16503 | amount-filled: 100.00%
	| epsilon: 0.24351763223996545
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1986, 2227, 1280, 1237, 1001, 2568, 2637, 3567]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 25, 13, 22, 12, 38, 35, 48]
	Time taken saving stuff: 0.01s
episode: 894/2000 -> reward: -124.99999999999183, steps:64224, time-taken: 2.26min, time-elasped: 2668.72min
-> berries picked: 65 of 800 | patches-visited: [2] | positive-in-buffer: 16544 | amount-filled: 100.00%
	| epsilon: 0.24332174781165597
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1994, 2230, 1283, 1240, 1006, 2577, 2644, 3570]
	| approx positives in sample 512: 176
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 29, 12, 17, 7, 18, 25, 50]
	Time taken saving stuff: 12.64s
episode: 895/2000 -> reward: -124.99999999999203, steps:50688, time-taken: 1.97min, time-elasped: 2670.90min
-> berries picked: 11 of 800 | patches-visited: [8] | positive-in-buffer: 16440 | amount-filled: 100.00%
	| epsilon: 0.2431260209518515
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1979, 2216, 1279, 1228, 998, 2549, 2631, 3560]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 33, 13, 14, 12, 28, 43, 50]
	Time taken saving stuff: 0.01s
episode: 896/2000 -> reward: -124.999999999991, steps:66816, time-taken: 3.14min, time-elasped: 2674.05min
-> berries picked: 74 of 800 | patches-visited: [0, 6] | positive-in-buffer: 16499 | amount-filled: 100.00%
	| epsilon: 0.24293045153380471
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1988, 2220, 1282, 1234, 1006, 2560, 2635, 3574]
	| approx positives in sample 512: 253
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [40, 29, 11, 22, 15, 39, 38, 59]
	Time taken saving stuff: 0.00s
episode: 897/2000 -> reward: -124.99999999999501, steps:80544, time-taken: 3.51min, time-elasped: 2677.56min
-> berries picked: 119 of 800 | patches-visited: [1, 6] | positive-in-buffer: 16575 | amount-filled: 100.00%
	| epsilon: 0.2427350394308701
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1996, 2229, 1289, 1246, 1015, 2571, 2645, 3584]
	| approx positives in sample 512: 207
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 32, 13, 14, 11, 30, 28, 52]
	Time taken saving stuff: 15.75s
episode: 898/2000 -> reward: -124.9999999999785, steps:95424, time-taken: 4.18min, time-elasped: 2682.00min
-> berries picked: 175 of 800 | patches-visited: [0, 1, 5] | positive-in-buffer: 16649 | amount-filled: 100.00%
	| epsilon: 0.24253978451650426
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1997, 2240, 1308, 1250, 1020, 2585, 2641, 3608]
	| approx positives in sample 512: 226
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 33, 10, 15, 17, 33, 34, 50]
	Time taken saving stuff: 0.00s
episode: 899/2000 -> reward: -124.99999999999203, steps:53664, time-taken: 2.04min, time-elasped: 2684.04min
-> berries picked: 20 of 800 | patches-visited: [8] | positive-in-buffer: 16599 | amount-filled: 100.00%
	| epsilon: 0.24234468666426537
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1989, 2235, 1305, 1245, 1014, 2569, 2636, 3606]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 28, 19, 12, 15, 37, 35, 48]
	Time taken saving stuff: 0.01s
episode: 900/2000 -> reward: -124.99999999999201, steps:60864, time-taken: 2.10min, time-elasped: 2686.14min
-> berries picked: 44 of 800 | patches-visited: [2, 7] | positive-in-buffer: 16561 | amount-filled: 100.00%
	| epsilon: 0.24214974574781345
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1988, 2235, 1301, 1239, 1008, 2548, 2629, 3613]
	| approx positives in sample 512: 187
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 25, 16, 11, 8, 28, 32, 47]
	Time taken saving stuff: 12.40s
episode: 901/2000 -> reward: -124.999999999993, steps:75840, time-taken: 3.17min, time-elasped: 2689.52min
-> berries picked: 93 of 800 | patches-visited: [0, 1, 4, 6] | positive-in-buffer: 16551 | amount-filled: 100.00%
	| epsilon: 0.24195496164091004
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1981, 2231, 1297, 1247, 1010, 2534, 2628, 3623]
	| approx positives in sample 512: 223
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 33, 12, 15, 13, 34, 42, 46]
	Time taken saving stuff: 0.01s
episode: 902/2000 -> reward: -124.99999999999152, steps:70848, time-taken: 3.24min, time-elasped: 2692.76min
-> berries picked: 89 of 800 | patches-visited: [0, 2, 3, 4] | positive-in-buffer: 16604 | amount-filled: 100.00%
	| epsilon: 0.24176033421741833
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1982, 2239, 1304, 1249, 1014, 2544, 2627, 3645]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 26, 12, 20, 12, 28, 36, 65]
	Time taken saving stuff: 0.01s
episode: 903/2000 -> reward: -124.99999999999224, steps:87168, time-taken: 3.62min, time-elasped: 2696.39min
-> berries picked: 150 of 800 | patches-visited: [5, 7, 9] | positive-in-buffer: 16673 | amount-filled: 100.00%
	| epsilon: 0.24156586335130287
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1990, 2246, 1311, 1256, 1014, 2552, 2629, 3675]
	| approx positives in sample 512: 184
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 21, 9, 11, 6, 25, 34, 50]
	Time taken saving stuff: 16.50s
episode: 904/2000 -> reward: -124.99999999999193, steps:64032, time-taken: 2.26min, time-elasped: 2698.93min
-> berries picked: 65 of 800 | patches-visited: [1, 2] | positive-in-buffer: 16601 | amount-filled: 100.00%
	| epsilon: 0.24137154891662974
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1990, 2222, 1293, 1253, 1003, 2544, 2622, 3674]
	| approx positives in sample 512: 185
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 18, 12, 13, 12, 29, 33, 44]
	Time taken saving stuff: 0.01s
episode: 905/2000 -> reward: -124.99999999999201, steps:64320, time-taken: 2.23min, time-elasped: 2701.16min
-> berries picked: 59 of 800 | patches-visited: [7] | positive-in-buffer: 16600 | amount-filled: 100.00%
	| epsilon: 0.24117739078756614
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1988, 2220, 1287, 1251, 1009, 2547, 2617, 3681]
	| approx positives in sample 512: 190
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 27, 10, 11, 8, 19, 47, 44]
	Time taken saving stuff: 0.01s
episode: 906/2000 -> reward: -124.99999999999197, steps:69600, time-taken: 3.49min, time-elasped: 2704.65min
-> berries picked: 70 of 800 | patches-visited: [4, 5, 8] | positive-in-buffer: 16610 | amount-filled: 100.00%
	| epsilon: 0.24098338883838066
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1988, 2223, 1293, 1254, 1008, 2543, 2619, 3682]
	| approx positives in sample 512: 234
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 36, 15, 14, 7, 31, 42, 57]
	Time taken saving stuff: 12.27s
episode: 907/2000 -> reward: -124.9999999999924, steps:69600, time-taken: 3.03min, time-elasped: 2707.89min
-> berries picked: 75 of 800 | patches-visited: [1, 4, 7] | positive-in-buffer: 16668 | amount-filled: 100.00%
	| epsilon: 0.24078954294344287
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1995, 2225, 1301, 1257, 1007, 2558, 2624, 3701]
	| approx positives in sample 512: 236
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 30, 17, 20, 13, 40, 33, 53]
	Time taken saving stuff: 0.01s
episode: 908/2000 -> reward: -124.99999999999199, steps:63744, time-taken: 2.50min, time-elasped: 2710.39min
-> berries picked: 59 of 800 | patches-visited: [1, 3] | positive-in-buffer: 16688 | amount-filled: 100.00%
	| epsilon: 0.24059585297722355
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1999, 2228, 1301, 1261, 1007, 2564, 2625, 3703]
	| approx positives in sample 512: 160
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 22, 9, 9, 9, 21, 27, 44]
	Time taken saving stuff: 0.01s
episode: 909/2000 -> reward: -124.99999999999449, steps:82656, time-taken: 3.62min, time-elasped: 2714.01min
-> berries picked: 127 of 800 | patches-visited: [3, 4, 5, 7] | positive-in-buffer: 16657 | amount-filled: 100.00%
	| epsilon: 0.24040231881429427
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2002, 2224, 1290, 1259, 1008, 2547, 2613, 3714]
	| approx positives in sample 512: 182
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 17, 12, 13, 3, 19, 32, 64]
	Time taken saving stuff: 15.39s
episode: 910/2000 -> reward: -124.99999999999268, steps:70080, time-taken: 3.30min, time-elasped: 2717.57min
-> berries picked: 79 of 800 | patches-visited: [5, 8] | positive-in-buffer: 16664 | amount-filled: 100.00%
	| epsilon: 0.24020894032932774
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2009, 2219, 1294, 1258, 1014, 2541, 2608, 3721]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 29, 5, 9, 17, 26, 35, 68]
	Time taken saving stuff: 0.01s
episode: 911/2000 -> reward: -124.99999999999477, steps:72864, time-taken: 3.30min, time-elasped: 2720.87min
-> berries picked: 90 of 800 | patches-visited: [0, 5, 8] | positive-in-buffer: 16734 | amount-filled: 100.00%
	| epsilon: 0.24001571739709723
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2022, 2227, 1300, 1259, 1022, 2550, 2609, 3745]
	| approx positives in sample 512: 226
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 25, 15, 15, 5, 29, 31, 75]
	Time taken saving stuff: 0.01s
episode: 912/2000 -> reward: -124.99999999999203, steps:53472, time-taken: 2.12min, time-elasped: 2722.99min
-> berries picked: 17 of 800 | patches-visited: [2, 5] | positive-in-buffer: 16736 | amount-filled: 100.00%
	| epsilon: 0.23982264989247692
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2021, 2231, 1301, 1256, 1026, 2547, 2609, 3745]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 17, 25, 13, 15, 29, 32, 62]
	Time taken saving stuff: 12.59s
episode: 913/2000 -> reward: -124.99999999999237, steps:61440, time-taken: 2.23min, time-elasped: 2725.44min
-> berries picked: 45 of 800 | patches-visited: [7, 8] | positive-in-buffer: 16741 | amount-filled: 100.00%
	| epsilon: 0.23962973769044157
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2025, 2231, 1306, 1253, 1029, 2543, 2604, 3750]
	| approx positives in sample 512: 201
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 27, 12, 12, 8, 29, 27, 60]
	Time taken saving stuff: 0.01s
episode: 914/2000 -> reward: -124.99999999999407, steps:65088, time-taken: 2.35min, time-elasped: 2727.80min
-> berries picked: 69 of 800 | patches-visited: [2, 4] | positive-in-buffer: 16688 | amount-filled: 100.00%
	| epsilon: 0.2394369806660665
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2015, 2222, 1300, 1245, 1027, 2529, 2597, 3753]
	| approx positives in sample 512: 186
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 23, 10, 10, 14, 30, 26, 47]
	Time taken saving stuff: 0.01s
episode: 915/2000 -> reward: -124.99999999999207, steps:59904, time-taken: 2.11min, time-elasped: 2729.91min
-> berries picked: 41 of 800 | patches-visited: [3, 7] | positive-in-buffer: 16599 | amount-filled: 100.00%
	| epsilon: 0.23924437869452755
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1996, 2208, 1294, 1243, 1016, 2511, 2585, 3746]
	| approx positives in sample 512: 206
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 25, 12, 14, 6, 24, 36, 58]
	Time taken saving stuff: 15.31s
episode: 916/2000 -> reward: -124.99999999999201, steps:59712, time-taken: 2.09min, time-elasped: 2732.26min
-> berries picked: 39 of 800 | patches-visited: [7] | positive-in-buffer: 16625 | amount-filled: 100.00%
	| epsilon: 0.23905193165110092
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1997, 2209, 1301, 1251, 1015, 2517, 2585, 3750]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 32, 16, 6, 12, 29, 29, 64]
	Time taken saving stuff: 0.01s
episode: 917/2000 -> reward: -124.9999999999919, steps:85824, time-taken: 3.37min, time-elasped: 2735.63min
-> berries picked: 135 of 800 | patches-visited: [0, 2, 6, 7] | positive-in-buffer: 16721 | amount-filled: 100.00%
	| epsilon: 0.23885963941116323
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2011, 2218, 1304, 1265, 1028, 2530, 2595, 3770]
	| approx positives in sample 512: 196
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 25, 9, 13, 6, 32, 30, 54]
	Time taken saving stuff: 0.01s
episode: 918/2000 -> reward: -124.99999999998802, steps:63744, time-taken: 2.47min, time-elasped: 2738.10min
-> berries picked: 65 of 800 | patches-visited: [2] | positive-in-buffer: 16688 | amount-filled: 100.00%
	| epsilon: 0.23866750185019123
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2004, 2206, 1306, 1264, 1024, 2521, 2586, 3777]
	| approx positives in sample 512: 187
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 17, 19, 15, 7, 26, 28, 51]
	Time taken saving stuff: 13.04s
episode: 919/2000 -> reward: -124.99999999999201, steps:53664, time-taken: 2.21min, time-elasped: 2740.53min
-> berries picked: 25 of 800 | patches-visited: [8] | positive-in-buffer: 16650 | amount-filled: 100.00%
	| epsilon: 0.23847551884376195
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1995, 2199, 1298, 1256, 1021, 2522, 2583, 3776]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 33, 12, 11, 14, 38, 34, 49]
	Time taken saving stuff: 0.01s
episode: 920/2000 -> reward: -124.99999999999206, steps:56352, time-taken: 2.30min, time-elasped: 2742.84min
-> berries picked: 31 of 800 | patches-visited: [6] | positive-in-buffer: 16669 | amount-filled: 100.00%
	| epsilon: 0.2382836902675524
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1994, 2200, 1298, 1260, 1025, 2525, 2589, 3778]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 32, 18, 13, 14, 41, 33, 65]
	Time taken saving stuff: 0.11s
episode: 921/2000 -> reward: -124.99999999999203, steps:56544, time-taken: 2.26min, time-elasped: 2745.10min
-> berries picked: 30 of 800 | patches-visited: [6] | positive-in-buffer: 16686 | amount-filled: 100.00%
	| epsilon: 0.23809201599733965
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1998, 2199, 1298, 1260, 1027, 2527, 2589, 3788]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 26, 19, 17, 13, 27, 42, 50]
	Time taken saving stuff: 15.11s
episode: 922/2000 -> reward: -124.99999999999204, steps:50400, time-taken: 1.85min, time-elasped: 2747.21min
-> berries picked: 10 of 800 | patches-visited: [9] | positive-in-buffer: 16677 | amount-filled: 100.00%
	| epsilon: 0.2379004959090007
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1999, 2198, 1298, 1259, 1026, 2522, 2589, 3786]
	| approx positives in sample 512: 240
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 34, 15, 18, 11, 29, 40, 62]
	Time taken saving stuff: 0.03s
episode: 923/2000 -> reward: -124.99999999998731, steps:68256, time-taken: 3.27min, time-elasped: 2750.47min
-> berries picked: 74 of 800 | patches-visited: [0, 4, 6] | positive-in-buffer: 16736 | amount-filled: 100.00%
	| epsilon: 0.2377091298785124
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2010, 2207, 1302, 1265, 1033, 2527, 2598, 3794]
	| approx positives in sample 512: 234
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 25, 23, 19, 12, 35, 37, 56]
	Time taken saving stuff: 0.00s
episode: 924/2000 -> reward: -124.99999999999213, steps:64896, time-taken: 2.25min, time-elasped: 2752.72min
-> berries picked: 64 of 800 | patches-visited: [1, 5, 9] | positive-in-buffer: 16747 | amount-filled: 100.00%
	| epsilon: 0.23751791778195133
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2011, 2204, 1300, 1267, 1037, 2525, 2601, 3802]
	| approx positives in sample 512: 206
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 21, 12, 16, 15, 26, 34, 54]
	Time taken saving stuff: 13.51s
episode: 925/2000 -> reward: -124.9999999999767, steps:96768, time-taken: 8.48min, time-elasped: 2761.43min
-> berries picked: 186 of 800 | patches-visited: [0, 5, 6, 7] | positive-in-buffer: 16802 | amount-filled: 100.00%
	| epsilon: 0.23732685949549376
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2016, 2205, 1296, 1275, 1046, 2525, 2613, 3826]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 29, 16, 13, 12, 32, 42, 52]
	Time taken saving stuff: 0.01s
episode: 926/2000 -> reward: -124.99999999999078, steps:68640, time-taken: 5.46min, time-elasped: 2766.89min
-> berries picked: 72 of 800 | patches-visited: [1, 4, 9] | positive-in-buffer: 16843 | amount-filled: 100.00%
	| epsilon: 0.23713595489541558
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2022, 2209, 1303, 1279, 1047, 2529, 2616, 3838]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [36, 22, 18, 19, 15, 24, 24, 59]
	Time taken saving stuff: 0.08s
episode: 927/2000 -> reward: -124.99999999999191, steps:64032, time-taken: 3.53min, time-elasped: 2770.43min
-> berries picked: 52 of 800 | patches-visited: [7, 8] | positive-in-buffer: 16868 | amount-filled: 100.00%
	| epsilon: 0.2369452038580922
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2023, 2210, 1308, 1282, 1052, 2530, 2618, 3845]
	| approx positives in sample 512: 180
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 18, 14, 9, 10, 31, 32, 48]
	Time taken saving stuff: 17.66s
episode: 928/2000 -> reward: -124.99999999999083, steps:73152, time-taken: 5.13min, time-elasped: 2775.85min
-> berries picked: 91 of 800 | patches-visited: [0, 4] | positive-in-buffer: 16754 | amount-filled: 100.00%
	| epsilon: 0.23675460625999845
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2013, 2198, 1295, 1268, 1036, 2503, 2599, 3842]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 23, 20, 11, 10, 32, 41, 65]
	Time taken saving stuff: 0.10s
episode: 929/2000 -> reward: -124.9999999999922, steps:56448, time-taken: 3.60min, time-elasped: 2779.45min
-> berries picked: 31 of 800 | patches-visited: [3, 5] | positive-in-buffer: 16780 | amount-filled: 100.00%
	| epsilon: 0.23656416197770855
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2015, 2204, 1297, 1272, 1037, 2506, 2601, 3848]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 28, 15, 17, 13, 31, 30, 58]
	Time taken saving stuff: 0.01s
episode: 930/2000 -> reward: -124.99999999999295, steps:65280, time-taken: 3.83min, time-elasped: 2783.28min
-> berries picked: 63 of 800 | patches-visited: [4, 7] | positive-in-buffer: 16816 | amount-filled: 100.00%
	| epsilon: 0.23637387088789602
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2021, 2205, 1301, 1277, 1043, 2509, 2604, 3856]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 27, 11, 18, 13, 31, 30, 66]
	Time taken saving stuff: 13.55s
episode: 931/2000 -> reward: -124.99999999998687, steps:68064, time-taken: 5.00min, time-elasped: 2788.51min
-> berries picked: 77 of 800 | patches-visited: [0, 9] | positive-in-buffer: 16788 | amount-filled: 100.00%
	| epsilon: 0.23618373286733355
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2020, 2201, 1292, 1272, 1031, 2508, 2601, 3863]
	| approx positives in sample 512: 244
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 29, 17, 17, 16, 37, 40, 57]
	Time taken saving stuff: 0.01s
episode: 932/2000 -> reward: -124.99999999999653, steps:77856, time-taken: 5.68min, time-elasped: 2794.20min
-> berries picked: 113 of 800 | patches-visited: [4, 5, 6] | positive-in-buffer: 16854 | amount-filled: 100.00%
	| epsilon: 0.23599374779289292
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2023, 2210, 1299, 1285, 1041, 2511, 2609, 3876]
	| approx positives in sample 512: 203
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 20, 14, 16, 10, 34, 33, 50]
	Time taken saving stuff: 0.11s
episode: 933/2000 -> reward: -124.99999999999207, steps:58464, time-taken: 3.40min, time-elasped: 2797.60min
-> berries picked: 37 of 800 | patches-visited: [4] | positive-in-buffer: 16849 | amount-filled: 100.00%
	| epsilon: 0.23580391554154503
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2027, 2207, 1298, 1283, 1039, 2511, 2608, 3876]
	| approx positives in sample 512: 208
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 22, 9, 15, 15, 25, 31, 67]
	Time taken saving stuff: 15.69s
episode: 934/2000 -> reward: -124.99999999999217, steps:76224, time-taken: 4.12min, time-elasped: 2801.99min
-> berries picked: 100 of 800 | patches-visited: [5, 7, 8] | positive-in-buffer: 16872 | amount-filled: 100.00%
	| epsilon: 0.2356142359903597
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2034, 2212, 1301, 1280, 1036, 2509, 2608, 3892]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 27, 14, 23, 9, 33, 31, 48]
	Time taken saving stuff: 0.07s
episode: 935/2000 -> reward: -124.99999999999015, steps:70464, time-taken: 3.25min, time-elasped: 2805.25min
-> berries picked: 89 of 800 | patches-visited: [2, 4] | positive-in-buffer: 16911 | amount-filled: 100.00%
	| epsilon: 0.23542470901650567
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2034, 2213, 1300, 1289, 1040, 2513, 2614, 3908]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 19, 9, 22, 13, 29, 31, 67]
	Time taken saving stuff: 0.00s
episode: 936/2000 -> reward: -124.99999999999145, steps:69504, time-taken: 2.93min, time-elasped: 2808.18min
-> berries picked: 79 of 800 | patches-visited: [4, 5] | positive-in-buffer: 16942 | amount-filled: 100.00%
	| epsilon: 0.2352353344972504
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2035, 2216, 1307, 1291, 1042, 2518, 2614, 3919]
	| approx positives in sample 512: 237
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 25, 9, 15, 18, 39, 31, 77]
	Time taken saving stuff: 11.88s
episode: 937/2000 -> reward: -124.9999999999924, steps:66912, time-taken: 2.94min, time-elasped: 2811.32min
-> berries picked: 66 of 800 | patches-visited: [6, 7, 9] | positive-in-buffer: 16950 | amount-filled: 100.00%
	| epsilon: 0.2350461123099602
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2037, 2211, 1316, 1291, 1045, 2513, 2611, 3926]
	| approx positives in sample 512: 235
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 35, 11, 13, 8, 33, 36, 71]
	Time taken saving stuff: 0.00s
episode: 938/2000 -> reward: -124.99999999999203, steps:49152, time-taken: 1.92min, time-elasped: 2813.24min
-> berries picked: 3 of 800 | patches-visited: [0] | positive-in-buffer: 16946 | amount-filled: 100.00%
	| epsilon: 0.23485704233209992
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2036, 2210, 1316, 1290, 1044, 2514, 2610, 3926]
	| approx positives in sample 512: 242
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 33, 8, 9, 10, 33, 39, 81]
	Time taken saving stuff: 0.02s
episode: 939/2000 -> reward: -124.99999999999214, steps:66336, time-taken: 2.97min, time-elasped: 2816.22min
-> berries picked: 62 of 800 | patches-visited: [2, 7] | positive-in-buffer: 16964 | amount-filled: 100.00%
	| epsilon: 0.23466812444123303
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2041, 2212, 1317, 1288, 1047, 2520, 2609, 3930]
	| approx positives in sample 512: 254
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 31, 11, 13, 9, 32, 49, 80]
	Time taken saving stuff: 14.92s
episode: 940/2000 -> reward: -124.99999999999206, steps:57888, time-taken: 2.09min, time-elasped: 2818.55min
-> berries picked: 35 of 800 | patches-visited: [7] | positive-in-buffer: 16970 | amount-filled: 100.00%
	| epsilon: 0.23447935851502144
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2040, 2213, 1319, 1288, 1048, 2520, 2606, 3936]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 23, 15, 14, 12, 27, 36, 61]
	Time taken saving stuff: 0.01s
episode: 941/2000 -> reward: -124.99999999999226, steps:62592, time-taken: 2.17min, time-elasped: 2820.73min
-> berries picked: 49 of 800 | patches-visited: [6, 9] | positive-in-buffer: 16908 | amount-filled: 100.00%
	| epsilon: 0.23429074443122555
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2033, 2211, 1315, 1272, 1042, 2503, 2605, 3927]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 30, 11, 15, 10, 35, 29, 58]
	Time taken saving stuff: 0.01s
episode: 942/2000 -> reward: -124.99999999999204, steps:50208, time-taken: 2.03min, time-elasped: 2822.76min
-> berries picked: 8 of 800 | patches-visited: [1] | positive-in-buffer: 16815 | amount-filled: 100.00%
	| epsilon: 0.23410228206770403
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2021, 2194, 1307, 1261, 1036, 2484, 2595, 3917]
	| approx positives in sample 512: 234
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 32, 19, 19, 12, 39, 25, 62]
	Time taken saving stuff: 12.08s
episode: 943/2000 -> reward: -124.9999999999947, steps:86784, time-taken: 3.17min, time-elasped: 2826.14min
-> berries picked: 145 of 800 | patches-visited: [1, 4, 5, 7] | positive-in-buffer: 16934 | amount-filled: 100.00%
	| epsilon: 0.2339139713024138
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2031, 2216, 1315, 1273, 1047, 2501, 2605, 3946]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 21, 13, 12, 13, 20, 47, 61]
	Time taken saving stuff: 0.01s
episode: 944/2000 -> reward: -124.99999999999143, steps:64032, time-taken: 2.18min, time-elasped: 2828.33min
-> berries picked: 55 of 800 | patches-visited: [4] | positive-in-buffer: 16838 | amount-filled: 100.00%
	| epsilon: 0.23372581201340997
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2019, 2199, 1310, 1263, 1045, 2479, 2586, 3937]
	| approx positives in sample 512: 166
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 14, 11, 9, 5, 19, 30, 61]
	Time taken saving stuff: 0.09s
episode: 945/2000 -> reward: -124.99999999999237, steps:64032, time-taken: 2.13min, time-elasped: 2830.46min
-> berries picked: 53 of 800 | patches-visited: [2, 6] | positive-in-buffer: 16834 | amount-filled: 100.00%
	| epsilon: 0.23353780407884572
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2020, 2192, 1309, 1259, 1040, 2479, 2587, 3948]
	| approx positives in sample 512: 208
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 18, 15, 15, 6, 37, 31, 61]
	Time taken saving stuff: 15.28s
episode: 946/2000 -> reward: -124.99999999999197, steps:54912, time-taken: 2.13min, time-elasped: 2832.85min
-> berries picked: 31 of 800 | patches-visited: [4] | positive-in-buffer: 16816 | amount-filled: 100.00%
	| epsilon: 0.23334994737697223
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2011, 2191, 1308, 1258, 1039, 2481, 2580, 3948]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 33, 9, 17, 14, 31, 29, 60]
	Time taken saving stuff: 0.02s
episode: 947/2000 -> reward: -124.99999999999204, steps:87360, time-taken: 3.41min, time-elasped: 2836.26min
-> berries picked: 137 of 800 | patches-visited: [2, 4, 5, 6] | positive-in-buffer: 16931 | amount-filled: 100.00%
	| epsilon: 0.23316224178613873
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2026, 2204, 1316, 1267, 1047, 2495, 2595, 3981]
	| approx positives in sample 512: 191
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 26, 15, 13, 7, 29, 37, 46]
	Time taken saving stuff: 0.01s
episode: 948/2000 -> reward: -124.99999999998312, steps:102240, time-taken: 4.50min, time-elasped: 2840.76min
-> berries picked: 211 of 800 | patches-visited: [0, 1, 6, 7, 8, 9] | positive-in-buffer: 17017 | amount-filled: 100.00%
	| epsilon: 0.23297468718479214
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2039, 2216, 1322, 1283, 1062, 2507, 2587, 4001]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 21, 12, 14, 14, 35, 24, 53]
	Time taken saving stuff: 12.70s
episode: 949/2000 -> reward: -124.99999999999194, steps:65568, time-taken: 2.16min, time-elasped: 2843.13min
-> berries picked: 71 of 800 | patches-visited: [6] | positive-in-buffer: 17009 | amount-filled: 100.00%
	| epsilon: 0.23278728345147726
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2037, 2215, 1318, 1284, 1061, 2504, 2581, 4009]
	| approx positives in sample 512: 184
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 30, 10, 13, 14, 19, 22, 50]
	Time taken saving stuff: 0.01s
episode: 950/2000 -> reward: -124.99999999998602, steps:108672, time-taken: 4.43min, time-elasped: 2847.57min
-> berries picked: 213 of 800 | patches-visited: [0, 3, 5, 7, 9] | positive-in-buffer: 17014 | amount-filled: 100.00%
	| epsilon: 0.23260003046483657
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2038, 2209, 1316, 1275, 1060, 2520, 2577, 4019]
	| approx positives in sample 512: 201
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 26, 10, 15, 9, 35, 27, 54]
	Time taken saving stuff: 0.10s
episode: 951/2000 -> reward: -124.99999999999494, steps:70560, time-taken: 3.18min, time-elasped: 2850.75min
-> berries picked: 85 of 800 | patches-visited: [6, 8] | positive-in-buffer: 16966 | amount-filled: 100.00%
	| epsilon: 0.23241292810361014
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2038, 2200, 1316, 1270, 1055, 2499, 2568, 4020]
	| approx positives in sample 512: 223
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 23, 23, 16, 7, 34, 28, 67]
	Time taken saving stuff: 15.67s
episode: 952/2000 -> reward: -124.99999999998602, steps:91392, time-taken: 4.28min, time-elasped: 2855.30min
-> berries picked: 163 of 800 | patches-visited: [1, 4, 6, 8] | positive-in-buffer: 17096 | amount-filled: 100.00%
	| epsilon: 0.2322259762466356
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2058, 2213, 1325, 1284, 1073, 2526, 2574, 4043]
	| approx positives in sample 512: 263
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 32, 23, 11, 14, 35, 46, 67]
	Time taken saving stuff: 0.03s
episode: 953/2000 -> reward: -124.999999999993, steps:62496, time-taken: 2.29min, time-elasped: 2857.60min
-> berries picked: 53 of 800 | patches-visited: [3, 7] | positive-in-buffer: 17109 | amount-filled: 100.00%
	| epsilon: 0.23203917477284802
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2058, 2218, 1323, 1285, 1073, 2529, 2578, 4045]
	| approx positives in sample 512: 194
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 24, 14, 11, 11, 27, 26, 60]
	Time taken saving stuff: 0.01s
episode: 954/2000 -> reward: -124.99999999999186, steps:63552, time-taken: 2.29min, time-elasped: 2859.88min
-> berries picked: 56 of 800 | patches-visited: [8] | positive-in-buffer: 17081 | amount-filled: 100.00%
	| epsilon: 0.23185252356127994
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2052, 2218, 1320, 1286, 1074, 2521, 2563, 4047]
	| approx positives in sample 512: 192
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 31, 8, 10, 5, 37, 37, 38]
	Time taken saving stuff: 12.30s
episode: 955/2000 -> reward: -124.99999999999373, steps:75840, time-taken: 3.05min, time-elasped: 2863.14min
-> berries picked: 97 of 800 | patches-visited: [2, 3, 5] | positive-in-buffer: 17096 | amount-filled: 100.00%
	| epsilon: 0.23166602249106114
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2053, 2221, 1315, 1295, 1073, 2515, 2564, 4060]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 29, 20, 17, 18, 24, 30, 56]
	Time taken saving stuff: 0.01s
episode: 956/2000 -> reward: -124.99999999999237, steps:59136, time-taken: 2.15min, time-elasped: 2865.29min
-> berries picked: 39 of 800 | patches-visited: [4, 7] | positive-in-buffer: 17122 | amount-filled: 100.00%
	| epsilon: 0.23147967144141857
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2056, 2222, 1316, 1296, 1079, 2521, 2566, 4066]
	| approx positives in sample 512: 211
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 31, 10, 13, 12, 32, 48, 42]
	Time taken saving stuff: 0.02s
episode: 957/2000 -> reward: -124.9999999999927, steps:55104, time-taken: 2.08min, time-elasped: 2867.37min
-> berries picked: 27 of 800 | patches-visited: [2, 5] | positive-in-buffer: 17105 | amount-filled: 100.00%
	| epsilon: 0.23129347029167643
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2055, 2223, 1311, 1293, 1075, 2520, 2559, 4069]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 33, 19, 17, 15, 32, 20, 44]
	Time taken saving stuff: 14.84s
episode: 958/2000 -> reward: -124.99999999999514, steps:71424, time-taken: 3.18min, time-elasped: 2870.80min
-> berries picked: 85 of 800 | patches-visited: [1, 6, 8] | positive-in-buffer: 17172 | amount-filled: 100.00%
	| epsilon: 0.23110741892125594
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2064, 2226, 1321, 1299, 1080, 2532, 2570, 4080]
	| approx positives in sample 512: 237
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 27, 18, 15, 15, 38, 37, 62]
	Time taken saving stuff: 0.09s
episode: 959/2000 -> reward: -124.99999999999204, steps:52704, time-taken: 1.93min, time-elasped: 2872.74min
-> berries picked: 19 of 800 | patches-visited: [0] | positive-in-buffer: 17182 | amount-filled: 100.00%
	| epsilon: 0.23092151720967533
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2064, 2229, 1326, 1300, 1078, 2533, 2571, 4081]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 37, 10, 17, 16, 33, 33, 39]
	Time taken saving stuff: 0.01s
episode: 960/2000 -> reward: -124.99999999998902, steps:79200, time-taken: 3.34min, time-elasped: 2876.08min
-> berries picked: 123 of 800 | patches-visited: [2, 7, 8] | positive-in-buffer: 17233 | amount-filled: 100.00%
	| epsilon: 0.23073576503654974
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2067, 2239, 1336, 1300, 1085, 2541, 2577, 4088]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 19, 19, 14, 15, 26, 33, 59]
	Time taken saving stuff: 12.16s
episode: 961/2000 -> reward: -124.99999999999203, steps:53280, time-taken: 2.10min, time-elasped: 2878.39min
-> berries picked: 17 of 800 | patches-visited: [0] | positive-in-buffer: 17155 | amount-filled: 100.00%
	| epsilon: 0.23055016228159114
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2062, 2222, 1316, 1293, 1084, 2530, 2570, 4078]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 22, 11, 15, 16, 36, 42, 50]
	Time taken saving stuff: 0.01s
episode: 962/2000 -> reward: -124.99999999999203, steps:48384, time-taken: 1.98min, time-elasped: 2880.37min
-> berries picked: 1 of 800 | patches-visited: [1] | positive-in-buffer: 17150 | amount-filled: 100.00%
	| epsilon: 0.23036470882460827
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2060, 2221, 1315, 1293, 1083, 2530, 2569, 4079]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 25, 14, 13, 14, 33, 26, 59]
	Time taken saving stuff: 0.12s
episode: 963/2000 -> reward: -124.99999999999203, steps:51840, time-taken: 2.08min, time-elasped: 2882.45min
-> berries picked: 14 of 800 | patches-visited: [7] | positive-in-buffer: 17164 | amount-filled: 100.00%
	| epsilon: 0.23017940454550656
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2061, 2224, 1315, 1293, 1084, 2532, 2570, 4085]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 29, 19, 12, 8, 42, 29, 47]
	Time taken saving stuff: 15.06s
episode: 964/2000 -> reward: -124.9999999999919, steps:74304, time-taken: 2.96min, time-elasped: 2885.67min
-> berries picked: 93 of 800 | patches-visited: [2, 5, 7, 8] | positive-in-buffer: 17233 | amount-filled: 100.00%
	| epsilon: 0.22999424932428802
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2069, 2232, 1332, 1299, 1089, 2538, 2573, 4101]
	| approx positives in sample 512: 248
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 35, 10, 22, 13, 35, 36, 66]
	Time taken saving stuff: 0.02s
episode: 965/2000 -> reward: -124.99999999999372, steps:82560, time-taken: 3.17min, time-elasped: 2888.84min
-> berries picked: 124 of 800 | patches-visited: [2, 3, 7, 8] | positive-in-buffer: 17294 | amount-filled: 100.00%
	| epsilon: 0.22980924304105113
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2075, 2236, 1336, 1305, 1097, 2550, 2573, 4122]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 14, 11, 15, 17, 31, 34, 57]
	Time taken saving stuff: 0.01s
episode: 966/2000 -> reward: -124.99999999999143, steps:70464, time-taken: 3.29min, time-elasped: 2892.13min
-> berries picked: 76 of 800 | patches-visited: [0, 4, 8] | positive-in-buffer: 17238 | amount-filled: 100.00%
	| epsilon: 0.22962438557599102
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2061, 2229, 1330, 1302, 1086, 2538, 2570, 4122]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 26, 10, 16, 11, 36, 40, 64]
	Time taken saving stuff: 12.36s
episode: 967/2000 -> reward: -124.99999999999177, steps:60864, time-taken: 2.23min, time-elasped: 2894.56min
-> berries picked: 52 of 800 | patches-visited: [4] | positive-in-buffer: 17270 | amount-filled: 100.00%
	| epsilon: 0.22943967680939895
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2063, 2236, 1332, 1304, 1086, 2542, 2578, 4129]
	| approx positives in sample 512: 190
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 25, 13, 16, 12, 35, 29, 38]
	Time taken saving stuff: 0.01s
episode: 968/2000 -> reward: -124.9999999999968, steps:103776, time-taken: 4.26min, time-elasped: 2898.83min
-> berries picked: 199 of 800 | patches-visited: [0, 1, 2, 4, 7, 9] | positive-in-buffer: 17327 | amount-filled: 100.00%
	| epsilon: 0.2292551166216626
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2062, 2242, 1329, 1309, 1099, 2554, 2584, 4148]
	| approx positives in sample 512: 205
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 24, 12, 17, 9, 33, 36, 56]
	Time taken saving stuff: 0.04s
episode: 969/2000 -> reward: -124.99999999999174, steps:68064, time-taken: 3.12min, time-elasped: 2901.95min
-> berries picked: 71 of 800 | patches-visited: [0, 3, 6] | positive-in-buffer: 17278 | amount-filled: 100.00%
	| epsilon: 0.22907070489326586
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2066, 2235, 1314, 1304, 1097, 2538, 2569, 4155]
	| approx positives in sample 512: 268
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [36, 22, 20, 15, 13, 36, 41, 85]
	Time taken saving stuff: 14.93s
episode: 970/2000 -> reward: -124.99999999999481, steps:77856, time-taken: 3.18min, time-elasped: 2905.38min
-> berries picked: 109 of 800 | patches-visited: [6, 7] | positive-in-buffer: 17347 | amount-filled: 100.00%
	| epsilon: 0.22888644150478873
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2071, 2245, 1321, 1314, 1103, 2543, 2577, 4173]
	| approx positives in sample 512: 226
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 31, 14, 16, 16, 36, 29, 52]
	Time taken saving stuff: 0.11s
episode: 971/2000 -> reward: -124.99999999999159, steps:67680, time-taken: 3.13min, time-elasped: 2908.52min
-> berries picked: 76 of 800 | patches-visited: [2, 3] | positive-in-buffer: 17333 | amount-filled: 100.00%
	| epsilon: 0.22870232633690726
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2061, 2237, 1319, 1314, 1103, 2544, 2572, 4183]
	| approx positives in sample 512: 259
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [36, 34, 15, 15, 15, 45, 44, 55]
	Time taken saving stuff: 0.06s
episode: 972/2000 -> reward: -124.99999999999206, steps:59232, time-taken: 2.07min, time-elasped: 2910.59min
-> berries picked: 41 of 800 | patches-visited: [2] | positive-in-buffer: 17353 | amount-filled: 100.00%
	| epsilon: 0.22851835927039357
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2063, 2241, 1323, 1314, 1104, 2548, 2569, 4191]
	| approx positives in sample 512: 196
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 31, 11, 17, 10, 31, 21, 56]
	Time taken saving stuff: 11.84s
episode: 973/2000 -> reward: -124.99999999999093, steps:67200, time-taken: 3.08min, time-elasped: 2913.88min
-> berries picked: 71 of 800 | patches-visited: [3, 4] | positive-in-buffer: 17261 | amount-filled: 100.00%
	| epsilon: 0.22833454018611557
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2059, 2226, 1317, 1308, 1093, 2537, 2545, 4176]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 26, 19, 13, 11, 34, 37, 56]
	Time taken saving stuff: 0.09s
episode: 974/2000 -> reward: -124.99999999999005, steps:62112, time-taken: 2.22min, time-elasped: 2916.10min
-> berries picked: 53 of 800 | patches-visited: [1, 3] | positive-in-buffer: 17301 | amount-filled: 100.00%
	| epsilon: 0.22815086896503706
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2063, 2231, 1319, 1308, 1098, 2545, 2550, 4187]
	| approx positives in sample 512: 199
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 17, 13, 17, 15, 34, 31, 55]
	Time taken saving stuff: 0.02s
episode: 975/2000 -> reward: -124.99999999999203, steps:48672, time-taken: 1.90min, time-elasped: 2918.00min
-> berries picked: 3 of 800 | patches-visited: [3] | positive-in-buffer: 17182 | amount-filled: 100.00%
	| epsilon: 0.2279673454882176
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2050, 2222, 1312, 1296, 1086, 2517, 2532, 4167]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 20, 15, 15, 19, 11, 41, 69]
	Time taken saving stuff: 15.86s
episode: 976/2000 -> reward: -124.99999999999017, steps:73248, time-taken: 3.32min, time-elasped: 2921.59min
-> berries picked: 96 of 800 | patches-visited: [0, 2, 8] | positive-in-buffer: 17258 | amount-filled: 100.00%
	| epsilon: 0.22778396963681238
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2055, 2237, 1317, 1307, 1097, 2525, 2538, 4182]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 16, 11, 15, 10, 28, 36, 69]
	Time taken saving stuff: 0.10s
episode: 977/2000 -> reward: -124.99999999999204, steps:58752, time-taken: 2.18min, time-elasped: 2923.78min
-> berries picked: 37 of 800 | patches-visited: [7] | positive-in-buffer: 17270 | amount-filled: 100.00%
	| epsilon: 0.22760074129207222
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2056, 2234, 1320, 1306, 1099, 2530, 2540, 4185]
	| approx positives in sample 512: 204
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 35, 5, 14, 10, 27, 29, 61]
	Time taken saving stuff: 0.09s
episode: 978/2000 -> reward: -124.99999999999244, steps:65952, time-taken: 2.20min, time-elasped: 2925.98min
-> berries picked: 63 of 800 | patches-visited: [0, 6, 7] | positive-in-buffer: 17248 | amount-filled: 100.00%
	| epsilon: 0.2274176603353435
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2051, 2228, 1323, 1305, 1100, 2522, 2533, 4186]
	| approx positives in sample 512: 170
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 24, 14, 5, 5, 25, 27, 57]
	Time taken saving stuff: 11.94s
episode: 979/2000 -> reward: -124.99999999999123, steps:68352, time-taken: 3.08min, time-elasped: 2929.26min
-> berries picked: 86 of 800 | patches-visited: [4, 5] | positive-in-buffer: 17189 | amount-filled: 100.00%
	| epsilon: 0.22723472664806796
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2032, 2221, 1319, 1303, 1095, 2521, 2524, 4174]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [37, 30, 9, 14, 17, 37, 33, 55]
	Time taken saving stuff: 0.06s
episode: 980/2000 -> reward: -124.99999999999584, steps:76992, time-taken: 3.40min, time-elasped: 2932.67min
-> berries picked: 114 of 800 | patches-visited: [4, 8] | positive-in-buffer: 17255 | amount-filled: 100.00%
	| epsilon: 0.22705194011178276
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2041, 2229, 1321, 1308, 1105, 2536, 2530, 4185]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 22, 24, 16, 12, 26, 45, 52]
	Time taken saving stuff: 0.05s
episode: 981/2000 -> reward: -124.99999999999179, steps:73920, time-taken: 3.10min, time-elasped: 2935.77min
-> berries picked: 88 of 800 | patches-visited: [2, 7] | positive-in-buffer: 17292 | amount-filled: 100.00%
	| epsilon: 0.22686930060812036
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2044, 2231, 1324, 1312, 1109, 2538, 2533, 4201]
	| approx positives in sample 512: 203
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 16, 18, 13, 14, 31, 33, 50]
	Time taken saving stuff: 15.07s
episode: 982/2000 -> reward: -124.9999999999934, steps:63936, time-taken: 2.16min, time-elasped: 2938.19min
-> berries picked: 61 of 800 | patches-visited: [8, 9] | positive-in-buffer: 17313 | amount-filled: 100.00%
	| epsilon: 0.22668680801880842
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2047, 2237, 1325, 1317, 1109, 2541, 2538, 4199]
	| approx positives in sample 512: 202
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 26, 14, 15, 14, 33, 27, 45]
	Time taken saving stuff: 0.04s
episode: 983/2000 -> reward: -124.99999999999153, steps:91296, time-taken: 4.31min, time-elasped: 2942.50min
-> berries picked: 160 of 800 | patches-visited: [2, 4, 7, 8] | positive-in-buffer: 17350 | amount-filled: 100.00%
	| epsilon: 0.22650446222566967
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2054, 2237, 1326, 1312, 1121, 2536, 2544, 4220]
	| approx positives in sample 512: 233
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 12, 13, 14, 20, 32, 35, 80]
	Time taken saving stuff: 0.09s
episode: 984/2000 -> reward: -124.99999999999204, steps:52608, time-taken: 2.03min, time-elasped: 2944.53min
-> berries picked: 15 of 800 | patches-visited: [0] | positive-in-buffer: 17357 | amount-filled: 100.00%
	| epsilon: 0.226322263110622
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2056, 2238, 1328, 1311, 1121, 2536, 2545, 4222]
	| approx positives in sample 512: 198
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 30, 12, 20, 14, 20, 32, 52]
	Time taken saving stuff: 11.93s
episode: 985/2000 -> reward: -124.999999999992, steps:61440, time-taken: 2.28min, time-elasped: 2947.01min
-> berries picked: 45 of 800 | patches-visited: [6] | positive-in-buffer: 17375 | amount-filled: 100.00%
	| epsilon: 0.22614021055567832
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2066, 2242, 1326, 1309, 1122, 2535, 2544, 4231]
	| approx positives in sample 512: 205
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 27, 11, 18, 9, 28, 38, 48]
	Time taken saving stuff: 0.09s
episode: 986/2000 -> reward: -124.99999999998592, steps:65664, time-taken: 2.42min, time-elasped: 2949.44min
-> berries picked: 70 of 800 | patches-visited: [4] | positive-in-buffer: 17375 | amount-filled: 100.00%
	| epsilon: 0.2259583044429463
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2062, 2246, 1328, 1317, 1121, 2528, 2547, 4226]
	| approx positives in sample 512: 199
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 18, 11, 11, 19, 23, 39, 55]
	Time taken saving stuff: 0.02s
episode: 987/2000 -> reward: -124.99999999999203, steps:56256, time-taken: 2.10min, time-elasped: 2951.54min
-> berries picked: 26 of 800 | patches-visited: [4] | positive-in-buffer: 17315 | amount-filled: 100.00%
	| epsilon: 0.2257765446546285
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2058, 2238, 1322, 1315, 1117, 2518, 2537, 4210]
	| approx positives in sample 512: 226
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 29, 19, 10, 17, 31, 34, 53]
	Time taken saving stuff: 15.11s
episode: 988/2000 -> reward: -124.99999999998738, steps:79200, time-taken: 3.02min, time-elasped: 2954.81min
-> berries picked: 118 of 800 | patches-visited: [3, 4, 9] | positive-in-buffer: 17395 | amount-filled: 100.00%
	| epsilon: 0.22559493107302234
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2069, 2252, 1328, 1325, 1124, 2527, 2546, 4224]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 24, 18, 9, 12, 30, 39, 66]
	Time taken saving stuff: 0.10s
episode: 989/2000 -> reward: -124.99999999999183, steps:57408, time-taken: 2.11min, time-elasped: 2956.92min
-> berries picked: 34 of 800 | patches-visited: [0, 5, 6] | positive-in-buffer: 17389 | amount-filled: 100.00%
	| epsilon: 0.22541346358051975
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2066, 2251, 1326, 1324, 1123, 2528, 2540, 4231]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 22, 14, 22, 8, 26, 31, 57]
	Time taken saving stuff: 0.01s
episode: 990/2000 -> reward: -124.99999999999433, steps:77280, time-taken: 3.31min, time-elasped: 2960.24min
-> berries picked: 99 of 800 | patches-visited: [1, 2, 6, 8] | positive-in-buffer: 17444 | amount-filled: 100.00%
	| epsilon: 0.22523214205960737
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2069, 2261, 1330, 1326, 1127, 2532, 2548, 4251]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 33, 19, 19, 9, 31, 34, 51]
	Time taken saving stuff: 11.94s
episode: 991/2000 -> reward: -124.99999999998938, steps:88896, time-taken: 4.28min, time-elasped: 2964.72min
-> berries picked: 143 of 800 | patches-visited: [0, 2, 4, 7, 8] | positive-in-buffer: 17518 | amount-filled: 100.00%
	| epsilon: 0.22505096639286637
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2078, 2269, 1335, 1338, 1131, 2547, 2557, 4263]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 32, 17, 12, 11, 26, 42, 62]
	Time taken saving stuff: 0.02s
episode: 992/2000 -> reward: -124.99999999999095, steps:61440, time-taken: 2.17min, time-elasped: 2966.89min
-> berries picked: 48 of 800 | patches-visited: [1, 2] | positive-in-buffer: 17526 | amount-filled: 100.00%
	| epsilon: 0.22486993646297238
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2080, 2274, 1336, 1338, 1131, 2540, 2560, 4267]
	| approx positives in sample 512: 198
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 26, 9, 15, 12, 31, 32, 50]
	Time taken saving stuff: 0.01s
episode: 993/2000 -> reward: -124.99999999999709, steps:102624, time-taken: 4.74min, time-elasped: 2971.64min
-> berries picked: 201 of 800 | patches-visited: [0, 2, 5, 6, 7, 9] | positive-in-buffer: 17539 | amount-filled: 100.00%
	| epsilon: 0.22468905215269527
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2077, 2283, 1339, 1348, 1128, 2531, 2561, 4272]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 21, 16, 19, 11, 22, 36, 56]
	Time taken saving stuff: 15.49s
episode: 994/2000 -> reward: -124.99999999999231, steps:60576, time-taken: 2.03min, time-elasped: 2973.93min
-> berries picked: 43 of 800 | patches-visited: [5, 9] | positive-in-buffer: 17483 | amount-filled: 100.00%
	| epsilon: 0.2245083133448994
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2067, 2273, 1340, 1346, 1129, 2524, 2542, 4262]
	| approx positives in sample 512: 198
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 18, 15, 14, 11, 30, 36, 53]
	Time taken saving stuff: 0.01s
episode: 995/2000 -> reward: -124.99999999999206, steps:55872, time-taken: 2.03min, time-elasped: 2975.97min
-> berries picked: 32 of 800 | patches-visited: [7] | positive-in-buffer: 17407 | amount-filled: 100.00%
	| epsilon: 0.22432771992254325
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2051, 2259, 1337, 1342, 1124, 2510, 2520, 4264]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 16, 19, 15, 13, 28, 39, 62]
	Time taken saving stuff: 0.02s
episode: 996/2000 -> reward: -124.99999999999167, steps:66144, time-taken: 2.99min, time-elasped: 2978.96min
-> berries picked: 73 of 800 | patches-visited: [0, 3] | positive-in-buffer: 17450 | amount-filled: 100.00%
	| epsilon: 0.22414727176867938
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2052, 2264, 1342, 1345, 1125, 2520, 2526, 4276]
	| approx positives in sample 512: 247
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 31, 17, 13, 18, 36, 34, 63]
	Time taken saving stuff: 11.96s
episode: 997/2000 -> reward: -124.99999999999149, steps:70560, time-taken: 3.22min, time-elasped: 2982.38min
-> berries picked: 84 of 800 | patches-visited: [4, 7] | positive-in-buffer: 17498 | amount-filled: 100.00%
	| epsilon: 0.2239669687664546
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2057, 2269, 1345, 1354, 1131, 2525, 2534, 4283]
	| approx positives in sample 512: 211
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 33, 18, 13, 15, 22, 36, 44]
	Time taken saving stuff: 0.10s
episode: 998/2000 -> reward: -124.99999999999207, steps:63168, time-taken: 2.19min, time-elasped: 2984.57min
-> berries picked: 55 of 800 | patches-visited: [6] | positive-in-buffer: 17511 | amount-filled: 100.00%
	| epsilon: 0.22378681079910961
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2056, 2271, 1347, 1359, 1133, 2522, 2538, 4285]
	| approx positives in sample 512: 203
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 24, 18, 21, 15, 24, 20, 54]
	Time taken saving stuff: 0.01s
episode: 999/2000 -> reward: -124.99999999999201, steps:63168, time-taken: 2.39min, time-elasped: 2986.96min
-> berries picked: 58 of 800 | patches-visited: [0] | positive-in-buffer: 17400 | amount-filled: 100.00%
	| epsilon: 0.223606797749979
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2054, 2254, 1326, 1349, 1123, 2514, 2519, 4261]
	| approx positives in sample 512: 206
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 29, 15, 14, 14, 23, 27, 58]
	Time taken saving stuff: 14.98s
episode: 1000/2000 -> reward: -124.99999999998991, steps:74592, time-taken: 3.10min, time-elasped: 2990.31min
-> berries picked: 89 of 800 | patches-visited: [2, 5, 6] | positive-in-buffer: 17432 | amount-filled: 100.00%
	| epsilon: 0.22342692950249127
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2058, 2261, 1327, 1352, 1125, 2512, 2525, 4272]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 18, 22, 20, 14, 25, 29, 53]
	Time taken saving stuff: 0.01s
episode: 1001/2000 -> reward: -124.99999999999206, steps:52800, time-taken: 2.06min, time-elasped: 2992.38min
-> berries picked: 18 of 800 | patches-visited: [1] | positive-in-buffer: 17442 | amount-filled: 100.00%
	| epsilon: 0.22324720594016867
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2061, 2261, 1327, 1353, 1126, 2513, 2528, 4273]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 26, 17, 9, 15, 22, 38, 57]
	Time taken saving stuff: 0.02s
episode: 1002/2000 -> reward: -124.99999999999025, steps:66720, time-taken: 3.11min, time-elasped: 2995.49min
-> berries picked: 67 of 800 | patches-visited: [3, 8, 9] | positive-in-buffer: 17492 | amount-filled: 100.00%
	| epsilon: 0.2230676269466271
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2065, 2266, 1330, 1355, 1131, 2517, 2537, 4291]
	| approx positives in sample 512: 246
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 32, 16, 22, 15, 36, 35, 63]
	Time taken saving stuff: 12.13s
episode: 1003/2000 -> reward: -124.9999999999941, steps:73440, time-taken: 3.08min, time-elasped: 2998.77min
-> berries picked: 96 of 800 | patches-visited: [4, 5] | positive-in-buffer: 17541 | amount-filled: 100.00%
	| epsilon: 0.22288819240557617
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2076, 2270, 1334, 1359, 1136, 2525, 2543, 4298]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 24, 17, 21, 7, 37, 25, 58]
	Time taken saving stuff: 0.09s
episode: 1004/2000 -> reward: -124.9999999999867, steps:69600, time-taken: 3.21min, time-elasped: 3001.98min
-> berries picked: 80 of 800 | patches-visited: [4, 7] | positive-in-buffer: 17583 | amount-filled: 100.00%
	| epsilon: 0.22270890220081893
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2075, 2280, 1337, 1372, 1145, 2529, 2543, 4302]
	| approx positives in sample 512: 252
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 42, 12, 12, 16, 32, 34, 71]
	Time taken saving stuff: 0.04s
episode: 1005/2000 -> reward: -124.99999999999227, steps:65376, time-taken: 2.30min, time-elasped: 3004.28min
-> berries picked: 69 of 800 | patches-visited: [2] | positive-in-buffer: 17558 | amount-filled: 100.00%
	| epsilon: 0.222529756216252
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2072, 2277, 1339, 1368, 1146, 2528, 2535, 4293]
	| approx positives in sample 512: 201
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 31, 10, 15, 13, 29, 25, 54]
	Time taken saving stuff: 15.33s
episode: 1006/2000 -> reward: -124.99999999998593, steps:76224, time-taken: 3.25min, time-elasped: 3007.79min
-> berries picked: 103 of 800 | patches-visited: [0, 1, 7, 9] | positive-in-buffer: 17499 | amount-filled: 100.00%
	| epsilon: 0.22235075433586535
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2070, 2273, 1327, 1362, 1144, 2514, 2527, 4282]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 24, 19, 16, 20, 28, 35, 59]
	Time taken saving stuff: 0.02s
episode: 1007/2000 -> reward: -124.99999999999203, steps:53472, time-taken: 2.11min, time-elasped: 3009.90min
-> berries picked: 23 of 800 | patches-visited: [2] | positive-in-buffer: 17511 | amount-filled: 100.00%
	| epsilon: 0.2221718964437422
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2073, 2274, 1328, 1362, 1143, 2514, 2529, 4288]
	| approx positives in sample 512: 249
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 34, 10, 23, 13, 35, 42, 68]
	Time taken saving stuff: 0.02s
episode: 1008/2000 -> reward: -124.99999999999169, steps:64992, time-taken: 2.51min, time-elasped: 3012.42min
-> berries picked: 64 of 800 | patches-visited: [1] | positive-in-buffer: 17541 | amount-filled: 100.00%
	| epsilon: 0.22199318242405908
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2076, 2283, 1330, 1366, 1143, 2523, 2527, 4293]
	| approx positives in sample 512: 192
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 33, 15, 16, 9, 28, 26, 40]
	Time taken saving stuff: 12.50s
episode: 1009/2000 -> reward: -124.99999999999207, steps:58080, time-taken: 2.08min, time-elasped: 3014.71min
-> berries picked: 36 of 800 | patches-visited: [0] | positive-in-buffer: 17463 | amount-filled: 100.00%
	| epsilon: 0.22181461216108575
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2069, 2263, 1324, 1362, 1139, 2511, 2517, 4278]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 26, 13, 17, 8, 31, 35, 60]
	Time taken saving stuff: 0.09s
episode: 1010/2000 -> reward: -124.9999999999938, steps:82176, time-taken: 3.36min, time-elasped: 3018.08min
-> berries picked: 126 of 800 | patches-visited: [1, 2, 6, 7] | positive-in-buffer: 17549 | amount-filled: 100.00%
	| epsilon: 0.22163618553918496
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2083, 2279, 1329, 1368, 1144, 2516, 2525, 4305]
	| approx positives in sample 512: 203
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 28, 14, 14, 10, 27, 34, 51]
	Time taken saving stuff: 0.03s
episode: 1011/2000 -> reward: -124.99999999999203, steps:50208, time-taken: 2.02min, time-elasped: 3020.10min
-> berries picked: 6 of 800 | patches-visited: [8] | positive-in-buffer: 17479 | amount-filled: 100.00%
	| epsilon: 0.2214579024428125
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2075, 2266, 1322, 1361, 1139, 2506, 2520, 4290]
	| approx positives in sample 512: 234
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 34, 22, 17, 16, 25, 30, 66]
	Time taken saving stuff: 14.82s
episode: 1012/2000 -> reward: -124.99999999998629, steps:79200, time-taken: 3.18min, time-elasped: 3023.53min
-> berries picked: 129 of 800 | patches-visited: [0, 7] | positive-in-buffer: 17583 | amount-filled: 100.00%
	| epsilon: 0.2212797627565171
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2089, 2281, 1328, 1372, 1151, 2519, 2536, 4307]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 22, 10, 11, 11, 42, 32, 62]
	Time taken saving stuff: 0.09s
episode: 1013/2000 -> reward: -124.99999999998924, steps:78048, time-taken: 3.20min, time-elasped: 3026.73min
-> berries picked: 113 of 800 | patches-visited: [2, 3, 5] | positive-in-buffer: 17655 | amount-filled: 100.00%
	| epsilon: 0.22110176636494042
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2103, 2281, 1331, 1384, 1165, 2530, 2549, 4312]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 25, 12, 15, 14, 31, 31, 62]
	Time taken saving stuff: 0.09s
episode: 1014/2000 -> reward: -124.99999999999186, steps:89088, time-taken: 4.19min, time-elasped: 3030.93min
-> berries picked: 157 of 800 | patches-visited: [1, 2, 5, 6] | positive-in-buffer: 17730 | amount-filled: 100.00%
	| epsilon: 0.2209239131528168
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2116, 2288, 1342, 1390, 1180, 2546, 2552, 4316]
	| approx positives in sample 512: 238
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 24, 25, 20, 15, 33, 35, 54]
	Time taken saving stuff: 12.30s
episode: 1015/2000 -> reward: -124.99999999999208, steps:58848, time-taken: 2.10min, time-elasped: 3033.23min
-> berries picked: 40 of 800 | patches-visited: [6] | positive-in-buffer: 17741 | amount-filled: 100.00%
	| epsilon: 0.22074620300497344
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2122, 2287, 1339, 1390, 1184, 2546, 2553, 4320]
	| approx positives in sample 512: 193
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 35, 18, 11, 11, 17, 26, 51]
	Time taken saving stuff: 0.03s
episode: 1016/2000 -> reward: -124.99999999998889, steps:62112, time-taken: 2.41min, time-elasped: 3035.65min
-> berries picked: 54 of 800 | patches-visited: [5] | positive-in-buffer: 17620 | amount-filled: 100.00%
	| epsilon: 0.22056863580633007
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2106, 2260, 1328, 1366, 1179, 2535, 2540, 4306]
	| approx positives in sample 512: 193
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 24, 11, 25, 9, 37, 22, 40]
	Time taken saving stuff: 0.09s
episode: 1017/2000 -> reward: -124.9999999999911, steps:69600, time-taken: 3.00min, time-elasped: 3038.66min
-> berries picked: 77 of 800 | patches-visited: [5, 9] | positive-in-buffer: 17570 | amount-filled: 100.00%
	| epsilon: 0.22039121144189908
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2096, 2250, 1321, 1363, 1178, 2528, 2532, 4302]
	| approx positives in sample 512: 235
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [36, 36, 16, 18, 16, 31, 22, 60]
	Time taken saving stuff: 14.92s
episode: 1018/2000 -> reward: -124.9999999999851, steps:85632, time-taken: 3.32min, time-elasped: 3042.22min
-> berries picked: 159 of 800 | patches-visited: [2, 8] | positive-in-buffer: 17674 | amount-filled: 100.00%
	| epsilon: 0.22021392979678522
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2103, 2260, 1334, 1375, 1189, 2549, 2541, 4323]
	| approx positives in sample 512: 181
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 21, 14, 10, 8, 29, 24, 59]
	Time taken saving stuff: 0.10s
episode: 1019/2000 -> reward: -124.99999999999167, steps:55872, time-taken: 2.12min, time-elasped: 3044.35min
-> berries picked: 32 of 800 | patches-visited: [1, 6] | positive-in-buffer: 17599 | amount-filled: 100.00%
	| epsilon: 0.22003679075618585
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2094, 2254, 1322, 1369, 1187, 2536, 2536, 4301]
	| approx positives in sample 512: 207
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [36, 21, 11, 20, 13, 25, 37, 44]
	Time taken saving stuff: 0.11s
episode: 1020/2000 -> reward: -124.99999999999204, steps:51168, time-taken: 2.07min, time-elasped: 3046.42min
-> berries picked: 11 of 800 | patches-visited: [2] | positive-in-buffer: 17593 | amount-filled: 100.00%
	| epsilon: 0.21985979420539048
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2095, 2253, 1323, 1367, 1185, 2531, 2539, 4300]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 29, 20, 10, 17, 36, 25, 62]
	Time taken saving stuff: 12.35s
episode: 1021/2000 -> reward: -124.99999999999251, steps:61248, time-taken: 2.23min, time-elasped: 3048.86min
-> berries picked: 47 of 800 | patches-visited: [2, 7] | positive-in-buffer: 17634 | amount-filled: 100.00%
	| epsilon: 0.21968294002978103
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2098, 2260, 1325, 1373, 1188, 2539, 2543, 4308]
	| approx positives in sample 512: 206
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 23, 11, 18, 10, 21, 31, 61]
	Time taken saving stuff: 0.10s
episode: 1022/2000 -> reward: -124.999999999992, steps:60672, time-taken: 2.16min, time-elasped: 3051.03min
-> berries picked: 44 of 800 | patches-visited: [3] | positive-in-buffer: 17603 | amount-filled: 100.00%
	| epsilon: 0.21950622811483161
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2100, 2259, 1321, 1369, 1185, 2533, 2533, 4303]
	| approx positives in sample 512: 191
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 22, 21, 17, 10, 26, 30, 47]
	Time taken saving stuff: 0.11s
episode: 1023/2000 -> reward: -124.9999999999797, steps:96384, time-taken: 4.37min, time-elasped: 3055.41min
-> berries picked: 189 of 800 | patches-visited: [1, 3, 5, 7, 9] | positive-in-buffer: 17699 | amount-filled: 100.00%
	| epsilon: 0.21932965834610837
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2108, 2267, 1327, 1378, 1205, 2545, 2540, 4329]
	| approx positives in sample 512: 208
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 24, 14, 18, 8, 32, 29, 55]
	Time taken saving stuff: 14.98s
episode: 1024/2000 -> reward: -124.99999999999162, steps:60384, time-taken: 2.31min, time-elasped: 3057.97min
-> berries picked: 52 of 800 | patches-visited: [0, 4] | positive-in-buffer: 17708 | amount-filled: 100.00%
	| epsilon: 0.21915323060926958
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2110, 2271, 1329, 1381, 1199, 2552, 2535, 4331]
	| approx positives in sample 512: 181
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 19, 6, 17, 14, 26, 28, 49]
	Time taken saving stuff: 0.11s
episode: 1025/2000 -> reward: -124.99999999999044, steps:68448, time-taken: 3.15min, time-elasped: 3061.13min
-> berries picked: 83 of 800 | patches-visited: [2, 3] | positive-in-buffer: 17639 | amount-filled: 100.00%
	| epsilon: 0.21897694479006546
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2096, 2260, 1327, 1387, 1197, 2537, 2521, 4314]
	| approx positives in sample 512: 244
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 24, 20, 22, 15, 36, 38, 69]
	Time taken saving stuff: 0.03s
episode: 1026/2000 -> reward: -124.99999999999271, steps:76032, time-taken: 3.14min, time-elasped: 3064.26min
-> berries picked: 105 of 800 | patches-visited: [3, 7] | positive-in-buffer: 17707 | amount-filled: 100.00%
	| epsilon: 0.21880080077433817
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2105, 2261, 1333, 1401, 1204, 2549, 2531, 4323]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 27, 14, 21, 11, 31, 27, 57]
	Time taken saving stuff: 12.17s
episode: 1027/2000 -> reward: -124.9999999999882, steps:63840, time-taken: 2.31min, time-elasped: 3066.78min
-> berries picked: 61 of 800 | patches-visited: [1] | positive-in-buffer: 17726 | amount-filled: 100.00%
	| epsilon: 0.21862479844802157
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2106, 2264, 1338, 1404, 1204, 2551, 2533, 4326]
	| approx positives in sample 512: 181
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 22, 10, 16, 15, 26, 19, 49]
	Time taken saving stuff: 0.02s
episode: 1028/2000 -> reward: -124.99999999999201, steps:55680, time-taken: 2.16min, time-elasped: 3068.94min
-> berries picked: 27 of 800 | patches-visited: [6] | positive-in-buffer: 17623 | amount-filled: 100.00%
	| epsilon: 0.2184489376971415
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2089, 2250, 1331, 1393, 1198, 2529, 2524, 4309]
	| approx positives in sample 512: 195
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 27, 16, 17, 16, 23, 28, 51]
	Time taken saving stuff: 0.01s
episode: 1029/2000 -> reward: -124.99999999998299, steps:106656, time-taken: 4.89min, time-elasped: 3073.83min
-> berries picked: 235 of 800 | patches-visited: [1, 4, 6, 7] | positive-in-buffer: 17781 | amount-filled: 100.00%
	| epsilon: 0.21827321840781527
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2102, 2271, 1343, 1409, 1215, 2551, 2551, 4339]
	| approx positives in sample 512: 190
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 18, 14, 12, 15, 34, 23, 49]
	Time taken saving stuff: 16.12s
episode: 1030/2000 -> reward: -124.99999999999191, steps:63648, time-taken: 2.39min, time-elasped: 3076.49min
-> berries picked: 54 of 800 | patches-visited: [5] | positive-in-buffer: 17692 | amount-filled: 100.00%
	| epsilon: 0.21809764046625188
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2095, 2261, 1338, 1398, 1204, 2541, 2541, 4314]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 25, 16, 18, 13, 40, 23, 53]
	Time taken saving stuff: 0.10s
episode: 1031/2000 -> reward: -124.99999999999265, steps:73824, time-taken: 3.07min, time-elasped: 3079.56min
-> berries picked: 93 of 800 | patches-visited: [2, 5, 6] | positive-in-buffer: 17658 | amount-filled: 100.00%
	| epsilon: 0.21792220375875188
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2090, 2252, 1332, 1401, 1209, 2544, 2521, 4309]
	| approx positives in sample 512: 196
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 24, 15, 14, 14, 25, 22, 49]
	Time taken saving stuff: 0.11s
episode: 1032/2000 -> reward: -124.99999999998765, steps:79584, time-taken: 3.40min, time-elasped: 3082.96min
-> berries picked: 123 of 800 | patches-visited: [0, 3] | positive-in-buffer: 17749 | amount-filled: 100.00%
	| epsilon: 0.21774690817170728
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2101, 2266, 1339, 1411, 1220, 2558, 2533, 4321]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 28, 13, 14, 18, 39, 30, 62]
	Time taken saving stuff: 12.39s
episode: 1033/2000 -> reward: -124.99999999998983, steps:88032, time-taken: 4.38min, time-elasped: 3087.55min
-> berries picked: 164 of 800 | patches-visited: [0, 5, 6] | positive-in-buffer: 17811 | amount-filled: 100.00%
	| epsilon: 0.21757175359160136
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2106, 2272, 1343, 1415, 1226, 2571, 2540, 4338]
	| approx positives in sample 512: 237
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 32, 24, 15, 17, 23, 30, 70]
	Time taken saving stuff: 0.07s
episode: 1034/2000 -> reward: -124.99999999999241, steps:67200, time-taken: 3.08min, time-elasped: 3090.63min
-> berries picked: 77 of 800 | patches-visited: [3] | positive-in-buffer: 17832 | amount-filled: 100.00%
	| epsilon: 0.21739673990500893
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2108, 2269, 1344, 1416, 1230, 2576, 2548, 4341]
	| approx positives in sample 512: 256
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 35, 15, 18, 14, 44, 40, 62]
	Time taken saving stuff: 0.04s
episode: 1035/2000 -> reward: -124.9999999999873, steps:94272, time-taken: 4.39min, time-elasped: 3095.02min
-> berries picked: 195 of 800 | patches-visited: [1, 7, 9] | positive-in-buffer: 17923 | amount-filled: 100.00%
	| epsilon: 0.21722186699859586
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2121, 2282, 1352, 1426, 1241, 2586, 2558, 4357]
	| approx positives in sample 512: 210
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 33, 11, 14, 15, 24, 35, 55]
	Time taken saving stuff: 15.29s
episode: 1036/2000 -> reward: -124.99999999999476, steps:79680, time-taken: 3.20min, time-elasped: 3098.48min
-> berries picked: 131 of 800 | patches-visited: [0, 1] | positive-in-buffer: 17925 | amount-filled: 100.00%
	| epsilon: 0.21704713475911921
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2131, 2283, 1352, 1415, 1234, 2594, 2562, 4354]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 20, 14, 22, 19, 33, 38, 50]
	Time taken saving stuff: 0.03s
episode: 1037/2000 -> reward: -124.9999999999927, steps:65280, time-taken: 2.14min, time-elasped: 3100.62min
-> berries picked: 63 of 800 | patches-visited: [3] | positive-in-buffer: 17873 | amount-filled: 100.00%
	| epsilon: 0.21687254307342724
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2129, 2270, 1346, 1414, 1235, 2580, 2553, 4346]
	| approx positives in sample 512: 198
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 31, 10, 19, 15, 17, 31, 52]
	Time taken saving stuff: 0.03s
episode: 1038/2000 -> reward: -124.99999999998705, steps:99264, time-taken: 4.46min, time-elasped: 3105.08min
-> berries picked: 214 of 800 | patches-visited: [1, 6, 7] | positive-in-buffer: 17875 | amount-filled: 100.00%
	| epsilon: 0.2166980918284591
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2132, 2267, 1342, 1407, 1239, 2595, 2543, 4350]
	| approx positives in sample 512: 210
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 33, 15, 16, 15, 22, 30, 49]
	Time taken saving stuff: 12.09s
episode: 1039/2000 -> reward: -124.9999999999852, steps:90720, time-taken: 4.15min, time-elasped: 3109.43min
-> berries picked: 175 of 800 | patches-visited: [0, 1, 2] | positive-in-buffer: 17947 | amount-filled: 100.00%
	| epsilon: 0.2165237809112449
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2134, 2272, 1348, 1416, 1246, 2609, 2558, 4364]
	| approx positives in sample 512: 230
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 28, 14, 17, 16, 42, 30, 56]
	Time taken saving stuff: 0.11s
episode: 1040/2000 -> reward: -124.99999999998153, steps:104352, time-taken: 4.52min, time-elasped: 3113.96min
-> berries picked: 212 of 800 | patches-visited: [0, 5, 8] | positive-in-buffer: 18025 | amount-filled: 100.00%
	| epsilon: 0.21634961020890575
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2142, 2272, 1352, 1430, 1270, 2618, 2563, 4378]
	| approx positives in sample 512: 197
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 23, 10, 17, 21, 32, 29, 48]
	Time taken saving stuff: 0.03s
episode: 1041/2000 -> reward: -124.99999999999226, steps:61632, time-taken: 2.06min, time-elasped: 3116.02min
-> berries picked: 52 of 800 | patches-visited: [3, 8] | positive-in-buffer: 17904 | amount-filled: 100.00%
	| epsilon: 0.21617557960865344
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2132, 2270, 1333, 1411, 1263, 2595, 2542, 4358]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 22, 13, 14, 20, 30, 33, 60]
	Time taken saving stuff: 15.10s
episode: 1042/2000 -> reward: -124.99999999999199, steps:66432, time-taken: 3.27min, time-elasped: 3119.54min
-> berries picked: 66 of 800 | patches-visited: [3] | positive-in-buffer: 17910 | amount-filled: 100.00%
	| epsilon: 0.2160016889977905
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2135, 2273, 1329, 1406, 1269, 2596, 2544, 4358]
	| approx positives in sample 512: 248
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 29, 17, 18, 22, 37, 41, 57]
	Time taken saving stuff: 0.24s
episode: 1043/2000 -> reward: -124.99999999997587, steps:105984, time-taken: 4.44min, time-elasped: 3123.98min
-> berries picked: 223 of 800 | patches-visited: [0, 1, 4, 5, 7] | positive-in-buffer: 18059 | amount-filled: 100.00%
	| epsilon: 0.2158279382637101
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2148, 2295, 1341, 1423, 1280, 2624, 2571, 4377]
	| approx positives in sample 512: 205
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 20, 11, 12, 14, 27, 36, 59]
	Time taken saving stuff: 0.03s
episode: 1044/2000 -> reward: -124.99999999999227, steps:62784, time-taken: 2.07min, time-elasped: 3126.06min
-> berries picked: 57 of 800 | patches-visited: [3] | positive-in-buffer: 17981 | amount-filled: 100.00%
	| epsilon: 0.21565432729389605
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2141, 2286, 1330, 1418, 1272, 2614, 2555, 4365]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 34, 15, 16, 15, 28, 21, 62]
	Time taken saving stuff: 11.86s
episode: 1045/2000 -> reward: -124.99999999999126, steps:66336, time-taken: 3.14min, time-elasped: 3129.40min
-> berries picked: 73 of 800 | patches-visited: [0] | positive-in-buffer: 17952 | amount-filled: 100.00%
	| epsilon: 0.21548085597592265
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2147, 2273, 1320, 1416, 1274, 2612, 2553, 4357]
	| approx positives in sample 512: 260
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [39, 32, 6, 22, 20, 41, 40, 60]
	Time taken saving stuff: 0.02s
episode: 1046/2000 -> reward: -124.99999999999007, steps:103296, time-taken: 4.33min, time-elasped: 3133.74min
-> berries picked: 217 of 800 | patches-visited: [3, 4, 8] | positive-in-buffer: 18094 | amount-filled: 100.00%
	| epsilon: 0.2153075241974546
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2161, 2289, 1330, 1433, 1294, 2633, 2571, 4383]
	| approx positives in sample 512: 199
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 29, 15, 13, 10, 27, 28, 56]
	Time taken saving stuff: 0.10s
episode: 1047/2000 -> reward: -124.99999999999129, steps:65184, time-taken: 2.42min, time-elasped: 3136.16min
-> berries picked: 80 of 800 | patches-visited: [9] | positive-in-buffer: 18079 | amount-filled: 100.00%
	| epsilon: 0.21513433184624703
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2160, 2285, 1325, 1426, 1290, 2636, 2568, 4389]
	| approx positives in sample 512: 202
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 28, 14, 15, 11, 35, 32, 41]
	Time taken saving stuff: 15.35s
episode: 1048/2000 -> reward: -124.99999999999157, steps:73728, time-taken: 3.01min, time-elasped: 3139.44min
-> berries picked: 107 of 800 | patches-visited: [2, 6] | positive-in-buffer: 18003 | amount-filled: 100.00%
	| epsilon: 0.21496127881014526
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2148, 2272, 1310, 1420, 1284, 2626, 2562, 4381]
	| approx positives in sample 512: 226
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [37, 26, 19, 21, 10, 31, 26, 56]
	Time taken saving stuff: 0.02s
episode: 1049/2000 -> reward: -109.24999999998057, steps:120000, time-taken: 5.37min, time-elasped: 3144.80min
-> berries picked: 298 of 800 | patches-visited: [0, 2, 3, 5, 8] | positive-in-buffer: 18208 | amount-filled: 100.00%
	| epsilon: 0.2147883649770849
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2170, 2286, 1333, 1451, 1310, 2665, 2580, 4413]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 33, 12, 17, 19, 25, 38, 47]
	Time taken saving stuff: 0.11s
episode: 1050/2000 -> reward: -124.99999999999216, steps:62400, time-taken: 2.19min, time-elasped: 3146.99min
-> berries picked: 56 of 800 | patches-visited: [8] | positive-in-buffer: 18192 | amount-filled: 100.00%
	| epsilon: 0.2146155902350917
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2175, 2280, 1334, 1446, 1306, 2658, 2574, 4419]
	| approx positives in sample 512: 226
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 37, 17, 23, 11, 30, 29, 56]
	Time taken saving stuff: 11.70s
episode: 1051/2000 -> reward: -124.9999999999923, steps:88608, time-taken: 4.15min, time-elasped: 3151.34min
-> berries picked: 175 of 800 | patches-visited: [0, 8, 9] | positive-in-buffer: 18145 | amount-filled: 100.00%
	| epsilon: 0.21444295447228137
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2175, 2277, 1315, 1436, 1309, 2653, 2570, 4410]
	| approx positives in sample 512: 255
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 33, 21, 17, 17, 26, 37, 72]
	Time taken saving stuff: 0.06s
episode: 1052/2000 -> reward: -124.99999999999264, steps:83424, time-taken: 3.32min, time-elasped: 3154.66min
-> berries picked: 144 of 800 | patches-visited: [1, 2] | positive-in-buffer: 18186 | amount-filled: 100.00%
	| epsilon: 0.21427045757685986
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2181, 2278, 1322, 1440, 1309, 2660, 2574, 4422]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 30, 17, 19, 16, 28, 25, 52]
	Time taken saving stuff: 0.10s
episode: 1053/2000 -> reward: -124.99999999999186, steps:64608, time-taken: 2.38min, time-elasped: 3157.04min
-> berries picked: 65 of 800 | patches-visited: [1] | positive-in-buffer: 18077 | amount-filled: 100.00%
	| epsilon: 0.21409809943712282
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2166, 2266, 1318, 1427, 1296, 2646, 2559, 4399]
	| approx positives in sample 512: 182
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 22, 11, 16, 17, 23, 26, 54]
	Time taken saving stuff: 15.13s
episode: 1054/2000 -> reward: -124.99999999999191, steps:66912, time-taken: 2.93min, time-elasped: 3160.22min
-> berries picked: 77 of 800 | patches-visited: [9] | positive-in-buffer: 18040 | amount-filled: 100.00%
	| epsilon: 0.21392587994145584
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2166, 2256, 1312, 1426, 1294, 2641, 2552, 4393]
	| approx positives in sample 512: 249
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 42, 18, 17, 15, 37, 27, 68]
	Time taken saving stuff: 0.08s
episode: 1055/2000 -> reward: -124.99999999998603, steps:85632, time-taken: 3.48min, time-elasped: 3163.70min
-> berries picked: 156 of 800 | patches-visited: [7, 8] | positive-in-buffer: 18154 | amount-filled: 100.00%
	| epsilon: 0.2137537989783343
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2175, 2264, 1320, 1440, 1306, 2658, 2573, 4418]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 29, 15, 23, 17, 26, 30, 48]
	Time taken saving stuff: 0.03s
episode: 1056/2000 -> reward: -124.99999999998661, steps:84864, time-taken: 3.34min, time-elasped: 3167.05min
-> berries picked: 159 of 800 | patches-visited: [2, 8] | positive-in-buffer: 18142 | amount-filled: 100.00%
	| epsilon: 0.21358185643632327
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2165, 2268, 1319, 1440, 1311, 2659, 2565, 4415]
	| approx positives in sample 512: 198
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 25, 11, 20, 15, 33, 22, 57]
	Time taken saving stuff: 12.44s
episode: 1057/2000 -> reward: -124.99999999998452, steps:86400, time-taken: 3.22min, time-elasped: 3170.48min
-> berries picked: 152 of 800 | patches-visited: [4, 5, 7] | positive-in-buffer: 18136 | amount-filled: 100.00%
	| epsilon: 0.21341005220407744
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2158, 2253, 1323, 1440, 1319, 2670, 2559, 4414]
	| approx positives in sample 512: 194
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 22, 18, 13, 13, 25, 27, 54]
	Time taken saving stuff: 0.03s
episode: 1058/2000 -> reward: -124.99999999998246, steps:113088, time-taken: 5.21min, time-elasped: 3175.69min
-> berries picked: 265 of 800 | patches-visited: [1, 6, 7, 9] | positive-in-buffer: 18212 | amount-filled: 100.00%
	| epsilon: 0.21323838617034116
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2164, 2264, 1325, 1455, 1327, 2670, 2572, 4435]
	| approx positives in sample 512: 240
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 33, 23, 16, 18, 32, 37, 51]
	Time taken saving stuff: 0.01s
episode: 1059/2000 -> reward: -124.99999999999194, steps:59904, time-taken: 2.19min, time-elasped: 3177.88min
-> berries picked: 47 of 800 | patches-visited: [8] | positive-in-buffer: 18209 | amount-filled: 100.00%
	| epsilon: 0.21306685822394814
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2163, 2262, 1324, 1454, 1323, 2674, 2574, 4435]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 24, 8, 24, 18, 26, 37, 53]
	Time taken saving stuff: 14.72s
episode: 1060/2000 -> reward: -124.99999999999085, steps:75840, time-taken: 3.15min, time-elasped: 3181.28min
-> berries picked: 104 of 800 | patches-visited: [0, 1, 6] | positive-in-buffer: 18119 | amount-filled: 100.00%
	| epsilon: 0.2128954682538216
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2161, 2263, 1318, 1447, 1287, 2655, 2563, 4425]
	| approx positives in sample 512: 244
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 26, 18, 22, 13, 31, 33, 66]
	Time taken saving stuff: 0.10s
episode: 1061/2000 -> reward: -124.9999999999847, steps:112800, time-taken: 5.13min, time-elasped: 3186.42min
-> berries picked: 246 of 800 | patches-visited: [2, 4, 8, 9] | positive-in-buffer: 18022 | amount-filled: 100.00%
	| epsilon: 0.2127242161489741
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2160, 2254, 1324, 1446, 1224, 2629, 2560, 4425]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 32, 17, 25, 12, 34, 33, 46]
	Time taken saving stuff: 0.01s
episode: 1062/2000 -> reward: -124.999999999992, steps:68160, time-taken: 2.99min, time-elasped: 3189.41min
-> berries picked: 72 of 800 | patches-visited: [0] | positive-in-buffer: 18052 | amount-filled: 100.00%
	| epsilon: 0.21255310179850745
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2165, 2253, 1329, 1454, 1224, 2624, 2564, 4439]
	| approx positives in sample 512: 259
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 24, 20, 16, 27, 24, 35, 80]
	Time taken saving stuff: 12.68s
episode: 1063/2000 -> reward: -124.99999999999433, steps:81312, time-taken: 3.25min, time-elasped: 3192.87min
-> berries picked: 140 of 800 | patches-visited: [0, 7] | positive-in-buffer: 18126 | amount-filled: 100.00%
	| epsilon: 0.21238212509161267
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2179, 2259, 1333, 1465, 1231, 2630, 2575, 4454]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 30, 15, 19, 13, 31, 28, 60]
	Time taken saving stuff: 0.11s
episode: 1064/2000 -> reward: -124.99999999999422, steps:83520, time-taken: 3.37min, time-elasped: 3196.25min
-> berries picked: 145 of 800 | patches-visited: [4, 7] | positive-in-buffer: 18141 | amount-filled: 100.00%
	| epsilon: 0.2122112859175699
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2184, 2270, 1342, 1464, 1232, 2622, 2567, 4460]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 37, 8, 24, 11, 29, 29, 57]
	Time taken saving stuff: 0.02s
episode: 1065/2000 -> reward: -124.99999999998522, steps:99744, time-taken: 4.36min, time-elasped: 3200.61min
-> berries picked: 215 of 800 | patches-visited: [0, 3, 6] | positive-in-buffer: 18222 | amount-filled: 100.00%
	| epsilon: 0.21204058416574842
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2188, 2280, 1353, 1473, 1247, 2629, 2579, 4473]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 33, 23, 16, 14, 28, 28, 46]
	Time taken saving stuff: 15.31s
episode: 1066/2000 -> reward: -124.99999999999199, steps:64128, time-taken: 2.05min, time-elasped: 3202.92min
-> berries picked: 65 of 800 | patches-visited: [2] | positive-in-buffer: 18225 | amount-filled: 100.00%
	| epsilon: 0.21187001972560643
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2188, 2280, 1353, 1473, 1248, 2627, 2580, 4476]
	| approx positives in sample 512: 199
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 24, 9, 15, 9, 40, 32, 56]
	Time taken saving stuff: 0.11s
episode: 1067/2000 -> reward: -124.99999999998411, steps:81888, time-taken: 3.35min, time-elasped: 3206.27min
-> berries picked: 131 of 800 | patches-visited: [1, 4] | positive-in-buffer: 18196 | amount-filled: 100.00%
	| epsilon: 0.21169959248669107
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2191, 2275, 1346, 1474, 1253, 2621, 2574, 4462]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 33, 16, 21, 11, 30, 28, 50]
	Time taken saving stuff: 0.01s
episode: 1068/2000 -> reward: -124.99999999999412, steps:87264, time-taken: 3.56min, time-elasped: 3209.83min
-> berries picked: 142 of 800 | patches-visited: [2, 4, 5] | positive-in-buffer: 18272 | amount-filled: 100.00%
	| epsilon: 0.21152930233863831
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2207, 2284, 1354, 1480, 1259, 2627, 2579, 4482]
	| approx positives in sample 512: 204
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 23, 13, 15, 15, 22, 29, 62]
	Time taken saving stuff: 12.64s
episode: 1069/2000 -> reward: -124.99999999998302, steps:84960, time-taken: 3.23min, time-elasped: 3213.28min
-> berries picked: 152 of 800 | patches-visited: [4, 6] | positive-in-buffer: 18275 | amount-filled: 100.00%
	| epsilon: 0.21135914917117293
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2205, 2290, 1356, 1481, 1260, 2631, 2572, 4480]
	| approx positives in sample 512: 190
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 25, 7, 18, 16, 29, 29, 44]
	Time taken saving stuff: 0.05s
episode: 1070/2000 -> reward: -124.9999999999918, steps:64896, time-taken: 2.31min, time-elasped: 3215.59min
-> berries picked: 70 of 800 | patches-visited: [2] | positive-in-buffer: 18270 | amount-filled: 100.00%
	| epsilon: 0.21118913287410834
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2199, 2284, 1351, 1477, 1265, 2634, 2576, 4484]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 30, 14, 20, 16, 27, 25, 57]
	Time taken saving stuff: 0.10s
episode: 1071/2000 -> reward: -124.99999999998931, steps:74400, time-taken: 3.05min, time-elasped: 3218.65min
-> berries picked: 103 of 800 | patches-visited: [1, 4] | positive-in-buffer: 18244 | amount-filled: 100.00%
	| epsilon: 0.2110192533373467
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2191, 2284, 1348, 1480, 1269, 2635, 2574, 4463]
	| approx positives in sample 512: 235
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [36, 30, 13, 15, 14, 35, 34, 58]
	Time taken saving stuff: 15.05s
episode: 1072/2000 -> reward: -124.999999999992, steps:61824, time-taken: 2.37min, time-elasped: 3221.27min
-> berries picked: 49 of 800 | patches-visited: [9] | positive-in-buffer: 18275 | amount-filled: 100.00%
	| epsilon: 0.21084951045087866
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2194, 2291, 1352, 1480, 1270, 2635, 2582, 4471]
	| approx positives in sample 512: 201
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 30, 14, 16, 9, 26, 26, 61]
	Time taken saving stuff: 0.09s
episode: 1073/2000 -> reward: -124.999999999991, steps:65376, time-taken: 2.25min, time-elasped: 3223.53min
-> berries picked: 68 of 800 | patches-visited: [3] | positive-in-buffer: 18285 | amount-filled: 100.00%
	| epsilon: 0.21067990410478335
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2197, 2287, 1355, 1487, 1269, 2635, 2579, 4476]
	| approx positives in sample 512: 193
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 23, 15, 12, 14, 27, 25, 48]
	Time taken saving stuff: 0.02s
episode: 1074/2000 -> reward: -124.99999999999199, steps:60768, time-taken: 2.23min, time-elasped: 3225.77min
-> berries picked: 52 of 800 | patches-visited: [6] | positive-in-buffer: 18259 | amount-filled: 100.00%
	| epsilon: 0.21051043418922835
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2200, 2283, 1354, 1490, 1267, 2622, 2574, 4469]
	| approx positives in sample 512: 202
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 23, 14, 26, 13, 25, 28, 44]
	Time taken saving stuff: 11.93s
episode: 1075/2000 -> reward: -124.99999999999203, steps:52128, time-taken: 2.14min, time-elasped: 3228.11min
-> berries picked: 13 of 800 | patches-visited: [9] | positive-in-buffer: 18249 | amount-filled: 100.00%
	| epsilon: 0.21034110059446962
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2198, 2281, 1355, 1486, 1268, 2618, 2571, 4472]
	| approx positives in sample 512: 230
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 26, 19, 16, 20, 38, 24, 57]
	Time taken saving stuff: 0.10s
episode: 1076/2000 -> reward: -124.9999999999899, steps:69792, time-taken: 3.10min, time-elasped: 3231.21min
-> berries picked: 95 of 800 | patches-visited: [1, 8] | positive-in-buffer: 18321 | amount-filled: 100.00%
	| epsilon: 0.21017190321085127
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2203, 2294, 1361, 1492, 1279, 2624, 2578, 4490]
	| approx positives in sample 512: 237
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 24, 16, 27, 6, 32, 29, 73]
	Time taken saving stuff: 0.02s
episode: 1077/2000 -> reward: -124.99999999999173, steps:81024, time-taken: 3.39min, time-elasped: 3234.60min
-> berries picked: 140 of 800 | patches-visited: [0, 3] | positive-in-buffer: 18398 | amount-filled: 100.00%
	| epsilon: 0.21000284192880578
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2216, 2300, 1366, 1504, 1283, 2636, 2590, 4503]
	| approx positives in sample 512: 208
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 17, 17, 18, 10, 24, 36, 60]
	Time taken saving stuff: 14.97s
episode: 1078/2000 -> reward: -124.99999999999194, steps:61248, time-taken: 2.17min, time-elasped: 3237.03min
-> berries picked: 49 of 800 | patches-visited: [0] | positive-in-buffer: 18349 | amount-filled: 100.00%
	| epsilon: 0.20983391663885367
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2211, 2298, 1366, 1501, 1273, 2632, 2581, 4487]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 21, 14, 20, 21, 33, 29, 48]
	Time taken saving stuff: 0.09s
episode: 1079/2000 -> reward: -124.99999999999173, steps:66624, time-taken: 3.00min, time-elasped: 3240.03min
-> berries picked: 78 of 800 | patches-visited: [0] | positive-in-buffer: 18326 | amount-filled: 100.00%
	| epsilon: 0.20966512723160355
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2204, 2290, 1366, 1503, 1271, 2626, 2572, 4494]
	| approx positives in sample 512: 234
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 32, 14, 24, 17, 33, 31, 59]
	Time taken saving stuff: 0.15s
episode: 1080/2000 -> reward: -124.99999999999174, steps:66816, time-taken: 3.14min, time-elasped: 3243.18min
-> berries picked: 72 of 800 | patches-visited: [5] | positive-in-buffer: 18371 | amount-filled: 100.00%
	| epsilon: 0.209496473597752
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2211, 2292, 1369, 1508, 1279, 2634, 2577, 4501]
	| approx positives in sample 512: 250
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 32, 21, 26, 21, 36, 27, 61]
	Time taken saving stuff: 11.77s
episode: 1081/2000 -> reward: -124.99999999998833, steps:86016, time-taken: 3.57min, time-elasped: 3246.95min
-> berries picked: 151 of 800 | patches-visited: [0, 4, 8] | positive-in-buffer: 18472 | amount-filled: 100.00%
	| epsilon: 0.20932795562808357
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2217, 2300, 1380, 1515, 1286, 2662, 2592, 4520]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 35, 8, 15, 12, 33, 32, 50]
	Time taken saving stuff: 0.10s
episode: 1082/2000 -> reward: -124.99999999999173, steps:84960, time-taken: 3.37min, time-elasped: 3250.32min
-> berries picked: 138 of 800 | patches-visited: [0, 7] | positive-in-buffer: 18408 | amount-filled: 100.00%
	| epsilon: 0.2091595732134706
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2217, 2292, 1386, 1517, 1282, 2648, 2570, 4496]
	| approx positives in sample 512: 202
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 20, 15, 22, 17, 24, 37, 51]
	Time taken saving stuff: 0.10s
episode: 1083/2000 -> reward: -124.99999999998619, steps:96864, time-taken: 4.30min, time-elasped: 3254.63min
-> berries picked: 205 of 800 | patches-visited: [3, 5, 9] | positive-in-buffer: 18453 | amount-filled: 100.00%
	| epsilon: 0.20899132624487327
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2218, 2295, 1393, 1518, 1291, 2668, 2572, 4498]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 31, 10, 13, 11, 42, 35, 51]
	Time taken saving stuff: 15.27s
episode: 1084/2000 -> reward: -124.99999999999416, steps:81888, time-taken: 3.29min, time-elasped: 3258.17min
-> berries picked: 138 of 800 | patches-visited: [4, 5] | positive-in-buffer: 18536 | amount-filled: 100.00%
	| epsilon: 0.20882321461333944
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2226, 2298, 1396, 1529, 1301, 2679, 2583, 4524]
	| approx positives in sample 512: 207
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 26, 15, 19, 12, 28, 21, 56]
	Time taken saving stuff: 0.10s
episode: 1085/2000 -> reward: -124.99999999998903, steps:92448, time-taken: 4.32min, time-elasped: 3262.49min
-> berries picked: 174 of 800 | patches-visited: [0, 5, 9] | positive-in-buffer: 18549 | amount-filled: 100.00%
	| epsilon: 0.20865523821000465
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2225, 2304, 1396, 1533, 1312, 2672, 2577, 4530]
	| approx positives in sample 512: 233
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 40, 11, 21, 16, 36, 27, 54]
	Time taken saving stuff: 0.11s
episode: 1086/2000 -> reward: -124.99999999999275, steps:67200, time-taken: 3.05min, time-elasped: 3265.55min
-> berries picked: 80 of 800 | patches-visited: [4] | positive-in-buffer: 18581 | amount-filled: 100.00%
	| epsilon: 0.20848739692609192
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2226, 2305, 1400, 1535, 1311, 2680, 2585, 4539]
	| approx positives in sample 512: 244
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 39, 18, 17, 25, 35, 37, 39]
	Time taken saving stuff: 12.81s
episode: 1087/2000 -> reward: -124.99999999999362, steps:72384, time-taken: 3.00min, time-elasped: 3268.76min
-> berries picked: 87 of 800 | patches-visited: [7, 8] | positive-in-buffer: 18611 | amount-filled: 100.00%
	| epsilon: 0.20831969065291187
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2230, 2309, 1404, 1540, 1317, 2682, 2583, 4546]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 39, 20, 24, 11, 20, 29, 54]
	Time taken saving stuff: 0.10s
episode: 1088/2000 -> reward: -124.99999999999554, steps:87552, time-taken: 3.44min, time-elasped: 3272.20min
-> berries picked: 152 of 800 | patches-visited: [6, 7] | positive-in-buffer: 18639 | amount-filled: 100.00%
	| epsilon: 0.20815211928186247
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2237, 2316, 1406, 1542, 1320, 2687, 2585, 4546]
	| approx positives in sample 512: 199
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 23, 19, 17, 16, 23, 26, 49]
	Time taken saving stuff: 0.02s
episode: 1089/2000 -> reward: -124.9999999999953, steps:81024, time-taken: 3.63min, time-elasped: 3275.84min
-> berries picked: 131 of 800 | patches-visited: [7, 8] | positive-in-buffer: 18509 | amount-filled: 100.00%
	| epsilon: 0.20798468270442913
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2227, 2291, 1402, 1534, 1310, 2675, 2558, 4512]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 30, 13, 19, 14, 32, 29, 47]
	Time taken saving stuff: 15.08s
episode: 1090/2000 -> reward: -124.99999999999211, steps:67488, time-taken: 2.90min, time-elasped: 3279.00min
-> berries picked: 79 of 800 | patches-visited: [3] | positive-in-buffer: 18550 | amount-filled: 100.00%
	| epsilon: 0.20781738081218448
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2231, 2292, 1404, 1533, 1320, 2678, 2565, 4527]
	| approx positives in sample 512: 235
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 29, 15, 21, 19, 33, 28, 59]
	Time taken saving stuff: 0.04s
episode: 1091/2000 -> reward: -124.99999999999203, steps:61152, time-taken: 2.28min, time-elasped: 3281.28min
-> berries picked: 48 of 800 | patches-visited: [2, 8] | positive-in-buffer: 18561 | amount-filled: 100.00%
	| epsilon: 0.20765021349678842
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2235, 2293, 1406, 1533, 1315, 2681, 2567, 4531]
	| approx positives in sample 512: 208
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 23, 13, 20, 16, 33, 33, 48]
	Time taken saving stuff: 0.08s
episode: 1092/2000 -> reward: -124.99999999999046, steps:85632, time-taken: 3.36min, time-elasped: 3284.64min
-> berries picked: 148 of 800 | patches-visited: [0, 3, 8] | positive-in-buffer: 18551 | amount-filled: 100.00%
	| epsilon: 0.20748318064998791
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2237, 2296, 1406, 1527, 1320, 2674, 2561, 4530]
	| approx positives in sample 512: 208
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 27, 24, 17, 17, 28, 17, 51]
	Time taken saving stuff: 12.61s
episode: 1093/2000 -> reward: -124.99999999999206, steps:53856, time-taken: 2.33min, time-elasped: 3287.19min
-> berries picked: 26 of 800 | patches-visited: [8] | positive-in-buffer: 18440 | amount-filled: 100.00%
	| epsilon: 0.2073162821636171
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2223, 2275, 1395, 1511, 1313, 2661, 2552, 4510]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 26, 16, 24, 13, 24, 30, 56]
	Time taken saving stuff: 0.02s
episode: 1094/2000 -> reward: -124.99999999999267, steps:68064, time-taken: 3.11min, time-elasped: 3290.30min
-> berries picked: 78 of 800 | patches-visited: [1] | positive-in-buffer: 18488 | amount-filled: 100.00%
	| epsilon: 0.2071495179295971
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2226, 2280, 1401, 1515, 1321, 2672, 2554, 4519]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 25, 21, 14, 18, 32, 34, 72]
	Time taken saving stuff: 0.07s
episode: 1095/2000 -> reward: -124.99999999999207, steps:66048, time-taken: 3.20min, time-elasped: 3293.50min
-> berries picked: 73 of 800 | patches-visited: [2] | positive-in-buffer: 18525 | amount-filled: 100.00%
	| epsilon: 0.20698288783993593
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2233, 2285, 1404, 1514, 1327, 2681, 2557, 4524]
	| approx positives in sample 512: 250
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [36, 31, 15, 22, 15, 39, 35, 57]
	Time taken saving stuff: 14.67s
episode: 1096/2000 -> reward: -124.999999999992, steps:61920, time-taken: 2.12min, time-elasped: 3295.87min
-> berries picked: 54 of 800 | patches-visited: [0, 6] | positive-in-buffer: 18547 | amount-filled: 100.00%
	| epsilon: 0.2068163917867285
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2235, 2286, 1403, 1518, 1328, 2687, 2560, 4530]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 33, 15, 12, 20, 34, 23, 45]
	Time taken saving stuff: 0.03s
episode: 1097/2000 -> reward: -124.99999999999196, steps:61536, time-taken: 2.16min, time-elasped: 3298.04min
-> berries picked: 51 of 800 | patches-visited: [4] | positive-in-buffer: 18450 | amount-filled: 100.00%
	| epsilon: 0.20665002966215656
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2226, 2277, 1391, 1508, 1311, 2689, 2542, 4506]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 16, 17, 13, 14, 36, 36, 56]
	Time taken saving stuff: 0.10s
episode: 1098/2000 -> reward: -124.99999999999201, steps:63456, time-taken: 2.20min, time-elasped: 3300.24min
-> berries picked: 67 of 800 | patches-visited: [3] | positive-in-buffer: 18442 | amount-filled: 100.00%
	| epsilon: 0.20648380135848854
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2219, 2273, 1394, 1498, 1308, 2692, 2549, 4509]
	| approx positives in sample 512: 192
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 19, 9, 12, 12, 32, 25, 55]
	Time taken saving stuff: 12.79s
episode: 1099/2000 -> reward: -124.99999999998967, steps:68928, time-taken: 2.94min, time-elasped: 3303.40min
-> berries picked: 85 of 800 | patches-visited: [1, 5] | positive-in-buffer: 18406 | amount-filled: 100.00%
	| epsilon: 0.20631770676807953
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2208, 2271, 1402, 1502, 1310, 2689, 2536, 4488]
	| approx positives in sample 512: 254
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 28, 29, 18, 15, 42, 36, 53]
	Time taken saving stuff: 0.02s
episode: 1100/2000 -> reward: -124.99999999999218, steps:64800, time-taken: 2.69min, time-elasped: 3306.09min
-> berries picked: 63 of 800 | patches-visited: [0] | positive-in-buffer: 18444 | amount-filled: 100.00%
	| epsilon: 0.2061517457833712
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2207, 2276, 1404, 1508, 1313, 2696, 2547, 4493]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 35, 13, 16, 17, 34, 26, 45]
	Time taken saving stuff: 0.03s
episode: 1101/2000 -> reward: -124.99999999998573, steps:87456, time-taken: 3.36min, time-elasped: 3309.45min
-> berries picked: 159 of 800 | patches-visited: [0, 5, 6] | positive-in-buffer: 18472 | amount-filled: 100.00%
	| epsilon: 0.20598591829689175
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2210, 2285, 1410, 1510, 1312, 2700, 2548, 4497]
	| approx positives in sample 512: 203
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 21, 11, 20, 10, 27, 27, 63]
	Time taken saving stuff: 12.31s
episode: 1102/2000 -> reward: -124.99999999998758, steps:89088, time-taken: 4.16min, time-elasped: 3313.82min
-> berries picked: 169 of 800 | patches-visited: [7, 8, 9] | positive-in-buffer: 18423 | amount-filled: 100.00%
	| epsilon: 0.2058202242012559
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2226, 2280, 1397, 1496, 1300, 2695, 2544, 4485]
	| approx positives in sample 512: 242
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 34, 15, 28, 17, 38, 32, 54]
	Time taken saving stuff: 0.14s
episode: 1103/2000 -> reward: -124.99999999998582, steps:83136, time-taken: 3.37min, time-elasped: 3317.19min
-> berries picked: 148 of 800 | patches-visited: [6, 9] | positive-in-buffer: 18491 | amount-filled: 100.00%
	| epsilon: 0.20565466338916463
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2235, 2282, 1406, 1507, 1308, 2705, 2554, 4494]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 17, 20, 19, 16, 37, 28, 50]
	Time taken saving stuff: 0.10s
episode: 1104/2000 -> reward: -124.99999999998919, steps:83328, time-taken: 3.29min, time-elasped: 3320.48min
-> berries picked: 144 of 800 | patches-visited: [0, 9] | positive-in-buffer: 18464 | amount-filled: 100.00%
	| epsilon: 0.20548923575340533
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2225, 2280, 1402, 1509, 1300, 2707, 2561, 4480]
	| approx positives in sample 512: 206
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 29, 13, 16, 17, 31, 23, 43]
	Time taken saving stuff: 12.43s
episode: 1105/2000 -> reward: -124.999999999993, steps:65280, time-taken: 2.27min, time-elasped: 3322.96min
-> berries picked: 72 of 800 | patches-visited: [5] | positive-in-buffer: 18357 | amount-filled: 100.00%
	| epsilon: 0.20532394118685157
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2213, 2276, 1399, 1496, 1296, 2686, 2539, 4452]
	| approx positives in sample 512: 183
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 22, 15, 20, 23, 25, 22, 39]
	Time taken saving stuff: 0.11s
episode: 1106/2000 -> reward: -124.99999999998806, steps:69984, time-taken: 3.13min, time-elasped: 3326.09min
-> berries picked: 86 of 800 | patches-visited: [4, 7] | positive-in-buffer: 18253 | amount-filled: 100.00%
	| epsilon: 0.20515877958246312
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2202, 2267, 1381, 1488, 1286, 2672, 2527, 4430]
	| approx positives in sample 512: 243
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 26, 16, 19, 21, 31, 41, 60]
	Time taken saving stuff: 0.10s
episode: 1107/2000 -> reward: -124.99999999999204, steps:60384, time-taken: 2.22min, time-elasped: 3328.32min
-> berries picked: 48 of 800 | patches-visited: [6] | positive-in-buffer: 18272 | amount-filled: 100.00%
	| epsilon: 0.2049937508332858
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2204, 2273, 1382, 1490, 1291, 2673, 2526, 4433]
	| approx positives in sample 512: 199
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 29, 10, 23, 15, 27, 31, 43]
	Time taken saving stuff: 15.15s
episode: 1108/2000 -> reward: -124.99999999999348, steps:66240, time-taken: 3.13min, time-elasped: 3331.70min
-> berries picked: 71 of 800 | patches-visited: [6] | positive-in-buffer: 18280 | amount-filled: 100.00%
	| epsilon: 0.20482885483245156
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2209, 2272, 1383, 1489, 1288, 2674, 2524, 4441]
	| approx positives in sample 512: 261
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [39, 38, 16, 24, 23, 36, 32, 53]
	Time taken saving stuff: 0.13s
episode: 1109/2000 -> reward: -124.99999999998725, steps:74208, time-taken: 3.21min, time-elasped: 3334.92min
-> berries picked: 103 of 800 | patches-visited: [1, 8] | positive-in-buffer: 18360 | amount-filled: 100.00%
	| epsilon: 0.20466409147317827
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2218, 2278, 1394, 1498, 1298, 2691, 2531, 4452]
	| approx positives in sample 512: 250
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 30, 12, 30, 19, 31, 31, 63]
	Time taken saving stuff: 0.04s
episode: 1110/2000 -> reward: -124.99999999999176, steps:84576, time-taken: 3.45min, time-elasped: 3338.37min
-> berries picked: 153 of 800 | patches-visited: [0, 4] | positive-in-buffer: 18442 | amount-filled: 100.00%
	| epsilon: 0.20449946064876967
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2231, 2282, 1395, 1510, 1305, 2711, 2547, 4461]
	| approx positives in sample 512: 194
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 23, 18, 14, 21, 22, 25, 44]
	Time taken saving stuff: 11.91s
episode: 1111/2000 -> reward: -124.99999999997989, steps:103680, time-taken: 4.33min, time-elasped: 3342.90min
-> berries picked: 215 of 800 | patches-visited: [0, 6, 8, 9] | positive-in-buffer: 18412 | amount-filled: 100.00%
	| epsilon: 0.20433496225261533
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2237, 2273, 1393, 1503, 1314, 2722, 2546, 4424]
	| approx positives in sample 512: 207
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 27, 13, 16, 12, 43, 27, 41]
	Time taken saving stuff: 0.02s
episode: 1112/2000 -> reward: -124.99999999999207, steps:64416, time-taken: 2.33min, time-elasped: 3345.24min
-> berries picked: 61 of 800 | patches-visited: [2] | positive-in-buffer: 18365 | amount-filled: 100.00%
	| epsilon: 0.20417059617819058
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2225, 2274, 1389, 1499, 1311, 2708, 2543, 4416]
	| approx positives in sample 512: 184
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 28, 11, 12, 14, 20, 25, 53]
	Time taken saving stuff: 0.10s
episode: 1113/2000 -> reward: -124.9999999999902, steps:77760, time-taken: 3.45min, time-elasped: 3348.69min
-> berries picked: 118 of 800 | patches-visited: [2, 9] | positive-in-buffer: 18317 | amount-filled: 100.00%
	| epsilon: 0.20400636231905647
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2213, 2266, 1382, 1509, 1315, 2706, 2531, 4395]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 31, 13, 15, 16, 36, 30, 50]
	Time taken saving stuff: 14.77s
episode: 1114/2000 -> reward: -124.9999999999906, steps:86112, time-taken: 3.51min, time-elasped: 3352.44min
-> berries picked: 155 of 800 | patches-visited: [2, 3] | positive-in-buffer: 18386 | amount-filled: 100.00%
	| epsilon: 0.20384226056885965
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2225, 2279, 1382, 1506, 1317, 2718, 2542, 4417]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 42, 17, 17, 12, 32, 28, 36]
	Time taken saving stuff: 0.02s
episode: 1115/2000 -> reward: -124.99999999999186, steps:62304, time-taken: 2.22min, time-elasped: 3354.67min
-> berries picked: 59 of 800 | patches-visited: [4] | positive-in-buffer: 18292 | amount-filled: 100.00%
	| epsilon: 0.20367829082133232
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2221, 2277, 1367, 1476, 1311, 2716, 2535, 4389]
	| approx positives in sample 512: 184
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 19, 11, 17, 19, 36, 24, 40]
	Time taken saving stuff: 0.05s
episode: 1116/2000 -> reward: -124.99999999999203, steps:50688, time-taken: 2.11min, time-elasped: 3356.78min
-> berries picked: 8 of 800 | patches-visited: [8] | positive-in-buffer: 18259 | amount-filled: 100.00%
	| epsilon: 0.20351445297029216
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2215, 2275, 1361, 1463, 1313, 2710, 2534, 4388]
	| approx positives in sample 512: 233
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 28, 13, 22, 20, 33, 34, 57]
	Time taken saving stuff: 11.84s
episode: 1117/2000 -> reward: -124.99999999999525, steps:95712, time-taken: 4.29min, time-elasped: 3361.27min
-> berries picked: 178 of 800 | patches-visited: [1, 4, 5] | positive-in-buffer: 18397 | amount-filled: 100.00%
	| epsilon: 0.20335074690964225
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2224, 2292, 1371, 1478, 1324, 2744, 2552, 4412]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 25, 11, 26, 15, 42, 29, 51]
	Time taken saving stuff: 0.11s
episode: 1118/2000 -> reward: -124.99999999998712, steps:93696, time-taken: 4.41min, time-elasped: 3365.68min
-> berries picked: 174 of 800 | patches-visited: [0, 6, 9] | positive-in-buffer: 18503 | amount-filled: 100.00%
	| epsilon: 0.20318717253337104
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2245, 2301, 1375, 1485, 1330, 2765, 2570, 4432]
	| approx positives in sample 512: 204
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 26, 12, 19, 10, 34, 25, 52]
	Time taken saving stuff: 0.11s
episode: 1119/2000 -> reward: -124.99999999999186, steps:65184, time-taken: 2.42min, time-elasped: 3368.10min
-> berries picked: 76 of 800 | patches-visited: [1] | positive-in-buffer: 18490 | amount-filled: 100.00%
	| epsilon: 0.2030237297355522
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2250, 2295, 1372, 1483, 1331, 2762, 2568, 4429]
	| approx positives in sample 512: 196
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 23, 18, 13, 16, 34, 24, 46]
	Time taken saving stuff: 14.92s
episode: 1120/2000 -> reward: -124.99999999998886, steps:86688, time-taken: 3.29min, time-elasped: 3371.65min
-> berries picked: 150 of 800 | patches-visited: [0, 4] | positive-in-buffer: 18372 | amount-filled: 100.00%
	| epsilon: 0.2028604184103447
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2231, 2283, 1361, 1475, 1327, 2748, 2561, 4386]
	| approx positives in sample 512: 197
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 33, 12, 13, 17, 30, 30, 38]
	Time taken saving stuff: 0.03s
episode: 1121/2000 -> reward: -124.9999999999817, steps:102336, time-taken: 4.54min, time-elasped: 3376.20min
-> berries picked: 217 of 800 | patches-visited: [1, 6, 8] | positive-in-buffer: 18422 | amount-filled: 100.00%
	| epsilon: 0.20269723845199253
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2254, 2286, 1367, 1473, 1331, 2767, 2566, 4378]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [36, 35, 15, 12, 18, 35, 24, 34]
	Time taken saving stuff: 0.03s
episode: 1122/2000 -> reward: -124.99999999998846, steps:85440, time-taken: 3.51min, time-elasped: 3379.71min
-> berries picked: 152 of 800 | patches-visited: [4, 7] | positive-in-buffer: 18486 | amount-filled: 100.00%
	| epsilon: 0.2025341897548249
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2259, 2290, 1376, 1481, 1338, 2778, 2574, 4390]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 27, 22, 21, 19, 38, 23, 40]
	Time taken saving stuff: 11.94s
episode: 1123/2000 -> reward: -124.99999999999203, steps:51168, time-taken: 2.37min, time-elasped: 3382.28min
-> berries picked: 10 of 800 | patches-visited: [2] | positive-in-buffer: 18311 | amount-filled: 100.00%
	| epsilon: 0.20237127221325588
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2244, 2268, 1356, 1461, 1334, 2753, 2554, 4341]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 36, 17, 17, 11, 32, 34, 47]
	Time taken saving stuff: 0.02s
episode: 1124/2000 -> reward: -124.99999999999203, steps:61248, time-taken: 2.30min, time-elasped: 3384.59min
-> berries picked: 54 of 800 | patches-visited: [2] | positive-in-buffer: 18339 | amount-filled: 100.00%
	| epsilon: 0.20220848572178454
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2247, 2268, 1359, 1466, 1337, 2753, 2561, 4348]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 28, 16, 12, 19, 40, 33, 40]
	Time taken saving stuff: 0.01s
episode: 1125/2000 -> reward: -124.99999999999015, steps:56928, time-taken: 2.55min, time-elasped: 3387.14min
-> berries picked: 30 of 800 | patches-visited: [7] | positive-in-buffer: 18298 | amount-filled: 100.00%
	| epsilon: 0.20204583017499478
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2243, 2263, 1359, 1460, 1333, 2748, 2552, 4340]
	| approx positives in sample 512: 204
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 20, 9, 11, 16, 30, 32, 57]
	Time taken saving stuff: 14.94s
episode: 1126/2000 -> reward: -124.99999999999142, steps:98016, time-taken: 4.39min, time-elasped: 3391.78min
-> berries picked: 178 of 800 | patches-visited: [0, 4, 5, 9] | positive-in-buffer: 18424 | amount-filled: 100.00%
	| epsilon: 0.20188330546755537
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2259, 2281, 1372, 1472, 1347, 2764, 2570, 4359]
	| approx positives in sample 512: 240
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 28, 16, 22, 14, 37, 37, 51]
	Time taken saving stuff: 0.10s
episode: 1127/2000 -> reward: -124.99999999999199, steps:62784, time-taken: 2.36min, time-elasped: 3394.15min
-> berries picked: 59 of 800 | patches-visited: [3] | positive-in-buffer: 18410 | amount-filled: 100.00%
	| epsilon: 0.20172091149421972
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2259, 2279, 1376, 1471, 1352, 2760, 2563, 4350]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 30, 18, 16, 15, 35, 31, 53]
	Time taken saving stuff: 0.03s
episode: 1128/2000 -> reward: -124.99999999999535, steps:82080, time-taken: 3.28min, time-elasped: 3397.43min
-> berries picked: 145 of 800 | patches-visited: [5, 7] | positive-in-buffer: 18345 | amount-filled: 100.00%
	| epsilon: 0.20155864814982594
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2252, 2278, 1363, 1462, 1354, 2749, 2568, 4319]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 31, 18, 14, 20, 31, 29, 49]
	Time taken saving stuff: 12.84s
episode: 1129/2000 -> reward: -124.99999999999218, steps:58848, time-taken: 2.05min, time-elasped: 3399.70min
-> berries picked: 45 of 800 | patches-visited: [6] | positive-in-buffer: 18329 | amount-filled: 100.00%
	| epsilon: 0.20139651532929675
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2252, 2276, 1362, 1466, 1351, 2744, 2561, 4317]
	| approx positives in sample 512: 199
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 26, 14, 19, 13, 25, 33, 51]
	Time taken saving stuff: 0.02s
episode: 1130/2000 -> reward: -124.99999999998255, steps:79584, time-taken: 3.41min, time-elasped: 3403.12min
-> berries picked: 127 of 800 | patches-visited: [2, 8] | positive-in-buffer: 18388 | amount-filled: 100.00%
	| epsilon: 0.20123451292763936
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2259, 2287, 1369, 1473, 1358, 2755, 2560, 4327]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 28, 19, 9, 13, 36, 40, 38]
	Time taken saving stuff: 0.02s
episode: 1131/2000 -> reward: -124.99999999999197, steps:62688, time-taken: 2.32min, time-elasped: 3405.43min
-> berries picked: 50 of 800 | patches-visited: [5] | positive-in-buffer: 18362 | amount-filled: 100.00%
	| epsilon: 0.20107264083994542
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2254, 2284, 1368, 1478, 1357, 2751, 2551, 4319]
	| approx positives in sample 512: 204
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 30, 17, 8, 16, 39, 27, 43]
	Time taken saving stuff: 15.29s
episode: 1132/2000 -> reward: -124.99999999999203, steps:59424, time-taken: 2.13min, time-elasped: 3407.82min
-> berries picked: 44 of 800 | patches-visited: [4] | positive-in-buffer: 18246 | amount-filled: 100.00%
	| epsilon: 0.20091089896139103
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2246, 2262, 1355, 1471, 1348, 2734, 2535, 4295]
	| approx positives in sample 512: 202
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 27, 12, 17, 20, 30, 33, 44]
	Time taken saving stuff: 0.09s
episode: 1133/2000 -> reward: -124.99999999998857, steps:100512, time-taken: 5.21min, time-elasped: 3413.03min
-> berries picked: 199 of 800 | patches-visited: [1, 6, 8] | positive-in-buffer: 18371 | amount-filled: 100.00%
	| epsilon: 0.20074928718723659
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2261, 2276, 1364, 1480, 1359, 2748, 2554, 4329]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 27, 19, 15, 18, 35, 21, 49]
	Time taken saving stuff: 0.08s
episode: 1134/2000 -> reward: -124.99999999999545, steps:83712, time-taken: 3.22min, time-elasped: 3416.25min
-> berries picked: 138 of 800 | patches-visited: [1, 4] | positive-in-buffer: 18416 | amount-filled: 100.00%
	| epsilon: 0.2005878054128267
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2263, 2273, 1372, 1490, 1366, 2760, 2558, 4334]
	| approx positives in sample 512: 202
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 27, 18, 15, 14, 39, 32, 38]
	Time taken saving stuff: 11.86s
episode: 1135/2000 -> reward: -124.99999999998838, steps:85344, time-taken: 3.61min, time-elasped: 3420.06min
-> berries picked: 141 of 800 | patches-visited: [4, 8, 9] | positive-in-buffer: 18297 | amount-filled: 100.00%
	| epsilon: 0.2004264535335902
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2247, 2261, 1359, 1492, 1368, 2745, 2539, 4286]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 33, 9, 16, 19, 36, 34, 47]
	Time taken saving stuff: 0.02s
episode: 1136/2000 -> reward: -124.9999999999873, steps:101472, time-taken: 4.30min, time-elasped: 3424.37min
-> berries picked: 223 of 800 | patches-visited: [0, 1, 3] | positive-in-buffer: 18379 | amount-filled: 100.00%
	| epsilon: 0.20026523144504002
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2256, 2267, 1370, 1497, 1379, 2751, 2555, 4304]
	| approx positives in sample 512: 194
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 17, 16, 14, 11, 44, 23, 45]
	Time taken saving stuff: 0.10s
episode: 1137/2000 -> reward: -124.9999999999919, steps:61152, time-taken: 3.54min, time-elasped: 3427.91min
-> berries picked: 43 of 800 | patches-visited: [2] | positive-in-buffer: 18346 | amount-filled: 100.00%
	| epsilon: 0.20010413904277316
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2250, 2267, 1368, 1498, 1378, 2744, 2542, 4299]
	| approx positives in sample 512: 198
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 27, 15, 24, 10, 33, 24, 48]
	Time taken saving stuff: 15.94s
episode: 1138/2000 -> reward: -124.99999999999203, steps:56832, time-taken: 3.59min, time-elasped: 3431.78min
-> berries picked: 34 of 800 | patches-visited: [9] | positive-in-buffer: 18282 | amount-filled: 100.00%
	| epsilon: 0.19994317622247057
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2244, 2260, 1369, 1491, 1377, 2732, 2533, 4276]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 27, 14, 19, 22, 35, 34, 47]
	Time taken saving stuff: 0.01s
episode: 1139/2000 -> reward: -124.99999999998664, steps:85152, time-taken: 3.79min, time-elasped: 3435.57min
-> berries picked: 150 of 800 | patches-visited: [1, 8] | positive-in-buffer: 18387 | amount-filled: 100.00%
	| epsilon: 0.19978234287989716
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2261, 2271, 1384, 1503, 1387, 2745, 2544, 4292]
	| approx positives in sample 512: 211
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 29, 14, 17, 22, 37, 18, 43]
	Time taken saving stuff: 0.01s
episode: 1140/2000 -> reward: -124.99999999999062, steps:70560, time-taken: 3.32min, time-elasped: 3438.90min
-> berries picked: 87 of 800 | patches-visited: [1, 9] | positive-in-buffer: 18256 | amount-filled: 100.00%
	| epsilon: 0.19962163891090165
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2247, 2259, 1370, 1483, 1382, 2741, 2528, 4246]
	| approx positives in sample 512: 226
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 40, 15, 23, 15, 30, 28, 48]
	Time taken saving stuff: 12.28s
episode: 1141/2000 -> reward: -124.9999999999916, steps:67392, time-taken: 3.13min, time-elasped: 3442.23min
-> berries picked: 72 of 800 | patches-visited: [6] | positive-in-buffer: 18293 | amount-filled: 100.00%
	| epsilon: 0.19946106421141652
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2248, 2259, 1373, 1490, 1390, 2746, 2533, 4254]
	| approx positives in sample 512: 226
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 33, 11, 12, 19, 35, 31, 54]
	Time taken saving stuff: 0.06s
episode: 1142/2000 -> reward: -124.99999999998171, steps:79872, time-taken: 3.38min, time-elasped: 3445.61min
-> berries picked: 121 of 800 | patches-visited: [2, 8] | positive-in-buffer: 18347 | amount-filled: 100.00%
	| epsilon: 0.19930061867745802
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2256, 2264, 1383, 1496, 1397, 2752, 2535, 4264]
	| approx positives in sample 512: 196
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 20, 9, 19, 19, 31, 29, 40]
	Time taken saving stuff: 0.02s
episode: 1143/2000 -> reward: -124.99999999999126, steps:96192, time-taken: 4.43min, time-elasped: 3450.04min
-> berries picked: 186 of 800 | patches-visited: [2, 3, 5] | positive-in-buffer: 18353 | amount-filled: 100.00%
	| epsilon: 0.19914030220512602
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2254, 2257, 1391, 1497, 1405, 2753, 2539, 4257]
	| approx positives in sample 512: 210
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 28, 15, 18, 12, 37, 28, 42]
	Time taken saving stuff: 11.80s
episode: 1144/2000 -> reward: -124.99999999998316, steps:74304, time-taken: 3.30min, time-elasped: 3453.54min
-> berries picked: 99 of 800 | patches-visited: [3, 7] | positive-in-buffer: 18402 | amount-filled: 100.00%
	| epsilon: 0.1989801146906039
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2259, 2263, 1395, 1501, 1414, 2761, 2540, 4269]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 30, 11, 21, 11, 37, 27, 58]
	Time taken saving stuff: 0.09s
episode: 1145/2000 -> reward: -124.9999999999885, steps:101568, time-taken: 4.45min, time-elasped: 3457.99min
-> berries picked: 213 of 800 | patches-visited: [2, 3, 5] | positive-in-buffer: 18476 | amount-filled: 100.00%
	| epsilon: 0.19882005603015868
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2271, 2270, 1397, 1522, 1414, 2777, 2551, 4274]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 21, 12, 21, 22, 23, 40, 56]
	Time taken saving stuff: 0.10s
episode: 1146/2000 -> reward: -124.99999999998747, steps:99264, time-taken: 4.55min, time-elasped: 3462.55min
-> berries picked: 208 of 800 | patches-visited: [3, 6, 8] | positive-in-buffer: 18436 | amount-filled: 100.00%
	| epsilon: 0.19866012612014072
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2273, 2262, 1407, 1515, 1411, 2782, 2543, 4243]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [37, 23, 21, 9, 15, 41, 23, 49]
	Time taken saving stuff: 12.55s
episode: 1147/2000 -> reward: -124.9999999999849, steps:80448, time-taken: 4.03min, time-elasped: 3466.78min
-> berries picked: 130 of 800 | patches-visited: [5, 9] | positive-in-buffer: 18436 | amount-filled: 100.00%
	| epsilon: 0.1985003248569838
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2269, 2268, 1418, 1513, 1405, 2785, 2549, 4229]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 26, 16, 18, 15, 35, 29, 49]
	Time taken saving stuff: 0.01s
episode: 1148/2000 -> reward: -124.99999999999653, steps:99840, time-taken: 4.76min, time-elasped: 3471.55min
-> berries picked: 203 of 800 | patches-visited: [2, 5, 6] | positive-in-buffer: 18444 | amount-filled: 100.00%
	| epsilon: 0.19834065213720498
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2272, 2271, 1434, 1513, 1402, 2784, 2541, 4227]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 27, 17, 10, 12, 22, 26, 63]
	Time taken saving stuff: 0.03s
episode: 1149/2000 -> reward: -124.99999999999214, steps:67872, time-taken: 3.15min, time-elasped: 3474.70min
-> berries picked: 77 of 800 | patches-visited: [8] | positive-in-buffer: 18394 | amount-filled: 100.00%
	| epsilon: 0.1981811078574046
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2269, 2273, 1430, 1511, 1403, 2778, 2525, 4205]
	| approx positives in sample 512: 248
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 30, 13, 13, 15, 35, 37, 73]
	Time taken saving stuff: 12.35s
episode: 1150/2000 -> reward: -124.9999999999922, steps:71520, time-taken: 3.55min, time-elasped: 3478.46min
-> berries picked: 90 of 800 | patches-visited: [3, 6] | positive-in-buffer: 18412 | amount-filled: 100.00%
	| epsilon: 0.1980216919142661
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2266, 2277, 1431, 1516, 1405, 2779, 2527, 4211]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 28, 17, 30, 18, 28, 35, 49]
	Time taken saving stuff: 0.01s
episode: 1151/2000 -> reward: -124.9999999999959, steps:94560, time-taken: 5.09min, time-elasped: 3483.54min
-> berries picked: 191 of 800 | patches-visited: [0, 1, 3] | positive-in-buffer: 18452 | amount-filled: 100.00%
	| epsilon: 0.1978624042045561
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2273, 2270, 1442, 1522, 1413, 2786, 2532, 4214]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 23, 15, 21, 19, 34, 34, 63]
	Time taken saving stuff: 0.01s
episode: 1152/2000 -> reward: -124.99999999999206, steps:55200, time-taken: 2.27min, time-elasped: 3485.82min
-> berries picked: 23 of 800 | patches-visited: [0] | positive-in-buffer: 18414 | amount-filled: 100.00%
	| epsilon: 0.1977032446251243
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2265, 2266, 1439, 1525, 1412, 2780, 2527, 4200]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 29, 20, 17, 18, 30, 34, 45]
	Time taken saving stuff: 13.39s
episode: 1153/2000 -> reward: -124.99999999999581, steps:79968, time-taken: 3.48min, time-elasped: 3489.53min
-> berries picked: 129 of 800 | patches-visited: [0, 1] | positive-in-buffer: 18448 | amount-filled: 100.00%
	| epsilon: 0.19754421307290326
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2273, 2270, 1440, 1535, 1418, 2791, 2527, 4194]
	| approx positives in sample 512: 210
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 27, 14, 15, 9, 41, 26, 55]
	Time taken saving stuff: 0.01s
episode: 1154/2000 -> reward: -124.9999999999921, steps:63456, time-taken: 2.42min, time-elasped: 3491.95min
-> berries picked: 65 of 800 | patches-visited: [6] | positive-in-buffer: 18386 | amount-filled: 100.00%
	| epsilon: 0.19738530944490848
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2267, 2259, 1432, 1535, 1410, 2792, 2520, 4171]
	| approx positives in sample 512: 199
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 20, 16, 22, 16, 32, 25, 43]
	Time taken saving stuff: 0.03s
episode: 1155/2000 -> reward: -124.9999999999919, steps:57312, time-taken: 2.46min, time-elasped: 3494.42min
-> berries picked: 33 of 800 | patches-visited: [4] | positive-in-buffer: 18275 | amount-filled: 100.00%
	| epsilon: 0.19722653363823833
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2255, 2239, 1427, 1528, 1406, 2777, 2501, 4142]
	| approx positives in sample 512: 198
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 17, 19, 22, 15, 30, 29, 42]
	Time taken saving stuff: 12.05s
episode: 1156/2000 -> reward: -124.99999999997895, steps:98976, time-taken: 5.55min, time-elasped: 3500.17min
-> berries picked: 202 of 800 | patches-visited: [1, 2, 5] | positive-in-buffer: 18431 | amount-filled: 100.00%
	| epsilon: 0.19706788555007396
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2269, 2263, 1443, 1546, 1423, 2803, 2514, 4170]
	| approx positives in sample 512: 243
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 31, 20, 22, 27, 39, 28, 42]
	Time taken saving stuff: 0.01s
episode: 1157/2000 -> reward: -124.9999999999921, steps:61344, time-taken: 2.50min, time-elasped: 3502.67min
-> berries picked: 55 of 800 | patches-visited: [8] | positive-in-buffer: 18433 | amount-filled: 100.00%
	| epsilon: 0.1969093650776792
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2270, 2263, 1443, 1548, 1423, 2805, 2512, 4169]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 24, 13, 18, 19, 26, 33, 54]
	Time taken saving stuff: 0.02s
episode: 1158/2000 -> reward: -124.99999999999199, steps:99744, time-taken: 4.65min, time-elasped: 3507.32min
-> berries picked: 197 of 800 | patches-visited: [3, 4, 9] | positive-in-buffer: 18491 | amount-filled: 100.00%
	| epsilon: 0.19675097211840054
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2280, 2273, 1453, 1555, 1430, 2816, 2522, 4162]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 31, 18, 20, 18, 29, 31, 48]
	Time taken saving stuff: 15.37s
episode: 1159/2000 -> reward: -124.9999999999913, steps:83616, time-taken: 3.77min, time-elasped: 3511.35min
-> berries picked: 138 of 800 | patches-visited: [0, 5] | positive-in-buffer: 18546 | amount-filled: 100.00%
	| epsilon: 0.19659270656966704
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2282, 2280, 1458, 1565, 1436, 2827, 2533, 4165]
	| approx positives in sample 512: 193
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 26, 17, 20, 16, 20, 23, 46]
	Time taken saving stuff: 0.01s
episode: 1160/2000 -> reward: -124.99999999999528, steps:82464, time-taken: 3.57min, time-elasped: 3514.92min
-> berries picked: 139 of 800 | patches-visited: [2, 7] | positive-in-buffer: 18433 | amount-filled: 100.00%
	| epsilon: 0.19643456832899023
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2264, 2262, 1450, 1557, 1437, 2817, 2525, 4121]
	| approx positives in sample 512: 203
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 33, 13, 19, 17, 26, 27, 38]
	Time taken saving stuff: 0.09s
episode: 1161/2000 -> reward: -124.99999999999483, steps:80832, time-taken: 3.24min, time-elasped: 3518.16min
-> berries picked: 143 of 800 | patches-visited: [4, 8] | positive-in-buffer: 18458 | amount-filled: 100.00%
	| epsilon: 0.19627655729396415
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2270, 2265, 1463, 1565, 1439, 2820, 2518, 4118]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 26, 16, 18, 13, 34, 35, 48]
	Time taken saving stuff: 15.56s
episode: 1162/2000 -> reward: -124.99999999999201, steps:64608, time-taken: 2.62min, time-elasped: 3521.04min
-> berries picked: 56 of 800 | patches-visited: [7, 8] | positive-in-buffer: 18429 | amount-filled: 100.00%
	| epsilon: 0.1961186733622651
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2260, 2258, 1462, 1563, 1431, 2824, 2514, 4117]
	| approx positives in sample 512: 206
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 35, 14, 17, 18, 29, 21, 46]
	Time taken saving stuff: 0.02s
episode: 1163/2000 -> reward: -124.99999999999564, steps:86304, time-taken: 3.46min, time-elasped: 3524.50min
-> berries picked: 155 of 800 | patches-visited: [4, 9] | positive-in-buffer: 18440 | amount-filled: 100.00%
	| epsilon: 0.1959609164316519
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2260, 2260, 1464, 1571, 1441, 2826, 2506, 4112]
	| approx positives in sample 512: 196
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 16, 23, 14, 16, 21, 32, 48]
	Time taken saving stuff: 0.01s
episode: 1164/2000 -> reward: -124.99999999998631, steps:105504, time-taken: 4.33min, time-elasped: 3528.84min
-> berries picked: 227 of 800 | patches-visited: [2, 4, 5] | positive-in-buffer: 18481 | amount-filled: 100.00%
	| epsilon: 0.19580328639996536
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2267, 2267, 1467, 1593, 1436, 2825, 2510, 4116]
	| approx positives in sample 512: 202
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 27, 13, 19, 24, 40, 20, 41]
	Time taken saving stuff: 14.92s
episode: 1165/2000 -> reward: -124.99999999999099, steps:85344, time-taken: 3.42min, time-elasped: 3532.52min
-> berries picked: 148 of 800 | patches-visited: [4, 5] | positive-in-buffer: 18513 | amount-filled: 100.00%
	| epsilon: 0.19564578316512865
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2272, 2272, 1476, 1598, 1446, 2825, 2504, 4120]
	| approx positives in sample 512: 197
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 22, 20, 20, 11, 25, 22, 48]
	Time taken saving stuff: 0.01s
episode: 1166/2000 -> reward: -124.99999999999216, steps:67296, time-taken: 3.01min, time-elasped: 3535.53min
-> berries picked: 77 of 800 | patches-visited: [8] | positive-in-buffer: 18441 | amount-filled: 100.00%
	| epsilon: 0.19548840662514697
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2258, 2274, 1475, 1600, 1441, 2808, 2495, 4090]
	| approx positives in sample 512: 263
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [39, 39, 19, 27, 19, 42, 26, 52]
	Time taken saving stuff: 0.10s
episode: 1167/2000 -> reward: -124.99999999999527, steps:73824, time-taken: 3.65min, time-elasped: 3539.18min
-> berries picked: 97 of 800 | patches-visited: [2, 4] | positive-in-buffer: 18500 | amount-filled: 100.00%
	| epsilon: 0.19533115667810758
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2264, 2277, 1483, 1606, 1448, 2818, 2502, 4102]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 21, 10, 28, 21, 25, 39, 44]
	Time taken saving stuff: 15.17s
episode: 1168/2000 -> reward: -124.99999999999082, steps:80064, time-taken: 3.39min, time-elasped: 3542.82min
-> berries picked: 131 of 800 | patches-visited: [2, 7] | positive-in-buffer: 18579 | amount-filled: 100.00%
	| epsilon: 0.19517403322217966
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2269, 2290, 1485, 1616, 1454, 2835, 2509, 4121]
	| approx positives in sample 512: 204
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 30, 19, 14, 18, 31, 25, 41]
	Time taken saving stuff: 0.10s
episode: 1169/2000 -> reward: -124.99999999998407, steps:85632, time-taken: 3.31min, time-elasped: 3546.13min
-> berries picked: 147 of 800 | patches-visited: [3, 4] | positive-in-buffer: 18597 | amount-filled: 100.00%
	| epsilon: 0.19501703615561447
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2277, 2286, 1491, 1627, 1461, 2830, 2510, 4115]
	| approx positives in sample 512: 188
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 28, 8, 25, 11, 22, 33, 34]
	Time taken saving stuff: 0.01s
episode: 1170/2000 -> reward: -124.99999999999503, steps:84288, time-taken: 3.50min, time-elasped: 3549.64min
-> berries picked: 143 of 800 | patches-visited: [6, 8] | positive-in-buffer: 18530 | amount-filled: 100.00%
	| epsilon: 0.19486016537674494
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2277, 2275, 1492, 1627, 1458, 2826, 2499, 4076]
	| approx positives in sample 512: 203
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 32, 9, 15, 15, 37, 25, 44]
	Time taken saving stuff: 16.14s
episode: 1171/2000 -> reward: -124.99999999998327, steps:82848, time-taken: 3.67min, time-elasped: 3553.58min
-> berries picked: 138 of 800 | patches-visited: [2, 4] | positive-in-buffer: 18531 | amount-filled: 100.00%
	| epsilon: 0.19470342078398584
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2281, 2279, 1496, 1629, 1460, 2825, 2498, 4063]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 22, 19, 17, 17, 20, 35, 49]
	Time taken saving stuff: 0.01s
episode: 1172/2000 -> reward: -124.99999999999412, steps:84288, time-taken: 5.07min, time-elasped: 3558.65min
-> berries picked: 154 of 800 | patches-visited: [2, 3] | positive-in-buffer: 18580 | amount-filled: 100.00%
	| epsilon: 0.1945468022758337
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2287, 2287, 1509, 1636, 1463, 2835, 2501, 4062]
	| approx positives in sample 512: 196
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 23, 16, 20, 17, 27, 24, 38]
	Time taken saving stuff: 0.03s
episode: 1173/2000 -> reward: -124.99999999998926, steps:77952, time-taken: 6.24min, time-elasped: 3564.89min
-> berries picked: 117 of 800 | patches-visited: [0, 9] | positive-in-buffer: 18535 | amount-filled: 100.00%
	| epsilon: 0.19439030975086663
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2293, 2284, 1511, 1643, 1464, 2829, 2481, 4030]
	| approx positives in sample 512: 230
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 23, 18, 18, 24, 36, 34, 46]
	Time taken saving stuff: 15.52s
episode: 1174/2000 -> reward: -124.9999999999921, steps:63744, time-taken: 4.03min, time-elasped: 3569.18min
-> berries picked: 58 of 800 | patches-visited: [1] | positive-in-buffer: 18557 | amount-filled: 100.00%
	| epsilon: 0.19423394310774436
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2294, 2287, 1517, 1648, 1464, 2831, 2484, 4032]
	| approx positives in sample 512: 186
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 19, 14, 23, 20, 29, 26, 34]
	Time taken saving stuff: 0.11s
episode: 1175/2000 -> reward: -124.99999999998172, steps:82656, time-taken: 6.37min, time-elasped: 3575.56min
-> berries picked: 131 of 800 | patches-visited: [1, 3] | positive-in-buffer: 18502 | amount-filled: 100.00%
	| epsilon: 0.1940777022452081
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2286, 2281, 1523, 1647, 1477, 2832, 2468, 3988]
	| approx positives in sample 512: 206
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 24, 16, 21, 20, 32, 30, 37]
	Time taken saving stuff: 0.01s
episode: 1176/2000 -> reward: -124.9999999999916, steps:82080, time-taken: 6.11min, time-elasped: 3581.68min
-> berries picked: 140 of 800 | patches-visited: [5, 6] | positive-in-buffer: 18573 | amount-filled: 100.00%
	| epsilon: 0.1939215870620806
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2300, 2295, 1523, 1663, 1482, 2841, 2472, 3997]
	| approx positives in sample 512: 206
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 23, 16, 18, 18, 30, 30, 49]
	Time taken saving stuff: 12.26s
episode: 1177/2000 -> reward: -124.99999999999184, steps:66528, time-taken: 6.37min, time-elasped: 3588.26min
-> berries picked: 77 of 800 | patches-visited: [2] | positive-in-buffer: 18520 | amount-filled: 100.00%
	| epsilon: 0.1937655974572659
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2290, 2288, 1524, 1662, 1477, 2830, 2467, 3982]
	| approx positives in sample 512: 245
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 28, 19, 23, 19, 39, 43, 45]
	Time taken saving stuff: 0.00s
episode: 1178/2000 -> reward: -124.99999999999267, steps:87552, time-taken: 6.20min, time-elasped: 3594.46min
-> berries picked: 152 of 800 | patches-visited: [2, 4, 9] | positive-in-buffer: 18637 | amount-filled: 100.00%
	| epsilon: 0.19360973332974946
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2302, 2301, 1539, 1674, 1482, 2855, 2479, 4005]
	| approx positives in sample 512: 210
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 38, 17, 22, 19, 23, 25, 36]
	Time taken saving stuff: 0.11s
episode: 1179/2000 -> reward: -124.99999999999184, steps:65760, time-taken: 4.15min, time-elasped: 3598.61min
-> berries picked: 70 of 800 | patches-visited: [2] | positive-in-buffer: 18526 | amount-filled: 100.00%
	| epsilon: 0.19345399457859785
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2281, 2294, 1534, 1664, 1477, 2838, 2478, 3960]
	| approx positives in sample 512: 181
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 25, 9, 18, 15, 30, 17, 42]
	Time taken saving stuff: 15.71s
episode: 1180/2000 -> reward: -124.99999999999214, steps:67200, time-taken: 5.66min, time-elasped: 3604.54min
-> berries picked: 76 of 800 | patches-visited: [8] | positive-in-buffer: 18484 | amount-filled: 100.00%
	| epsilon: 0.193298381102959
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2279, 2282, 1535, 1665, 1471, 2832, 2472, 3948]
	| approx positives in sample 512: 254
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 40, 18, 21, 21, 35, 34, 52]
	Time taken saving stuff: 0.02s
episode: 1181/2000 -> reward: -124.99999999999143, steps:65664, time-taken: 4.07min, time-elasped: 3608.62min
-> berries picked: 78 of 800 | patches-visited: [3] | positive-in-buffer: 18527 | amount-filled: 100.00%
	| epsilon: 0.1931428928020618
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2285, 2288, 1541, 1670, 1476, 2836, 2477, 3954]
	| approx positives in sample 512: 192
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 21, 13, 21, 10, 30, 25, 43]
	Time taken saving stuff: 0.01s
episode: 1182/2000 -> reward: -124.9999999999927, steps:65856, time-taken: 3.78min, time-elasped: 3612.40min
-> berries picked: 71 of 800 | patches-visited: [0] | positive-in-buffer: 18488 | amount-filled: 100.00%
	| epsilon: 0.1929875295752163
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2283, 2283, 1535, 1672, 1480, 2829, 2473, 3933]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 29, 20, 20, 15, 25, 30, 38]
	Time taken saving stuff: 12.71s
episode: 1183/2000 -> reward: -124.99999999999203, steps:50880, time-taken: 4.22min, time-elasped: 3616.84min
-> berries picked: 9 of 800 | patches-visited: [5] | positive-in-buffer: 18445 | amount-filled: 100.00%
	| epsilon: 0.1928322913218136
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2276, 2275, 1536, 1669, 1478, 2824, 2466, 3921]
	| approx positives in sample 512: 230
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 27, 19, 24, 20, 35, 31, 46]
	Time taken saving stuff: 0.01s
episode: 1184/2000 -> reward: -124.9999999999918, steps:81408, time-taken: 5.66min, time-elasped: 3622.50min
-> berries picked: 144 of 800 | patches-visited: [3, 8] | positive-in-buffer: 18548 | amount-filled: 100.00%
	| epsilon: 0.1926771779413256
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2286, 2287, 1544, 1683, 1486, 2844, 2474, 3944]
	| approx positives in sample 512: 186
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 29, 14, 15, 16, 35, 29, 29]
	Time taken saving stuff: 0.08s
episode: 1185/2000 -> reward: -124.99999999999058, steps:85152, time-taken: 6.28min, time-elasped: 3628.79min
-> berries picked: 157 of 800 | patches-visited: [1, 5] | positive-in-buffer: 18621 | amount-filled: 100.00%
	| epsilon: 0.19252218933330512
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2298, 2295, 1554, 1688, 1497, 2855, 2478, 3956]
	| approx positives in sample 512: 203
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 29, 23, 11, 10, 33, 26, 47]
	Time taken saving stuff: 15.23s
episode: 1186/2000 -> reward: -124.99999999999207, steps:58272, time-taken: 3.19min, time-elasped: 3632.24min
-> berries picked: 34 of 800 | patches-visited: [8] | positive-in-buffer: 18542 | amount-filled: 100.00%
	| epsilon: 0.19236732539738577
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2287, 2289, 1550, 1683, 1488, 2836, 2473, 3936]
	| approx positives in sample 512: 208
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 24, 15, 16, 18, 47, 37, 34]
	Time taken saving stuff: 0.03s
episode: 1187/2000 -> reward: -124.99999999997974, steps:117408, time-taken: 6.81min, time-elasped: 3639.05min
-> berries picked: 273 of 800 | patches-visited: [4, 5, 7, 8] | positive-in-buffer: 18720 | amount-filled: 100.00%
	| epsilon: 0.1922125860332819
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2302, 2308, 1562, 1706, 1501, 2867, 2494, 3980]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 29, 22, 26, 29, 25, 24, 56]
	Time taken saving stuff: 0.01s
episode: 1188/2000 -> reward: -118.49999999997895, steps:120000, time-taken: 6.40min, time-elasped: 3645.45min
-> berries picked: 306 of 800 | patches-visited: [3, 4, 7, 8] | positive-in-buffer: 18880 | amount-filled: 100.00%
	| epsilon: 0.19205797114078857
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2326, 2319, 1576, 1720, 1514, 2902, 2504, 4019]
	| approx positives in sample 512: 201
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 28, 22, 18, 7, 36, 24, 44]
	Time taken saving stuff: 11.93s
episode: 1189/2000 -> reward: -124.99999999999204, steps:62208, time-taken: 3.33min, time-elasped: 3648.98min
-> berries picked: 63 of 800 | patches-visited: [4] | positive-in-buffer: 18780 | amount-filled: 100.00%
	| epsilon: 0.19190348061978138
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2311, 2306, 1569, 1715, 1500, 2878, 2499, 4002]
	| approx positives in sample 512: 190
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 18, 9, 21, 16, 35, 29, 39]
	Time taken saving stuff: 0.01s
episode: 1190/2000 -> reward: -124.99999999999294, steps:85248, time-taken: 4.23min, time-elasped: 3653.21min
-> berries picked: 152 of 800 | patches-visited: [4, 7] | positive-in-buffer: 18703 | amount-filled: 100.00%
	| epsilon: 0.1917491143702165
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2312, 2297, 1570, 1713, 1506, 2875, 2481, 3949]
	| approx positives in sample 512: 205
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 25, 16, 15, 17, 35, 34, 41]
	Time taken saving stuff: 0.11s
episode: 1191/2000 -> reward: -124.99999999999196, steps:66816, time-taken: 5.87min, time-elasped: 3659.09min
-> berries picked: 71 of 800 | patches-visited: [2] | positive-in-buffer: 18609 | amount-filled: 100.00%
	| epsilon: 0.19159487229213057
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2297, 2285, 1568, 1713, 1504, 2851, 2471, 3920]
	| approx positives in sample 512: 245
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 30, 20, 33, 19, 26, 40, 50]
	Time taken saving stuff: 15.56s
episode: 1192/2000 -> reward: -124.99999999999059, steps:82368, time-taken: 5.18min, time-elasped: 3664.53min
-> berries picked: 134 of 800 | patches-visited: [7, 9] | positive-in-buffer: 18690 | amount-filled: 100.00%
	| epsilon: 0.19144075428564067
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2307, 2296, 1577, 1723, 1510, 2864, 2483, 3930]
	| approx positives in sample 512: 211
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 27, 21, 16, 10, 29, 30, 49]
	Time taken saving stuff: 0.02s
episode: 1193/2000 -> reward: -124.99999999999251, steps:84864, time-taken: 6.31min, time-elasped: 3670.84min
-> berries picked: 151 of 800 | patches-visited: [0, 9] | positive-in-buffer: 18683 | amount-filled: 100.00%
	| epsilon: 0.19128676025094413
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2306, 2305, 1585, 1725, 1504, 2859, 2477, 3922]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 33, 22, 20, 16, 28, 29, 47]
	Time taken saving stuff: 0.01s
episode: 1194/2000 -> reward: -124.99999999999126, steps:79680, time-taken: 5.83min, time-elasped: 3676.67min
-> berries picked: 131 of 800 | patches-visited: [1, 8] | positive-in-buffer: 18671 | amount-filled: 100.00%
	| epsilon: 0.19113289008831869
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2314, 2308, 1584, 1730, 1496, 2850, 2469, 3920]
	| approx positives in sample 512: 207
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 21, 25, 22, 25, 27, 28, 37]
	Time taken saving stuff: 14.32s
episode: 1195/2000 -> reward: -124.99999999999206, steps:66432, time-taken: 5.43min, time-elasped: 3682.35min
-> berries picked: 73 of 800 | patches-visited: [8] | positive-in-buffer: 18699 | amount-filled: 100.00%
	| epsilon: 0.19097914369812222
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2316, 2309, 1588, 1732, 1501, 2855, 2475, 3923]
	| approx positives in sample 512: 246
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 32, 19, 27, 17, 45, 31, 46]
	Time taken saving stuff: 0.01s
episode: 1196/2000 -> reward: -122.74999999998923, steps:120000, time-taken: 10.13min, time-elasped: 3692.48min
-> berries picked: 279 of 800 | patches-visited: [3, 4, 8, 9] | positive-in-buffer: 18858 | amount-filled: 100.00%
	| epsilon: 0.19082552098079278
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2339, 2336, 1606, 1740, 1509, 2886, 2493, 3949]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 26, 16, 24, 15, 35, 29, 55]
	Time taken saving stuff: 0.02s
episode: 1197/2000 -> reward: -124.99999999999675, steps:105888, time-taken: 8.40min, time-elasped: 3700.88min
-> berries picked: 232 of 800 | patches-visited: [1, 2, 3, 4] | positive-in-buffer: 18928 | amount-filled: 100.00%
	| epsilon: 0.19067202183684848
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2335, 2336, 1622, 1754, 1512, 2907, 2499, 3963]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 39, 18, 20, 19, 41, 43, 35]
	Time taken saving stuff: 13.03s
episode: 1198/2000 -> reward: -124.99999999999372, steps:84000, time-taken: 6.33min, time-elasped: 3707.43min
-> berries picked: 137 of 800 | patches-visited: [4, 7] | positive-in-buffer: 18780 | amount-filled: 100.00%
	| epsilon: 0.19051864616688746
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2312, 2321, 1618, 1742, 1511, 2900, 2484, 3892]
	| approx positives in sample 512: 201
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 26, 17, 14, 14, 35, 32, 32]
	Time taken saving stuff: 0.03s
episode: 1199/2000 -> reward: -124.9999999999786, steps:102720, time-taken: 6.39min, time-elasped: 3713.82min
-> berries picked: 224 of 800 | patches-visited: [0, 3, 8] | positive-in-buffer: 18851 | amount-filled: 100.00%
	| epsilon: 0.19036539387158788
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2325, 2332, 1638, 1751, 1511, 2911, 2495, 3888]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 23, 9, 32, 19, 30, 37, 45]
	Time taken saving stuff: 0.01s
episode: 1200/2000 -> reward: -124.99999999999163, steps:64800, time-taken: 2.34min, time-elasped: 3716.17min
-> berries picked: 70 of 800 | patches-visited: [6] | positive-in-buffer: 18811 | amount-filled: 100.00%
	| epsilon: 0.19021226485170772
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2323, 2324, 1632, 1746, 1506, 2902, 2490, 3888]
	| approx positives in sample 512: 190
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 31, 17, 12, 12, 30, 20, 42]
	Time taken saving stuff: 12.04s
episode: 1201/2000 -> reward: -124.99999999999201, steps:82080, time-taken: 3.60min, time-elasped: 3719.97min
-> berries picked: 138 of 800 | patches-visited: [0, 2, 8] | positive-in-buffer: 18784 | amount-filled: 100.00%
	| epsilon: 0.19005925900808482
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2318, 2332, 1633, 1749, 1508, 2891, 2494, 3859]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 32, 14, 22, 16, 32, 31, 40]
	Time taken saving stuff: 0.01s
episode: 1202/2000 -> reward: -124.99999999998377, steps:104448, time-taken: 4.58min, time-elasped: 3724.55min
-> berries picked: 219 of 800 | patches-visited: [0, 4, 7, 8] | positive-in-buffer: 18940 | amount-filled: 100.00%
	| epsilon: 0.1899063762416368
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2341, 2346, 1650, 1765, 1519, 2916, 2512, 3891]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 37, 17, 19, 19, 30, 31, 36]
	Time taken saving stuff: 0.11s
episode: 1203/2000 -> reward: -124.9999999999917, steps:84672, time-taken: 3.34min, time-elasped: 3727.89min
-> berries picked: 142 of 800 | patches-visited: [1, 2, 5] | positive-in-buffer: 18882 | amount-filled: 100.00%
	| epsilon: 0.18975361645336095
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2329, 2342, 1648, 1767, 1521, 2909, 2507, 3859]
	| approx positives in sample 512: 198
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 37, 9, 17, 17, 39, 27, 35]
	Time taken saving stuff: 12.74s
episode: 1204/2000 -> reward: -124.99999999999402, steps:100800, time-taken: 4.26min, time-elasped: 3732.37min
-> berries picked: 191 of 800 | patches-visited: [4, 6, 7] | positive-in-buffer: 18780 | amount-filled: 100.00%
	| epsilon: 0.18960097954433422
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2302, 2341, 1649, 1769, 1519, 2897, 2487, 3816]
	| approx positives in sample 512: 223
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 26, 16, 22, 18, 42, 31, 43]
	Time taken saving stuff: 0.11s
episode: 1205/2000 -> reward: -107.74999999998347, steps:120000, time-taken: 5.38min, time-elasped: 3737.75min
-> berries picked: 306 of 800 | patches-visited: [2, 4, 5, 6, 7] | positive-in-buffer: 18953 | amount-filled: 100.00%
	| epsilon: 0.18944846541571306
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2324, 2362, 1654, 1786, 1533, 2928, 2513, 3853]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 22, 19, 19, 13, 34, 37, 42]
	Time taken saving stuff: 0.01s
episode: 1206/2000 -> reward: -124.99999999999282, steps:88032, time-taken: 4.10min, time-elasped: 3741.86min
-> berries picked: 164 of 800 | patches-visited: [5, 7, 9] | positive-in-buffer: 18968 | amount-filled: 100.00%
	| epsilon: 0.1892960739687336
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2318, 2353, 1663, 1788, 1536, 2949, 2511, 3850]
	| approx positives in sample 512: 254
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [40, 33, 22, 20, 23, 34, 37, 45]
	Time taken saving stuff: 12.44s
episode: 1207/2000 -> reward: -124.9999999999921, steps:64128, time-taken: 2.60min, time-elasped: 3744.67min
-> berries picked: 55 of 800 | patches-visited: [2, 3] | positive-in-buffer: 18957 | amount-filled: 100.00%
	| epsilon: 0.18914380510471127
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2321, 2358, 1667, 1783, 1533, 2942, 2507, 3846]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 38, 20, 21, 11, 33, 31, 41]
	Time taken saving stuff: 0.01s
episode: 1208/2000 -> reward: -124.99999999999203, steps:65760, time-taken: 2.29min, time-elasped: 3746.96min
-> berries picked: 67 of 800 | patches-visited: [7] | positive-in-buffer: 18751 | amount-filled: 100.00%
	| epsilon: 0.1889916587250409
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2297, 2337, 1661, 1775, 1527, 2919, 2480, 3755]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 24, 21, 20, 14, 39, 18, 35]
	Time taken saving stuff: 0.09s
episode: 1209/2000 -> reward: -124.99999999999537, steps:81408, time-taken: 3.30min, time-elasped: 3750.26min
-> berries picked: 136 of 800 | patches-visited: [5, 8] | positive-in-buffer: 18736 | amount-filled: 100.00%
	| epsilon: 0.18883963473119664
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2299, 2325, 1667, 1785, 1532, 2908, 2478, 3742]
	| approx positives in sample 512: 205
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 28, 22, 21, 11, 32, 32, 35]
	Time taken saving stuff: 12.65s
episode: 1210/2000 -> reward: -124.99999999998539, steps:97152, time-taken: 4.46min, time-elasped: 3754.94min
-> berries picked: 195 of 800 | patches-visited: [1, 2, 3] | positive-in-buffer: 18866 | amount-filled: 100.00%
	| epsilon: 0.18868773302473196
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2312, 2339, 1683, 1796, 1543, 2930, 2486, 3777]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 30, 22, 24, 14, 34, 33, 42]
	Time taken saving stuff: 0.10s
episode: 1211/2000 -> reward: -124.99999999999574, steps:84096, time-taken: 3.32min, time-elasped: 3758.26min
-> berries picked: 152 of 800 | patches-visited: [1, 6] | positive-in-buffer: 18918 | amount-filled: 100.00%
	| epsilon: 0.18853595350727947
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2316, 2345, 1693, 1801, 1549, 2936, 2498, 3780]
	| approx positives in sample 512: 210
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 24, 14, 24, 19, 34, 26, 43]
	Time taken saving stuff: 0.01s
episode: 1212/2000 -> reward: -124.99999999999207, steps:64416, time-taken: 2.39min, time-elasped: 3760.66min
-> berries picked: 59 of 800 | patches-visited: [3] | positive-in-buffer: 18687 | amount-filled: 100.00%
	| epsilon: 0.18838429608055085
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2271, 2329, 1682, 1803, 1550, 2910, 2472, 3670]
	| approx positives in sample 512: 185
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 25, 15, 16, 23, 30, 19, 27]
	Time taken saving stuff: 12.18s
episode: 1213/2000 -> reward: -124.99999999999301, steps:66144, time-taken: 3.19min, time-elasped: 3764.05min
-> berries picked: 77 of 800 | patches-visited: [5] | positive-in-buffer: 18606 | amount-filled: 100.00%
	| epsilon: 0.18823276064633698
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2259, 2319, 1684, 1801, 1541, 2909, 2443, 3650]
	| approx positives in sample 512: 249
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 34, 24, 24, 15, 42, 39, 42]
	Time taken saving stuff: 0.00s
episode: 1214/2000 -> reward: -124.99999999999321, steps:84864, time-taken: 3.47min, time-elasped: 3767.52min
-> berries picked: 142 of 800 | patches-visited: [4, 8] | positive-in-buffer: 18708 | amount-filled: 100.00%
	| epsilon: 0.18808134710650762
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2270, 2329, 1691, 1816, 1553, 2927, 2457, 3665]
	| approx positives in sample 512: 187
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 20, 16, 16, 17, 36, 22, 36]
	Time taken saving stuff: 0.10s
episode: 1215/2000 -> reward: -124.99999999999449, steps:103296, time-taken: 4.47min, time-elasped: 3772.00min
-> berries picked: 228 of 800 | patches-visited: [5, 6, 7] | positive-in-buffer: 18731 | amount-filled: 100.00%
	| epsilon: 0.1879300553630115
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2288, 2328, 1694, 1826, 1557, 2922, 2450, 3666]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 27, 20, 19, 14, 33, 31, 43]
	Time taken saving stuff: 15.30s
episode: 1216/2000 -> reward: -124.99999999999208, steps:67296, time-taken: 3.10min, time-elasped: 3775.35min
-> berries picked: 78 of 800 | patches-visited: [3] | positive-in-buffer: 18692 | amount-filled: 100.00%
	| epsilon: 0.18777888531787623
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2278, 2321, 1690, 1829, 1554, 2918, 2442, 3660]
	| approx positives in sample 512: 250
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [38, 27, 21, 32, 20, 43, 24, 45]
	Time taken saving stuff: 0.08s
episode: 1217/2000 -> reward: -124.99999999998299, steps:85632, time-taken: 3.66min, time-elasped: 3779.01min
-> berries picked: 143 of 800 | patches-visited: [0, 3] | positive-in-buffer: 18772 | amount-filled: 100.00%
	| epsilon: 0.18762783687320822
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2290, 2327, 1700, 1839, 1561, 2935, 2449, 3671]
	| approx positives in sample 512: 207
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 27, 19, 14, 14, 31, 24, 48]
	Time taken saving stuff: 0.01s
episode: 1218/2000 -> reward: -124.99999999999606, steps:106560, time-taken: 4.50min, time-elasped: 3783.51min
-> berries picked: 241 of 800 | patches-visited: [0, 1, 2, 7] | positive-in-buffer: 18764 | amount-filled: 100.00%
	| epsilon: 0.18747690993119262
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2292, 2321, 1710, 1845, 1567, 2935, 2453, 3641]
	| approx positives in sample 512: 223
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 26, 19, 30, 21, 31, 30, 37]
	Time taken saving stuff: 15.69s
episode: 1219/2000 -> reward: -101.74999999999605, steps:120000, time-taken: 5.42min, time-elasped: 3789.20min
-> berries picked: 322 of 800 | patches-visited: [0, 1, 2, 3, 7] | positive-in-buffer: 18878 | amount-filled: 100.00%
	| epsilon: 0.18732610439409333
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2305, 2332, 1732, 1862, 1588, 2951, 2462, 3646]
	| approx positives in sample 512: 211
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 20, 18, 15, 20, 35, 34, 42]
	Time taken saving stuff: 0.01s
episode: 1220/2000 -> reward: -124.9999999999921, steps:65184, time-taken: 2.19min, time-elasped: 3791.39min
-> berries picked: 73 of 800 | patches-visited: [9] | positive-in-buffer: 18894 | amount-filled: 100.00%
	| epsilon: 0.1871754201642528
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2306, 2333, 1733, 1866, 1586, 2955, 2461, 3654]
	| approx positives in sample 512: 192
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 29, 14, 19, 25, 25, 23, 33]
	Time taken saving stuff: 0.10s
episode: 1221/2000 -> reward: -124.99999999999153, steps:84576, time-taken: 3.34min, time-elasped: 3794.74min
-> berries picked: 149 of 800 | patches-visited: [4, 8] | positive-in-buffer: 18673 | amount-filled: 100.00%
	| epsilon: 0.18702485714409198
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2283, 2313, 1720, 1861, 1571, 2928, 2446, 3551]
	| approx positives in sample 512: 198
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 25, 22, 22, 12, 27, 28, 32]
	Time taken saving stuff: 15.21s
episode: 1222/2000 -> reward: -124.9999999999921, steps:65856, time-taken: 2.37min, time-elasped: 3797.37min
-> berries picked: 69 of 800 | patches-visited: [2] | positive-in-buffer: 18686 | amount-filled: 100.00%
	| epsilon: 0.18687441523611042
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2284, 2313, 1722, 1862, 1574, 2932, 2449, 3550]
	| approx positives in sample 512: 176
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 29, 13, 16, 13, 28, 24, 37]
	Time taken saving stuff: 0.10s
episode: 1223/2000 -> reward: -124.99999999999083, steps:79584, time-taken: 3.21min, time-elasped: 3800.58min
-> berries picked: 125 of 800 | patches-visited: [3, 4] | positive-in-buffer: 18645 | amount-filled: 100.00%
	| epsilon: 0.1867240943428861
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2266, 2299, 1724, 1863, 1579, 2930, 2437, 3547]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 22, 20, 25, 18, 36, 33, 53]
	Time taken saving stuff: 0.00s
episode: 1224/2000 -> reward: -124.24999999998765, steps:120000, time-taken: 5.68min, time-elasped: 3806.26min
-> berries picked: 281 of 800 | patches-visited: [1, 3, 8, 9] | positive-in-buffer: 18861 | amount-filled: 100.00%
	| epsilon: 0.1865738943670752
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2299, 2322, 1746, 1891, 1600, 2958, 2464, 3581]
	| approx positives in sample 512: 233
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 27, 19, 27, 24, 40, 30, 41]
	Time taken saving stuff: 15.28s
episode: 1225/2000 -> reward: -124.99999999998485, steps:106848, time-taken: 4.69min, time-elasped: 3811.20min
-> berries picked: 231 of 800 | patches-visited: [1, 6, 9] | positive-in-buffer: 18972 | amount-filled: 100.00%
	| epsilon: 0.18642381521141246
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2314, 2327, 1763, 1906, 1622, 2969, 2472, 3599]
	| approx positives in sample 512: 196
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 16, 24, 16, 26, 35, 23, 36]
	Time taken saving stuff: 0.01s
episode: 1226/2000 -> reward: -124.99999999999203, steps:57216, time-taken: 2.10min, time-elasped: 3813.31min
-> berries picked: 33 of 800 | patches-visited: [0] | positive-in-buffer: 18825 | amount-filled: 100.00%
	| epsilon: 0.18627385677871067
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2286, 2319, 1753, 1887, 1609, 2950, 2465, 3556]
	| approx positives in sample 512: 185
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 25, 19, 23, 12, 32, 19, 34]
	Time taken saving stuff: 0.10s
episode: 1227/2000 -> reward: -124.99999999999397, steps:70848, time-taken: 3.11min, time-elasped: 3816.43min
-> berries picked: 95 of 800 | patches-visited: [5, 6] | positive-in-buffer: 18884 | amount-filled: 100.00%
	| epsilon: 0.18612401897186087
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2291, 2323, 1756, 1894, 1621, 2968, 2470, 3561]
	| approx positives in sample 512: 237
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 32, 24, 18, 15, 35, 35, 45]
	Time taken saving stuff: 14.75s
episode: 1228/2000 -> reward: -124.9999999999925, steps:67584, time-taken: 3.12min, time-elasped: 3819.79min
-> berries picked: 76 of 800 | patches-visited: [1] | positive-in-buffer: 18930 | amount-filled: 100.00%
	| epsilon: 0.18597430169383217
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2299, 2330, 1765, 1897, 1625, 2973, 2472, 3569]
	| approx positives in sample 512: 259
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 29, 22, 26, 30, 37, 38, 54]
	Time taken saving stuff: 0.08s
episode: 1229/2000 -> reward: -124.99999999999183, steps:65280, time-taken: 2.39min, time-elasped: 3822.19min
-> berries picked: 68 of 800 | patches-visited: [5] | positive-in-buffer: 18966 | amount-filled: 100.00%
	| epsilon: 0.18582470484767175
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2305, 2335, 1768, 1901, 1628, 2977, 2475, 3577]
	| approx positives in sample 512: 180
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 19, 19, 21, 12, 25, 32, 33]
	Time taken saving stuff: 0.01s
episode: 1230/2000 -> reward: -124.99999999999213, steps:68064, time-taken: 3.04min, time-elasped: 3825.23min
-> berries picked: 74 of 800 | patches-visited: [0] | positive-in-buffer: 18804 | amount-filled: 100.00%
	| epsilon: 0.1856752283365048
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2278, 2309, 1759, 1896, 1620, 2959, 2453, 3530]
	| approx positives in sample 512: 241
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [38, 29, 26, 24, 23, 37, 26, 38]
	Time taken saving stuff: 15.36s
episode: 1231/2000 -> reward: -124.99999999999126, steps:66336, time-taken: 3.04min, time-elasped: 3828.52min
-> berries picked: 72 of 800 | patches-visited: [2] | positive-in-buffer: 18856 | amount-filled: 100.00%
	| epsilon: 0.18552587206353446
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2288, 2313, 1764, 1902, 1624, 2967, 2458, 3540]
	| approx positives in sample 512: 249
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [37, 40, 11, 28, 14, 37, 38, 44]
	Time taken saving stuff: 0.00s
episode: 1232/2000 -> reward: -124.99999999999346, steps:96288, time-taken: 4.54min, time-elasped: 3833.07min
-> berries picked: 184 of 800 | patches-visited: [3, 6, 9] | positive-in-buffer: 18982 | amount-filled: 100.00%
	| epsilon: 0.18537663593204165
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2305, 2333, 1775, 1920, 1635, 2985, 2473, 3556]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 36, 17, 23, 14, 36, 31, 41]
	Time taken saving stuff: 0.02s
episode: 1233/2000 -> reward: -124.99999999999179, steps:81792, time-taken: 3.41min, time-elasped: 3836.48min
-> berries picked: 137 of 800 | patches-visited: [0, 8] | positive-in-buffer: 19061 | amount-filled: 100.00%
	| epsilon: 0.18522751984538516
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2316, 2336, 1779, 1927, 1646, 3002, 2484, 3571]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 29, 24, 22, 14, 39, 23, 42]
	Time taken saving stuff: 15.29s
episode: 1234/2000 -> reward: -124.99999999999223, steps:78816, time-taken: 3.25min, time-elasped: 3839.99min
-> berries picked: 124 of 800 | patches-visited: [0, 1] | positive-in-buffer: 19002 | amount-filled: 100.00%
	| epsilon: 0.18507852370700148
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2307, 2328, 1775, 1922, 1647, 3008, 2464, 3551]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 34, 16, 21, 19, 35, 31, 34]
	Time taken saving stuff: 0.09s
episode: 1235/2000 -> reward: -124.99999999999423, steps:102912, time-taken: 4.34min, time-elasped: 3844.33min
-> berries picked: 206 of 800 | patches-visited: [1, 2, 4] | positive-in-buffer: 19138 | amount-filled: 100.00%
	| epsilon: 0.1849296474204048
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2326, 2338, 1783, 1942, 1657, 3025, 2481, 3586]
	| approx positives in sample 512: 206
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 35, 15, 19, 17, 47, 27, 33]
	Time taken saving stuff: 0.00s
episode: 1236/2000 -> reward: -124.9999999999917, steps:67872, time-taken: 3.14min, time-elasped: 3847.48min
-> berries picked: 80 of 800 | patches-visited: [2] | positive-in-buffer: 19027 | amount-filled: 100.00%
	| epsilon: 0.18478089088918684
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2316, 2325, 1774, 1939, 1647, 3013, 2473, 3540]
	| approx positives in sample 512: 241
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 30, 18, 27, 22, 34, 28, 57]
	Time taken saving stuff: 15.50s
episode: 1237/2000 -> reward: -124.99999999999548, steps:84384, time-taken: 3.43min, time-elasped: 3851.17min
-> berries picked: 149 of 800 | patches-visited: [0, 6] | positive-in-buffer: 19104 | amount-filled: 100.00%
	| epsilon: 0.18463225401701705
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2323, 2334, 1782, 1953, 1652, 3026, 2484, 3550]
	| approx positives in sample 512: 202
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 24, 22, 26, 17, 26, 33, 35]
	Time taken saving stuff: 0.01s
episode: 1238/2000 -> reward: -124.99999999997893, steps:98880, time-taken: 4.53min, time-elasped: 3855.70min
-> berries picked: 200 of 800 | patches-visited: [1, 3, 4] | positive-in-buffer: 19019 | amount-filled: 100.00%
	| epsilon: 0.18448373670764223
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2312, 2321, 1785, 1955, 1665, 3027, 2462, 3492]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 23, 24, 29, 20, 41, 27, 47]
	Time taken saving stuff: 0.09s
episode: 1239/2000 -> reward: -124.99999999999365, steps:81408, time-taken: 3.23min, time-elasped: 3858.94min
-> berries picked: 126 of 800 | patches-visited: [7, 8, 9] | positive-in-buffer: 19086 | amount-filled: 100.00%
	| epsilon: 0.1843353388648866
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2317, 2326, 1799, 1963, 1666, 3043, 2468, 3504]
	| approx positives in sample 512: 206
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 28, 20, 21, 18, 27, 34, 39]
	Time taken saving stuff: 15.35s
episode: 1240/2000 -> reward: -124.99999999999206, steps:54720, time-taken: 2.65min, time-elasped: 3861.85min
-> berries picked: 25 of 800 | patches-visited: [6] | positive-in-buffer: 18945 | amount-filled: 100.00%
	| epsilon: 0.18418706039265179
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2300, 2308, 1789, 1944, 1653, 3022, 2458, 3471]
	| approx positives in sample 512: 199
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 26, 19, 18, 12, 38, 23, 38]
	Time taken saving stuff: 0.02s
episode: 1241/2000 -> reward: -124.99999999999216, steps:67296, time-taken: 3.08min, time-elasped: 3864.93min
-> berries picked: 71 of 800 | patches-visited: [3] | positive-in-buffer: 18989 | amount-filled: 100.00%
	| epsilon: 0.18403890119491673
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2302, 2312, 1798, 1950, 1656, 3029, 2463, 3479]
	| approx positives in sample 512: 262
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 21, 20, 29, 22, 51, 38, 52]
	Time taken saving stuff: 0.00s
episode: 1242/2000 -> reward: -124.99999999999207, steps:64128, time-taken: 2.21min, time-elasped: 3867.14min
-> berries picked: 71 of 800 | patches-visited: [1] | positive-in-buffer: 19013 | amount-filled: 100.00%
	| epsilon: 0.18389086117573755
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2302, 2314, 1799, 1955, 1660, 3029, 2468, 3486]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 26, 21, 18, 15, 38, 39, 35]
	Time taken saving stuff: 11.94s
episode: 1243/2000 -> reward: -124.99999999999227, steps:102240, time-taken: 4.44min, time-elasped: 3871.78min
-> berries picked: 197 of 800 | patches-visited: [1, 5, 6] | positive-in-buffer: 18818 | amount-filled: 100.00%
	| epsilon: 0.18374294023924764
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2272, 2301, 1799, 1948, 1666, 3013, 2421, 3398]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 28, 11, 14, 21, 36, 47, 38]
	Time taken saving stuff: 0.00s
episode: 1244/2000 -> reward: -124.99999999999326, steps:103968, time-taken: 4.62min, time-elasped: 3876.40min
-> berries picked: 223 of 800 | patches-visited: [2, 8, 9] | positive-in-buffer: 18933 | amount-filled: 100.00%
	| epsilon: 0.1835951382896574
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2286, 2309, 1814, 1954, 1682, 3034, 2434, 3420]
	| approx positives in sample 512: 203
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 21, 16, 22, 23, 34, 26, 37]
	Time taken saving stuff: 0.02s
episode: 1245/2000 -> reward: -124.99999999998609, steps:103968, time-taken: 4.65min, time-elasped: 3881.06min
-> berries picked: 223 of 800 | patches-visited: [2, 4, 8] | positive-in-buffer: 18885 | amount-filled: 100.00%
	| epsilon: 0.18344745523125436
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2287, 2291, 1814, 1963, 1685, 3037, 2434, 3374]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 25, 26, 17, 23, 30, 35, 38]
	Time taken saving stuff: 14.77s
episode: 1246/2000 -> reward: -124.99999999998496, steps:80736, time-taken: 3.51min, time-elasped: 3884.82min
-> berries picked: 144 of 800 | patches-visited: [2, 6] | positive-in-buffer: 18839 | amount-filled: 100.00%
	| epsilon: 0.183299890968403
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2273, 2290, 1806, 1956, 1686, 3041, 2427, 3360]
	| approx positives in sample 512: 194
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 22, 15, 22, 15, 33, 15, 42]
	Time taken saving stuff: 0.08s
episode: 1247/2000 -> reward: -124.99999999999159, steps:65184, time-taken: 2.28min, time-elasped: 3887.11min
-> berries picked: 66 of 800 | patches-visited: [0] | positive-in-buffer: 18802 | amount-filled: 100.00%
	| epsilon: 0.18315244540554473
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2264, 2284, 1800, 1962, 1682, 3034, 2428, 3348]
	| approx positives in sample 512: 185
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 30, 17, 19, 15, 30, 21, 29]
	Time taken saving stuff: 0.01s
episode: 1248/2000 -> reward: -124.99999999999191, steps:66528, time-taken: 3.02min, time-elasped: 3890.13min
-> berries picked: 74 of 800 | patches-visited: [2] | positive-in-buffer: 18665 | amount-filled: 100.00%
	| epsilon: 0.18300511844719786
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2239, 2273, 1797, 1948, 1682, 3024, 2411, 3291]
	| approx positives in sample 512: 233
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 26, 17, 26, 20, 44, 33, 41]
	Time taken saving stuff: 12.86s
episode: 1249/2000 -> reward: -124.99999999998877, steps:74400, time-taken: 3.17min, time-elasped: 3893.52min
-> berries picked: 99 of 800 | patches-visited: [5, 9] | positive-in-buffer: 18745 | amount-filled: 100.00%
	| epsilon: 0.18285790999795748
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2253, 2281, 1798, 1956, 1691, 3043, 2417, 3306]
	| approx positives in sample 512: 226
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 28, 26, 19, 14, 34, 27, 43]
	Time taken saving stuff: 0.00s
episode: 1250/2000 -> reward: -124.99999999999207, steps:64896, time-taken: 2.26min, time-elasped: 3895.78min
-> berries picked: 66 of 800 | patches-visited: [9] | positive-in-buffer: 18771 | amount-filled: 100.00%
	| epsilon: 0.1827108199624954
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2253, 2283, 1803, 1959, 1696, 3048, 2421, 3308]
	| approx positives in sample 512: 193
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 31, 23, 18, 14, 36, 28, 18]
	Time taken saving stuff: 0.01s
episode: 1251/2000 -> reward: -124.99999999999619, steps:85056, time-taken: 3.40min, time-elasped: 3899.18min
-> berries picked: 142 of 800 | patches-visited: [3, 7] | positive-in-buffer: 18723 | amount-filled: 100.00%
	| epsilon: 0.1825638482455602
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2245, 2276, 1805, 1956, 1699, 3047, 2410, 3285]
	| approx positives in sample 512: 183
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 18, 21, 17, 16, 28, 16, 46]
	Time taken saving stuff: 14.96s
episode: 1252/2000 -> reward: -124.99999999998748, steps:102624, time-taken: 4.47min, time-elasped: 3903.90min
-> berries picked: 223 of 800 | patches-visited: [3, 5, 8, 9] | positive-in-buffer: 18796 | amount-filled: 100.00%
	| epsilon: 0.18241699475197692
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2255, 2284, 1823, 1981, 1702, 3056, 2408, 3287]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 24, 18, 19, 10, 50, 27, 38]
	Time taken saving stuff: 0.10s
episode: 1253/2000 -> reward: -124.99999999999203, steps:61920, time-taken: 2.23min, time-elasped: 3906.14min
-> berries picked: 51 of 800 | patches-visited: [3] | positive-in-buffer: 18761 | amount-filled: 100.00%
	| epsilon: 0.18227025938664737
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2247, 2284, 1823, 1981, 1697, 3042, 2404, 3283]
	| approx positives in sample 512: 189
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 25, 13, 20, 20, 32, 19, 38]
	Time taken saving stuff: 0.01s
episode: 1254/2000 -> reward: -124.99999999999199, steps:81696, time-taken: 3.42min, time-elasped: 3909.56min
-> berries picked: 120 of 800 | patches-visited: [0, 3] | positive-in-buffer: 18702 | amount-filled: 100.00%
	| epsilon: 0.18212364205454967
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2232, 2277, 1826, 1980, 1688, 3036, 2393, 3270]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 25, 18, 26, 18, 36, 29, 41]
	Time taken saving stuff: 11.97s
episode: 1255/2000 -> reward: -124.99999999999872, steps:98688, time-taken: 4.33min, time-elasped: 3914.09min
-> berries picked: 194 of 800 | patches-visited: [2, 3, 9] | positive-in-buffer: 18820 | amount-filled: 100.00%
	| epsilon: 0.18197714266073847
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2243, 2280, 1844, 1988, 1695, 3069, 2403, 3298]
	| approx positives in sample 512: 230
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 30, 23, 29, 19, 38, 31, 38]
	Time taken saving stuff: 0.01s
episode: 1256/2000 -> reward: -124.9999999999906, steps:63744, time-taken: 2.37min, time-elasped: 3916.46min
-> berries picked: 58 of 800 | patches-visited: [2] | positive-in-buffer: 18829 | amount-filled: 100.00%
	| epsilon: 0.1818307611103448
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2244, 2278, 1845, 1992, 1691, 3070, 2406, 3303]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 26, 14, 25, 25, 27, 33, 38]
	Time taken saving stuff: 0.09s
episode: 1257/2000 -> reward: -124.99999999999211, steps:60000, time-taken: 2.43min, time-elasped: 3918.89min
-> berries picked: 45 of 800 | patches-visited: [7] | positive-in-buffer: 18666 | amount-filled: 100.00%
	| epsilon: 0.1816844973085759
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2219, 2260, 1830, 1983, 1679, 3054, 2385, 3256]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 26, 21, 23, 13, 43, 23, 34]
	Time taken saving stuff: 14.99s
episode: 1258/2000 -> reward: -124.99999999999216, steps:82464, time-taken: 3.40min, time-elasped: 3922.55min
-> berries picked: 149 of 800 | patches-visited: [5, 8] | positive-in-buffer: 18753 | amount-filled: 100.00%
	| epsilon: 0.1815383511607154
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2224, 2262, 1841, 1991, 1688, 3070, 2407, 3270]
	| approx positives in sample 512: 182
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 26, 13, 19, 14, 30, 22, 35]
	Time taken saving stuff: 0.06s
episode: 1259/2000 -> reward: -116.24999999999712, steps:120000, time-taken: 5.50min, time-elasped: 3928.05min
-> berries picked: 272 of 800 | patches-visited: [0, 1, 6, 7] | positive-in-buffer: 18926 | amount-filled: 100.00%
	| epsilon: 0.181392322572123
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2243, 2275, 1869, 2005, 1712, 3094, 2420, 3308]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 30, 18, 21, 20, 45, 34, 39]
	Time taken saving stuff: 0.00s
episode: 1260/2000 -> reward: -124.99999999999231, steps:67296, time-taken: 2.94min, time-elasped: 3930.99min
-> berries picked: 74 of 800 | patches-visited: [6] | positive-in-buffer: 18946 | amount-filled: 100.00%
	| epsilon: 0.18124641144823467
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2246, 2277, 1874, 2010, 1714, 3094, 2415, 3316]
	| approx positives in sample 512: 267
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 41, 22, 28, 19, 51, 40, 44]
	Time taken saving stuff: 11.77s
episode: 1261/2000 -> reward: -124.99999999998128, steps:114624, time-taken: 5.47min, time-elasped: 3936.66min
-> berries picked: 270 of 800 | patches-visited: [0, 7, 8, 9] | positive-in-buffer: 19111 | amount-filled: 100.00%
	| epsilon: 0.18110061769456226
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2259, 2289, 1889, 2031, 1735, 3128, 2434, 3346]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 26, 33, 24, 16, 33, 35, 29]
	Time taken saving stuff: 0.00s
episode: 1262/2000 -> reward: -124.9999999999919, steps:60768, time-taken: 2.37min, time-elasped: 3939.03min
-> berries picked: 50 of 800 | patches-visited: [0] | positive-in-buffer: 19033 | amount-filled: 100.00%
	| epsilon: 0.18095494121669378
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2252, 2281, 1881, 2015, 1729, 3112, 2429, 3334]
	| approx positives in sample 512: 211
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 32, 23, 19, 16, 40, 24, 32]
	Time taken saving stuff: 0.10s
episode: 1263/2000 -> reward: -124.99999999999206, steps:65280, time-taken: 2.40min, time-elasped: 3941.43min
-> berries picked: 72 of 800 | patches-visited: [0] | positive-in-buffer: 18918 | amount-filled: 100.00%
	| epsilon: 0.1808093819202931
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2247, 2266, 1854, 2010, 1723, 3093, 2422, 3303]
	| approx positives in sample 512: 207
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 29, 12, 27, 13, 37, 29, 31]
	Time taken saving stuff: 15.75s
episode: 1264/2000 -> reward: -124.99999999999018, steps:86304, time-taken: 3.53min, time-elasped: 3945.22min
-> berries picked: 149 of 800 | patches-visited: [2, 7] | positive-in-buffer: 18895 | amount-filled: 100.00%
	| epsilon: 0.18066393971110004
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2244, 2257, 1857, 2000, 1725, 3109, 2417, 3286]
	| approx positives in sample 512: 207
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 22, 19, 24, 19, 34, 30, 32]
	Time taken saving stuff: 0.02s
episode: 1265/2000 -> reward: -124.9999999999921, steps:66048, time-taken: 3.12min, time-elasped: 3948.34min
-> berries picked: 72 of 800 | patches-visited: [5] | positive-in-buffer: 18891 | amount-filled: 100.00%
	| epsilon: 0.18051861449493017
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2244, 2261, 1856, 1989, 1725, 3114, 2419, 3283]
	| approx positives in sample 512: 253
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 34, 19, 30, 25, 33, 37, 41]
	Time taken saving stuff: 0.00s
episode: 1266/2000 -> reward: -124.99999999999154, steps:115104, time-taken: 5.30min, time-elasped: 3953.65min
-> berries picked: 260 of 800 | patches-visited: [1, 3, 4, 6, 8] | positive-in-buffer: 19089 | amount-filled: 100.00%
	| epsilon: 0.1803734061776749
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2264, 2282, 1884, 2012, 1744, 3145, 2438, 3320]
	| approx positives in sample 512: 249
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 39, 18, 29, 18, 30, 49, 37]
	Time taken saving stuff: 11.55s
episode: 1267/2000 -> reward: -124.99999999999231, steps:66240, time-taken: 3.18min, time-elasped: 3957.03min
-> berries picked: 80 of 800 | patches-visited: [6] | positive-in-buffer: 19109 | amount-filled: 100.00%
	| epsilon: 0.18022831466530126
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2265, 2282, 1889, 2014, 1750, 3149, 2436, 3324]
	| approx positives in sample 512: 247
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 35, 21, 29, 27, 27, 42, 38]
	Time taken saving stuff: 0.01s
episode: 1268/2000 -> reward: -124.99999999999162, steps:68160, time-taken: 3.47min, time-elasped: 3960.50min
-> berries picked: 81 of 800 | patches-visited: [6, 7] | positive-in-buffer: 19138 | amount-filled: 100.00%
	| epsilon: 0.18008333986385197
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2275, 2284, 1895, 2017, 1753, 3150, 2440, 3324]
	| approx positives in sample 512: 242
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 30, 21, 22, 21, 46, 34, 42]
	Time taken saving stuff: 0.02s
episode: 1269/2000 -> reward: -124.99999999999194, steps:82560, time-taken: 3.30min, time-elasped: 3963.80min
-> berries picked: 130 of 800 | patches-visited: [0, 4] | positive-in-buffer: 19173 | amount-filled: 100.00%
	| epsilon: 0.1799384816794453
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2268, 2288, 1903, 2027, 1761, 3158, 2439, 3329]
	| approx positives in sample 512: 205
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 29, 17, 14, 22, 28, 31, 39]
	Time taken saving stuff: 14.99s
episode: 1270/2000 -> reward: -124.99999999999183, steps:73248, time-taken: 3.13min, time-elasped: 3967.18min
-> berries picked: 89 of 800 | patches-visited: [0, 1] | positive-in-buffer: 18991 | amount-filled: 100.00%
	| epsilon: 0.17979374001827508
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2250, 2278, 1898, 2007, 1743, 3143, 2416, 3256]
	| approx positives in sample 512: 244
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 41, 17, 19, 30, 32, 34, 49]
	Time taken saving stuff: 0.02s
episode: 1271/2000 -> reward: -124.99999999999189, steps:66720, time-taken: 3.06min, time-elasped: 3970.24min
-> berries picked: 80 of 800 | patches-visited: [7] | positive-in-buffer: 19040 | amount-filled: 100.00%
	| epsilon: 0.17964911478661058
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2257, 2282, 1900, 2012, 1749, 3150, 2424, 3266]
	| approx positives in sample 512: 233
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 37, 18, 24, 20, 44, 28, 35]
	Time taken saving stuff: 0.00s
episode: 1272/2000 -> reward: -124.99999999998539, steps:98016, time-taken: 4.26min, time-elasped: 3974.50min
-> berries picked: 194 of 800 | patches-visited: [2, 3, 8] | positive-in-buffer: 19181 | amount-filled: 100.00%
	| epsilon: 0.17950460589079642
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2273, 2298, 1917, 2033, 1755, 3175, 2447, 3283]
	| approx positives in sample 512: 201
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [37, 21, 21, 19, 15, 32, 27, 29]
	Time taken saving stuff: 11.87s
episode: 1273/2000 -> reward: -124.9999999999922, steps:65280, time-taken: 2.26min, time-elasped: 3976.97min
-> berries picked: 72 of 800 | patches-visited: [4] | positive-in-buffer: 19169 | amount-filled: 100.00%
	| epsilon: 0.1793602132372526
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2264, 2290, 1917, 2029, 1759, 3175, 2449, 3286]
	| approx positives in sample 512: 204
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 37, 17, 17, 14, 40, 27, 32]
	Time taken saving stuff: 0.01s
episode: 1274/2000 -> reward: -124.9999999999966, steps:117408, time-taken: 5.31min, time-elasped: 3982.28min
-> berries picked: 291 of 800 | patches-visited: [0, 2, 7, 9] | positive-in-buffer: 19140 | amount-filled: 100.00%
	| epsilon: 0.1792159367324744
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2255, 2268, 1897, 2020, 1768, 3180, 2456, 3296]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 27, 17, 21, 20, 32, 29, 46]
	Time taken saving stuff: 0.03s
episode: 1275/2000 -> reward: -124.99999999998491, steps:104160, time-taken: 4.61min, time-elasped: 3986.90min
-> berries picked: 237 of 800 | patches-visited: [0, 4, 9] | positive-in-buffer: 19277 | amount-filled: 100.00%
	| epsilon: 0.17907177628303234
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2269, 2281, 1917, 2031, 1783, 3210, 2471, 3315]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 34, 24, 26, 18, 46, 32, 33]
	Time taken saving stuff: 12.56s
episode: 1276/2000 -> reward: -124.99999999999174, steps:76416, time-taken: 3.34min, time-elasped: 3990.45min
-> berries picked: 107 of 800 | patches-visited: [2, 5] | positive-in-buffer: 19162 | amount-filled: 100.00%
	| epsilon: 0.17892773179557195
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2251, 2276, 1910, 2022, 1767, 3190, 2453, 3293]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 22, 19, 27, 13, 37, 28, 29]
	Time taken saving stuff: 0.02s
episode: 1277/2000 -> reward: -124.99999999999285, steps:61728, time-taken: 2.29min, time-elasped: 3992.74min
-> berries picked: 50 of 800 | patches-visited: [6] | positive-in-buffer: 19181 | amount-filled: 100.00%
	| epsilon: 0.17878380317681408
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2256, 2275, 1913, 2026, 1770, 3187, 2453, 3301]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 25, 20, 27, 24, 36, 25, 28]
	Time taken saving stuff: 0.01s
episode: 1278/2000 -> reward: -124.99999999999191, steps:66720, time-taken: 3.11min, time-elasped: 3995.86min
-> berries picked: 79 of 800 | patches-visited: [7] | positive-in-buffer: 19066 | amount-filled: 100.00%
	| epsilon: 0.17863999033355446
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2242, 2259, 1905, 2009, 1754, 3180, 2439, 3278]
	| approx positives in sample 512: 246
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 36, 22, 29, 20, 41, 34, 42]
	Time taken saving stuff: 12.50s
episode: 1279/2000 -> reward: -124.99999999999214, steps:58944, time-taken: 2.22min, time-elasped: 3998.29min
-> berries picked: 37 of 800 | patches-visited: [5] | positive-in-buffer: 19088 | amount-filled: 100.00%
	| epsilon: 0.1784962931726638
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2242, 2259, 1910, 2011, 1756, 3187, 2440, 3283]
	| approx positives in sample 512: 211
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 21, 18, 24, 16, 39, 31, 36]
	Time taken saving stuff: 0.01s
episode: 1280/2000 -> reward: -124.9999999999921, steps:65760, time-taken: 2.54min, time-elasped: 4000.84min
-> berries picked: 78 of 800 | patches-visited: [2] | positive-in-buffer: 19098 | amount-filled: 100.00%
	| epsilon: 0.1783527116010878
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2243, 2255, 1913, 2014, 1759, 3193, 2447, 3274]
	| approx positives in sample 512: 187
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 25, 18, 23, 17, 33, 26, 25]
	Time taken saving stuff: 0.10s
episode: 1281/2000 -> reward: -124.99999999999227, steps:67008, time-taken: 3.08min, time-elasped: 4003.92min
-> berries picked: 80 of 800 | patches-visited: [6] | positive-in-buffer: 18966 | amount-filled: 100.00%
	| epsilon: 0.1782092455258469
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2232, 2244, 1892, 2000, 1756, 3163, 2434, 3245]
	| approx positives in sample 512: 251
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 41, 20, 27, 26, 49, 26, 36]
	Time taken saving stuff: 12.58s
episode: 1282/2000 -> reward: -124.99999999999163, steps:67104, time-taken: 3.70min, time-elasped: 4007.83min
-> berries picked: 80 of 800 | patches-visited: [3] | positive-in-buffer: 19017 | amount-filled: 100.00%
	| epsilon: 0.17806589485403646
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2240, 2250, 1896, 2006, 1760, 3172, 2441, 3252]
	| approx positives in sample 512: 239
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 29, 26, 26, 25, 39, 27, 42]
	Time taken saving stuff: 0.02s
episode: 1283/2000 -> reward: -124.99999999999203, steps:66816, time-taken: 3.22min, time-elasped: 4011.06min
-> berries picked: 79 of 800 | patches-visited: [2] | positive-in-buffer: 19042 | amount-filled: 100.00%
	| epsilon: 0.17792265949282643
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2244, 2252, 1900, 2013, 1759, 3175, 2441, 3258]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 33, 29, 20, 18, 38, 33, 35]
	Time taken saving stuff: 0.00s
episode: 1284/2000 -> reward: -124.99999999999201, steps:62496, time-taken: 2.24min, time-elasped: 4013.30min
-> berries picked: 52 of 800 | patches-visited: [1] | positive-in-buffer: 19071 | amount-filled: 100.00%
	| epsilon: 0.17777953934946158
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2247, 2254, 1905, 2014, 1770, 3179, 2441, 3261]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 18, 21, 23, 15, 30, 22, 42]
	Time taken saving stuff: 12.21s
episode: 1285/2000 -> reward: -124.99999999999285, steps:91008, time-taken: 4.26min, time-elasped: 4017.76min
-> berries picked: 177 of 800 | patches-visited: [2, 3, 5] | positive-in-buffer: 19069 | amount-filled: 100.00%
	| epsilon: 0.17763653433126123
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2247, 2248, 1899, 2015, 1772, 3184, 2452, 3252]
	| approx positives in sample 512: 244
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 27, 27, 28, 16, 42, 42, 37]
	Time taken saving stuff: 0.01s
episode: 1286/2000 -> reward: -124.9999999999953, steps:86304, time-taken: 3.49min, time-elasped: 4021.25min
-> berries picked: 154 of 800 | patches-visited: [4, 7] | positive-in-buffer: 19154 | amount-filled: 100.00%
	| epsilon: 0.17749364434561918
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2258, 2251, 1902, 2025, 1784, 3205, 2467, 3262]
	| approx positives in sample 512: 205
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 22, 22, 24, 11, 37, 34, 32]
	Time taken saving stuff: 0.10s
episode: 1287/2000 -> reward: -124.99999999999598, steps:112320, time-taken: 5.78min, time-elasped: 4027.03min
-> berries picked: 253 of 800 | patches-visited: [3, 4, 7, 9] | positive-in-buffer: 19168 | amount-filled: 100.00%
	| epsilon: 0.17735086930000382
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2254, 2248, 1904, 2021, 1785, 3223, 2474, 3259]
	| approx positives in sample 512: 230
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 27, 28, 30, 28, 37, 35, 31]
	Time taken saving stuff: 12.67s
episode: 1288/2000 -> reward: -124.99999999999196, steps:65280, time-taken: 2.36min, time-elasped: 4029.61min
-> berries picked: 71 of 800 | patches-visited: [8] | positive-in-buffer: 19207 | amount-filled: 100.00%
	| epsilon: 0.17720820910195795
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2258, 2251, 1905, 2025, 1789, 3234, 2478, 3267]
	| approx positives in sample 512: 192
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 23, 21, 19, 14, 35, 23, 32]
	Time taken saving stuff: 0.09s
episode: 1289/2000 -> reward: -124.99999999998786, steps:116256, time-taken: 6.23min, time-elasped: 4035.84min
-> berries picked: 270 of 800 | patches-visited: [0, 5, 7, 9] | positive-in-buffer: 19196 | amount-filled: 100.00%
	| epsilon: 0.17706566365909865
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2254, 2232, 1905, 2024, 1791, 3242, 2478, 3270]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 25, 29, 23, 28, 36, 32, 30]
	Time taken saving stuff: 0.01s
episode: 1290/2000 -> reward: -124.99999999999248, steps:81024, time-taken: 3.40min, time-elasped: 4039.24min
-> berries picked: 133 of 800 | patches-visited: [1, 9] | positive-in-buffer: 19247 | amount-filled: 100.00%
	| epsilon: 0.17692323287911751
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2258, 2237, 1910, 2034, 1799, 3252, 2485, 3272]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 34, 16, 24, 21, 34, 27, 34]
	Time taken saving stuff: 12.47s
episode: 1291/2000 -> reward: -124.99999999999206, steps:64896, time-taken: 2.57min, time-elasped: 4042.02min
-> berries picked: 74 of 800 | patches-visited: [5] | positive-in-buffer: 19180 | amount-filled: 100.00%
	| epsilon: 0.1767809166697802
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2252, 2230, 1905, 2021, 1794, 3238, 2480, 3260]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 27, 15, 28, 18, 45, 35, 35]
	Time taken saving stuff: 0.01s
episode: 1292/2000 -> reward: -124.99999999999234, steps:67296, time-taken: 3.68min, time-elasped: 4045.70min
-> berries picked: 73 of 800 | patches-visited: [2] | positive-in-buffer: 19028 | amount-filled: 100.00%
	| epsilon: 0.17663871493892666
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2235, 2213, 1870, 2007, 1779, 3229, 2469, 3226]
	| approx positives in sample 512: 246
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 29, 30, 29, 14, 46, 36, 36]
	Time taken saving stuff: 0.03s
episode: 1293/2000 -> reward: -124.9999999999946, steps:84768, time-taken: 3.87min, time-elasped: 4049.57min
-> berries picked: 143 of 800 | patches-visited: [6, 8] | positive-in-buffer: 19117 | amount-filled: 100.00%
	| epsilon: 0.1764966275944709
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2246, 2222, 1882, 2019, 1796, 3242, 2477, 3233]
	| approx positives in sample 512: 201
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 20, 13, 31, 18, 38, 35, 22]
	Time taken saving stuff: 15.73s
episode: 1294/2000 -> reward: -124.99999999998306, steps:86976, time-taken: 3.66min, time-elasped: 4053.49min
-> berries picked: 144 of 800 | patches-visited: [7, 8] | positive-in-buffer: 19143 | amount-filled: 100.00%
	| epsilon: 0.17635465454440108
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2243, 2213, 1894, 2023, 1803, 3249, 2483, 3235]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 26, 26, 20, 14, 42, 29, 31]
	Time taken saving stuff: 0.09s
episode: 1295/2000 -> reward: -124.99999999999193, steps:62112, time-taken: 2.42min, time-elasped: 4055.92min
-> berries picked: 52 of 800 | patches-visited: [1] | positive-in-buffer: 19026 | amount-filled: 100.00%
	| epsilon: 0.1762127956967793
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2235, 2201, 1878, 2013, 1791, 3227, 2471, 3210]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 21, 17, 25, 20, 33, 30, 46]
	Time taken saving stuff: 0.01s
episode: 1296/2000 -> reward: -124.99999999999793, steps:93408, time-taken: 4.27min, time-elasped: 4060.20min
-> berries picked: 177 of 800 | patches-visited: [1, 2, 3] | positive-in-buffer: 19129 | amount-filled: 100.00%
	| epsilon: 0.1760710509597417
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2245, 2212, 1891, 2026, 1809, 3239, 2484, 3223]
	| approx positives in sample 512: 235
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 25, 16, 29, 13, 48, 37, 40]
	Time taken saving stuff: 16.04s
episode: 1297/2000 -> reward: -124.9999999999973, steps:99744, time-taken: 4.49min, time-elasped: 4064.96min
-> berries picked: 200 of 800 | patches-visited: [0, 1, 4] | positive-in-buffer: 19237 | amount-filled: 100.00%
	| epsilon: 0.17592942024149824
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2254, 2227, 1905, 2034, 1820, 3269, 2493, 3235]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 33, 24, 15, 26, 34, 20, 44]
	Time taken saving stuff: 0.10s
episode: 1298/2000 -> reward: -124.999999999992, steps:67488, time-taken: 2.95min, time-elasped: 4067.92min
-> berries picked: 78 of 800 | patches-visited: [3] | positive-in-buffer: 19219 | amount-filled: 100.00%
	| epsilon: 0.17578790345033274
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2250, 2222, 1904, 2037, 1822, 3263, 2488, 3233]
	| approx positives in sample 512: 247
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 26, 18, 27, 18, 48, 43, 39]
	Time taken saving stuff: 0.16s
episode: 1299/2000 -> reward: -124.9999999999913, steps:74016, time-taken: 3.60min, time-elasped: 4071.53min
-> berries picked: 99 of 800 | patches-visited: [0, 7] | positive-in-buffer: 19285 | amount-filled: 100.00%
	| epsilon: 0.1756465004946028
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2258, 2229, 1911, 2043, 1830, 3272, 2499, 3243]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 28, 25, 29, 24, 30, 25, 40]
	Time taken saving stuff: 15.18s
episode: 1300/2000 -> reward: -124.99999999999808, steps:112320, time-taken: 5.56min, time-elasped: 4077.34min
-> berries picked: 248 of 800 | patches-visited: [4, 7, 8, 9] | positive-in-buffer: 19404 | amount-filled: 100.00%
	| epsilon: 0.17550521128273974
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2275, 2244, 1933, 2065, 1832, 3279, 2515, 3261]
	| approx positives in sample 512: 265
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 34, 28, 21, 20, 48, 35, 44]
	Time taken saving stuff: 0.08s
episode: 1301/2000 -> reward: -124.99999999999207, steps:67392, time-taken: 3.20min, time-elasped: 4080.54min
-> berries picked: 79 of 800 | patches-visited: [0] | positive-in-buffer: 19400 | amount-filled: 100.00%
	| epsilon: 0.1753640357232485
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2269, 2244, 1929, 2066, 1833, 3283, 2515, 3261]
	| approx positives in sample 512: 241
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 28, 22, 21, 28, 44, 29, 48]
	Time taken saving stuff: 0.05s
episode: 1302/2000 -> reward: -124.99999999999208, steps:61728, time-taken: 2.72min, time-elasped: 4083.26min
-> berries picked: 49 of 800 | patches-visited: [6] | positive-in-buffer: 19396 | amount-filled: 100.00%
	| epsilon: 0.17522297372470771
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2266, 2248, 1932, 2064, 1833, 3278, 2514, 3261]
	| approx positives in sample 512: 206
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 26, 12, 24, 19, 34, 32, 36]
	Time taken saving stuff: 15.32s
episode: 1303/2000 -> reward: -124.99999999999089, steps:80352, time-taken: 3.12min, time-elasped: 4086.64min
-> berries picked: 120 of 800 | patches-visited: [0, 3] | positive-in-buffer: 19317 | amount-filled: 100.00%
	| epsilon: 0.17508202519576946
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2258, 2243, 1932, 2058, 1825, 3265, 2502, 3234]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 21, 10, 22, 22, 33, 35, 34]
	Time taken saving stuff: 0.10s
episode: 1304/2000 -> reward: -124.99999999999295, steps:71712, time-taken: 3.00min, time-elasped: 4089.65min
-> berries picked: 98 of 800 | patches-visited: [5, 9] | positive-in-buffer: 19372 | amount-filled: 100.00%
	| epsilon: 0.17494119004515934
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2265, 2245, 1939, 2067, 1830, 3272, 2508, 3246]
	| approx positives in sample 512: 248
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 29, 22, 28, 17, 33, 37, 56]
	Time taken saving stuff: 0.03s
episode: 1305/2000 -> reward: -124.99999999998643, steps:91200, time-taken: 4.33min, time-elasped: 4093.98min
-> berries picked: 177 of 800 | patches-visited: [5, 7, 9] | positive-in-buffer: 19485 | amount-filled: 100.00%
	| epsilon: 0.17480046818167636
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2279, 2258, 1950, 2083, 1838, 3295, 2514, 3268]
	| approx positives in sample 512: 253
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 38, 19, 23, 27, 47, 41, 34]
	Time taken saving stuff: 14.59s
episode: 1306/2000 -> reward: -124.99999999999203, steps:73248, time-taken: 3.18min, time-elasped: 4097.41min
-> berries picked: 99 of 800 | patches-visited: [1, 4] | positive-in-buffer: 19521 | amount-filled: 100.00%
	| epsilon: 0.17465985951419286
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2281, 2260, 1956, 2095, 1834, 3301, 2519, 3275]
	| approx positives in sample 512: 235
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 29, 13, 25, 23, 39, 31, 46]
	Time taken saving stuff: 0.01s
episode: 1307/2000 -> reward: -124.99999999999243, steps:65856, time-taken: 2.35min, time-elasped: 4099.76min
-> berries picked: 77 of 800 | patches-visited: [7] | positive-in-buffer: 19485 | amount-filled: 100.00%
	| epsilon: 0.17451936395165457
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2276, 2260, 1961, 2087, 1836, 3295, 2512, 3258]
	| approx positives in sample 512: 199
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 24, 15, 21, 21, 34, 31, 31]
	Time taken saving stuff: 0.02s
episode: 1308/2000 -> reward: -124.99999999999244, steps:115200, time-taken: 5.36min, time-elasped: 4105.12min
-> berries picked: 254 of 800 | patches-visited: [2, 6, 8, 9] | positive-in-buffer: 19465 | amount-filled: 100.00%
	| epsilon: 0.17437898140308036
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2275, 2262, 1968, 2090, 1842, 3287, 2508, 3233]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 28, 19, 25, 20, 45, 25, 38]
	Time taken saving stuff: 15.03s
episode: 1309/2000 -> reward: -124.99999999999154, steps:66240, time-taken: 3.10min, time-elasped: 4108.47min
-> berries picked: 79 of 800 | patches-visited: [6] | positive-in-buffer: 19500 | amount-filled: 100.00%
	| epsilon: 0.17423871177756237
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2279, 2264, 1974, 2093, 1845, 3297, 2511, 3237]
	| approx positives in sample 512: 237
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 17, 19, 30, 22, 43, 38, 42]
	Time taken saving stuff: 0.02s
episode: 1310/2000 -> reward: -124.99999999999491, steps:94560, time-taken: 4.00min, time-elasped: 4112.48min
-> berries picked: 173 of 800 | patches-visited: [2, 4, 8] | positive-in-buffer: 19605 | amount-filled: 100.00%
	| epsilon: 0.17409855498426582
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2290, 2270, 1982, 2105, 1858, 3321, 2522, 3257]
	| approx positives in sample 512: 234
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 26, 22, 29, 21, 53, 22, 37]
	Time taken saving stuff: 0.11s
episode: 1311/2000 -> reward: -124.99999999999137, steps:64800, time-taken: 2.20min, time-elasped: 4114.68min
-> berries picked: 66 of 800 | patches-visited: [2] | positive-in-buffer: 19604 | amount-filled: 100.00%
	| epsilon: 0.17395851093242898
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2289, 2268, 1983, 2106, 1858, 3323, 2520, 3257]
	| approx positives in sample 512: 202
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 24, 17, 20, 18, 44, 26, 31]
	Time taken saving stuff: 14.43s
episode: 1312/2000 -> reward: -124.99999999998496, steps:85536, time-taken: 3.56min, time-elasped: 4118.49min
-> berries picked: 152 of 800 | patches-visited: [5, 7] | positive-in-buffer: 19301 | amount-filled: 100.00%
	| epsilon: 0.17381857953136318
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2264, 2247, 1947, 2068, 1843, 3276, 2479, 3177]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 25, 27, 27, 26, 31, 37, 25]
	Time taken saving stuff: 0.10s
episode: 1313/2000 -> reward: -124.99999999999922, steps:117312, time-taken: 5.35min, time-elasped: 4123.84min
-> berries picked: 274 of 800 | patches-visited: [1, 3, 7, 9] | positive-in-buffer: 19431 | amount-filled: 100.00%
	| epsilon: 0.17367876069045263
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2282, 2261, 1958, 2088, 1863, 3305, 2482, 3192]
	| approx positives in sample 512: 233
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 29, 25, 26, 21, 44, 27, 34]
	Time taken saving stuff: 0.01s
episode: 1314/2000 -> reward: -124.99999999998448, steps:84096, time-taken: 3.37min, time-elasped: 4127.22min
-> berries picked: 148 of 800 | patches-visited: [0, 7] | positive-in-buffer: 19519 | amount-filled: 100.00%
	| epsilon: 0.17353905431915456
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2291, 2272, 1968, 2094, 1870, 3329, 2492, 3203]
	| approx positives in sample 512: 208
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 28, 25, 20, 20, 35, 24, 33]
	Time taken saving stuff: 14.56s
episode: 1315/2000 -> reward: -124.99999999999206, steps:65280, time-taken: 2.45min, time-elasped: 4129.92min
-> berries picked: 72 of 800 | patches-visited: [6] | positive-in-buffer: 19315 | amount-filled: 100.00%
	| epsilon: 0.1733994603269989
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2259, 2244, 1949, 2082, 1857, 3289, 2477, 3158]
	| approx positives in sample 512: 206
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 17, 24, 21, 20, 37, 30, 33]
	Time taken saving stuff: 0.01s
episode: 1316/2000 -> reward: -124.99999999999321, steps:94464, time-taken: 4.57min, time-elasped: 4134.49min
-> berries picked: 180 of 800 | patches-visited: [1, 3, 8] | positive-in-buffer: 19261 | amount-filled: 100.00%
	| epsilon: 0.17325997862358838
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2257, 2227, 1948, 2081, 1850, 3277, 2471, 3150]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 23, 19, 36, 21, 39, 35, 29]
	Time taken saving stuff: 0.10s
episode: 1317/2000 -> reward: -124.99999999999233, steps:64608, time-taken: 2.45min, time-elasped: 4136.94min
-> berries picked: 64 of 800 | patches-visited: [3] | positive-in-buffer: 19292 | amount-filled: 100.00%
	| epsilon: 0.1731206091185985
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2256, 2228, 1954, 2085, 1855, 3282, 2478, 3154]
	| approx positives in sample 512: 196
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 29, 10, 28, 13, 27, 29, 32]
	Time taken saving stuff: 15.34s
episode: 1318/2000 -> reward: -124.99999999999167, steps:67200, time-taken: 3.26min, time-elasped: 4140.46min
-> berries picked: 80 of 800 | patches-visited: [8] | positive-in-buffer: 19206 | amount-filled: 100.00%
	| epsilon: 0.1729813517217774
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2247, 2214, 1947, 2081, 1856, 3276, 2462, 3123]
	| approx positives in sample 512: 254
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 30, 20, 38, 30, 51, 29, 30]
	Time taken saving stuff: 0.15s
episode: 1319/2000 -> reward: -124.99999999999227, steps:80256, time-taken: 3.25min, time-elasped: 4143.71min
-> berries picked: 131 of 800 | patches-visited: [0, 2] | positive-in-buffer: 19300 | amount-filled: 100.00%
	| epsilon: 0.17284220634294573
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2259, 2230, 1957, 2091, 1867, 3290, 2468, 3138]
	| approx positives in sample 512: 226
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 29, 22, 19, 19, 42, 35, 35]
	Time taken saving stuff: 0.01s
episode: 1320/2000 -> reward: -124.9999999999889, steps:99168, time-taken: 4.60min, time-elasped: 4148.31min
-> berries picked: 199 of 800 | patches-visited: [0, 1, 5] | positive-in-buffer: 19419 | amount-filled: 100.00%
	| epsilon: 0.1727031728919968
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2276, 2240, 1970, 2103, 1879, 3304, 2486, 3161]
	| approx positives in sample 512: 210
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 23, 19, 30, 22, 37, 20, 41]
	Time taken saving stuff: 15.18s
episode: 1321/2000 -> reward: -124.99999999999257, steps:64512, time-taken: 2.37min, time-elasped: 4150.93min
-> berries picked: 70 of 800 | patches-visited: [6] | positive-in-buffer: 19413 | amount-filled: 100.00%
	| epsilon: 0.17256425127889635
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2271, 2235, 1969, 2103, 1876, 3311, 2486, 3162]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 28, 22, 27, 16, 29, 26, 30]
	Time taken saving stuff: 0.01s
episode: 1322/2000 -> reward: -124.99999999999208, steps:67104, time-taken: 3.17min, time-elasped: 4154.10min
-> berries picked: 72 of 800 | patches-visited: [5] | positive-in-buffer: 19194 | amount-filled: 100.00%
	| epsilon: 0.17242544141368252
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2256, 2213, 1959, 2076, 1861, 3263, 2463, 3103]
	| approx positives in sample 512: 263
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 31, 20, 34, 19, 47, 36, 49]
	Time taken saving stuff: 0.09s
episode: 1323/2000 -> reward: -124.99999999999092, steps:73728, time-taken: 3.36min, time-elasped: 4157.47min
-> berries picked: 96 of 800 | patches-visited: [1, 9] | positive-in-buffer: 19263 | amount-filled: 100.00%
	| epsilon: 0.1722867432064659
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2259, 2217, 1969, 2086, 1869, 3274, 2471, 3118]
	| approx positives in sample 512: 266
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 28, 25, 21, 24, 50, 41, 44]
	Time taken saving stuff: 12.63s
episode: 1324/2000 -> reward: -124.99999999999224, steps:86880, time-taken: 3.44min, time-elasped: 4161.12min
-> berries picked: 159 of 800 | patches-visited: [4, 6] | positive-in-buffer: 19359 | amount-filled: 100.00%
	| epsilon: 0.17214815656742924
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2270, 2228, 1977, 2098, 1877, 3294, 2480, 3135]
	| approx positives in sample 512: 186
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 19, 17, 18, 20, 31, 33, 29]
	Time taken saving stuff: 0.10s
episode: 1325/2000 -> reward: -124.99999999998467, steps:79680, time-taken: 3.50min, time-elasped: 4164.62min
-> berries picked: 118 of 800 | patches-visited: [0, 5] | positive-in-buffer: 19245 | amount-filled: 100.00%
	| epsilon: 0.17200968140682768
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2262, 2221, 1960, 2088, 1870, 3279, 2457, 3108]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 35, 19, 21, 20, 32, 29, 39]
	Time taken saving stuff: 0.01s
episode: 1326/2000 -> reward: -124.99999999999204, steps:64512, time-taken: 2.34min, time-elasped: 4166.97min
-> berries picked: 66 of 800 | patches-visited: [6] | positive-in-buffer: 19256 | amount-filled: 100.00%
	| epsilon: 0.17187131763498847
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2262, 2224, 1959, 2093, 1870, 3279, 2460, 3109]
	| approx positives in sample 512: 205
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 22, 19, 26, 22, 37, 24, 27]
	Time taken saving stuff: 12.03s
episode: 1327/2000 -> reward: -124.99999999998943, steps:84672, time-taken: 3.57min, time-elasped: 4170.74min
-> berries picked: 148 of 800 | patches-visited: [2, 9] | positive-in-buffer: 19224 | amount-filled: 100.00%
	| epsilon: 0.17173306516231107
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2251, 2219, 1956, 2106, 1870, 3264, 2457, 3101]
	| approx positives in sample 512: 195
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 23, 22, 15, 18, 29, 28, 36]
	Time taken saving stuff: 0.01s
episode: 1328/2000 -> reward: -124.99999999999316, steps:72288, time-taken: 3.53min, time-elasped: 4174.28min
-> berries picked: 93 of 800 | patches-visited: [5, 6] | positive-in-buffer: 19238 | amount-filled: 100.00%
	| epsilon: 0.1715949238992669
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2255, 2217, 1961, 2103, 1876, 3267, 2462, 3097]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 32, 25, 27, 24, 40, 28, 28]
	Time taken saving stuff: 0.11s
episode: 1329/2000 -> reward: -124.99999999999523, steps:101856, time-taken: 4.85min, time-elasped: 4179.13min
-> berries picked: 214 of 800 | patches-visited: [1, 4, 6] | positive-in-buffer: 19379 | amount-filled: 100.00%
	| epsilon: 0.1714568937563995
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2269, 2232, 1976, 2114, 1889, 3296, 2477, 3126]
	| approx positives in sample 512: 204
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 15, 24, 22, 22, 33, 35, 28]
	Time taken saving stuff: 15.37s
episode: 1330/2000 -> reward: -124.9999999999915, steps:66240, time-taken: 3.20min, time-elasped: 4182.60min
-> berries picked: 71 of 800 | patches-visited: [8] | positive-in-buffer: 19343 | amount-filled: 100.00%
	| epsilon: 0.1713189746443243
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2275, 2231, 1974, 2110, 1889, 3285, 2471, 3108]
	| approx positives in sample 512: 268
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 29, 24, 33, 21, 56, 27, 45]
	Time taken saving stuff: 0.07s
episode: 1331/2000 -> reward: -124.99999999999902, steps:108864, time-taken: 4.59min, time-elasped: 4187.19min
-> berries picked: 224 of 800 | patches-visited: [3, 6, 7, 8] | positive-in-buffer: 19471 | amount-filled: 100.00%
	| epsilon: 0.1711811664737287
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2287, 2239, 1997, 2126, 1899, 3309, 2481, 3133]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 31, 17, 27, 23, 32, 29, 33]
	Time taken saving stuff: 0.00s
episode: 1332/2000 -> reward: -124.99999999999609, steps:86400, time-taken: 3.49min, time-elasped: 4190.68min
-> berries picked: 156 of 800 | patches-visited: [6, 9] | positive-in-buffer: 19220 | amount-filled: 100.00%
	| epsilon: 0.17104346915537183
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2266, 2223, 1971, 2114, 1870, 3279, 2452, 3045]
	| approx positives in sample 512: 197
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 30, 23, 19, 20, 29, 31, 25]
	Time taken saving stuff: 12.53s
episode: 1333/2000 -> reward: -124.99999999999233, steps:64800, time-taken: 2.44min, time-elasped: 4193.33min
-> berries picked: 72 of 800 | patches-visited: [8] | positive-in-buffer: 19137 | amount-filled: 100.00%
	| epsilon: 0.17090588260008474
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2256, 2225, 1964, 2117, 1856, 3260, 2431, 3028]
	| approx positives in sample 512: 195
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 19, 18, 20, 19, 39, 29, 32]
	Time taken saving stuff: 0.01s
episode: 1334/2000 -> reward: -124.99999999999189, steps:63648, time-taken: 2.25min, time-elasped: 4195.59min
-> berries picked: 65 of 800 | patches-visited: [6] | positive-in-buffer: 19108 | amount-filled: 100.00%
	| epsilon: 0.1707684067187701
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2247, 2223, 1963, 2120, 1859, 3255, 2428, 3013]
	| approx positives in sample 512: 202
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 22, 22, 15, 21, 44, 29, 26]
	Time taken saving stuff: 0.09s
episode: 1335/2000 -> reward: -124.99999999999206, steps:66144, time-taken: 2.99min, time-elasped: 4198.58min
-> berries picked: 68 of 800 | patches-visited: [1] | positive-in-buffer: 19123 | amount-filled: 100.00%
	| epsilon: 0.17063104142240232
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2252, 2225, 1964, 2129, 1861, 3255, 2424, 3013]
	| approx positives in sample 512: 239
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [36, 18, 20, 31, 13, 42, 40, 39]
	Time taken saving stuff: 11.73s
episode: 1336/2000 -> reward: -124.99999999999203, steps:57696, time-taken: 2.11min, time-elasped: 4200.89min
-> berries picked: 33 of 800 | patches-visited: [8] | positive-in-buffer: 19141 | amount-filled: 100.00%
	| epsilon: 0.17049378662202738
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2253, 2226, 1967, 2135, 1861, 3260, 2425, 3014]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 31, 28, 30, 15, 31, 23, 46]
	Time taken saving stuff: 0.12s
episode: 1337/2000 -> reward: -124.99999999997539, steps:119424, time-taken: 5.68min, time-elasped: 4206.57min
-> berries picked: 286 of 800 | patches-visited: [3, 4, 5, 6] | positive-in-buffer: 19318 | amount-filled: 100.00%
	| epsilon: 0.17035664222876284
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2270, 2242, 1993, 2159, 1880, 3296, 2440, 3038]
	| approx positives in sample 512: 241
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 25, 27, 34, 23, 45, 26, 32]
	Time taken saving stuff: 0.01s
episode: 1338/2000 -> reward: -124.99999999999227, steps:65088, time-taken: 2.37min, time-elasped: 4208.95min
-> berries picked: 65 of 800 | patches-visited: [7] | positive-in-buffer: 19307 | amount-filled: 100.00%
	| epsilon: 0.17021960815379766
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2267, 2243, 1989, 2151, 1882, 3294, 2442, 3039]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 37, 21, 24, 19, 42, 21, 22]
	Time taken saving stuff: 12.58s
episode: 1339/2000 -> reward: -124.99999999999194, steps:61920, time-taken: 2.33min, time-elasped: 4211.49min
-> berries picked: 52 of 800 | patches-visited: [3] | positive-in-buffer: 19106 | amount-filled: 100.00%
	| epsilon: 0.17008268430839246
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2245, 2230, 1971, 2128, 1867, 3254, 2413, 2998]
	| approx positives in sample 512: 206
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 16, 10, 26, 17, 42, 35, 26]
	Time taken saving stuff: 0.01s
episode: 1340/2000 -> reward: -124.99999999999098, steps:65280, time-taken: 2.48min, time-elasped: 4213.98min
-> berries picked: 71 of 800 | patches-visited: [5] | positive-in-buffer: 19141 | amount-filled: 100.00%
	| epsilon: 0.16994587060387903
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2251, 2230, 1978, 2133, 1872, 3260, 2415, 3002]
	| approx positives in sample 512: 202
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 28, 18, 19, 18, 28, 32, 36]
	Time taken saving stuff: 0.09s
episode: 1341/2000 -> reward: -124.99999999999592, steps:73920, time-taken: 3.48min, time-elasped: 4217.46min
-> berries picked: 94 of 800 | patches-visited: [1, 5] | positive-in-buffer: 19131 | amount-filled: 100.00%
	| epsilon: 0.16980916695166057
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2244, 2221, 1979, 2140, 1874, 3255, 2415, 3003]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 33, 16, 22, 23, 45, 31, 38]
	Time taken saving stuff: 12.15s
episode: 1342/2000 -> reward: -124.99999999999109, steps:83712, time-taken: 3.49min, time-elasped: 4221.16min
-> berries picked: 139 of 800 | patches-visited: [2, 7] | positive-in-buffer: 19230 | amount-filled: 100.00%
	| epsilon: 0.16967257326321156
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2261, 2227, 1988, 2158, 1878, 3278, 2420, 3020]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 30, 13, 26, 24, 39, 27, 42]
	Time taken saving stuff: 0.03s
episode: 1343/2000 -> reward: -124.99999999999139, steps:82368, time-taken: 3.38min, time-elasped: 4224.54min
-> berries picked: 124 of 800 | patches-visited: [8, 9] | positive-in-buffer: 19239 | amount-filled: 100.00%
	| epsilon: 0.16953608945007761
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2262, 2232, 1986, 2162, 1885, 3277, 2417, 3018]
	| approx positives in sample 512: 205
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 21, 14, 19, 23, 35, 27, 35]
	Time taken saving stuff: 0.01s
episode: 1344/2000 -> reward: -124.99999999999208, steps:63840, time-taken: 2.54min, time-elasped: 4227.08min
-> berries picked: 65 of 800 | patches-visited: [2] | positive-in-buffer: 19230 | amount-filled: 100.00%
	| epsilon: 0.16939971542387558
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2259, 2230, 1984, 2159, 1880, 3278, 2422, 3018]
	| approx positives in sample 512: 201
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 22, 25, 22, 18, 41, 20, 31]
	Time taken saving stuff: 15.04s
episode: 1345/2000 -> reward: -124.9999999999936, steps:83520, time-taken: 3.46min, time-elasped: 4230.79min
-> berries picked: 129 of 800 | patches-visited: [1, 2] | positive-in-buffer: 19210 | amount-filled: 100.00%
	| epsilon: 0.16926345109629334
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2249, 2234, 1975, 2161, 1881, 3273, 2425, 3012]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 17, 19, 20, 14, 46, 27, 39]
	Time taken saving stuff: 0.01s
episode: 1346/2000 -> reward: -124.99999999999203, steps:63648, time-taken: 2.39min, time-elasped: 4233.18min
-> berries picked: 66 of 800 | patches-visited: [3] | positive-in-buffer: 19227 | amount-filled: 100.00%
	| epsilon: 0.1691272963790899
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2253, 2229, 1980, 2161, 1880, 3278, 2431, 3015]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 20, 16, 28, 23, 37, 27, 42]
	Time taken saving stuff: 0.10s
episode: 1347/2000 -> reward: -124.9999999999917, steps:78048, time-taken: 3.62min, time-elasped: 4236.81min
-> berries picked: 116 of 800 | patches-visited: [4, 8] | positive-in-buffer: 19229 | amount-filled: 100.00%
	| epsilon: 0.1689912511840952
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2249, 2223, 1967, 2166, 1885, 3279, 2435, 3025]
	| approx positives in sample 512: 233
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 31, 14, 24, 33, 41, 25, 37]
	Time taken saving stuff: 15.13s
episode: 1348/2000 -> reward: -124.9999999999918, steps:73440, time-taken: 3.45min, time-elasped: 4240.51min
-> berries picked: 86 of 800 | patches-visited: [5, 9] | positive-in-buffer: 19287 | amount-filled: 100.00%
	| epsilon: 0.16885531542321
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2256, 2228, 1971, 2174, 1894, 3288, 2444, 3032]
	| approx positives in sample 512: 253
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 21, 31, 29, 34, 52, 30, 36]
	Time taken saving stuff: 0.06s
episode: 1349/2000 -> reward: -124.99999999999193, steps:60672, time-taken: 2.31min, time-elasped: 4242.82min
-> berries picked: 39 of 800 | patches-visited: [4] | positive-in-buffer: 19321 | amount-filled: 100.00%
	| epsilon: 0.1687194890084061
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2258, 2232, 1976, 2179, 1898, 3295, 2446, 3037]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 19, 26, 29, 24, 33, 24, 30]
	Time taken saving stuff: 0.01s
episode: 1350/2000 -> reward: -124.99999999999454, steps:97536, time-taken: 4.37min, time-elasped: 4247.20min
-> berries picked: 197 of 800 | patches-visited: [0, 1, 4] | positive-in-buffer: 19395 | amount-filled: 100.00%
	| epsilon: 0.16858377185172596
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2271, 2237, 1979, 2188, 1911, 3314, 2453, 3042]
	| approx positives in sample 512: 238
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 24, 16, 24, 23, 37, 32, 47]
	Time taken saving stuff: 14.99s
episode: 1351/2000 -> reward: -124.99999999999054, steps:87072, time-taken: 3.32min, time-elasped: 4250.77min
-> berries picked: 151 of 800 | patches-visited: [0, 7, 9] | positive-in-buffer: 19470 | amount-filled: 100.00%
	| epsilon: 0.16844816386528297
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2274, 2246, 1986, 2202, 1920, 3325, 2460, 3057]
	| approx positives in sample 512: 196
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 23, 15, 26, 24, 35, 21, 26]
	Time taken saving stuff: 0.01s
episode: 1352/2000 -> reward: -124.99999999999082, steps:83424, time-taken: 3.41min, time-elasped: 4254.18min
-> berries picked: 139 of 800 | patches-visited: [2, 3] | positive-in-buffer: 19319 | amount-filled: 100.00%
	| epsilon: 0.16831266496126104
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2255, 2228, 1975, 2186, 1899, 3320, 2444, 3012]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 22, 22, 23, 18, 53, 30, 33]
	Time taken saving stuff: 0.10s
episode: 1353/2000 -> reward: -124.99999999998373, steps:76416, time-taken: 3.36min, time-elasped: 4257.55min
-> berries picked: 107 of 800 | patches-visited: [3, 6] | positive-in-buffer: 19378 | amount-filled: 100.00%
	| epsilon: 0.16817727505191482
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2267, 2233, 1982, 2189, 1908, 3328, 2451, 3020]
	| approx positives in sample 512: 257
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [36, 21, 24, 43, 22, 43, 33, 35]
	Time taken saving stuff: 15.07s
episode: 1354/2000 -> reward: -124.99999999999095, steps:81888, time-taken: 3.31min, time-elasped: 4261.11min
-> berries picked: 130 of 800 | patches-visited: [0, 6] | positive-in-buffer: 19437 | amount-filled: 100.00%
	| epsilon: 0.16804199404956946
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2264, 2239, 1985, 2203, 1910, 3343, 2464, 3029]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 30, 17, 23, 15, 36, 33, 35]
	Time taken saving stuff: 0.10s
episode: 1355/2000 -> reward: -124.99999999999206, steps:66336, time-taken: 3.11min, time-elasped: 4264.22min
-> berries picked: 75 of 800 | patches-visited: [5] | positive-in-buffer: 19394 | amount-filled: 100.00%
	| epsilon: 0.16790682186662073
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2261, 2235, 1983, 2195, 1907, 3333, 2458, 3022]
	| approx positives in sample 512: 256
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 27, 21, 23, 36, 47, 33, 39]
	Time taken saving stuff: 0.01s
episode: 1356/2000 -> reward: -124.99999999999201, steps:58080, time-taken: 2.17min, time-elasped: 4266.39min
-> berries picked: 33 of 800 | patches-visited: [3] | positive-in-buffer: 19425 | amount-filled: 100.00%
	| epsilon: 0.16777175841553482
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2265, 2239, 1993, 2197, 1912, 3336, 2459, 3024]
	| approx positives in sample 512: 205
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 30, 11, 26, 26, 34, 24, 32]
	Time taken saving stuff: 15.32s
episode: 1357/2000 -> reward: -124.99999999999221, steps:82656, time-taken: 3.23min, time-elasped: 4269.88min
-> berries picked: 140 of 800 | patches-visited: [0, 2] | positive-in-buffer: 19457 | amount-filled: 100.00%
	| epsilon: 0.1676368036088483
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2263, 2243, 1995, 2206, 1913, 3343, 2461, 3033]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 20, 26, 21, 19, 33, 29, 31]
	Time taken saving stuff: 0.01s
episode: 1358/2000 -> reward: -124.99999999998691, steps:96384, time-taken: 4.12min, time-elasped: 4274.00min
-> berries picked: 192 of 800 | patches-visited: [2, 5, 6] | positive-in-buffer: 19427 | amount-filled: 100.00%
	| epsilon: 0.16750195735916817
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2268, 2242, 1994, 2209, 1911, 3328, 2457, 3018]
	| approx positives in sample 512: 230
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 30, 23, 27, 18, 39, 39, 39]
	Time taken saving stuff: 0.02s
episode: 1359/2000 -> reward: -124.99999999999226, steps:67008, time-taken: 2.96min, time-elasped: 4276.96min
-> berries picked: 79 of 800 | patches-visited: [3] | positive-in-buffer: 19459 | amount-filled: 100.00%
	| epsilon: 0.1673672195791717
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2271, 2240, 1996, 2208, 1915, 3341, 2462, 3026]
	| approx positives in sample 512: 245
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 30, 21, 23, 17, 44, 27, 54]
	Time taken saving stuff: 15.14s
episode: 1360/2000 -> reward: -98.9999999999838, steps:120000, time-taken: 5.14min, time-elasped: 4282.36min
-> berries picked: 320 of 800 | patches-visited: [1, 2, 4, 7, 9] | positive-in-buffer: 19654 | amount-filled: 100.00%
	| epsilon: 0.16723259018160633
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2289, 2262, 2011, 2226, 1933, 3392, 2480, 3061]
	| approx positives in sample 512: 226
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 32, 20, 19, 22, 42, 29, 32]
	Time taken saving stuff: 0.10s
episode: 1361/2000 -> reward: -124.99999999999076, steps:97344, time-taken: 4.34min, time-elasped: 4286.70min
-> berries picked: 179 of 800 | patches-visited: [0, 2, 4, 6] | positive-in-buffer: 19639 | amount-filled: 100.00%
	| epsilon: 0.16709806907928978
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2290, 2262, 2025, 2219, 1934, 3388, 2473, 3048]
	| approx positives in sample 512: 226
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 22, 27, 28, 10, 38, 38, 36]
	Time taken saving stuff: 0.01s
episode: 1362/2000 -> reward: -124.99999999999221, steps:82656, time-taken: 3.08min, time-elasped: 4289.78min
-> berries picked: 131 of 800 | patches-visited: [1, 5] | positive-in-buffer: 19634 | amount-filled: 100.00%
	| epsilon: 0.1669636561851099
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2299, 2257, 2029, 2221, 1934, 3375, 2479, 3040]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 19, 17, 21, 21, 41, 24, 30]
	Time taken saving stuff: 15.00s
episode: 1363/2000 -> reward: -124.9999999999918, steps:63456, time-taken: 2.19min, time-elasped: 4292.23min
-> berries picked: 63 of 800 | patches-visited: [1] | positive-in-buffer: 19416 | amount-filled: 100.00%
	| epsilon: 0.16682935141202446
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2265, 2232, 2002, 2202, 1913, 3350, 2457, 2995]
	| approx positives in sample 512: 204
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 24, 11, 23, 25, 41, 27, 30]
	Time taken saving stuff: 0.01s
episode: 1364/2000 -> reward: -124.999999999993, steps:81312, time-taken: 3.09min, time-elasped: 4295.32min
-> berries picked: 142 of 800 | patches-visited: [6, 7] | positive-in-buffer: 19394 | amount-filled: 100.00%
	| epsilon: 0.1666951546730615
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2256, 2230, 2001, 2201, 1918, 3353, 2449, 2986]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 29, 16, 25, 18, 35, 26, 40]
	Time taken saving stuff: 0.02s
episode: 1365/2000 -> reward: -124.99999999999572, steps:84864, time-taken: 3.24min, time-elasped: 4298.57min
-> berries picked: 142 of 800 | patches-visited: [3, 8] | positive-in-buffer: 19486 | amount-filled: 100.00%
	| epsilon: 0.16656106588131886
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2265, 2233, 2007, 2219, 1931, 3367, 2460, 3004]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 24, 18, 25, 13, 41, 34, 35]
	Time taken saving stuff: 12.88s
episode: 1366/2000 -> reward: -124.99999999999164, steps:99168, time-taken: 4.15min, time-elasped: 4302.93min
-> berries picked: 201 of 800 | patches-visited: [2, 5, 6, 8] | positive-in-buffer: 19487 | amount-filled: 100.00%
	| epsilon: 0.16642708494996425
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2256, 2232, 2016, 2215, 1927, 3365, 2464, 3012]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 22, 19, 25, 17, 57, 23, 37]
	Time taken saving stuff: 0.02s
episode: 1367/2000 -> reward: -124.99999999999211, steps:71136, time-taken: 3.12min, time-elasped: 4306.05min
-> berries picked: 89 of 800 | patches-visited: [4, 5] | positive-in-buffer: 19511 | amount-filled: 100.00%
	| epsilon: 0.16629321179223533
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2259, 2238, 2013, 2215, 1933, 3374, 2465, 3014]
	| approx positives in sample 512: 259
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 31, 27, 27, 29, 42, 38, 37]
	Time taken saving stuff: 0.10s
episode: 1368/2000 -> reward: -124.9999999999847, steps:87840, time-taken: 3.39min, time-elasped: 4309.44min
-> berries picked: 154 of 800 | patches-visited: [2, 7, 8] | positive-in-buffer: 19610 | amount-filled: 100.00%
	| epsilon: 0.1661594463214395
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2268, 2249, 2021, 2224, 1947, 3397, 2480, 3024]
	| approx positives in sample 512: 196
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 28, 22, 33, 12, 28, 23, 23]
	Time taken saving stuff: 12.26s
episode: 1369/2000 -> reward: -124.99999999999167, steps:67680, time-taken: 2.87min, time-elasped: 4312.52min
-> berries picked: 80 of 800 | patches-visited: [5] | positive-in-buffer: 19435 | amount-filled: 100.00%
	| epsilon: 0.1660257884509539
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2242, 2225, 2006, 2207, 1943, 3351, 2465, 2996]
	| approx positives in sample 512: 265
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 32, 23, 32, 29, 45, 29, 40]
	Time taken saving stuff: 0.16s
episode: 1370/2000 -> reward: -114.99999999999037, steps:120000, time-taken: 5.21min, time-elasped: 4317.73min
-> berries picked: 293 of 800 | patches-visited: [0, 1, 3, 4, 7] | positive-in-buffer: 19650 | amount-filled: 100.00%
	| epsilon: 0.16589223809422532
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2261, 2252, 2037, 2230, 1958, 3394, 2482, 3036]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 29, 19, 27, 26, 42, 29, 30]
	Time taken saving stuff: 0.11s
episode: 1371/2000 -> reward: -124.99999999998525, steps:78912, time-taken: 3.39min, time-elasped: 4321.13min
-> berries picked: 119 of 800 | patches-visited: [0, 9] | positive-in-buffer: 19709 | amount-filled: 100.00%
	| epsilon: 0.16575879516477024
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2265, 2261, 2037, 2239, 1968, 3409, 2486, 3044]
	| approx positives in sample 512: 234
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 33, 19, 25, 25, 39, 29, 39]
	Time taken saving stuff: 12.04s
episode: 1372/2000 -> reward: -124.99999999999092, steps:84192, time-taken: 3.04min, time-elasped: 4324.37min
-> berries picked: 148 of 800 | patches-visited: [2, 4] | positive-in-buffer: 19666 | amount-filled: 100.00%
	| epsilon: 0.16562545957617467
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2266, 2260, 2039, 2240, 1962, 3392, 2480, 3027]
	| approx positives in sample 512: 186
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 20, 17, 23, 18, 39, 27, 29]
	Time taken saving stuff: 0.11s
episode: 1373/2000 -> reward: -124.99999999999203, steps:56064, time-taken: 2.12min, time-elasped: 4326.50min
-> berries picked: 33 of 800 | patches-visited: [3] | positive-in-buffer: 19395 | amount-filled: 100.00%
	| epsilon: 0.1654922312420941
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2237, 2228, 2007, 2202, 1938, 3337, 2465, 2981]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 33, 26, 25, 16, 39, 22, 32]
	Time taken saving stuff: 0.01s
episode: 1374/2000 -> reward: -124.99999999999211, steps:66528, time-taken: 3.08min, time-elasped: 4329.58min
-> berries picked: 69 of 800 | patches-visited: [4] | positive-in-buffer: 19445 | amount-filled: 100.00%
	| epsilon: 0.16535911007625356
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2239, 2232, 2013, 2205, 1945, 3348, 2469, 2994]
	| approx positives in sample 512: 249
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 20, 21, 28, 30, 46, 38, 43]
	Time taken saving stuff: 11.82s
episode: 1375/2000 -> reward: -124.9999999999955, steps:81600, time-taken: 3.02min, time-elasped: 4332.80min
-> berries picked: 140 of 800 | patches-visited: [0, 6] | positive-in-buffer: 19527 | amount-filled: 100.00%
	| epsilon: 0.16522609599244736
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2242, 2244, 2023, 2217, 1953, 3368, 2475, 3005]
	| approx positives in sample 512: 203
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 20, 14, 23, 21, 43, 26, 35]
	Time taken saving stuff: 0.11s
episode: 1376/2000 -> reward: -124.99999999999231, steps:65568, time-taken: 2.29min, time-elasped: 4335.09min
-> berries picked: 69 of 800 | patches-visited: [8] | positive-in-buffer: 19482 | amount-filled: 100.00%
	| epsilon: 0.16509318890453928
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2237, 2238, 2024, 2216, 1953, 3359, 2468, 2987]
	| approx positives in sample 512: 195
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 35, 15, 25, 19, 30, 27, 22]
	Time taken saving stuff: 0.12s
episode: 1377/2000 -> reward: -124.99999999999443, steps:84000, time-taken: 3.13min, time-elasped: 4338.23min
-> berries picked: 145 of 800 | patches-visited: [5, 7] | positive-in-buffer: 19390 | amount-filled: 100.00%
	| epsilon: 0.1649603887264623
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2222, 2229, 2025, 2210, 1951, 3352, 2446, 2955]
	| approx positives in sample 512: 201
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 26, 22, 26, 25, 24, 26, 28]
	Time taken saving stuff: 12.55s
episode: 1378/2000 -> reward: -124.99999999999467, steps:101568, time-taken: 4.03min, time-elasped: 4342.47min
-> berries picked: 217 of 800 | patches-visited: [0, 6, 9] | positive-in-buffer: 19525 | amount-filled: 100.00%
	| epsilon: 0.16482769537221867
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2232, 2246, 2042, 2229, 1964, 3379, 2457, 2976]
	| approx positives in sample 512: 203
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 20, 25, 25, 22, 38, 25, 25]
	Time taken saving stuff: 0.04s
episode: 1379/2000 -> reward: -124.99999999999235, steps:68448, time-taken: 2.98min, time-elasped: 4345.45min
-> berries picked: 74 of 800 | patches-visited: [9] | positive-in-buffer: 19534 | amount-filled: 100.00%
	| epsilon: 0.16469510875587978
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2230, 2244, 2041, 2230, 1968, 3382, 2462, 2977]
	| approx positives in sample 512: 237
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 31, 26, 29, 20, 48, 27, 27]
	Time taken saving stuff: 0.02s
episode: 1380/2000 -> reward: -124.99999999999339, steps:102144, time-taken: 4.13min, time-elasped: 4349.59min
-> berries picked: 214 of 800 | patches-visited: [0, 5, 7] | positive-in-buffer: 19659 | amount-filled: 100.00%
	| epsilon: 0.1645626287915862
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2237, 2262, 2051, 2247, 1988, 3404, 2477, 2993]
	| approx positives in sample 512: 236
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 33, 31, 30, 29, 41, 28, 26]
	Time taken saving stuff: 12.34s
episode: 1381/2000 -> reward: -124.99999999999515, steps:84960, time-taken: 3.14min, time-elasped: 4352.94min
-> berries picked: 150 of 800 | patches-visited: [1, 5] | positive-in-buffer: 19579 | amount-filled: 100.00%
	| epsilon: 0.1644302553935475
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2235, 2244, 2050, 2237, 1975, 3396, 2465, 2977]
	| approx positives in sample 512: 202
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 19, 24, 23, 20, 27, 30, 34]
	Time taken saving stuff: 0.01s
episode: 1382/2000 -> reward: -124.99999999999105, steps:76512, time-taken: 3.03min, time-elasped: 4355.97min
-> berries picked: 112 of 800 | patches-visited: [3, 8] | positive-in-buffer: 19492 | amount-filled: 100.00%
	| epsilon: 0.1642979884760423
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2221, 2234, 2039, 2235, 1972, 3370, 2455, 2966]
	| approx positives in sample 512: 233
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 36, 21, 28, 27, 34, 26, 34]
	Time taken saving stuff: 0.11s
episode: 1383/2000 -> reward: -124.99999999998127, steps:119616, time-taken: 5.23min, time-elasped: 4361.21min
-> berries picked: 287 of 800 | patches-visited: [1, 2, 5, 6] | positive-in-buffer: 19678 | amount-filled: 100.00%
	| epsilon: 0.16416582795341816
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2241, 2244, 2071, 2269, 1989, 3400, 2474, 2990]
	| approx positives in sample 512: 207
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 36, 19, 28, 17, 32, 29, 29]
	Time taken saving stuff: 11.68s
episode: 1384/2000 -> reward: -124.99999999999247, steps:75264, time-taken: 3.03min, time-elasped: 4364.43min
-> berries picked: 108 of 800 | patches-visited: [4, 7] | positive-in-buffer: 19700 | amount-filled: 100.00%
	| epsilon: 0.16403377374009157
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2244, 2251, 2070, 2262, 1994, 3414, 2475, 2990]
	| approx positives in sample 512: 247
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 29, 22, 29, 26, 42, 37, 33]
	Time taken saving stuff: 0.03s
episode: 1385/2000 -> reward: -124.99999999999206, steps:62016, time-taken: 2.04min, time-elasped: 4366.48min
-> berries picked: 54 of 800 | patches-visited: [5] | positive-in-buffer: 19670 | amount-filled: 100.00%
	| epsilon: 0.16390182575054782
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2241, 2248, 2066, 2263, 1989, 3409, 2470, 2984]
	| approx positives in sample 512: 201
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 29, 18, 23, 24, 28, 35, 24]
	Time taken saving stuff: 0.09s
episode: 1386/2000 -> reward: -124.99999999999218, steps:99936, time-taken: 4.13min, time-elasped: 4370.61min
-> berries picked: 201 of 800 | patches-visited: [3, 6, 8] | positive-in-buffer: 19552 | amount-filled: 100.00%
	| epsilon: 0.16376998389934097
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2218, 2248, 2072, 2254, 1982, 3384, 2450, 2944]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 27, 25, 28, 26, 31, 18, 34]
	Time taken saving stuff: 11.70s
episode: 1387/2000 -> reward: -124.99999999999199, steps:57600, time-taken: 2.08min, time-elasped: 4372.89min
-> berries picked: 38 of 800 | patches-visited: [2] | positive-in-buffer: 19561 | amount-filled: 100.00%
	| epsilon: 0.16363824810109384
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2223, 2246, 2073, 2259, 1985, 3385, 2447, 2943]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 26, 19, 19, 25, 38, 20, 35]
	Time taken saving stuff: 0.02s
episode: 1388/2000 -> reward: -124.99999999999334, steps:98976, time-taken: 4.17min, time-elasped: 4377.06min
-> berries picked: 216 of 800 | patches-visited: [4, 5, 9] | positive-in-buffer: 19667 | amount-filled: 100.00%
	| epsilon: 0.163506618270498
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2232, 2258, 2082, 2277, 2003, 3402, 2456, 2957]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 29, 24, 22, 23, 35, 27, 28]
	Time taken saving stuff: 0.01s
episode: 1389/2000 -> reward: -124.99999999999251, steps:69312, time-taken: 3.09min, time-elasped: 4380.16min
-> berries picked: 87 of 800 | patches-visited: [7, 9] | positive-in-buffer: 19678 | amount-filled: 100.00%
	| epsilon: 0.16337509432231356
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2235, 2254, 2079, 2275, 2004, 3414, 2453, 2964]
	| approx positives in sample 512: 238
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 26, 23, 24, 17, 49, 32, 37]
	Time taken saving stuff: 15.20s
episode: 1390/2000 -> reward: -124.99999999999211, steps:65760, time-taken: 2.18min, time-elasped: 4382.60min
-> berries picked: 75 of 800 | patches-visited: [4] | positive-in-buffer: 19713 | amount-filled: 100.00%
	| epsilon: 0.16324367617136917
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2239, 2253, 2084, 2282, 2009, 3419, 2458, 2969]
	| approx positives in sample 512: 199
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 18, 21, 22, 14, 42, 32, 29]
	Time taken saving stuff: 0.00s
episode: 1391/2000 -> reward: -124.99999999999046, steps:84864, time-taken: 3.19min, time-elasped: 4385.79min
-> berries picked: 150 of 800 | patches-visited: [1, 6] | positive-in-buffer: 19515 | amount-filled: 100.00%
	| epsilon: 0.16311236373256208
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2221, 2238, 2077, 2238, 1991, 3363, 2438, 2949]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 20, 20, 23, 23, 48, 29, 37]
	Time taken saving stuff: 0.10s
episode: 1392/2000 -> reward: -124.9999999999949, steps:80160, time-taken: 3.20min, time-elasped: 4389.00min
-> berries picked: 123 of 800 | patches-visited: [3, 4] | positive-in-buffer: 19577 | amount-filled: 100.00%
	| epsilon: 0.16298115692085788
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2228, 2245, 2089, 2250, 1991, 3372, 2443, 2959]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 22, 18, 30, 19, 40, 33, 30]
	Time taken saving stuff: 11.44s
episode: 1393/2000 -> reward: -124.99999999999285, steps:82272, time-taken: 3.25min, time-elasped: 4392.44min
-> berries picked: 136 of 800 | patches-visited: [3, 7] | positive-in-buffer: 19664 | amount-filled: 100.00%
	| epsilon: 0.16285005565129068
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2242, 2252, 2103, 2258, 1996, 3394, 2449, 2970]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 23, 24, 23, 31, 27, 34, 28]
	Time taken saving stuff: 0.02s
episode: 1394/2000 -> reward: -124.9999999999911, steps:81984, time-taken: 3.08min, time-elasped: 4395.53min
-> berries picked: 126 of 800 | patches-visited: [7, 8] | positive-in-buffer: 19671 | amount-filled: 100.00%
	| epsilon: 0.16271905983896287
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2241, 2250, 2103, 2265, 1994, 3397, 2449, 2972]
	| approx positives in sample 512: 198
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 26, 22, 23, 19, 29, 16, 40]
	Time taken saving stuff: 0.00s
episode: 1395/2000 -> reward: -124.99999999999196, steps:62016, time-taken: 2.22min, time-elasped: 4397.75min
-> berries picked: 55 of 800 | patches-visited: [4] | positive-in-buffer: 19623 | amount-filled: 100.00%
	| epsilon: 0.16258816939904516
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2234, 2254, 2101, 2262, 1989, 3381, 2446, 2956]
	| approx positives in sample 512: 202
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 27, 16, 27, 20, 29, 32, 23]
	Time taken saving stuff: 14.59s
episode: 1396/2000 -> reward: -124.999999999992, steps:63360, time-taken: 1.97min, time-elasped: 4399.96min
-> berries picked: 56 of 800 | patches-visited: [6] | positive-in-buffer: 19528 | amount-filled: 100.00%
	| epsilon: 0.1624573842467765
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2222, 2248, 2090, 2255, 1977, 3360, 2436, 2940]
	| approx positives in sample 512: 235
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 31, 22, 27, 25, 36, 34, 32]
	Time taken saving stuff: 0.00s
episode: 1397/2000 -> reward: -124.99999999998703, steps:61824, time-taken: 2.40min, time-elasped: 4402.36min
-> berries picked: 53 of 800 | patches-visited: [1] | positive-in-buffer: 19458 | amount-filled: 100.00%
	| epsilon: 0.16232670429746393
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2217, 2239, 2079, 2248, 1974, 3355, 2425, 2921]
	| approx positives in sample 512: 208
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 29, 21, 29, 19, 35, 24, 29]
	Time taken saving stuff: 0.01s
episode: 1398/2000 -> reward: -124.99999999999093, steps:84192, time-taken: 3.18min, time-elasped: 4405.54min
-> berries picked: 143 of 800 | patches-visited: [4, 8] | positive-in-buffer: 19530 | amount-filled: 100.00%
	| epsilon: 0.16219612946648276
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2225, 2248, 2082, 2259, 1979, 3373, 2434, 2930]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 23, 29, 20, 24, 35, 33, 32]
	Time taken saving stuff: 12.22s
episode: 1399/2000 -> reward: -124.99999999998535, steps:80544, time-taken: 3.08min, time-elasped: 4408.82min
-> berries picked: 127 of 800 | patches-visited: [0, 1] | positive-in-buffer: 19577 | amount-filled: 100.00%
	| epsilon: 0.1620656596692763
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2238, 2250, 2087, 2265, 1977, 3376, 2446, 2938]
	| approx positives in sample 512: 233
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 32, 20, 25, 20, 40, 33, 35]
	Time taken saving stuff: 0.08s
episode: 1400/2000 -> reward: -124.99999999999466, steps:117504, time-taken: 5.07min, time-elasped: 4413.90min
-> berries picked: 268 of 800 | patches-visited: [0, 1, 3, 6, 8] | positive-in-buffer: 19753 | amount-filled: 100.00%
	| epsilon: 0.1619352948213558
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2263, 2268, 2106, 2276, 1993, 3412, 2466, 2969]
	| approx positives in sample 512: 258
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 19, 30, 27, 19, 69, 28, 39]
	Time taken saving stuff: 0.01s
episode: 1401/2000 -> reward: -124.9999999999947, steps:98784, time-taken: 4.17min, time-elasped: 4418.07min
-> berries picked: 194 of 800 | patches-visited: [4, 5, 6, 9] | positive-in-buffer: 19819 | amount-filled: 100.00%
	| epsilon: 0.16180503483830067
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2265, 2274, 2120, 2291, 2002, 3423, 2467, 2977]
	| approx positives in sample 512: 234
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 22, 27, 32, 21, 37, 22, 48]
	Time taken saving stuff: 15.02s
episode: 1402/2000 -> reward: -124.99999999999228, steps:83712, time-taken: 3.21min, time-elasped: 4421.53min
-> berries picked: 138 of 800 | patches-visited: [0, 3, 8] | positive-in-buffer: 19786 | amount-filled: 100.00%
	| epsilon: 0.16167487963575805
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2260, 2277, 2112, 2287, 2006, 3407, 2463, 2974]
	| approx positives in sample 512: 208
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 27, 21, 17, 17, 29, 28, 44]
	Time taken saving stuff: 0.01s
episode: 1403/2000 -> reward: -124.99999999999199, steps:59136, time-taken: 2.14min, time-elasped: 4423.67min
-> berries picked: 43 of 800 | patches-visited: [8] | positive-in-buffer: 19518 | amount-filled: 100.00%
	| epsilon: 0.16154482912944299
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2228, 2249, 2094, 2238, 1973, 3362, 2433, 2941]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 22, 29, 27, 24, 36, 25, 34]
	Time taken saving stuff: 0.11s
episode: 1404/2000 -> reward: -124.99999999998667, steps:72576, time-taken: 2.86min, time-elasped: 4426.54min
-> berries picked: 97 of 800 | patches-visited: [0, 4] | positive-in-buffer: 19585 | amount-filled: 100.00%
	| epsilon: 0.16141488323513833
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2239, 2255, 2102, 2241, 1976, 3379, 2438, 2955]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 35, 17, 33, 15, 38, 28, 42]
	Time taken saving stuff: 11.93s
episode: 1405/2000 -> reward: -124.999999999992, steps:82464, time-taken: 3.25min, time-elasped: 4429.99min
-> berries picked: 130 of 800 | patches-visited: [2, 6] | positive-in-buffer: 19649 | amount-filled: 100.00%
	| epsilon: 0.16128504186869472
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2244, 2263, 2115, 2245, 1983, 3397, 2442, 2960]
	| approx positives in sample 512: 210
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 35, 17, 27, 16, 34, 27, 29]
	Time taken saving stuff: 0.01s
episode: 1406/2000 -> reward: -124.99999999999132, steps:85056, time-taken: 3.31min, time-elasped: 4433.30min
-> berries picked: 144 of 800 | patches-visited: [4, 7] | positive-in-buffer: 19628 | amount-filled: 100.00%
	| epsilon: 0.1611553049460304
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2237, 2259, 2118, 2250, 1979, 3384, 2439, 2962]
	| approx positives in sample 512: 205
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 26, 19, 30, 15, 36, 28, 33]
	Time taken saving stuff: 0.10s
episode: 1407/2000 -> reward: -124.99999999999196, steps:66528, time-taken: 2.83min, time-elasped: 4436.13min
-> berries picked: 67 of 800 | patches-visited: [6] | positive-in-buffer: 19543 | amount-filled: 100.00%
	| epsilon: 0.16102567238313129
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2227, 2253, 2116, 2244, 1968, 3366, 2421, 2948]
	| approx positives in sample 512: 267
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 40, 32, 30, 34, 38, 29, 37]
	Time taken saving stuff: 12.32s
episode: 1408/2000 -> reward: -124.9999999999918, steps:66048, time-taken: 3.02min, time-elasped: 4439.36min
-> berries picked: 71 of 800 | patches-visited: [8] | positive-in-buffer: 19594 | amount-filled: 100.00%
	| epsilon: 0.16089614409605088
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2232, 2260, 2119, 2249, 1971, 3377, 2429, 2957]
	| approx positives in sample 512: 245
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 35, 25, 19, 26, 47, 24, 39]
	Time taken saving stuff: 0.06s
episode: 1409/2000 -> reward: -124.99999999998757, steps:115392, time-taken: 5.12min, time-elasped: 4444.49min
-> berries picked: 272 of 800 | patches-visited: [2, 3, 6, 7] | positive-in-buffer: 19791 | amount-filled: 100.00%
	| epsilon: 0.16076672000091022
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2253, 2277, 2137, 2265, 1994, 3424, 2456, 2985]
	| approx positives in sample 512: 248
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 22, 25, 32, 25, 37, 39, 36]
	Time taken saving stuff: 0.00s
episode: 1410/2000 -> reward: -124.99999999999177, steps:98112, time-taken: 4.34min, time-elasped: 4448.83min
-> berries picked: 191 of 800 | patches-visited: [1, 5, 6] | positive-in-buffer: 19872 | amount-filled: 100.00%
	| epsilon: 0.1606374000138978
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2259, 2290, 2145, 2276, 2004, 3428, 2468, 3002]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 26, 26, 26, 24, 43, 24, 34]
	Time taken saving stuff: 12.35s
episode: 1411/2000 -> reward: -124.99999999999098, steps:66816, time-taken: 2.75min, time-elasped: 4451.79min
-> berries picked: 73 of 800 | patches-visited: [7] | positive-in-buffer: 19816 | amount-filled: 100.00%
	| epsilon: 0.16050818405126957
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2255, 2280, 2138, 2266, 2000, 3424, 2464, 2989]
	| approx positives in sample 512: 253
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 30, 25, 39, 30, 41, 21, 45]
	Time taken saving stuff: 0.00s
episode: 1412/2000 -> reward: -124.9999999999856, steps:95520, time-taken: 4.14min, time-elasped: 4455.94min
-> berries picked: 189 of 800 | patches-visited: [2, 8, 9] | positive-in-buffer: 19936 | amount-filled: 100.00%
	| epsilon: 0.1603790720293487
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2272, 2295, 2145, 2279, 2010, 3454, 2478, 3003]
	| approx positives in sample 512: 248
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 30, 25, 29, 16, 48, 39, 33]
	Time taken saving stuff: 0.02s
episode: 1413/2000 -> reward: -124.99999999999245, steps:78816, time-taken: 3.10min, time-elasped: 4459.04min
-> berries picked: 116 of 800 | patches-visited: [1, 9] | positive-in-buffer: 19869 | amount-filled: 100.00%
	| epsilon: 0.16025006386452592
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2268, 2286, 2141, 2274, 2002, 3440, 2471, 2987]
	| approx positives in sample 512: 223
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 39, 15, 26, 20, 43, 20, 43]
	Time taken saving stuff: 11.66s
episode: 1414/2000 -> reward: -124.99999999999136, steps:63552, time-taken: 2.19min, time-elasped: 4461.43min
-> berries picked: 62 of 800 | patches-visited: [2] | positive-in-buffer: 19667 | amount-filled: 100.00%
	| epsilon: 0.16012115947325897
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2231, 2262, 2132, 2260, 1989, 3408, 2442, 2943]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 30, 17, 16, 23, 40, 34, 35]
	Time taken saving stuff: 0.08s
episode: 1415/2000 -> reward: -124.99999999999199, steps:67584, time-taken: 3.01min, time-elasped: 4464.44min
-> berries picked: 79 of 800 | patches-visited: [0] | positive-in-buffer: 19538 | amount-filled: 100.00%
	| epsilon: 0.15999235877207296
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2217, 2243, 2119, 2259, 1974, 3383, 2414, 2929]
	| approx positives in sample 512: 258
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 29, 31, 25, 29, 51, 39, 32]
	Time taken saving stuff: 0.00s
episode: 1416/2000 -> reward: -124.9999999999945, steps:86592, time-taken: 3.32min, time-elasped: 4467.76min
-> berries picked: 149 of 800 | patches-visited: [1, 3, 7] | positive-in-buffer: 19646 | amount-filled: 100.00%
	| epsilon: 0.15986366167756003
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2231, 2255, 2133, 2267, 1983, 3403, 2429, 2945]
	| approx positives in sample 512: 188
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 25, 19, 14, 21, 40, 26, 28]
	Time taken saving stuff: 14.96s
episode: 1417/2000 -> reward: -124.99999999999602, steps:85920, time-taken: 3.19min, time-elasped: 4471.20min
-> berries picked: 151 of 800 | patches-visited: [7, 8] | positive-in-buffer: 19601 | amount-filled: 100.00%
	| epsilon: 0.1597350681063795
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2236, 2239, 2120, 2271, 1983, 3375, 2426, 2951]
	| approx positives in sample 512: 186
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 21, 17, 18, 20, 25, 25, 32]
	Time taken saving stuff: 0.01s
episode: 1418/2000 -> reward: -124.99999999999392, steps:97920, time-taken: 4.47min, time-elasped: 4475.68min
-> berries picked: 189 of 800 | patches-visited: [5, 6, 8, 9] | positive-in-buffer: 19633 | amount-filled: 100.00%
	| epsilon: 0.15960657797525765
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2238, 2252, 2116, 2282, 1989, 3388, 2416, 2952]
	| approx positives in sample 512: 210
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 24, 25, 20, 17, 42, 26, 28]
	Time taken saving stuff: 0.11s
episode: 1419/2000 -> reward: -124.99999999999173, steps:85728, time-taken: 3.26min, time-elasped: 4478.94min
-> berries picked: 149 of 800 | patches-visited: [3, 9] | positive-in-buffer: 19705 | amount-filled: 100.00%
	| epsilon: 0.15947819120098786
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2246, 2259, 2126, 2286, 1996, 3405, 2421, 2966]
	| approx positives in sample 512: 199
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 20, 20, 31, 23, 25, 26, 36]
	Time taken saving stuff: 11.87s
episode: 1420/2000 -> reward: -124.99999999999528, steps:97728, time-taken: 4.06min, time-elasped: 4483.20min
-> berries picked: 202 of 800 | patches-visited: [3, 5, 6] | positive-in-buffer: 19669 | amount-filled: 100.00%
	| epsilon: 0.15934990770043028
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2234, 2247, 2124, 2281, 2003, 3405, 2413, 2962]
	| approx positives in sample 512: 245
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 30, 29, 26, 27, 34, 32, 41]
	Time taken saving stuff: 0.03s
episode: 1421/2000 -> reward: -124.99999999999523, steps:86016, time-taken: 3.31min, time-elasped: 4486.52min
-> berries picked: 158 of 800 | patches-visited: [6, 9] | positive-in-buffer: 19735 | amount-filled: 100.00%
	| epsilon: 0.15922172739051207
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2240, 2250, 2134, 2294, 2014, 3413, 2417, 2973]
	| approx positives in sample 512: 188
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 27, 18, 15, 19, 31, 28, 31]
	Time taken saving stuff: 0.01s
episode: 1422/2000 -> reward: -124.99999999999245, steps:64128, time-taken: 2.11min, time-elasped: 4488.63min
-> berries picked: 61 of 800 | patches-visited: [8] | positive-in-buffer: 19559 | amount-filled: 100.00%
	| epsilon: 0.1590936501882272
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2219, 2230, 2126, 2283, 1996, 3364, 2401, 2940]
	| approx positives in sample 512: 192
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 19, 27, 9, 24, 38, 23, 29]
	Time taken saving stuff: 14.87s
episode: 1423/2000 -> reward: -124.9999999999924, steps:65568, time-taken: 2.22min, time-elasped: 4491.10min
-> berries picked: 73 of 800 | patches-visited: [1] | positive-in-buffer: 19523 | amount-filled: 100.00%
	| epsilon: 0.15896567601063633
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2219, 2233, 2121, 2277, 1992, 3353, 2395, 2933]
	| approx positives in sample 512: 188
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 21, 24, 18, 17, 30, 16, 41]
	Time taken saving stuff: 0.01s
episode: 1424/2000 -> reward: -124.99999999999278, steps:65472, time-taken: 2.30min, time-elasped: 4493.40min
-> berries picked: 80 of 800 | patches-visited: [5] | positive-in-buffer: 19484 | amount-filled: 100.00%
	| epsilon: 0.15883780477486686
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2211, 2217, 2120, 2277, 1987, 3350, 2393, 2929]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 25, 15, 13, 24, 34, 25, 42]
	Time taken saving stuff: 0.10s
episode: 1425/2000 -> reward: -124.99999999999204, steps:63936, time-taken: 2.08min, time-elasped: 4495.48min
-> berries picked: 60 of 800 | patches-visited: [4] | positive-in-buffer: 19463 | amount-filled: 100.00%
	| epsilon: 0.15871003639811296
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2204, 2218, 2119, 2273, 1983, 3348, 2389, 2929]
	| approx positives in sample 512: 199
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 25, 19, 18, 22, 32, 26, 36]
	Time taken saving stuff: 12.22s
episode: 1426/2000 -> reward: -124.99999999999211, steps:67104, time-taken: 2.90min, time-elasped: 4498.58min
-> berries picked: 71 of 800 | patches-visited: [3] | positive-in-buffer: 19499 | amount-filled: 100.00%
	| epsilon: 0.15858237079763526
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2207, 2223, 2122, 2281, 1983, 3355, 2395, 2933]
	| approx positives in sample 512: 251
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 25, 35, 26, 17, 44, 38, 39]
	Time taken saving stuff: 0.20s
episode: 1427/2000 -> reward: -124.99999999999407, steps:78912, time-taken: 3.19min, time-elasped: 4501.78min
-> berries picked: 126 of 800 | patches-visited: [0, 4] | positive-in-buffer: 19568 | amount-filled: 100.00%
	| epsilon: 0.15845480789076105
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2216, 2230, 2130, 2289, 1984, 3375, 2400, 2944]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 28, 23, 16, 12, 35, 36, 32]
	Time taken saving stuff: 0.01s
episode: 1428/2000 -> reward: -124.99999999999224, steps:64512, time-taken: 2.10min, time-elasped: 4503.88min
-> berries picked: 64 of 800 | patches-visited: [6] | positive-in-buffer: 19594 | amount-filled: 100.00%
	| epsilon: 0.1583273475948841
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2218, 2232, 2132, 2293, 1988, 3380, 2400, 2951]
	| approx positives in sample 512: 195
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 29, 15, 22, 10, 38, 28, 31]
	Time taken saving stuff: 12.21s
episode: 1429/2000 -> reward: -124.9999999999919, steps:61632, time-taken: 2.14min, time-elasped: 4506.23min
-> berries picked: 49 of 800 | patches-visited: [1] | positive-in-buffer: 19481 | amount-filled: 100.00%
	| epsilon: 0.15819998982746453
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2215, 2219, 2116, 2284, 1977, 3351, 2389, 2930]
	| approx positives in sample 512: 203
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 26, 22, 26, 19, 38, 28, 23]
	Time taken saving stuff: 0.00s
episode: 1430/2000 -> reward: -124.99999999998892, steps:116064, time-taken: 4.98min, time-elasped: 4511.21min
-> berries picked: 276 of 800 | patches-visited: [4, 7, 8, 9] | positive-in-buffer: 19630 | amount-filled: 100.00%
	| epsilon: 0.15807273450602902
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2223, 2240, 2136, 2305, 1990, 3378, 2405, 2953]
	| approx positives in sample 512: 250
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 25, 23, 32, 24, 46, 33, 37]
	Time taken saving stuff: 0.10s
episode: 1431/2000 -> reward: -124.99999999999193, steps:63744, time-taken: 2.25min, time-elasped: 4513.46min
-> berries picked: 61 of 800 | patches-visited: [5] | positive-in-buffer: 19631 | amount-filled: 100.00%
	| epsilon: 0.15794558154817043
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2224, 2239, 2134, 2308, 1988, 3378, 2405, 2955]
	| approx positives in sample 512: 190
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 19, 16, 26, 19, 37, 35, 23]
	Time taken saving stuff: 12.27s
episode: 1432/2000 -> reward: -124.99999999999685, steps:85440, time-taken: 3.06min, time-elasped: 4516.73min
-> berries picked: 153 of 800 | patches-visited: [0, 2, 3] | positive-in-buffer: 19586 | amount-filled: 100.00%
	| epsilon: 0.15781853087154804
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2222, 2240, 2137, 2294, 1983, 3371, 2389, 2950]
	| approx positives in sample 512: 202
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 22, 14, 22, 18, 33, 29, 35]
	Time taken saving stuff: 0.11s
episode: 1433/2000 -> reward: -124.99999999999194, steps:62592, time-taken: 2.12min, time-elasped: 4518.86min
-> berries picked: 61 of 800 | patches-visited: [8] | positive-in-buffer: 19547 | amount-filled: 100.00%
	| epsilon: 0.1576915823938873
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2217, 2236, 2123, 2297, 1979, 3363, 2387, 2945]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 19, 25, 27, 20, 32, 33, 31]
	Time taken saving stuff: 0.03s
episode: 1434/2000 -> reward: -124.99999999999484, steps:99840, time-taken: 4.18min, time-elasped: 4523.03min
-> berries picked: 204 of 800 | patches-visited: [2, 3, 9] | positive-in-buffer: 19671 | amount-filled: 100.00%
	| epsilon: 0.15756473603297985
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2233, 2244, 2140, 2301, 1988, 3394, 2401, 2970]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 24, 20, 33, 25, 49, 21, 27]
	Time taken saving stuff: 12.27s
episode: 1435/2000 -> reward: -124.99999999999204, steps:65568, time-taken: 2.12min, time-elasped: 4525.36min
-> berries picked: 67 of 800 | patches-visited: [3] | positive-in-buffer: 19706 | amount-filled: 100.00%
	| epsilon: 0.15743799170668343
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2236, 2247, 2142, 2310, 1994, 3404, 2399, 2974]
	| approx positives in sample 512: 189
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 30, 22, 22, 16, 35, 21, 24]
	Time taken saving stuff: 0.10s
episode: 1436/2000 -> reward: -124.99999999999201, steps:74784, time-taken: 3.02min, time-elasped: 4528.39min
-> berries picked: 100 of 800 | patches-visited: [2, 9] | positive-in-buffer: 19491 | amount-filled: 100.00%
	| epsilon: 0.15731134933292193
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2220, 2242, 2131, 2257, 1976, 3381, 2377, 2907]
	| approx positives in sample 512: 248
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 23, 29, 25, 27, 36, 34, 49]
	Time taken saving stuff: 0.03s
episode: 1437/2000 -> reward: -124.99999999999218, steps:62496, time-taken: 2.13min, time-elasped: 4530.52min
-> berries picked: 62 of 800 | patches-visited: [2] | positive-in-buffer: 19521 | amount-filled: 100.00%
	| epsilon: 0.15718480882968514
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2222, 2243, 2135, 2261, 1980, 3389, 2380, 2911]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 32, 23, 25, 20, 34, 24, 32]
	Time taken saving stuff: 12.16s
episode: 1438/2000 -> reward: -111.49999999998698, steps:120000, time-taken: 5.18min, time-elasped: 4535.91min
-> berries picked: 295 of 800 | patches-visited: [1, 2, 3, 5, 9] | positive-in-buffer: 19726 | amount-filled: 100.00%
	| epsilon: 0.15705837011502896
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2239, 2268, 2150, 2274, 2007, 3435, 2405, 2948]
	| approx positives in sample 512: 233
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 33, 23, 29, 33, 27, 27, 30]
	Time taken saving stuff: 0.01s
episode: 1439/2000 -> reward: -124.99999999999581, steps:77568, time-taken: 3.12min, time-elasped: 4539.04min
-> berries picked: 112 of 800 | patches-visited: [6, 9] | positive-in-buffer: 19764 | amount-filled: 100.00%
	| epsilon: 0.15693203310707513
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2239, 2269, 2156, 2273, 2011, 3451, 2410, 2955]
	| approx positives in sample 512: 223
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 33, 23, 14, 14, 40, 28, 42]
	Time taken saving stuff: 0.11s
episode: 1440/2000 -> reward: -124.99999999999034, steps:95040, time-taken: 3.96min, time-elasped: 4543.01min
-> berries picked: 176 of 800 | patches-visited: [1, 4, 5, 9] | positive-in-buffer: 19818 | amount-filled: 100.00%
	| epsilon: 0.15680579772401124
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2243, 2269, 2163, 2281, 2018, 3457, 2420, 2967]
	| approx positives in sample 512: 237
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 28, 25, 35, 24, 40, 29, 23]
	Time taken saving stuff: 11.55s
episode: 1441/2000 -> reward: -124.99999999999217, steps:65184, time-taken: 2.17min, time-elasped: 4545.37min
-> berries picked: 67 of 800 | patches-visited: [3] | positive-in-buffer: 19831 | amount-filled: 100.00%
	| epsilon: 0.15667966388409074
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2247, 2270, 2167, 2281, 2019, 3462, 2421, 2964]
	| approx positives in sample 512: 195
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 26, 19, 20, 16, 32, 28, 35]
	Time taken saving stuff: 0.09s
episode: 1442/2000 -> reward: -124.99999999999184, steps:83616, time-taken: 3.15min, time-elasped: 4548.52min
-> berries picked: 141 of 800 | patches-visited: [3, 7] | positive-in-buffer: 19590 | amount-filled: 100.00%
	| epsilon: 0.15655363150563278
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2210, 2250, 2140, 2268, 1992, 3412, 2402, 2916]
	| approx positives in sample 512: 207
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 15, 17, 29, 29, 35, 23, 32]
	Time taken saving stuff: 0.02s
episode: 1443/2000 -> reward: -124.99999999999686, steps:92640, time-taken: 4.06min, time-elasped: 4552.59min
-> berries picked: 178 of 800 | patches-visited: [1, 2, 4] | positive-in-buffer: 19683 | amount-filled: 100.00%
	| epsilon: 0.15642770050702223
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2223, 2263, 2153, 2280, 2003, 3424, 2411, 2926]
	| approx positives in sample 512: 233
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 29, 24, 23, 19, 41, 26, 40]
	Time taken saving stuff: 12.18s
episode: 1444/2000 -> reward: -124.99999999999301, steps:92832, time-taken: 3.94min, time-elasped: 4556.74min
-> berries picked: 164 of 800 | patches-visited: [1, 2, 3] | positive-in-buffer: 19791 | amount-filled: 100.00%
	| epsilon: 0.15630187080670968
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2240, 2277, 2165, 2294, 2015, 3437, 2418, 2945]
	| approx positives in sample 512: 263
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 33, 44, 23, 23, 44, 30, 38]
	Time taken saving stuff: 0.10s
episode: 1445/2000 -> reward: -124.99999999999375, steps:65376, time-taken: 2.30min, time-elasped: 4559.04min
-> berries picked: 75 of 800 | patches-visited: [5] | positive-in-buffer: 19809 | amount-filled: 100.00%
	| epsilon: 0.1561761423232112
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2241, 2276, 2171, 2296, 2018, 3438, 2420, 2949]
	| approx positives in sample 512: 203
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 24, 24, 21, 15, 38, 25, 34]
	Time taken saving stuff: 0.02s
episode: 1446/2000 -> reward: -124.99999999999194, steps:63456, time-taken: 2.12min, time-elasped: 4561.16min
-> berries picked: 67 of 800 | patches-visited: [4] | positive-in-buffer: 19659 | amount-filled: 100.00%
	| epsilon: 0.15605051497510847
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2227, 2249, 2156, 2278, 2005, 3410, 2411, 2923]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 24, 20, 21, 21, 42, 28, 35]
	Time taken saving stuff: 12.26s
episode: 1447/2000 -> reward: -124.99999999999213, steps:81408, time-taken: 2.99min, time-elasped: 4564.36min
-> berries picked: 128 of 800 | patches-visited: [0, 7] | positive-in-buffer: 19720 | amount-filled: 100.00%
	| epsilon: 0.1559249886810487
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2236, 2259, 2163, 2289, 2014, 3420, 2413, 2926]
	| approx positives in sample 512: 191
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 32, 18, 27, 13, 37, 28, 23]
	Time taken saving stuff: 0.02s
episode: 1448/2000 -> reward: -124.99999999999456, steps:101568, time-taken: 4.07min, time-elasped: 4568.44min
-> berries picked: 207 of 800 | patches-visited: [5, 6, 7] | positive-in-buffer: 19849 | amount-filled: 100.00%
	| epsilon: 0.15579956335974446
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2251, 2269, 2180, 2308, 2029, 3441, 2426, 2945]
	| approx positives in sample 512: 237
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 30, 25, 20, 25, 39, 36, 35]
	Time taken saving stuff: 0.10s
episode: 1449/2000 -> reward: -124.99999999999325, steps:84864, time-taken: 3.21min, time-elasped: 4571.65min
-> berries picked: 145 of 800 | patches-visited: [6, 7] | positive-in-buffer: 19878 | amount-filled: 100.00%
	| epsilon: 0.1556742389299737
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2254, 2274, 2180, 2306, 2028, 3452, 2428, 2956]
	| approx positives in sample 512: 204
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 22, 25, 25, 19, 40, 16, 30]
	Time taken saving stuff: 12.61s
episode: 1450/2000 -> reward: -124.99999999998552, steps:113856, time-taken: 4.88min, time-elasped: 4576.75min
-> berries picked: 272 of 800 | patches-visited: [1, 2, 3, 7] | positive-in-buffer: 19842 | amount-filled: 100.00%
	| epsilon: 0.15554901531057985
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2245, 2279, 2179, 2309, 2031, 3431, 2426, 2942]
	| approx positives in sample 512: 248
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 27, 21, 30, 23, 48, 32, 40]
	Time taken saving stuff: 0.02s
episode: 1451/2000 -> reward: -124.99999999999208, steps:67584, time-taken: 2.86min, time-elasped: 4579.61min
-> berries picked: 78 of 800 | patches-visited: [9] | positive-in-buffer: 19843 | amount-filled: 100.00%
	| epsilon: 0.15542389242047147
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2239, 2275, 2184, 2311, 2026, 3434, 2431, 2943]
	| approx positives in sample 512: 247
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 35, 26, 25, 25, 46, 36, 29]
	Time taken saving stuff: 0.03s
episode: 1452/2000 -> reward: -124.99999999998464, steps:93216, time-taken: 4.04min, time-elasped: 4583.65min
-> berries picked: 188 of 800 | patches-visited: [1, 2, 7] | positive-in-buffer: 19935 | amount-filled: 100.00%
	| epsilon: 0.15529887017862243
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2248, 2286, 2203, 2320, 2032, 3452, 2444, 2950]
	| approx positives in sample 512: 239
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 22, 29, 30, 22, 38, 32, 43]
	Time taken saving stuff: 11.85s
episode: 1453/2000 -> reward: -124.99999999999194, steps:65088, time-taken: 2.17min, time-elasped: 4586.02min
-> berries picked: 68 of 800 | patches-visited: [9] | positive-in-buffer: 19916 | amount-filled: 100.00%
	| epsilon: 0.1551739485040717
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2253, 2287, 2200, 2318, 2029, 3445, 2436, 2948]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 24, 21, 25, 21, 34, 21, 35]
	Time taken saving stuff: 0.09s
episode: 1454/2000 -> reward: -124.999999999988, steps:76800, time-taken: 3.01min, time-elasped: 4589.03min
-> berries picked: 116 of 800 | patches-visited: [7, 9] | positive-in-buffer: 19667 | amount-filled: 100.00%
	| epsilon: 0.15504912731592344
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2221, 2255, 2174, 2306, 2005, 3375, 2409, 2922]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 28, 23, 25, 16, 50, 24, 27]
	Time taken saving stuff: 0.11s
episode: 1455/2000 -> reward: -124.99999999999186, steps:65376, time-taken: 2.17min, time-elasped: 4591.20min
-> berries picked: 66 of 800 | patches-visited: [6] | positive-in-buffer: 19696 | amount-filled: 100.00%
	| epsilon: 0.15492440653334688
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2227, 2257, 2180, 2309, 2008, 3383, 2410, 2922]
	| approx positives in sample 512: 187
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 22, 19, 18, 21, 28, 31, 23]
	Time taken saving stuff: 12.16s
episode: 1456/2000 -> reward: -124.9999999999939, steps:81024, time-taken: 3.22min, time-elasped: 4594.63min
-> berries picked: 134 of 800 | patches-visited: [1, 3] | positive-in-buffer: 19637 | amount-filled: 100.00%
	| epsilon: 0.15479978607557623
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2216, 2257, 2174, 2308, 2006, 3360, 2414, 2902]
	| approx positives in sample 512: 207
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 16, 23, 24, 18, 35, 33, 39]
	Time taken saving stuff: 0.09s
episode: 1457/2000 -> reward: -124.99999999999118, steps:74304, time-taken: 3.02min, time-elasped: 4597.65min
-> berries picked: 106 of 800 | patches-visited: [4, 7] | positive-in-buffer: 19687 | amount-filled: 100.00%
	| epsilon: 0.15467526586191072
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2220, 2263, 2180, 2309, 2015, 3370, 2416, 2914]
	| approx positives in sample 512: 230
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 22, 31, 20, 22, 46, 27, 37]
	Time taken saving stuff: 0.10s
episode: 1458/2000 -> reward: -124.9999999999943, steps:99168, time-taken: 4.07min, time-elasped: 4601.73min
-> berries picked: 199 of 800 | patches-visited: [3, 5, 7] | positive-in-buffer: 19784 | amount-filled: 100.00%
	| epsilon: 0.15455084581171444
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2230, 2277, 2193, 2322, 2022, 3389, 2426, 2925]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 24, 20, 17, 25, 42, 22, 40]
	Time taken saving stuff: 12.36s
episode: 1459/2000 -> reward: -124.99999999999206, steps:64128, time-taken: 2.14min, time-elasped: 4604.08min
-> berries picked: 57 of 800 | patches-visited: [8] | positive-in-buffer: 19784 | amount-filled: 100.00%
	| epsilon: 0.15442652584441638
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2237, 2275, 2193, 2331, 2017, 3386, 2425, 2920]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 26, 21, 21, 22, 30, 26, 39]
	Time taken saving stuff: 0.00s
episode: 1460/2000 -> reward: -124.99999999999156, steps:81312, time-taken: 3.17min, time-elasped: 4607.25min
-> berries picked: 125 of 800 | patches-visited: [7, 9] | positive-in-buffer: 19653 | amount-filled: 100.00%
	| epsilon: 0.15430230587951035
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2224, 2260, 2183, 2316, 1991, 3360, 2408, 2911]
	| approx positives in sample 512: 204
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 23, 19, 21, 14, 40, 20, 45]
	Time taken saving stuff: 0.09s
episode: 1461/2000 -> reward: -124.9999999999956, steps:96096, time-taken: 4.08min, time-elasped: 4611.34min
-> berries picked: 176 of 800 | patches-visited: [0, 3, 8] | positive-in-buffer: 19789 | amount-filled: 100.00%
	| epsilon: 0.15417818583655485
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2245, 2273, 2191, 2334, 2005, 3378, 2427, 2936]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 29, 27, 22, 25, 41, 21, 37]
	Time taken saving stuff: 11.76s
episode: 1462/2000 -> reward: -124.99999999999456, steps:90048, time-taken: 4.04min, time-elasped: 4615.57min
-> berries picked: 160 of 800 | patches-visited: [1, 5, 7, 9] | positive-in-buffer: 19870 | amount-filled: 100.00%
	| epsilon: 0.15405416563517318
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2251, 2279, 2203, 2344, 2017, 3398, 2432, 2946]
	| approx positives in sample 512: 240
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 25, 24, 23, 25, 46, 29, 34]
	Time taken saving stuff: 0.02s
episode: 1463/2000 -> reward: -124.99999999999294, steps:83136, time-taken: 3.14min, time-elasped: 4618.71min
-> berries picked: 125 of 800 | patches-visited: [0, 5] | positive-in-buffer: 19934 | amount-filled: 100.00%
	| epsilon: 0.15393024519505327
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2259, 2283, 2205, 2350, 2027, 3412, 2442, 2956]
	| approx positives in sample 512: 208
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 27, 23, 20, 20, 31, 24, 37]
	Time taken saving stuff: 0.10s
episode: 1464/2000 -> reward: -118.74999999998718, steps:120000, time-taken: 5.13min, time-elasped: 4623.85min
-> berries picked: 284 of 800 | patches-visited: [0, 4, 5, 6, 7] | positive-in-buffer: 19847 | amount-filled: 100.00%
	| epsilon: 0.1538064244359476
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2244, 2287, 2175, 2334, 2025, 3394, 2436, 2952]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 27, 27, 36, 21, 40, 21, 34]
	Time taken saving stuff: 11.79s
episode: 1465/2000 -> reward: -124.99999999998859, steps:112704, time-taken: 4.99min, time-elasped: 4629.04min
-> berries picked: 246 of 800 | patches-visited: [1, 2, 4, 6] | positive-in-buffer: 19974 | amount-filled: 100.00%
	| epsilon: 0.15368270327767325
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2255, 2304, 2186, 2350, 2042, 3415, 2452, 2970]
	| approx positives in sample 512: 235
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 30, 18, 33, 15, 45, 31, 36]
	Time taken saving stuff: 0.11s
episode: 1466/2000 -> reward: -124.99999999999197, steps:65184, time-taken: 2.34min, time-elasped: 4631.38min
-> berries picked: 67 of 800 | patches-visited: [1] | positive-in-buffer: 19989 | amount-filled: 100.00%
	| epsilon: 0.15355908164011176
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2257, 2300, 2190, 2353, 2045, 3421, 2450, 2973]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 27, 31, 16, 11, 36, 31, 25]
	Time taken saving stuff: 0.01s
episode: 1467/2000 -> reward: -124.99999999999369, steps:84096, time-taken: 3.13min, time-elasped: 4634.51min
-> berries picked: 145 of 800 | patches-visited: [1, 3] | positive-in-buffer: 19744 | amount-filled: 100.00%
	| epsilon: 0.15343555944320916
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2235, 2278, 2178, 2311, 2023, 3381, 2423, 2915]
	| approx positives in sample 512: 211
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 20, 26, 28, 25, 30, 27, 32]
	Time taken saving stuff: 12.33s
episode: 1468/2000 -> reward: -124.9999999999948, steps:77952, time-taken: 3.13min, time-elasped: 4637.85min
-> berries picked: 115 of 800 | patches-visited: [7, 9] | positive-in-buffer: 19793 | amount-filled: 100.00%
	| epsilon: 0.15331213660697585
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2240, 2287, 2178, 2317, 2028, 3386, 2427, 2930]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 22, 24, 20, 26, 32, 28, 42]
	Time taken saving stuff: 0.11s
episode: 1469/2000 -> reward: -124.9999999999864, steps:79776, time-taken: 3.19min, time-elasped: 4641.04min
-> berries picked: 122 of 800 | patches-visited: [2, 5] | positive-in-buffer: 19858 | amount-filled: 100.00%
	| epsilon: 0.1531888130514866
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2249, 2294, 2190, 2320, 2035, 3400, 2434, 2936]
	| approx positives in sample 512: 198
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 23, 19, 19, 19, 34, 30, 39]
	Time taken saving stuff: 0.10s
episode: 1470/2000 -> reward: -124.9999999999835, steps:105216, time-taken: 4.26min, time-elasped: 4645.31min
-> berries picked: 218 of 800 | patches-visited: [0, 4, 6] | positive-in-buffer: 19944 | amount-filled: 100.00%
	| epsilon: 0.15306558869688042
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2260, 2294, 2191, 2323, 2049, 3424, 2452, 2951]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 33, 25, 26, 17, 46, 21, 33]
	Time taken saving stuff: 12.20s
episode: 1471/2000 -> reward: -124.999999999997, steps:117984, time-taken: 5.15min, time-elasped: 4650.66min
-> berries picked: 270 of 800 | patches-visited: [0, 2, 3, 6, 7] | positive-in-buffer: 19953 | amount-filled: 100.00%
	| epsilon: 0.1529424634633606
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2270, 2293, 2188, 2326, 2058, 3413, 2451, 2954]
	| approx positives in sample 512: 247
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 28, 23, 24, 28, 44, 39, 27]
	Time taken saving stuff: 0.07s
episode: 1472/2000 -> reward: -124.99999999999218, steps:66144, time-taken: 3.11min, time-elasped: 4653.78min
-> berries picked: 74 of 800 | patches-visited: [1] | positive-in-buffer: 19968 | amount-filled: 100.00%
	| epsilon: 0.1528194372711946
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2273, 2296, 2192, 2332, 2052, 3419, 2454, 2950]
	| approx positives in sample 512: 246
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 26, 25, 26, 24, 50, 30, 38]
	Time taken saving stuff: 0.05s
episode: 1473/2000 -> reward: -124.9999999999889, steps:63072, time-taken: 2.60min, time-elasped: 4656.38min
-> berries picked: 63 of 800 | patches-visited: [3] | positive-in-buffer: 20007 | amount-filled: 100.00%
	| epsilon: 0.15269651004071405
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2279, 2301, 2195, 2336, 2059, 3423, 2458, 2956]
	| approx positives in sample 512: 208
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 29, 21, 25, 24, 29, 26, 29]
	Time taken saving stuff: 14.68s
episode: 1474/2000 -> reward: -124.99999999999277, steps:66912, time-taken: 2.76min, time-elasped: 4659.39min
-> berries picked: 67 of 800 | patches-visited: [3, 7] | positive-in-buffer: 19781 | amount-filled: 100.00%
	| epsilon: 0.15257368169231458
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2248, 2269, 2185, 2322, 2041, 3386, 2415, 2915]
	| approx positives in sample 512: 243
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 27, 30, 30, 28, 47, 21, 33]
	Time taken saving stuff: 0.15s
episode: 1475/2000 -> reward: -124.99999999999186, steps:79776, time-taken: 3.12min, time-elasped: 4662.51min
-> berries picked: 118 of 800 | patches-visited: [4, 6] | positive-in-buffer: 19855 | amount-filled: 100.00%
	| epsilon: 0.152450952146456
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2253, 2276, 2187, 2335, 2046, 3409, 2426, 2923]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 25, 23, 22, 27, 36, 32, 34]
	Time taken saving stuff: 0.10s
episode: 1476/2000 -> reward: -124.99999999999172, steps:62784, time-taken: 2.13min, time-elasped: 4664.65min
-> berries picked: 60 of 800 | patches-visited: [5] | positive-in-buffer: 19874 | amount-filled: 100.00%
	| epsilon: 0.15232832132366197
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2255, 2280, 2188, 2333, 2048, 3412, 2428, 2930]
	| approx positives in sample 512: 196
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 22, 17, 27, 17, 47, 22, 25]
	Time taken saving stuff: 11.96s
episode: 1477/2000 -> reward: -124.99999999999203, steps:63840, time-taken: 2.08min, time-elasped: 4666.93min
-> berries picked: 59 of 800 | patches-visited: [5] | positive-in-buffer: 19748 | amount-filled: 100.00%
	| epsilon: 0.15220578914452013
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2245, 2269, 2177, 2319, 2033, 3380, 2409, 2916]
	| approx positives in sample 512: 190
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 28, 19, 16, 23, 32, 24, 29]
	Time taken saving stuff: 0.04s
episode: 1478/2000 -> reward: -124.99999999999314, steps:81792, time-taken: 3.05min, time-elasped: 4669.98min
-> berries picked: 132 of 800 | patches-visited: [1, 5] | positive-in-buffer: 19709 | amount-filled: 100.00%
	| epsilon: 0.15208335552968197
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2242, 2262, 2172, 2317, 2041, 3374, 2397, 2904]
	| approx positives in sample 512: 206
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 27, 27, 37, 18, 32, 23, 24]
	Time taken saving stuff: 0.02s
episode: 1479/2000 -> reward: -124.99999999999186, steps:68352, time-taken: 2.85min, time-elasped: 4672.84min
-> berries picked: 79 of 800 | patches-visited: [3] | positive-in-buffer: 19753 | amount-filled: 100.00%
	| epsilon: 0.15196102039986287
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2250, 2266, 2175, 2321, 2040, 3386, 2401, 2914]
	| approx positives in sample 512: 249
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 28, 30, 40, 16, 44, 31, 40]
	Time taken saving stuff: 14.66s
episode: 1480/2000 -> reward: -124.99999999999561, steps:79392, time-taken: 3.14min, time-elasped: 4676.22min
-> berries picked: 114 of 800 | patches-visited: [3, 7] | positive-in-buffer: 19823 | amount-filled: 100.00%
	| epsilon: 0.15183878367584194
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2259, 2281, 2181, 2331, 2049, 3395, 2405, 2922]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 24, 22, 33, 20, 40, 29, 34]
	Time taken saving stuff: 0.09s
episode: 1481/2000 -> reward: -124.99999999998805, steps:73440, time-taken: 3.12min, time-elasped: 4679.35min
-> berries picked: 99 of 800 | patches-visited: [0, 5] | positive-in-buffer: 19844 | amount-filled: 100.00%
	| epsilon: 0.151716645278462
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2261, 2276, 2184, 2335, 2047, 3402, 2411, 2928]
	| approx positives in sample 512: 238
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 28, 19, 24, 22, 45, 37, 33]
	Time taken saving stuff: 0.10s
episode: 1482/2000 -> reward: -124.99999999999216, steps:60288, time-taken: 2.01min, time-elasped: 4681.37min
-> berries picked: 51 of 800 | patches-visited: [3] | positive-in-buffer: 19856 | amount-filled: 100.00%
	| epsilon: 0.15159460512862957
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2262, 2276, 2185, 2332, 2049, 3405, 2411, 2936]
	| approx positives in sample 512: 194
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 26, 16, 17, 26, 35, 34, 24]
	Time taken saving stuff: 14.78s
episode: 1483/2000 -> reward: -124.99999999999253, steps:70848, time-taken: 2.96min, time-elasped: 4684.57min
-> berries picked: 86 of 800 | patches-visited: [8, 9] | positive-in-buffer: 19777 | amount-filled: 100.00%
	| epsilon: 0.1514726631473148
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2256, 2268, 2180, 2327, 2034, 3386, 2410, 2916]
	| approx positives in sample 512: 242
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 34, 22, 25, 33, 33, 36, 39]
	Time taken saving stuff: 0.04s
episode: 1484/2000 -> reward: -124.99999999999206, steps:58656, time-taken: 2.01min, time-elasped: 4686.58min
-> berries picked: 38 of 800 | patches-visited: [2] | positive-in-buffer: 19806 | amount-filled: 100.00%
	| epsilon: 0.15135081925555144
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2258, 2272, 2183, 2333, 2039, 3391, 2412, 2918]
	| approx positives in sample 512: 202
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 25, 18, 25, 11, 45, 19, 32]
	Time taken saving stuff: 0.09s
episode: 1485/2000 -> reward: -124.99999999999207, steps:70560, time-taken: 2.97min, time-elasped: 4689.56min
-> berries picked: 85 of 800 | patches-visited: [3, 6] | positive-in-buffer: 19818 | amount-filled: 100.00%
	| epsilon: 0.15122907337443664
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2262, 2281, 2190, 2328, 2036, 3395, 2409, 2917]
	| approx positives in sample 512: 245
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 30, 25, 31, 28, 34, 38, 37]
	Time taken saving stuff: 11.83s
episode: 1486/2000 -> reward: -124.99999999999218, steps:64992, time-taken: 2.36min, time-elasped: 4692.12min
-> berries picked: 59 of 800 | patches-visited: [9] | positive-in-buffer: 19857 | amount-filled: 100.00%
	| epsilon: 0.15110742542513111
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2267, 2283, 2196, 2330, 2043, 3401, 2412, 2925]
	| approx positives in sample 512: 233
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 23, 34, 29, 16, 45, 26, 27]
	Time taken saving stuff: 0.10s
episode: 1487/2000 -> reward: -124.99999999999547, steps:87744, time-taken: 3.20min, time-elasped: 4695.32min
-> berries picked: 160 of 800 | patches-visited: [1, 4, 5] | positive-in-buffer: 19793 | amount-filled: 100.00%
	| epsilon: 0.15098587532885901
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2260, 2275, 2194, 2336, 2025, 3384, 2403, 2916]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 24, 29, 23, 19, 34, 21, 38]
	Time taken saving stuff: 0.01s
episode: 1488/2000 -> reward: -124.99999999999203, steps:50496, time-taken: 1.89min, time-elasped: 4697.21min
-> berries picked: 12 of 800 | patches-visited: [1] | positive-in-buffer: 19698 | amount-filled: 100.00%
	| epsilon: 0.15086442300690786
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2256, 2265, 2182, 2324, 2013, 3363, 2394, 2901]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 27, 19, 28, 20, 38, 28, 37]
	Time taken saving stuff: 14.97s
episode: 1489/2000 -> reward: -124.99999999999264, steps:67392, time-taken: 3.01min, time-elasped: 4700.47min
-> berries picked: 77 of 800 | patches-visited: [7] | positive-in-buffer: 19750 | amount-filled: 100.00%
	| epsilon: 0.15074306838062837
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2264, 2271, 2186, 2332, 2017, 3368, 2405, 2907]
	| approx positives in sample 512: 253
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 37, 26, 27, 23, 44, 33, 40]
	Time taken saving stuff: 0.03s
episode: 1490/2000 -> reward: -124.9999999999838, steps:84768, time-taken: 3.28min, time-elasped: 4703.76min
-> berries picked: 143 of 800 | patches-visited: [2, 4] | positive-in-buffer: 19837 | amount-filled: 100.00%
	| epsilon: 0.15062181137143466
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2275, 2283, 2196, 2342, 2026, 3384, 2414, 2917]
	| approx positives in sample 512: 204
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 19, 16, 20, 29, 45, 22, 30]
	Time taken saving stuff: 0.10s
episode: 1491/2000 -> reward: -124.99999999999059, steps:74592, time-taken: 3.02min, time-elasped: 4706.78min
-> berries picked: 99 of 800 | patches-visited: [5, 7] | positive-in-buffer: 19821 | amount-filled: 100.00%
	| epsilon: 0.15050065190080397
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2270, 2284, 2194, 2341, 2026, 3380, 2406, 2920]
	| approx positives in sample 512: 239
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 32, 30, 30, 20, 38, 31, 33]
	Time taken saving stuff: 12.07s
episode: 1492/2000 -> reward: -124.99999999998332, steps:86208, time-taken: 3.18min, time-elasped: 4710.17min
-> berries picked: 145 of 800 | patches-visited: [0, 5] | positive-in-buffer: 19926 | amount-filled: 100.00%
	| epsilon: 0.1503795898902768
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2277, 2297, 2202, 2354, 2037, 3404, 2422, 2933]
	| approx positives in sample 512: 198
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 18, 17, 31, 21, 26, 26, 34]
	Time taken saving stuff: 0.10s
episode: 1493/2000 -> reward: -124.99999999999231, steps:79200, time-taken: 3.20min, time-elasped: 4713.37min
-> berries picked: 120 of 800 | patches-visited: [3, 6] | positive-in-buffer: 19724 | amount-filled: 100.00%
	| epsilon: 0.15025862526145664
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2264, 2277, 2167, 2333, 2012, 3388, 2404, 2879]
	| approx positives in sample 512: 237
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 32, 22, 25, 24, 45, 35, 27]
	Time taken saving stuff: 0.11s
episode: 1494/2000 -> reward: -124.99999999999203, steps:57312, time-taken: 2.00min, time-elasped: 4715.37min
-> berries picked: 34 of 800 | patches-visited: [1] | positive-in-buffer: 19737 | amount-filled: 100.00%
	| epsilon: 0.15013775793601017
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2269, 2278, 2166, 2334, 2013, 3389, 2405, 2883]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 31, 25, 16, 23, 31, 27, 35]
	Time taken saving stuff: 14.54s
episode: 1495/2000 -> reward: -124.99999999999346, steps:77280, time-taken: 3.15min, time-elasped: 4718.76min
-> berries picked: 110 of 800 | patches-visited: [5, 9] | positive-in-buffer: 19778 | amount-filled: 100.00%
	| epsilon: 0.15001698783566697
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2274, 2289, 2174, 2341, 2010, 3389, 2412, 2889]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 34, 22, 30, 21, 38, 28, 35]
	Time taken saving stuff: 0.11s
episode: 1496/2000 -> reward: -124.99999999999216, steps:66144, time-taken: 3.09min, time-elasped: 4721.86min
-> berries picked: 70 of 800 | patches-visited: [2] | positive-in-buffer: 19788 | amount-filled: 100.00%
	| epsilon: 0.14989631488221963
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2276, 2283, 2178, 2342, 2015, 3390, 2414, 2890]
	| approx positives in sample 512: 253
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 27, 27, 28, 29, 46, 31, 37]
	Time taken saving stuff: 0.07s
episode: 1497/2000 -> reward: -124.99999999999487, steps:79584, time-taken: 3.14min, time-elasped: 4725.00min
-> berries picked: 132 of 800 | patches-visited: [2, 8] | positive-in-buffer: 19855 | amount-filled: 100.00%
	| epsilon: 0.14977573899752367
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2283, 2294, 2187, 2348, 2019, 3403, 2423, 2898]
	| approx positives in sample 512: 191
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 25, 22, 27, 13, 38, 21, 22]
	Time taken saving stuff: 15.11s
episode: 1498/2000 -> reward: -124.99999999999504, steps:79392, time-taken: 3.27min, time-elasped: 4728.53min
-> berries picked: 129 of 800 | patches-visited: [2, 3] | positive-in-buffer: 19811 | amount-filled: 100.00%
	| epsilon: 0.14965526010349742
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2277, 2299, 2179, 2347, 2018, 3384, 2420, 2887]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 31, 25, 18, 21, 31, 19, 33]
	Time taken saving stuff: 0.01s
episode: 1499/2000 -> reward: -124.99999999999218, steps:74400, time-taken: 3.03min, time-elasped: 4731.56min
-> berries picked: 94 of 800 | patches-visited: [4, 8] | positive-in-buffer: 19800 | amount-filled: 100.00%
	| epsilon: 0.14953487812212207
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2278, 2289, 2177, 2354, 2017, 3386, 2413, 2886]
	| approx positives in sample 512: 234
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 29, 25, 24, 27, 41, 39, 28]
	Time taken saving stuff: 0.10s
episode: 1500/2000 -> reward: -124.99999999999302, steps:58080, time-taken: 2.39min, time-elasped: 4733.95min
-> berries picked: 35 of 800 | patches-visited: [4] | positive-in-buffer: 19817 | amount-filled: 100.00%
	| epsilon: 0.14941459297544155
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2277, 2289, 2181, 2354, 2020, 3388, 2420, 2888]
	| approx positives in sample 512: 202
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 27, 19, 20, 20, 47, 24, 26]
	Time taken saving stuff: 14.85s
episode: 1501/2000 -> reward: -124.9999999999921, steps:58464, time-taken: 2.13min, time-elasped: 4736.33min
-> berries picked: 42 of 800 | patches-visited: [9] | positive-in-buffer: 19727 | amount-filled: 100.00%
	| epsilon: 0.14929440458556248
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2276, 2278, 2163, 2348, 2009, 3373, 2400, 2880]
	| approx positives in sample 512: 230
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 32, 34, 19, 20, 31, 28, 37]
	Time taken saving stuff: 0.03s
episode: 1502/2000 -> reward: -124.99999999999355, steps:86016, time-taken: 3.12min, time-elasped: 4739.45min
-> berries picked: 137 of 800 | patches-visited: [1, 2, 8] | positive-in-buffer: 19779 | amount-filled: 100.00%
	| epsilon: 0.14917431287465416
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2284, 2288, 2170, 2361, 2014, 3380, 2395, 2887]
	| approx positives in sample 512: 205
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 23, 27, 21, 17, 40, 30, 21]
	Time taken saving stuff: 0.11s
episode: 1503/2000 -> reward: -124.99999999999346, steps:113280, time-taken: 5.39min, time-elasped: 4744.85min
-> berries picked: 246 of 800 | patches-visited: [3, 5, 7, 8, 9] | positive-in-buffer: 19730 | amount-filled: 100.00%
	| epsilon: 0.14905431776494843
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2261, 2292, 2176, 2372, 2016, 3370, 2376, 2867]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 19, 34, 37, 21, 37, 25, 29]
	Time taken saving stuff: 15.47s
episode: 1504/2000 -> reward: -124.99999999998617, steps:79008, time-taken: 6.01min, time-elasped: 4751.12min
-> berries picked: 125 of 800 | patches-visited: [3, 9] | positive-in-buffer: 19780 | amount-filled: 100.00%
	| epsilon: 0.1489344191787398
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2262, 2301, 2179, 2379, 2020, 3376, 2390, 2873]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 30, 18, 26, 26, 46, 29, 30]
	Time taken saving stuff: 0.09s
episode: 1505/2000 -> reward: -124.9999999999919, steps:64416, time-taken: 4.14min, time-elasped: 4755.27min
-> berries picked: 63 of 800 | patches-visited: [1] | positive-in-buffer: 19756 | amount-filled: 100.00%
	| epsilon: 0.14881461703838522
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2266, 2301, 2183, 2370, 2013, 3369, 2387, 2867]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 25, 17, 27, 21, 43, 23, 27]
	Time taken saving stuff: 0.07s
episode: 1506/2000 -> reward: -124.99999999999096, steps:80928, time-taken: 18.52min, time-elasped: 4773.80min
-> berries picked: 133 of 800 | patches-visited: [4, 7] | positive-in-buffer: 19583 | amount-filled: 100.00%
	| epsilon: 0.1486949112663041
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2245, 2274, 2182, 2367, 2002, 3335, 2350, 2828]
	| approx positives in sample 512: 234
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 29, 20, 30, 21, 35, 28, 41]
	Time taken saving stuff: 16.23s
episode: 1507/2000 -> reward: -124.99999999999315, steps:104448, time-taken: 3.60min, time-elasped: 4777.67min
-> berries picked: 213 of 800 | patches-visited: [1, 6, 7, 9] | positive-in-buffer: 19736 | amount-filled: 100.00%
	| epsilon: 0.14857530178497821
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2263, 2294, 2204, 2380, 2017, 3367, 2368, 2843]
	| approx positives in sample 512: 204
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 20, 21, 26, 19, 41, 18, 40]
	Time taken saving stuff: 0.12s
episode: 1508/2000 -> reward: -124.99999999999196, steps:62688, time-taken: 1.94min, time-elasped: 4779.62min
-> berries picked: 57 of 800 | patches-visited: [4] | positive-in-buffer: 19676 | amount-filled: 100.00%
	| epsilon: 0.1484557885169518
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2261, 2284, 2189, 2377, 2013, 3361, 2361, 2830]
	| approx positives in sample 512: 196
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 28, 18, 20, 20, 42, 27, 21]
	Time taken saving stuff: 0.01s
episode: 1509/2000 -> reward: -124.9999999999822, steps:95904, time-taken: 4.20min, time-elasped: 4783.81min
-> berries picked: 190 of 800 | patches-visited: [2, 8, 9] | positive-in-buffer: 19693 | amount-filled: 100.00%
	| epsilon: 0.14833637138483127
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2254, 2278, 2191, 2383, 2021, 3365, 2359, 2842]
	| approx positives in sample 512: 244
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 33, 27, 30, 23, 36, 31, 38]
	Time taken saving stuff: 12.77s
episode: 1510/2000 -> reward: -124.99999999998965, steps:78624, time-taken: 3.34min, time-elasped: 4787.36min
-> berries picked: 111 of 800 | patches-visited: [1, 3, 8] | positive-in-buffer: 19749 | amount-filled: 100.00%
	| epsilon: 0.14821705031128543
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2257, 2284, 2203, 2395, 2022, 3380, 2362, 2846]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 27, 21, 27, 24, 32, 29, 33]
	Time taken saving stuff: 0.02s
episode: 1511/2000 -> reward: -124.99999999999159, steps:61152, time-taken: 2.21min, time-elasped: 4789.58min
-> berries picked: 52 of 800 | patches-visited: [0] | positive-in-buffer: 19732 | amount-filled: 100.00%
	| epsilon: 0.14809782521904513
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2257, 2284, 2203, 2387, 2020, 3375, 2360, 2846]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 22, 16, 20, 15, 44, 21, 41]
	Time taken saving stuff: 0.11s
episode: 1512/2000 -> reward: -124.99999999999199, steps:74496, time-taken: 2.91min, time-elasped: 4792.49min
-> berries picked: 99 of 800 | patches-visited: [5, 7] | positive-in-buffer: 19639 | amount-filled: 100.00%
	| epsilon: 0.14797869603090355
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2246, 2279, 2195, 2386, 2016, 3344, 2341, 2832]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 29, 16, 27, 20, 41, 30, 40]
	Time taken saving stuff: 11.88s
episode: 1513/2000 -> reward: -124.99999999998589, steps:66240, time-taken: 3.22min, time-elasped: 4795.90min
-> berries picked: 75 of 800 | patches-visited: [9] | positive-in-buffer: 19684 | amount-filled: 100.00%
	| epsilon: 0.14785966266971584
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2250, 2284, 2197, 2391, 2018, 3354, 2351, 2839]
	| approx positives in sample 512: 268
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 27, 29, 38, 29, 48, 19, 50]
	Time taken saving stuff: 0.02s
episode: 1514/2000 -> reward: -124.99999999999689, steps:113472, time-taken: 5.27min, time-elasped: 4801.18min
-> berries picked: 254 of 800 | patches-visited: [0, 1, 3, 5] | positive-in-buffer: 19837 | amount-filled: 100.00%
	| epsilon: 0.14774072505839927
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2272, 2293, 2208, 2413, 2034, 3392, 2364, 2861]
	| approx positives in sample 512: 245
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 23, 21, 33, 13, 44, 34, 43]
	Time taken saving stuff: 0.02s
episode: 1515/2000 -> reward: -124.99999999999417, steps:75072, time-taken: 3.08min, time-elasped: 4804.26min
-> berries picked: 103 of 800 | patches-visited: [3, 7] | positive-in-buffer: 19866 | amount-filled: 100.00%
	| epsilon: 0.1476218831199331
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2279, 2299, 2209, 2421, 2036, 3393, 2366, 2863]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 26, 20, 28, 25, 35, 23, 33]
	Time taken saving stuff: 44.49s
episode: 1516/2000 -> reward: -124.99999999999201, steps:65280, time-taken: 2.22min, time-elasped: 4807.22min
-> berries picked: 68 of 800 | patches-visited: [8] | positive-in-buffer: 19816 | amount-filled: 100.00%
	| epsilon: 0.14750313677735855
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2263, 2290, 2207, 2421, 2034, 3383, 2360, 2858]
	| approx positives in sample 512: 196
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 27, 19, 24, 30, 29, 18, 24]
	Time taken saving stuff: 0.02s
episode: 1517/2000 -> reward: -124.99999999999577, steps:85248, time-taken: 3.34min, time-elasped: 4810.56min
-> berries picked: 145 of 800 | patches-visited: [0, 1] | positive-in-buffer: 19699 | amount-filled: 100.00%
	| epsilon: 0.1473844859537787
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2250, 2297, 2199, 2407, 2030, 3362, 2335, 2819]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 28, 15, 27, 19, 39, 25, 30]
	Time taken saving stuff: 0.03s
episode: 1518/2000 -> reward: -124.99999999998384, steps:74976, time-taken: 3.26min, time-elasped: 4813.82min
-> berries picked: 105 of 800 | patches-visited: [4, 9] | positive-in-buffer: 19714 | amount-filled: 100.00%
	| epsilon: 0.14726593057235857
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2251, 2308, 2199, 2408, 2037, 3366, 2321, 2824]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 31, 22, 31, 25, 31, 37, 22]
	Time taken saving stuff: 12.20s
episode: 1519/2000 -> reward: -124.99999999999203, steps:58944, time-taken: 2.22min, time-elasped: 4816.25min
-> berries picked: 41 of 800 | patches-visited: [5] | positive-in-buffer: 19725 | amount-filled: 100.00%
	| epsilon: 0.14714747055632488
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2250, 2307, 2204, 2411, 2039, 3363, 2324, 2827]
	| approx positives in sample 512: 206
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 21, 16, 18, 26, 36, 26, 37]
	Time taken saving stuff: 0.03s
episode: 1520/2000 -> reward: -124.99999999999191, steps:65184, time-taken: 2.24min, time-elasped: 4818.49min
-> berries picked: 70 of 800 | patches-visited: [8] | positive-in-buffer: 19728 | amount-filled: 100.00%
	| epsilon: 0.14702910582896622
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2254, 2303, 2205, 2420, 2039, 3357, 2320, 2830]
	| approx positives in sample 512: 207
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 23, 27, 22, 18, 41, 30, 31]
	Time taken saving stuff: 0.03s
episode: 1521/2000 -> reward: -124.9999999999906, steps:78144, time-taken: 3.06min, time-elasped: 4821.55min
-> berries picked: 117 of 800 | patches-visited: [6, 7] | positive-in-buffer: 19611 | amount-filled: 100.00%
	| epsilon: 0.14691083631363283
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2246, 2297, 2196, 2402, 2032, 3326, 2297, 2815]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 30, 26, 28, 23, 41, 26, 32]
	Time taken saving stuff: 15.14s
episode: 1522/2000 -> reward: -124.99999999998815, steps:90528, time-taken: 4.32min, time-elasped: 4826.13min
-> berries picked: 160 of 800 | patches-visited: [0, 2, 7] | positive-in-buffer: 19732 | amount-filled: 100.00%
	| epsilon: 0.14679266193373658
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2261, 2300, 2206, 2417, 2052, 3346, 2313, 2837]
	| approx positives in sample 512: 252
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 29, 20, 33, 30, 40, 27, 47]
	Time taken saving stuff: 0.10s
episode: 1523/2000 -> reward: -124.9999999999875, steps:94560, time-taken: 4.24min, time-elasped: 4830.38min
-> berries picked: 189 of 800 | patches-visited: [2, 5, 6] | positive-in-buffer: 19847 | amount-filled: 100.00%
	| epsilon: 0.14667458261275096
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2270, 2314, 2219, 2435, 2063, 3371, 2324, 2851]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 33, 18, 34, 26, 37, 23, 32]
	Time taken saving stuff: 0.03s
episode: 1524/2000 -> reward: -124.99999999999206, steps:60000, time-taken: 2.09min, time-elasped: 4832.47min
-> berries picked: 50 of 800 | patches-visited: [7] | positive-in-buffer: 19831 | amount-filled: 100.00%
	| epsilon: 0.14655659827421108
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2269, 2314, 2219, 2430, 2058, 3366, 2324, 2851]
	| approx positives in sample 512: 206
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 25, 24, 30, 15, 32, 29, 30]
	Time taken saving stuff: 12.55s
episode: 1525/2000 -> reward: -124.99999999999177, steps:75744, time-taken: 3.19min, time-elasped: 4835.88min
-> berries picked: 115 of 800 | patches-visited: [7, 9] | positive-in-buffer: 19772 | amount-filled: 100.00%
	| epsilon: 0.1464387088417135
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2271, 2306, 2214, 2420, 2057, 3344, 2319, 2841]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 26, 30, 27, 21, 34, 24, 31]
	Time taken saving stuff: 0.02s
episode: 1526/2000 -> reward: -124.99999999998232, steps:83520, time-taken: 3.60min, time-elasped: 4839.48min
-> berries picked: 141 of 800 | patches-visited: [0, 3] | positive-in-buffer: 19852 | amount-filled: 100.00%
	| epsilon: 0.14632091423891624
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2277, 2314, 2225, 2432, 2065, 3357, 2330, 2852]
	| approx positives in sample 512: 203
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 29, 17, 29, 23, 35, 27, 20]
	Time taken saving stuff: 0.10s
episode: 1527/2000 -> reward: -124.99999999999152, steps:67392, time-taken: 3.07min, time-elasped: 4842.55min
-> berries picked: 75 of 800 | patches-visited: [6] | positive-in-buffer: 19737 | amount-filled: 100.00%
	| epsilon: 0.14620321438953876
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2267, 2301, 2210, 2421, 2043, 3347, 2316, 2832]
	| approx positives in sample 512: 243
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 26, 20, 27, 32, 42, 34, 43]
	Time taken saving stuff: 14.52s
episode: 1528/2000 -> reward: -124.99999999998597, steps:80928, time-taken: 3.56min, time-elasped: 4846.35min
-> berries picked: 126 of 800 | patches-visited: [6, 7] | positive-in-buffer: 19809 | amount-filled: 100.00%
	| epsilon: 0.14608560921736183
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2273, 2308, 2221, 2428, 2048, 3364, 2325, 2842]
	| approx positives in sample 512: 205
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 26, 26, 21, 20, 34, 22, 31]
	Time taken saving stuff: 0.03s
episode: 1529/2000 -> reward: -124.99999999998528, steps:77568, time-taken: 3.54min, time-elasped: 4849.89min
-> berries picked: 112 of 800 | patches-visited: [0, 6] | positive-in-buffer: 19811 | amount-filled: 100.00%
	| epsilon: 0.14596809864622756
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2274, 2307, 2215, 2430, 2051, 3366, 2331, 2837]
	| approx positives in sample 512: 238
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 32, 16, 24, 22, 47, 36, 32]
	Time taken saving stuff: 0.03s
episode: 1530/2000 -> reward: -124.99999999999201, steps:63264, time-taken: 2.28min, time-elasped: 4852.18min
-> berries picked: 56 of 800 | patches-visited: [9] | positive-in-buffer: 19829 | amount-filled: 100.00%
	| epsilon: 0.14585068260003933
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2276, 2306, 2219, 2431, 2053, 3368, 2332, 2844]
	| approx positives in sample 512: 203
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 14, 20, 23, 17, 42, 32, 24]
	Time taken saving stuff: 12.30s
episode: 1531/2000 -> reward: -124.99999999999072, steps:69120, time-taken: 3.21min, time-elasped: 4855.60min
-> berries picked: 83 of 800 | patches-visited: [6, 9] | positive-in-buffer: 19643 | amount-filled: 100.00%
	| epsilon: 0.14573336100276174
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2257, 2281, 2208, 2414, 2043, 3326, 2316, 2798]
	| approx positives in sample 512: 278
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 39, 33, 36, 28, 48, 25, 42]
	Time taken saving stuff: 0.01s
episode: 1532/2000 -> reward: -124.99999999998458, steps:82368, time-taken: 3.44min, time-elasped: 4859.04min
-> berries picked: 144 of 800 | patches-visited: [2, 6, 7] | positive-in-buffer: 19738 | amount-filled: 100.00%
	| epsilon: 0.14561613377842048
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2269, 2297, 2218, 2425, 2051, 3339, 2331, 2808]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [36, 21, 22, 32, 16, 29, 24, 38]
	Time taken saving stuff: 0.01s
episode: 1533/2000 -> reward: -124.99999999999204, steps:59616, time-taken: 2.03min, time-elasped: 4861.08min
-> berries picked: 41 of 800 | patches-visited: [8] | positive-in-buffer: 19707 | amount-filled: 100.00%
	| epsilon: 0.14549900085110246
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2269, 2289, 2216, 2423, 2049, 3333, 2325, 2803]
	| approx positives in sample 512: 206
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 24, 18, 25, 20, 38, 27, 39]
	Time taken saving stuff: 12.19s
episode: 1534/2000 -> reward: -124.99999999999449, steps:96960, time-taken: 4.29min, time-elasped: 4865.57min
-> berries picked: 196 of 800 | patches-visited: [5, 6, 9] | positive-in-buffer: 19817 | amount-filled: 100.00%
	| epsilon: 0.1453819621449556
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2281, 2301, 2227, 2440, 2056, 3360, 2336, 2816]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 29, 27, 24, 22, 40, 26, 30]
	Time taken saving stuff: 0.02s
episode: 1535/2000 -> reward: -124.99999999998363, steps:76032, time-taken: 3.49min, time-elasped: 4869.07min
-> berries picked: 100 of 800 | patches-visited: [2, 8] | positive-in-buffer: 19875 | amount-filled: 100.00%
	| epsilon: 0.1452650175841888
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2287, 2307, 2235, 2446, 2064, 3369, 2339, 2828]
	| approx positives in sample 512: 242
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 25, 33, 26, 23, 40, 27, 40]
	Time taken saving stuff: 0.06s
episode: 1536/2000 -> reward: -124.99999999999183, steps:61152, time-taken: 2.09min, time-elasped: 4871.16min
-> berries picked: 45 of 800 | patches-visited: [9] | positive-in-buffer: 19847 | amount-filled: 100.00%
	| epsilon: 0.14514816709307196
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2286, 2303, 2229, 2438, 2060, 3366, 2339, 2826]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 27, 23, 31, 20, 32, 23, 34]
	Time taken saving stuff: 12.60s
episode: 1537/2000 -> reward: -124.99999999997264, steps:98592, time-taken: 4.31min, time-elasped: 4875.68min
-> berries picked: 196 of 800 | patches-visited: [3, 5, 6] | positive-in-buffer: 19775 | amount-filled: 100.00%
	| epsilon: 0.14503141059593594
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2285, 2308, 2221, 2435, 2042, 3330, 2335, 2819]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 24, 26, 32, 22, 30, 33, 27]
	Time taken saving stuff: 0.12s
episode: 1538/2000 -> reward: -124.99999999999297, steps:57984, time-taken: 2.29min, time-elasped: 4877.97min
-> berries picked: 35 of 800 | patches-visited: [1] | positive-in-buffer: 19768 | amount-filled: 100.00%
	| epsilon: 0.14491474801717244
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2284, 2311, 2225, 2432, 2044, 3324, 2335, 2813]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 24, 27, 27, 22, 26, 25, 38]
	Time taken saving stuff: 0.09s
episode: 1539/2000 -> reward: -124.99999999998039, steps:109536, time-taken: 4.51min, time-elasped: 4882.48min
-> berries picked: 243 of 800 | patches-visited: [0, 2, 7, 9] | positive-in-buffer: 19880 | amount-filled: 100.00%
	| epsilon: 0.14479817928123392
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2308, 2316, 2231, 2441, 2052, 3353, 2344, 2835]
	| approx positives in sample 512: 203
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 30, 26, 21, 16, 29, 23, 34]
	Time taken saving stuff: 12.53s
episode: 1540/2000 -> reward: -124.99999999999457, steps:84192, time-taken: 3.24min, time-elasped: 4885.94min
-> berries picked: 149 of 800 | patches-visited: [4, 5, 9] | positive-in-buffer: 19689 | amount-filled: 100.00%
	| epsilon: 0.14468170431263366
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2275, 2290, 2201, 2426, 2022, 3314, 2330, 2831]
	| approx positives in sample 512: 195
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 18, 27, 20, 22, 30, 19, 31]
	Time taken saving stuff: 0.11s
episode: 1541/2000 -> reward: -124.99999999999565, steps:93312, time-taken: 4.54min, time-elasped: 4890.48min
-> berries picked: 162 of 800 | patches-visited: [1, 4, 8] | positive-in-buffer: 19757 | amount-filled: 100.00%
	| epsilon: 0.14456532303594571
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2283, 2289, 2212, 2430, 2030, 3339, 2334, 2840]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 32, 22, 24, 25, 39, 20, 33]
	Time taken saving stuff: 0.11s
episode: 1542/2000 -> reward: -124.99999999999315, steps:73248, time-taken: 3.33min, time-elasped: 4893.82min
-> berries picked: 88 of 800 | patches-visited: [5, 6] | positive-in-buffer: 19801 | amount-filled: 100.00%
	| epsilon: 0.14444903537580467
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2295, 2300, 2213, 2435, 2037, 3340, 2338, 2843]
	| approx positives in sample 512: 236
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 31, 26, 27, 25, 34, 33, 35]
	Time taken saving stuff: 12.25s
episode: 1543/2000 -> reward: -124.99999999999255, steps:79008, time-taken: 3.31min, time-elasped: 4897.33min
-> berries picked: 128 of 800 | patches-visited: [6, 8] | positive-in-buffer: 19831 | amount-filled: 100.00%
	| epsilon: 0.14433284125690587
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2294, 2305, 2215, 2441, 2045, 3344, 2339, 2848]
	| approx positives in sample 512: 237
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 20, 25, 37, 29, 35, 36, 29]
	Time taken saving stuff: 0.03s
episode: 1544/2000 -> reward: -124.99999999999135, steps:77664, time-taken: 3.18min, time-elasped: 4900.51min
-> berries picked: 107 of 800 | patches-visited: [8, 9] | positive-in-buffer: 19810 | amount-filled: 100.00%
	| epsilon: 0.1442167406040052
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2300, 2294, 2208, 2439, 2051, 3331, 2345, 2842]
	| approx positives in sample 512: 230
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 36, 17, 27, 28, 33, 33, 35]
	Time taken saving stuff: 0.03s
episode: 1545/2000 -> reward: -124.99999999999187, steps:64224, time-taken: 2.28min, time-elasped: 4902.80min
-> berries picked: 55 of 800 | patches-visited: [8] | positive-in-buffer: 19775 | amount-filled: 100.00%
	| epsilon: 0.144100733341919
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2299, 2292, 2201, 2430, 2044, 3324, 2344, 2841]
	| approx positives in sample 512: 196
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 26, 20, 24, 12, 20, 35, 30]
	Time taken saving stuff: 12.01s
episode: 1546/2000 -> reward: -124.9999999999946, steps:76896, time-taken: 3.29min, time-elasped: 4906.30min
-> berries picked: 109 of 800 | patches-visited: [0, 2] | positive-in-buffer: 19637 | amount-filled: 100.00%
	| epsilon: 0.14398481939552418
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2288, 2291, 2178, 2407, 2003, 3308, 2344, 2818]
	| approx positives in sample 512: 233
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 27, 13, 23, 24, 53, 36, 30]
	Time taken saving stuff: 0.10s
episode: 1547/2000 -> reward: -124.99999999999207, steps:58656, time-taken: 2.26min, time-elasped: 4908.56min
-> berries picked: 43 of 800 | patches-visited: [7] | positive-in-buffer: 19657 | amount-filled: 100.00%
	| epsilon: 0.14386899868975805
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2286, 2293, 2181, 2409, 2008, 3312, 2346, 2822]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 24, 24, 18, 13, 49, 32, 25]
	Time taken saving stuff: 0.01s
episode: 1548/2000 -> reward: -124.99999999999032, steps:76608, time-taken: 3.46min, time-elasped: 4912.02min
-> berries picked: 118 of 800 | patches-visited: [1, 5] | positive-in-buffer: 19706 | amount-filled: 100.00%
	| epsilon: 0.14375327114961822
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2289, 2290, 2186, 2421, 2009, 3332, 2351, 2828]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 25, 33, 26, 23, 43, 17, 30]
	Time taken saving stuff: 12.57s
episode: 1549/2000 -> reward: -124.99999999999213, steps:65952, time-taken: 2.45min, time-elasped: 4914.69min
-> berries picked: 73 of 800 | patches-visited: [3] | positive-in-buffer: 19737 | amount-filled: 100.00%
	| epsilon: 0.1436376367001628
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2294, 2295, 2189, 2429, 2008, 3335, 2356, 2831]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 22, 31, 29, 26, 41, 21, 28]
	Time taken saving stuff: 0.02s
episode: 1550/2000 -> reward: -124.99999999999515, steps:80352, time-taken: 3.43min, time-elasped: 4918.13min
-> berries picked: 128 of 800 | patches-visited: [8, 9] | positive-in-buffer: 19610 | amount-filled: 100.00%
	| epsilon: 0.14352209526651002
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2291, 2284, 2171, 2402, 2004, 3303, 2329, 2826]
	| approx positives in sample 512: 192
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 21, 18, 25, 18, 36, 25, 26]
	Time taken saving stuff: 0.03s
episode: 1551/2000 -> reward: -124.999999999992, steps:63072, time-taken: 2.38min, time-elasped: 4920.52min
-> berries picked: 57 of 800 | patches-visited: [5] | positive-in-buffer: 19627 | amount-filled: 100.00%
	| epsilon: 0.14340664677383844
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2291, 2285, 2169, 2401, 2006, 3310, 2336, 2829]
	| approx positives in sample 512: 199
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 20, 25, 21, 15, 35, 27, 31]
	Time taken saving stuff: 12.68s
episode: 1552/2000 -> reward: -124.99999999998607, steps:62400, time-taken: 2.83min, time-elasped: 4923.56min
-> berries picked: 63 of 800 | patches-visited: [7] | positive-in-buffer: 19601 | amount-filled: 100.00%
	| epsilon: 0.14329129114738676
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2287, 2285, 2172, 2401, 1997, 3295, 2334, 2830]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 27, 32, 22, 23, 29, 24, 32]
	Time taken saving stuff: 0.03s
episode: 1553/2000 -> reward: -124.99999999999291, steps:82272, time-taken: 3.51min, time-elasped: 4927.07min
-> berries picked: 123 of 800 | patches-visited: [1, 3, 7] | positive-in-buffer: 19661 | amount-filled: 100.00%
	| epsilon: 0.14317602831245385
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2299, 2291, 2173, 2409, 2001, 3305, 2345, 2838]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 33, 26, 17, 21, 37, 32, 32]
	Time taken saving stuff: 0.11s
episode: 1554/2000 -> reward: -124.99999999999113, steps:72576, time-taken: 3.60min, time-elasped: 4930.67min
-> berries picked: 89 of 800 | patches-visited: [0, 4] | positive-in-buffer: 19665 | amount-filled: 100.00%
	| epsilon: 0.14306085819439862
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2304, 2290, 2175, 2411, 2001, 3307, 2339, 2838]
	| approx positives in sample 512: 239
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 36, 20, 26, 28, 33, 23, 39]
	Time taken saving stuff: 12.58s
episode: 1555/2000 -> reward: -124.99999999999255, steps:92640, time-taken: 9.75min, time-elasped: 4940.64min
-> berries picked: 170 of 800 | patches-visited: [3, 5, 7] | positive-in-buffer: 19774 | amount-filled: 100.00%
	| epsilon: 0.1429457807186401
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2312, 2307, 2184, 2428, 2015, 3324, 2347, 2857]
	| approx positives in sample 512: 237
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 26, 28, 23, 26, 40, 28, 32]
	Time taken saving stuff: 0.03s
episode: 1556/2000 -> reward: -124.9999999999901, steps:96960, time-taken: 6.86min, time-elasped: 4947.52min
-> berries picked: 179 of 800 | patches-visited: [4, 5, 9] | positive-in-buffer: 19914 | amount-filled: 100.00%
	| epsilon: 0.14283079581065722
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2324, 2322, 2194, 2449, 2036, 3350, 2358, 2881]
	| approx positives in sample 512: 243
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 33, 33, 29, 24, 29, 33, 36]
	Time taken saving stuff: 0.01s
episode: 1557/2000 -> reward: -124.99999999999133, steps:72672, time-taken: 2.98min, time-elasped: 4950.50min
-> berries picked: 100 of 800 | patches-visited: [2, 9] | positive-in-buffer: 19910 | amount-filled: 100.00%
	| epsilon: 0.1427159033959889
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2324, 2320, 2196, 2450, 2030, 3345, 2362, 2883]
	| approx positives in sample 512: 257
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 34, 26, 40, 25, 46, 36, 28]
	Time taken saving stuff: 12.11s
episode: 1558/2000 -> reward: -124.99999999999055, steps:82176, time-taken: 3.49min, time-elasped: 4954.19min
-> berries picked: 137 of 800 | patches-visited: [2, 3] | positive-in-buffer: 19944 | amount-filled: 100.00%
	| epsilon: 0.14260110340023402
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2325, 2317, 2199, 2460, 2034, 3355, 2368, 2886]
	| approx positives in sample 512: 235
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 32, 26, 26, 30, 38, 30, 29]
	Time taken saving stuff: 0.01s
episode: 1559/2000 -> reward: -124.99999999999392, steps:81600, time-taken: 3.54min, time-elasped: 4957.73min
-> berries picked: 130 of 800 | patches-visited: [6, 7] | positive-in-buffer: 19691 | amount-filled: 100.00%
	| epsilon: 0.14248639574905117
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2307, 2295, 2168, 2409, 2007, 3308, 2350, 2847]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 28, 30, 18, 24, 39, 30, 34]
	Time taken saving stuff: 0.01s
episode: 1560/2000 -> reward: -124.99999999999204, steps:61536, time-taken: 2.52min, time-elasped: 4960.26min
-> berries picked: 60 of 800 | patches-visited: [2] | positive-in-buffer: 19646 | amount-filled: 100.00%
	| epsilon: 0.14237178036815884
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2300, 2292, 2165, 2403, 2004, 3301, 2341, 2840]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 31, 28, 17, 18, 30, 21, 40]
	Time taken saving stuff: 14.91s
episode: 1561/2000 -> reward: -124.99999999999233, steps:59616, time-taken: 2.21min, time-elasped: 4962.72min
-> berries picked: 48 of 800 | patches-visited: [0] | positive-in-buffer: 19571 | amount-filled: 100.00%
	| epsilon: 0.14225725718333526
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2297, 2286, 2147, 2399, 1993, 3281, 2338, 2830]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 26, 29, 26, 20, 29, 27, 36]
	Time taken saving stuff: 0.01s
episode: 1562/2000 -> reward: -124.99999999999135, steps:67488, time-taken: 3.21min, time-elasped: 4965.93min
-> berries picked: 79 of 800 | patches-visited: [8, 9] | positive-in-buffer: 19604 | amount-filled: 100.00%
	| epsilon: 0.14214282612041834
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2302, 2292, 2156, 2404, 1990, 3285, 2341, 2834]
	| approx positives in sample 512: 245
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 30, 22, 24, 27, 29, 30, 48]
	Time taken saving stuff: 0.01s
episode: 1563/2000 -> reward: -124.99999999999199, steps:60864, time-taken: 2.34min, time-elasped: 4968.28min
-> berries picked: 56 of 800 | patches-visited: [2] | positive-in-buffer: 19642 | amount-filled: 100.00%
	| epsilon: 0.14202848710530566
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2305, 2295, 2158, 2408, 1992, 3298, 2344, 2842]
	| approx positives in sample 512: 204
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 21, 22, 22, 17, 40, 20, 42]
	Time taken saving stuff: 15.85s
episode: 1564/2000 -> reward: -124.99999999999314, steps:97440, time-taken: 4.41min, time-elasped: 4972.96min
-> berries picked: 199 of 800 | patches-visited: [2, 7, 8] | positive-in-buffer: 19693 | amount-filled: 100.00%
	| epsilon: 0.1419142400639544
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2308, 2301, 2164, 2410, 1997, 3313, 2352, 2848]
	| approx positives in sample 512: 226
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 22, 26, 27, 28, 41, 25, 30]
	Time taken saving stuff: 0.01s
episode: 1565/2000 -> reward: -124.99999999999203, steps:83040, time-taken: 3.21min, time-elasped: 4976.17min
-> berries picked: 128 of 800 | patches-visited: [4, 6, 9] | positive-in-buffer: 19774 | amount-filled: 100.00%
	| epsilon: 0.1418000849223813
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2321, 2312, 2168, 2418, 2000, 3335, 2359, 2861]
	| approx positives in sample 512: 205
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 30, 16, 27, 26, 26, 28, 29]
	Time taken saving stuff: 0.01s
episode: 1566/2000 -> reward: -124.99999999999201, steps:60576, time-taken: 2.29min, time-elasped: 4978.46min
-> berries picked: 42 of 800 | patches-visited: [3] | positive-in-buffer: 19615 | amount-filled: 100.00%
	| epsilon: 0.1416860216066626
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2309, 2292, 2141, 2389, 1980, 3320, 2351, 2833]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 29, 16, 24, 23, 47, 30, 27]
	Time taken saving stuff: 14.78s
episode: 1567/2000 -> reward: -124.99999999999287, steps:61632, time-taken: 2.23min, time-elasped: 4980.94min
-> berries picked: 52 of 800 | patches-visited: [4] | positive-in-buffer: 19598 | amount-filled: 100.00%
	| epsilon: 0.14157205004293405
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2304, 2279, 2142, 2391, 1980, 3319, 2355, 2828]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 28, 28, 27, 24, 40, 27, 23]
	Time taken saving stuff: 0.01s
episode: 1568/2000 -> reward: -124.99999999999278, steps:81984, time-taken: 3.14min, time-elasped: 4984.09min
-> berries picked: 136 of 800 | patches-visited: [0, 5] | positive-in-buffer: 19601 | amount-filled: 100.00%
	| epsilon: 0.1414581701573908
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2305, 2285, 2138, 2391, 1984, 3314, 2346, 2838]
	| approx positives in sample 512: 189
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 30, 16, 12, 22, 37, 29, 26]
	Time taken saving stuff: 0.01s
episode: 1569/2000 -> reward: -124.99999999998305, steps:84096, time-taken: 3.61min, time-elasped: 4987.70min
-> berries picked: 141 of 800 | patches-visited: [1, 7] | positive-in-buffer: 19669 | amount-filled: 100.00%
	| epsilon: 0.14134438187628726
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2310, 2299, 2146, 2396, 1999, 3325, 2352, 2842]
	| approx positives in sample 512: 210
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [38, 20, 18, 20, 14, 45, 27, 28]
	Time taken saving stuff: 15.02s
episode: 1570/2000 -> reward: -124.99999999999201, steps:58560, time-taken: 2.16min, time-elasped: 4990.11min
-> berries picked: 44 of 800 | patches-visited: [3] | positive-in-buffer: 19560 | amount-filled: 100.00%
	| epsilon: 0.14123068512593734
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2294, 2292, 2143, 2380, 1988, 3300, 2341, 2822]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 31, 20, 30, 22, 35, 29, 36]
	Time taken saving stuff: 0.01s
episode: 1571/2000 -> reward: -124.99999999999206, steps:65184, time-taken: 2.35min, time-elasped: 4992.47min
-> berries picked: 66 of 800 | patches-visited: [8] | positive-in-buffer: 19593 | amount-filled: 100.00%
	| epsilon: 0.14111707983271413
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2301, 2294, 2144, 2388, 1988, 3310, 2343, 2825]
	| approx positives in sample 512: 201
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 25, 19, 12, 19, 38, 29, 32]
	Time taken saving stuff: 0.01s
episode: 1572/2000 -> reward: -124.99999999999093, steps:80832, time-taken: 3.47min, time-elasped: 4995.94min
-> berries picked: 137 of 800 | patches-visited: [0, 9] | positive-in-buffer: 19468 | amount-filled: 100.00%
	| epsilon: 0.1410035659230499
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2293, 2280, 2109, 2353, 1969, 3303, 2337, 2824]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 26, 21, 24, 26, 40, 27, 32]
	Time taken saving stuff: 15.08s
episode: 1573/2000 -> reward: -124.99999999999204, steps:60864, time-taken: 2.30min, time-elasped: 4998.49min
-> berries picked: 50 of 800 | patches-visited: [8] | positive-in-buffer: 19469 | amount-filled: 100.00%
	| epsilon: 0.14089014332343616
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2295, 2286, 2108, 2354, 1966, 3305, 2336, 2819]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 38, 22, 22, 16, 42, 25, 32]
	Time taken saving stuff: 0.01s
episode: 1574/2000 -> reward: -124.99999999999216, steps:63744, time-taken: 2.67min, time-elasped: 5001.17min
-> berries picked: 66 of 800 | patches-visited: [9] | positive-in-buffer: 19495 | amount-filled: 100.00%
	| epsilon: 0.14077681196042358
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2302, 2293, 2106, 2353, 1967, 3313, 2338, 2823]
	| approx positives in sample 512: 199
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 22, 22, 17, 19, 38, 26, 32]
	Time taken saving stuff: 0.01s
episode: 1575/2000 -> reward: -124.99999999999206, steps:55200, time-taken: 2.41min, time-elasped: 5003.58min
-> berries picked: 26 of 800 | patches-visited: [7] | positive-in-buffer: 19386 | amount-filled: 100.00%
	| epsilon: 0.14066357176062186
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2302, 2283, 2089, 2339, 1960, 3289, 2326, 2798]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 26, 25, 33, 17, 41, 25, 38]
	Time taken saving stuff: 16.46s
episode: 1576/2000 -> reward: -124.99999999999035, steps:105504, time-taken: 5.02min, time-elasped: 5008.88min
-> berries picked: 224 of 800 | patches-visited: [0, 1, 4, 5] | positive-in-buffer: 19545 | amount-filled: 100.00%
	| epsilon: 0.14055042265069972
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2324, 2305, 2104, 2360, 1985, 3312, 2339, 2816]
	| approx positives in sample 512: 241
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 43, 29, 24, 27, 35, 17, 36]
	Time taken saving stuff: 0.01s
episode: 1577/2000 -> reward: -124.99999999999251, steps:56160, time-taken: 3.23min, time-elasped: 5012.11min
-> berries picked: 30 of 800 | patches-visited: [0] | positive-in-buffer: 19487 | amount-filled: 100.00%
	| epsilon: 0.14043736455738492
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2314, 2297, 2101, 2356, 1980, 3294, 2332, 2813]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 25, 32, 24, 28, 42, 23, 32]
	Time taken saving stuff: 0.01s
episode: 1578/2000 -> reward: -124.99999999999247, steps:79008, time-taken: 3.36min, time-elasped: 5015.47min
-> berries picked: 122 of 800 | patches-visited: [7, 8] | positive-in-buffer: 19552 | amount-filled: 100.00%
	| epsilon: 0.14032439740746414
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2319, 2308, 2111, 2362, 1988, 3300, 2340, 2824]
	| approx positives in sample 512: 226
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [37, 19, 17, 28, 26, 43, 28, 28]
	Time taken saving stuff: 14.99s
episode: 1579/2000 -> reward: -124.99999999999565, steps:78720, time-taken: 3.44min, time-elasped: 5019.15min
-> berries picked: 130 of 800 | patches-visited: [7, 9] | positive-in-buffer: 19600 | amount-filled: 100.00%
	| epsilon: 0.1402115211277829
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2322, 2312, 2114, 2370, 1992, 3309, 2344, 2837]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 27, 12, 22, 29, 42, 27, 34]
	Time taken saving stuff: 0.01s
episode: 1580/2000 -> reward: -124.99999999999181, steps:66816, time-taken: 3.07min, time-elasped: 5022.22min
-> berries picked: 78 of 800 | patches-visited: [5] | positive-in-buffer: 19576 | amount-filled: 100.00%
	| epsilon: 0.14009873564524564
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2321, 2314, 2116, 2367, 1983, 3308, 2337, 2830]
	| approx positives in sample 512: 236
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 35, 21, 31, 23, 42, 19, 34]
	Time taken saving stuff: 0.01s
episode: 1581/2000 -> reward: -124.99999999999199, steps:60288, time-taken: 2.36min, time-elasped: 5024.58min
-> berries picked: 48 of 800 | patches-visited: [1] | positive-in-buffer: 19606 | amount-filled: 100.00%
	| epsilon: 0.13998604088681554
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2321, 2316, 2120, 2374, 1985, 3314, 2341, 2835]
	| approx positives in sample 512: 193
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 30, 32, 21, 16, 38, 22, 22]
	Time taken saving stuff: 15.20s
episode: 1582/2000 -> reward: -124.99999999999181, steps:64512, time-taken: 2.21min, time-elasped: 5027.05min
-> berries picked: 64 of 800 | patches-visited: [4] | positive-in-buffer: 19476 | amount-filled: 100.00%
	| epsilon: 0.1398734367795146
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2300, 2299, 2107, 2361, 1975, 3286, 2327, 2821]
	| approx positives in sample 512: 211
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 33, 15, 20, 20, 36, 33, 28]
	Time taken saving stuff: 0.01s
episode: 1583/2000 -> reward: -124.99999999998406, steps:82272, time-taken: 3.33min, time-elasped: 5030.38min
-> berries picked: 143 of 800 | patches-visited: [4, 8] | positive-in-buffer: 19347 | amount-filled: 100.00%
	| epsilon: 0.1397609232504235
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2292, 2286, 2089, 2354, 1967, 3266, 2301, 2792]
	| approx positives in sample 512: 211
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 26, 19, 20, 24, 47, 24, 28]
	Time taken saving stuff: 0.01s
episode: 1584/2000 -> reward: -124.99999999999197, steps:61056, time-taken: 2.49min, time-elasped: 5032.88min
-> berries picked: 51 of 800 | patches-visited: [7] | positive-in-buffer: 19352 | amount-filled: 100.00%
	| epsilon: 0.1396485002266815
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2290, 2289, 2090, 2360, 1968, 3263, 2302, 2790]
	| approx positives in sample 512: 207
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 25, 25, 20, 20, 35, 28, 31]
	Time taken saving stuff: 15.29s
episode: 1585/2000 -> reward: -124.99999999999201, steps:59904, time-taken: 2.14min, time-elasped: 5035.28min
-> berries picked: 51 of 800 | patches-visited: [4] | positive-in-buffer: 19345 | amount-filled: 100.00%
	| epsilon: 0.13953616763548649
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2285, 2288, 2092, 2358, 1966, 3261, 2302, 2793]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 26, 19, 25, 19, 32, 30, 33]
	Time taken saving stuff: 0.01s
episode: 1586/2000 -> reward: -124.99999999998779, steps:80160, time-taken: 3.28min, time-elasped: 5038.56min
-> berries picked: 132 of 800 | patches-visited: [5, 6] | positive-in-buffer: 19425 | amount-filled: 100.00%
	| epsilon: 0.13942392540409507
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2299, 2299, 2099, 2369, 1977, 3276, 2308, 2798]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 23, 22, 21, 32, 40, 25, 22]
	Time taken saving stuff: 0.01s
episode: 1587/2000 -> reward: -124.99999999999208, steps:76032, time-taken: 3.30min, time-elasped: 5041.87min
-> berries picked: 101 of 800 | patches-visited: [4, 6] | positive-in-buffer: 19451 | amount-filled: 100.00%
	| epsilon: 0.13931177345982218
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2304, 2303, 2102, 2371, 1978, 3285, 2306, 2802]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 41, 18, 30, 20, 46, 34, 19]
	Time taken saving stuff: 15.38s
episode: 1588/2000 -> reward: -124.99999999999159, steps:82560, time-taken: 3.39min, time-elasped: 5045.51min
-> berries picked: 127 of 800 | patches-visited: [4, 6, 7] | positive-in-buffer: 19516 | amount-filled: 100.00%
	| epsilon: 0.13919971173004128
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2309, 2316, 2117, 2382, 1987, 3287, 2308, 2810]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 29, 27, 23, 21, 31, 20, 31]
	Time taken saving stuff: 0.01s
episode: 1589/2000 -> reward: -124.99999999998397, steps:77568, time-taken: 3.40min, time-elasped: 5048.92min
-> berries picked: 107 of 800 | patches-visited: [7, 9] | positive-in-buffer: 19447 | amount-filled: 100.00%
	| epsilon: 0.1390877401421843
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2307, 2309, 2103, 2375, 1980, 3273, 2303, 2797]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 30, 22, 29, 18, 41, 31, 37]
	Time taken saving stuff: 0.01s
episode: 1590/2000 -> reward: -124.99999999999083, steps:66624, time-taken: 3.13min, time-elasped: 5052.05min
-> berries picked: 75 of 800 | patches-visited: [7] | positive-in-buffer: 19479 | amount-filled: 100.00%
	| epsilon: 0.1389758586237415
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2312, 2316, 2103, 2379, 1988, 3276, 2306, 2799]
	| approx positives in sample 512: 275
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 31, 32, 34, 33, 42, 31, 46]
	Time taken saving stuff: 15.01s
episode: 1591/2000 -> reward: -124.99999999999622, steps:81024, time-taken: 3.33min, time-elasped: 5055.63min
-> berries picked: 132 of 800 | patches-visited: [7, 9] | positive-in-buffer: 19534 | amount-filled: 100.00%
	| epsilon: 0.13886406710226143
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2319, 2321, 2108, 2385, 1994, 3282, 2317, 2808]
	| approx positives in sample 512: 205
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 27, 22, 22, 22, 30, 31, 26]
	Time taken saving stuff: 0.01s
episode: 1592/2000 -> reward: -124.9999999999927, steps:83520, time-taken: 3.18min, time-elasped: 5058.81min
-> berries picked: 143 of 800 | patches-visited: [1, 4] | positive-in-buffer: 19450 | amount-filled: 100.00%
	| epsilon: 0.138752365505351
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2316, 2318, 2087, 2370, 1974, 3267, 2316, 2802]
	| approx positives in sample 512: 199
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 23, 16, 24, 15, 44, 20, 33]
	Time taken saving stuff: 0.00s
episode: 1593/2000 -> reward: -124.99999999999055, steps:86304, time-taken: 3.42min, time-elasped: 5062.23min
-> berries picked: 151 of 800 | patches-visited: [0, 2, 4] | positive-in-buffer: 19404 | amount-filled: 100.00%
	| epsilon: 0.13864075376067528
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2320, 2305, 2079, 2357, 1975, 3270, 2301, 2797]
	| approx positives in sample 512: 207
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 33, 20, 29, 15, 33, 21, 32]
	Time taken saving stuff: 15.32s
episode: 1594/2000 -> reward: -124.99999999999034, steps:81024, time-taken: 3.56min, time-elasped: 5066.05min
-> berries picked: 130 of 800 | patches-visited: [6, 9] | positive-in-buffer: 19282 | amount-filled: 100.00%
	| epsilon: 0.13852923179595758
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2306, 2293, 2057, 2353, 1939, 3269, 2287, 2778]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 30, 25, 20, 21, 30, 36, 32]
	Time taken saving stuff: 0.01s
episode: 1595/2000 -> reward: -124.99999999999203, steps:59328, time-taken: 2.10min, time-elasped: 5068.16min
-> berries picked: 44 of 800 | patches-visited: [5] | positive-in-buffer: 19290 | amount-filled: 100.00%
	| epsilon: 0.13841779953897934
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2311, 2294, 2063, 2352, 1939, 3266, 2288, 2777]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 30, 22, 22, 23, 30, 25, 30]
	Time taken saving stuff: 0.01s
episode: 1596/2000 -> reward: -124.99999999999201, steps:53568, time-taken: 2.36min, time-elasped: 5070.52min
-> berries picked: 20 of 800 | patches-visited: [3] | positive-in-buffer: 19280 | amount-filled: 100.00%
	| epsilon: 0.13830645691758003
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2310, 2295, 2063, 2351, 1934, 3263, 2287, 2777]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 29, 28, 29, 20, 36, 28, 28]
	Time taken saving stuff: 15.37s
episode: 1597/2000 -> reward: -124.99999999999221, steps:60384, time-taken: 2.41min, time-elasped: 5073.18min
-> berries picked: 48 of 800 | patches-visited: [5] | positive-in-buffer: 19310 | amount-filled: 100.00%
	| epsilon: 0.13819520385965725
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2314, 2295, 2067, 2354, 1941, 3270, 2289, 2780]
	| approx positives in sample 512: 194
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 29, 15, 16, 21, 34, 30, 31]
	Time taken saving stuff: 0.01s
episode: 1598/2000 -> reward: -124.99999999999045, steps:79200, time-taken: 3.21min, time-elasped: 5076.40min
-> berries picked: 128 of 800 | patches-visited: [7, 9] | positive-in-buffer: 19342 | amount-filled: 100.00%
	| epsilon: 0.13808404029316657
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2318, 2298, 2071, 2361, 1944, 3281, 2290, 2779]
	| approx positives in sample 512: 203
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 23, 23, 20, 15, 37, 30, 38]
	Time taken saving stuff: 0.01s
episode: 1599/2000 -> reward: -124.99999999999537, steps:78816, time-taken: 3.21min, time-elasped: 5079.61min
-> berries picked: 128 of 800 | patches-visited: [1, 3] | positive-in-buffer: 19408 | amount-filled: 100.00%
	| epsilon: 0.1379729661461215
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2327, 2298, 2083, 2373, 1954, 3287, 2297, 2789]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 30, 17, 32, 21, 34, 38, 31]
	Time taken saving stuff: 15.45s
episode: 1600/2000 -> reward: -124.99999999999224, steps:83424, time-taken: 3.35min, time-elasped: 5083.21min
-> berries picked: 138 of 800 | patches-visited: [3, 9] | positive-in-buffer: 19438 | amount-filled: 100.00%
	| epsilon: 0.13786198134659347
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2328, 2304, 2078, 2377, 1956, 3285, 2311, 2799]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 26, 25, 24, 18, 46, 20, 24]
	Time taken saving stuff: 0.01s
episode: 1601/2000 -> reward: -124.9999999999855, steps:101376, time-taken: 4.39min, time-elasped: 5087.60min
-> berries picked: 223 of 800 | patches-visited: [0, 4, 5] | positive-in-buffer: 19405 | amount-filled: 100.00%
	| epsilon: 0.13775108582271176
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2337, 2304, 2066, 2371, 1949, 3272, 2312, 2794]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 25, 25, 29, 18, 36, 26, 36]
	Time taken saving stuff: 0.01s
episode: 1602/2000 -> reward: -124.99999999999051, steps:72384, time-taken: 3.58min, time-elasped: 5091.18min
-> berries picked: 95 of 800 | patches-visited: [6, 9] | positive-in-buffer: 19402 | amount-filled: 100.00%
	| epsilon: 0.13764027950266344
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2338, 2300, 2063, 2373, 1948, 3277, 2314, 2789]
	| approx positives in sample 512: 245
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 26, 32, 26, 22, 46, 42, 33]
	Time taken saving stuff: 15.22s
episode: 1603/2000 -> reward: -124.99999999998818, steps:83616, time-taken: 3.49min, time-elasped: 5094.93min
-> berries picked: 135 of 800 | patches-visited: [0, 7] | positive-in-buffer: 19479 | amount-filled: 100.00%
	| epsilon: 0.13752956231469338
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2347, 2309, 2071, 2382, 1951, 3291, 2330, 2798]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 24, 22, 24, 20, 46, 26, 30]
	Time taken saving stuff: 0.01s
episode: 1604/2000 -> reward: -124.99999999997605, steps:98976, time-taken: 4.29min, time-elasped: 5099.22min
-> berries picked: 196 of 800 | patches-visited: [1, 3, 4] | positive-in-buffer: 19449 | amount-filled: 100.00%
	| epsilon: 0.13741893418710419
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2350, 2307, 2056, 2377, 1950, 3288, 2323, 2798]
	| approx positives in sample 512: 226
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 29, 28, 20, 23, 43, 35, 28]
	Time taken saving stuff: 0.01s
episode: 1605/2000 -> reward: -124.99999999999393, steps:77088, time-taken: 3.26min, time-elasped: 5102.49min
-> berries picked: 118 of 800 | patches-visited: [2, 7] | positive-in-buffer: 19495 | amount-filled: 100.00%
	| epsilon: 0.13730839504825607
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2355, 2314, 2062, 2385, 1957, 3296, 2322, 2804]
	| approx positives in sample 512: 243
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 34, 30, 30, 26, 50, 25, 25]
	Time taken saving stuff: 15.15s
episode: 1606/2000 -> reward: -124.999999999995, steps:93696, time-taken: 4.38min, time-elasped: 5107.12min
-> berries picked: 173 of 800 | patches-visited: [0, 1, 2, 6] | positive-in-buffer: 19558 | amount-filled: 100.00%
	| epsilon: 0.13719794482656694
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2368, 2327, 2068, 2398, 1961, 3295, 2330, 2811]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 37, 21, 23, 22, 32, 31, 34]
	Time taken saving stuff: 0.01s
episode: 1607/2000 -> reward: -124.99999999999446, steps:105024, time-taken: 4.53min, time-elasped: 5111.65min
-> berries picked: 220 of 800 | patches-visited: [1, 2, 4, 6] | positive-in-buffer: 19612 | amount-filled: 100.00%
	| epsilon: 0.13708758345051222
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2371, 2328, 2084, 2409, 1966, 3304, 2337, 2813]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [43, 25, 16, 23, 23, 37, 29, 32]
	Time taken saving stuff: 0.01s
episode: 1608/2000 -> reward: -124.99999999999139, steps:62976, time-taken: 2.34min, time-elasped: 5114.00min
-> berries picked: 56 of 800 | patches-visited: [1] | positive-in-buffer: 19292 | amount-filled: 100.00%
	| epsilon: 0.13697731084862497
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2347, 2296, 2030, 2360, 1914, 3263, 2296, 2786]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 26, 27, 40, 22, 24, 27, 27]
	Time taken saving stuff: 14.87s
episode: 1609/2000 -> reward: -124.99999999999184, steps:64992, time-taken: 2.31min, time-elasped: 5116.55min
-> berries picked: 60 of 800 | patches-visited: [5] | positive-in-buffer: 19250 | amount-filled: 100.00%
	| epsilon: 0.1368671269494956
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2346, 2286, 2024, 2354, 1900, 3257, 2293, 2790]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 34, 29, 28, 16, 31, 25, 27]
	Time taken saving stuff: 0.01s
episode: 1610/2000 -> reward: -124.99999999999228, steps:66432, time-taken: 3.15min, time-elasped: 5119.71min
-> berries picked: 73 of 800 | patches-visited: [0] | positive-in-buffer: 19181 | amount-filled: 100.00%
	| epsilon: 0.13675703168177203
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2338, 2284, 2012, 2347, 1892, 3249, 2276, 2783]
	| approx positives in sample 512: 266
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [36, 25, 32, 24, 22, 55, 31, 41]
	Time taken saving stuff: 0.01s
episode: 1611/2000 -> reward: -124.99999999999189, steps:84576, time-taken: 3.45min, time-elasped: 5123.16min
-> berries picked: 140 of 800 | patches-visited: [5, 6, 7] | positive-in-buffer: 19280 | amount-filled: 100.00%
	| epsilon: 0.13664702497415965
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2352, 2292, 2018, 2364, 1901, 3268, 2285, 2800]
	| approx positives in sample 512: 210
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 34, 16, 27, 27, 29, 22, 21]
	Time taken saving stuff: 14.92s
episode: 1612/2000 -> reward: -124.9999999999869, steps:62304, time-taken: 2.53min, time-elasped: 5125.93min
-> berries picked: 55 of 800 | patches-visited: [7] | positive-in-buffer: 19278 | amount-filled: 100.00%
	| epsilon: 0.13653710675542108
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2348, 2294, 2027, 2364, 1898, 3263, 2282, 2802]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 23, 13, 23, 25, 35, 30, 39]
	Time taken saving stuff: 0.01s
episode: 1613/2000 -> reward: -124.99999999999565, steps:117984, time-taken: 5.37min, time-elasped: 5131.31min
-> berries picked: 263 of 800 | patches-visited: [0, 1, 4, 9] | positive-in-buffer: 19415 | amount-filled: 100.00%
	| epsilon: 0.1364272769543763
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2366, 2309, 2038, 2386, 1916, 3289, 2292, 2819]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 25, 20, 32, 21, 30, 37, 30]
	Time taken saving stuff: 0.01s
episode: 1614/2000 -> reward: -124.99999999999059, steps:75456, time-taken: 3.19min, time-elasped: 5134.50min
-> berries picked: 112 of 800 | patches-visited: [1, 3] | positive-in-buffer: 19437 | amount-filled: 100.00%
	| epsilon: 0.1363175354999025
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2371, 2307, 2043, 2386, 1924, 3290, 2298, 2818]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 23, 24, 24, 26, 35, 41, 23]
	Time taken saving stuff: 14.54s
episode: 1615/2000 -> reward: -124.99999999998386, steps:72096, time-taken: 3.16min, time-elasped: 5137.90min
-> berries picked: 85 of 800 | patches-visited: [3, 8] | positive-in-buffer: 19445 | amount-filled: 100.00%
	| epsilon: 0.13620788232093417
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2373, 2307, 2046, 2394, 1920, 3291, 2297, 2817]
	| approx positives in sample 512: 236
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 29, 30, 32, 23, 26, 27, 34]
	Time taken saving stuff: 0.01s
episode: 1616/2000 -> reward: -124.99999999999142, steps:101280, time-taken: 4.38min, time-elasped: 5142.29min
-> berries picked: 207 of 800 | patches-visited: [1, 2, 5, 9] | positive-in-buffer: 19508 | amount-filled: 100.00%
	| epsilon: 0.13609831734646288
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2383, 2319, 2049, 2406, 1926, 3297, 2300, 2828]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 23, 20, 30, 31, 34, 18, 35]
	Time taken saving stuff: 0.01s
episode: 1617/2000 -> reward: -124.99999999999483, steps:98304, time-taken: 4.32min, time-elasped: 5146.61min
-> berries picked: 184 of 800 | patches-visited: [0, 8, 9] | positive-in-buffer: 19452 | amount-filled: 100.00%
	| epsilon: 0.1359888405055374
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2370, 2310, 2050, 2391, 1932, 3289, 2291, 2819]
	| approx positives in sample 512: 241
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 36, 21, 30, 27, 41, 29, 30]
	Time taken saving stuff: 14.98s
episode: 1618/2000 -> reward: -124.99999999999226, steps:74688, time-taken: 3.22min, time-elasped: 5150.08min
-> berries picked: 101 of 800 | patches-visited: [1, 2] | positive-in-buffer: 19443 | amount-filled: 100.00%
	| epsilon: 0.13587945172726343
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2372, 2314, 2049, 2390, 1924, 3288, 2293, 2813]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 38, 29, 31, 16, 31, 21, 25]
	Time taken saving stuff: 0.01s
episode: 1619/2000 -> reward: -124.99999999999167, steps:65184, time-taken: 2.33min, time-elasped: 5152.41min
-> berries picked: 67 of 800 | patches-visited: [9] | positive-in-buffer: 19446 | amount-filled: 100.00%
	| epsilon: 0.13577015094080389
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2374, 2315, 2052, 2390, 1928, 3283, 2292, 2812]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 34, 25, 15, 23, 32, 26, 42]
	Time taken saving stuff: 0.01s
episode: 1620/2000 -> reward: -124.99999999999359, steps:63936, time-taken: 2.41min, time-elasped: 5154.83min
-> berries picked: 59 of 800 | patches-visited: [5] | positive-in-buffer: 19232 | amount-filled: 100.00%
	| epsilon: 0.1356609380753785
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2348, 2282, 2041, 2366, 1900, 3243, 2266, 2786]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 27, 21, 28, 20, 30, 28, 34]
	Time taken saving stuff: 15.05s
episode: 1621/2000 -> reward: -124.99999999999211, steps:64800, time-taken: 2.40min, time-elasped: 5157.48min
-> berries picked: 74 of 800 | patches-visited: [3] | positive-in-buffer: 19235 | amount-filled: 100.00%
	| epsilon: 0.13555181306026406
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2350, 2285, 2045, 2363, 1902, 3235, 2265, 2790]
	| approx positives in sample 512: 190
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 26, 21, 21, 17, 37, 20, 29]
	Time taken saving stuff: 0.01s
episode: 1622/2000 -> reward: -124.99999999999173, steps:79296, time-taken: 3.17min, time-elasped: 5160.66min
-> berries picked: 119 of 800 | patches-visited: [5, 7] | positive-in-buffer: 19258 | amount-filled: 100.00%
	| epsilon: 0.13544277582479414
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2356, 2286, 2038, 2370, 1904, 3239, 2267, 2798]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 27, 37, 28, 19, 36, 22, 32]
	Time taken saving stuff: 0.01s
episode: 1623/2000 -> reward: -124.99999999997965, steps:97056, time-taken: 4.24min, time-elasped: 5164.90min
-> berries picked: 182 of 800 | patches-visited: [0, 1, 7] | positive-in-buffer: 19395 | amount-filled: 100.00%
	| epsilon: 0.13533382629835924
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2372, 2306, 2053, 2383, 1916, 3270, 2281, 2814]
	| approx positives in sample 512: 245
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 41, 24, 29, 19, 42, 23, 35]
	Time taken saving stuff: 15.76s
episode: 1624/2000 -> reward: -124.99999999999315, steps:90912, time-taken: 4.34min, time-elasped: 5169.50min
-> berries picked: 171 of 800 | patches-visited: [6, 7, 9] | positive-in-buffer: 19457 | amount-filled: 100.00%
	| epsilon: 0.13522496441040666
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2378, 2320, 2054, 2386, 1918, 3280, 2293, 2828]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 23, 25, 27, 28, 42, 28, 30]
	Time taken saving stuff: 0.01s
episode: 1625/2000 -> reward: -124.99999999999551, steps:89376, time-taken: 4.16min, time-elasped: 5173.66min
-> berries picked: 156 of 800 | patches-visited: [2, 6, 9] | positive-in-buffer: 19516 | amount-filled: 100.00%
	| epsilon: 0.1351161900904404
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2390, 2329, 2060, 2393, 1924, 3290, 2299, 2831]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 35, 21, 26, 18, 44, 28, 32]
	Time taken saving stuff: 0.00s
episode: 1626/2000 -> reward: -124.99999999999201, steps:64320, time-taken: 2.38min, time-elasped: 5176.04min
-> berries picked: 64 of 800 | patches-visited: [3] | positive-in-buffer: 19526 | amount-filled: 100.00%
	| epsilon: 0.13500750326802116
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2391, 2328, 2059, 2394, 1932, 3286, 2303, 2833]
	| approx positives in sample 512: 188
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 16, 21, 23, 15, 19, 28, 34]
	Time taken saving stuff: 15.25s
episode: 1627/2000 -> reward: -124.99999999998795, steps:89472, time-taken: 4.17min, time-elasped: 5180.47min
-> berries picked: 161 of 800 | patches-visited: [0, 5, 6] | positive-in-buffer: 19451 | amount-filled: 100.00%
	| epsilon: 0.13489890387276635
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2386, 2331, 2049, 2374, 1907, 3283, 2293, 2828]
	| approx positives in sample 512: 248
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [37, 36, 26, 29, 21, 40, 33, 26]
	Time taken saving stuff: 0.00s
episode: 1628/2000 -> reward: -124.99999999998583, steps:97728, time-taken: 4.54min, time-elasped: 5185.01min
-> berries picked: 198 of 800 | patches-visited: [2, 3, 6] | positive-in-buffer: 19559 | amount-filled: 100.00%
	| epsilon: 0.13479039183434996
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2400, 2340, 2060, 2389, 1922, 3299, 2306, 2843]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 32, 18, 25, 27, 33, 32, 28]
	Time taken saving stuff: 0.01s
episode: 1629/2000 -> reward: -124.999999999992, steps:63456, time-taken: 2.29min, time-elasped: 5187.30min
-> berries picked: 61 of 800 | patches-visited: [0] | positive-in-buffer: 19543 | amount-filled: 100.00%
	| epsilon: 0.13468196708250257
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2399, 2339, 2055, 2387, 1915, 3296, 2303, 2849]
	| approx positives in sample 512: 203
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 28, 24, 23, 17, 35, 25, 29]
	Time taken saving stuff: 15.10s
episode: 1630/2000 -> reward: -124.99999999999206, steps:76416, time-taken: 3.28min, time-elasped: 5190.84min
-> berries picked: 108 of 800 | patches-visited: [0, 4, 8] | positive-in-buffer: 19394 | amount-filled: 100.00%
	| epsilon: 0.1345736295470113
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2385, 2319, 2048, 2367, 1902, 3261, 2290, 2822]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 21, 24, 31, 21, 38, 26, 42]
	Time taken saving stuff: 0.01s
episode: 1631/2000 -> reward: -124.99999999999274, steps:71040, time-taken: 3.23min, time-elasped: 5194.08min
-> berries picked: 85 of 800 | patches-visited: [1, 2] | positive-in-buffer: 19431 | amount-filled: 100.00%
	| epsilon: 0.1344653791577197
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2390, 2320, 2052, 2377, 1913, 3266, 2293, 2820]
	| approx positives in sample 512: 240
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 36, 36, 35, 23, 36, 26, 22]
	Time taken saving stuff: 0.01s
episode: 1632/2000 -> reward: -124.99999999999339, steps:94560, time-taken: 4.53min, time-elasped: 5198.61min
-> berries picked: 187 of 800 | patches-visited: [2, 4, 7] | positive-in-buffer: 19520 | amount-filled: 100.00%
	| epsilon: 0.13435721584452778
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2396, 2332, 2061, 2387, 1927, 3286, 2303, 2828]
	| approx positives in sample 512: 233
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 31, 25, 23, 22, 38, 31, 38]
	Time taken saving stuff: 15.57s
episode: 1633/2000 -> reward: -124.99999999999206, steps:59040, time-taken: 2.15min, time-elasped: 5201.02min
-> berries picked: 43 of 800 | patches-visited: [9] | positive-in-buffer: 19499 | amount-filled: 100.00%
	| epsilon: 0.13424913953739195
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2396, 2325, 2059, 2386, 1923, 3282, 2302, 2826]
	| approx positives in sample 512: 223
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 32, 27, 22, 20, 36, 34, 30]
	Time taken saving stuff: 0.01s
episode: 1634/2000 -> reward: -124.99999999999203, steps:62208, time-taken: 2.28min, time-elasped: 5203.30min
-> berries picked: 55 of 800 | patches-visited: [0] | positive-in-buffer: 19389 | amount-filled: 100.00%
	| epsilon: 0.1341411501663249
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2388, 2313, 2043, 2374, 1916, 3259, 2284, 2812]
	| approx positives in sample 512: 197
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 23, 16, 21, 21, 37, 22, 33]
	Time taken saving stuff: 0.01s
episode: 1635/2000 -> reward: -124.99999999999223, steps:65760, time-taken: 2.34min, time-elasped: 5205.64min
-> berries picked: 72 of 800 | patches-visited: [1] | positive-in-buffer: 19337 | amount-filled: 100.00%
	| epsilon: 0.1340332476613958
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2382, 2310, 2039, 2367, 1905, 3252, 2273, 2809]
	| approx positives in sample 512: 191
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 33, 12, 30, 13, 36, 27, 21]
	Time taken saving stuff: 15.41s
episode: 1636/2000 -> reward: -124.99999999999329, steps:81408, time-taken: 3.34min, time-elasped: 5209.24min
-> berries picked: 128 of 800 | patches-visited: [3, 9] | positive-in-buffer: 19317 | amount-filled: 100.00%
	| epsilon: 0.1339254319527298
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2382, 2303, 2028, 2376, 1900, 3247, 2273, 2808]
	| approx positives in sample 512: 223
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 29, 23, 27, 13, 44, 24, 35]
	Time taken saving stuff: 0.01s
episode: 1637/2000 -> reward: -124.99999999999203, steps:50496, time-taken: 2.03min, time-elasped: 5211.27min
-> berries picked: 7 of 800 | patches-visited: [8] | positive-in-buffer: 19302 | amount-filled: 100.00%
	| epsilon: 0.1338177029705085
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2376, 2301, 2028, 2371, 1900, 3248, 2271, 2807]
	| approx positives in sample 512: 237
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 29, 22, 28, 27, 46, 23, 31]
	Time taken saving stuff: 0.01s
episode: 1638/2000 -> reward: -124.99999999999235, steps:63648, time-taken: 2.29min, time-elasped: 5213.56min
-> berries picked: 60 of 800 | patches-visited: [1] | positive-in-buffer: 19332 | amount-filled: 100.00%
	| epsilon: 0.13371006064496946
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2379, 2306, 2029, 2375, 1906, 3250, 2277, 2810]
	| approx positives in sample 512: 203
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 24, 17, 30, 28, 27, 32, 20]
	Time taken saving stuff: 15.09s
episode: 1639/2000 -> reward: -124.99999999999345, steps:94368, time-taken: 4.21min, time-elasped: 5218.02min
-> berries picked: 183 of 800 | patches-visited: [1, 3, 8] | positive-in-buffer: 19380 | amount-filled: 100.00%
	| epsilon: 0.13360250490640654
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2385, 2311, 2035, 2387, 1910, 3250, 2285, 2817]
	| approx positives in sample 512: 230
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 27, 23, 24, 22, 51, 25, 24]
	Time taken saving stuff: 0.01s
episode: 1640/2000 -> reward: -124.99999999999196, steps:77664, time-taken: 3.14min, time-elasped: 5221.17min
-> berries picked: 110 of 800 | patches-visited: [3, 4] | positive-in-buffer: 19443 | amount-filled: 100.00%
	| epsilon: 0.13349503568516957
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2391, 2322, 2041, 2390, 1919, 3259, 2294, 2827]
	| approx positives in sample 512: 238
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 20, 19, 35, 34, 42, 24, 37]
	Time taken saving stuff: 0.01s
episode: 1641/2000 -> reward: -124.9999999999919, steps:67488, time-taken: 3.11min, time-elasped: 5224.28min
-> berries picked: 72 of 800 | patches-visited: [2, 8] | positive-in-buffer: 19467 | amount-filled: 100.00%
	| epsilon: 0.13338765291166438
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2393, 2323, 2043, 2395, 1921, 3266, 2297, 2829]
	| approx positives in sample 512: 251
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 40, 27, 32, 17, 42, 34, 36]
	Time taken saving stuff: 15.17s
episode: 1642/2000 -> reward: -124.9999999999827, steps:107712, time-taken: 5.06min, time-elasped: 5229.59min
-> berries picked: 221 of 800 | patches-visited: [0, 2, 7, 8, 9] | positive-in-buffer: 19600 | amount-filled: 100.00%
	| epsilon: 0.1332803565163529
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2407, 2342, 2055, 2409, 1931, 3282, 2323, 2851]
	| approx positives in sample 512: 208
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 18, 24, 22, 19, 38, 22, 34]
	Time taken saving stuff: 0.02s
episode: 1643/2000 -> reward: -124.99999999999548, steps:78432, time-taken: 3.41min, time-elasped: 5233.00min
-> berries picked: 127 of 800 | patches-visited: [0, 9] | positive-in-buffer: 19445 | amount-filled: 100.00%
	| epsilon: 0.13317314642975284
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2396, 2337, 2023, 2386, 1902, 3253, 2307, 2841]
	| approx positives in sample 512: 194
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 28, 23, 22, 16, 35, 22, 24]
	Time taken saving stuff: 0.01s
episode: 1644/2000 -> reward: -124.99999999999527, steps:94080, time-taken: 4.20min, time-elasped: 5237.20min
-> berries picked: 182 of 800 | patches-visited: [0, 4, 8] | positive-in-buffer: 19557 | amount-filled: 100.00%
	| epsilon: 0.1330660225824379
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2413, 2356, 2035, 2395, 1925, 3268, 2313, 2852]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 27, 22, 37, 16, 48, 15, 39]
	Time taken saving stuff: 15.44s
episode: 1645/2000 -> reward: -124.99999999999184, steps:68544, time-taken: 2.90min, time-elasped: 5240.36min
-> berries picked: 78 of 800 | patches-visited: [3] | positive-in-buffer: 19557 | amount-filled: 100.00%
	| epsilon: 0.13295898490503766
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2412, 2350, 2036, 2392, 1914, 3272, 2321, 2860]
	| approx positives in sample 512: 245
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 34, 14, 27, 20, 46, 32, 43]
	Time taken saving stuff: 0.01s
episode: 1646/2000 -> reward: -124.99999999999022, steps:76416, time-taken: 2.96min, time-elasped: 5243.31min
-> berries picked: 110 of 800 | patches-visited: [1, 9] | positive-in-buffer: 19598 | amount-filled: 100.00%
	| epsilon: 0.1328520333282374
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2415, 2357, 2045, 2397, 1917, 3277, 2322, 2868]
	| approx positives in sample 512: 235
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 32, 21, 25, 21, 46, 27, 29]
	Time taken saving stuff: 0.00s
episode: 1647/2000 -> reward: -124.99999999999189, steps:99840, time-taken: 4.34min, time-elasped: 5247.66min
-> berries picked: 190 of 800 | patches-visited: [2, 4, 6, 8] | positive-in-buffer: 19665 | amount-filled: 100.00%
	| epsilon: 0.1327451677827782
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2426, 2360, 2048, 2407, 1924, 3294, 2324, 2882]
	| approx positives in sample 512: 240
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 22, 27, 43, 20, 33, 32, 32]
	Time taken saving stuff: 14.79s
episode: 1648/2000 -> reward: -124.99999999999241, steps:66720, time-taken: 2.98min, time-elasped: 5250.89min
-> berries picked: 75 of 800 | patches-visited: [8] | positive-in-buffer: 19558 | amount-filled: 100.00%
	| epsilon: 0.1326383881994569
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2420, 2346, 2030, 2386, 1917, 3268, 2313, 2878]
	| approx positives in sample 512: 233
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 28, 22, 29, 21, 37, 33, 32]
	Time taken saving stuff: 0.00s
episode: 1649/2000 -> reward: -124.99999999998556, steps:113856, time-taken: 5.13min, time-elasped: 5256.02min
-> berries picked: 259 of 800 | patches-visited: [0, 1, 4, 5] | positive-in-buffer: 19689 | amount-filled: 100.00%
	| epsilon: 0.13253169450912594
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2432, 2369, 2044, 2404, 1927, 3285, 2329, 2899]
	| approx positives in sample 512: 240
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 43, 29, 31, 20, 28, 31, 30]
	Time taken saving stuff: 0.00s
episode: 1650/2000 -> reward: -124.99999999999064, steps:76704, time-taken: 3.01min, time-elasped: 5259.04min
-> berries picked: 111 of 800 | patches-visited: [1, 9] | positive-in-buffer: 19692 | amount-filled: 100.00%
	| epsilon: 0.1324250866426934
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2435, 2367, 2044, 2405, 1922, 3284, 2334, 2901]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 34, 18, 25, 18, 51, 29, 32]
	Time taken saving stuff: 15.13s
episode: 1651/2000 -> reward: -124.99999999999233, steps:66816, time-taken: 3.04min, time-elasped: 5262.33min
-> berries picked: 77 of 800 | patches-visited: [8] | positive-in-buffer: 19544 | amount-filled: 100.00%
	| epsilon: 0.13231856453112295
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2409, 2360, 2029, 2379, 1908, 3252, 2324, 2883]
	| approx positives in sample 512: 244
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 30, 19, 33, 17, 41, 36, 38]
	Time taken saving stuff: 0.01s
episode: 1652/2000 -> reward: -122.24999999998691, steps:120000, time-taken: 5.59min, time-elasped: 5267.92min
-> berries picked: 304 of 800 | patches-visited: [1, 2, 3, 4, 5] | positive-in-buffer: 19721 | amount-filled: 100.00%
	| epsilon: 0.1322121281054338
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2439, 2388, 2043, 2412, 1929, 3266, 2339, 2905]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 22, 22, 31, 21, 36, 17, 35]
	Time taken saving stuff: 0.01s
episode: 1653/2000 -> reward: -124.99999999999207, steps:64224, time-taken: 2.23min, time-elasped: 5270.16min
-> berries picked: 62 of 800 | patches-visited: [9] | positive-in-buffer: 19596 | amount-filled: 100.00%
	| epsilon: 0.13210577729670062
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2420, 2371, 2033, 2399, 1914, 3251, 2326, 2882]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 30, 13, 22, 23, 33, 34, 40]
	Time taken saving stuff: 15.24s
episode: 1654/2000 -> reward: -124.99999999999238, steps:66816, time-taken: 2.99min, time-elasped: 5273.41min
-> berries picked: 72 of 800 | patches-visited: [2] | positive-in-buffer: 19357 | amount-filled: 100.00%
	| epsilon: 0.13199951203605353
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2397, 2342, 2018, 2373, 1865, 3204, 2307, 2851]
	| approx positives in sample 512: 241
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [36, 25, 25, 36, 18, 35, 28, 38]
	Time taken saving stuff: 0.00s
episode: 1655/2000 -> reward: -124.99999999999072, steps:75456, time-taken: 3.15min, time-elasped: 5276.55min
-> berries picked: 107 of 800 | patches-visited: [0, 9] | positive-in-buffer: 19419 | amount-filled: 100.00%
	| epsilon: 0.1318933322546781
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2407, 2352, 2021, 2381, 1869, 3213, 2315, 2861]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 31, 19, 27, 15, 49, 36, 30]
	Time taken saving stuff: 0.00s
episode: 1656/2000 -> reward: -124.99999999998941, steps:113568, time-taken: 5.15min, time-elasped: 5281.71min
-> berries picked: 258 of 800 | patches-visited: [0, 2, 3, 5] | positive-in-buffer: 19572 | amount-filled: 100.00%
	| epsilon: 0.1317872378838151
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2417, 2372, 2026, 2410, 1883, 3246, 2334, 2884]
	| approx positives in sample 512: 251
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [37, 28, 21, 32, 20, 46, 31, 36]
	Time taken saving stuff: 15.24s
episode: 1657/2000 -> reward: -124.99999999998688, steps:85344, time-taken: 3.47min, time-elasped: 5285.43min
-> berries picked: 148 of 800 | patches-visited: [2, 6] | positive-in-buffer: 19637 | amount-filled: 100.00%
	| epsilon: 0.13168122885476083
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2430, 2382, 2028, 2409, 1896, 3259, 2338, 2895]
	| approx positives in sample 512: 206
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 27, 19, 23, 17, 32, 23, 36]
	Time taken saving stuff: 0.01s
episode: 1658/2000 -> reward: -124.99999999999184, steps:64128, time-taken: 2.29min, time-elasped: 5287.72min
-> berries picked: 71 of 800 | patches-visited: [4] | positive-in-buffer: 19419 | amount-filled: 100.00%
	| epsilon: 0.13157530509886672
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2395, 2361, 2018, 2367, 1866, 3215, 2317, 2880]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 32, 24, 25, 19, 37, 26, 29]
	Time taken saving stuff: 0.01s
episode: 1659/2000 -> reward: -124.99999999998269, steps:103680, time-taken: 4.28min, time-elasped: 5292.01min
-> berries picked: 223 of 800 | patches-visited: [0, 4, 9] | positive-in-buffer: 19444 | amount-filled: 100.00%
	| epsilon: 0.13146946654753938
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2397, 2370, 2027, 2372, 1854, 3220, 2323, 2881]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 27, 15, 30, 26, 30, 32, 38]
	Time taken saving stuff: 15.05s
episode: 1660/2000 -> reward: -124.99999999999206, steps:58656, time-taken: 2.10min, time-elasped: 5294.36min
-> berries picked: 40 of 800 | patches-visited: [6] | positive-in-buffer: 19419 | amount-filled: 100.00%
	| epsilon: 0.13136371313224074
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2395, 2368, 2020, 2375, 1852, 3209, 2321, 2879]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 29, 16, 32, 22, 38, 21, 37]
	Time taken saving stuff: 0.01s
episode: 1661/2000 -> reward: -124.99999999999211, steps:60192, time-taken: 2.07min, time-elasped: 5296.43min
-> berries picked: 51 of 800 | patches-visited: [7] | positive-in-buffer: 19401 | amount-filled: 100.00%
	| epsilon: 0.13125804478448774
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2392, 2367, 2026, 2367, 1855, 3206, 2317, 2871]
	| approx positives in sample 512: 211
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 29, 19, 27, 21, 40, 21, 34]
	Time taken saving stuff: 0.01s
episode: 1662/2000 -> reward: -124.99999999999243, steps:61824, time-taken: 2.26min, time-elasped: 5298.70min
-> berries picked: 50 of 800 | patches-visited: [7] | positive-in-buffer: 19327 | amount-filled: 100.00%
	| epsilon: 0.13115246143585246
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2380, 2354, 2016, 2355, 1851, 3190, 2317, 2864]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 30, 20, 30, 18, 40, 28, 27]
	Time taken saving stuff: 15.17s
episode: 1663/2000 -> reward: -124.9999999999917, steps:79776, time-taken: 3.24min, time-elasped: 5302.19min
-> berries picked: 123 of 800 | patches-visited: [3, 8] | positive-in-buffer: 19354 | amount-filled: 100.00%
	| epsilon: 0.13104696301796204
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2382, 2357, 2019, 2360, 1848, 3192, 2318, 2878]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 26, 22, 27, 21, 40, 31, 29]
	Time taken saving stuff: 0.01s
episode: 1664/2000 -> reward: -124.99999999999359, steps:81120, time-taken: 3.15min, time-elasped: 5305.34min
-> berries picked: 135 of 800 | patches-visited: [0, 6] | positive-in-buffer: 19398 | amount-filled: 100.00%
	| epsilon: 0.13094154946249856
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2390, 2362, 2021, 2364, 1857, 3200, 2320, 2884]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 28, 32, 30, 14, 24, 38, 26]
	Time taken saving stuff: 0.01s
episode: 1665/2000 -> reward: -124.99999999999262, steps:72864, time-taken: 2.98min, time-elasped: 5308.33min
-> berries picked: 107 of 800 | patches-visited: [5, 7] | positive-in-buffer: 19393 | amount-filled: 100.00%
	| epsilon: 0.13083622070119907
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2393, 2361, 2021, 2363, 1855, 3198, 2324, 2878]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 34, 20, 25, 23, 40, 24, 25]
	Time taken saving stuff: 12.02s
episode: 1666/2000 -> reward: -124.99999999999292, steps:96288, time-taken: 4.16min, time-elasped: 5312.69min
-> berries picked: 191 of 800 | patches-visited: [1, 2, 7] | positive-in-buffer: 19473 | amount-filled: 100.00%
	| epsilon: 0.1307309766658556
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2403, 2366, 2031, 2367, 1869, 3213, 2331, 2893]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 27, 20, 29, 21, 33, 25, 35]
	Time taken saving stuff: 0.00s
episode: 1667/2000 -> reward: -124.99999999999172, steps:72288, time-taken: 3.10min, time-elasped: 5315.79min
-> berries picked: 94 of 800 | patches-visited: [0, 8] | positive-in-buffer: 19497 | amount-filled: 100.00%
	| epsilon: 0.13062581728831493
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2406, 2373, 2034, 2372, 1871, 3214, 2332, 2895]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 36, 21, 22, 19, 34, 29, 38]
	Time taken saving stuff: 0.00s
episode: 1668/2000 -> reward: -124.99999999999207, steps:64224, time-taken: 2.18min, time-elasped: 5317.97min
-> berries picked: 59 of 800 | patches-visited: [1] | positive-in-buffer: 19513 | amount-filled: 100.00%
	| epsilon: 0.1305207425004788
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2405, 2376, 2035, 2382, 1870, 3214, 2332, 2899]
	| approx positives in sample 512: 183
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 25, 18, 22, 16, 31, 30, 22]
	Time taken saving stuff: 12.44s
episode: 1669/2000 -> reward: -124.99999999999501, steps:76704, time-taken: 3.07min, time-elasped: 5321.25min
-> berries picked: 123 of 800 | patches-visited: [7, 8] | positive-in-buffer: 19310 | amount-filled: 100.00%
	| epsilon: 0.13041575223430357
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2378, 2355, 2007, 2366, 1848, 3194, 2308, 2854]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 25, 23, 25, 19, 44, 28, 31]
	Time taken saving stuff: 0.01s
episode: 1670/2000 -> reward: -124.99999999999304, steps:81504, time-taken: 3.21min, time-elasped: 5324.46min
-> berries picked: 128 of 800 | patches-visited: [0, 3, 5] | positive-in-buffer: 19381 | amount-filled: 100.00%
	| epsilon: 0.13031084642180046
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2383, 2361, 2015, 2374, 1860, 3208, 2313, 2867]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 26, 26, 26, 24, 35, 22, 35]
	Time taken saving stuff: 0.01s
