getBabyEnv :
	 logDir : .temp\2022-5-18 13-39-15
	 initial_juice : 0.5
	 end_on_boundary_hit : False
	 penalize_boundary_hit : False
	 allow_no_action : False
	 no_action_threshold : 0.7
	 field_size : (20000, 20000)
	 initial_pos_around_berry : True
	 living_cost : True
	 nberries : 80
	 num_patches : 10
	 patch_size : (2000, 2000)
	 show : False
	 spawn_radius : 100


with living cost, rewards scaled by 1/(berry_env.REWARD_RATE*MAXSIZE)
Agent :
	 self : <Agent.Agent object at 0x0000027E92852648>
	 berryField : <BerryFieldEnv instance>
	 mode : train
	 field_grid_size : (40, 40)
	 angle : 45
	 persistence : 0.7
	 worth_offset : 0.0
	 noise : 0.01
	 positive_emphasis : True
	 emphasis_mode : replace
	 memory_alpha : 0.995
	 time_memory_delta : 0.005
	 time_memory_exp : 1
	 disjoint : False
	 debug : False
	 debugDir : .temp


positive rewards are now emphasised in the state-transitions
            Once a berry is encountered (say at index i), new transitions of the following
            description will also be appended (if emphasis_mode = 'append') or the entries 
            will be replaced: all the transitions k < i such that the sum of reward from
            k to i is positive will have the next-state replaced by the state at transition
            at index i. And the rewards will also be replaced by the summation from k to i.
            currently, emphasis-mode is replace.
            if disjoint=True, then k is limited to the index of the last berry seen
            currently disjoint behaviour is set to False

total-params:  5377
net(
  (feedforward): ModuleList(
    (0): Linear(in_features=38, out_features=16, bias=True)
    (1): Linear(in_features=16, out_features=8, bias=True)
  )
  (conv1): ModuleList(
    (0): Conv2d(1, 8, kernel_size=(4, 4), stride=(2, 2), padding=(3, 3))
    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (2): Conv2d(8, 8, kernel_size=(3, 3), stride=(2, 2), padding=(3, 3))
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(8, 16, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1))
  )
  (final_stage): ModuleList(
    (0): Linear(in_features=200, out_features=16, bias=True)
  )
  (valueL): Linear(in_features=16, out_features=1, bias=True)
  (actadvs): Linear(in_features=16, out_features=8, bias=True)
)
lr used = 0.00005
optimizing the online-model after every 1000 actions (skipSteps=10)
Using greedy strategy as evalExplortionStrategy.
episode: 0 -> reward: -124.9999999999922, steps:49152, time-elasped: 86.78s
-> berries picked: 4 of 800 | patches-visited: [5, 6, 8] | positive-in-buffer: 20 | amount-filled: 89.37%
	| epsilon: 0.4989951124587212
	| action-stats:  [0, 2, 3, 5] [2, 6, 5, 7]
	| approx positives in sample 512: 0
	| approx action-dist in sample 512: [] []
episode: 1 -> reward: -124.99999999999122, steps:50208, time-elasped: 184.19s
-> berries picked: 8 of 800 | patches-visited: [0, 6, 8] | positive-in-buffer: 63 | amount-filled: 100.00%
	| epsilon: 0.4979922445153836
	| action-stats:  [0, 2, 3, 4, 5] [2, 27, 20, 7, 7]
	| approx positives in sample 512: 2
	| approx action-dist in sample 512: [2] [2]
episode: 2 -> reward: -124.99999999999208, steps:48480, time-elasped: 290.58s
-> berries picked: 2 of 800 | patches-visited: [3, 4, 7] | positive-in-buffer: 81 | amount-filled: 100.00%
	| epsilon: 0.49699139211104965
	| action-stats:  [0, 2, 3, 4, 5] [2, 45, 20, 7, 7]
	| approx positives in sample 512: 3
	| approx action-dist in sample 512: [0, 2, 5] [1, 1, 1]
episode: 3 -> reward: -124.99999999999203, steps:48288, time-elasped: 384.18s
-> berries picked: 1 of 800 | patches-visited: [0] | positive-in-buffer: 89 | amount-filled: 100.00%
	| epsilon: 0.49599255119493924
	| action-stats:  [0, 2, 3, 4, 5] [2, 53, 20, 7, 7]
	| approx positives in sample 512: 4
	| approx action-dist in sample 512: [2, 3, 5] [1, 1, 2]
episode: 4 -> reward: -124.99999999999207, steps:48864, time-elasped: 486.65s
-> berries picked: 3 of 800 | patches-visited: [3, 8] | positive-in-buffer: 103 | amount-filled: 100.00%
	| epsilon: 0.4949957177244134
	| action-stats:  [0, 2, 3, 4, 5] [2, 53, 20, 21, 7]
	| approx positives in sample 512: 4
	| approx action-dist in sample 512: [2, 4] [2, 2]
episode: 5 -> reward: -124.99999999999193, steps:48960, time-elasped: 591.38s
-> berries picked: 3 of 800 | patches-visited: [0, 9] | positive-in-buffer: 123 | amount-filled: 100.00%
	| epsilon: 0.4940008876649582
	| action-stats:  [0, 1, 2, 3, 4, 5] [2, 7, 53, 20, 34, 7]
	| approx positives in sample 512: 3
	| approx action-dist in sample 512: [2, 5] [2, 1]
episode: 6 -> reward: -124.99999999999206, steps:50016, time-elasped: 729.44s
-> berries picked: 7 of 800 | patches-visited: [8] | positive-in-buffer: 153 | amount-filled: 100.00%
	| epsilon: 0.4930080569901678
	| action-stats:  [0, 1, 2, 3, 4, 5, 7] [2, 7, 53, 26, 51, 7, 7]
	| approx positives in sample 512: 10
	| approx action-dist in sample 512: [1, 2, 3, 4, 5] [1, 3, 2, 3, 1]
episode: 7 -> reward: -124.99999999999217, steps:52128, time-elasped: 845.03s
-> berries picked: 13 of 800 | patches-visited: [3] | positive-in-buffer: 220 | amount-filled: 100.00%
	| epsilon: 0.4920172216817288
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2, 19, 72, 31, 51, 7, 4, 34]
	| approx positives in sample 512: 12
	| approx action-dist in sample 512: [1, 2, 3, 4, 6, 7] [1, 7, 1, 1, 1, 1]
episode: 8 -> reward: -124.99999999999153, steps:49728, time-elasped: 975.10s
-> berries picked: 8 of 800 | patches-visited: [2, 6] | positive-in-buffer: 245 | amount-filled: 100.00%
	| epsilon: 0.4910283777294036
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2, 19, 72, 33, 51, 28, 4, 36]
	| approx positives in sample 512: 10
	| approx action-dist in sample 512: [2, 4, 5, 6, 7] [3, 4, 1, 1, 1]
episode: 9 -> reward: -124.99999999999167, steps:50976, time-elasped: 1121.18s
-> berries picked: 10 of 800 | patches-visited: [1] | positive-in-buffer: 280 | amount-filled: 100.00%
	| epsilon: 0.4900415211310144
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2, 19, 72, 57, 51, 34, 4, 41]
	| approx positives in sample 512: 8
	| approx action-dist in sample 512: [1, 2, 3, 4, 7] [1, 3, 1, 2, 1]
episode: 10 -> reward: -124.99999999999203, steps:48480, time-elasped: 1242.84s
-> berries picked: 2 of 800 | patches-visited: [7, 8] | positive-in-buffer: 289 | amount-filled: 100.00%
	| epsilon: 0.48905664789242664
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2, 19, 72, 66, 51, 34, 4, 41]
	| approx positives in sample 512: 20
	| approx action-dist in sample 512: [1, 2, 3, 4, 6] [4, 8, 1, 6, 1]
episode: 11 -> reward: -124.99999999999302, steps:54240, time-elasped: 1369.71s
-> berries picked: 19 of 800 | patches-visited: [3, 4, 6] | positive-in-buffer: 404 | amount-filled: 100.00%
	| epsilon: 0.4880737540275333
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2, 19, 72, 67, 51, 84, 4, 105]
	| approx positives in sample 512: 10
	| approx action-dist in sample 512: [1, 2, 5, 7] [1, 3, 3, 3]
episode: 12 -> reward: -124.99999999999213, steps:50016, time-elasped: 1524.67s
-> berries picked: 7 of 800 | patches-visited: [0] | positive-in-buffer: 457 | amount-filled: 100.00%
	| epsilon: 0.48709283555823835
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2, 19, 72, 67, 51, 113, 4, 129]
	| approx positives in sample 512: 18
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7] [1, 3, 2, 2, 4, 1, 5]
episode: 13 -> reward: -124.99999999999243, steps:51264, time-elasped: 1652.81s
-> berries picked: 10 of 800 | patches-visited: [1, 2, 9] | positive-in-buffer: 520 | amount-filled: 100.00%
	| epsilon: 0.4861138885144411
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2, 19, 72, 78, 51, 152, 4, 142]
	| approx positives in sample 512: 22
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7] [1, 4, 3, 3, 6, 1, 4]
episode: 14 -> reward: -124.99999999999203, steps:50688, time-elasped: 1816.43s
-> berries picked: 9 of 800 | patches-visited: [5] | positive-in-buffer: 569 | amount-filled: 100.00%
	| epsilon: 0.48513690893401956
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [7, 27, 72, 87, 51, 167, 4, 154]
	| approx positives in sample 512: 22
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 7] [1, 3, 3, 2, 7, 6]
episode: 15 -> reward: -124.99999999999203, steps:51264, time-elasped: 1923.57s
-> berries picked: 9 of 800 | patches-visited: [0] | positive-in-buffer: 609 | amount-filled: 100.00%
	| epsilon: 0.4841618928628149
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [7, 34, 72, 87, 51, 177, 6, 175]
	| approx positives in sample 512: 18
	| approx action-dist in sample 512: [1, 3, 4, 5, 7] [1, 2, 1, 4, 10]
episode: 16 -> reward: -124.99999999999136, steps:50112, time-elasped: 2064.25s
-> berries picked: 7 of 800 | patches-visited: [2] | positive-in-buffer: 641 | amount-filled: 100.00%
	| epsilon: 0.4831888363546153
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [7, 34, 72, 87, 57, 177, 6, 201]
	| approx positives in sample 512: 22
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 7] [3, 4, 4, 2, 5, 4]
episode: 17 -> reward: -124.9999999999922, steps:50880, time-elasped: 2206.74s
-> berries picked: 11 of 800 | patches-visited: [4, 5] | positive-in-buffer: 686 | amount-filled: 100.00%
	| epsilon: 0.4822177354711398
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [7, 45, 80, 87, 68, 177, 6, 216]
	| approx positives in sample 512: 20
	| approx action-dist in sample 512: [0, 1, 2, 3, 5, 7] [1, 4, 2, 2, 7, 4]
episode: 18 -> reward: -124.99999999999187, steps:49056, time-elasped: 2341.12s
-> berries picked: 5 of 800 | patches-visited: [4] | positive-in-buffer: 702 | amount-filled: 100.00%
	| epsilon: 0.4812485862820225
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [9, 45, 84, 87, 68, 187, 6, 216]
	| approx positives in sample 512: 27
	| approx action-dist in sample 512: [2, 3, 4, 5, 7] [1, 6, 3, 3, 14]
episode: 19 -> reward: -124.99999999999162, steps:54720, time-elasped: 2488.18s
-> berries picked: 21 of 800 | patches-visited: [4, 9] | positive-in-buffer: 799 | amount-filled: 100.00%
	| epsilon: 0.4802813848647968
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [9, 75, 85, 91, 70, 211, 11, 247]
	| approx positives in sample 512: 19
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7] [1, 2, 2, 3, 2, 1, 8]
episode: 20 -> reward: -124.99999999999204, steps:48000, time-elasped: 2589.33s
-> berries picked: 0 of 800 | patches-visited: [1] | positive-in-buffer: 799 | amount-filled: 100.00%
	| epsilon: 0.47931612730487927
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [9, 75, 85, 91, 70, 211, 11, 247]
	| approx positives in sample 512: 27
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 7] [2, 2, 5, 2, 9, 7]
episode: 21 -> reward: -124.9999999999919, steps:48768, time-elasped: 2707.41s
-> berries picked: 3 of 800 | patches-visited: [2, 5] | positive-in-buffer: 805 | amount-filled: 100.00%
	| epsilon: 0.4783528096955539
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [9, 75, 85, 97, 70, 211, 11, 247]
	| approx positives in sample 512: 25
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7] [2, 2, 4, 2, 5, 1, 9]
episode: 22 -> reward: -124.99999999999204, steps:51168, time-elasped: 2819.83s
-> berries picked: 10 of 800 | patches-visited: [5] | positive-in-buffer: 867 | amount-filled: 100.00%
	| epsilon: 0.4773914281379564
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [9, 95, 85, 97, 76, 217, 11, 277]
	| approx positives in sample 512: 26
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 7] [2, 2, 2, 2, 7, 11]
episode: 23 -> reward: -124.99999999999137, steps:50592, time-elasped: 2957.26s
-> berries picked: 9 of 800 | patches-visited: [3, 6] | positive-in-buffer: 911 | amount-filled: 100.00%
	| epsilon: 0.4764319787410581
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [9, 102, 85, 101, 76, 231, 11, 296]
	| approx positives in sample 512: 28
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 7] [5, 1, 3, 1, 7, 11]
episode: 24 -> reward: -124.99999999999208, steps:51456, time-elasped: 3077.95s
-> berries picked: 11 of 800 | patches-visited: [3] | positive-in-buffer: 964 | amount-filled: 100.00%
	| epsilon: 0.4754744576216507
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [9, 105, 85, 113, 83, 258, 11, 300]
	| approx positives in sample 512: 14
	| approx action-dist in sample 512: [1, 2, 3, 5, 6, 7] [1, 4, 1, 3, 1, 4]
episode: 25 -> reward: -124.9999999999918, steps:50688, time-elasped: 3192.61s
-> berries picked: 8 of 800 | patches-visited: [6] | positive-in-buffer: 1011 | amount-filled: 100.00%
	| epsilon: 0.4745188609043301
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [9, 109, 91, 145, 83, 263, 11, 300]
	| approx positives in sample 512: 30
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 7] [4, 1, 4, 6, 7, 8]
episode: 26 -> reward: -124.99999999999187, steps:50304, time-elasped: 3301.23s
-> berries picked: 6 of 800 | patches-visited: [8] | positive-in-buffer: 1044 | amount-filled: 100.00%
	| epsilon: 0.4735651847214809
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [9, 137, 91, 150, 83, 263, 11, 300]
	| approx positives in sample 512: 27
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7] [1, 4, 2, 1, 7, 2, 10]
episode: 27 -> reward: -124.99999999999203, steps:49152, time-elasped: 3395.85s
-> berries picked: 4 of 800 | patches-visited: [4] | positive-in-buffer: 1070 | amount-filled: 100.00%
	| epsilon: 0.4726134252132609
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [9, 137, 91, 166, 83, 273, 11, 300]
	| approx positives in sample 512: 41
	| approx action-dist in sample 512: [1, 2, 3, 5, 6, 7] [5, 2, 10, 10, 1, 13]
episode: 28 -> reward: -124.99999999999241, steps:52512, time-elasped: 3514.11s
-> berries picked: 16 of 800 | patches-visited: [5] | positive-in-buffer: 1154 | amount-filled: 100.00%
	| epsilon: 0.47166357852758506
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [9, 154, 97, 187, 88, 283, 19, 317]
	| approx positives in sample 512: 22
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 7] [2, 2, 6, 2, 4, 6]
episode: 29 -> reward: -124.99999999999092, steps:54912, time-elasped: 3676.72s
-> berries picked: 24 of 800 | patches-visited: [0, 1, 3] | positive-in-buffer: 1289 | amount-filled: 100.00%
	| epsilon: 0.47071564082011036
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [36, 171, 132, 192, 98, 292, 33, 335]
	| approx positives in sample 512: 28
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 4, 1, 5, 1, 8, 2, 4]
episode: 30 -> reward: -124.99999999999268, steps:56256, time-elasped: 3842.53s
-> berries picked: 30 of 800 | patches-visited: [1, 2] | positive-in-buffer: 1458 | amount-filled: 100.00%
	| epsilon: 0.46976960825421993
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [38, 212, 139, 232, 102, 344, 45, 346]
	| approx positives in sample 512: 71
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 12, 8, 12, 2, 16, 1, 18]
episode: 31 -> reward: -124.99999999999203, steps:50688, time-elasped: 3947.02s
-> berries picked: 7 of 800 | patches-visited: [3] | positive-in-buffer: 1491 | amount-filled: 100.00%
	| epsilon: 0.46882547700100774
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [38, 223, 139, 244, 102, 344, 45, 356]
	| approx positives in sample 512: 35
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7] [8, 5, 4, 1, 4, 1, 12]
episode: 32 -> reward: -124.99999999999211, steps:52992, time-elasped: 4074.18s
-> berries picked: 15 of 800 | patches-visited: [1] | positive-in-buffer: 1556 | amount-filled: 100.00%
	| epsilon: 0.46788324323926295
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [40, 242, 143, 263, 102, 356, 45, 365]
	| approx positives in sample 512: 40
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7] [6, 2, 6, 3, 8, 1, 14]
episode: 33 -> reward: -124.99999999999216, steps:58080, time-elasped: 4238.64s
-> berries picked: 34 of 800 | patches-visited: [0] | positive-in-buffer: 1740 | amount-filled: 100.00%
	| epsilon: 0.4669429031554544
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [49, 294, 143, 313, 108, 396, 50, 387]
	| approx positives in sample 512: 56
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 10, 3, 10, 1, 14, 3, 12]
episode: 34 -> reward: -124.99999999998985, steps:61248, time-elasped: 4406.12s
-> berries picked: 48 of 800 | patches-visited: [5, 7] | positive-in-buffer: 1987 | amount-filled: 100.00%
	| epsilon: 0.46600445294371545
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [68, 329, 156, 361, 132, 481, 60, 400]
	| approx positives in sample 512: 50
	| approx action-dist in sample 512: [0, 1, 2, 3, 5, 6, 7] [3, 12, 1, 10, 11, 4, 9]
episode: 35 -> reward: -124.99999999999214, steps:53664, time-elasped: 4570.96s
-> berries picked: 20 of 800 | patches-visited: [8] | positive-in-buffer: 2065 | amount-filled: 100.00%
	| epsilon: 0.4650678888058283
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [67, 341, 156, 380, 133, 502, 65, 421]
	| approx positives in sample 512: 44
	| approx action-dist in sample 512: [0, 1, 2, 3, 5, 7] [3, 9, 2, 11, 14, 5]
episode: 36 -> reward: -124.99999999999204, steps:50400, time-elasped: 4685.98s
-> berries picked: 8 of 800 | patches-visited: [4] | positive-in-buffer: 2063 | amount-filled: 100.00%
	| epsilon: 0.46413320695120863
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [62, 352, 156, 372, 130, 500, 65, 426]
	| approx positives in sample 512: 58
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7] [12, 2, 12, 2, 12, 3, 15]
episode: 37 -> reward: -124.99999999999183, steps:52896, time-elasped: 4840.26s
-> berries picked: 20 of 800 | patches-visited: [1] | positive-in-buffer: 2163 | amount-filled: 100.00%
	| epsilon: 0.4632004035968905
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [62, 394, 156, 403, 130, 519, 75, 424]
	| approx positives in sample 512: 51
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 7, 3, 14, 3, 11, 1, 8]
episode: 38 -> reward: -124.99999999999204, steps:50016, time-elasped: 4946.42s
-> berries picked: 6 of 800 | patches-visited: [4] | positive-in-buffer: 2170 | amount-filled: 100.00%
	| epsilon: 0.46226947496751086
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [73, 390, 155, 395, 130, 519, 90, 418]
	| approx positives in sample 512: 46
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7] [7, 4, 6, 4, 15, 2, 8]
episode: 39 -> reward: -124.9999999999925, steps:57792, time-elasped: 5082.04s
-> berries picked: 36 of 800 | patches-visited: [6] | positive-in-buffer: 2329 | amount-filled: 100.00%
	| epsilon: 0.4613404172952942
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [81, 471, 155, 404, 133, 567, 90, 428]
	| approx positives in sample 512: 80
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 15, 3, 17, 8, 15, 2, 16]
episode: 40 -> reward: -124.99999999999285, steps:55488, time-elasped: 5209.06s
-> berries picked: 24 of 800 | patches-visited: [2, 4] | positive-in-buffer: 2454 | amount-filled: 100.00%
	| epsilon: 0.4604132268200373
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [89, 514, 155, 433, 140, 572, 102, 449]
	| approx positives in sample 512: 95
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 28, 3, 14, 6, 15, 4, 20]
episode: 41 -> reward: -124.99999999999147, steps:53952, time-elasped: 5349.20s
-> berries picked: 18 of 800 | patches-visited: [0] | positive-in-buffer: 2535 | amount-filled: 100.00%
	| epsilon: 0.4594878997890945
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [99, 540, 176, 443, 139, 578, 102, 458]
	| approx positives in sample 512: 20
	| approx action-dist in sample 512: [1, 3, 4, 5, 6, 7] [4, 3, 2, 5, 1, 5]
episode: 42 -> reward: -124.99999999999135, steps:55200, time-elasped: 5508.29s
-> berries picked: 27 of 800 | patches-visited: [7] | positive-in-buffer: 2650 | amount-filled: 100.00%
	| epsilon: 0.4585644324573616
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [115, 570, 166, 454, 153, 587, 105, 500]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 16, 5, 21, 5, 21, 5, 18]
episode: 43 -> reward: -124.9999999999927, steps:56448, time-elasped: 5670.92s
-> berries picked: 29 of 800 | patches-visited: [2, 4] | positive-in-buffer: 2771 | amount-filled: 100.00%
	| epsilon: 0.4576428210872616
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [125, 604, 184, 488, 153, 602, 111, 504]
	| approx positives in sample 512: 60
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 16, 4, 9, 6, 9, 2, 11]
episode: 44 -> reward: -124.99999999999145, steps:54624, time-elasped: 5843.58s
-> berries picked: 25 of 800 | patches-visited: [1] | positive-in-buffer: 2900 | amount-filled: 100.00%
	| epsilon: 0.4567230619487291
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [131, 642, 191, 491, 169, 620, 132, 524]
	| approx positives in sample 512: 8
	| approx action-dist in sample 512: [1, 2, 3, 5, 6, 7] [1, 1, 1, 3, 1, 1]
episode: 45 -> reward: -124.99999999999203, steps:50688, time-elasped: 5953.55s
-> berries picked: 7 of 800 | patches-visited: [4] | positive-in-buffer: 2908 | amount-filled: 100.00%
	| epsilon: 0.4558051513191951
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [143, 650, 191, 489, 160, 627, 138, 510]
	| approx positives in sample 512: 14
	| approx action-dist in sample 512: [0, 1, 3, 4, 5, 6] [3, 2, 4, 1, 3, 1]
episode: 46 -> reward: -124.99999999999253, steps:52032, time-elasped: 6101.56s
-> berries picked: 13 of 800 | patches-visited: [5] | positive-in-buffer: 2979 | amount-filled: 100.00%
	| epsilon: 0.4548890854835724
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [143, 668, 191, 502, 167, 649, 143, 516]
	| approx positives in sample 512: 18
	| approx action-dist in sample 512: [1, 2, 3, 4, 6, 7] [6, 2, 2, 2, 1, 5]
episode: 47 -> reward: -124.99999999998812, steps:59712, time-elasped: 6276.63s
-> berries picked: 43 of 800 | patches-visited: [1] | positive-in-buffer: 3185 | amount-filled: 100.00%
	| epsilon: 0.45397486073424004
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [156, 730, 203, 527, 177, 709, 155, 528]
	| approx positives in sample 512: 41
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 7] [10, 1, 4, 3, 15, 8]
episode: 48 -> reward: -124.99999999999203, steps:48768, time-elasped: 6393.21s
-> berries picked: 2 of 800 | patches-visited: [8] | positive-in-buffer: 3190 | amount-filled: 100.00%
	| epsilon: 0.4530624733710288
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [155, 739, 203, 527, 177, 706, 153, 530]
	| approx positives in sample 512: 29
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 7] [2, 5, 1, 6, 2, 9, 4]
episode: 49 -> reward: -124.9999999999924, steps:53856, time-elasped: 6581.95s
-> berries picked: 23 of 800 | patches-visited: [3] | positive-in-buffer: 3305 | amount-filled: 100.00%
	| epsilon: 0.4521519197012058
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [165, 751, 210, 562, 183, 727, 161, 546]
	| approx positives in sample 512: 19
	| approx action-dist in sample 512: [0, 1, 3, 4, 5, 7] [1, 5, 4, 1, 7, 1]
episode: 50 -> reward: -124.99999999999184, steps:52608, time-elasped: 6716.41s
-> berries picked: 14 of 800 | patches-visited: [5, 7] | positive-in-buffer: 3344 | amount-filled: 100.00%
	| epsilon: 0.45124319603945967
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [164, 766, 204, 564, 183, 729, 160, 574]
	| approx positives in sample 512: 11
	| approx action-dist in sample 512: [1, 3, 4, 5, 7] [3, 1, 1, 4, 2]
episode: 51 -> reward: -124.99999999999268, steps:55008, time-elasped: 6880.35s
-> berries picked: 24 of 800 | patches-visited: [3, 4, 5] | positive-in-buffer: 3433 | amount-filled: 100.00%
	| epsilon: 0.45033629870788594
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [179, 809, 201, 568, 182, 740, 181, 573]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 30, 6, 17, 6, 21, 12, 13]
episode: 52 -> reward: -124.999999999992, steps:49824, time-elasped: 7009.81s
-> berries picked: 7 of 800 | patches-visited: [7] | positive-in-buffer: 3461 | amount-filled: 100.00%
	| epsilon: 0.4494312240359716
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [179, 813, 201, 568, 182, 748, 197, 573]
	| approx positives in sample 512: 29
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 9, 2, 3, 2, 5, 3, 4]
episode: 53 -> reward: -124.9999999999919, steps:53568, time-elasped: 7162.75s
-> berries picked: 18 of 800 | patches-visited: [1] | positive-in-buffer: 3534 | amount-filled: 100.00%
	| epsilon: 0.4485279683605807
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [179, 835, 201, 598, 184, 759, 200, 578]
	| approx positives in sample 512: 16
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 7] [1, 4, 1, 3, 1, 5, 1]
episode: 54 -> reward: -124.99999999999201, steps:50784, time-elasped: 7279.49s
-> berries picked: 9 of 800 | patches-visited: [4] | positive-in-buffer: 3570 | amount-filled: 100.00%
	| epsilon: 0.4476265280259394
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [179, 851, 199, 601, 184, 774, 197, 585]
	| approx positives in sample 512: 21
	| approx action-dist in sample 512: [0, 1, 3, 4, 5, 6, 7] [2, 5, 4, 2, 3, 2, 3]
episode: 55 -> reward: -124.99999999999058, steps:63072, time-elasped: 7469.07s
-> berries picked: 49 of 800 | patches-visited: [0, 8] | positive-in-buffer: 3779 | amount-filled: 100.00%
	| epsilon: 0.4467268993836211
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [182, 878, 241, 620, 211, 795, 229, 623]
	| approx positives in sample 512: 12
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 2, 1, 2, 1, 1, 2, 2]
episode: 56 -> reward: -124.99999999999199, steps:50400, time-elasped: 7605.82s
-> berries picked: 8 of 800 | patches-visited: [0] | positive-in-buffer: 3800 | amount-filled: 100.00%
	| epsilon: 0.44582907879253164
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [183, 888, 249, 623, 211, 791, 233, 622]
	| approx positives in sample 512: 18
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7] [4, 2, 4, 1, 4, 2, 1]
episode: 57 -> reward: -124.99999999999014, steps:65184, time-elasped: 7785.00s
-> berries picked: 67 of 800 | patches-visited: [8] | positive-in-buffer: 4086 | amount-filled: 100.00%
	| epsilon: 0.4449330626188948
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [208, 951, 312, 639, 243, 829, 265, 639]
	| approx positives in sample 512: 18
	| approx action-dist in sample 512: [0, 1, 3, 4, 5, 6, 7] [1, 3, 4, 2, 2, 1, 5]
episode: 58 -> reward: -124.99999999999218, steps:53472, time-elasped: 7914.86s
-> berries picked: 20 of 800 | patches-visited: [0, 2] | positive-in-buffer: 4110 | amount-filled: 100.00%
	| epsilon: 0.44403884723623727
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [212, 944, 299, 651, 237, 832, 298, 637]
	| approx positives in sample 512: 21
	| approx action-dist in sample 512: [0, 1, 3, 4, 5, 6, 7] [2, 3, 4, 2, 2, 4, 4]
episode: 59 -> reward: -124.99999999999136, steps:51840, time-elasped: 8087.65s
-> berries picked: 15 of 800 | patches-visited: [1, 4, 5] | positive-in-buffer: 4135 | amount-filled: 100.00%
	| epsilon: 0.44314642902537427
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [210, 947, 318, 654, 235, 831, 305, 635]
	| approx positives in sample 512: 24
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6] [2, 5, 1, 4, 1, 6, 5]
episode: 60 -> reward: -124.99999999999203, steps:48480, time-elasped: 8245.27s
-> berries picked: 2 of 800 | patches-visited: [3] | positive-in-buffer: 4134 | amount-filled: 100.00%
	| epsilon: 0.4422558043743947
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [209, 946, 312, 654, 235, 830, 313, 635]
	| approx positives in sample 512: 26
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 5, 2, 4, 5, 1, 2, 5]
episode: 61 -> reward: -124.99999999999203, steps:49344, time-elasped: 8382.81s
-> berries picked: 4 of 800 | patches-visited: [1] | positive-in-buffer: 4151 | amount-filled: 100.00%
	| epsilon: 0.4413669696786465
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [209, 946, 312, 654, 235, 835, 325, 635]
	| approx positives in sample 512: 31
	| approx action-dist in sample 512: [0, 1, 2, 3, 5, 6, 7] [2, 3, 2, 6, 4, 5, 9]
episode: 62 -> reward: -124.99999999999248, steps:50688, time-elasped: 8546.83s
-> berries picked: 8 of 800 | patches-visited: [9] | positive-in-buffer: 4176 | amount-filled: 100.00%
	| epsilon: 0.44047992134072245
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [221, 941, 312, 654, 235, 847, 331, 635]
	| approx positives in sample 512: 22
	| approx action-dist in sample 512: [1, 3, 4, 5, 6, 7] [7, 6, 1, 3, 2, 3]
episode: 63 -> reward: -124.99999999998988, steps:54720, time-elasped: 8727.12s
-> berries picked: 23 of 800 | patches-visited: [4, 9] | positive-in-buffer: 4269 | amount-filled: 100.00%
	| epsilon: 0.43959465577044493
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [224, 967, 312, 676, 235, 855, 338, 662]
	| approx positives in sample 512: 14
	| approx action-dist in sample 512: [1, 3, 4, 5, 7] [5, 4, 1, 3, 1]
episode: 64 -> reward: -124.99999999999362, steps:58272, time-elasped: 8929.39s
-> berries picked: 36 of 800 | patches-visited: [6, 8] | positive-in-buffer: 4418 | amount-filled: 100.00%
	| epsilon: 0.43871116938485194
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [229, 1018, 311, 686, 240, 882, 367, 685]
	| approx positives in sample 512: 44
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 10, 3, 5, 1, 12, 4, 5]
episode: 65 -> reward: -124.99999999999203, steps:50304, time-elasped: 9125.47s
-> berries picked: 9 of 800 | patches-visited: [4] | positive-in-buffer: 4461 | amount-filled: 100.00%
	| epsilon: 0.43782945860818256
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [229, 1048, 311, 694, 246, 881, 367, 685]
	| approx positives in sample 512: 23
	| approx action-dist in sample 512: [1, 2, 3, 5, 6, 7] [4, 3, 3, 7, 1, 5]
episode: 66 -> reward: -124.99999999999203, steps:51552, time-elasped: 9274.00s
-> berries picked: 10 of 800 | patches-visited: [9] | positive-in-buffer: 4499 | amount-filled: 100.00%
	| epsilon: 0.43694951987186215
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [237, 1046, 310, 692, 246, 889, 384, 695]
	| approx positives in sample 512: 16
	| approx action-dist in sample 512: [0, 1, 3, 5, 6, 7] [2, 3, 3, 2, 2, 4]
episode: 67 -> reward: -124.99999999999183, steps:50592, time-elasped: 9436.90s
-> berries picked: 7 of 800 | patches-visited: [5] | positive-in-buffer: 4517 | amount-filled: 100.00%
	| epsilon: 0.4360713496144882
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [243, 1045, 309, 690, 246, 901, 389, 694]
	| approx positives in sample 512: 22
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7] [5, 1, 5, 3, 4, 1, 3]
episode: 68 -> reward: -124.99999999999208, steps:49728, time-elasped: 9625.11s
-> berries picked: 6 of 800 | patches-visited: [8] | positive-in-buffer: 4550 | amount-filled: 100.00%
	| epsilon: 0.4351949442818157
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [254, 1053, 316, 690, 246, 905, 389, 697]
	| approx positives in sample 512: 27
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 7] [8, 1, 6, 1, 6, 5]
episode: 69 -> reward: -124.99999999999257, steps:53952, time-elasped: 9801.00s
-> berries picked: 18 of 800 | patches-visited: [9] | positive-in-buffer: 4634 | amount-filled: 100.00%
	| epsilon: 0.434320300326743
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [255, 1063, 323, 700, 251, 956, 389, 697]
	| approx positives in sample 512: 21
	| approx action-dist in sample 512: [0, 1, 2, 3, 5, 7] [1, 9, 1, 2, 3, 5]
episode: 70 -> reward: -124.99999999999204, steps:51456, time-elasped: 9942.40s
-> berries picked: 12 of 800 | patches-visited: [8] | positive-in-buffer: 4650 | amount-filled: 100.00%
	| epsilon: 0.4334474142092974
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [255, 1055, 321, 697, 264, 958, 393, 707]
	| approx positives in sample 512: 26
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7] [5, 4, 3, 1, 2, 4, 7]
episode: 71 -> reward: -124.9999999999924, steps:57408, time-elasped: 10160.48s
-> berries picked: 34 of 800 | patches-visited: [1, 7] | positive-in-buffer: 4825 | amount-filled: 100.00%
	| epsilon: 0.4325762823966205
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [255, 1078, 341, 708, 281, 979, 419, 764]
	| approx positives in sample 512: 65
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 16, 1, 2, 1, 19, 6, 16]
episode: 72 -> reward: -124.999999999992, steps:49920, time-elasped: 10303.52s
-> berries picked: 7 of 800 | patches-visited: [5] | positive-in-buffer: 4847 | amount-filled: 100.00%
	| epsilon: 0.43170690136295437
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [255, 1077, 339, 710, 281, 1002, 413, 770]
	| approx positives in sample 512: 22
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 6, 2, 1, 4, 1, 4, 2]
episode: 73 -> reward: -124.99999999999066, steps:56352, time-elasped: 10519.69s
-> berries picked: 26 of 800 | patches-visited: [3] | positive-in-buffer: 4979 | amount-filled: 100.00%
	| epsilon: 0.43083926758962693
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [293, 1083, 333, 722, 288, 1033, 428, 799]
	| approx positives in sample 512: 66
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 13, 8, 13, 1, 11, 7, 10]
episode: 74 -> reward: -124.9999999999924, steps:53568, time-elasped: 10687.91s
-> berries picked: 17 of 800 | patches-visited: [2, 6] | positive-in-buffer: 5039 | amount-filled: 100.00%
	| epsilon: 0.42997337756503795
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [302, 1087, 331, 727, 284, 1036, 453, 819]
	| approx positives in sample 512: 22
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 3, 1, 2, 2, 4, 4, 4]
episode: 75 -> reward: -124.99999999999199, steps:59808, time-elasped: 10904.34s
-> berries picked: 37 of 800 | patches-visited: [0, 2, 3] | positive-in-buffer: 5169 | amount-filled: 100.00%
	| epsilon: 0.42910922778464455
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [329, 1107, 349, 722, 284, 1072, 489, 817]
	| approx positives in sample 512: 37
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 3, 1, 11, 3, 7, 5, 6]
episode: 76 -> reward: -124.99999999999203, steps:49344, time-elasped: 11051.70s
-> berries picked: 4 of 800 | patches-visited: [0] | positive-in-buffer: 5186 | amount-filled: 100.00%
	| epsilon: 0.42824681475094745
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [328, 1117, 349, 725, 284, 1072, 494, 817]
	| approx positives in sample 512: 31
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 7] [1, 8, 2, 2, 3, 9, 6]
episode: 77 -> reward: -124.9999999999917, steps:63360, time-elasped: 11297.41s
-> berries picked: 51 of 800 | patches-visited: [4, 5, 7] | positive-in-buffer: 5445 | amount-filled: 100.00%
	| epsilon: 0.42738613497347633
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [354, 1115, 380, 762, 287, 1132, 541, 874]
	| approx positives in sample 512: 22
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 2, 4, 4, 1, 6, 2, 2]
episode: 78 -> reward: -124.99999999999007, steps:62592, time-elasped: 11557.02s
-> berries picked: 52 of 800 | patches-visited: [2] | positive-in-buffer: 5657 | amount-filled: 100.00%
	| epsilon: 0.426527184968776
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [363, 1139, 413, 752, 348, 1141, 552, 949]
	| approx positives in sample 512: 24
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 4, 3, 3, 1, 2, 1, 9]
episode: 79 -> reward: -124.99999999999204, steps:51264, time-elasped: 11716.79s
-> berries picked: 11 of 800 | patches-visited: [3] | positive-in-buffer: 5684 | amount-filled: 100.00%
	| epsilon: 0.4256699612603923
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [362, 1136, 411, 748, 348, 1161, 551, 967]
	| approx positives in sample 512: 27
	| approx action-dist in sample 512: [0, 1, 2, 3, 5, 6, 7] [2, 10, 2, 1, 4, 2, 6]
episode: 80 -> reward: -124.99999999999206, steps:64128, time-elasped: 11924.56s
-> berries picked: 61 of 800 | patches-visited: [3] | positive-in-buffer: 5969 | amount-filled: 100.00%
	| epsilon: 0.4248144603788579
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [389, 1153, 443, 802, 358, 1209, 569, 1046]
	| approx positives in sample 512: 23
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 4, 1, 3, 2, 4, 1, 7]
episode: 81 -> reward: -124.99999999999203, steps:50400, time-elasped: 12043.84s
-> berries picked: 8 of 800 | patches-visited: [3, 9] | positive-in-buffer: 5949 | amount-filled: 100.00%
	| epsilon: 0.4239606788616783
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [394, 1158, 443, 797, 354, 1205, 573, 1025]
	| approx positives in sample 512: 35
	| approx action-dist in sample 512: [0, 1, 2, 3, 5, 6, 7] [1, 4, 1, 7, 8, 6, 8]
episode: 82 -> reward: -124.99999999999199, steps:51648, time-elasped: 12205.75s
-> berries picked: 17 of 800 | patches-visited: [5] | positive-in-buffer: 5989 | amount-filled: 100.00%
	| epsilon: 0.4231086132533179
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [404, 1175, 450, 798, 353, 1210, 573, 1026]
	| approx positives in sample 512: 25
	| approx action-dist in sample 512: [1, 2, 3, 5, 6, 7] [6, 1, 3, 7, 3, 5]
episode: 83 -> reward: -124.99999999999106, steps:60672, time-elasped: 12365.74s
-> berries picked: 37 of 800 | patches-visited: [2, 7] | positive-in-buffer: 6156 | amount-filled: 100.00%
	| epsilon: 0.42225826010518586
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [414, 1175, 450, 795, 384, 1238, 596, 1104]
	| approx positives in sample 512: 34
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 7, 1, 4, 4, 3, 1, 11]
episode: 84 -> reward: -124.99999999999208, steps:51168, time-elasped: 12520.13s
-> berries picked: 10 of 800 | patches-visited: [5] | positive-in-buffer: 6176 | amount-filled: 100.00%
	| epsilon: 0.4214096159756223
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [421, 1202, 450, 791, 384, 1235, 606, 1087]
	| approx positives in sample 512: 27
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 6, 1, 3, 1, 8, 4, 2]
episode: 85 -> reward: -124.99999999998617, steps:72672, time-elasped: 12720.79s
-> berries picked: 77 of 800 | patches-visited: [1, 7, 8] | positive-in-buffer: 6469 | amount-filled: 100.00%
	| epsilon: 0.42056267742988435
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [451, 1217, 466, 829, 398, 1288, 686, 1134]
	| approx positives in sample 512: 33
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 4, 1, 3, 2, 9, 4, 9]
episode: 86 -> reward: -124.99999999999297, steps:73536, time-elasped: 12930.68s
-> berries picked: 94 of 800 | patches-visited: [0, 5] | positive-in-buffer: 6799 | amount-filled: 100.00%
	| epsilon: 0.41971744104013203
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [454, 1330, 507, 890, 413, 1309, 712, 1184]
	| approx positives in sample 512: 31
	| approx action-dist in sample 512: [0, 1, 2, 3, 5, 6, 7] [3, 1, 2, 6, 9, 4, 6]
episode: 87 -> reward: -124.99999999999184, steps:53568, time-elasped: 13063.88s
-> berries picked: 19 of 800 | patches-visited: [9] | positive-in-buffer: 6810 | amount-filled: 100.00%
	| epsilon: 0.4188739033854147
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [467, 1305, 513, 888, 428, 1306, 725, 1178]
	| approx positives in sample 512: 28
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 4, 4, 4, 3, 4, 3, 3]
episode: 88 -> reward: -124.99999999999086, steps:64800, time-elasped: 13270.26s
-> berries picked: 57 of 800 | patches-visited: [5] | positive-in-buffer: 6894 | amount-filled: 100.00%
	| epsilon: 0.418032061051657
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [472, 1358, 521, 892, 434, 1328, 721, 1168]
	| approx positives in sample 512: 21
	| approx action-dist in sample 512: [0, 1, 2, 3, 5, 6, 7] [1, 5, 3, 2, 4, 4, 2]
episode: 89 -> reward: -124.99999999999223, steps:50880, time-elasped: 13413.86s
-> berries picked: 9 of 800 | patches-visited: [3, 8] | positive-in-buffer: 6857 | amount-filled: 100.00%
	| epsilon: 0.41719191063164524
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [470, 1343, 526, 880, 436, 1320, 716, 1166]
	| approx positives in sample 512: 32
	| approx action-dist in sample 512: [0, 1, 2, 3, 5, 6, 7] [1, 7, 2, 4, 8, 4, 6]
episode: 90 -> reward: -124.99999999999204, steps:52416, time-elasped: 13573.19s
-> berries picked: 14 of 800 | patches-visited: [6, 8] | positive-in-buffer: 6931 | amount-filled: 100.00%
	| epsilon: 0.4163534487250131
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [480, 1349, 526, 910, 435, 1328, 720, 1183]
	| approx positives in sample 512: 28
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 9, 2, 1, 3, 5, 3, 4]
episode: 91 -> reward: -124.99999999999044, steps:62112, time-elasped: 13787.74s
-> berries picked: 50 of 800 | patches-visited: [0, 6] | positive-in-buffer: 7095 | amount-filled: 100.00%
	| epsilon: 0.41551667193822867
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [486, 1381, 540, 935, 435, 1345, 725, 1248]
	| approx positives in sample 512: 32
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 7, 7, 3, 1, 5, 4, 4]
episode: 92 -> reward: -124.99999999999243, steps:63936, time-elasped: 14003.38s
-> berries picked: 56 of 800 | patches-visited: [6] | positive-in-buffer: 7395 | amount-filled: 100.00%
	| epsilon: 0.41468157688457996
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [554, 1479, 549, 949, 442, 1392, 748, 1282]
	| approx positives in sample 512: 34
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 3, 3, 4, 3, 8, 2, 7]
episode: 93 -> reward: -124.9999999999917, steps:57216, time-elasped: 14179.25s
-> berries picked: 32 of 800 | patches-visited: [9] | positive-in-buffer: 7403 | amount-filled: 100.00%
	| epsilon: 0.4138481601841616
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [549, 1537, 540, 953, 430, 1393, 737, 1264]
	| approx positives in sample 512: 81
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 12, 7, 14, 6, 21, 9, 7]
episode: 94 -> reward: -124.99999999999213, steps:55392, time-elasped: 14385.00s
-> berries picked: 25 of 800 | patches-visited: [0, 2] | positive-in-buffer: 7468 | amount-filled: 100.00%
	| epsilon: 0.41301641846386117
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [550, 1535, 540, 960, 442, 1401, 747, 1293]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 26, 9, 12, 7, 30, 15, 26]
episode: 95 -> reward: -124.9999999999879, steps:62688, time-elasped: 14598.05s
-> berries picked: 53 of 800 | patches-visited: [1, 5] | positive-in-buffer: 7670 | amount-filled: 100.00%
	| epsilon: 0.4121863483573453
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [564, 1541, 541, 967, 475, 1433, 797, 1352]
	| approx positives in sample 512: 42
	| approx action-dist in sample 512: [0, 1, 2, 3, 5, 6, 7] [4, 7, 2, 8, 7, 10, 4]
episode: 96 -> reward: -124.99999999999204, steps:50208, time-elasped: 14740.77s
-> berries picked: 7 of 800 | patches-visited: [8] | positive-in-buffer: 7661 | amount-filled: 100.00%
	| epsilon: 0.41135794650504626
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [553, 1543, 554, 965, 468, 1440, 801, 1337]
	| approx positives in sample 512: 42
	| approx action-dist in sample 512: [0, 1, 3, 4, 5, 6, 7] [6, 8, 4, 3, 13, 4, 4]
episode: 97 -> reward: -124.99999999999167, steps:55488, time-elasped: 14907.97s
-> berries picked: 25 of 800 | patches-visited: [8] | positive-in-buffer: 7747 | amount-filled: 100.00%
	| epsilon: 0.41053120955414835
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [582, 1551, 553, 969, 471, 1461, 806, 1354]
	| approx positives in sample 512: 162
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 27, 10, 19, 13, 32, 18, 30]
episode: 98 -> reward: -124.9999999999914, steps:53664, time-elasped: 15053.84s
-> berries picked: 19 of 800 | patches-visited: [3, 7] | positive-in-buffer: 7831 | amount-filled: 100.00%
	| epsilon: 0.40970613415857415
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [582, 1558, 553, 980, 471, 1482, 813, 1392]
	| approx positives in sample 512: 16
	| approx action-dist in sample 512: [0, 1, 3, 4, 6, 7] [4, 1, 3, 1, 4, 3]
episode: 99 -> reward: -124.99999999999214, steps:56832, time-elasped: 15222.59s
-> berries picked: 34 of 800 | patches-visited: [7] | positive-in-buffer: 7868 | amount-filled: 100.00%
	| epsilon: 0.4088827169789713
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [579, 1542, 553, 977, 467, 1494, 844, 1412]
	| approx positives in sample 512: 83
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 14, 9, 16, 4, 14, 9, 14]
episode: 100 -> reward: -124.99999999999213, steps:57216, time-elasped: 15402.06s
-> berries picked: 31 of 800 | patches-visited: [3, 5] | positive-in-buffer: 7973 | amount-filled: 100.00%
	| epsilon: 0.4080609546826985
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [581, 1570, 567, 999, 483, 1491, 843, 1439]
	| approx positives in sample 512: 82
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 14, 4, 15, 6, 17, 8, 14]
episode: 101 -> reward: -124.99999999998904, steps:64992, time-elasped: 15621.43s
-> berries picked: 73 of 800 | patches-visited: [2] | positive-in-buffer: 8282 | amount-filled: 100.00%
	| epsilon: 0.4072408439438125
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [606, 1607, 621, 1021, 509, 1526, 868, 1524]
	| approx positives in sample 512: 31
	| approx action-dist in sample 512: [1, 3, 4, 5, 6, 7] [10, 4, 2, 7, 3, 5]
episode: 102 -> reward: -124.99999999999248, steps:64992, time-elasped: 15840.04s
-> berries picked: 57 of 800 | patches-visited: [3, 7, 8] | positive-in-buffer: 8368 | amount-filled: 100.00%
	| epsilon: 0.4064223814430545
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [601, 1605, 642, 1038, 525, 1497, 874, 1586]
	| approx positives in sample 512: 26
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 6, 1, 1, 2, 5, 5, 4]
episode: 103 -> reward: -124.99999999999201, steps:51360, time-elasped: 15981.54s
-> berries picked: 10 of 800 | patches-visited: [0] | positive-in-buffer: 8252 | amount-filled: 100.00%
	| epsilon: 0.40560556386783647
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [605, 1612, 612, 1011, 507, 1473, 871, 1561]
	| approx positives in sample 512: 27
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7] [7, 1, 2, 1, 6, 6, 4]
episode: 104 -> reward: -124.999999999992, steps:51840, time-elasped: 16126.19s
-> berries picked: 12 of 800 | patches-visited: [6] | positive-in-buffer: 8293 | amount-filled: 100.00%
	| epsilon: 0.40479038791222816
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [615, 1610, 624, 1017, 506, 1469, 904, 1548]
	| approx positives in sample 512: 37
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 11, 1, 4, 2, 4, 2, 10]
episode: 105 -> reward: -124.99999999999218, steps:57504, time-elasped: 16317.48s
-> berries picked: 33 of 800 | patches-visited: [0, 8] | positive-in-buffer: 8380 | amount-filled: 100.00%
	| epsilon: 0.40397685027694336
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [634, 1634, 611, 1014, 523, 1494, 920, 1550]
	| approx positives in sample 512: 78
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 23, 8, 7, 5, 10, 9, 10]
episode: 106 -> reward: -124.99999999999245, steps:53952, time-elasped: 16477.69s
-> berries picked: 18 of 800 | patches-visited: [5, 6, 9] | positive-in-buffer: 8439 | amount-filled: 100.00%
	| epsilon: 0.40316494766932665
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [634, 1643, 636, 1018, 519, 1500, 930, 1559]
	| approx positives in sample 512: 24
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 2, 1, 6, 1, 4, 3, 5]
episode: 107 -> reward: -124.99999999999167, steps:57312, time-elasped: 16674.44s
-> berries picked: 35 of 800 | patches-visited: [6] | positive-in-buffer: 8480 | amount-filled: 100.00%
	| epsilon: 0.40235467680334014
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [643, 1607, 646, 1014, 514, 1497, 976, 1583]
	| approx positives in sample 512: 80
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 14, 7, 8, 5, 13, 7, 22]
episode: 108 -> reward: -124.99999999999255, steps:65088, time-elasped: 16875.81s
-> berries picked: 67 of 800 | patches-visited: [3] | positive-in-buffer: 8809 | amount-filled: 100.00%
	| epsilon: 0.4015460343995503
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [696, 1660, 706, 1038, 547, 1540, 998, 1624]
	| approx positives in sample 512: 24
	| approx action-dist in sample 512: [1, 3, 4, 5, 6, 7] [8, 4, 1, 3, 2, 6]
episode: 109 -> reward: -124.99999999999204, steps:51648, time-elasped: 17011.46s
-> berries picked: 11 of 800 | patches-visited: [0] | positive-in-buffer: 8743 | amount-filled: 100.00%
	| epsilon: 0.40073901718511423
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [670, 1657, 691, 1031, 555, 1541, 978, 1620]
	| approx positives in sample 512: 22
	| approx action-dist in sample 512: [0, 1, 2, 3, 5, 6, 7] [1, 2, 1, 2, 5, 7, 4]
episode: 110 -> reward: -124.99999999999204, steps:52032, time-elasped: 17146.12s
-> berries picked: 11 of 800 | patches-visited: [9] | positive-in-buffer: 8766 | amount-filled: 100.00%
	| epsilon: 0.39993362189376697
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [660, 1666, 694, 1027, 561, 1552, 978, 1628]
	| approx positives in sample 512: 30
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 9, 6, 2, 3, 4, 2, 3]
episode: 111 -> reward: -124.99999999999267, steps:66624, time-elasped: 17388.68s
-> berries picked: 59 of 800 | patches-visited: [0, 7] | positive-in-buffer: 8969 | amount-filled: 100.00%
	| epsilon: 0.39912984526580786
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [703, 1667, 706, 1019, 574, 1616, 971, 1713]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 25, 6, 14, 13, 36, 16, 24]
episode: 112 -> reward: -124.99999999999199, steps:48480, time-elasped: 17555.30s
-> berries picked: 2 of 800 | patches-visited: [8] | positive-in-buffer: 8954 | amount-filled: 100.00%
	| epsilon: 0.39832768404808755
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [700, 1664, 706, 1019, 573, 1606, 971, 1715]
	| approx positives in sample 512: 55
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 10, 5, 7, 3, 8, 7, 11]
episode: 113 -> reward: -124.99999999999193, steps:51648, time-elasped: 17693.74s
-> berries picked: 12 of 800 | patches-visited: [5] | positive-in-buffer: 8993 | amount-filled: 100.00%
	| epsilon: 0.3975271349939948
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [700, 1670, 724, 1030, 579, 1604, 967, 1719]
	| approx positives in sample 512: 31
	| approx action-dist in sample 512: [0, 1, 2, 3, 5, 6, 7] [1, 8, 5, 3, 5, 3, 6]
episode: 114 -> reward: -124.999999999991, steps:65760, time-elasped: 17919.93s
-> berries picked: 63 of 800 | patches-visited: [2, 4, 7, 9] | positive-in-buffer: 9206 | amount-filled: 100.00%
	| epsilon: 0.39672819486344335
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [697, 1783, 720, 1084, 575, 1623, 968, 1756]
	| approx positives in sample 512: 34
	| approx action-dist in sample 512: [0, 1, 2, 3, 5, 6, 7] [4, 10, 2, 5, 3, 4, 6]
episode: 115 -> reward: -124.99999999999166, steps:63744, time-elasped: 18148.04s
-> berries picked: 56 of 800 | patches-visited: [7] | positive-in-buffer: 9216 | amount-filled: 100.00%
	| epsilon: 0.39593086042285874
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [674, 1751, 713, 1088, 593, 1646, 986, 1765]
	| approx positives in sample 512: 30
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 4, 2, 3, 1, 6, 6, 5]
episode: 116 -> reward: -124.999999999992, steps:52224, time-elasped: 18290.53s
-> berries picked: 15 of 800 | patches-visited: [5] | positive-in-buffer: 9233 | amount-filled: 100.00%
	| epsilon: 0.39513512844516524
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [685, 1731, 716, 1090, 591, 1643, 1007, 1770]
	| approx positives in sample 512: 39
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 8, 4, 5, 1, 10, 4, 6]
episode: 117 -> reward: -124.9999999999924, steps:67008, time-elasped: 18504.50s
-> berries picked: 74 of 800 | patches-visited: [8] | positive-in-buffer: 9540 | amount-filled: 100.00%
	| epsilon: 0.39434099570977293
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [719, 1769, 741, 1138, 600, 1676, 1020, 1877]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 33, 10, 16, 7, 27, 10, 17]
episode: 118 -> reward: -124.99999999999012, steps:77184, time-elasped: 18781.28s
-> berries picked: 97 of 800 | patches-visited: [0, 1, 3, 4, 7] | positive-in-buffer: 9995 | amount-filled: 100.00%
	| epsilon: 0.39354845900256447
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [769, 1856, 828, 1176, 670, 1689, 1055, 1952]
	| approx positives in sample 512: 150
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 23, 12, 21, 9, 21, 18, 30]
episode: 119 -> reward: -124.99999999998963, steps:64608, time-elasped: 19003.87s
-> berries picked: 54 of 800 | patches-visited: [6, 8] | positive-in-buffer: 10201 | amount-filled: 100.00%
	| epsilon: 0.3927575151158822
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [798, 1885, 860, 1204, 664, 1723, 1057, 2010]
	| approx positives in sample 512: 50
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 7, 6, 5, 3, 11, 3, 11]
episode: 120 -> reward: -124.99999999999142, steps:63648, time-elasped: 19182.78s
-> berries picked: 61 of 800 | patches-visited: [2] | positive-in-buffer: 10173 | amount-filled: 100.00%
	| epsilon: 0.39196816084851505
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [773, 1896, 851, 1188, 650, 1725, 1045, 2045]
	| approx positives in sample 512: 40
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 8, 2, 2, 5, 13, 1, 5]
episode: 121 -> reward: -124.99999999999206, steps:56064, time-elasped: 19327.75s
-> berries picked: 26 of 800 | patches-visited: [9] | positive-in-buffer: 10173 | amount-filled: 100.00%
	| epsilon: 0.39118039300568574
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [775, 1914, 840, 1175, 639, 1729, 1056, 2045]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 37, 10, 14, 8, 24, 13, 25]
episode: 122 -> reward: -124.99999999999173, steps:60384, time-elasped: 19491.14s
-> berries picked: 41 of 800 | patches-visited: [9] | positive-in-buffer: 10334 | amount-filled: 100.00%
	| epsilon: 0.3903942083990378
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [779, 1927, 858, 1230, 650, 1756, 1055, 2079]
	| approx positives in sample 512: 53
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 15, 2, 3, 3, 11, 6, 10]
episode: 123 -> reward: -124.99999999999184, steps:64320, time-elasped: 19674.25s
-> berries picked: 49 of 800 | patches-visited: [0, 2] | positive-in-buffer: 10504 | amount-filled: 100.00%
	| epsilon: 0.38960960384662263
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [794, 1962, 894, 1272, 653, 1773, 1058, 2098]
	| approx positives in sample 512: 31
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 5, 1, 3, 4, 7, 3, 5]
episode: 124 -> reward: -124.99999999999255, steps:72384, time-elasped: 19902.50s
-> berries picked: 86 of 800 | patches-visited: [0, 9] | positive-in-buffer: 10681 | amount-filled: 100.00%
	| epsilon: 0.3888265761728865
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [840, 1939, 978, 1273, 665, 1806, 1064, 2116]
	| approx positives in sample 512: 53
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 9, 4, 9, 2, 8, 7, 10]
episode: 125 -> reward: -124.99999999999203, steps:52704, time-elasped: 20050.15s
-> berries picked: 16 of 800 | patches-visited: [9] | positive-in-buffer: 10743 | amount-filled: 100.00%
	| epsilon: 0.38804512220865806
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [842, 1945, 972, 1271, 682, 1833, 1069, 2129]
	| approx positives in sample 512: 42
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 7, 5, 3, 3, 12, 3, 6]
episode: 126 -> reward: -124.99999999999062, steps:68448, time-elasped: 20279.79s
-> berries picked: 67 of 800 | patches-visited: [3, 5] | positive-in-buffer: 10892 | amount-filled: 100.00%
	| epsilon: 0.38726523879113506
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [863, 1936, 1005, 1295, 687, 1846, 1085, 2175]
	| approx positives in sample 512: 84
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 8, 10, 11, 5, 16, 9, 17]
episode: 127 -> reward: -124.99999999999302, steps:69120, time-elasped: 20514.11s
-> berries picked: 74 of 800 | patches-visited: [6, 7, 8] | positive-in-buffer: 11168 | amount-filled: 100.00%
	| epsilon: 0.3864869227638719
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [897, 2018, 1002, 1339, 685, 1882, 1119, 2226]
	| approx positives in sample 512: 71
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 15, 10, 5, 3, 9, 8, 14]
episode: 128 -> reward: -124.99999999999196, steps:76128, time-elasped: 20755.30s
-> berries picked: 97 of 800 | patches-visited: [3, 8] | positive-in-buffer: 11596 | amount-filled: 100.00%
	| epsilon: 0.3857101709767667
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [951, 2060, 1064, 1334, 730, 1934, 1171, 2352]
	| approx positives in sample 512: 31
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 4, 5, 4, 1, 4, 3, 6]
episode: 129 -> reward: -124.99999999999409, steps:61728, time-elasped: 20942.90s
-> berries picked: 46 of 800 | patches-visited: [5, 8] | positive-in-buffer: 11388 | amount-filled: 100.00%
	| epsilon: 0.38493498028604856
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [968, 1974, 1055, 1301, 714, 1923, 1154, 2299]
	| approx positives in sample 512: 48
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 5, 5, 4, 3, 8, 5, 13]
episode: 130 -> reward: -124.9999999999916, steps:64416, time-elasped: 21147.12s
-> berries picked: 52 of 800 | patches-visited: [3, 9] | positive-in-buffer: 11587 | amount-filled: 100.00%
	| epsilon: 0.38416134755426484
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1020, 2011, 1081, 1345, 713, 1907, 1181, 2329]
	| approx positives in sample 512: 41
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 12, 4, 3, 2, 7, 3, 8]
episode: 131 -> reward: -124.999999999989, steps:73728, time-elasped: 21379.81s
-> berries picked: 92 of 800 | patches-visited: [5, 9] | positive-in-buffer: 11834 | amount-filled: 100.00%
	| epsilon: 0.38338926965026854
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1063, 2038, 1078, 1401, 743, 1931, 1191, 2389]
	| approx positives in sample 512: 38
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 6, 2, 4, 4, 5, 3, 11]
episode: 132 -> reward: -124.99999999998936, steps:62784, time-elasped: 21572.75s
-> berries picked: 57 of 800 | patches-visited: [4, 6, 7] | positive-in-buffer: 11967 | amount-filled: 100.00%
	| epsilon: 0.38261874344920543
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1098, 2075, 1078, 1413, 746, 1953, 1191, 2413]
	| approx positives in sample 512: 47
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 10, 4, 5, 3, 3, 6, 12]
episode: 133 -> reward: -124.99999999999234, steps:62016, time-elasped: 21744.25s
-> berries picked: 51 of 800 | patches-visited: [1, 8] | positive-in-buffer: 12129 | amount-filled: 100.00%
	| epsilon: 0.3818497658325017
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1114, 2092, 1100, 1446, 737, 1976, 1203, 2461]
	| approx positives in sample 512: 46
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 9, 1, 4, 3, 6, 8, 7]
episode: 134 -> reward: -124.99999999999191, steps:63360, time-elasped: 21931.90s
-> berries picked: 56 of 800 | patches-visited: [8] | positive-in-buffer: 12197 | amount-filled: 100.00%
	| epsilon: 0.38108233368785105
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1139, 2073, 1099, 1481, 720, 1983, 1241, 2461]
	| approx positives in sample 512: 47
	| approx action-dist in sample 512: [0, 1, 2, 3, 5, 7] [3, 10, 3, 11, 7, 13]
episode: 135 -> reward: -124.99999999999282, steps:69696, time-elasped: 22152.14s
-> berries picked: 72 of 800 | patches-visited: [6, 8] | positive-in-buffer: 12149 | amount-filled: 100.00%
	| epsilon: 0.38031644390920233
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1162, 2083, 1117, 1436, 723, 1923, 1238, 2467]
	| approx positives in sample 512: 84
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 17, 8, 14, 4, 17, 5, 12]
episode: 136 -> reward: -124.99999999999211, steps:52512, time-elasped: 22286.81s
-> berries picked: 17 of 800 | patches-visited: [9] | positive-in-buffer: 12192 | amount-filled: 100.00%
	| epsilon: 0.37955209339674667
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1168, 2085, 1113, 1454, 722, 1940, 1236, 2474]
	| approx positives in sample 512: 41
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 10, 4, 3, 2, 5, 7, 6]
episode: 137 -> reward: -124.99999999999203, steps:51840, time-elasped: 22422.65s
-> berries picked: 13 of 800 | patches-visited: [2] | positive-in-buffer: 11924 | amount-filled: 100.00%
	| epsilon: 0.3787892790569053
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1139, 2069, 1089, 1418, 712, 1867, 1207, 2423]
	| approx positives in sample 512: 50
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 5, 5, 4, 2, 11, 6, 10]
episode: 138 -> reward: -124.9999999999923, steps:58560, time-elasped: 22616.01s
-> berries picked: 35 of 800 | patches-visited: [3] | positive-in-buffer: 12063 | amount-filled: 100.00%
	| epsilon: 0.3780279978023168
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1160, 2068, 1092, 1409, 712, 1907, 1216, 2499]
	| approx positives in sample 512: 101
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 19, 9, 11, 4, 19, 7, 19]
episode: 139 -> reward: -124.99999999998612, steps:70176, time-elasped: 22849.68s
-> berries picked: 74 of 800 | patches-visited: [2, 3] | positive-in-buffer: 12408 | amount-filled: 100.00%
	| epsilon: 0.3772682465518245
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1194, 2089, 1117, 1471, 721, 1973, 1256, 2587]
	| approx positives in sample 512: 71
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 14, 8, 8, 3, 13, 6, 11]
episode: 140 -> reward: -124.9999999999872, steps:79008, time-elasped: 23124.84s
-> berries picked: 120 of 800 | patches-visited: [1, 4] | positive-in-buffer: 12816 | amount-filled: 100.00%
	| epsilon: 0.3765100222304644
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1208, 2130, 1192, 1526, 743, 2025, 1286, 2706]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 20, 8, 14, 9, 17, 9, 33]
episode: 141 -> reward: -124.99999999998661, steps:82176, time-elasped: 23382.63s
-> berries picked: 121 of 800 | patches-visited: [4, 5, 7] | positive-in-buffer: 13211 | amount-filled: 100.00%
	| epsilon: 0.3757533217694525
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1222, 2212, 1214, 1588, 786, 2035, 1318, 2836]
	| approx positives in sample 512: 71
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 9, 7, 10, 6, 9, 8, 10]
episode: 142 -> reward: -124.99999999999136, steps:66432, time-elasped: 23594.46s
-> berries picked: 74 of 800 | patches-visited: [4] | positive-in-buffer: 13035 | amount-filled: 100.00%
	| epsilon: 0.37499814210617194
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1235, 2137, 1195, 1608, 780, 2024, 1303, 2753]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 40, 15, 29, 9, 35, 17, 45]
episode: 143 -> reward: -124.99999999999297, steps:66816, time-elasped: 23822.43s
-> berries picked: 75 of 800 | patches-visited: [4] | positive-in-buffer: 13225 | amount-filled: 100.00%
	| epsilon: 0.37424448018416157
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1305, 2140, 1275, 1634, 765, 2037, 1317, 2752]
	| approx positives in sample 512: 159
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 23, 13, 21, 8, 30, 19, 31]
episode: 144 -> reward: -124.99999999999342, steps:66048, time-elasped: 24061.71s
-> berries picked: 68 of 800 | patches-visited: [8] | positive-in-buffer: 13407 | amount-filled: 100.00%
	| epsilon: 0.3734923329531027
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1291, 2182, 1305, 1658, 762, 2085, 1368, 2756]
	| approx positives in sample 512: 207
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 38, 27, 30, 10, 35, 18, 32]
episode: 145 -> reward: -124.99999999999038, steps:59424, time-elasped: 24312.72s
-> berries picked: 42 of 800 | patches-visited: [3] | positive-in-buffer: 13571 | amount-filled: 100.00%
	| epsilon: 0.37274169736880725
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1305, 2209, 1327, 1659, 779, 2089, 1358, 2845]
	| approx positives in sample 512: 84
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 14, 5, 7, 7, 14, 10, 23]
episode: 146 -> reward: -124.99999999999288, steps:60768, time-elasped: 24502.40s
-> berries picked: 53 of 800 | patches-visited: [2] | positive-in-buffer: 13510 | amount-filled: 100.00%
	| epsilon: 0.37199257039320516
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1263, 2201, 1347, 1660, 785, 2061, 1351, 2842]
	| approx positives in sample 512: 57
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 12, 6, 3, 4, 7, 5, 11]
episode: 147 -> reward: -124.99999999999282, steps:64128, time-elasped: 24704.38s
-> berries picked: 62 of 800 | patches-visited: [7] | positive-in-buffer: 13359 | amount-filled: 100.00%
	| epsilon: 0.37124494899433236
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1246, 2157, 1325, 1641, 783, 2053, 1370, 2784]
	| approx positives in sample 512: 46
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 7, 3, 8, 4, 9, 1, 13]
episode: 148 -> reward: -124.99999999999146, steps:64032, time-elasped: 24899.90s
-> berries picked: 66 of 800 | patches-visited: [0] | positive-in-buffer: 12786 | amount-filled: 100.00%
	| epsilon: 0.3704988301463181
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1189, 2072, 1273, 1563, 724, 2005, 1340, 2620]
	| approx positives in sample 512: 49
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 10, 5, 7, 1, 4, 3, 11]
episode: 149 -> reward: -124.99999999999336, steps:57216, time-elasped: 25089.12s
-> berries picked: 32 of 800 | patches-visited: [0] | positive-in-buffer: 12814 | amount-filled: 100.00%
	| epsilon: 0.3697542108293733
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1214, 2069, 1271, 1565, 726, 1998, 1329, 2642]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 17, 18, 14, 8, 13, 13, 22]
episode: 150 -> reward: -124.99999999999197, steps:64896, time-elasped: 25275.93s
-> berries picked: 63 of 800 | patches-visited: [2] | positive-in-buffer: 13062 | amount-filled: 100.00%
	| epsilon: 0.36901108802977767
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1244, 2089, 1339, 1576, 723, 2014, 1342, 2735]
	| approx positives in sample 512: 37
	| approx action-dist in sample 512: [0, 1, 2, 3, 5, 6, 7] [2, 5, 7, 3, 6, 6, 8]
episode: 151 -> reward: -124.9999999999903, steps:70176, time-elasped: 25510.99s
-> berries picked: 83 of 800 | patches-visited: [1, 7] | positive-in-buffer: 12962 | amount-filled: 100.00%
	| epsilon: 0.36826945873986794
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1241, 2069, 1311, 1565, 725, 2039, 1355, 2657]
	| approx positives in sample 512: 73
	| approx action-dist in sample 512: [0, 1, 2, 3, 5, 6, 7] [5, 14, 10, 4, 11, 11, 18]
episode: 152 -> reward: -124.99999999999183, steps:55968, time-elasped: 25679.52s
-> berries picked: 26 of 800 | patches-visited: [2, 3] | positive-in-buffer: 13051 | amount-filled: 100.00%
	| epsilon: 0.36752931995802557
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1273, 2070, 1330, 1568, 730, 2038, 1370, 2672]
	| approx positives in sample 512: 158
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 17, 15, 20, 5, 29, 11, 43]
episode: 153 -> reward: -124.99999999998956, steps:71136, time-elasped: 25908.63s
-> berries picked: 85 of 800 | patches-visited: [2, 3] | positive-in-buffer: 13381 | amount-filled: 100.00%
	| epsilon: 0.3667906686886646
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1295, 2080, 1350, 1651, 739, 2116, 1405, 2745]
	| approx positives in sample 512: 61
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 10, 7, 7, 4, 7, 8, 13]
episode: 154 -> reward: -124.99999999999295, steps:60480, time-elasped: 26123.84s
-> berries picked: 47 of 800 | patches-visited: [2] | positive-in-buffer: 13436 | amount-filled: 100.00%
	| epsilon: 0.3660535019422195
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1317, 2084, 1343, 1669, 738, 2111, 1413, 2761]
	| approx positives in sample 512: 58
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 9, 5, 10, 3, 8, 3, 8]
episode: 155 -> reward: -124.99999999999194, steps:59424, time-elasped: 26316.14s
-> berries picked: 38 of 800 | patches-visited: [1] | positive-in-buffer: 13476 | amount-filled: 100.00%
	| epsilon: 0.365317816735133
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1336, 2088, 1315, 1687, 735, 2123, 1423, 2769]
	| approx positives in sample 512: 67
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 12, 8, 7, 8, 10, 4, 15]
episode: 156 -> reward: -124.99999999999201, steps:56544, time-elasped: 26469.93s
-> berries picked: 31 of 800 | patches-visited: [1, 7] | positive-in-buffer: 13548 | amount-filled: 100.00%
	| epsilon: 0.3645836100898444
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1353, 2098, 1317, 1687, 753, 2118, 1423, 2799]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 16, 12, 18, 5, 25, 12, 32]
episode: 157 -> reward: -124.99999999999199, steps:65280, time-elasped: 26678.57s
-> berries picked: 70 of 800 | patches-visited: [9] | positive-in-buffer: 13791 | amount-filled: 100.00%
	| epsilon: 0.3638508790347769
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1399, 2107, 1322, 1700, 779, 2184, 1470, 2830]
	| approx positives in sample 512: 49
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 6, 6, 7, 2, 12, 4, 7]
episode: 158 -> reward: -124.99999999999183, steps:67968, time-elasped: 26902.56s
-> berries picked: 78 of 800 | patches-visited: [2] | positive-in-buffer: 13161 | amount-filled: 100.00%
	| epsilon: 0.3631196206043261
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1296, 2048, 1263, 1621, 754, 2052, 1399, 2728]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 19, 8, 19, 5, 16, 5, 26]
episode: 159 -> reward: -124.999999999993, steps:67104, time-elasped: 27121.28s
-> berries picked: 72 of 800 | patches-visited: [3] | positive-in-buffer: 13343 | amount-filled: 100.00%
	| epsilon: 0.36238983183884776
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1345, 2056, 1289, 1641, 754, 2089, 1414, 2755]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 29, 11, 23, 10, 19, 12, 31]
episode: 160 -> reward: -124.99999999999298, steps:63744, time-elasped: 27331.08s
-> berries picked: 59 of 800 | patches-visited: [9] | positive-in-buffer: 13497 | amount-filled: 100.00%
	| epsilon: 0.3616615097846458
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1379, 2075, 1297, 1672, 761, 2104, 1443, 2766]
	| approx positives in sample 512: 39
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 7, 4, 4, 1, 3, 7, 6]
episode: 161 -> reward: -124.99999999999116, steps:81024, time-elasped: 27601.00s
-> berries picked: 139 of 800 | patches-visited: [5, 7] | positive-in-buffer: 13627 | amount-filled: 100.00%
	| epsilon: 0.3609346514939605
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1379, 2075, 1315, 1679, 751, 2190, 1466, 2772]
	| approx positives in sample 512: 81
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 10, 8, 8, 4, 14, 7, 22]
episode: 162 -> reward: -124.99999999999223, steps:76800, time-elasped: 27841.51s
-> berries picked: 102 of 800 | patches-visited: [4, 8] | positive-in-buffer: 13951 | amount-filled: 100.00%
	| epsilon: 0.3602092540249563
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1441, 2105, 1325, 1740, 739, 2268, 1510, 2823]
	| approx positives in sample 512: 49
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 5, 5, 4, 3, 11, 8, 10]
episode: 163 -> reward: -124.99999999998838, steps:58368, time-elasped: 28023.29s
-> berries picked: 34 of 800 | patches-visited: [0, 8] | positive-in-buffer: 13194 | amount-filled: 100.00%
	| epsilon: 0.3594853144417102
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1345, 2003, 1245, 1673, 701, 2173, 1395, 2659]
	| approx positives in sample 512: 100
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 13, 5, 19, 5, 20, 11, 17]
episode: 164 -> reward: -124.99999999998855, steps:70176, time-elasped: 28271.28s
-> berries picked: 86 of 800 | patches-visited: [2, 3] | positive-in-buffer: 13557 | amount-filled: 100.00%
	| epsilon: 0.3587628298141999
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1346, 2096, 1272, 1721, 727, 2257, 1435, 2703]
	| approx positives in sample 512: 72
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 12, 8, 11, 2, 14, 3, 19]
episode: 165 -> reward: -124.99999999999187, steps:76128, time-elasped: 28520.22s
-> berries picked: 113 of 800 | patches-visited: [2, 4] | positive-in-buffer: 13951 | amount-filled: 100.00%
	| epsilon: 0.35804179721829144
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1354, 2183, 1283, 1793, 779, 2292, 1456, 2811]
	| approx positives in sample 512: 41
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7] [10, 6, 5, 3, 8, 2, 7]
episode: 166 -> reward: -124.9999999999915, steps:67392, time-elasped: 28752.02s
-> berries picked: 71 of 800 | patches-visited: [3] | positive-in-buffer: 13654 | amount-filled: 100.00%
	| epsilon: 0.357322213735728
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1311, 2128, 1258, 1769, 744, 2200, 1413, 2831]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 17, 15, 16, 5, 21, 10, 37]
episode: 167 -> reward: -124.99999999999157, steps:67104, time-elasped: 28964.14s
-> berries picked: 75 of 800 | patches-visited: [5] | positive-in-buffer: 13875 | amount-filled: 100.00%
	| epsilon: 0.35660407645411757
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1318, 2131, 1254, 1808, 760, 2250, 1454, 2900]
	| approx positives in sample 512: 145
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 25, 16, 21, 10, 17, 14, 31]
episode: 168 -> reward: -124.99999999999187, steps:59424, time-elasped: 29169.48s
-> berries picked: 37 of 800 | patches-visited: [7] | positive-in-buffer: 13863 | amount-filled: 100.00%
	| epsilon: 0.35588738246692164
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1332, 2105, 1250, 1792, 758, 2268, 1456, 2902]
	| approx positives in sample 512: 75
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 8, 6, 11, 6, 11, 7, 18]
episode: 169 -> reward: -124.99999999999199, steps:55584, time-elasped: 29362.66s
-> berries picked: 27 of 800 | patches-visited: [0] | positive-in-buffer: 13837 | amount-filled: 100.00%
	| epsilon: 0.35517212887344296
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1339, 2108, 1242, 1769, 752, 2256, 1454, 2917]
	| approx positives in sample 512: 171
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 28, 17, 21, 11, 27, 17, 38]
episode: 170 -> reward: -124.99999999999204, steps:61632, time-elasped: 29544.66s
-> berries picked: 48 of 800 | patches-visited: [0] | positive-in-buffer: 14044 | amount-filled: 100.00%
	| epsilon: 0.3544583127788141
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1377, 2136, 1245, 1796, 790, 2285, 1458, 2957]
	| approx positives in sample 512: 47
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 7, 4, 3, 4, 7, 6, 10]
episode: 171 -> reward: -124.99999999999203, steps:50688, time-elasped: 29663.53s
-> berries picked: 9 of 800 | patches-visited: [1] | positive-in-buffer: 13861 | amount-filled: 100.00%
	| epsilon: 0.35374593129398585
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1362, 2093, 1237, 1754, 777, 2243, 1438, 2957]
	| approx positives in sample 512: 44
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 10, 9, 8, 1, 4, 3, 6]
episode: 172 -> reward: -124.99999999999434, steps:79584, time-elasped: 29921.00s
-> berries picked: 117 of 800 | patches-visited: [0, 7] | positive-in-buffer: 14230 | amount-filled: 100.00%
	| epsilon: 0.35303498153571505
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1401, 2163, 1243, 1818, 815, 2275, 1469, 3046]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 17, 8, 13, 6, 22, 8, 24]
episode: 173 -> reward: -124.99999999999118, steps:64032, time-elasped: 30132.62s
-> berries picked: 58 of 800 | patches-visited: [2, 4] | positive-in-buffer: 14407 | amount-filled: 100.00%
	| epsilon: 0.3523254606265534
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1425, 2163, 1280, 1854, 815, 2308, 1489, 3073]
	| approx positives in sample 512: 31
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 3, 5, 4, 2, 5, 3, 6]
episode: 174 -> reward: -124.99999999999467, steps:75456, time-elasped: 30390.27s
-> berries picked: 101 of 800 | patches-visited: [1, 6] | positive-in-buffer: 14273 | amount-filled: 100.00%
	| epsilon: 0.35161736569483554
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1418, 2075, 1282, 1817, 771, 2384, 1451, 3075]
	| approx positives in sample 512: 43
	| approx action-dist in sample 512: [0, 1, 2, 3, 5, 6, 7] [5, 6, 4, 5, 9, 8, 6]
episode: 175 -> reward: -124.99999999998882, steps:92448, time-elasped: 30697.32s
-> berries picked: 169 of 800 | patches-visited: [3, 5, 6] | positive-in-buffer: 14348 | amount-filled: 100.00%
	| epsilon: 0.35091069387466745
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1468, 2123, 1297, 1850, 764, 2365, 1437, 3044]
	| approx positives in sample 512: 87
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 16, 10, 11, 4, 16, 9, 15]
episode: 176 -> reward: -124.99999999999211, steps:63840, time-elasped: 30890.68s
-> berries picked: 66 of 800 | patches-visited: [9] | positive-in-buffer: 14422 | amount-filled: 100.00%
	| epsilon: 0.35020544230591516
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1455, 2144, 1279, 1866, 761, 2396, 1462, 3059]
	| approx positives in sample 512: 45
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 9, 3, 4, 1, 9, 2, 9]
episode: 177 -> reward: -124.99999999998977, steps:73824, time-elasped: 31155.16s
-> berries picked: 101 of 800 | patches-visited: [1, 5, 7] | positive-in-buffer: 14212 | amount-filled: 100.00%
	| epsilon: 0.3495016081341926
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1445, 2107, 1307, 1800, 795, 2271, 1471, 3016]
	| approx positives in sample 512: 49
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 8, 6, 6, 2, 7, 2, 14]
episode: 178 -> reward: -124.9999999999914, steps:67392, time-elasped: 31372.40s
-> berries picked: 71 of 800 | patches-visited: [1] | positive-in-buffer: 14406 | amount-filled: 100.00%
	| epsilon: 0.34879918851085073
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1502, 2119, 1317, 1844, 799, 2309, 1474, 3042]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 19, 13, 33, 4, 19, 19, 31]
episode: 179 -> reward: -124.99999999999193, steps:55872, time-elasped: 31566.43s
-> berries picked: 25 of 800 | patches-visited: [6] | positive-in-buffer: 14471 | amount-filled: 100.00%
	| epsilon: 0.3480981805929653
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1508, 2114, 1328, 1837, 797, 2346, 1486, 3055]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 25, 17, 21, 5, 24, 13, 30]
episode: 180 -> reward: -124.99999999999201, steps:67296, time-elasped: 31780.96s
-> berries picked: 71 of 800 | patches-visited: [2] | positive-in-buffer: 14675 | amount-filled: 100.00%
	| epsilon: 0.3473985815433259
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1508, 2181, 1326, 1883, 823, 2364, 1522, 3068]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 22, 9, 14, 7, 23, 15, 24]
episode: 181 -> reward: -124.99999999999255, steps:54432, time-elasped: 31950.07s
-> berries picked: 22 of 800 | patches-visited: [7] | positive-in-buffer: 14669 | amount-filled: 100.00%
	| epsilon: 0.3467003885304243
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1496, 2198, 1329, 1885, 824, 2370, 1512, 3055]
	| approx positives in sample 512: 36
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 4, 2, 8, 1, 5, 3, 10]
episode: 182 -> reward: -124.99999999999584, steps:69312, time-elasped: 32173.38s
-> berries picked: 81 of 800 | patches-visited: [0, 7] | positive-in-buffer: 14198 | amount-filled: 100.00%
	| epsilon: 0.3460035987284428
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1436, 2080, 1264, 1810, 810, 2364, 1424, 3010]
	| approx positives in sample 512: 90
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 15, 5, 12, 1, 12, 11, 20]
episode: 183 -> reward: -124.99999999999221, steps:67776, time-elasped: 32394.22s
-> berries picked: 72 of 800 | patches-visited: [0] | positive-in-buffer: 14449 | amount-filled: 100.00%
	| epsilon: 0.34530820931724304
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1480, 2147, 1303, 1842, 798, 2380, 1451, 3048]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 16, 13, 18, 8, 20, 20, 20]
episode: 184 -> reward: -124.9999999999917, steps:66432, time-elasped: 32589.17s
-> berries picked: 79 of 800 | patches-visited: [2] | positive-in-buffer: 14666 | amount-filled: 100.00%
	| epsilon: 0.3446142174823547
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1500, 2182, 1323, 1890, 817, 2393, 1496, 3065]
	| approx positives in sample 512: 176
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 33, 11, 23, 8, 32, 12, 40]
episode: 185 -> reward: -124.99999999999204, steps:55584, time-elasped: 32789.49s
-> berries picked: 26 of 800 | patches-visited: [1] | positive-in-buffer: 14743 | amount-filled: 100.00%
	| epsilon: 0.34392162041496355
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1513, 2188, 1331, 1887, 834, 2399, 1497, 3094]
	| approx positives in sample 512: 170
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 23, 19, 22, 14, 25, 20, 31]
episode: 186 -> reward: -124.99999999999234, steps:65664, time-elasped: 32999.08s
-> berries picked: 65 of 800 | patches-visited: [3] | positive-in-buffer: 14831 | amount-filled: 100.00%
	| epsilon: 0.34323041531190074
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1499, 2221, 1344, 1897, 848, 2423, 1489, 3110]
	| approx positives in sample 512: 39
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 2, 4, 5, 2, 9, 7, 9]
episode: 187 -> reward: -124.99999999999118, steps:64128, time-elasped: 33173.67s
-> berries picked: 61 of 800 | patches-visited: [2] | positive-in-buffer: 14268 | amount-filled: 100.00%
	| epsilon: 0.34254059937563097
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1451, 2161, 1244, 1843, 831, 2342, 1441, 2955]
	| approx positives in sample 512: 45
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 10, 2, 3, 3, 6, 8, 8]
episode: 188 -> reward: -124.99999999999231, steps:68832, time-elasped: 33409.05s
-> berries picked: 72 of 800 | patches-visited: [1, 3] | positive-in-buffer: 14472 | amount-filled: 100.00%
	| epsilon: 0.34185216981424144
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1445, 2219, 1250, 1850, 830, 2429, 1471, 2978]
	| approx positives in sample 512: 93
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 17, 6, 21, 4, 19, 5, 16]
episode: 189 -> reward: -124.99999999999201, steps:54912, time-elasped: 33561.98s
-> berries picked: 25 of 800 | patches-visited: [0] | positive-in-buffer: 14546 | amount-filled: 100.00%
	| epsilon: 0.34116512384143055
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1454, 2242, 1251, 1869, 834, 2454, 1468, 2974]
	| approx positives in sample 512: 33
	| approx action-dist in sample 512: [0, 1, 2, 3, 5, 6, 7] [3, 8, 4, 4, 3, 5, 6]
episode: 190 -> reward: -124.99999999999199, steps:57504, time-elasped: 33737.45s
-> berries picked: 30 of 800 | patches-visited: [8] | positive-in-buffer: 13934 | amount-filled: 100.00%
	| epsilon: 0.3404794586764963
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1358, 2154, 1203, 1801, 807, 2403, 1381, 2827]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 13, 13, 9, 10, 22, 12, 18]
episode: 191 -> reward: -124.99999999999375, steps:62304, time-elasped: 33949.00s
-> berries picked: 49 of 800 | patches-visited: [4] | positive-in-buffer: 14150 | amount-filled: 100.00%
	| epsilon: 0.3397951715443256
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1366, 2168, 1234, 1801, 812, 2476, 1448, 2845]
	| approx positives in sample 512: 45
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 5, 1, 10, 1, 9, 4, 6]
episode: 192 -> reward: -124.9999999999849, steps:70848, time-elasped: 34182.12s
-> berries picked: 81 of 800 | patches-visited: [0, 4] | positive-in-buffer: 14479 | amount-filled: 100.00%
	| epsilon: 0.3391122596753824
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1444, 2185, 1274, 1818, 836, 2484, 1516, 2922]
	| approx positives in sample 512: 52
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 3, 2, 6, 2, 10, 5, 15]
episode: 193 -> reward: -124.99999999999203, steps:76512, time-elasped: 34433.50s
-> berries picked: 108 of 800 | patches-visited: [1, 7] | positive-in-buffer: 14853 | amount-filled: 100.00%
	| epsilon: 0.338430720305697
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1491, 2251, 1302, 1873, 872, 2540, 1561, 2963]
	| approx positives in sample 512: 41
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 5, 3, 8, 1, 5, 5, 9]
episode: 194 -> reward: -124.99999999999167, steps:54240, time-elasped: 34619.65s
-> berries picked: 21 of 800 | patches-visited: [8] | positive-in-buffer: 14332 | amount-filled: 100.00%
	| epsilon: 0.3377505506768546
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1409, 2161, 1263, 1858, 834, 2469, 1514, 2824]
	| approx positives in sample 512: 42
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 8, 6, 2, 1, 9, 7, 7]
episode: 195 -> reward: -124.99999999999086, steps:65952, time-elasped: 34826.66s
-> berries picked: 59 of 800 | patches-visited: [1, 5] | positive-in-buffer: 14408 | amount-filled: 100.00%
	| epsilon: 0.33707174803598416
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1398, 2203, 1283, 1857, 853, 2476, 1511, 2827]
	| approx positives in sample 512: 36
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 6, 3, 5, 2, 5, 3, 6]
episode: 196 -> reward: -124.99999999998884, steps:59616, time-elasped: 35024.39s
-> berries picked: 38 of 800 | patches-visited: [4] | positive-in-buffer: 14031 | amount-filled: 100.00%
	| epsilon: 0.3363943096357473
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1388, 2150, 1214, 1834, 820, 2387, 1464, 2774]
	| approx positives in sample 512: 78
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 11, 11, 9, 5, 11, 9, 15]
episode: 197 -> reward: -124.99999999999197, steps:66816, time-elasped: 35228.69s
-> berries picked: 76 of 800 | patches-visited: [6] | positive-in-buffer: 14348 | amount-filled: 100.00%
	| epsilon: 0.33571823273432716
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1412, 2199, 1272, 1875, 835, 2474, 1478, 2803]
	| approx positives in sample 512: 143
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 22, 9, 11, 9, 26, 15, 33]
episode: 198 -> reward: -124.99999999999199, steps:62400, time-elasped: 35434.23s
-> berries picked: 54 of 800 | patches-visited: [0] | positive-in-buffer: 14541 | amount-filled: 100.00%
	| epsilon: 0.3350435145954174
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1448, 2234, 1270, 1912, 857, 2484, 1514, 2822]
	| approx positives in sample 512: 47
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 8, 5, 10, 3, 4, 1, 13]
episode: 199 -> reward: -124.99999999998717, steps:63744, time-elasped: 35664.31s
-> berries picked: 61 of 800 | patches-visited: [1] | positive-in-buffer: 14673 | amount-filled: 100.00%
	| epsilon: 0.33437015248821106
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1503, 2226, 1279, 1933, 857, 2485, 1531, 2859]
	| approx positives in sample 512: 59
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 5, 6, 6, 3, 9, 7, 15]
episode: 200 -> reward: -124.9999999999899, steps:55680, time-elasped: 35851.12s
-> berries picked: 31 of 800 | patches-visited: [5] | positive-in-buffer: 14339 | amount-filled: 100.00%
	| epsilon: 0.33369814368738926
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1471, 2134, 1241, 1921, 808, 2407, 1532, 2825]
	| approx positives in sample 512: 171
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 26, 12, 18, 7, 34, 23, 30]
episode: 201 -> reward: -124.999999999993, steps:68448, time-elasped: 36081.73s
-> berries picked: 72 of 800 | patches-visited: [7] | positive-in-buffer: 14576 | amount-filled: 100.00%
	| epsilon: 0.33302748547311056
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1459, 2162, 1276, 1967, 837, 2433, 1552, 2890]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 13, 14, 11, 4, 21, 14, 24]
episode: 202 -> reward: -124.99999999998509, steps:84000, time-elasped: 36346.86s
-> berries picked: 143 of 800 | patches-visited: [1, 7] | positive-in-buffer: 15098 | amount-filled: 100.00%
	| epsilon: 0.3323581751309999
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1579, 2239, 1312, 2044, 863, 2518, 1641, 2902]
	| approx positives in sample 512: 58
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 5, 3, 7, 4, 8, 11, 12]
episode: 203 -> reward: -124.99999999999139, steps:64416, time-elasped: 36565.70s
-> berries picked: 58 of 800 | patches-visited: [5] | positive-in-buffer: 15015 | amount-filled: 100.00%
	| epsilon: 0.33169020995213727
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1597, 2188, 1274, 2081, 863, 2526, 1639, 2847]
	| approx positives in sample 512: 48
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 7] [8, 9, 4, 7, 5, 4, 11]
episode: 204 -> reward: -124.99999999999119, steps:62880, time-elasped: 36775.75s
-> berries picked: 54 of 800 | patches-visited: [3] | positive-in-buffer: 14533 | amount-filled: 100.00%
	| epsilon: 0.33102358723304715
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1543, 2167, 1225, 1970, 819, 2476, 1583, 2750]
	| approx positives in sample 512: 51
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 9, 3, 10, 3, 6, 5, 11]
episode: 205 -> reward: -124.99999999999079, steps:85824, time-elasped: 37049.09s
-> berries picked: 154 of 800 | patches-visited: [2, 9] | positive-in-buffer: 15019 | amount-filled: 100.00%
	| epsilon: 0.33035830427568735
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1572, 2221, 1254, 2014, 891, 2598, 1638, 2831]
	| approx positives in sample 512: 47
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 5, 3, 7, 2, 8, 10, 8]
episode: 206 -> reward: -124.99999999999503, steps:85152, time-elasped: 37333.25s
-> berries picked: 143 of 800 | patches-visited: [2, 4, 8] | positive-in-buffer: 14992 | amount-filled: 100.00%
	| epsilon: 0.3296943583874381
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1551, 2228, 1241, 2008, 922, 2561, 1595, 2886]
	| approx positives in sample 512: 52
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 6, 4, 4, 5, 7, 9, 12]
episode: 207 -> reward: -124.99999999999197, steps:57216, time-elasped: 37538.87s
-> berries picked: 31 of 800 | patches-visited: [1] | positive-in-buffer: 14879 | amount-filled: 100.00%
	| epsilon: 0.32903174688109116
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1587, 2208, 1239, 1992, 896, 2523, 1583, 2851]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 21, 13, 15, 8, 19, 14, 13]
episode: 208 -> reward: -124.99999999999193, steps:66432, time-elasped: 37739.39s
-> berries picked: 73 of 800 | patches-visited: [2] | positive-in-buffer: 15046 | amount-filled: 100.00%
	| epsilon: 0.32837046707483913
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1603, 2240, 1246, 2011, 918, 2545, 1596, 2887]
	| approx positives in sample 512: 181
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 25, 9, 28, 11, 34, 23, 35]
episode: 209 -> reward: -124.99999999999183, steps:67104, time-elasped: 37935.04s
-> berries picked: 70 of 800 | patches-visited: [5] | positive-in-buffer: 15230 | amount-filled: 100.00%
	| epsilon: 0.32771051629226433
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1640, 2274, 1241, 2040, 950, 2567, 1596, 2922]
	| approx positives in sample 512: 168
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 34, 16, 14, 10, 30, 18, 31]
episode: 210 -> reward: -124.99999999999035, steps:71328, time-elasped: 38163.45s
-> berries picked: 88 of 800 | patches-visited: [0, 8] | positive-in-buffer: 15437 | amount-filled: 100.00%
	| epsilon: 0.327051891862328
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1670, 2295, 1250, 2075, 955, 2561, 1674, 2957]
	| approx positives in sample 512: 65
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 10, 6, 9, 3, 12, 7, 14]
episode: 211 -> reward: -124.99999999999199, steps:66144, time-elasped: 38360.69s
-> berries picked: 76 of 800 | patches-visited: [1] | positive-in-buffer: 15473 | amount-filled: 100.00%
	| epsilon: 0.3263945911193598
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1671, 2319, 1247, 2047, 968, 2546, 1676, 2999]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 26, 16, 32, 17, 44, 21, 43]
episode: 212 -> reward: -124.99999999999201, steps:54048, time-elasped: 38501.35s
-> berries picked: 21 of 800 | patches-visited: [2] | positive-in-buffer: 15485 | amount-filled: 100.00%
	| epsilon: 0.3257386114030465
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1690, 2320, 1257, 2037, 961, 2555, 1679, 2986]
	| approx positives in sample 512: 47
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 5, 3, 9, 2, 8, 5, 9]
episode: 213 -> reward: -124.99999999998755, steps:76032, time-elasped: 38745.64s
-> berries picked: 102 of 800 | patches-visited: [0, 7] | positive-in-buffer: 14616 | amount-filled: 100.00%
	| epsilon: 0.3250839500584218
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1555, 2123, 1244, 1882, 900, 2461, 1583, 2868]
	| approx positives in sample 512: 50
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 6, 3, 3, 3, 11, 9, 10]
episode: 214 -> reward: -124.99999999999396, steps:64512, time-elasped: 38974.08s
-> berries picked: 57 of 800 | patches-visited: [5] | positive-in-buffer: 14525 | amount-filled: 100.00%
	| epsilon: 0.3244306044358549
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1556, 2104, 1201, 1870, 905, 2463, 1597, 2829]
	| approx positives in sample 512: 41
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 10, 6, 2, 1, 8, 5, 7]
episode: 215 -> reward: -124.99999999999227, steps:64416, time-elasped: 39177.44s
-> berries picked: 69 of 800 | patches-visited: [6] | positive-in-buffer: 14603 | amount-filled: 100.00%
	| epsilon: 0.32377857189104065
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1568, 2118, 1202, 1889, 911, 2469, 1635, 2811]
	| approx positives in sample 512: 41
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 3, 4, 4, 3, 7, 7, 9]
episode: 216 -> reward: -124.99999999998947, steps:63840, time-elasped: 39377.21s
-> berries picked: 64 of 800 | patches-visited: [0] | positive-in-buffer: 14658 | amount-filled: 100.00%
	| epsilon: 0.32312784978498793
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1633, 2103, 1239, 1864, 946, 2478, 1597, 2798]
	| approx positives in sample 512: 47
	| approx action-dist in sample 512: [0, 1, 2, 3, 5, 6, 7] [3, 9, 9, 5, 10, 2, 9]
episode: 217 -> reward: -124.99999999998941, steps:63552, time-elasped: 39576.02s
-> berries picked: 47 of 800 | patches-visited: [0, 9] | positive-in-buffer: 14632 | amount-filled: 100.00%
	| epsilon: 0.3224784354840096
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1629, 2106, 1211, 1864, 940, 2460, 1584, 2838]
	| approx positives in sample 512: 51
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 9, 4, 10, 5, 7, 5, 8]
episode: 218 -> reward: -124.99999999999112, steps:66528, time-elasped: 39815.55s
-> berries picked: 64 of 800 | patches-visited: [2] | positive-in-buffer: 14636 | amount-filled: 100.00%
	| epsilon: 0.3218303263597117
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1632, 2093, 1194, 1872, 941, 2480, 1617, 2807]
	| approx positives in sample 512: 182
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 22, 10, 13, 9, 34, 24, 41]
episode: 219 -> reward: -124.99999999999204, steps:49056, time-elasped: 39939.96s
-> berries picked: 3 of 800 | patches-visited: [2] | positive-in-buffer: 14637 | amount-filled: 100.00%
	| epsilon: 0.3211835197889826
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1632, 2092, 1193, 1871, 941, 2482, 1617, 2809]
	| approx positives in sample 512: 72
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 9, 6, 12, 7, 15, 6, 13]
episode: 220 -> reward: -124.99999999999254, steps:78528, time-elasped: 40228.04s
-> berries picked: 126 of 800 | patches-visited: [3, 6] | positive-in-buffer: 15118 | amount-filled: 100.00%
	| epsilon: 0.3205380131539825
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1655, 2203, 1209, 1958, 974, 2583, 1695, 2841]
	| approx positives in sample 512: 155
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 22, 10, 20, 9, 30, 17, 27]
episode: 221 -> reward: -124.99999999999129, steps:57408, time-elasped: 40428.37s
-> berries picked: 33 of 800 | patches-visited: [9] | positive-in-buffer: 15135 | amount-filled: 100.00%
	| epsilon: 0.3198938038421331
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1659, 2230, 1204, 1963, 964, 2594, 1673, 2848]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 18, 9, 13, 4, 27, 20, 16]
episode: 222 -> reward: -124.99999999999207, steps:67296, time-elasped: 40615.90s
-> berries picked: 66 of 800 | patches-visited: [2, 4] | positive-in-buffer: 15337 | amount-filled: 100.00%
	| epsilon: 0.3192508892461066
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1702, 2264, 1212, 1985, 977, 2617, 1671, 2909]
	| approx positives in sample 512: 143
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 25, 15, 14, 13, 15, 14, 28]
episode: 223 -> reward: -124.99999999999201, steps:58848, time-elasped: 40776.28s
-> berries picked: 43 of 800 | patches-visited: [7] | positive-in-buffer: 15388 | amount-filled: 100.00%
	| epsilon: 0.3186092667638154
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1687, 2259, 1219, 2003, 987, 2640, 1663, 2930]
	| approx positives in sample 512: 89
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 9, 8, 10, 11, 16, 6, 21]
episode: 224 -> reward: -124.99999999999189, steps:67200, time-elasped: 40988.26s
-> berries picked: 80 of 800 | patches-visited: [9] | positive-in-buffer: 15450 | amount-filled: 100.00%
	| epsilon: 0.3179689337984015
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1672, 2251, 1241, 2015, 991, 2663, 1701, 2916]
	| approx positives in sample 512: 164
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 22, 13, 21, 12, 34, 14, 32]
episode: 225 -> reward: -124.99999999999162, steps:65376, time-elasped: 41211.66s
-> berries picked: 61 of 800 | patches-visited: [6, 9] | positive-in-buffer: 15583 | amount-filled: 100.00%
	| epsilon: 0.31732988775822607
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1680, 2272, 1243, 2024, 1009, 2702, 1704, 2949]
	| approx positives in sample 512: 50
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 1, 5, 7, 4, 12, 6, 11]
episode: 226 -> reward: -124.99999999999191, steps:63168, time-elasped: 41414.34s
-> berries picked: 50 of 800 | patches-visited: [5] | positive-in-buffer: 14694 | amount-filled: 100.00%
	| epsilon: 0.3166921260568588
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1538, 2128, 1199, 1937, 908, 2576, 1631, 2777]
	| approx positives in sample 512: 53
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 7, 9, 5, 2, 10, 3, 11]
episode: 227 -> reward: -124.9999999999899, steps:73728, time-elasped: 41655.09s
-> berries picked: 91 of 800 | patches-visited: [2, 4] | positive-in-buffer: 14965 | amount-filled: 100.00%
	| epsilon: 0.3160556461130675
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1545, 2194, 1234, 1938, 953, 2594, 1640, 2867]
	| approx positives in sample 512: 61
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 9, 4, 10, 6, 9, 6, 10]
episode: 228 -> reward: -124.99999999999241, steps:52992, time-elasped: 41819.46s
-> berries picked: 16 of 800 | patches-visited: [1] | positive-in-buffer: 14874 | amount-filled: 100.00%
	| epsilon: 0.3154204453508078
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1533, 2183, 1216, 1919, 956, 2600, 1621, 2846]
	| approx positives in sample 512: 46
	| approx action-dist in sample 512: [0, 1, 2, 3, 5, 6, 7] [2, 6, 9, 7, 9, 8, 5]
episode: 229 -> reward: -124.99999999999314, steps:76704, time-elasped: 42068.94s
-> berries picked: 102 of 800 | patches-visited: [6, 8] | positive-in-buffer: 14833 | amount-filled: 100.00%
	| epsilon: 0.3147865211992125
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1524, 2160, 1225, 1889, 945, 2635, 1613, 2842]
	| approx positives in sample 512: 41
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 2, 6, 8, 3, 6, 3, 8]
episode: 230 -> reward: -124.99999999998208, steps:103584, time-elasped: 42416.11s
-> berries picked: 218 of 800 | patches-visited: [3, 7, 8] | positive-in-buffer: 14850 | amount-filled: 100.00%
	| epsilon: 0.31415387109258136
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1545, 2135, 1278, 1919, 979, 2611, 1623, 2760]
	| approx positives in sample 512: 70
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 11, 8, 8, 5, 10, 8, 11]
episode: 231 -> reward: -124.9999999999917, steps:64704, time-elasped: 42609.43s
-> berries picked: 77 of 800 | patches-visited: [8] | positive-in-buffer: 14962 | amount-filled: 100.00%
	| epsilon: 0.3135224924703705
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1539, 2199, 1276, 1938, 1006, 2639, 1614, 2751]
	| approx positives in sample 512: 54
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 6, 4, 4, 4, 15, 8, 9]
episode: 232 -> reward: -124.9999999999918, steps:65280, time-elasped: 42816.75s
-> berries picked: 68 of 800 | patches-visited: [2] | positive-in-buffer: 14722 | amount-filled: 100.00%
	| epsilon: 0.3128923827771822
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1517, 2179, 1251, 1908, 961, 2627, 1598, 2681]
	| approx positives in sample 512: 39
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 3, 2, 7, 5, 6, 6, 3]
episode: 233 -> reward: -124.99999999998883, steps:64032, time-elasped: 43036.68s
-> berries picked: 57 of 800 | patches-visited: [6] | positive-in-buffer: 14650 | amount-filled: 100.00%
	| epsilon: 0.3122635394627545
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1516, 2203, 1260, 1852, 937, 2620, 1601, 2661]
	| approx positives in sample 512: 37
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 3, 2, 2, 2, 7, 9, 6]
episode: 234 -> reward: -124.99999999999201, steps:50592, time-elasped: 43203.52s
-> berries picked: 9 of 800 | patches-visited: [1] | positive-in-buffer: 14630 | amount-filled: 100.00%
	| epsilon: 0.311635959981951
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1512, 2193, 1256, 1846, 936, 2607, 1623, 2657]
	| approx positives in sample 512: 50
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 10, 4, 8, 7, 6, 2, 8]
episode: 235 -> reward: -124.99999999998992, steps:86304, time-elasped: 43497.93s
-> berries picked: 145 of 800 | patches-visited: [0, 2, 4] | positive-in-buffer: 15183 | amount-filled: 100.00%
	| epsilon: 0.3110096417947503
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1566, 2393, 1266, 1948, 943, 2690, 1676, 2701]
	| approx positives in sample 512: 57
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 13, 3, 6, 1, 11, 5, 9]
episode: 236 -> reward: -124.999999999992, steps:54144, time-elasped: 43667.44s
-> berries picked: 21 of 800 | patches-visited: [2] | positive-in-buffer: 15027 | amount-filled: 100.00%
	| epsilon: 0.31038458236623606
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1549, 2368, 1227, 1920, 939, 2676, 1681, 2667]
	| approx positives in sample 512: 49
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 9, 3, 7, 3, 9, 4, 10]
episode: 237 -> reward: -124.999999999992, steps:67296, time-elasped: 43851.99s
-> berries picked: 74 of 800 | patches-visited: [5] | positive-in-buffer: 14761 | amount-filled: 100.00%
	| epsilon: 0.30976077916658634
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1558, 2231, 1189, 1869, 974, 2649, 1631, 2660]
	| approx positives in sample 512: 160
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 24, 9, 18, 13, 30, 15, 34]
episode: 238 -> reward: -124.9999999999925, steps:63360, time-elasped: 44062.51s
-> berries picked: 52 of 800 | patches-visited: [2] | positive-in-buffer: 14920 | amount-filled: 100.00%
	| epsilon: 0.30913822967106375
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1567, 2301, 1209, 1875, 976, 2667, 1654, 2671]
	| approx positives in sample 512: 39
	| approx action-dist in sample 512: [0, 1, 2, 4, 5, 6, 7] [10, 5, 5, 7, 5, 1, 6]
episode: 239 -> reward: -124.9999999999901, steps:60576, time-elasped: 44261.87s
-> berries picked: 43 of 800 | patches-visited: [4] | positive-in-buffer: 15046 | amount-filled: 100.00%
	| epsilon: 0.30851693136000485
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1563, 2333, 1239, 1927, 967, 2681, 1668, 2668]
	| approx positives in sample 512: 69
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 14, 1, 9, 5, 12, 9, 11]
episode: 240 -> reward: -124.99999999998637, steps:79680, time-elasped: 44531.99s
-> berries picked: 124 of 800 | patches-visited: [3, 8] | positive-in-buffer: 15474 | amount-filled: 100.00%
	| epsilon: 0.30789688171881036
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1625, 2403, 1260, 1949, 1006, 2759, 1738, 2734]
	| approx positives in sample 512: 104
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 16, 7, 15, 8, 17, 10, 15]
episode: 241 -> reward: -124.99999999999207, steps:54816, time-elasped: 44672.96s
-> berries picked: 23 of 800 | patches-visited: [8] | positive-in-buffer: 15367 | amount-filled: 100.00%
	| epsilon: 0.3072780782379347
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1619, 2383, 1235, 1937, 995, 2739, 1727, 2732]
	| approx positives in sample 512: 56
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 8, 8, 12, 4, 5, 4, 6]
episode: 242 -> reward: -124.99999999999214, steps:68640, time-elasped: 44921.12s
-> berries picked: 66 of 800 | patches-visited: [3, 4, 6] | positive-in-buffer: 14645 | amount-filled: 100.00%
	| epsilon: 0.3066605184128759
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1533, 2249, 1156, 1807, 1008, 2639, 1657, 2596]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 18, 10, 12, 9, 22, 13, 20]
episode: 243 -> reward: -124.99999999999152, steps:52896, time-elasped: 45092.89s
-> berries picked: 15 of 800 | patches-visited: [2] | positive-in-buffer: 14689 | amount-filled: 100.00%
	| epsilon: 0.3060441997441655
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1534, 2247, 1165, 1806, 1008, 2660, 1672, 2597]
	| approx positives in sample 512: 48
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 6, 5, 6, 2, 11, 7, 9]
episode: 244 -> reward: -124.99999999999177, steps:65856, time-elasped: 45269.13s
-> berries picked: 69 of 800 | patches-visited: [5] | positive-in-buffer: 14864 | amount-filled: 100.00%
	| epsilon: 0.30542911973735837
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1581, 2283, 1164, 1847, 1022, 2686, 1685, 2596]
	| approx positives in sample 512: 41
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 6, 3, 4, 4, 11, 3, 3]
episode: 245 -> reward: -124.99999999999153, steps:66816, time-elasped: 45488.46s
-> berries picked: 73 of 800 | patches-visited: [0] | positive-in-buffer: 14465 | amount-filled: 100.00%
	| epsilon: 0.3048152759030227
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1547, 2235, 1140, 1738, 983, 2676, 1654, 2492]
	| approx positives in sample 512: 169
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 29, 15, 26, 9, 36, 17, 24]
episode: 246 -> reward: -124.99999999999176, steps:70080, time-elasped: 45712.92s
-> berries picked: 79 of 800 | patches-visited: [1, 9] | positive-in-buffer: 14703 | amount-filled: 100.00%
	| epsilon: 0.3042026657567299
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1579, 2292, 1159, 1772, 983, 2716, 1705, 2497]
	| approx positives in sample 512: 67
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 9, 6, 10, 5, 14, 7, 11]
episode: 247 -> reward: -124.99999999998823, steps:81696, time-elasped: 45974.39s
-> berries picked: 131 of 800 | patches-visited: [0, 5] | positive-in-buffer: 15156 | amount-filled: 100.00%
	| epsilon: 0.3035912868190444
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1588, 2366, 1217, 1786, 1090, 2780, 1744, 2585]
	| approx positives in sample 512: 57
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 12, 5, 5, 3, 10, 5, 9]
episode: 248 -> reward: -124.99999999999213, steps:50496, time-elasped: 46130.97s
-> berries picked: 10 of 800 | patches-visited: [9] | positive-in-buffer: 15048 | amount-filled: 100.00%
	| epsilon: 0.3029811366155139
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1581, 2343, 1190, 1772, 1086, 2772, 1731, 2573]
	| approx positives in sample 512: 59
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 5, 3, 7, 6, 9, 10, 10]
episode: 249 -> reward: -124.99999999998693, steps:78816, time-elasped: 46389.27s
-> berries picked: 119 of 800 | patches-visited: [1, 3] | positive-in-buffer: 15388 | amount-filled: 100.00%
	| epsilon: 0.30237221267665904
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1616, 2384, 1271, 1852, 1096, 2819, 1745, 2605]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 19, 11, 7, 7, 23, 8, 17]
episode: 250 -> reward: -124.99999999999186, steps:53472, time-elasped: 46566.93s
-> berries picked: 20 of 800 | patches-visited: [0] | positive-in-buffer: 15386 | amount-filled: 100.00%
	| epsilon: 0.30176451253796366
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1602, 2386, 1284, 1846, 1096, 2816, 1738, 2618]
	| approx positives in sample 512: 39
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 4, 3, 4, 4, 4, 6, 9]
episode: 251 -> reward: -124.99999999998882, steps:74112, time-elasped: 46793.91s
-> berries picked: 98 of 800 | patches-visited: [1, 3] | positive-in-buffer: 15001 | amount-filled: 100.00%
	| epsilon: 0.3011580337398647
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1539, 2322, 1247, 1825, 1039, 2725, 1727, 2577]
	| approx positives in sample 512: 43
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 9, 1, 8, 3, 6, 4, 9]
episode: 252 -> reward: -124.9999999999913, steps:67392, time-elasped: 47022.36s
-> berries picked: 77 of 800 | patches-visited: [9] | positive-in-buffer: 15137 | amount-filled: 100.00%
	| epsilon: 0.3005527738277423
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1518, 2421, 1248, 1837, 1057, 2735, 1761, 2560]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 28, 9, 18, 12, 19, 17, 21]
episode: 253 -> reward: -124.99999999998896, steps:101088, time-elasped: 47359.28s
-> berries picked: 206 of 800 | patches-visited: [1, 4, 5] | positive-in-buffer: 15678 | amount-filled: 100.00%
	| epsilon: 0.2999487303519097
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1528, 2487, 1285, 1893, 1063, 2803, 1817, 2802]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 17, 12, 18, 6, 20, 26, 17]
episode: 254 -> reward: -124.9999999999918, steps:61248, time-elasped: 47550.95s
-> berries picked: 48 of 800 | patches-visited: [3] | positive-in-buffer: 15689 | amount-filled: 100.00%
	| epsilon: 0.29934590086760365
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1521, 2527, 1295, 1884, 1063, 2826, 1822, 2751]
	| approx positives in sample 512: 63
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 13, 6, 9, 3, 9, 6, 10]
episode: 255 -> reward: -124.99999999999186, steps:67296, time-elasped: 47750.87s
-> berries picked: 73 of 800 | patches-visited: [8] | positive-in-buffer: 15584 | amount-filled: 100.00%
	| epsilon: 0.2987442829349742
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1460, 2581, 1258, 1853, 1068, 2806, 1816, 2742]
	| approx positives in sample 512: 156
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 24, 12, 24, 12, 26, 18, 20]
episode: 256 -> reward: -124.99999999999245, steps:55392, time-elasped: 47954.27s
-> berries picked: 26 of 800 | patches-visited: [4] | positive-in-buffer: 15657 | amount-filled: 100.00%
	| epsilon: 0.29814387411907495
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1464, 2600, 1262, 1901, 1066, 2818, 1815, 2731]
	| approx positives in sample 512: 186
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 41, 18, 27, 15, 36, 10, 28]
episode: 257 -> reward: -124.99999999999484, steps:83520, time-elasped: 48255.92s
-> berries picked: 135 of 800 | patches-visited: [6, 7] | positive-in-buffer: 16068 | amount-filled: 100.00%
	| epsilon: 0.2975446719898532
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1494, 2681, 1396, 1960, 1089, 2849, 1851, 2748]
	| approx positives in sample 512: 71
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 10, 4, 7, 5, 13, 11, 13]
episode: 258 -> reward: -124.99999999999427, steps:88416, time-elasped: 48558.34s
-> berries picked: 155 of 800 | patches-visited: [3, 6, 8] | positive-in-buffer: 16048 | amount-filled: 100.00%
	| epsilon: 0.2969466741221402
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1497, 2661, 1426, 1927, 1156, 2848, 1877, 2656]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 35, 26, 26, 18, 33, 22, 37]
episode: 259 -> reward: -124.9999999999922, steps:81696, time-elasped: 48802.71s
-> berries picked: 127 of 800 | patches-visited: [3, 6, 7] | positive-in-buffer: 16254 | amount-filled: 100.00%
	| epsilon: 0.2963498780956412
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1516, 2696, 1448, 1959, 1132, 2885, 1897, 2721]
	| approx positives in sample 512: 80
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 14, 11, 13, 7, 11, 10, 9]
episode: 260 -> reward: -124.99999999999505, steps:85536, time-elasped: 49064.45s
-> berries picked: 151 of 800 | patches-visited: [6, 8] | positive-in-buffer: 16272 | amount-filled: 100.00%
	| epsilon: 0.29575428149492555
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1504, 2691, 1474, 1992, 1106, 2899, 1906, 2700]
	| approx positives in sample 512: 55
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 5, 5, 6, 3, 13, 8, 11]
episode: 261 -> reward: -124.99999999998803, steps:90624, time-elasped: 49375.79s
-> berries picked: 162 of 800 | patches-visited: [3, 4, 7] | positive-in-buffer: 15500 | amount-filled: 100.00%
	| epsilon: 0.29515988190941733
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1460, 2609, 1423, 1875, 1042, 2739, 1788, 2564]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 14, 9, 14, 5, 22, 16, 16]
episode: 262 -> reward: -124.99999999998752, steps:86496, time-elasped: 49681.45s
-> berries picked: 143 of 800 | patches-visited: [0, 3, 9] | positive-in-buffer: 15921 | amount-filled: 100.00%
	| epsilon: 0.2945666769333851
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1501, 2631, 1488, 1874, 1182, 2794, 1799, 2652]
	| approx positives in sample 512: 47
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 8, 3, 8, 4, 7, 7, 5]
episode: 263 -> reward: -124.99999999999193, steps:64608, time-elasped: 49945.73s
-> berries picked: 61 of 800 | patches-visited: [6] | positive-in-buffer: 15146 | amount-filled: 100.00%
	| epsilon: 0.2939746641659326
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1421, 2520, 1401, 1782, 1161, 2660, 1697, 2504]
	| approx positives in sample 512: 32
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 5, 4, 3, 5, 7, 3, 3]
episode: 264 -> reward: -124.9999999999921, steps:63264, time-elasped: 50170.67s
-> berries picked: 57 of 800 | patches-visited: [1] | positive-in-buffer: 14906 | amount-filled: 100.00%
	| epsilon: 0.29338384121098865
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1389, 2457, 1403, 1746, 1127, 2638, 1682, 2464]
	| approx positives in sample 512: 44
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 7, 3, 4, 3, 9, 8, 6]
episode: 265 -> reward: -124.99999999999149, steps:59808, time-elasped: 50416.39s
-> berries picked: 41 of 800 | patches-visited: [8] | positive-in-buffer: 15034 | amount-filled: 100.00%
	| epsilon: 0.29279420567729775
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1396, 2471, 1390, 1744, 1127, 2700, 1692, 2514]
	| approx positives in sample 512: 69
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 15, 10, 8, 4, 10, 6, 8]
episode: 266 -> reward: -124.99999999999203, steps:61152, time-elasped: 50643.66s
-> berries picked: 44 of 800 | patches-visited: [7] | positive-in-buffer: 15124 | amount-filled: 100.00%
	| epsilon: 0.2922057551784103
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1426, 2495, 1377, 1759, 1126, 2679, 1690, 2572]
	| approx positives in sample 512: 63
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 11, 8, 6, 4, 11, 4, 8]
episode: 267 -> reward: -124.99999999998883, steps:65376, time-elasped: 50872.45s
-> berries picked: 55 of 800 | patches-visited: [9] | positive-in-buffer: 15264 | amount-filled: 100.00%
	| epsilon: 0.29161848733267276
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1430, 2484, 1378, 1785, 1161, 2703, 1695, 2628]
	| approx positives in sample 512: 43
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 10, 4, 3, 4, 4, 6, 6]
episode: 268 -> reward: -124.99999999998708, steps:77856, time-elasped: 51180.99s
-> berries picked: 117 of 800 | patches-visited: [1, 5] | positive-in-buffer: 14979 | amount-filled: 100.00%
	| epsilon: 0.29103239976321843
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1351, 2453, 1325, 1791, 1107, 2693, 1693, 2566]
	| approx positives in sample 512: 145
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 30, 12, 18, 6, 32, 17, 23]
episode: 269 -> reward: -124.99999999999125, steps:57600, time-elasped: 51546.27s
-> berries picked: 38 of 800 | patches-visited: [6] | positive-in-buffer: 15083 | amount-filled: 100.00%
	| epsilon: 0.29044749009795734
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1344, 2497, 1376, 1804, 1108, 2691, 1692, 2571]
	| approx positives in sample 512: 126
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 23, 11, 17, 5, 22, 9, 20]
episode: 270 -> reward: -124.99999999998917, steps:76512, time-elasped: 51959.59s
-> berries picked: 101 of 800 | patches-visited: [3, 6, 9] | positive-in-buffer: 15336 | amount-filled: 100.00%
	| epsilon: 0.2898637559695671
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1389, 2503, 1373, 1823, 1096, 2799, 1770, 2583]
	| approx positives in sample 512: 44
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 10, 4, 6, 3, 2, 3, 9]
episode: 271 -> reward: -124.99999999999181, steps:50880, time-elasped: 52244.93s
-> berries picked: 13 of 800 | patches-visited: [7] | positive-in-buffer: 14720 | amount-filled: 100.00%
	| epsilon: 0.2892811950154829
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1343, 2427, 1309, 1715, 1049, 2719, 1708, 2450]
	| approx positives in sample 512: 47
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 11, 6, 10, 2, 7, 6, 4]
episode: 272 -> reward: -124.99999999999177, steps:66144, time-elasped: 52540.52s
-> berries picked: 68 of 800 | patches-visited: [2] | positive-in-buffer: 14879 | amount-filled: 100.00%
	| epsilon: 0.28869980487788827
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1353, 2457, 1327, 1767, 1082, 2726, 1722, 2445]
	| approx positives in sample 512: 211
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 29, 21, 24, 23, 39, 14, 44]
episode: 273 -> reward: -124.9999999999921, steps:64032, time-elasped: 52825.03s
-> berries picked: 56 of 800 | patches-visited: [7] | positive-in-buffer: 15059 | amount-filled: 100.00%
	| epsilon: 0.28811958320370545
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1383, 2451, 1347, 1773, 1085, 2781, 1767, 2472]
	| approx positives in sample 512: 39
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 5, 5, 2, 6, 6, 1, 7]
episode: 274 -> reward: -124.99999999999297, steps:65952, time-elasped: 53155.86s
-> berries picked: 77 of 800 | patches-visited: [7] | positive-in-buffer: 15096 | amount-filled: 100.00%
	| epsilon: 0.2875405276445857
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1369, 2428, 1335, 1765, 1119, 2781, 1807, 2492]
	| approx positives in sample 512: 38
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 7, 5, 2, 4, 5, 5, 8]
episode: 275 -> reward: -124.999999999992, steps:66048, time-elasped: 53486.61s
-> berries picked: 68 of 800 | patches-visited: [4] | positive-in-buffer: 14414 | amount-filled: 100.00%
	| epsilon: 0.2869626358569002
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1314, 2344, 1279, 1669, 1076, 2649, 1712, 2371]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 31, 15, 38, 18, 31, 25, 47]
episode: 276 -> reward: -124.99999999999197, steps:67680, time-elasped: 53802.24s
-> berries picked: 76 of 800 | patches-visited: [6] | positive-in-buffer: 14677 | amount-filled: 100.00%
	| epsilon: 0.2863859055017299
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1330, 2403, 1286, 1741, 1092, 2697, 1720, 2408]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 14, 10, 19, 9, 24, 12, 24]
episode: 277 -> reward: -124.99999999999234, steps:59712, time-elasped: 53974.98s
-> berries picked: 44 of 800 | patches-visited: [0, 5, 9] | positive-in-buffer: 14723 | amount-filled: 100.00%
	| epsilon: 0.28581033424485686
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1325, 2405, 1271, 1736, 1090, 2720, 1716, 2460]
	| approx positives in sample 512: 77
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 16, 7, 13, 10, 11, 8, 8]
episode: 278 -> reward: -124.99999999999235, steps:67488, time-elasped: 54182.57s
-> berries picked: 69 of 800 | patches-visited: [3, 9] | positive-in-buffer: 14860 | amount-filled: 100.00%
	| epsilon: 0.28523591975675405
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1324, 2451, 1305, 1740, 1097, 2789, 1710, 2444]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 21, 13, 15, 10, 16, 17, 19]
episode: 279 -> reward: -124.99999999999467, steps:76320, time-elasped: 54427.37s
-> berries picked: 108 of 800 | patches-visited: [4, 7] | positive-in-buffer: 15191 | amount-filled: 100.00%
	| epsilon: 0.2846626597125765
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1386, 2515, 1337, 1737, 1090, 2876, 1746, 2504]
	| approx positives in sample 512: 46
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 11, 6, 11, 2, 1, 4, 6]
episode: 280 -> reward: -124.99999999999133, steps:64320, time-elasped: 54645.73s
-> berries picked: 56 of 800 | patches-visited: [2, 9] | positive-in-buffer: 14936 | amount-filled: 100.00%
	| epsilon: 0.2840905517921516
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1364, 2482, 1306, 1678, 1064, 2822, 1764, 2456]
	| approx positives in sample 512: 38
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 4, 4, 4, 2, 7, 2, 10]
episode: 281 -> reward: -124.99999999999193, steps:53472, time-elasped: 54825.41s
-> berries picked: 17 of 800 | patches-visited: [3] | positive-in-buffer: 14761 | amount-filled: 100.00%
	| epsilon: 0.28351959367996965
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1343, 2455, 1298, 1685, 1060, 2787, 1740, 2393]
	| approx positives in sample 512: 45
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 8, 5, 4, 6, 6, 3, 11]
episode: 282 -> reward: -124.99999999999304, steps:73728, time-elasped: 55071.54s
-> berries picked: 99 of 800 | patches-visited: [1, 4] | positive-in-buffer: 14957 | amount-filled: 100.00%
	| epsilon: 0.2829497830651748
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1358, 2446, 1328, 1734, 1087, 2829, 1753, 2422]
	| approx positives in sample 512: 50
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 7, 2, 8, 6, 7, 8, 6]
episode: 283 -> reward: -124.99999999999147, steps:63072, time-elasped: 55245.91s
-> berries picked: 62 of 800 | patches-visited: [4] | positive-in-buffer: 15103 | amount-filled: 100.00%
	| epsilon: 0.2823811176415553
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1352, 2465, 1357, 1768, 1117, 2862, 1755, 2427]
	| approx positives in sample 512: 40
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 7, 4, 3, 2, 8, 6, 6]
episode: 284 -> reward: -124.99999999998998, steps:72576, time-elasped: 55502.85s
-> berries picked: 92 of 800 | patches-visited: [0, 6] | positive-in-buffer: 15228 | amount-filled: 100.00%
	| epsilon: 0.28181359510753456
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1363, 2485, 1426, 1768, 1154, 2831, 1764, 2437]
	| approx positives in sample 512: 55
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 10, 4, 6, 4, 8, 5, 9]
episode: 285 -> reward: -124.99999999999233, steps:56352, time-elasped: 55686.80s
-> berries picked: 30 of 800 | patches-visited: [7] | positive-in-buffer: 15201 | amount-filled: 100.00%
	| epsilon: 0.28124721316616147
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1379, 2498, 1441, 1759, 1148, 2792, 1769, 2415]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 29, 12, 13, 7, 21, 16, 18]
episode: 286 -> reward: -124.99999999998609, steps:64512, time-elasped: 55915.63s
-> berries picked: 57 of 800 | patches-visited: [6] | positive-in-buffer: 15443 | amount-filled: 100.00%
	| epsilon: 0.2806819695251013
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1404, 2534, 1477, 1773, 1170, 2860, 1784, 2441]
	| approx positives in sample 512: 45
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 5, 5, 7, 5, 7, 4, 9]
episode: 287 -> reward: -124.99999999999082, steps:75456, time-elasped: 56148.96s
-> berries picked: 99 of 800 | patches-visited: [0, 5, 6] | positive-in-buffer: 15059 | amount-filled: 100.00%
	| epsilon: 0.2801178618966266
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1370, 2499, 1415, 1690, 1174, 2796, 1767, 2348]
	| approx positives in sample 512: 43
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 1, 3, 10, 2, 12, 6, 6]
episode: 288 -> reward: -124.99999999999207, steps:54240, time-elasped: 56290.44s
-> berries picked: 19 of 800 | patches-visited: [1] | positive-in-buffer: 14703 | amount-filled: 100.00%
	| epsilon: 0.2795548879976074
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1329, 2452, 1371, 1637, 1151, 2717, 1763, 2283]
	| approx positives in sample 512: 35
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 8, 3, 4, 1, 9, 1, 6]
episode: 289 -> reward: -124.99999999999147, steps:56736, time-elasped: 56472.05s
-> berries picked: 27 of 800 | patches-visited: [3] | positive-in-buffer: 14428 | amount-filled: 100.00%
	| epsilon: 0.27899304554950266
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1320, 2379, 1340, 1620, 1104, 2690, 1742, 2233]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 22, 15, 16, 10, 26, 21, 25]
episode: 290 -> reward: -124.99999999999206, steps:65760, time-elasped: 56689.02s
-> berries picked: 66 of 800 | patches-visited: [7] | positive-in-buffer: 14656 | amount-filled: 100.00%
	| epsilon: 0.2784323322783504
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1355, 2408, 1376, 1644, 1108, 2714, 1788, 2263]
	| approx positives in sample 512: 44
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 8, 5, 7, 3, 11, 5, 3]
episode: 291 -> reward: -124.99999999999187, steps:66912, time-elasped: 56890.39s
-> berries picked: 75 of 800 | patches-visited: [1] | positive-in-buffer: 14446 | amount-filled: 100.00%
	| epsilon: 0.2778727459147589
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1340, 2398, 1372, 1603, 1106, 2660, 1730, 2237]
	| approx positives in sample 512: 155
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 25, 15, 17, 16, 26, 14, 27]
episode: 292 -> reward: -124.99999999999211, steps:63552, time-elasped: 57095.62s
-> berries picked: 58 of 800 | patches-visited: [6] | positive-in-buffer: 14645 | amount-filled: 100.00%
	| epsilon: 0.2773142841938976
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1340, 2415, 1399, 1621, 1118, 2728, 1788, 2236]
	| approx positives in sample 512: 54
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 6, 7, 4, 3, 9, 7, 10]
episode: 293 -> reward: -124.99999999999208, steps:61344, time-elasped: 57262.18s
-> berries picked: 46 of 800 | patches-visited: [5] | positive-in-buffer: 14728 | amount-filled: 100.00%
	| epsilon: 0.2767569448554874
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1354, 2429, 1412, 1640, 1105, 2711, 1832, 2245]
	| approx positives in sample 512: 51
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 10, 3, 9, 2, 9, 8, 7]
episode: 294 -> reward: -124.99999999999214, steps:54912, time-elasped: 57407.55s
-> berries picked: 22 of 800 | patches-visited: [9] | positive-in-buffer: 14758 | amount-filled: 100.00%
	| epsilon: 0.27620072564379206
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1378, 2434, 1405, 1623, 1108, 2701, 1845, 2264]
	| approx positives in sample 512: 23
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 1, 6, 1, 1, 5, 2, 4]
episode: 295 -> reward: -124.99999999998153, steps:103584, time-elasped: 57757.09s
-> berries picked: 236 of 800 | patches-visited: [3, 6, 9] | positive-in-buffer: 15026 | amount-filled: 100.00%
	| epsilon: 0.27564562430760886
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1410, 2497, 1406, 1652, 1139, 2711, 1873, 2338]
	| approx positives in sample 512: 81
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 22, 8, 13, 8, 9, 8, 9]
episode: 296 -> reward: -124.99999999999213, steps:65952, time-elasped: 57902.67s
-> berries picked: 67 of 800 | patches-visited: [1] | positive-in-buffer: 15073 | amount-filled: 100.00%
	| epsilon: 0.27509163860025937
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1432, 2505, 1402, 1661, 1151, 2705, 1897, 2320]
	| approx positives in sample 512: 30
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 5, 4, 3, 3, 3, 7, 3]
episode: 297 -> reward: -124.99999999999203, steps:57120, time-elasped: 58043.71s
-> berries picked: 38 of 800 | patches-visited: [3] | positive-in-buffer: 14357 | amount-filled: 100.00%
	| epsilon: 0.2745387662795806
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1329, 2434, 1375, 1597, 1056, 2613, 1764, 2189]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 22, 16, 7, 5, 26, 10, 18]
episode: 298 -> reward: -124.99999999999154, steps:65568, time-elasped: 58245.53s
-> berries picked: 79 of 800 | patches-visited: [2] | positive-in-buffer: 14598 | amount-filled: 100.00%
	| epsilon: 0.2739870051079158
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1372, 2483, 1378, 1642, 1055, 2662, 1793, 2213]
	| approx positives in sample 512: 32
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 3, 2, 2, 1, 9, 4, 7]
episode: 299 -> reward: -124.9999999999829, steps:88704, time-elasped: 58495.69s
-> berries picked: 170 of 800 | patches-visited: [1, 2, 6] | positive-in-buffer: 14925 | amount-filled: 100.00%
	| epsilon: 0.2734363528521053
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1462, 2536, 1411, 1638, 1120, 2730, 1789, 2239]
	| approx positives in sample 512: 175
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 21, 30, 15, 13, 40, 20, 24]
episode: 300 -> reward: -124.99999999999203, steps:48384, time-elasped: 58592.67s
-> berries picked: 1 of 800 | patches-visited: [7] | positive-in-buffer: 14889 | amount-filled: 100.00%
	| epsilon: 0.2728868072834777
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1451, 2533, 1406, 1636, 1117, 2725, 1783, 2238]
	| approx positives in sample 512: 68
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 16, 11, 6, 9, 4, 2, 9]
episode: 301 -> reward: -124.99999999999189, steps:66816, time-elasped: 58772.05s
-> berries picked: 79 of 800 | patches-visited: [7] | positive-in-buffer: 14966 | amount-filled: 100.00%
	| epsilon: 0.2723383661778407
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1430, 2571, 1427, 1660, 1139, 2723, 1791, 2225]
	| approx positives in sample 512: 172
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 29, 16, 23, 10, 39, 21, 21]
episode: 302 -> reward: -124.99999999999214, steps:68256, time-elasped: 58920.65s
-> berries picked: 78 of 800 | patches-visited: [4] | positive-in-buffer: 15132 | amount-filled: 100.00%
	| epsilon: 0.271791027315472
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1456, 2549, 1477, 1691, 1156, 2752, 1799, 2252]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 17, 11, 16, 5, 28, 10, 21]
episode: 303 -> reward: -124.9999999999886, steps:70848, time-elasped: 59098.30s
-> berries picked: 83 of 800 | patches-visited: [2, 9] | positive-in-buffer: 15440 | amount-filled: 100.00%
	| epsilon: 0.2712447884811106
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1463, 2624, 1495, 1772, 1162, 2825, 1843, 2256]
	| approx positives in sample 512: 57
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 5, 3, 13, 9, 9, 6, 8]
episode: 304 -> reward: -124.99999999999204, steps:52224, time-elasped: 59214.46s
-> berries picked: 13 of 800 | patches-visited: [9] | positive-in-buffer: 15318 | amount-filled: 100.00%
	| epsilon: 0.27069964746394765
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1449, 2572, 1476, 1749, 1159, 2823, 1845, 2245]
	| approx positives in sample 512: 39
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 7, 1, 3, 4, 9, 2, 9]
episode: 305 -> reward: -124.99999999998707, steps:72384, time-elasped: 59433.16s
-> berries picked: 86 of 800 | patches-visited: [7, 9] | positive-in-buffer: 15195 | amount-filled: 100.00%
	| epsilon: 0.2701556020576175
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1465, 2472, 1512, 1727, 1195, 2746, 1874, 2204]
	| approx positives in sample 512: 60
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 3, 5, 11, 7, 11, 6, 11]
episode: 306 -> reward: -124.99999999999261, steps:56832, time-elasped: 59581.09s
-> berries picked: 33 of 800 | patches-visited: [2] | positive-in-buffer: 15173 | amount-filled: 100.00%
	| epsilon: 0.2696126500601887
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1474, 2472, 1490, 1737, 1224, 2735, 1852, 2189]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 19, 18, 16, 10, 21, 19, 16]
episode: 307 -> reward: -124.99999999999208, steps:57504, time-elasped: 59748.53s
-> berries picked: 31 of 800 | patches-visited: [5] | positive-in-buffer: 15245 | amount-filled: 100.00%
	| epsilon: 0.26907078927415545
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1486, 2496, 1495, 1734, 1219, 2740, 1848, 2227]
	| approx positives in sample 512: 90
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 13, 11, 13, 7, 17, 11, 12]
episode: 308 -> reward: -124.99999999999196, steps:56448, time-elasped: 59899.09s
-> berries picked: 30 of 800 | patches-visited: [3, 7] | positive-in-buffer: 15327 | amount-filled: 100.00%
	| epsilon: 0.2685300175064281
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1501, 2513, 1490, 1747, 1215, 2771, 1861, 2229]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 15, 15, 13, 11, 24, 16, 22]
episode: 309 -> reward: -124.99999999999253, steps:60288, time-elasped: 60044.09s
-> berries picked: 46 of 800 | patches-visited: [7, 8] | positive-in-buffer: 15433 | amount-filled: 100.00%
	| epsilon: 0.26799033256832494
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1497, 2555, 1498, 1751, 1224, 2774, 1879, 2255]
	| approx positives in sample 512: 70
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 10, 9, 9, 2, 14, 8, 14]
episode: 310 -> reward: -124.99999999998282, steps:90432, time-elasped: 60268.17s
-> berries picked: 155 of 800 | patches-visited: [0, 2, 7] | positive-in-buffer: 15774 | amount-filled: 100.00%
	| epsilon: 0.2674517322755628
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1536, 2632, 1620, 1784, 1243, 2828, 1894, 2237]
	| approx positives in sample 512: 93
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 15, 19, 12, 9, 14, 3, 16]
episode: 311 -> reward: -124.9999999999905, steps:62304, time-elasped: 61050.33s
-> berries picked: 55 of 800 | patches-visited: [0, 9] | positive-in-buffer: 15807 | amount-filled: 100.00%
	| epsilon: 0.2669142144482485
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1545, 2625, 1641, 1791, 1256, 2832, 1888, 2229]
	| approx positives in sample 512: 62
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 9, 7, 6, 9, 10, 8, 4]
episode: 312 -> reward: -124.9999999999835, steps:115296, time-elasped: 61297.24s
-> berries picked: 265 of 800 | patches-visited: [0, 2, 6, 8] | positive-in-buffer: 15882 | amount-filled: 100.00%
	| epsilon: 0.26637777691086995
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1490, 2613, 1782, 1744, 1299, 2830, 1950, 2174]
	| approx positives in sample 512: 78
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 13, 10, 11, 6, 12, 7, 11]
episode: 313 -> reward: -124.99999999998683, steps:73248, time-elasped: 61484.45s
-> berries picked: 93 of 800 | patches-visited: [2, 3] | positive-in-buffer: 16051 | amount-filled: 100.00%
	| epsilon: 0.2658424174922874
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1502, 2712, 1752, 1809, 1276, 2872, 1975, 2153]
	| approx positives in sample 512: 46
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 8, 3, 9, 2, 10, 4, 7]
episode: 314 -> reward: -124.99999999998231, steps:82752, time-elasped: 61729.88s
-> berries picked: 136 of 800 | patches-visited: [2, 8, 9] | positive-in-buffer: 15862 | amount-filled: 100.00%
	| epsilon: 0.2653081340257245
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1514, 2656, 1698, 1803, 1238, 2881, 1966, 2106]
	| approx positives in sample 512: 65
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 9, 9, 10, 5, 15, 4, 11]
episode: 315 -> reward: -124.99999999999194, steps:65472, time-elasped: 61956.60s
-> berries picked: 72 of 800 | patches-visited: [1] | positive-in-buffer: 15820 | amount-filled: 100.00%
	| epsilon: 0.26477492434875977
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1503, 2670, 1716, 1798, 1270, 2840, 1930, 2093]
	| approx positives in sample 512: 44
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 12, 5, 3, 5, 8, 4, 5]
episode: 316 -> reward: -116.99999999999005, steps:120000, time-elasped: 62414.86s
-> berries picked: 293 of 800 | patches-visited: [0, 1, 2, 6, 8] | positive-in-buffer: 15784 | amount-filled: 100.00%
	| epsilon: 0.2642427863033175
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1412, 2732, 1776, 1814, 1265, 2869, 1847, 2069]
	| approx positives in sample 512: 54
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 11, 7, 3, 5, 10, 8, 5]
episode: 317 -> reward: -124.9999999999908, steps:62496, time-elasped: 62658.71s
-> berries picked: 53 of 800 | patches-visited: [9] | positive-in-buffer: 15189 | amount-filled: 100.00%
	| epsilon: 0.2637117177356595
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1351, 2673, 1656, 1721, 1251, 2756, 1787, 1994]
	| approx positives in sample 512: 57
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 13, 5, 5, 4, 11, 9, 4]
episode: 318 -> reward: -124.99999999998583, steps:84192, time-elasped: 62997.40s
-> berries picked: 146 of 800 | patches-visited: [0, 2] | positive-in-buffer: 15501 | amount-filled: 100.00%
	| epsilon: 0.2631817164963759
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1400, 2703, 1743, 1700, 1285, 2774, 1844, 2052]
	| approx positives in sample 512: 64
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 14, 13, 10, 2, 9, 5, 9]
episode: 319 -> reward: -124.99999999999194, steps:64800, time-elasped: 63231.70s
-> berries picked: 67 of 800 | patches-visited: [5] | positive-in-buffer: 15358 | amount-filled: 100.00%
	| epsilon: 0.26265278044037677
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1383, 2687, 1728, 1678, 1299, 2755, 1815, 2013]
	| approx positives in sample 512: 53
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 2, 8, 10, 5, 10, 5, 12]
episode: 320 -> reward: -124.9999999999905, steps:82944, time-elasped: 63579.21s
-> berries picked: 128 of 800 | patches-visited: [0, 4] | positive-in-buffer: 15195 | amount-filled: 100.00%
	| epsilon: 0.2621249074268832
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1338, 2589, 1703, 1678, 1412, 2742, 1768, 1965]
	| approx positives in sample 512: 64
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 11, 4, 12, 5, 13, 5, 10]
episode: 321 -> reward: -124.99999999999149, steps:70656, time-elasped: 63869.20s
-> berries picked: 90 of 800 | patches-visited: [3, 7] | positive-in-buffer: 15366 | amount-filled: 100.00%
	| epsilon: 0.2615980953194189
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1343, 2598, 1756, 1701, 1432, 2775, 1806, 1955]
	| approx positives in sample 512: 76
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 20, 13, 9, 3, 15, 10, 5]
episode: 322 -> reward: -124.9999999999921, steps:56928, time-elasped: 64060.43s
-> berries picked: 31 of 800 | patches-visited: [1] | positive-in-buffer: 15415 | amount-filled: 100.00%
	| epsilon: 0.2610723419858014
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1350, 2607, 1775, 1701, 1450, 2760, 1810, 1962]
	| approx positives in sample 512: 145
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 29, 15, 17, 13, 27, 19, 13]
episode: 323 -> reward: -124.9999999999921, steps:66048, time-elasped: 64289.44s
-> berries picked: 80 of 800 | patches-visited: [9] | positive-in-buffer: 15617 | amount-filled: 100.00%
	| epsilon: 0.2605476452981334
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1387, 2631, 1820, 1746, 1466, 2770, 1828, 1969]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 47, 22, 22, 14, 41, 33, 32]
episode: 324 -> reward: -124.99999999998548, steps:75168, time-elasped: 64569.84s
-> berries picked: 99 of 800 | patches-visited: [0, 7] | positive-in-buffer: 15911 | amount-filled: 100.00%
	| epsilon: 0.2600240031327941
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1444, 2634, 1885, 1781, 1497, 2825, 1841, 2004]
	| approx positives in sample 512: 47
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 7, 2, 3, 3, 10, 10, 6]
episode: 325 -> reward: -124.99999999999211, steps:56352, time-elasped: 64786.75s
-> berries picked: 28 of 800 | patches-visited: [1] | positive-in-buffer: 15325 | amount-filled: 100.00%
	| epsilon: 0.259501413370431
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1381, 2552, 1792, 1679, 1440, 2735, 1824, 1922]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 23, 17, 8, 12, 22, 19, 15]
episode: 326 -> reward: -124.99999999999193, steps:62016, time-elasped: 65008.07s
-> berries picked: 49 of 800 | patches-visited: [3] | positive-in-buffer: 15473 | amount-filled: 100.00%
	| epsilon: 0.25897987389595056
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1391, 2585, 1791, 1689, 1463, 2799, 1822, 1933]
	| approx positives in sample 512: 59
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 10, 6, 9, 5, 13, 7, 6]
episode: 327 -> reward: -124.99999999997965, steps:90432, time-elasped: 65353.47s
-> berries picked: 160 of 800 | patches-visited: [5, 7, 8] | positive-in-buffer: 15927 | amount-filled: 100.00%
	| epsilon: 0.2584593825985106
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1416, 2749, 1839, 1761, 1528, 2852, 1828, 1954]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 24, 13, 15, 13, 12, 15, 10]
episode: 328 -> reward: -124.99999999998734, steps:64800, time-elasped: 65615.49s
-> berries picked: 57 of 800 | patches-visited: [1, 6] | positive-in-buffer: 16000 | amount-filled: 100.00%
	| epsilon: 0.25793993737151083
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1410, 2748, 1847, 1780, 1535, 2848, 1867, 1965]
	| approx positives in sample 512: 46
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 5, 4, 6, 3, 9, 7, 8]
episode: 329 -> reward: -124.99999999999204, steps:51072, time-elasped: 65772.44s
-> berries picked: 9 of 800 | patches-visited: [6] | positive-in-buffer: 15113 | amount-filled: 100.00%
	| epsilon: 0.2574215361125851
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1368, 2576, 1718, 1733, 1445, 2695, 1733, 1845]
	| approx positives in sample 512: 50
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 8, 2, 9, 4, 9, 9, 6]
episode: 330 -> reward: -124.99999999999164, steps:67104, time-elasped: 65999.04s
-> berries picked: 69 of 800 | patches-visited: [9] | positive-in-buffer: 15324 | amount-filled: 100.00%
	| epsilon: 0.25690417672359234
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1405, 2584, 1756, 1725, 1473, 2746, 1762, 1873]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 22, 18, 19, 13, 30, 17, 15]
episode: 331 -> reward: -119.74999999999542, steps:120000, time-elasped: 66501.29s
-> berries picked: 271 of 800 | patches-visited: [1, 4, 7, 8] | positive-in-buffer: 16144 | amount-filled: 100.00%
	| epsilon: 0.2563878571106083
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1497, 2748, 1816, 1895, 1532, 2873, 1789, 1994]
	| approx positives in sample 512: 43
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 6, 7, 4, 5, 8, 9, 1]
episode: 332 -> reward: -124.99999999999196, steps:57120, time-elasped: 66680.13s
-> berries picked: 32 of 800 | patches-visited: [7] | positive-in-buffer: 15220 | amount-filled: 100.00%
	| epsilon: 0.25587257518391704
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1453, 2599, 1664, 1761, 1446, 2729, 1711, 1857]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 21, 12, 20, 13, 23, 14, 16]
episode: 333 -> reward: -124.99999999999187, steps:68448, time-elasped: 66938.47s
-> berries picked: 81 of 800 | patches-visited: [1, 8] | positive-in-buffer: 15495 | amount-filled: 100.00%
	| epsilon: 0.2553583288580025
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1463, 2633, 1738, 1782, 1485, 2790, 1727, 1877]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 23, 13, 16, 15, 19, 9, 17]
episode: 334 -> reward: -124.99999999999189, steps:65568, time-elasped: 67119.55s
-> berries picked: 79 of 800 | patches-visited: [2] | positive-in-buffer: 15602 | amount-filled: 100.00%
	| epsilon: 0.25484511605154014
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1460, 2661, 1742, 1772, 1532, 2823, 1726, 1886]
	| approx positives in sample 512: 45
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 3, 3, 6, 7, 9, 7, 5]
episode: 335 -> reward: -124.9999999999894, steps:63552, time-elasped: 67297.82s
-> berries picked: 56 of 800 | patches-visited: [3] | positive-in-buffer: 15091 | amount-filled: 100.00%
	| epsilon: 0.25433293468738827
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1406, 2569, 1685, 1694, 1494, 2718, 1663, 1862]
	| approx positives in sample 512: 51
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 8, 8, 6, 6, 10, 2, 6]
episode: 336 -> reward: -124.9999999999919, steps:61152, time-elasped: 67442.29s
-> berries picked: 49 of 800 | patches-visited: [4] | positive-in-buffer: 15165 | amount-filled: 100.00%
	| epsilon: 0.2538217826925798
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1403, 2587, 1662, 1692, 1494, 2765, 1667, 1895]
	| approx positives in sample 512: 57
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7] [18, 2, 6, 2, 17, 6, 6]
episode: 337 -> reward: -124.9999999999941, steps:81888, time-elasped: 67719.06s
-> berries picked: 126 of 800 | patches-visited: [4, 5] | positive-in-buffer: 15497 | amount-filled: 100.00%
	| epsilon: 0.2533116579983139
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1442, 2605, 1713, 1715, 1559, 2845, 1689, 1929]
	| approx positives in sample 512: 81
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 15, 5, 6, 7, 16, 10, 14]
episode: 338 -> reward: -124.99999999998539, steps:87072, time-elasped: 68125.84s
-> berries picked: 153 of 800 | patches-visited: [0, 6] | positive-in-buffer: 15835 | amount-filled: 100.00%
	| epsilon: 0.25280255853994754
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1489, 2667, 1728, 1743, 1656, 2869, 1764, 1919]
	| approx positives in sample 512: 52
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 8, 4, 9, 9, 8, 3, 6]
episode: 339 -> reward: -124.99999999999437, steps:76512, time-elasped: 68322.64s
-> berries picked: 118 of 800 | patches-visited: [0, 3] | positive-in-buffer: 15327 | amount-filled: 100.00%
	| epsilon: 0.25229448225698714
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1438, 2568, 1711, 1650, 1611, 2832, 1724, 1793]
	| approx positives in sample 512: 35
	| approx action-dist in sample 512: [0, 1, 3, 4, 5, 6, 7] [3, 3, 5, 6, 10, 2, 6]
episode: 340 -> reward: -124.99999999998737, steps:82272, time-elasped: 68563.72s
-> berries picked: 133 of 800 | patches-visited: [0, 2] | positive-in-buffer: 15296 | amount-filled: 100.00%
	| epsilon: 0.2517874270930802
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1403, 2528, 1734, 1656, 1573, 2864, 1707, 1831]
	| approx positives in sample 512: 71
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 10, 6, 6, 8, 11, 15, 7]
episode: 341 -> reward: -124.99999999999199, steps:60096, time-elasped: 68753.26s
-> berries picked: 41 of 800 | patches-visited: [6] | positive-in-buffer: 15298 | amount-filled: 100.00%
	| epsilon: 0.25128139099600727
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1393, 2554, 1696, 1668, 1575, 2879, 1695, 1838]
	| approx positives in sample 512: 75
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 15, 9, 5, 3, 15, 6, 16]
episode: 342 -> reward: -124.99999999997871, steps:95424, time-elasped: 69013.68s
-> berries picked: 189 of 800 | patches-visited: [5, 6, 8] | positive-in-buffer: 15751 | amount-filled: 100.00%
	| epsilon: 0.2507763719176731
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1422, 2672, 1805, 1695, 1628, 2932, 1711, 1886]
	| approx positives in sample 512: 50
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 8, 1, 5, 7, 8, 6, 13]
episode: 343 -> reward: -124.99999999999187, steps:56928, time-elasped: 69166.60s
-> berries picked: 32 of 800 | patches-visited: [8] | positive-in-buffer: 15405 | amount-filled: 100.00%
	| epsilon: 0.25027236781409873
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1401, 2609, 1731, 1653, 1581, 2870, 1704, 1856]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 27, 14, 18, 13, 16, 15, 12]
episode: 344 -> reward: -124.99999999998684, steps:93120, time-elasped: 69432.32s
-> berries picked: 169 of 800 | patches-visited: [3, 4, 9] | positive-in-buffer: 15980 | amount-filled: 100.00%
	| epsilon: 0.24976937664541327
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1431, 2701, 1847, 1725, 1636, 2947, 1753, 1940]
	| approx positives in sample 512: 72
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 13, 9, 9, 7, 17, 7, 8]
episode: 345 -> reward: -124.99999999999194, steps:66144, time-elasped: 69657.39s
-> berries picked: 74 of 800 | patches-visited: [3] | positive-in-buffer: 15868 | amount-filled: 100.00%
	| epsilon: 0.24926739637584536
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1430, 2693, 1805, 1713, 1617, 2926, 1743, 1941]
	| approx positives in sample 512: 223
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 36, 26, 25, 31, 35, 23, 35]
episode: 346 -> reward: -124.99999999999207, steps:67104, time-elasped: 69834.15s
-> berries picked: 79 of 800 | patches-visited: [4] | positive-in-buffer: 15951 | amount-filled: 100.00%
	| epsilon: 0.24876642497371518
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1420, 2755, 1810, 1715, 1615, 2949, 1739, 1948]
	| approx positives in sample 512: 153
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 30, 14, 18, 21, 28, 14, 17]
episode: 347 -> reward: -124.99999999999203, steps:49440, time-elasped: 69962.69s
-> berries picked: 4 of 800 | patches-visited: [5] | positive-in-buffer: 15923 | amount-filled: 100.00%
	| epsilon: 0.24826646041142605
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1420, 2747, 1800, 1723, 1609, 2947, 1732, 1945]
	| approx positives in sample 512: 66
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 12, 11, 11, 4, 14, 5, 5]
episode: 348 -> reward: -124.99999999999066, steps:84768, time-elasped: 70196.78s
-> berries picked: 137 of 800 | patches-visited: [3, 4] | positive-in-buffer: 16162 | amount-filled: 100.00%
	| epsilon: 0.24776750066545639
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1423, 2738, 1823, 1736, 1683, 3053, 1730, 1976]
	| approx positives in sample 512: 61
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 6, 10, 7, 4, 12, 9, 10]
episode: 349 -> reward: -124.99999999998862, steps:76224, time-elasped: 70416.11s
-> berries picked: 107 of 800 | patches-visited: [5, 7] | positive-in-buffer: 15848 | amount-filled: 100.00%
	| epsilon: 0.24726954371635138
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1430, 2657, 1741, 1698, 1642, 3020, 1743, 1917]
	| approx positives in sample 512: 36
	| approx action-dist in sample 512: [0, 2, 3, 4, 5, 6, 7] [4, 5, 8, 4, 9, 3, 3]
episode: 350 -> reward: -124.99999999999199, steps:56640, time-elasped: 70554.53s
-> berries picked: 27 of 800 | patches-visited: [9] | positive-in-buffer: 14959 | amount-filled: 100.00%
	| epsilon: 0.24677258754871484
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1356, 2492, 1662, 1619, 1535, 2836, 1697, 1762]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 18, 23, 10, 13, 17, 19, 19]
episode: 351 -> reward: -124.99999999999015, steps:86400, time-elasped: 70781.12s
-> berries picked: 150 of 800 | patches-visited: [0, 7] | positive-in-buffer: 15449 | amount-filled: 100.00%
	| epsilon: 0.2462766301512012
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1372, 2592, 1787, 1653, 1576, 2913, 1740, 1816]
	| approx positives in sample 512: 46
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 9, 3, 3, 5, 12, 5, 7]
episode: 352 -> reward: -124.99999999999162, steps:68640, time-elasped: 70952.29s
-> berries picked: 78 of 800 | patches-visited: [6, 8] | positive-in-buffer: 15427 | amount-filled: 100.00%
	| epsilon: 0.24578166951650704
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1376, 2536, 1823, 1667, 1577, 2925, 1750, 1773]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 19, 8, 11, 11, 16, 9, 11]
episode: 353 -> reward: -124.9999999999917, steps:52992, time-elasped: 71152.74s
-> berries picked: 18 of 800 | patches-visited: [6] | positive-in-buffer: 15482 | amount-filled: 100.00%
	| epsilon: 0.24528770364136335
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1381, 2548, 1813, 1695, 1604, 2916, 1752, 1773]
	| approx positives in sample 512: 57
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 6, 6, 5, 5, 14, 8, 7]
episode: 354 -> reward: -124.99999999999191, steps:65664, time-elasped: 71338.53s
-> berries picked: 69 of 800 | patches-visited: [8] | positive-in-buffer: 15378 | amount-filled: 100.00%
	| epsilon: 0.24479473052652714
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1373, 2561, 1775, 1701, 1559, 2880, 1741, 1788]
	| approx positives in sample 512: 32
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 7, 6, 2, 1, 6, 5, 3]
episode: 355 -> reward: -124.99999999999375, steps:76416, time-elasped: 71600.14s
-> berries picked: 111 of 800 | patches-visited: [1, 6] | positive-in-buffer: 15062 | amount-filled: 100.00%
	| epsilon: 0.2443027481767735
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1350, 2548, 1770, 1688, 1494, 2790, 1724, 1698]
	| approx positives in sample 512: 38
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 9, 4, 4, 4, 6, 4, 4]
episode: 356 -> reward: -124.99999999999207, steps:67296, time-elasped: 71825.17s
-> berries picked: 77 of 800 | patches-visited: [7] | positive-in-buffer: 14980 | amount-filled: 100.00%
	| epsilon: 0.2438117546008875
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1316, 2499, 1770, 1671, 1504, 2791, 1722, 1707]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 13, 16, 20, 12, 31, 15, 17]
episode: 357 -> reward: -124.99999999999163, steps:59616, time-elasped: 72035.78s
-> berries picked: 44 of 800 | patches-visited: [7] | positive-in-buffer: 15047 | amount-filled: 100.00%
	| epsilon: 0.24332174781165597
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1335, 2481, 1785, 1663, 1519, 2814, 1705, 1745]
	| approx positives in sample 512: 80
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 11, 11, 14, 9, 8, 12, 5]
episode: 358 -> reward: -124.99999999999255, steps:57888, time-elasped: 72260.44s
-> berries picked: 40 of 800 | patches-visited: [3] | positive-in-buffer: 15148 | amount-filled: 100.00%
	| epsilon: 0.24283272582585974
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1340, 2489, 1813, 1659, 1522, 2816, 1743, 1766]
	| approx positives in sample 512: 96
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 13, 8, 14, 6, 20, 8, 21]
episode: 359 -> reward: -124.99999999998937, steps:90816, time-elasped: 72606.64s
-> berries picked: 154 of 800 | patches-visited: [2, 8, 9] | positive-in-buffer: 15702 | amount-filled: 100.00%
	| epsilon: 0.24234468666426537
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1471, 2625, 1856, 1744, 1560, 2898, 1771, 1777]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 15, 14, 8, 7, 23, 11, 13]
episode: 360 -> reward: -124.99999999999223, steps:58080, time-elasped: 72812.74s
-> berries picked: 33 of 800 | patches-visited: [0] | positive-in-buffer: 15707 | amount-filled: 100.00%
	| epsilon: 0.24185762835161728
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1473, 2598, 1849, 1745, 1560, 2932, 1766, 1784]
	| approx positives in sample 512: 92
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 15, 9, 14, 9, 17, 14, 11]
episode: 361 -> reward: -124.99999999998909, steps:97152, time-elasped: 73141.24s
-> berries picked: 179 of 800 | patches-visited: [1, 4, 5, 7] | positive-in-buffer: 16147 | amount-filled: 100.00%
	| epsilon: 0.24137154891662974
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1495, 2690, 1972, 1796, 1584, 2960, 1820, 1830]
	| approx positives in sample 512: 58
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 12, 6, 4, 7, 8, 7, 9]
episode: 362 -> reward: -124.99999999999115, steps:86400, time-elasped: 73421.08s
-> berries picked: 154 of 800 | patches-visited: [6, 7] | positive-in-buffer: 15831 | amount-filled: 100.00%
	| epsilon: 0.24088644639197876
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1369, 2620, 1920, 1793, 1591, 2941, 1784, 1813]
	| approx positives in sample 512: 46
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 7, 7, 10, 3, 6, 4, 7]
episode: 363 -> reward: -124.99999999998381, steps:98304, time-elasped: 73727.01s
-> berries picked: 189 of 800 | patches-visited: [1, 3, 9] | positive-in-buffer: 16084 | amount-filled: 100.00%
	| epsilon: 0.24040231881429427
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1362, 2672, 1997, 1808, 1706, 2914, 1776, 1849]
	| approx positives in sample 512: 53
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 5, 2, 9, 6, 8, 9, 5]
episode: 364 -> reward: -124.99999999999159, steps:64896, time-elasped: 73909.50s
-> berries picked: 69 of 800 | patches-visited: [6] | positive-in-buffer: 15254 | amount-filled: 100.00%
	| epsilon: 0.23991916422415224
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1323, 2521, 1922, 1726, 1604, 2811, 1671, 1676]
	| approx positives in sample 512: 41
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 5, 8, 4, 5, 4, 3, 10]
episode: 365 -> reward: -124.99999999999069, steps:104928, time-elasped: 74246.16s
-> berries picked: 218 of 800 | patches-visited: [3, 4, 6] | positive-in-buffer: 15710 | amount-filled: 100.00%
	| epsilon: 0.23943698066606647
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1291, 2615, 1995, 1745, 1792, 2890, 1679, 1703]
	| approx positives in sample 512: 63
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 11, 5, 10, 3, 15, 8, 8]
episode: 366 -> reward: -124.99999999999208, steps:59328, time-elasped: 74434.53s
-> berries picked: 45 of 800 | patches-visited: [3] | positive-in-buffer: 15686 | amount-filled: 100.00%
	| epsilon: 0.238955766188481
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1291, 2602, 1961, 1755, 1795, 2892, 1701, 1689]
	| approx positives in sample 512: 82
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 13, 7, 14, 5, 16, 8, 14]
episode: 367 -> reward: -124.99999999997684, steps:101856, time-elasped: 74789.88s
-> berries picked: 228 of 800 | patches-visited: [1, 2, 3] | positive-in-buffer: 16329 | amount-filled: 100.00%
	| epsilon: 0.23847551884376192
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1370, 2694, 2016, 1902, 1861, 3050, 1719, 1717]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 17, 12, 16, 11, 29, 10, 11]
episode: 368 -> reward: -124.99999999999547, steps:81888, time-elasped: 75032.29s
-> berries picked: 141 of 800 | patches-visited: [0, 6] | positive-in-buffer: 16446 | amount-filled: 100.00%
	| epsilon: 0.23799623668818973
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1348, 2726, 2024, 1929, 1888, 3073, 1709, 1749]
	| approx positives in sample 512: 66
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 11, 11, 6, 5, 16, 2, 10]
episode: 369 -> reward: -124.99999999999187, steps:64416, time-elasped: 75227.92s
-> berries picked: 64 of 800 | patches-visited: [4] | positive-in-buffer: 16328 | amount-filled: 100.00%
	| epsilon: 0.23751791778195133
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1331, 2746, 2028, 1904, 1816, 3060, 1696, 1747]
	| approx positives in sample 512: 40
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 4, 5, 6, 6, 8, 5, 3]
episode: 370 -> reward: -124.99999999998538, steps:83904, time-elasped: 75495.12s
-> berries picked: 142 of 800 | patches-visited: [5, 6] | positive-in-buffer: 15778 | amount-filled: 100.00%
	| epsilon: 0.23704056018913217
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1349, 2629, 1932, 1814, 1707, 3008, 1694, 1645]
	| approx positives in sample 512: 53
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 7, 6, 8, 6, 14, 5, 4]
episode: 371 -> reward: -124.99999999999183, steps:64032, time-elasped: 75703.34s
-> berries picked: 67 of 800 | patches-visited: [5] | positive-in-buffer: 15807 | amount-filled: 100.00%
	| epsilon: 0.23656416197770855
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1344, 2642, 1983, 1805, 1706, 2966, 1712, 1649]
	| approx positives in sample 512: 49
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 8, 7, 7, 3, 8, 7, 6]
episode: 372 -> reward: -124.99999999999129, steps:66816, time-elasped: 75913.58s
-> berries picked: 80 of 800 | patches-visited: [9] | positive-in-buffer: 15383 | amount-filled: 100.00%
	| epsilon: 0.2360887212195396
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1293, 2590, 1923, 1768, 1646, 2888, 1669, 1606]
	| approx positives in sample 512: 160
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 27, 24, 18, 21, 28, 18, 10]
episode: 373 -> reward: -124.99999999999245, steps:65952, time-elasped: 76122.72s
-> berries picked: 71 of 800 | patches-visited: [7] | positive-in-buffer: 15527 | amount-filled: 100.00%
	| epsilon: 0.2356142359903597
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1305, 2623, 1945, 1824, 1657, 2902, 1671, 1600]
	| approx positives in sample 512: 38
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 9, 2, 4, 1, 6, 8, 7]
episode: 374 -> reward: -124.99999999999169, steps:65088, time-elasped: 76348.99s
-> berries picked: 71 of 800 | patches-visited: [8] | positive-in-buffer: 15056 | amount-filled: 100.00%
	| epsilon: 0.23514070436977044
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1284, 2564, 1883, 1793, 1596, 2776, 1618, 1542]
	| approx positives in sample 512: 39
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 4, 6, 7, 6, 4, 3, 6]
episode: 375 -> reward: -124.99999999999214, steps:66048, time-elasped: 76539.74s
-> berries picked: 77 of 800 | patches-visited: [5] | positive-in-buffer: 15196 | amount-filled: 100.00%
	| epsilon: 0.234668124441233
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1273, 2581, 1881, 1812, 1625, 2842, 1630, 1552]
	| approx positives in sample 512: 237
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 34, 26, 26, 19, 50, 25, 33]
episode: 376 -> reward: -124.9999999999859, steps:66528, time-elasped: 76765.94s
-> berries picked: 74 of 800 | patches-visited: [7] | positive-in-buffer: 15397 | amount-filled: 100.00%
	| epsilon: 0.2341964942920605
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1306, 2619, 1881, 1862, 1656, 2876, 1648, 1549]
	| approx positives in sample 512: 174
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 31, 12, 28, 16, 33, 18, 19]
episode: 377 -> reward: -124.99999999999034, steps:78528, time-elasped: 77035.15s
-> berries picked: 119 of 800 | patches-visited: [1, 3] | positive-in-buffer: 15724 | amount-filled: 100.00%
	| epsilon: 0.23372581201340994
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1312, 2657, 2040, 1848, 1699, 2909, 1664, 1595]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 18, 18, 9, 15, 31, 11, 19]
episode: 378 -> reward: -124.999999999992, steps:60384, time-elasped: 77201.60s
-> berries picked: 41 of 800 | patches-visited: [1] | positive-in-buffer: 15833 | amount-filled: 100.00%
	| epsilon: 0.23325607570027485
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1310, 2708, 2046, 1877, 1699, 2903, 1698, 1592]
	| approx positives in sample 512: 75
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 20, 8, 8, 4, 17, 10, 5]
episode: 379 -> reward: -124.9999999999917, steps:67968, time-elasped: 77425.17s
-> berries picked: 80 of 800 | patches-visited: [1] | positive-in-buffer: 15956 | amount-filled: 100.00%
	| epsilon: 0.23278728345147726
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1304, 2690, 2037, 1932, 1727, 2910, 1708, 1648]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 25, 19, 17, 15, 28, 12, 12]
episode: 380 -> reward: -124.99999999999118, steps:67104, time-elasped: 77644.25s
-> berries picked: 78 of 800 | patches-visited: [0] | positive-in-buffer: 16088 | amount-filled: 100.00%
	| epsilon: 0.23231943336966018
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1307, 2709, 2022, 1989, 1755, 2947, 1720, 1639]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 22, 13, 21, 20, 22, 11, 11]
episode: 381 -> reward: -124.99999999999137, steps:65376, time-elasped: 77846.94s
-> berries picked: 73 of 800 | patches-visited: [3] | positive-in-buffer: 16127 | amount-filled: 100.00%
	| epsilon: 0.23185252356127994
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1306, 2702, 2018, 1998, 1779, 2935, 1759, 1630]
	| approx positives in sample 512: 49
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 8, 6, 8, 10, 8, 2, 4]
episode: 382 -> reward: -124.99999999999245, steps:68640, time-elasped: 78043.63s
-> berries picked: 80 of 800 | patches-visited: [8] | positive-in-buffer: 15429 | amount-filled: 100.00%
	| epsilon: 0.23138655213659837
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1226, 2564, 1941, 1902, 1672, 2850, 1700, 1574]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 18, 10, 12, 9, 23, 17, 9]
episode: 383 -> reward: -124.9999999999919, steps:53568, time-elasped: 78225.05s
-> berries picked: 18 of 800 | patches-visited: [6] | positive-in-buffer: 15462 | amount-filled: 100.00%
	| epsilon: 0.23092151720967533
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1231, 2595, 1935, 1900, 1677, 2843, 1698, 1583]
	| approx positives in sample 512: 40
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 9, 5, 3, 2, 8, 3, 5]
episode: 384 -> reward: -124.9999999999922, steps:57888, time-elasped: 78384.02s
-> berries picked: 34 of 800 | patches-visited: [0, 1] | positive-in-buffer: 15243 | amount-filled: 100.00%
	| epsilon: 0.2304574168983609
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1207, 2572, 1899, 1873, 1628, 2790, 1678, 1596]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 16, 13, 11, 8, 31, 12, 11]
episode: 385 -> reward: -124.9999999999921, steps:64896, time-elasped: 78593.61s
-> berries picked: 73 of 800 | patches-visited: [3] | positive-in-buffer: 15432 | amount-filled: 100.00%
	| epsilon: 0.229994249324288
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1221, 2613, 1926, 1911, 1669, 2807, 1679, 1606]
	| approx positives in sample 512: 46
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 6, 7, 3, 6, 7, 7, 7]
episode: 386 -> reward: -124.99999999999211, steps:65664, time-elasped: 78774.29s
-> berries picked: 64 of 800 | patches-visited: [6] | positive-in-buffer: 15117 | amount-filled: 100.00%
	| epsilon: 0.2295320126128645
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1197, 2514, 1888, 1852, 1662, 2796, 1624, 1584]
	| approx positives in sample 512: 50
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 9, 5, 4, 7, 11, 7, 5]
episode: 387 -> reward: -124.99999999999183, steps:63936, time-elasped: 78992.40s
-> berries picked: 73 of 800 | patches-visited: [0] | positive-in-buffer: 14855 | amount-filled: 100.00%
	| epsilon: 0.22907070489326584
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1147, 2466, 1879, 1794, 1626, 2790, 1616, 1537]
	| approx positives in sample 512: 48
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 3, 9, 9, 6, 5, 8, 6]
episode: 388 -> reward: -124.99999999999207, steps:56928, time-elasped: 79146.63s
-> berries picked: 28 of 800 | patches-visited: [2] | positive-in-buffer: 14844 | amount-filled: 100.00%
	| epsilon: 0.22861032429842745
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1136, 2464, 1857, 1795, 1659, 2792, 1613, 1528]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 24, 15, 11, 17, 28, 13, 13]
episode: 389 -> reward: -124.99999999999189, steps:67584, time-elasped: 79396.99s
-> berries picked: 76 of 800 | patches-visited: [1, 5] | positive-in-buffer: 15125 | amount-filled: 100.00%
	| epsilon: 0.22815086896503706
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1180, 2514, 1870, 1816, 1755, 2819, 1634, 1537]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 19, 22, 19, 13, 26, 17, 11]
episode: 390 -> reward: -124.99999999999187, steps:63360, time-elasped: 79617.09s
-> berries picked: 55 of 800 | patches-visited: [9] | positive-in-buffer: 15240 | amount-filled: 100.00%
	| epsilon: 0.22769233703352723
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1192, 2561, 1879, 1852, 1744, 2841, 1628, 1543]
	| approx positives in sample 512: 47
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7] [17, 4, 7, 5, 5, 6, 3]
episode: 391 -> reward: -124.99999999999189, steps:62400, time-elasped: 79784.74s
-> berries picked: 55 of 800 | patches-visited: [4] | positive-in-buffer: 15191 | amount-filled: 100.00%
	| epsilon: 0.22723472664806796
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1170, 2524, 1891, 1870, 1738, 2851, 1619, 1528]
	| approx positives in sample 512: 46
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 8, 6, 6, 3, 10, 7, 3]
episode: 392 -> reward: -124.99999999999204, steps:52704, time-elasped: 79921.35s
-> berries picked: 14 of 800 | patches-visited: [4] | positive-in-buffer: 15074 | amount-filled: 100.00%
	| epsilon: 0.22677803595655885
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1156, 2460, 1882, 1868, 1723, 2818, 1614, 1553]
	| approx positives in sample 512: 52
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 5, 4, 11, 12, 9, 6, 2]
episode: 393 -> reward: -124.99999999999298, steps:81984, time-elasped: 80206.39s
-> berries picked: 122 of 800 | patches-visited: [4, 6] | positive-in-buffer: 15178 | amount-filled: 100.00%
	| epsilon: 0.226322263110622
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1126, 2404, 1878, 1864, 1759, 2883, 1647, 1617]
	| approx positives in sample 512: 62
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 11, 9, 6, 8, 13, 5, 5]
episode: 394 -> reward: -124.99999999999193, steps:67200, time-elasped: 80412.82s
-> berries picked: 80 of 800 | patches-visited: [9] | positive-in-buffer: 15424 | amount-filled: 100.00%
	| epsilon: 0.22586740626559426
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1125, 2449, 1908, 1956, 1748, 2945, 1654, 1639]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 34, 18, 16, 13, 23, 13, 17]
episode: 395 -> reward: -124.99999999999187, steps:67488, time-elasped: 80617.35s
-> berries picked: 78 of 800 | patches-visited: [9] | positive-in-buffer: 15610 | amount-filled: 100.00%
	| epsilon: 0.22541346358051972
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1139, 2527, 1934, 1955, 1747, 3019, 1646, 1643]
	| approx positives in sample 512: 139
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 26, 16, 13, 21, 31, 11, 14]
episode: 396 -> reward: -124.99999999999224, steps:67872, time-elasped: 80814.67s
-> berries picked: 78 of 800 | patches-visited: [3] | positive-in-buffer: 15722 | amount-filled: 100.00%
	| epsilon: 0.2249604332181426
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1135, 2573, 1935, 1962, 1771, 3029, 1649, 1668]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 19, 11, 16, 11, 17, 14, 21]
episode: 397 -> reward: -124.99999999999211, steps:63072, time-elasped: 81035.30s
-> berries picked: 58 of 800 | patches-visited: [5] | positive-in-buffer: 15819 | amount-filled: 100.00%
	| epsilon: 0.22450831334489937
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1146, 2593, 1945, 2003, 1766, 3027, 1656, 1683]
	| approx positives in sample 512: 57
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 8, 10, 6, 4, 9, 7, 8]
episode: 398 -> reward: -124.99999999999203, steps:49152, time-elasped: 81177.48s
-> berries picked: 4 of 800 | patches-visited: [5] | positive-in-buffer: 15393 | amount-filled: 100.00%
	| epsilon: 0.22405710213091176
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1123, 2536, 1899, 1918, 1714, 2973, 1635, 1595]
	| approx positives in sample 512: 62
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 11, 5, 8, 7, 8, 11, 7]
episode: 399 -> reward: -124.99999999999201, steps:66912, time-elasped: 81378.48s
-> berries picked: 72 of 800 | patches-visited: [7] | positive-in-buffer: 15665 | amount-filled: 100.00%
	| epsilon: 0.223606797749979
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1125, 2589, 1948, 1971, 1774, 2989, 1652, 1617]
	| approx positives in sample 512: 170
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 23, 21, 22, 27, 27, 25, 17]
episode: 400 -> reward: -124.99999999999179, steps:51168, time-elasped: 81518.41s
-> berries picked: 12 of 800 | patches-visited: [1, 4] | positive-in-buffer: 15632 | amount-filled: 100.00%
	| epsilon: 0.22315739837957058
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1125, 2563, 1941, 1964, 1771, 2991, 1655, 1622]
	| approx positives in sample 512: 51
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 7, 4, 9, 5, 12, 3, 6]
episode: 401 -> reward: -124.99999999999152, steps:63744, time-elasped: 81738.30s
-> berries picked: 61 of 800 | patches-visited: [2] | positive-in-buffer: 15526 | amount-filled: 100.00%
	| epsilon: 0.22270890220081893
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1123, 2526, 1919, 1922, 1810, 2934, 1679, 1613]
	| approx positives in sample 512: 58
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 12, 6, 11, 5, 9, 4, 6]
episode: 402 -> reward: -124.99999999999028, steps:56640, time-elasped: 81924.23s
-> berries picked: 28 of 800 | patches-visited: [3] | positive-in-buffer: 15089 | amount-filled: 100.00%
	| epsilon: 0.22226130739851196
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1110, 2433, 1859, 1849, 1807, 2841, 1649, 1541]
	| approx positives in sample 512: 139
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 19, 9, 18, 15, 23, 19, 20]
episode: 403 -> reward: -124.99999999999204, steps:67008, time-elasped: 82110.25s
-> berries picked: 78 of 800 | patches-visited: [4] | positive-in-buffer: 15347 | amount-filled: 100.00%
	| epsilon: 0.22181461216108575
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1125, 2473, 1871, 1879, 1845, 2888, 1690, 1576]
	| approx positives in sample 512: 150
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 23, 14, 15, 22, 32, 17, 13]
episode: 404 -> reward: -124.99999999999184, steps:65184, time-elasped: 82296.44s
-> berries picked: 77 of 800 | patches-visited: [3] | positive-in-buffer: 15503 | amount-filled: 100.00%
	| epsilon: 0.2213688146806172
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1134, 2510, 1900, 1898, 1883, 2898, 1689, 1591]
	| approx positives in sample 512: 47
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 1, 6, 7, 7, 8, 2, 8]
episode: 405 -> reward: -124.99999999999078, steps:99840, time-elasped: 82643.80s
-> berries picked: 215 of 800 | patches-visited: [0, 4, 7] | positive-in-buffer: 15657 | amount-filled: 100.00%
	| epsilon: 0.2209239131528168
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1081, 2526, 1897, 2013, 1904, 2911, 1747, 1578]
	| approx positives in sample 512: 173
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 27, 24, 18, 18, 31, 25, 16]
episode: 406 -> reward: -124.99999999999184, steps:66816, time-elasped: 82841.27s
-> berries picked: 72 of 800 | patches-visited: [4] | positive-in-buffer: 15765 | amount-filled: 100.00%
	| epsilon: 0.22047990577702115
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1076, 2542, 1920, 2028, 1936, 2941, 1743, 1579]
	| approx positives in sample 512: 177
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 28, 10, 28, 20, 27, 32, 23]
episode: 407 -> reward: -124.9999999999916, steps:67584, time-elasped: 83065.72s
-> berries picked: 80 of 800 | patches-visited: [7] | positive-in-buffer: 15969 | amount-filled: 100.00%
	| epsilon: 0.22003679075618582
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1081, 2610, 1929, 2030, 1963, 2972, 1728, 1656]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 20, 18, 22, 20, 22, 17, 10]
episode: 408 -> reward: -124.99999999999174, steps:73920, time-elasped: 83281.27s
-> berries picked: 107 of 800 | patches-visited: [6, 7] | positive-in-buffer: 16156 | amount-filled: 100.00%
	| epsilon: 0.2195945662968781
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1079, 2654, 1955, 2050, 1987, 3020, 1745, 1666]
	| approx positives in sample 512: 53
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 10, 7, 6, 4, 10, 7, 7]
episode: 409 -> reward: -124.99999999999106, steps:66336, time-elasped: 83473.69s
-> berries picked: 80 of 800 | patches-visited: [7] | positive-in-buffer: 15931 | amount-filled: 100.00%
	| epsilon: 0.21915323060926956
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1053, 2625, 1937, 2011, 1981, 3017, 1710, 1597]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 28, 30, 26, 23, 40, 21, 28]
episode: 410 -> reward: -124.99999999999179, steps:66144, time-elasped: 83670.74s
-> berries picked: 69 of 800 | patches-visited: [3] | positive-in-buffer: 16120 | amount-filled: 100.00%
	| epsilon: 0.21871278190712906
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1069, 2613, 1953, 2057, 2023, 3044, 1737, 1624]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 37, 19, 28, 26, 41, 24, 31]
episode: 411 -> reward: -124.99999999999437, steps:84000, time-elasped: 83949.93s
-> berries picked: 157 of 800 | patches-visited: [4, 6] | positive-in-buffer: 16407 | amount-filled: 100.00%
	| epsilon: 0.21827321840781527
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1069, 2667, 2006, 2081, 2086, 3065, 1756, 1677]
	| approx positives in sample 512: 66
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 6, 10, 7, 9, 14, 11, 6]
episode: 412 -> reward: -124.99999999999328, steps:67296, time-elasped: 84167.50s
-> berries picked: 79 of 800 | patches-visited: [6] | positive-in-buffer: 15973 | amount-filled: 100.00%
	| epsilon: 0.21783453833226957
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1044, 2608, 1925, 2036, 1981, 3019, 1742, 1618]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 22, 14, 22, 12, 20, 14, 15]
episode: 413 -> reward: -124.99999999999217, steps:65184, time-elasped: 84395.81s
-> berries picked: 64 of 800 | patches-visited: [6] | positive-in-buffer: 16154 | amount-filled: 100.00%
	| epsilon: 0.21739673990500893
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1043, 2634, 1925, 2083, 1997, 3075, 1748, 1649]
	| approx positives in sample 512: 43
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 6, 7, 5, 4, 15, 1, 3]
episode: 414 -> reward: -124.99999999999098, steps:86304, time-elasped: 84699.03s
-> berries picked: 151 of 800 | patches-visited: [2, 3, 9] | positive-in-buffer: 15485 | amount-filled: 100.00%
	| epsilon: 0.21695982135411856
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [988, 2447, 1845, 2025, 1945, 2979, 1645, 1611]
	| approx positives in sample 512: 51
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 3, 6, 10, 6, 14, 6, 5]
episode: 415 -> reward: -124.99999999999203, steps:49440, time-elasped: 84877.20s
-> berries picked: 5 of 800 | patches-visited: [9] | positive-in-buffer: 15185 | amount-filled: 100.00%
	| epsilon: 0.2165237809112449
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [988, 2391, 1813, 1966, 1902, 2941, 1633, 1551]
	| approx positives in sample 512: 68
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 15, 11, 6, 6, 14, 6, 8]
episode: 416 -> reward: -124.99999999999106, steps:92352, time-elasped: 85205.73s
-> berries picked: 168 of 800 | patches-visited: [3, 4, 9] | positive-in-buffer: 15669 | amount-filled: 100.00%
	| epsilon: 0.21608861681158834
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1002, 2455, 1931, 2043, 1950, 3002, 1665, 1621]
	| approx positives in sample 512: 88
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 8, 15, 9, 4, 19, 13, 13]
episode: 417 -> reward: -124.99999999999189, steps:65664, time-elasped: 85393.16s
-> berries picked: 73 of 800 | patches-visited: [2] | positive-in-buffer: 15844 | amount-filled: 100.00%
	| epsilon: 0.21565432729389605
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1023, 2498, 1975, 2050, 1965, 3006, 1677, 1650]
	| approx positives in sample 512: 45
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 1, 7, 10, 3, 9, 7, 6]
episode: 418 -> reward: -124.99999999998856, steps:74304, time-elasped: 85639.69s
-> berries picked: 106 of 800 | patches-visited: [0, 3] | positive-in-buffer: 15225 | amount-filled: 100.00%
	| epsilon: 0.21522091060045506
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [979, 2431, 1820, 1938, 1966, 2931, 1624, 1536]
	| approx positives in sample 512: 53
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7] [9, 7, 11, 10, 4, 6, 6]
episode: 419 -> reward: -124.99999999998856, steps:66048, time-elasped: 85886.39s
-> berries picked: 76 of 800 | patches-visited: [0] | positive-in-buffer: 15287 | amount-filled: 100.00%
	| epsilon: 0.21478836497708487
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [985, 2423, 1850, 1977, 2001, 2900, 1619, 1532]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 26, 36, 25, 30, 48, 21, 19]
episode: 420 -> reward: -124.99999999999292, steps:61152, time-elasped: 86094.48s
-> berries picked: 52 of 800 | patches-visited: [2] | positive-in-buffer: 15391 | amount-filled: 100.00%
	| epsilon: 0.21435668867313065
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1006, 2439, 1855, 2033, 1964, 2922, 1643, 1529]
	| approx positives in sample 512: 74
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 13, 9, 10, 11, 13, 9, 6]
episode: 421 -> reward: -124.99999999999055, steps:78432, time-elasped: 86366.85s
-> berries picked: 122 of 800 | patches-visited: [5, 6] | positive-in-buffer: 15544 | amount-filled: 100.00%
	| epsilon: 0.21392587994145584
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [999, 2466, 1877, 2043, 1977, 2960, 1673, 1549]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 22, 17, 16, 18, 27, 16, 10]
episode: 422 -> reward: -124.99999999999201, steps:67680, time-elasped: 86617.11s
-> berries picked: 79 of 800 | patches-visited: [1] | positive-in-buffer: 15808 | amount-filled: 100.00%
	| epsilon: 0.21349593703843528
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1013, 2511, 1940, 2090, 2037, 2984, 1678, 1555]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 23, 12, 17, 17, 28, 13, 15]
episode: 423 -> reward: -124.99999999999116, steps:72768, time-elasped: 86891.71s
-> berries picked: 92 of 800 | patches-visited: [0, 2, 4] | positive-in-buffer: 15976 | amount-filled: 100.00%
	| epsilon: 0.21306685822394814
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1022, 2504, 2010, 2074, 2076, 3030, 1689, 1571]
	| approx positives in sample 512: 51
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 7, 7, 9, 6, 7, 8, 5]
episode: 424 -> reward: -124.99999999999228, steps:84672, time-elasped: 87199.44s
-> berries picked: 144 of 800 | patches-visited: [0, 7] | positive-in-buffer: 16040 | amount-filled: 100.00%
	| epsilon: 0.2126386417613708
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1058, 2490, 1976, 2043, 2100, 3031, 1735, 1607]
	| approx positives in sample 512: 49
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 5, 7, 5, 8, 10, 4, 6]
episode: 425 -> reward: -124.99999999998681, steps:102336, time-elasped: 87569.43s
-> berries picked: 206 of 800 | patches-visited: [1, 4, 5, 9] | positive-in-buffer: 16201 | amount-filled: 100.00%
	| epsilon: 0.2122112859175699
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1044, 2620, 2010, 2120, 2115, 3007, 1724, 1561]
	| approx positives in sample 512: 84
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 7, 17, 5, 13, 18, 9, 13]
episode: 426 -> reward: -124.99999999999206, steps:51648, time-elasped: 87737.91s
-> berries picked: 12 of 800 | patches-visited: [8] | positive-in-buffer: 16094 | amount-filled: 100.00%
	| epsilon: 0.21178478896289527
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1031, 2593, 1983, 2101, 2100, 3028, 1717, 1541]
	| approx positives in sample 512: 59
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 12, 10, 6, 3, 13, 4, 5]
episode: 427 -> reward: -124.99999999999324, steps:72768, time-elasped: 88002.66s
-> berries picked: 95 of 800 | patches-visited: [2, 9] | positive-in-buffer: 15664 | amount-filled: 100.00%
	| epsilon: 0.2113591491711729
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [953, 2478, 1935, 2036, 2056, 2965, 1705, 1536]
	| approx positives in sample 512: 65
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 13, 8, 8, 5, 15, 7, 5]
episode: 428 -> reward: -124.99999999999247, steps:66528, time-elasped: 88218.43s
-> berries picked: 78 of 800 | patches-visited: [6] | positive-in-buffer: 15741 | amount-filled: 100.00%
	| epsilon: 0.2109343648196981
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [956, 2512, 1937, 2038, 2075, 2957, 1726, 1540]
	| approx positives in sample 512: 186
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 31, 20, 21, 20, 35, 21, 28]
episode: 429 -> reward: -124.99999999999497, steps:86592, time-elasped: 88503.14s
-> berries picked: 157 of 800 | patches-visited: [1, 7] | positive-in-buffer: 16178 | amount-filled: 100.00%
	| epsilon: 0.21051043418922832
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [967, 2603, 2021, 2071, 2176, 2983, 1758, 1599]
	| approx positives in sample 512: 52
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 7, 7, 8, 6, 14, 4, 3]
episode: 430 -> reward: -124.99999999999208, steps:67584, time-elasped: 88714.68s
-> berries picked: 77 of 800 | patches-visited: [7] | positive-in-buffer: 15170 | amount-filled: 100.00%
	| epsilon: 0.21008735556397645
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [904, 2386, 1933, 1891, 2078, 2861, 1674, 1443]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 18, 15, 20, 16, 22, 14, 17]
episode: 431 -> reward: -124.99999999999184, steps:66912, time-elasped: 88929.19s
-> berries picked: 79 of 800 | patches-visited: [7] | positive-in-buffer: 15349 | amount-filled: 100.00%
	| epsilon: 0.20966512723160352
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [920, 2431, 1973, 1909, 2083, 2889, 1675, 1469]
	| approx positives in sample 512: 167
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 32, 14, 16, 18, 40, 12, 23]
episode: 432 -> reward: -124.99999999999183, steps:69504, time-elasped: 89166.66s
-> berries picked: 84 of 800 | patches-visited: [1, 7] | positive-in-buffer: 15520 | amount-filled: 100.00%
	| epsilon: 0.20924374748321217
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [915, 2449, 1981, 1920, 2146, 2884, 1735, 1490]
	| approx positives in sample 512: 94
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 18, 17, 8, 12, 11, 11, 9]
episode: 433 -> reward: -124.99999999999184, steps:67008, time-elasped: 89404.35s
-> berries picked: 79 of 800 | patches-visited: [2] | positive-in-buffer: 15579 | amount-filled: 100.00%
	| epsilon: 0.20882321461333944
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [944, 2454, 1992, 1939, 2131, 2880, 1744, 1495]
	| approx positives in sample 512: 174
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 24, 19, 25, 18, 46, 21, 16]
episode: 434 -> reward: -124.99999999998383, steps:82656, time-elasped: 89711.27s
-> berries picked: 144 of 800 | patches-visited: [6, 8] | positive-in-buffer: 15904 | amount-filled: 100.00%
	| epsilon: 0.20840352691994996
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [938, 2479, 1997, 1967, 2179, 2957, 1788, 1599]
	| approx positives in sample 512: 79
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 12, 9, 11, 14, 12, 11, 5]
episode: 435 -> reward: -124.99999999999183, steps:67968, time-elasped: 89933.34s
-> berries picked: 80 of 800 | patches-visited: [5] | positive-in-buffer: 15872 | amount-filled: 100.00%
	| epsilon: 0.20798468270442913
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [920, 2480, 1981, 1992, 2202, 2961, 1757, 1579]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 17, 15, 20, 17, 23, 10, 13]
episode: 436 -> reward: -124.99999999999284, steps:67392, time-elasped: 90182.17s
-> berries picked: 70 of 800 | patches-visited: [0, 4] | positive-in-buffer: 16069 | amount-filled: 100.00%
	| epsilon: 0.2075666802715761
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [928, 2552, 2008, 2011, 2211, 2988, 1779, 1592]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 29, 17, 16, 19, 32, 17, 12]
episode: 437 -> reward: -124.99999999998744, steps:68064, time-elasped: 90439.32s
-> berries picked: 61 of 800 | patches-visited: [2, 4, 6] | positive-in-buffer: 16174 | amount-filled: 100.00%
	| epsilon: 0.2071495179295971
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [949, 2554, 2013, 2025, 2258, 2983, 1782, 1610]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 26, 14, 14, 13, 28, 15, 14]
episode: 438 -> reward: -124.99999999999355, steps:88032, time-elasped: 90740.86s
-> berries picked: 160 of 800 | patches-visited: [0, 8] | positive-in-buffer: 16451 | amount-filled: 100.00%
	| epsilon: 0.20673319399009837
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [943, 2567, 2013, 2065, 2369, 3065, 1800, 1629]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 37, 29, 31, 33, 46, 25, 19]
episode: 439 -> reward: -124.99999999999297, steps:65952, time-elasped: 90933.87s
-> berries picked: 70 of 800 | patches-visited: [2] | positive-in-buffer: 16502 | amount-filled: 100.00%
	| epsilon: 0.2063177067680795
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [942, 2576, 2088, 2060, 2331, 3067, 1800, 1638]
	| approx positives in sample 512: 47
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 5, 6, 5, 7, 10, 2, 4]
episode: 440 -> reward: -124.99999999999199, steps:69888, time-elasped: 91146.89s
-> berries picked: 78 of 800 | patches-visited: [4, 5] | positive-in-buffer: 15365 | amount-filled: 100.00%
	| epsilon: 0.2059030545819266
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [910, 2326, 1874, 1902, 2155, 2953, 1686, 1559]
	| approx positives in sample 512: 77
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 9, 9, 12, 11, 18, 6, 7]
episode: 441 -> reward: -124.99999999999217, steps:67488, time-elasped: 91384.14s
-> berries picked: 79 of 800 | patches-visited: [4] | positive-in-buffer: 15534 | amount-filled: 100.00%
	| epsilon: 0.2054892357534053
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [916, 2368, 1881, 1929, 2194, 2981, 1688, 1577]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 18, 14, 16, 19, 29, 24, 16]
episode: 442 -> reward: -124.99999999999191, steps:66240, time-elasped: 91601.56s
-> berries picked: 72 of 800 | patches-visited: [2] | positive-in-buffer: 15632 | amount-filled: 100.00%
	| epsilon: 0.20507624860765433
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [921, 2373, 1905, 1941, 2193, 2995, 1716, 1588]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 36, 27, 33, 19, 47, 24, 16]
episode: 443 -> reward: -124.99999999999203, steps:56160, time-elasped: 91751.19s
-> berries picked: 29 of 800 | patches-visited: [8] | positive-in-buffer: 15677 | amount-filled: 100.00%
	| epsilon: 0.20466409147317827
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [932, 2363, 1929, 1965, 2196, 3000, 1711, 1581]
	| approx positives in sample 512: 146
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 17, 11, 25, 21, 24, 22, 16]
episode: 444 -> reward: -124.99999999999204, steps:54048, time-elasped: 91902.76s
-> berries picked: 21 of 800 | patches-visited: [8] | positive-in-buffer: 15708 | amount-filled: 100.00%
	| epsilon: 0.20425276268184117
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [930, 2363, 1917, 1988, 2199, 2998, 1727, 1586]
	| approx positives in sample 512: 41
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 9, 5, 7, 2, 8, 2, 4]
episode: 445 -> reward: -124.99999999999194, steps:67008, time-elasped: 92128.66s
-> berries picked: 73 of 800 | patches-visited: [9] | positive-in-buffer: 15307 | amount-filled: 100.00%
	| epsilon: 0.20384226056885965
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [905, 2339, 1861, 1937, 2130, 2910, 1687, 1538]
	| approx positives in sample 512: 161
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 26, 25, 23, 20, 29, 14, 14]
episode: 446 -> reward: -124.99999999999494, steps:100320, time-elasped: 92475.68s
-> berries picked: 209 of 800 | patches-visited: [4, 5, 7] | positive-in-buffer: 15925 | amount-filled: 100.00%
	| epsilon: 0.20343258347279614
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [938, 2433, 1981, 1978, 2251, 2996, 1723, 1625]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 19, 19, 21, 22, 29, 12, 8]
episode: 447 -> reward: -124.99999999999298, steps:74016, time-elasped: 92741.38s
-> berries picked: 101 of 800 | patches-visited: [1, 4] | positive-in-buffer: 16035 | amount-filled: 100.00%
	| epsilon: 0.2030237297355522
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [917, 2437, 1971, 1985, 2275, 3021, 1767, 1662]
	| approx positives in sample 512: 61
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 11, 7, 8, 9, 7, 8, 6]
episode: 448 -> reward: -124.9999999999933, steps:61632, time-elasped: 92957.62s
-> berries picked: 42 of 800 | patches-visited: [6, 8] | positive-in-buffer: 15694 | amount-filled: 100.00%
	| epsilon: 0.20261569770236176
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [917, 2362, 1919, 1934, 2218, 2971, 1718, 1655]
	| approx positives in sample 512: 65
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 11, 7, 5, 12, 11, 5, 8]
episode: 449 -> reward: -124.99999999999227, steps:83904, time-elasped: 93238.74s
-> berries picked: 139 of 800 | patches-visited: [6, 7] | positive-in-buffer: 16038 | amount-filled: 100.00%
	| epsilon: 0.20220848572178451
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [925, 2396, 1990, 1997, 2255, 3110, 1712, 1653]
	| approx positives in sample 512: 62
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 6, 5, 14, 6, 17, 7, 6]
episode: 450 -> reward: -124.99999999999167, steps:53760, time-elasped: 93438.77s
-> berries picked: 19 of 800 | patches-visited: [9] | positive-in-buffer: 15902 | amount-filled: 100.00%
	| epsilon: 0.20180209214569916
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [915, 2368, 1970, 1988, 2225, 3086, 1714, 1636]
	| approx positives in sample 512: 29
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 2, 8, 4, 4, 7, 1, 2]
episode: 451 -> reward: -124.99999999997611, steps:103488, time-elasped: 93802.13s
-> berries picked: 214 of 800 | patches-visited: [2, 4, 5] | positive-in-buffer: 15559 | amount-filled: 100.00%
	| epsilon: 0.20139651532929673
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [836, 2327, 1920, 1943, 2257, 3027, 1704, 1545]
	| approx positives in sample 512: 73
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 11, 11, 6, 7, 16, 10, 8]
episode: 452 -> reward: -124.99999999999018, steps:79680, time-elasped: 94094.47s
-> berries picked: 125 of 800 | patches-visited: [1, 6, 8] | positive-in-buffer: 15757 | amount-filled: 100.00%
	| epsilon: 0.200991753631074
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [872, 2345, 1993, 1964, 2254, 3036, 1715, 1578]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 16, 13, 17, 13, 23, 12, 17]
episode: 453 -> reward: -124.99999999999267, steps:65088, time-elasped: 94292.90s
-> berries picked: 75 of 800 | patches-visited: [3] | positive-in-buffer: 15912 | amount-filled: 100.00%
	| epsilon: 0.2005878054128267
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [858, 2354, 2016, 2024, 2272, 3062, 1746, 1580]
	| approx positives in sample 512: 44
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 6, 7, 4, 6, 11, 1, 8]
episode: 454 -> reward: -124.99999999999203, steps:49824, time-elasped: 94424.73s
-> berries picked: 6 of 800 | patches-visited: [9] | positive-in-buffer: 15124 | amount-filled: 100.00%
	| epsilon: 0.20018466903964308
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [820, 2217, 1900, 1913, 2153, 2916, 1700, 1505]
	| approx positives in sample 512: 71
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 10, 9, 8, 11, 17, 5, 9]
episode: 455 -> reward: -124.99999999999213, steps:59136, time-elasped: 94649.33s
-> berries picked: 39 of 800 | patches-visited: [1] | positive-in-buffer: 15274 | amount-filled: 100.00%
	| epsilon: 0.19978234287989716
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [828, 2258, 1905, 1923, 2166, 2934, 1747, 1513]
	| approx positives in sample 512: 76
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 14, 13, 7, 8, 13, 10, 8]
episode: 456 -> reward: -124.99999999999152, steps:65760, time-elasped: 94862.57s
-> berries picked: 65 of 800 | patches-visited: [9] | positive-in-buffer: 15388 | amount-filled: 100.00%
	| epsilon: 0.19938082530524215
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [834, 2289, 1925, 1955, 2175, 2943, 1751, 1516]
	| approx positives in sample 512: 47
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 8, 12, 6, 3, 10, 4, 1]
episode: 457 -> reward: -124.99999999999058, steps:74304, time-elasped: 95090.96s
-> berries picked: 104 of 800 | patches-visited: [1, 7] | positive-in-buffer: 15122 | amount-filled: 100.00%
	| epsilon: 0.1989801146906039
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [824, 2284, 1873, 1909, 2165, 2903, 1724, 1440]
	| approx positives in sample 512: 51
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 8, 7, 8, 5, 8, 5, 8]
episode: 458 -> reward: -124.99999999999122, steps:84672, time-elasped: 95385.79s
-> berries picked: 145 of 800 | patches-visited: [1, 6] | positive-in-buffer: 15554 | amount-filled: 100.00%
	| epsilon: 0.19858020941417426
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [822, 2311, 1964, 1945, 2307, 2955, 1769, 1481]
	| approx positives in sample 512: 55
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 8, 7, 5, 11, 7, 5, 6]
episode: 459 -> reward: -124.9999999999923, steps:67968, time-elasped: 95607.21s
-> berries picked: 80 of 800 | patches-visited: [8] | positive-in-buffer: 15558 | amount-filled: 100.00%
	| epsilon: 0.1981811078574046
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [840, 2286, 1908, 1986, 2278, 2980, 1779, 1501]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 16, 17, 18, 17, 19, 11, 9]
episode: 460 -> reward: -124.99999999999174, steps:79872, time-elasped: 95915.66s
-> berries picked: 121 of 800 | patches-visited: [5, 9] | positive-in-buffer: 15861 | amount-filled: 100.00%
	| epsilon: 0.1977828084049991
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [879, 2303, 1958, 2071, 2345, 3006, 1789, 1510]
	| approx positives in sample 512: 94
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 18, 11, 8, 10, 20, 7, 15]
episode: 461 -> reward: -124.99999999999481, steps:90912, time-elasped: 96247.49s
-> berries picked: 161 of 800 | patches-visited: [3, 4, 7] | positive-in-buffer: 16247 | amount-filled: 100.00%
	| epsilon: 0.19738530944490845
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [871, 2430, 2111, 2075, 2359, 3014, 1810, 1577]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 9, 21, 12, 23, 17, 9, 5]
episode: 462 -> reward: -124.99999999998626, steps:64320, time-elasped: 96483.34s
-> berries picked: 61 of 800 | patches-visited: [9] | positive-in-buffer: 16287 | amount-filled: 100.00%
	| epsilon: 0.19698860936832316
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [883, 2462, 2083, 2109, 2349, 3007, 1813, 1581]
	| approx positives in sample 512: 49
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 8, 3, 4, 8, 13, 8, 3]
episode: 463 -> reward: -124.99999999998197, steps:90048, time-elasped: 96827.44s
-> berries picked: 167 of 800 | patches-visited: [2, 4, 9] | positive-in-buffer: 15996 | amount-filled: 100.00%
	| epsilon: 0.19659270656966704
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [839, 2373, 1935, 2109, 2363, 2957, 1855, 1565]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 19, 12, 16, 21, 18, 11, 11]
episode: 464 -> reward: -124.99999999999226, steps:59808, time-elasped: 97013.93s
-> berries picked: 39 of 800 | patches-visited: [9] | positive-in-buffer: 15969 | amount-filled: 100.00%
	| epsilon: 0.19619759944659074
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [834, 2367, 1940, 2104, 2369, 3001, 1808, 1546]
	| approx positives in sample 512: 80
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 13, 2, 8, 8, 13, 16, 13]
episode: 465 -> reward: -124.99999999999267, steps:63744, time-elasped: 97226.00s
-> berries picked: 58 of 800 | patches-visited: [2] | positive-in-buffer: 16012 | amount-filled: 100.00%
	| epsilon: 0.19580328639996536
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [836, 2421, 1942, 2106, 2353, 3007, 1805, 1542]
	| approx positives in sample 512: 41
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 5, 3, 3, 10, 11, 5, 3]
episode: 466 -> reward: -124.99999999999393, steps:63072, time-elasped: 97454.48s
-> berries picked: 58 of 800 | patches-visited: [2] | positive-in-buffer: 15618 | amount-filled: 100.00%
	| epsilon: 0.19540976583387581
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [783, 2316, 1891, 2052, 2351, 2927, 1783, 1515]
	| approx positives in sample 512: 64
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 14, 5, 7, 12, 9, 4, 10]
episode: 467 -> reward: -124.99999999999403, steps:65952, time-elasped: 97689.39s
-> berries picked: 69 of 800 | patches-visited: [1] | positive-in-buffer: 15637 | amount-filled: 100.00%
	| epsilon: 0.19501703615561447
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [778, 2354, 1902, 2071, 2353, 2910, 1766, 1503]
	| approx positives in sample 512: 44
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 7] [2, 9, 8, 5, 7, 10, 3]
episode: 468 -> reward: -124.99999999999133, steps:64416, time-elasped: 97884.56s
-> berries picked: 67 of 800 | patches-visited: [3] | positive-in-buffer: 14717 | amount-filled: 100.00%
	| epsilon: 0.19462509577567466
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [727, 2118, 1772, 1930, 2210, 2790, 1742, 1428]
	| approx positives in sample 512: 40
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7] [6, 5, 8, 4, 7, 8, 2]
episode: 469 -> reward: -124.99999999999177, steps:62880, time-elasped: 98064.52s
-> berries picked: 52 of 800 | patches-visited: [6] | positive-in-buffer: 14864 | amount-filled: 100.00%
	| epsilon: 0.19423394310774433
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [730, 2128, 1788, 1964, 2262, 2789, 1757, 1446]
	| approx positives in sample 512: 64
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 9, 8, 12, 10, 12, 8, 2]
episode: 470 -> reward: -124.99999999999115, steps:60480, time-elasped: 98258.45s
-> berries picked: 43 of 800 | patches-visited: [3, 6] | positive-in-buffer: 14970 | amount-filled: 100.00%
	| epsilon: 0.19384357656869947
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [741, 2140, 1774, 1996, 2245, 2835, 1791, 1448]
	| approx positives in sample 512: 65
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 15, 13, 7, 5, 9, 5, 6]
episode: 471 -> reward: -124.99999999999179, steps:50688, time-elasped: 98432.40s
-> berries picked: 9 of 800 | patches-visited: [1] | positive-in-buffer: 14880 | amount-filled: 100.00%
	| epsilon: 0.19345399457859783
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [728, 2125, 1754, 1987, 2231, 2828, 1776, 1451]
	| approx positives in sample 512: 50
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 5, 11, 6, 4, 11, 7, 3]
episode: 472 -> reward: -124.99999999998654, steps:86208, time-elasped: 98716.28s
-> berries picked: 154 of 800 | patches-visited: [4, 5, 8] | positive-in-buffer: 15244 | amount-filled: 100.00%
	| epsilon: 0.19306519556067253
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [751, 2141, 1894, 1997, 2286, 2880, 1811, 1484]
	| approx positives in sample 512: 40
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 3, 5, 8, 1, 9, 6, 3]
episode: 473 -> reward: -124.99999999998913, steps:101088, time-elasped: 99061.56s
-> berries picked: 217 of 800 | patches-visited: [4, 8, 9] | positive-in-buffer: 15516 | amount-filled: 100.00%
	| epsilon: 0.19267717794132558
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [772, 2272, 1922, 2056, 2283, 2928, 1807, 1476]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 19, 17, 18, 16, 30, 16, 6]
episode: 474 -> reward: -124.999999999992, steps:62688, time-elasped: 99285.18s
-> berries picked: 60 of 800 | patches-visited: [7] | positive-in-buffer: 15615 | amount-filled: 100.00%
	| epsilon: 0.19228994015012157
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [767, 2231, 1914, 2054, 2352, 2961, 1837, 1499]
	| approx positives in sample 512: 43
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7] [5, 4, 6, 8, 9, 9, 2]
episode: 475 -> reward: -124.99999999998177, steps:86496, time-elasped: 99570.96s
-> berries picked: 155 of 800 | patches-visited: [1, 6] | positive-in-buffer: 15990 | amount-filled: 100.00%
	| epsilon: 0.19190348061978138
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [761, 2297, 1959, 2108, 2472, 2969, 1899, 1525]
	| approx positives in sample 512: 58
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 7, 9, 5, 8, 12, 8, 5]
episode: 476 -> reward: -124.99999999998377, steps:84576, time-elasped: 99870.58s
-> berries picked: 133 of 800 | patches-visited: [1, 2, 5, 9] | positive-in-buffer: 15726 | amount-filled: 100.00%
	| epsilon: 0.19151779778617564
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [735, 2269, 1910, 2025, 2392, 2903, 1977, 1515]
	| approx positives in sample 512: 54
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 7, 4, 4, 11, 10, 7, 9]
episode: 477 -> reward: -124.99999999999197, steps:79296, time-elasped: 100116.33s
-> berries picked: 127 of 800 | patches-visited: [6, 9] | positive-in-buffer: 15858 | amount-filled: 100.00%
	| epsilon: 0.19113289008831869
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [773, 2306, 1983, 2069, 2357, 2935, 1939, 1496]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 14, 20, 17, 21, 30, 12, 11]
episode: 478 -> reward: -124.99999999997986, steps:119424, time-elasped: 100505.99s
-> berries picked: 269 of 800 | patches-visited: [0, 1, 3, 8] | positive-in-buffer: 16550 | amount-filled: 100.00%
	| epsilon: 0.19074875596836194
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [762, 2477, 1982, 2163, 2521, 2980, 2062, 1603]
	| approx positives in sample 512: 52
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 10, 7, 9, 4, 13, 3, 3]
episode: 479 -> reward: -124.99999999998917, steps:97632, time-elasped: 100852.62s
-> berries picked: 206 of 800 | patches-visited: [0, 3, 9] | positive-in-buffer: 16083 | amount-filled: 100.00%
	| epsilon: 0.19036539387158788
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [795, 2360, 1959, 2065, 2410, 2986, 1971, 1537]
	| approx positives in sample 512: 45
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 4, 5, 1, 10, 9, 7, 2]
episode: 480 -> reward: -124.99999999998262, steps:105600, time-elasped: 101186.95s
-> berries picked: 231 of 800 | patches-visited: [2, 5, 9] | positive-in-buffer: 16077 | amount-filled: 100.00%
	| epsilon: 0.1899828022464035
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [791, 2362, 1987, 2065, 2425, 3020, 1919, 1508]
	| approx positives in sample 512: 66
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 8, 9, 7, 11, 8, 11, 7]
episode: 481 -> reward: -124.9999999999812, steps:99840, time-elasped: 101509.58s
-> berries picked: 208 of 800 | patches-visited: [3, 4, 6] | positive-in-buffer: 16392 | amount-filled: 100.00%
	| epsilon: 0.1896009795443342
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [791, 2409, 2004, 2124, 2420, 3131, 1920, 1593]
	| approx positives in sample 512: 162
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 35, 17, 20, 20, 32, 13, 17]
episode: 482 -> reward: -124.99999999998714, steps:82848, time-elasped: 101784.29s
-> berries picked: 137 of 800 | patches-visited: [0, 3] | positive-in-buffer: 16311 | amount-filled: 100.00%
	| epsilon: 0.18921992422001746
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [861, 2395, 2040, 2101, 2383, 3082, 1941, 1508]
	| approx positives in sample 512: 64
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 10, 7, 3, 8, 9, 15, 5]
episode: 483 -> reward: -124.99999999999191, steps:66432, time-elasped: 101979.24s
-> berries picked: 79 of 800 | patches-visited: [3] | positive-in-buffer: 15763 | amount-filled: 100.00%
	| epsilon: 0.18883963473119664
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [771, 2309, 2000, 2037, 2282, 3050, 1867, 1447]
	| approx positives in sample 512: 196
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 26, 15, 24, 33, 43, 25, 24]
episode: 484 -> reward: -124.99999999999207, steps:60672, time-elasped: 102196.12s
-> berries picked: 42 of 800 | patches-visited: [0] | positive-in-buffer: 15852 | amount-filled: 100.00%
	| epsilon: 0.1884601095387146
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [784, 2285, 2019, 2069, 2311, 3062, 1872, 1450]
	| approx positives in sample 512: 65
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 8, 9, 13, 11, 7, 8, 8]
episode: 485 -> reward: -124.99999999999189, steps:61056, time-elasped: 102362.27s
-> berries picked: 50 of 800 | patches-visited: [2] | positive-in-buffer: 15757 | amount-filled: 100.00%
	| epsilon: 0.18808134710650762
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [757, 2274, 1969, 2061, 2328, 3054, 1861, 1453]
	| approx positives in sample 512: 70
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 12, 8, 4, 12, 18, 8, 5]
episode: 486 -> reward: -124.99999999998906, steps:65376, time-elasped: 102581.89s
-> berries picked: 60 of 800 | patches-visited: [4, 5] | positive-in-buffer: 15764 | amount-filled: 100.00%
	| epsilon: 0.18770334590159907
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [756, 2290, 1978, 2063, 2328, 3034, 1890, 1425]
	| approx positives in sample 512: 51
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 8, 6, 5, 13, 8, 6, 3]
episode: 487 -> reward: -124.99999999998779, steps:76032, time-elasped: 102841.31s
-> berries picked: 102 of 800 | patches-visited: [2, 7] | positive-in-buffer: 15109 | amount-filled: 100.00%
	| epsilon: 0.18732610439409333
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [752, 2164, 1885, 2057, 2216, 2993, 1786, 1256]
	| approx positives in sample 512: 47
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 6, 10, 9, 4, 9, 2, 6]
episode: 488 -> reward: -124.99999999999426, steps:64992, time-elasped: 103037.13s
-> berries picked: 70 of 800 | patches-visited: [4] | positive-in-buffer: 15057 | amount-filled: 100.00%
	| epsilon: 0.1869496210571695
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [721, 2152, 1930, 2019, 2234, 2957, 1777, 1267]
	| approx positives in sample 512: 33
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7] [6, 6, 4, 5, 7, 4, 1]
episode: 489 -> reward: -124.99999999999193, steps:67872, time-elasped: 103243.04s
-> berries picked: 79 of 800 | patches-visited: [2] | positive-in-buffer: 15095 | amount-filled: 100.00%
	| epsilon: 0.1865738943670752
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [693, 2101, 1924, 2036, 2257, 2999, 1787, 1298]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 20, 18, 17, 27, 28, 6, 10]
episode: 490 -> reward: -124.99999999999183, steps:65184, time-elasped: 103415.56s
-> berries picked: 79 of 800 | patches-visited: [6] | positive-in-buffer: 15298 | amount-filled: 100.00%
	| epsilon: 0.18619892280312053
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [699, 2168, 1985, 2047, 2273, 3042, 1786, 1298]
	| approx positives in sample 512: 36
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 7, 6, 8, 2, 5, 4, 2]
episode: 491 -> reward: -124.99999999999214, steps:67008, time-elasped: 103604.12s
-> berries picked: 74 of 800 | patches-visited: [8] | positive-in-buffer: 15181 | amount-filled: 100.00%
	| epsilon: 0.18582470484767172
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [688, 2142, 1956, 2030, 2273, 3030, 1764, 1298]
	| approx positives in sample 512: 159
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 26, 17, 24, 27, 27, 15, 17]
episode: 492 -> reward: -124.99999999999217, steps:56160, time-elasped: 103792.54s
-> berries picked: 33 of 800 | patches-visited: [5] | positive-in-buffer: 15248 | amount-filled: 100.00%
	| epsilon: 0.18545123898614527
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [697, 2166, 1962, 2046, 2273, 3038, 1771, 1295]
	| approx positives in sample 512: 162
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 34, 19, 17, 22, 35, 13, 19]
episode: 493 -> reward: -124.99999999999221, steps:61824, time-elasped: 103970.00s
-> berries picked: 49 of 800 | patches-visited: [0] | positive-in-buffer: 15367 | amount-filled: 100.00%
	| epsilon: 0.18507852370700145
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [705, 2184, 1957, 2058, 2284, 3063, 1797, 1319]
	| approx positives in sample 512: 59
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 8, 6, 2, 11, 13, 10, 5]
episode: 494 -> reward: -124.99999999999243, steps:63744, time-elasped: 104182.87s
-> berries picked: 57 of 800 | patches-visited: [2] | positive-in-buffer: 15473 | amount-filled: 100.00%
	| epsilon: 0.1847065575017386
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [743, 2197, 1967, 2074, 2298, 3063, 1799, 1332]
	| approx positives in sample 512: 40
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 9, 7, 5, 6, 5, 2, 4]
episode: 495 -> reward: -124.99999999998407, steps:76032, time-elasped: 104423.51s
-> berries picked: 107 of 800 | patches-visited: [0, 5, 8] | positive-in-buffer: 15573 | amount-filled: 100.00%
	| epsilon: 0.18433533886488657
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [765, 2224, 1933, 2077, 2366, 3071, 1804, 1333]
	| approx positives in sample 512: 54
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 12, 6, 4, 9, 10, 6, 4]
episode: 496 -> reward: -124.9999999999871, steps:72864, time-elasped: 104652.25s
-> berries picked: 83 of 800 | patches-visited: [3, 4] | positive-in-buffer: 15283 | amount-filled: 100.00%
	| epsilon: 0.1839648662940011
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [739, 2177, 1906, 2048, 2329, 3027, 1780, 1277]
	| approx positives in sample 512: 50
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 12, 8, 6, 6, 8, 6, 1]
episode: 497 -> reward: -124.99999999999271, steps:67200, time-elasped: 104845.13s
-> berries picked: 71 of 800 | patches-visited: [3, 7] | positive-in-buffer: 15386 | amount-filled: 100.00%
	| epsilon: 0.1835951382896574
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [726, 2208, 1930, 2085, 2331, 3047, 1775, 1284]
	| approx positives in sample 512: 158
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 21, 20, 25, 21, 34, 18, 10]
episode: 498 -> reward: -124.99999999999268, steps:66720, time-elasped: 105041.51s
-> berries picked: 79 of 800 | patches-visited: [2] | positive-in-buffer: 15553 | amount-filled: 100.00%
	| epsilon: 0.1832261533554441
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [725, 2230, 1981, 2102, 2357, 3063, 1790, 1305]
	| approx positives in sample 512: 174
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 23, 26, 29, 27, 35, 15, 15]
episode: 499 -> reward: -124.99999999999311, steps:63840, time-elasped: 105207.36s
-> berries picked: 64 of 800 | patches-visited: [2] | positive-in-buffer: 15708 | amount-filled: 100.00%
	| epsilon: 0.18285790999795745
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [729, 2251, 1990, 2105, 2382, 3111, 1819, 1321]
	| approx positives in sample 512: 44
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 4, 7, 5, 10, 8, 6, 1]
episode: 500 -> reward: -124.99999999999203, steps:50976, time-elasped: 105344.10s
-> berries picked: 9 of 800 | patches-visited: [8] | positive-in-buffer: 15393 | amount-filled: 100.00%
	| epsilon: 0.182490406726795
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [713, 2185, 1946, 2075, 2353, 3052, 1792, 1277]
	| approx positives in sample 512: 48
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 5, 9, 8, 7, 13, 3, 2]
episode: 501 -> reward: -124.99999999999201, steps:61344, time-elasped: 105567.59s
-> berries picked: 46 of 800 | patches-visited: [7] | positive-in-buffer: 15575 | amount-filled: 100.00%
	| epsilon: 0.18212364205454967
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [731, 2208, 1969, 2089, 2407, 3053, 1821, 1297]
	| approx positives in sample 512: 77
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 11, 9, 14, 7, 14, 12, 4]
episode: 502 -> reward: -124.99999999999149, steps:69024, time-elasped: 105779.41s
-> berries picked: 76 of 800 | patches-visited: [1, 2, 3] | positive-in-buffer: 15658 | amount-filled: 100.00%
	| epsilon: 0.18175761449680378
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [768, 2228, 1947, 2102, 2436, 3040, 1810, 1327]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 13, 12, 19, 22, 21, 18, 6]
episode: 503 -> reward: -124.99999999998147, steps:78048, time-elasped: 106042.92s
-> berries picked: 121 of 800 | patches-visited: [1, 7] | positive-in-buffer: 16162 | amount-filled: 100.00%
	| epsilon: 0.181392322572123
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [794, 2379, 2113, 2115, 2527, 3071, 1833, 1330]
	| approx positives in sample 512: 160
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 19, 7, 22, 29, 39, 21, 15]
episode: 504 -> reward: -124.99999999999203, steps:52224, time-elasped: 106196.78s
-> berries picked: 14 of 800 | patches-visited: [4] | positive-in-buffer: 16033 | amount-filled: 100.00%
	| epsilon: 0.1810277648020503
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [788, 2344, 2063, 2120, 2512, 3080, 1806, 1320]
	| approx positives in sample 512: 48
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 5, 10, 3, 5, 16, 4, 2]
episode: 505 -> reward: -124.99999999999255, steps:68736, time-elasped: 106442.42s
-> berries picked: 74 of 800 | patches-visited: [4] | positive-in-buffer: 15672 | amount-filled: 100.00%
	| epsilon: 0.18066393971110004
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [762, 2269, 2008, 2064, 2406, 3075, 1797, 1291]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 23, 12, 19, 15, 27, 11, 5]
episode: 506 -> reward: -124.99999999999183, steps:62304, time-elasped: 106635.73s
-> berries picked: 58 of 800 | patches-visited: [9] | positive-in-buffer: 15832 | amount-filled: 100.00%
	| epsilon: 0.180300845826752
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [784, 2262, 2051, 2085, 2436, 3097, 1811, 1306]
	| approx positives in sample 512: 59
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 5, 8, 10, 7, 14, 4, 8]
episode: 507 -> reward: -124.99999999999167, steps:67008, time-elasped: 106861.80s
-> berries picked: 80 of 800 | patches-visited: [4] | positive-in-buffer: 15822 | amount-filled: 100.00%
	| epsilon: 0.1799384816794453
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [799, 2232, 2036, 2134, 2406, 3110, 1780, 1325]
	| approx positives in sample 512: 169
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 18, 32, 22, 21, 29, 17, 17]
episode: 508 -> reward: -124.99999999999203, steps:60768, time-elasped: 107051.30s
-> berries picked: 50 of 800 | patches-visited: [1] | positive-in-buffer: 15933 | amount-filled: 100.00%
	| epsilon: 0.1795768458025727
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [814, 2240, 2066, 2131, 2417, 3124, 1824, 1317]
	| approx positives in sample 512: 62
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 8, 10, 6, 7, 11, 12, 6]
episode: 509 -> reward: -124.99999999999193, steps:66912, time-elasped: 107252.54s
-> berries picked: 80 of 800 | patches-visited: [9] | positive-in-buffer: 15878 | amount-filled: 100.00%
	| epsilon: 0.17921593673247438
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [783, 2244, 2066, 2119, 2429, 3096, 1834, 1307]
	| approx positives in sample 512: 175
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 20, 14, 33, 26, 39, 24, 14]
episode: 510 -> reward: -124.9999999999933, steps:80832, time-elasped: 107513.23s
-> berries picked: 142 of 800 | patches-visited: [1, 4] | positive-in-buffer: 16241 | amount-filled: 100.00%
	| epsilon: 0.17885575300843226
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [826, 2289, 2181, 2147, 2464, 3126, 1885, 1323]
	| approx positives in sample 512: 75
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 14, 8, 12, 8, 13, 10, 4]
episode: 511 -> reward: -124.99999999999183, steps:62688, time-elasped: 107713.85s
-> berries picked: 61 of 800 | patches-visited: [6] | positive-in-buffer: 16310 | amount-filled: 100.00%
	| epsilon: 0.1784962931726638
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [824, 2249, 2155, 2155, 2493, 3147, 1937, 1350]
	| approx positives in sample 512: 60
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 5, 7, 9, 9, 9, 11, 5]
episode: 512 -> reward: -124.999999999992, steps:64896, time-elasped: 107925.74s
-> berries picked: 74 of 800 | patches-visited: [4] | positive-in-buffer: 15691 | amount-filled: 100.00%
	| epsilon: 0.17813755577031648
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [771, 2159, 2083, 2074, 2416, 3047, 1848, 1293]
	| approx positives in sample 512: 56
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 3, 8, 7, 9, 17, 4, 4]
episode: 513 -> reward: -124.99999999999137, steps:68256, time-elasped: 108116.97s
-> berries picked: 70 of 800 | patches-visited: [0, 5] | positive-in-buffer: 15217 | amount-filled: 100.00%
	| epsilon: 0.17777953934946158
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [743, 2050, 2019, 2033, 2367, 2942, 1787, 1276]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 16, 5, 21, 17, 26, 16, 12]
episode: 514 -> reward: -124.99999999999204, steps:64128, time-elasped: 108296.72s
-> berries picked: 68 of 800 | patches-visited: [4] | positive-in-buffer: 15389 | amount-filled: 100.00%
	| epsilon: 0.17742224246108845
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [745, 2086, 2081, 2069, 2368, 2949, 1804, 1287]
	| approx positives in sample 512: 45
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 9, 4, 5, 4, 9, 5, 6]
episode: 515 -> reward: -124.9999999999866, steps:66528, time-elasped: 108530.81s
-> berries picked: 67 of 800 | patches-visited: [1, 6] | positive-in-buffer: 15437 | amount-filled: 100.00%
	| epsilon: 0.17706566365909865
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [782, 2063, 2074, 2084, 2334, 3009, 1819, 1272]
	| approx positives in sample 512: 194
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 27, 31, 33, 25, 37, 18, 11]
episode: 516 -> reward: -124.99999999999169, steps:80160, time-elasped: 108788.53s
-> berries picked: 122 of 800 | patches-visited: [2, 7] | positive-in-buffer: 15714 | amount-filled: 100.00%
	| epsilon: 0.17670980150030005
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [797, 2149, 2136, 2109, 2380, 3019, 1832, 1292]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 12, 16, 17, 16, 16, 11, 8]
episode: 517 -> reward: -124.99999999999362, steps:69120, time-elasped: 108983.21s
-> berries picked: 72 of 800 | patches-visited: [2, 7] | positive-in-buffer: 15823 | amount-filled: 100.00%
	| epsilon: 0.17635465454440108
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [800, 2132, 2152, 2116, 2422, 3089, 1820, 1292]
	| approx positives in sample 512: 95
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 18, 11, 11, 15, 15, 14, 8]
episode: 518 -> reward: -124.99999999999089, steps:64416, time-elasped: 109206.74s
-> berries picked: 70 of 800 | patches-visited: [7] | positive-in-buffer: 16009 | amount-filled: 100.00%
	| epsilon: 0.17600022135400467
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [828, 2141, 2165, 2142, 2432, 3146, 1882, 1273]
	| approx positives in sample 512: 45
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 5, 5, 6, 8, 11, 2, 5]
episode: 519 -> reward: -124.99999999999464, steps:80160, time-elasped: 109481.36s
-> berries picked: 111 of 800 | patches-visited: [3, 4, 5, 9] | positive-in-buffer: 15690 | amount-filled: 100.00%
	| epsilon: 0.17564650049460276
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [834, 2083, 2128, 2093, 2385, 3102, 1875, 1190]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 14, 10, 14, 16, 26, 9, 10]
episode: 520 -> reward: -124.99999999999253, steps:52704, time-elasped: 109682.08s
-> berries picked: 15 of 800 | patches-visited: [2] | positive-in-buffer: 15700 | amount-filled: 100.00%
	| epsilon: 0.17529349053457027
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [847, 2074, 2124, 2090, 2381, 3105, 1888, 1191]
	| approx positives in sample 512: 44
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 8, 7, 5, 9, 7, 4, 2]
episode: 521 -> reward: -124.99999999999262, steps:62880, time-elasped: 109874.19s
-> berries picked: 51 of 800 | patches-visited: [9] | positive-in-buffer: 15565 | amount-filled: 100.00%
	| epsilon: 0.17494119004515934
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [817, 2044, 2115, 2084, 2352, 3055, 1890, 1208]
	| approx positives in sample 512: 53
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 9, 5, 3, 5, 16, 6, 5]
episode: 522 -> reward: -124.99999999999189, steps:56928, time-elasped: 110040.69s
-> berries picked: 30 of 800 | patches-visited: [0] | positive-in-buffer: 15587 | amount-filled: 100.00%
	| epsilon: 0.17458959760049358
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [817, 2063, 2102, 2084, 2366, 3065, 1877, 1213]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 8, 18, 23, 12, 28, 12, 7]
episode: 523 -> reward: -124.99999999999203, steps:48576, time-elasped: 110191.43s
-> berries picked: 2 of 800 | patches-visited: [9] | positive-in-buffer: 15576 | amount-filled: 100.00%
	| epsilon: 0.17423871177756237
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [817, 2058, 2102, 2081, 2367, 3062, 1876, 1213]
	| approx positives in sample 512: 84
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 14, 15, 13, 6, 14, 9, 6]
episode: 524 -> reward: -124.99999999999017, steps:65568, time-elasped: 110388.69s
-> berries picked: 70 of 800 | patches-visited: [6] | positive-in-buffer: 15866 | amount-filled: 100.00%
	| epsilon: 0.1738885311562149
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [860, 2108, 2101, 2151, 2375, 3108, 1908, 1255]
	| approx positives in sample 512: 47
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 5, 5, 8, 4, 14, 5, 4]
episode: 525 -> reward: -124.99999999999297, steps:55584, time-elasped: 110571.50s
-> berries picked: 24 of 800 | patches-visited: [6] | positive-in-buffer: 15007 | amount-filled: 100.00%
	| epsilon: 0.17353905431915456
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [779, 1969, 1995, 2038, 2290, 2971, 1761, 1204]
	| approx positives in sample 512: 172
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 25, 22, 19, 17, 36, 23, 16]
episode: 526 -> reward: -124.99999999998903, steps:58176, time-elasped: 110750.30s
-> berries picked: 37 of 800 | patches-visited: [0, 6] | positive-in-buffer: 15074 | amount-filled: 100.00%
	| epsilon: 0.1731902798519333
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [791, 1975, 2040, 2057, 2306, 2965, 1758, 1182]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 8, 18, 19, 12, 23, 15, 12]
episode: 527 -> reward: -124.99999999999206, steps:61344, time-elasped: 110964.20s
-> berries picked: 50 of 800 | patches-visited: [4] | positive-in-buffer: 15236 | amount-filled: 100.00%
	| epsilon: 0.17284220634294573
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [794, 2032, 2053, 2073, 2310, 2999, 1768, 1207]
	| approx positives in sample 512: 53
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 8, 3, 5, 8, 18, 4, 5]
episode: 528 -> reward: -124.99999999999055, steps:65664, time-elasped: 111163.63s
-> berries picked: 60 of 800 | patches-visited: [0, 1] | positive-in-buffer: 15369 | amount-filled: 100.00%
	| epsilon: 0.17249483238342336
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [787, 2057, 2061, 2085, 2342, 2985, 1777, 1275]
	| approx positives in sample 512: 54
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 6, 1, 9, 14, 10, 6, 5]
episode: 529 -> reward: -124.99999999999207, steps:61920, time-elasped: 111328.62s
-> berries picked: 44 of 800 | patches-visited: [1] | positive-in-buffer: 14941 | amount-filled: 100.00%
	| epsilon: 0.1721481565674292
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [757, 1973, 1975, 2054, 2308, 2914, 1711, 1249]
	| approx positives in sample 512: 62
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7] [9, 10, 10, 9, 10, 6, 8]
episode: 530 -> reward: -124.99999999999203, steps:51648, time-elasped: 111466.02s
-> berries picked: 13 of 800 | patches-visited: [3] | positive-in-buffer: 14951 | amount-filled: 100.00%
	| epsilon: 0.17180217749185178
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [759, 1979, 1980, 2059, 2307, 2916, 1711, 1240]
	| approx positives in sample 512: 58
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 8, 6, 12, 6, 10, 5, 6]
episode: 531 -> reward: -124.99999999998231, steps:87936, time-elasped: 111773.79s
-> berries picked: 145 of 800 | patches-visited: [3, 5, 8] | positive-in-buffer: 15460 | amount-filled: 100.00%
	| epsilon: 0.1714568937563995
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [811, 2046, 2050, 2118, 2344, 3026, 1780, 1285]
	| approx positives in sample 512: 53
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 6, 6, 9, 9, 8, 6, 6]
episode: 532 -> reward: -124.99999999999211, steps:69888, time-elasped: 111977.84s
-> berries picked: 76 of 800 | patches-visited: [3, 7] | positive-in-buffer: 15124 | amount-filled: 100.00%
	| epsilon: 0.17111230396359514
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [785, 1942, 2012, 2095, 2343, 3019, 1726, 1202]
	| approx positives in sample 512: 91
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 7, 9, 13, 18, 16, 12, 9]
episode: 533 -> reward: -124.999999999992, steps:59808, time-elasped: 112157.43s
-> berries picked: 45 of 800 | patches-visited: [4] | positive-in-buffer: 15227 | amount-filled: 100.00%
	| epsilon: 0.1707684067187701
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [818, 1975, 2013, 2094, 2360, 3031, 1736, 1200]
	| approx positives in sample 512: 78
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 8, 10, 11, 11, 17, 12, 7]
episode: 534 -> reward: -124.99999999999481, steps:79200, time-elasped: 112411.52s
-> berries picked: 108 of 800 | patches-visited: [4, 7, 8] | positive-in-buffer: 15581 | amount-filled: 100.00%
	| epsilon: 0.17042520063005864
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [817, 2030, 2069, 2144, 2443, 3045, 1763, 1270]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 14, 12, 7, 15, 25, 16, 16]
episode: 535 -> reward: -124.99999999999136, steps:82176, time-elasped: 112710.67s
-> berries picked: 110 of 800 | patches-visited: [1, 7, 8] | positive-in-buffer: 15868 | amount-filled: 100.00%
	| epsilon: 0.17008268430839246
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [884, 2079, 2110, 2239, 2441, 3070, 1774, 1271]
	| approx positives in sample 512: 73
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 11, 9, 10, 11, 19, 5, 5]
episode: 536 -> reward: -124.99999999999227, steps:59712, time-elasped: 112913.35s
-> berries picked: 43 of 800 | patches-visited: [6] | positive-in-buffer: 15618 | amount-filled: 100.00%
	| epsilon: 0.16974085636749492
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [867, 2040, 2089, 2212, 2395, 3034, 1739, 1242]
	| approx positives in sample 512: 80
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 6, 14, 12, 16, 17, 4, 8]
episode: 537 -> reward: -124.99999999999203, steps:51072, time-elasped: 113049.66s
-> berries picked: 9 of 800 | patches-visited: [0] | positive-in-buffer: 15436 | amount-filled: 100.00%
	| epsilon: 0.16939971542387558
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [849, 1990, 2047, 2208, 2387, 3003, 1729, 1223]
	| approx positives in sample 512: 56
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 8, 8, 8, 5, 12, 10, 4]
episode: 538 -> reward: -124.99999999998866, steps:75936, time-elasped: 113312.71s
-> berries picked: 104 of 800 | patches-visited: [3, 4, 7] | positive-in-buffer: 15438 | amount-filled: 100.00%
	| epsilon: 0.1690592600968243
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [827, 2006, 2046, 2203, 2472, 2969, 1718, 1197]
	| approx positives in sample 512: 39
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 2, 5, 7, 6, 9, 3, 4]
episode: 539 -> reward: -124.99999999999207, steps:50112, time-elasped: 113468.47s
-> berries picked: 6 of 800 | patches-visited: [4] | positive-in-buffer: 14804 | amount-filled: 100.00%
	| epsilon: 0.16871948900840605
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [780, 1881, 1950, 2068, 2385, 2883, 1675, 1182]
	| approx positives in sample 512: 50
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 8, 6, 6, 8, 7, 6, 4]
episode: 540 -> reward: -124.99999999999196, steps:49632, time-elasped: 113593.09s
-> berries picked: 5 of 800 | patches-visited: [1] | positive-in-buffer: 14808 | amount-filled: 100.00%
	| epsilon: 0.16838040078345515
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [779, 1881, 1950, 2065, 2394, 2882, 1675, 1182]
	| approx positives in sample 512: 69
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 5, 11, 8, 15, 8, 6, 11]
episode: 541 -> reward: -124.99999999999326, steps:72672, time-elasped: 113791.96s
-> berries picked: 85 of 800 | patches-visited: [4, 6, 7] | positive-in-buffer: 15026 | amount-filled: 100.00%
	| epsilon: 0.16804199404956946
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [796, 1907, 1969, 2122, 2400, 2903, 1710, 1219]
	| approx positives in sample 512: 64
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 8, 5, 8, 12, 10, 10, 9]
episode: 542 -> reward: -124.99999999999208, steps:62976, time-elasped: 113956.64s
-> berries picked: 55 of 800 | patches-visited: [5] | positive-in-buffer: 15153 | amount-filled: 100.00%
	| epsilon: 0.16770426743710534
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [789, 1911, 1968, 2151, 2432, 2950, 1723, 1229]
	| approx positives in sample 512: 47
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 6, 5, 5, 5, 14, 7, 2]
episode: 543 -> reward: -124.99999999999503, steps:77664, time-elasped: 114191.83s
-> berries picked: 104 of 800 | patches-visited: [1, 2, 8] | positive-in-buffer: 15196 | amount-filled: 100.00%
	| epsilon: 0.1673672195791717
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [819, 1920, 1982, 2158, 2400, 2966, 1703, 1248]
	| approx positives in sample 512: 177
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 22, 21, 21, 25, 37, 25, 18]
episode: 544 -> reward: -124.99999999999203, steps:53088, time-elasped: 114314.94s
-> berries picked: 19 of 800 | patches-visited: [6] | positive-in-buffer: 15218 | amount-filled: 100.00%
	| epsilon: 0.1670308491116245
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [824, 1922, 1979, 2159, 2421, 2977, 1699, 1237]
	| approx positives in sample 512: 56
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 5, 4, 10, 13, 9, 11, 1]
episode: 545 -> reward: -124.99999999999325, steps:58464, time-elasped: 114478.69s
-> berries picked: 30 of 800 | patches-visited: [3, 7] | positive-in-buffer: 14924 | amount-filled: 100.00%
	| epsilon: 0.1666951546730615
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [799, 1884, 1946, 2147, 2357, 2931, 1647, 1213]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 12, 9, 13, 17, 26, 5, 10]
episode: 546 -> reward: -124.99999999998376, steps:73248, time-elasped: 114680.71s
-> berries picked: 96 of 800 | patches-visited: [1, 2] | positive-in-buffer: 15255 | amount-filled: 100.00%
	| epsilon: 0.1663601349048165
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [847, 1901, 2065, 2179, 2392, 2971, 1669, 1231]
	| approx positives in sample 512: 56
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 8, 5, 12, 8, 13, 6, 3]
episode: 547 -> reward: -124.9999999999921, steps:61536, time-elasped: 114855.54s
-> berries picked: 49 of 800 | patches-visited: [5] | positive-in-buffer: 15324 | amount-filled: 100.00%
	| epsilon: 0.1660257884509539
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [853, 1893, 2043, 2180, 2408, 3006, 1707, 1234]
	| approx positives in sample 512: 55
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 7, 7, 9, 11, 4, 8, 5]
episode: 548 -> reward: -124.9999999999922, steps:59616, time-elasped: 115029.68s
-> berries picked: 40 of 800 | patches-visited: [5] | positive-in-buffer: 15399 | amount-filled: 100.00%
	| epsilon: 0.16569211395826317
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [845, 1919, 2022, 2203, 2427, 3035, 1706, 1242]
	| approx positives in sample 512: 75
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7] [13, 10, 15, 10, 15, 5, 7]
episode: 549 -> reward: -124.99999999999278, steps:61440, time-elasped: 115195.01s
-> berries picked: 39 of 800 | patches-visited: [2, 7] | positive-in-buffer: 15530 | amount-filled: 100.00%
	| epsilon: 0.16535911007625353
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [854, 1916, 2048, 2235, 2461, 3028, 1719, 1269]
	| approx positives in sample 512: 58
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 8, 9, 7, 10, 11, 5, 4]
episode: 550 -> reward: -124.99999999999342, steps:72096, time-elasped: 115432.15s
-> berries picked: 89 of 800 | patches-visited: [5, 6] | positive-in-buffer: 15662 | amount-filled: 100.00%
	| epsilon: 0.1650267754571484
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [876, 1933, 2086, 2258, 2469, 3034, 1726, 1280]
	| approx positives in sample 512: 77
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 10, 8, 14, 10, 19, 9, 4]
episode: 551 -> reward: -124.99999999998634, steps:65856, time-elasped: 115648.04s
-> berries picked: 68 of 800 | patches-visited: [3] | positive-in-buffer: 15810 | amount-filled: 100.00%
	| epsilon: 0.16469510875587978
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [873, 1951, 2102, 2265, 2499, 3074, 1778, 1268]
	| approx positives in sample 512: 38
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6] [1, 3, 8, 5, 10, 6, 5]
episode: 552 -> reward: -124.99999999999206, steps:56352, time-elasped: 115789.43s
-> berries picked: 27 of 800 | patches-visited: [9] | positive-in-buffer: 14839 | amount-filled: 100.00%
	| epsilon: 0.16436410863008308
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [813, 1784, 1882, 2146, 2381, 2934, 1676, 1223]
	| approx positives in sample 512: 151
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 23, 24, 24, 25, 25, 18, 7]
episode: 553 -> reward: -124.99999999998884, steps:99744, time-elasped: 116110.76s
-> berries picked: 216 of 800 | patches-visited: [2, 5, 7] | positive-in-buffer: 15483 | amount-filled: 100.00%
	| epsilon: 0.16403377374009154
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [842, 1847, 1913, 2266, 2521, 3033, 1746, 1315]
	| approx positives in sample 512: 190
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 28, 27, 26, 30, 33, 23, 9]
episode: 554 -> reward: -124.99999999999233, steps:72576, time-elasped: 116317.74s
-> berries picked: 93 of 800 | patches-visited: [1, 8] | positive-in-buffer: 15728 | amount-filled: 100.00%
	| epsilon: 0.16370410274893082
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [866, 1863, 2023, 2317, 2546, 3033, 1763, 1317]
	| approx positives in sample 512: 52
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 10, 7, 8, 6, 9, 5, 3]
episode: 555 -> reward: -124.99999999999127, steps:56640, time-elasped: 116460.80s
-> berries picked: 27 of 800 | patches-visited: [4] | positive-in-buffer: 15629 | amount-filled: 100.00%
	| epsilon: 0.16337509432231356
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [870, 1842, 2028, 2303, 2536, 3015, 1739, 1296]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 18, 16, 22, 24, 31, 12, 7]
episode: 556 -> reward: -124.99999999999169, steps:66336, time-elasped: 116629.60s
-> berries picked: 60 of 800 | patches-visited: [1, 4] | positive-in-buffer: 15795 | amount-filled: 100.00%
	| epsilon: 0.16304674712863407
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [901, 1859, 2025, 2376, 2550, 3047, 1739, 1298]
	| approx positives in sample 512: 226
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 36, 27, 37, 30, 39, 21, 24]
episode: 557 -> reward: -124.99999999999021, steps:56064, time-elasped: 116789.57s
-> berries picked: 27 of 800 | patches-visited: [2] | positive-in-buffer: 15845 | amount-filled: 100.00%
	| epsilon: 0.16271905983896287
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [894, 1875, 2036, 2390, 2566, 3047, 1733, 1304]
	| approx positives in sample 512: 170
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 15, 21, 26, 30, 26, 21, 20]
episode: 558 -> reward: -124.999999999992, steps:62400, time-elasped: 116934.97s
-> berries picked: 51 of 800 | patches-visited: [4] | positive-in-buffer: 15928 | amount-filled: 100.00%
	| epsilon: 0.16239203112704131
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [900, 1875, 2043, 2388, 2590, 3080, 1742, 1310]
	| approx positives in sample 512: 62
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 9, 10, 11, 7, 13, 7, 4]
episode: 559 -> reward: -124.99999999998484, steps:67008, time-elasped: 117122.46s
-> berries picked: 85 of 800 | patches-visited: [4, 5] | positive-in-buffer: 15763 | amount-filled: 100.00%
	| epsilon: 0.16206565966927625
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [871, 1841, 1982, 2390, 2601, 3079, 1722, 1277]
	| approx positives in sample 512: 174
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 17, 19, 21, 32, 31, 30, 15]
episode: 560 -> reward: -124.99999999999208, steps:63840, time-elasped: 117307.68s
-> berries picked: 61 of 800 | patches-visited: [2] | positive-in-buffer: 15857 | amount-filled: 100.00%
	| epsilon: 0.1617399441447347
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [881, 1841, 1993, 2401, 2623, 3101, 1733, 1284]
	| approx positives in sample 512: 37
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 4, 2, 12, 10, 3, 4, 1]
episode: 561 -> reward: -124.99999999999272, steps:80736, time-elasped: 117597.11s
-> berries picked: 129 of 800 | patches-visited: [3, 9] | positive-in-buffer: 15775 | amount-filled: 100.00%
	| epsilon: 0.16141488323513833
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [865, 1866, 1972, 2373, 2580, 3067, 1749, 1303]
	| approx positives in sample 512: 90
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 10, 10, 14, 11, 23, 5, 10]
episode: 562 -> reward: -124.99999999999221, steps:62688, time-elasped: 117768.42s
-> berries picked: 61 of 800 | patches-visited: [3] | positive-in-buffer: 15887 | amount-filled: 100.00%
	| epsilon: 0.1610904756248584
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [892, 1897, 1976, 2395, 2585, 3082, 1749, 1311]
	| approx positives in sample 512: 57
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 8, 4, 15, 6, 10, 5, 5]
episode: 563 -> reward: -124.99999999999234, steps:63744, time-elasped: 117980.83s
-> berries picked: 61 of 800 | patches-visited: [1, 5] | positive-in-buffer: 15776 | amount-filled: 100.00%
	| epsilon: 0.1607667200009102
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [890, 1843, 1952, 2379, 2545, 3115, 1764, 1288]
	| approx positives in sample 512: 52
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 6, 6, 4, 17, 5, 9, 2]
episode: 564 -> reward: -124.99999999999356, steps:58944, time-elasped: 118170.94s
-> berries picked: 40 of 800 | patches-visited: [5, 9] | positive-in-buffer: 15529 | amount-filled: 100.00%
	| epsilon: 0.16044361505294788
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [877, 1866, 1911, 2347, 2535, 3047, 1707, 1239]
	| approx positives in sample 512: 93
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 11, 10, 17, 17, 15, 11, 7]
episode: 565 -> reward: -124.99999999999126, steps:64224, time-elasped: 118358.87s
-> berries picked: 76 of 800 | patches-visited: [0] | positive-in-buffer: 15744 | amount-filled: 100.00%
	| epsilon: 0.16012115947325897
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [880, 1878, 2000, 2356, 2554, 3110, 1722, 1244]
	| approx positives in sample 512: 50
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 9, 10, 6, 10, 7, 3, 2]
episode: 566 -> reward: -124.99999999998269, steps:73824, time-elasped: 118631.13s
-> berries picked: 84 of 800 | patches-visited: [1, 3, 7] | positive-in-buffer: 15690 | amount-filled: 100.00%
	| epsilon: 0.15979935195675937
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [878, 1811, 1909, 2467, 2566, 3038, 1762, 1259]
	| approx positives in sample 512: 68
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 8, 6, 16, 10, 15, 3, 7]
episode: 567 -> reward: -124.99999999999294, steps:84000, time-elasped: 118893.20s
-> berries picked: 160 of 800 | patches-visited: [4, 8] | positive-in-buffer: 15998 | amount-filled: 100.00%
	| epsilon: 0.15947819120098786
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [862, 1883, 1945, 2487, 2664, 3046, 1809, 1302]
	| approx positives in sample 512: 56
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 8, 6, 9, 11, 11, 2, 4]
episode: 568 -> reward: -124.99999999999166, steps:57696, time-elasped: 119079.44s
-> berries picked: 38 of 800 | patches-visited: [9] | positive-in-buffer: 15999 | amount-filled: 100.00%
	| epsilon: 0.15915767590610072
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [863, 1886, 1995, 2470, 2663, 3039, 1789, 1294]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 17, 15, 22, 18, 24, 14, 7]
episode: 569 -> reward: -124.99999999999203, steps:52416, time-elasped: 119202.45s
-> berries picked: 13 of 800 | patches-visited: [7] | positive-in-buffer: 16011 | amount-filled: 100.00%
	| epsilon: 0.15883780477486686
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [863, 1906, 1995, 2482, 2655, 3028, 1789, 1293]
	| approx positives in sample 512: 65
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 5, 12, 11, 10, 9, 8, 9]
episode: 570 -> reward: -124.99999999999204, steps:52608, time-elasped: 119343.45s
-> berries picked: 14 of 800 | patches-visited: [4] | positive-in-buffer: 15616 | amount-filled: 100.00%
	| epsilon: 0.15851857651266218
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [843, 1860, 1928, 2449, 2603, 2967, 1729, 1237]
	| approx positives in sample 512: 56
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 9, 8, 10, 3, 10, 5, 6]
episode: 571 -> reward: -124.99999999999204, steps:56640, time-elasped: 119560.09s
-> berries picked: 30 of 800 | patches-visited: [7] | positive-in-buffer: 15557 | amount-filled: 100.00%
	| epsilon: 0.15819998982746453
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [825, 1850, 1906, 2453, 2600, 2964, 1713, 1246]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 9, 18, 29, 24, 23, 15, 9]
episode: 572 -> reward: -124.9999999999921, steps:97728, time-elasped: 119883.54s
-> berries picked: 175 of 800 | patches-visited: [0, 2, 6, 9] | positive-in-buffer: 15980 | amount-filled: 100.00%
	| epsilon: 0.1578820434298484
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [869, 1905, 1964, 2543, 2625, 3018, 1747, 1309]
	| approx positives in sample 512: 44
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 2, 3, 14, 5, 10, 4, 3]
episode: 573 -> reward: -124.99999999999314, steps:60768, time-elasped: 120082.66s
-> berries picked: 44 of 800 | patches-visited: [2] | positive-in-buffer: 15474 | amount-filled: 100.00%
	| epsilon: 0.1575647360329798
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [820, 1818, 1888, 2466, 2586, 2932, 1698, 1266]
	| approx positives in sample 512: 67
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 5, 6, 16, 7, 14, 11, 5]
episode: 574 -> reward: -124.99999999999204, steps:56160, time-elasped: 120277.58s
-> berries picked: 27 of 800 | patches-visited: [8] | positive-in-buffer: 15596 | amount-filled: 100.00%
	| epsilon: 0.157248066352611
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [847, 1866, 1906, 2479, 2600, 2931, 1703, 1264]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 14, 13, 20, 19, 24, 21, 14]
episode: 575 -> reward: -124.99999999998934, steps:79872, time-elasped: 120527.53s
-> berries picked: 128 of 800 | patches-visited: [2, 5] | positive-in-buffer: 15988 | amount-filled: 100.00%
	| epsilon: 0.15693203310707513
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [890, 1937, 1966, 2515, 2654, 3007, 1729, 1290]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 19, 13, 20, 20, 25, 8, 14]
episode: 576 -> reward: -124.99999999999226, steps:53568, time-elasped: 120729.12s
-> berries picked: 17 of 800 | patches-visited: [2] | positive-in-buffer: 15942 | amount-filled: 100.00%
	| epsilon: 0.1566166350172814
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [878, 1926, 1954, 2534, 2637, 2998, 1726, 1289]
	| approx positives in sample 512: 35
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 7, 1, 11, 4, 5, 2, 4]
episode: 577 -> reward: -124.99999999999173, steps:57888, time-elasped: 120917.32s
-> berries picked: 32 of 800 | patches-visited: [5, 9] | positive-in-buffer: 15559 | amount-filled: 100.00%
	| epsilon: 0.15630187080670968
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [857, 1848, 1887, 2496, 2570, 2957, 1706, 1238]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 16, 12, 22, 10, 23, 12, 5]
episode: 578 -> reward: -124.99999999999221, steps:66144, time-elasped: 121101.35s
-> berries picked: 63 of 800 | patches-visited: [1] | positive-in-buffer: 15721 | amount-filled: 100.00%
	| epsilon: 0.15598773920140518
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [859, 1849, 1887, 2563, 2581, 2998, 1750, 1234]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 24, 29, 35, 49, 36, 25, 13]
episode: 579 -> reward: -124.9999999999919, steps:64224, time-elasped: 121276.64s
-> berries picked: 63 of 800 | patches-visited: [3] | positive-in-buffer: 15888 | amount-filled: 100.00%
	| epsilon: 0.1556742389299737
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [865, 1884, 1913, 2572, 2604, 3010, 1763, 1277]
	| approx positives in sample 512: 48
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 4, 4, 10, 9, 6, 9, 2]
episode: 580 -> reward: -124.99999999999008, steps:61728, time-elasped: 121481.18s
-> berries picked: 50 of 800 | patches-visited: [1] | positive-in-buffer: 15767 | amount-filled: 100.00%
	| epsilon: 0.15536136872357612
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [844, 1826, 1918, 2575, 2610, 2969, 1731, 1294]
	| approx positives in sample 512: 65
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 11, 4, 14, 10, 15, 5, 2]
episode: 581 -> reward: -124.99999999999187, steps:60096, time-elasped: 121645.58s
-> berries picked: 41 of 800 | patches-visited: [1, 5] | positive-in-buffer: 15850 | amount-filled: 100.00%
	| epsilon: 0.15504912731592344
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [867, 1855, 1900, 2572, 2624, 2968, 1739, 1325]
	| approx positives in sample 512: 73
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 8, 7, 12, 13, 9, 11, 8]
episode: 582 -> reward: -124.99999999999217, steps:61632, time-elasped: 121827.84s
-> berries picked: 49 of 800 | patches-visited: [8] | positive-in-buffer: 15982 | amount-filled: 100.00%
	| epsilon: 0.15473751344327158
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [860, 1928, 1900, 2589, 2633, 2996, 1758, 1318]
	| approx positives in sample 512: 66
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 16, 11, 9, 9, 9, 7, 3]
episode: 583 -> reward: -124.99999999998933, steps:73536, time-elasped: 122056.89s
-> berries picked: 100 of 800 | patches-visited: [1, 4] | positive-in-buffer: 16157 | amount-filled: 100.00%
	| epsilon: 0.15442652584441635
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [892, 1942, 1905, 2643, 2640, 3051, 1755, 1329]
	| approx positives in sample 512: 49
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 7, 8, 7, 9, 8, 3, 6]
episode: 584 -> reward: -124.99999999999183, steps:65088, time-elasped: 122243.43s
-> berries picked: 61 of 800 | patches-visited: [1] | positive-in-buffer: 15810 | amount-filled: 100.00%
	| epsilon: 0.15411616326068833
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [921, 1888, 1870, 2575, 2578, 2967, 1716, 1295]
	| approx positives in sample 512: 44
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 6, 5, 7, 7, 6, 5, 5]
episode: 585 -> reward: -124.99999999999201, steps:55680, time-elasped: 122393.81s
-> berries picked: 23 of 800 | patches-visited: [5] | positive-in-buffer: 15165 | amount-filled: 100.00%
	| epsilon: 0.1538064244359476
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [865, 1818, 1778, 2465, 2520, 2856, 1659, 1204]
	| approx positives in sample 512: 186
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 33, 19, 27, 41, 27, 19, 13]
episode: 586 -> reward: -124.99999999999206, steps:65856, time-elasped: 122581.13s
-> berries picked: 71 of 800 | patches-visited: [8] | positive-in-buffer: 15414 | amount-filled: 100.00%
	| epsilon: 0.15349730811657894
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [865, 1899, 1783, 2498, 2554, 2902, 1670, 1243]
	| approx positives in sample 512: 43
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 8, 6, 7, 5, 8, 4, 3]
episode: 587 -> reward: -124.99999999998522, steps:84096, time-elasped: 122862.77s
-> berries picked: 147 of 800 | patches-visited: [2, 6] | positive-in-buffer: 15510 | amount-filled: 100.00%
	| epsilon: 0.1531888130514866
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [854, 1831, 1811, 2525, 2550, 2969, 1748, 1222]
	| approx positives in sample 512: 50
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 10, 6, 5, 10, 9, 4, 3]
episode: 588 -> reward: -124.99999999999208, steps:64992, time-elasped: 123052.74s
-> berries picked: 74 of 800 | patches-visited: [0] | positive-in-buffer: 15584 | amount-filled: 100.00%
	| epsilon: 0.15288093799208913
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [856, 1870, 1812, 2565, 2579, 2951, 1730, 1221]
	| approx positives in sample 512: 48
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 6, 6, 5, 13, 6, 6, 5]
episode: 589 -> reward: -124.999999999992, steps:67104, time-elasped: 123242.84s
-> berries picked: 76 of 800 | patches-visited: [9] | positive-in-buffer: 15415 | amount-filled: 100.00%
	| epsilon: 0.15257368169231458
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [833, 1835, 1877, 2538, 2548, 2924, 1655, 1205]
	| approx positives in sample 512: 164
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 26, 17, 28, 18, 30, 21, 13]
episode: 590 -> reward: -124.99999999999203, steps:49248, time-elasped: 123375.03s
-> berries picked: 5 of 800 | patches-visited: [9] | positive-in-buffer: 15428 | amount-filled: 100.00%
	| epsilon: 0.15226704290859527
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [832, 1855, 1874, 2533, 2546, 2919, 1658, 1211]
	| approx positives in sample 512: 70
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 9, 6, 16, 11, 11, 6, 5]
episode: 591 -> reward: -124.99999999999193, steps:68832, time-elasped: 123571.48s
-> berries picked: 79 of 800 | patches-visited: [7, 9] | positive-in-buffer: 15676 | amount-filled: 100.00%
	| epsilon: 0.15196102039986287
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [827, 1895, 1880, 2569, 2591, 2991, 1664, 1259]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 14, 17, 22, 11, 19, 20, 8]
episode: 592 -> reward: -124.99999999999189, steps:67776, time-elasped: 123763.06s
-> berries picked: 77 of 800 | patches-visited: [9] | positive-in-buffer: 15830 | amount-filled: 100.00%
	| epsilon: 0.15165561292754318
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [829, 1905, 1887, 2590, 2605, 3043, 1694, 1277]
	| approx positives in sample 512: 145
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 22, 16, 26, 24, 26, 10, 13]
episode: 593 -> reward: -124.99999999999153, steps:50688, time-elasped: 123952.45s
-> berries picked: 12 of 800 | patches-visited: [9] | positive-in-buffer: 15842 | amount-filled: 100.00%
	| epsilon: 0.15135081925555138
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [836, 1909, 1882, 2598, 2605, 3039, 1696, 1277]
	| approx positives in sample 512: 52
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 3, 8, 7, 7, 12, 9, 4]
episode: 594 -> reward: -124.99999999999241, steps:73152, time-elasped: 124154.69s
-> berries picked: 92 of 800 | patches-visited: [8, 9] | positive-in-buffer: 15999 | amount-filled: 100.00%
	| epsilon: 0.15104663815028693
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [840, 1916, 1910, 2624, 2629, 3061, 1739, 1280]
	| approx positives in sample 512: 71
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7] [7, 12, 14, 13, 9, 8, 8]
episode: 595 -> reward: -124.99999999999204, steps:58848, time-elasped: 124362.57s
-> berries picked: 36 of 800 | patches-visited: [5] | positive-in-buffer: 15962 | amount-filled: 100.00%
	| epsilon: 0.15074306838062837
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [837, 1911, 1916, 2620, 2627, 3033, 1732, 1286]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 13, 12, 21, 21, 20, 10, 8]
episode: 596 -> reward: -124.99999999998535, steps:69312, time-elasped: 124584.47s
-> berries picked: 70 of 800 | patches-visited: [4, 7] | positive-in-buffer: 16166 | amount-filled: 100.00%
	| epsilon: 0.15044010871792868
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [884, 1958, 1902, 2679, 2623, 3073, 1764, 1283]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 14, 17, 25, 23, 14, 11, 4]
episode: 597 -> reward: -124.99999999998683, steps:74208, time-elasped: 124809.35s
-> berries picked: 91 of 800 | patches-visited: [4, 9] | positive-in-buffer: 16349 | amount-filled: 100.00%
	| epsilon: 0.15013775793601017
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [886, 1970, 1899, 2695, 2637, 3119, 1819, 1324]
	| approx positives in sample 512: 62
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7] [10, 6, 12, 8, 15, 5, 6]
episode: 598 -> reward: -124.99999999999204, steps:51360, time-elasped: 124985.25s
-> berries picked: 11 of 800 | patches-visited: [8] | positive-in-buffer: 15921 | amount-filled: 100.00%
	| epsilon: 0.1498360148111593
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [860, 1879, 1841, 2635, 2600, 3038, 1781, 1287]
	| approx positives in sample 512: 48
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 5, 4, 8, 12, 9, 3, 5]
episode: 599 -> reward: -124.99999999999169, steps:84768, time-elasped: 125240.15s
-> berries picked: 134 of 800 | patches-visited: [6, 8] | positive-in-buffer: 16361 | amount-filled: 100.00%
	| epsilon: 0.14953487812212207
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [902, 1911, 1905, 2729, 2641, 3149, 1820, 1304]
	| approx positives in sample 512: 48
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 10, 5, 9, 8, 7, 6, 2]
episode: 600 -> reward: -124.9999999999923, steps:64704, time-elasped: 125414.31s
-> berries picked: 59 of 800 | patches-visited: [4] | positive-in-buffer: 16242 | amount-filled: 100.00%
	| epsilon: 0.14923434665009894
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [894, 1930, 1875, 2697, 2630, 3138, 1786, 1292]
	| approx positives in sample 512: 43
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7] [4, 1, 12, 9, 6, 6, 5]
episode: 601 -> reward: -124.99999999999113, steps:59424, time-elasped: 125613.35s
-> berries picked: 52 of 800 | patches-visited: [4] | positive-in-buffer: 15736 | amount-filled: 100.00%
	| epsilon: 0.1489344191787398
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [860, 1883, 1806, 2611, 2570, 3027, 1736, 1243]
	| approx positives in sample 512: 99
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 13, 13, 12, 18, 22, 15, 3]
episode: 602 -> reward: -124.99999999999203, steps:49632, time-elasped: 125803.25s
-> berries picked: 5 of 800 | patches-visited: [0] | positive-in-buffer: 15695 | amount-filled: 100.00%
	| epsilon: 0.14863509449413917
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [857, 1867, 1812, 2602, 2568, 3015, 1728, 1246]
	| approx positives in sample 512: 79
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 10, 6, 17, 13, 14, 5, 10]
episode: 603 -> reward: -124.99999999999432, steps:100608, time-elasped: 126124.07s
-> berries picked: 200 of 800 | patches-visited: [0, 3, 7, 8] | positive-in-buffer: 16232 | amount-filled: 100.00%
	| epsilon: 0.14833637138483124
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [911, 1937, 1898, 2642, 2693, 3106, 1775, 1270]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 8, 13, 20, 30, 20, 18, 10]
episode: 604 -> reward: -124.99999999999176, steps:61920, time-elasped: 126297.34s
-> berries picked: 50 of 800 | patches-visited: [6] | positive-in-buffer: 16276 | amount-filled: 100.00%
	| epsilon: 0.14803824864178503
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [925, 1960, 1908, 2649, 2694, 3111, 1770, 1259]
	| approx positives in sample 512: 68
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6] [3, 11, 6, 10, 18, 13, 7]
episode: 605 -> reward: -124.99999999999204, steps:57120, time-elasped: 126463.82s
-> berries picked: 31 of 800 | patches-visited: [2] | positive-in-buffer: 16077 | amount-filled: 100.00%
	| epsilon: 0.14774072505839927
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [881, 1887, 1889, 2608, 2699, 3087, 1760, 1266]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 15, 12, 24, 21, 25, 10, 12]
episode: 606 -> reward: -124.99999999999201, steps:58080, time-elasped: 126644.27s
-> berries picked: 35 of 800 | patches-visited: [1, 2, 4] | positive-in-buffer: 16182 | amount-filled: 100.00%
	| epsilon: 0.1474437994304979
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [877, 1880, 1902, 2609, 2724, 3117, 1800, 1273]
	| approx positives in sample 512: 121
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 19, 12, 22, 13, 23, 14, 10]
episode: 607 -> reward: -124.99999999999203, steps:49152, time-elasped: 126762.52s
-> berries picked: 4 of 800 | patches-visited: [0] | positive-in-buffer: 16175 | amount-filled: 100.00%
	| epsilon: 0.14714747055632485
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [875, 1875, 1897, 2618, 2716, 3120, 1801, 1273]
	| approx positives in sample 512: 89
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 7, 10, 16, 14, 22, 8, 8]
episode: 608 -> reward: -124.99999999999154, steps:63456, time-elasped: 126965.30s
-> berries picked: 63 of 800 | patches-visited: [0] | positive-in-buffer: 16310 | amount-filled: 100.00%
	| epsilon: 0.14685173723653938
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [880, 1876, 1927, 2607, 2751, 3155, 1806, 1308]
	| approx positives in sample 512: 52
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 6, 9, 7, 11, 10, 1, 6]
episode: 609 -> reward: -124.99999999999217, steps:49632, time-elasped: 127111.70s
-> berries picked: 7 of 800 | patches-visited: [7] | positive-in-buffer: 15778 | amount-filled: 100.00%
	| epsilon: 0.14655659827421108
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [866, 1770, 1862, 2549, 2677, 3063, 1738, 1253]
	| approx positives in sample 512: 65
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 4, 5, 10, 7, 13, 11, 9]
episode: 610 -> reward: -124.99999999999207, steps:61728, time-elasped: 127268.49s
-> berries picked: 47 of 800 | patches-visited: [9] | positive-in-buffer: 15912 | amount-filled: 100.00%
	| epsilon: 0.14626205247481516
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [868, 1797, 1883, 2574, 2705, 3076, 1753, 1256]
	| approx positives in sample 512: 68
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 6, 10, 9, 13, 9, 9, 7]
episode: 611 -> reward: -124.99999999999208, steps:70176, time-elasped: 127472.79s
-> berries picked: 79 of 800 | patches-visited: [0, 1] | positive-in-buffer: 16132 | amount-filled: 100.00%
	| epsilon: 0.14596809864622756
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [905, 1838, 1923, 2602, 2704, 3077, 1830, 1253]
	| approx positives in sample 512: 91
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 13, 5, 13, 8, 21, 18, 8]
episode: 612 -> reward: -124.99999999999204, steps:59712, time-elasped: 127634.62s
-> berries picked: 41 of 800 | patches-visited: [4, 8] | positive-in-buffer: 16192 | amount-filled: 100.00%
	| epsilon: 0.14567473559872005
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [923, 1838, 1919, 2615, 2715, 3080, 1842, 1260]
	| approx positives in sample 512: 81
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 5, 14, 13, 15, 17, 10, 2]
episode: 613 -> reward: -124.9999999999896, steps:61536, time-elasped: 127830.95s
-> berries picked: 50 of 800 | patches-visited: [2] | positive-in-buffer: 16300 | amount-filled: 100.00%
	| epsilon: 0.14538196214495555
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [924, 1831, 1989, 2604, 2747, 3093, 1841, 1271]
	| approx positives in sample 512: 58
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 3, 12, 14, 8, 9, 7, 4]
episode: 614 -> reward: -124.99999999999194, steps:59424, time-elasped: 128060.14s
-> berries picked: 37 of 800 | patches-visited: [6, 9] | positive-in-buffer: 16186 | amount-filled: 100.00%
	| epsilon: 0.1450897770999833
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [901, 1826, 1963, 2585, 2740, 3116, 1814, 1241]
	| approx positives in sample 512: 93
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 13, 6, 13, 16, 19, 12, 9]
episode: 615 -> reward: -124.99999999999446, steps:67296, time-elasped: 128277.30s
-> berries picked: 74 of 800 | patches-visited: [0, 5] | positive-in-buffer: 16414 | amount-filled: 100.00%
	| epsilon: 0.14479817928123392
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [907, 1871, 1986, 2591, 2776, 3137, 1854, 1292]
	| approx positives in sample 512: 174
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 20, 25, 27, 27, 38, 13, 15]
episode: 616 -> reward: -124.99999999999253, steps:83328, time-elasped: 128545.32s
-> berries picked: 129 of 800 | patches-visited: [3, 6, 8] | positive-in-buffer: 16775 | amount-filled: 100.00%
	| epsilon: 0.14450716750851478
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [985, 1964, 2046, 2621, 2819, 3169, 1877, 1294]
	| approx positives in sample 512: 77
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 9, 7, 16, 10, 13, 5, 11]
episode: 617 -> reward: -124.99999999999203, steps:61056, time-elasped: 128714.86s
-> berries picked: 54 of 800 | patches-visited: [8] | positive-in-buffer: 16436 | amount-filled: 100.00%
	| epsilon: 0.14421674060400516
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [945, 1894, 1934, 2627, 2811, 3148, 1837, 1240]
	| approx positives in sample 512: 63
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 5, 12, 11, 9, 11, 6, 5]
episode: 618 -> reward: -124.99999999999177, steps:58560, time-elasped: 128903.31s
-> berries picked: 39 of 800 | patches-visited: [9] | positive-in-buffer: 16377 | amount-filled: 100.00%
	| epsilon: 0.1439268973922516
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [936, 1877, 1923, 2604, 2803, 3139, 1837, 1258]
	| approx positives in sample 512: 101
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 8, 13, 16, 14, 17, 14, 12]
episode: 619 -> reward: -124.99999999998897, steps:77184, time-elasped: 129161.95s
-> berries picked: 110 of 800 | patches-visited: [0, 8] | positive-in-buffer: 16688 | amount-filled: 100.00%
	| epsilon: 0.1436376367001628
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [985, 1947, 1947, 2727, 2811, 3172, 1852, 1247]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 30, 27, 33, 35, 42, 25, 26]
episode: 620 -> reward: -124.99999999999213, steps:58272, time-elasped: 129320.53s
-> berries picked: 33 of 800 | patches-visited: [3, 8] | positive-in-buffer: 16565 | amount-filled: 100.00%
	| epsilon: 0.14334895735700534
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [981, 1907, 1935, 2698, 2805, 3170, 1837, 1232]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 9, 14, 20, 12, 24, 16, 6]
episode: 621 -> reward: -124.99999999998838, steps:78816, time-elasped: 129610.76s
-> berries picked: 117 of 800 | patches-visited: [4, 8] | positive-in-buffer: 16879 | amount-filled: 100.00%
	| epsilon: 0.14306085819439862
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1002, 1934, 1955, 2709, 2872, 3212, 1936, 1259]
	| approx positives in sample 512: 160
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 27, 22, 35, 14, 28, 18, 11]
episode: 622 -> reward: -124.99999999999109, steps:80256, time-elasped: 129854.76s
-> berries picked: 113 of 800 | patches-visited: [3, 6, 7] | positive-in-buffer: 17085 | amount-filled: 100.00%
	| epsilon: 0.1427733380463102
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1076, 1949, 1996, 2724, 2921, 3236, 1915, 1268]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 15, 14, 15, 13, 27, 14, 8]
episode: 623 -> reward: -124.99999999999206, steps:54816, time-elasped: 130000.32s
-> berries picked: 21 of 800 | patches-visited: [6] | positive-in-buffer: 16958 | amount-filled: 100.00%
	| epsilon: 0.14248639574905114
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1053, 1930, 1971, 2728, 2899, 3215, 1889, 1273]
	| approx positives in sample 512: 49
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 8, 4, 8, 8, 10, 3, 5]
episode: 624 -> reward: -124.99999999999498, steps:79776, time-elasped: 130226.66s
-> berries picked: 123 of 800 | patches-visited: [1, 2] | positive-in-buffer: 16000 | amount-filled: 100.00%
	| epsilon: 0.14220003014127128
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [946, 1854, 1851, 2561, 2816, 3096, 1714, 1162]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 21, 14, 18, 25, 23, 14, 8]
episode: 625 -> reward: -124.999999999992, steps:65280, time-elasped: 130438.21s
-> berries picked: 72 of 800 | patches-visited: [0, 3] | positive-in-buffer: 16133 | amount-filled: 100.00%
	| epsilon: 0.1419142400639544
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [958, 1892, 1850, 2581, 2831, 3090, 1746, 1185]
	| approx positives in sample 512: 42
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 7, 5, 5, 9, 8, 4, 3]
episode: 626 -> reward: -124.99999999999255, steps:58848, time-elasped: 130645.95s
-> berries picked: 38 of 800 | patches-visited: [4, 5] | positive-in-buffer: 15539 | amount-filled: 100.00%
	| epsilon: 0.14162902436041375
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [905, 1849, 1736, 2477, 2741, 2994, 1690, 1147]
	| approx positives in sample 512: 80
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 6, 9, 12, 17, 20, 3, 8]
episode: 627 -> reward: -124.99999999999204, steps:52704, time-elasped: 130771.25s
-> berries picked: 16 of 800 | patches-visited: [2] | positive-in-buffer: 15562 | amount-filled: 100.00%
	| epsilon: 0.14134438187628723
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [910, 1853, 1741, 2473, 2744, 3003, 1693, 1145]
	| approx positives in sample 512: 52
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 9, 3, 11, 12, 8, 5, 2]
episode: 628 -> reward: -124.99999999999204, steps:60672, time-elasped: 130944.40s
-> berries picked: 50 of 800 | patches-visited: [0] | positive-in-buffer: 15641 | amount-filled: 100.00%
	| epsilon: 0.1410603114595328
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [907, 1859, 1756, 2460, 2801, 2997, 1699, 1162]
	| approx positives in sample 512: 69
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 8, 9, 8, 11, 15, 10, 6]
episode: 629 -> reward: -124.99999999998964, steps:83712, time-elasped: 131205.18s
-> berries picked: 145 of 800 | patches-visited: [0, 6, 7] | positive-in-buffer: 16051 | amount-filled: 100.00%
	| epsilon: 0.14077681196042358
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [977, 1920, 1815, 2537, 2824, 3078, 1703, 1197]
	| approx positives in sample 512: 68
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 11, 4, 13, 12, 14, 8, 4]
episode: 630 -> reward: -124.99999999999085, steps:75840, time-elasped: 131440.62s
-> berries picked: 103 of 800 | patches-visited: [0, 1] | positive-in-buffer: 16272 | amount-filled: 100.00%
	| epsilon: 0.1404938822315436
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1065, 1936, 1848, 2559, 2841, 3089, 1727, 1207]
	| approx positives in sample 512: 48
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 9, 6, 3, 9, 10, 4, 3]
episode: 631 -> reward: -124.99999999999184, steps:57888, time-elasped: 131618.16s
-> berries picked: 33 of 800 | patches-visited: [7] | positive-in-buffer: 15881 | amount-filled: 100.00%
	| epsilon: 0.1402115211277829
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1019, 1865, 1766, 2531, 2795, 3027, 1707, 1171]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 10, 9, 9, 21, 23, 13, 11]
episode: 632 -> reward: -124.99999999999275, steps:55584, time-elasped: 131796.81s
-> berries picked: 24 of 800 | patches-visited: [2, 8] | positive-in-buffer: 15946 | amount-filled: 100.00%
	| epsilon: 0.13992972750633276
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1004, 1863, 1781, 2544, 2821, 3040, 1704, 1189]
	| approx positives in sample 512: 206
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 29, 24, 37, 31, 36, 28, 10]
episode: 633 -> reward: -124.99999999999207, steps:54816, time-elasped: 131933.79s
-> berries picked: 19 of 800 | patches-visited: [1] | positive-in-buffer: 15997 | amount-filled: 100.00%
	| epsilon: 0.13964850022668146
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [996, 1878, 1778, 2554, 2818, 3082, 1704, 1187]
	| approx positives in sample 512: 57
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 9, 6, 8, 10, 12, 6, 1]
episode: 634 -> reward: -124.99999999999214, steps:56928, time-elasped: 132140.03s
-> berries picked: 36 of 800 | patches-visited: [9] | positive-in-buffer: 15593 | amount-filled: 100.00%
	| epsilon: 0.13936783815060935
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [935, 1793, 1737, 2538, 2780, 3029, 1642, 1139]
	| approx positives in sample 512: 152
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 19, 15, 21, 26, 32, 21, 8]
episode: 635 -> reward: -124.9999999999909, steps:81888, time-elasped: 132396.40s
-> berries picked: 130 of 800 | patches-visited: [2, 9] | positive-in-buffer: 15989 | amount-filled: 100.00%
	| epsilon: 0.1390877401421843
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [958, 1804, 1881, 2570, 2809, 3111, 1640, 1216]
	| approx positives in sample 512: 89
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 15, 12, 12, 18, 10, 9, 6]
episode: 636 -> reward: -124.99999999999599, steps:75072, time-elasped: 132640.33s
-> berries picked: 92 of 800 | patches-visited: [1, 3, 4] | positive-in-buffer: 16162 | amount-filled: 100.00%
	| epsilon: 0.1388082050677573
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1037, 1830, 1909, 2566, 2840, 3127, 1648, 1205]
	| approx positives in sample 512: 49
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 3, 7, 10, 4, 7, 8, 4]
episode: 637 -> reward: -124.99999999998424, steps:79776, time-elasped: 132914.12s
-> berries picked: 121 of 800 | patches-visited: [2, 6] | positive-in-buffer: 16146 | amount-filled: 100.00%
	| epsilon: 0.13852923179595755
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1118, 1823, 1878, 2567, 2804, 3131, 1617, 1208]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 17, 14, 21, 22, 18, 14, 9]
episode: 638 -> reward: -124.99999999999211, steps:67584, time-elasped: 133135.31s
-> berries picked: 73 of 800 | patches-visited: [2, 5] | positive-in-buffer: 16282 | amount-filled: 100.00%
	| epsilon: 0.1382508191976882
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1149, 1848, 1881, 2581, 2818, 3153, 1635, 1217]
	| approx positives in sample 512: 157
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 17, 16, 25, 29, 34, 14, 10]
episode: 639 -> reward: -124.99999999999214, steps:61920, time-elasped: 133305.48s
-> berries picked: 57 of 800 | patches-visited: [0] | positive-in-buffer: 16429 | amount-filled: 100.00%
	| epsilon: 0.1379729661461215
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1210, 1873, 1914, 2600, 2823, 3149, 1631, 1229]
	| approx positives in sample 512: 66
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 4, 9, 12, 16, 14, 3, 3]
episode: 640 -> reward: -124.9999999999907, steps:64128, time-elasped: 133513.83s
-> berries picked: 58 of 800 | patches-visited: [0] | positive-in-buffer: 16416 | amount-filled: 100.00%
	| epsilon: 0.13769567151669446
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1189, 1899, 1908, 2593, 2813, 3151, 1639, 1224]
	| approx positives in sample 512: 54
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 7, 9, 11, 10, 6, 4, 4]
episode: 641 -> reward: -124.99999999999196, steps:65856, time-elasped: 133692.25s
-> berries picked: 74 of 800 | patches-visited: [4] | positive-in-buffer: 15953 | amount-filled: 100.00%
	| epsilon: 0.13741893418710419
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1061, 1827, 1873, 2535, 2759, 3088, 1609, 1201]
	| approx positives in sample 512: 41
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 2, 5, 8, 6, 7, 7, 2]
episode: 642 -> reward: -124.99999999999399, steps:70272, time-elasped: 133934.38s
-> berries picked: 80 of 800 | patches-visited: [0, 9] | positive-in-buffer: 15640 | amount-filled: 100.00%
	| epsilon: 0.1371427530373033
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1049, 1799, 1844, 2506, 2722, 3003, 1556, 1161]
	| approx positives in sample 512: 84
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 9, 13, 12, 18, 11, 12, 4]
episode: 643 -> reward: -124.9999999999918, steps:68160, time-elasped: 134175.46s
-> berries picked: 75 of 800 | patches-visited: [1, 5] | positive-in-buffer: 15847 | amount-filled: 100.00%
	| epsilon: 0.13686712694949557
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1040, 1818, 1867, 2559, 2752, 3020, 1570, 1221]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 17, 18, 26, 22, 22, 15, 13]
episode: 644 -> reward: -124.99999999999208, steps:58272, time-elasped: 134341.91s
-> berries picked: 38 of 800 | patches-visited: [7] | positive-in-buffer: 15912 | amount-filled: 100.00%
	| epsilon: 0.13659205480813122
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1037, 1853, 1860, 2576, 2755, 3029, 1569, 1233]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 14, 8, 22, 24, 15, 10, 8]
episode: 645 -> reward: -124.9999999999917, steps:52992, time-elasped: 134516.94s
-> berries picked: 17 of 800 | patches-visited: [5, 6] | positive-in-buffer: 15921 | amount-filled: 100.00%
	| epsilon: 0.1363175354999025
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1041, 1841, 1882, 2582, 2753, 3021, 1564, 1237]
	| approx positives in sample 512: 49
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 7, 10, 7, 4, 10, 6, 3]
episode: 646 -> reward: -124.99999999999214, steps:79776, time-elasped: 134759.25s
-> berries picked: 116 of 800 | patches-visited: [3, 4] | positive-in-buffer: 16003 | amount-filled: 100.00%
	| epsilon: 0.13604356791373912
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1123, 1839, 1915, 2563, 2763, 3000, 1573, 1227]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 16, 11, 29, 12, 16, 11, 9]
episode: 647 -> reward: -124.99999999999183, steps:60192, time-elasped: 134947.79s
-> berries picked: 45 of 800 | patches-visited: [2] | positive-in-buffer: 16125 | amount-filled: 100.00%
	| epsilon: 0.13577015094080386
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1202, 1851, 1911, 2567, 2777, 3014, 1572, 1231]
	| approx positives in sample 512: 87
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 8, 9, 13, 12, 17, 11, 9]
episode: 648 -> reward: -124.99999999999203, steps:49440, time-elasped: 135065.33s
-> berries picked: 6 of 800 | patches-visited: [8] | positive-in-buffer: 16067 | amount-filled: 100.00%
	| epsilon: 0.13549728347448795
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1188, 1842, 1902, 2560, 2770, 3014, 1565, 1226]
	| approx positives in sample 512: 85
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 7, 7, 14, 17, 11, 11, 9]
episode: 649 -> reward: -124.99999999999201, steps:64896, time-elasped: 135251.31s
-> berries picked: 67 of 800 | patches-visited: [7] | positive-in-buffer: 16212 | amount-filled: 100.00%
	| epsilon: 0.13522496441040666
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1197, 1847, 1905, 2618, 2793, 3046, 1561, 1245]
	| approx positives in sample 512: 53
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 5, 12, 7, 5, 12, 7, 3]
episode: 650 -> reward: -124.99999999999083, steps:81024, time-elasped: 135491.60s
-> berries picked: 132 of 800 | patches-visited: [3, 7] | positive-in-buffer: 16256 | amount-filled: 100.00%
	| epsilon: 0.13495319264639488
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1211, 1793, 1963, 2613, 2771, 3123, 1544, 1238]
	| approx positives in sample 512: 87
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 7, 8, 15, 20, 14, 9, 5]
episode: 651 -> reward: -124.99999999999221, steps:56256, time-elasped: 135634.68s
-> berries picked: 29 of 800 | patches-visited: [2] | positive-in-buffer: 16189 | amount-filled: 100.00%
	| epsilon: 0.13468196708250257
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1193, 1796, 1966, 2600, 2748, 3122, 1534, 1230]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 27, 16, 20, 19, 26, 12, 9]
episode: 652 -> reward: -124.99999999999186, steps:63264, time-elasped: 135842.18s
-> berries picked: 58 of 800 | patches-visited: [5, 7] | positive-in-buffer: 16336 | amount-filled: 100.00%
	| epsilon: 0.1344112866209903
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1218, 1852, 1959, 2617, 2757, 3138, 1552, 1243]
	| approx positives in sample 512: 64
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 10, 12, 8, 8, 10, 10, 2]
episode: 653 -> reward: -124.99999999999216, steps:67488, time-elasped: 136051.75s
-> berries picked: 80 of 800 | patches-visited: [6] | positive-in-buffer: 16195 | amount-filled: 100.00%
	| epsilon: 0.1341411501663249
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1223, 1837, 1928, 2569, 2741, 3110, 1541, 1246]
	| approx positives in sample 512: 167
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 20, 21, 13, 29, 38, 15, 12]
episode: 654 -> reward: -124.99999999999247, steps:67008, time-elasped: 136270.18s
-> berries picked: 79 of 800 | patches-visited: [2] | positive-in-buffer: 16400 | amount-filled: 100.00%
	| epsilon: 0.133871556625175
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1229, 1852, 1933, 2659, 2755, 3163, 1564, 1245]
	| approx positives in sample 512: 154
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 12, 16, 24, 22, 35, 22, 13]
episode: 655 -> reward: -124.99999999999658, steps:95520, time-elasped: 136565.90s
-> berries picked: 184 of 800 | patches-visited: [0, 2, 8, 9] | positive-in-buffer: 16834 | amount-filled: 100.00%
	| epsilon: 0.13360250490640654
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1284, 1916, 1948, 2773, 2782, 3188, 1637, 1306]
	| approx positives in sample 512: 53
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7] [6, 6, 8, 13, 13, 1, 6]
episode: 656 -> reward: -124.99999999999199, steps:53088, time-elasped: 136751.91s
-> berries picked: 16 of 800 | patches-visited: [0] | positive-in-buffer: 16315 | amount-filled: 100.00%
	| epsilon: 0.13333399392107836
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1194, 1819, 1932, 2681, 2725, 3115, 1580, 1269]
	| approx positives in sample 512: 57
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 8, 6, 8, 9, 10, 5, 9]
episode: 657 -> reward: -124.99999999999213, steps:57024, time-elasped: 136960.83s
-> berries picked: 32 of 800 | patches-visited: [3, 8] | positive-in-buffer: 15596 | amount-filled: 100.00%
	| epsilon: 0.13306602258243788
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1105, 1688, 1872, 2568, 2630, 3041, 1498, 1194]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 10, 13, 23, 27, 19, 18, 9]
episode: 658 -> reward: -124.99999999999167, steps:83136, time-elasped: 137227.98s
-> berries picked: 134 of 800 | patches-visited: [4, 9] | positive-in-buffer: 16009 | amount-filled: 100.00%
	| epsilon: 0.13279858980591666
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1180, 1766, 1970, 2617, 2672, 3093, 1512, 1199]
	| approx positives in sample 512: 69
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 5, 9, 5, 15, 19, 11, 2]
episode: 659 -> reward: -124.99999999999227, steps:71328, time-elasped: 137425.67s
-> berries picked: 87 of 800 | patches-visited: [3, 9] | positive-in-buffer: 16170 | amount-filled: 100.00%
	| epsilon: 0.13253169450912594
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1173, 1836, 1963, 2652, 2693, 3096, 1543, 1214]
	| approx positives in sample 512: 79
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 10, 5, 12, 13, 15, 8, 8]
episode: 660 -> reward: -124.99999999999224, steps:57984, time-elasped: 137620.93s
-> berries picked: 34 of 800 | patches-visited: [5] | positive-in-buffer: 16215 | amount-filled: 100.00%
	| epsilon: 0.13226533561185233
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1181, 1842, 1976, 2661, 2692, 3115, 1540, 1208]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 16, 17, 21, 22, 21, 8, 10]
episode: 661 -> reward: -124.99999999998902, steps:83136, time-elasped: 137884.78s
-> berries picked: 143 of 800 | patches-visited: [3, 6] | positive-in-buffer: 16604 | amount-filled: 100.00%
	| epsilon: 0.13199951203605353
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1235, 1873, 2057, 2691, 2695, 3228, 1584, 1241]
	| approx positives in sample 512: 79
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 7, 11, 12, 9, 15, 7, 10]
episode: 662 -> reward: -124.9999999999922, steps:54624, time-elasped: 138034.57s
-> berries picked: 22 of 800 | patches-visited: [7] | positive-in-buffer: 16261 | amount-filled: 100.00%
	| epsilon: 0.1317342227058537
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1191, 1822, 1995, 2654, 2668, 3175, 1537, 1219]
	| approx positives in sample 512: 65
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 7, 3, 10, 12, 14, 9, 5]
episode: 663 -> reward: -124.99999999999032, steps:53856, time-elasped: 138177.42s
-> berries picked: 18 of 800 | patches-visited: [2, 4] | positive-in-buffer: 15336 | amount-filled: 100.00%
	| epsilon: 0.13146946654753938
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1056, 1735, 1834, 2533, 2570, 3043, 1454, 1111]
	| approx positives in sample 512: 51
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 6, 6, 14, 3, 7, 5, 5]
episode: 664 -> reward: -124.99999999999143, steps:55008, time-elasped: 138372.56s
-> berries picked: 22 of 800 | patches-visited: [4] | positive-in-buffer: 15353 | amount-filled: 100.00%
	| epsilon: 0.13120524248955498
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1049, 1719, 1840, 2520, 2581, 3080, 1447, 1117]
	| approx positives in sample 512: 239
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 37, 35, 33, 43, 38, 22, 15]
episode: 665 -> reward: -124.99999999999102, steps:66240, time-elasped: 138588.92s
-> berries picked: 74 of 800 | patches-visited: [5] | positive-in-buffer: 15573 | amount-filled: 100.00%
	| epsilon: 0.13094154946249856
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1100, 1753, 1887, 2560, 2595, 3077, 1454, 1147]
	| approx positives in sample 512: 234
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 20, 32, 40, 44, 45, 26, 16]
episode: 666 -> reward: -124.99999999998683, steps:98016, time-elasped: 138910.97s
-> berries picked: 194 of 800 | patches-visited: [2, 4, 8] | positive-in-buffer: 16144 | amount-filled: 100.00%
	| epsilon: 0.13067838639911733
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1164, 1813, 2037, 2568, 2722, 3153, 1465, 1222]
	| approx positives in sample 512: 47
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 7, 10, 2, 12, 7, 3, 4]
episode: 667 -> reward: -124.99999999999221, steps:49632, time-elasped: 139086.74s
-> berries picked: 5 of 800 | patches-visited: [8] | positive-in-buffer: 15634 | amount-filled: 100.00%
	| epsilon: 0.13041575223430354
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1081, 1755, 1960, 2531, 2642, 3081, 1420, 1164]
	| approx positives in sample 512: 79
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 11, 11, 17, 10, 15, 7, 3]
episode: 668 -> reward: -124.99999999999416, steps:80064, time-elasped: 139346.81s
-> berries picked: 129 of 800 | patches-visited: [4, 6] | positive-in-buffer: 15541 | amount-filled: 100.00%
	| epsilon: 0.13015364590509004
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1031, 1783, 1929, 2536, 2608, 3068, 1414, 1172]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 11, 13, 27, 20, 17, 7, 10]
episode: 669 -> reward: -124.9999999999918, steps:61440, time-elasped: 139517.92s
-> berries picked: 60 of 800 | patches-visited: [7] | positive-in-buffer: 15601 | amount-filled: 100.00%
	| epsilon: 0.12989206635064596
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1029, 1778, 1934, 2546, 2623, 3090, 1411, 1190]
	| approx positives in sample 512: 71
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 11, 6, 12, 9, 12, 5, 10]
episode: 670 -> reward: -124.99999999999177, steps:53664, time-elasped: 139722.35s
-> berries picked: 18 of 800 | patches-visited: [8] | positive-in-buffer: 15329 | amount-filled: 100.00%
	| epsilon: 0.1296310125122725
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1004, 1759, 1873, 2490, 2606, 3053, 1383, 1161]
	| approx positives in sample 512: 53
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 5, 8, 12, 9, 5, 5, 2]
episode: 671 -> reward: -124.99999999999191, steps:65280, time-elasped: 139893.65s
-> berries picked: 68 of 800 | patches-visited: [6] | positive-in-buffer: 15046 | amount-filled: 100.00%
	| epsilon: 0.12937048333339862
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [977, 1773, 1811, 2430, 2547, 3050, 1353, 1105]
	| approx positives in sample 512: 45
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 5, 4, 12, 8, 4, 4, 4]
episode: 672 -> reward: -124.99999999999615, steps:73152, time-elasped: 140113.40s
-> berries picked: 97 of 800 | patches-visited: [5, 8] | positive-in-buffer: 15174 | amount-filled: 100.00%
	| epsilon: 0.12911047775957674
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1022, 1767, 1804, 2545, 2534, 3049, 1363, 1090]
	| approx positives in sample 512: 54
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 7, 4, 12, 11, 6, 3, 6]
episode: 673 -> reward: -124.99999999999262, steps:58944, time-elasped: 140330.34s
-> berries picked: 36 of 800 | patches-visited: [2] | positive-in-buffer: 15244 | amount-filled: 100.00%
	| epsilon: 0.1288509947384784
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1052, 1752, 1813, 2558, 2545, 3052, 1356, 1116]
	| approx positives in sample 512: 83
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 12, 14, 18, 14, 10, 5, 7]
episode: 674 -> reward: -124.99999999999228, steps:65664, time-elasped: 140538.16s
-> berries picked: 67 of 800 | patches-visited: [6] | positive-in-buffer: 15430 | amount-filled: 100.00%
	| epsilon: 0.12859203321989024
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1100, 1786, 1816, 2615, 2551, 3089, 1361, 1112]
	| approx positives in sample 512: 55
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 13, 3, 13, 6, 6, 6, 3]
episode: 675 -> reward: -124.99999999999625, steps:96096, time-elasped: 140848.55s
-> berries picked: 173 of 800 | patches-visited: [0, 5, 6, 7] | positive-in-buffer: 15394 | amount-filled: 100.00%
	| epsilon: 0.1283335921557095
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1096, 1786, 1790, 2585, 2518, 3103, 1448, 1068]
	| approx positives in sample 512: 55
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 9, 9, 10, 5, 9, 6, 3]
episode: 676 -> reward: -124.99999999998636, steps:66528, time-elasped: 141086.67s
-> berries picked: 59 of 800 | patches-visited: [0, 2] | positive-in-buffer: 15428 | amount-filled: 100.00%
	| epsilon: 0.12807567049993984
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1078, 1822, 1787, 2600, 2520, 3122, 1437, 1062]
	| approx positives in sample 512: 207
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 33, 29, 34, 35, 36, 12, 10]
episode: 677 -> reward: -124.999999999991, steps:72480, time-elasped: 141337.08s
-> berries picked: 94 of 800 | patches-visited: [4, 7] | positive-in-buffer: 15642 | amount-filled: 100.00%
	| epsilon: 0.1278182672086872
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1128, 1890, 1808, 2616, 2524, 3100, 1494, 1082]
	| approx positives in sample 512: 65
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 11, 9, 13, 1, 12, 5, 8]
episode: 678 -> reward: -124.99999999999206, steps:55680, time-elasped: 141487.38s
-> berries picked: 26 of 800 | patches-visited: [4] | positive-in-buffer: 15637 | amount-filled: 100.00%
	| epsilon: 0.12756138124015548
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1095, 1886, 1817, 2639, 2524, 3118, 1482, 1076]
	| approx positives in sample 512: 189
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 28, 18, 24, 23, 47, 24, 14]
episode: 679 -> reward: -124.999999999992, steps:62112, time-elasped: 141663.67s
-> berries picked: 48 of 800 | patches-visited: [2, 4] | positive-in-buffer: 15782 | amount-filled: 100.00%
	| epsilon: 0.12730501155464238
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1099, 1898, 1842, 2664, 2553, 3140, 1490, 1096]
	| approx positives in sample 512: 70
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 14, 8, 12, 13, 9, 4, 6]
episode: 680 -> reward: -124.99999999999211, steps:49632, time-elasped: 141844.73s
-> berries picked: 5 of 800 | patches-visited: [9] | positive-in-buffer: 15674 | amount-filled: 100.00%
	| epsilon: 0.12704915711453516
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1078, 1882, 1844, 2642, 2545, 3128, 1465, 1090]
	| approx positives in sample 512: 78
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 10, 9, 16, 11, 14, 9, 2]
episode: 681 -> reward: -124.99999999998542, steps:76608, time-elasped: 142101.85s
-> berries picked: 101 of 800 | patches-visited: [0, 9] | positive-in-buffer: 15933 | amount-filled: 100.00%
	| epsilon: 0.12679381688430638
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1105, 1900, 1940, 2637, 2597, 3142, 1500, 1112]
	| approx positives in sample 512: 52
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 10, 6, 7, 10, 9, 2, 4]
episode: 682 -> reward: -124.99999999999213, steps:52800, time-elasped: 142247.41s
-> berries picked: 17 of 800 | patches-visited: [3] | positive-in-buffer: 15158 | amount-filled: 100.00%
	| epsilon: 0.12653898983050996
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1055, 1804, 1841, 2467, 2535, 2976, 1414, 1066]
	| approx positives in sample 512: 53
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 8, 9, 8, 8, 8, 3, 7]
episode: 683 -> reward: -124.99999999999196, steps:58368, time-elasped: 142412.46s
-> berries picked: 33 of 800 | patches-visited: [1] | positive-in-buffer: 15234 | amount-filled: 100.00%
	| epsilon: 0.12628467492177659
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1078, 1828, 1824, 2468, 2541, 3006, 1422, 1067]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 16, 12, 14, 12, 21, 10, 10]
episode: 684 -> reward: -124.99999999999231, steps:66624, time-elasped: 142621.29s
-> berries picked: 80 of 800 | patches-visited: [6] | positive-in-buffer: 15462 | amount-filled: 100.00%
	| epsilon: 0.1260308711288099
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1109, 1831, 1883, 2492, 2562, 3052, 1457, 1076]
	| approx positives in sample 512: 196
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 21, 26, 33, 26, 43, 11, 18]
episode: 685 -> reward: -124.9999999999911, steps:75744, time-elasped: 142875.94s
-> berries picked: 92 of 800 | patches-visited: [0, 4, 7] | positive-in-buffer: 15782 | amount-filled: 100.00%
	| epsilon: 0.1257775774243822
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1109, 1903, 1870, 2560, 2622, 3094, 1516, 1108]
	| approx positives in sample 512: 56
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 9, 5, 8, 11, 12, 3, 6]
episode: 686 -> reward: -124.99999999999237, steps:71424, time-elasped: 143124.46s
-> berries picked: 83 of 800 | patches-visited: [0, 4] | positive-in-buffer: 15650 | amount-filled: 100.00%
	| epsilon: 0.1255247927833302
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1117, 1888, 1841, 2522, 2600, 3097, 1499, 1086]
	| approx positives in sample 512: 67
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 12, 12, 7, 6, 14, 7, 6]
episode: 687 -> reward: -124.99999999999206, steps:54720, time-elasped: 143300.23s
-> berries picked: 25 of 800 | patches-visited: [2, 6] | positive-in-buffer: 15644 | amount-filled: 100.00%
	| epsilon: 0.12527251618255106
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1110, 1884, 1846, 2526, 2593, 3117, 1489, 1079]
	| approx positives in sample 512: 37
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7] [5, 3, 6, 11, 6, 4, 2]
episode: 688 -> reward: -124.99999999999126, steps:84000, time-elasped: 143594.72s
-> berries picked: 139 of 800 | patches-visited: [5, 8, 9] | positive-in-buffer: 15579 | amount-filled: 100.00%
	| epsilon: 0.12502074660099807
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1067, 1862, 1829, 2532, 2587, 3120, 1508, 1074]
	| approx positives in sample 512: 58
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 6, 10, 14, 7, 10, 5, 2]
episode: 689 -> reward: -124.99999999999208, steps:80928, time-elasped: 143831.93s
-> berries picked: 121 of 800 | patches-visited: [0, 5] | positive-in-buffer: 15911 | amount-filled: 100.00%
	| epsilon: 0.12476948301967664
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1103, 1907, 1897, 2558, 2647, 3185, 1475, 1139]
	| approx positives in sample 512: 87
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 9, 11, 7, 11, 23, 10, 6]
episode: 690 -> reward: -124.99999999998438, steps:81120, time-elasped: 144106.40s
-> berries picked: 123 of 800 | patches-visited: [4, 5, 9] | positive-in-buffer: 16292 | amount-filled: 100.00%
	| epsilon: 0.12451872442164008
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1190, 1901, 1932, 2610, 2710, 3300, 1514, 1135]
	| approx positives in sample 512: 91
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 10, 9, 14, 18, 21, 10, 3]
episode: 691 -> reward: -124.99999999999226, steps:83616, time-elasped: 144354.09s
-> berries picked: 137 of 800 | patches-visited: [3, 7] | positive-in-buffer: 16494 | amount-filled: 100.00%
	| epsilon: 0.1242684697919856
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1222, 1938, 1955, 2589, 2769, 3318, 1539, 1164]
	| approx positives in sample 512: 59
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 8, 7, 10, 12, 5, 5, 5]
episode: 692 -> reward: -124.99999999999424, steps:64224, time-elasped: 144542.22s
-> berries picked: 57 of 800 | patches-visited: [9] | positive-in-buffer: 16388 | amount-filled: 100.00%
	| epsilon: 0.12401871811785012
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1190, 1911, 1925, 2585, 2759, 3355, 1510, 1153]
	| approx positives in sample 512: 53
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 3, 6, 8, 10, 8, 5, 8]
episode: 693 -> reward: -124.99999999999191, steps:52224, time-elasped: 144683.36s
-> berries picked: 16 of 800 | patches-visited: [6] | positive-in-buffer: 15841 | amount-filled: 100.00%
	| epsilon: 0.12376946838840612
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1151, 1840, 1866, 2533, 2661, 3243, 1459, 1088]
	| approx positives in sample 512: 58
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 7, 5, 16, 9, 13, 2, 3]
episode: 694 -> reward: -124.99999999999159, steps:67680, time-elasped: 144881.22s
-> berries picked: 77 of 800 | patches-visited: [1] | positive-in-buffer: 15961 | amount-filled: 100.00%
	| epsilon: 0.12352071959485769
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1139, 1836, 1878, 2525, 2707, 3285, 1471, 1120]
	| approx positives in sample 512: 143
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 14, 20, 19, 32, 27, 14, 9]
episode: 695 -> reward: -124.99999999999221, steps:56640, time-elasped: 145039.13s
-> berries picked: 30 of 800 | patches-visited: [4] | positive-in-buffer: 16029 | amount-filled: 100.00%
	| epsilon: 0.12327247073043637
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1156, 1854, 1879, 2531, 2727, 3289, 1473, 1120]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 19, 17, 18, 21, 28, 14, 12]
episode: 696 -> reward: -124.99999999999211, steps:54528, time-elasped: 145178.84s
-> berries picked: 24 of 800 | patches-visited: [7, 8] | positive-in-buffer: 16047 | amount-filled: 100.00%
	| epsilon: 0.12302472079039702
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1152, 1845, 1876, 2540, 2725, 3304, 1487, 1118]
	| approx positives in sample 512: 55
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 9, 8, 10, 4, 10, 7, 5]
episode: 697 -> reward: -124.9999999999911, steps:60864, time-elasped: 145385.28s
-> berries picked: 46 of 800 | patches-visited: [0] | positive-in-buffer: 15599 | amount-filled: 100.00%
	| epsilon: 0.12277746877201386
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1101, 1783, 1846, 2473, 2648, 3194, 1464, 1090]
	| approx positives in sample 512: 66
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7] [6, 7, 8, 15, 20, 7, 3]
episode: 698 -> reward: -124.99999999999282, steps:68544, time-elasped: 145597.72s
-> berries picked: 77 of 800 | patches-visited: [0] | positive-in-buffer: 15634 | amount-filled: 100.00%
	| epsilon: 0.12253071367457638
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1130, 1787, 1871, 2459, 2626, 3206, 1472, 1083]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 20, 12, 19, 19, 14, 11, 5]
episode: 699 -> reward: -124.99999999999196, steps:65376, time-elasped: 145768.99s
-> berries picked: 61 of 800 | patches-visited: [1] | positive-in-buffer: 15736 | amount-filled: 100.00%
	| epsilon: 0.12228445449938521
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1131, 1791, 1890, 2459, 2650, 3242, 1476, 1097]
	| approx positives in sample 512: 41
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 4, 3, 11, 9, 7, 2, 1]
episode: 700 -> reward: -124.9999999999921, steps:54624, time-elasped: 145910.65s
-> berries picked: 23 of 800 | patches-visited: [5] | positive-in-buffer: 14941 | amount-filled: 100.00%
	| epsilon: 0.12203869024974819
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1037, 1725, 1808, 2374, 2521, 3101, 1343, 1032]
	| approx positives in sample 512: 48
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 5, 5, 8, 11, 11, 2, 4]
episode: 701 -> reward: -124.99999999999203, steps:66432, time-elasped: 146135.30s
-> berries picked: 69 of 800 | patches-visited: [5] | positive-in-buffer: 15091 | amount-filled: 100.00%
	| epsilon: 0.12179341993097627
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1026, 1793, 1794, 2412, 2558, 3121, 1348, 1039]
	| approx positives in sample 512: 204
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 19, 26, 33, 38, 43, 16, 17]
episode: 702 -> reward: -124.99999999998788, steps:62976, time-elasped: 146330.97s
-> berries picked: 54 of 800 | patches-visited: [6, 8] | positive-in-buffer: 15299 | amount-filled: 100.00%
	| epsilon: 0.12154864255037953
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1046, 1834, 1802, 2422, 2607, 3179, 1356, 1053]
	| approx positives in sample 512: 44
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 3, 3, 7, 11, 13, 1, 1]
episode: 703 -> reward: -124.99999999999066, steps:63648, time-elasped: 146531.61s
-> berries picked: 57 of 800 | patches-visited: [2] | positive-in-buffer: 15447 | amount-filled: 100.00%
	| epsilon: 0.12130435711726306
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1062, 1854, 1844, 2436, 2639, 3167, 1370, 1075]
	| approx positives in sample 512: 67
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 8, 6, 7, 9, 18, 7, 7]
episode: 704 -> reward: -124.99999999999126, steps:63744, time-elasped: 146712.70s
-> berries picked: 55 of 800 | patches-visited: [7] | positive-in-buffer: 15550 | amount-filled: 100.00%
	| epsilon: 0.12106056264292311
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1067, 1911, 1864, 2428, 2616, 3204, 1393, 1067]
	| approx positives in sample 512: 61
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 8, 6, 8, 9, 22, 2, 2]
episode: 705 -> reward: -124.99999999999481, steps:69120, time-elasped: 146882.64s
-> berries picked: 77 of 800 | patches-visited: [7] | positive-in-buffer: 15745 | amount-filled: 100.00%
	| epsilon: 0.12081725814064297
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1063, 1893, 1936, 2425, 2626, 3304, 1421, 1077]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 18, 10, 22, 16, 19, 11, 5]
episode: 706 -> reward: -124.99999999999174, steps:53856, time-elasped: 147054.22s
-> berries picked: 21 of 800 | patches-visited: [9] | positive-in-buffer: 15807 | amount-filled: 100.00%
	| epsilon: 0.12057444262568896
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1062, 1887, 1929, 2426, 2642, 3310, 1439, 1112]
	| approx positives in sample 512: 47
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 7, 7, 3, 11, 10, 2, 6]
episode: 707 -> reward: -124.99999999999216, steps:64704, time-elasped: 147188.03s
-> berries picked: 57 of 800 | patches-visited: [7] | positive-in-buffer: 15689 | amount-filled: 100.00%
	| epsilon: 0.12033211511530657
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1063, 1900, 1915, 2385, 2635, 3264, 1435, 1092]
	| approx positives in sample 512: 49
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 5, 4, 5, 11, 10, 8, 2]
episode: 708 -> reward: -124.99999999999122, steps:67104, time-elasped: 147375.19s
-> berries picked: 79 of 800 | patches-visited: [7] | positive-in-buffer: 15848 | amount-filled: 100.00%
	| epsilon: 0.12009027462871637
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1058, 1909, 1925, 2377, 2706, 3303, 1461, 1109]
	| approx positives in sample 512: 163
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 19, 17, 16, 36, 38, 13, 14]
episode: 709 -> reward: -124.99999999999203, steps:49440, time-elasped: 147489.31s
-> berries picked: 4 of 800 | patches-visited: [4] | positive-in-buffer: 15816 | amount-filled: 100.00%
	| epsilon: 0.11984892018711009
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1058, 1912, 1931, 2374, 2688, 3294, 1455, 1104]
	| approx positives in sample 512: 84
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 17, 14, 12, 11, 9, 6, 8]
episode: 710 -> reward: -124.999999999992, steps:64608, time-elasped: 147662.00s
-> berries picked: 69 of 800 | patches-visited: [8] | positive-in-buffer: 16005 | amount-filled: 100.00%
	| epsilon: 0.11960805081364659
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1056, 1948, 1938, 2371, 2753, 3329, 1458, 1152]
	| approx positives in sample 512: 53
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 6, 8, 6, 7, 13, 8, 2]
episode: 711 -> reward: -124.99999999999226, steps:71712, time-elasped: 147831.80s
-> berries picked: 93 of 800 | patches-visited: [1, 8] | positive-in-buffer: 15961 | amount-filled: 100.00%
	| epsilon: 0.11936766553344802
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1071, 1948, 1892, 2390, 2783, 3302, 1457, 1118]
	| approx positives in sample 512: 65
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 13, 6, 7, 9, 10, 6, 5]
episode: 712 -> reward: -124.99999999999184, steps:67296, time-elasped: 147996.58s
-> berries picked: 80 of 800 | patches-visited: [4] | positive-in-buffer: 16127 | amount-filled: 100.00%
	| epsilon: 0.11912776337359585
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1086, 1963, 1902, 2426, 2810, 3358, 1462, 1120]
	| approx positives in sample 512: 153
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 20, 24, 27, 25, 26, 7, 10]
episode: 713 -> reward: -124.99999999999206, steps:64032, time-elasped: 148179.95s
-> berries picked: 59 of 800 | patches-visited: [9] | positive-in-buffer: 16251 | amount-filled: 100.00%
	| epsilon: 0.11888834336312676
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1089, 2034, 1909, 2446, 2816, 3360, 1471, 1126]
	| approx positives in sample 512: 51
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 7, 5, 8, 6, 16, 6, 2]
episode: 714 -> reward: -124.99999999999194, steps:67008, time-elasped: 148348.78s
-> berries picked: 68 of 800 | patches-visited: [9] | positive-in-buffer: 16126 | amount-filled: 100.00%
	| epsilon: 0.118649404533029
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1135, 2016, 1905, 2419, 2766, 3324, 1447, 1114]
	| approx positives in sample 512: 185
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 24, 21, 22, 32, 42, 20, 8]
episode: 715 -> reward: -124.99999999998629, steps:74976, time-elasped: 148548.29s
-> berries picked: 98 of 800 | patches-visited: [1, 4] | positive-in-buffer: 16418 | amount-filled: 100.00%
	| epsilon: 0.11841094591623823
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1207, 2057, 1954, 2457, 2792, 3345, 1493, 1113]
	| approx positives in sample 512: 48
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 5, 7, 8, 10, 9, 4, 3]
episode: 716 -> reward: -124.999999999992, steps:65760, time-elasped: 148705.22s
-> berries picked: 71 of 800 | patches-visited: [4] | positive-in-buffer: 16201 | amount-filled: 100.00%
	| epsilon: 0.11817296654763368
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1143, 1994, 1961, 2387, 2776, 3378, 1470, 1092]
	| approx positives in sample 512: 54
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 9, 5, 7, 7, 14, 3, 5]
episode: 717 -> reward: -124.99999999999203, steps:53472, time-elasped: 148812.36s
-> berries picked: 20 of 800 | patches-visited: [5] | positive-in-buffer: 15374 | amount-filled: 100.00%
	| epsilon: 0.11793546546403433
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1082, 1874, 1864, 2258, 2605, 3266, 1375, 1050]
	| approx positives in sample 512: 54
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6] [5, 3, 6, 15, 10, 9, 6]
episode: 718 -> reward: -124.99999999998973, steps:59616, time-elasped: 148969.42s
-> berries picked: 42 of 800 | patches-visited: [1] | positive-in-buffer: 15519 | amount-filled: 100.00%
	| epsilon: 0.11769844170419487
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1096, 1925, 1897, 2300, 2598, 3251, 1391, 1061]
	| approx positives in sample 512: 75
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 11, 9, 11, 13, 20, 6, 3]
episode: 719 -> reward: -124.99999999999231, steps:65184, time-elasped: 149122.83s
-> berries picked: 65 of 800 | patches-visited: [0] | positive-in-buffer: 15683 | amount-filled: 100.00%
	| epsilon: 0.11746189430880193
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1098, 1974, 1915, 2354, 2603, 3269, 1399, 1071]
	| approx positives in sample 512: 43
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 3, 6, 8, 7, 8, 5, 3]
episode: 720 -> reward: -124.99999999999328, steps:57312, time-elasped: 149285.52s
-> berries picked: 36 of 800 | patches-visited: [4] | positive-in-buffer: 15584 | amount-filled: 100.00%
	| epsilon: 0.11722582232047007
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1101, 1985, 1899, 2312, 2571, 3261, 1397, 1058]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 16, 19, 19, 17, 29, 7, 6]
episode: 721 -> reward: -124.9999999999909, steps:52992, time-elasped: 149444.04s
-> berries picked: 20 of 800 | patches-visited: [3] | positive-in-buffer: 15566 | amount-filled: 100.00%
	| epsilon: 0.11699022478373805
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1090, 1962, 1903, 2304, 2595, 3251, 1404, 1057]
	| approx positives in sample 512: 51
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 6, 9, 8, 6, 7, 5, 3]
episode: 722 -> reward: -124.99999999998909, steps:64800, time-elasped: 149621.00s
-> berries picked: 61 of 800 | patches-visited: [0, 6] | positive-in-buffer: 15573 | amount-filled: 100.00%
	| epsilon: 0.1167551007450649
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1088, 1952, 1915, 2293, 2592, 3269, 1416, 1048]
	| approx positives in sample 512: 59
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 5, 9, 4, 16, 14, 4, 5]
episode: 723 -> reward: -124.99999999999208, steps:66336, time-elasped: 149775.67s
-> berries picked: 76 of 800 | patches-visited: [7] | positive-in-buffer: 15592 | amount-filled: 100.00%
	| epsilon: 0.11652044925282595
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1069, 1916, 1904, 2289, 2657, 3251, 1426, 1080]
	| approx positives in sample 512: 248
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 34, 41, 40, 38, 56, 17, 12]
episode: 724 -> reward: -124.99999999999466, steps:85344, time-elasped: 149986.37s
-> berries picked: 152 of 800 | patches-visited: [7, 8] | positive-in-buffer: 16039 | amount-filled: 100.00%
	| epsilon: 0.1162862693573092
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1094, 1975, 1942, 2328, 2773, 3355, 1462, 1110]
	| approx positives in sample 512: 46
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 10, 7, 4, 4, 10, 3, 4]
episode: 725 -> reward: -124.99999999999207, steps:66048, time-elasped: 150139.78s
-> berries picked: 71 of 800 | patches-visited: [5] | positive-in-buffer: 16024 | amount-filled: 100.00%
	| epsilon: 0.11605256011071131
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1089, 1955, 1966, 2344, 2725, 3341, 1485, 1119]
	| approx positives in sample 512: 256
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 32, 28, 40, 35, 55, 31, 10]
episode: 726 -> reward: -124.99999999999136, steps:60672, time-elasped: 150297.82s
-> berries picked: 43 of 800 | patches-visited: [2, 8, 9] | positive-in-buffer: 16038 | amount-filled: 100.00%
	| epsilon: 0.11581932056713377
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1112, 1977, 1969, 2348, 2709, 3327, 1480, 1116]
	| approx positives in sample 512: 93
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 11, 12, 14, 13, 21, 8, 7]
episode: 727 -> reward: -124.99999999999238, steps:52224, time-elasped: 150428.88s
-> berries picked: 13 of 800 | patches-visited: [9] | positive-in-buffer: 15822 | amount-filled: 100.00%
	| epsilon: 0.11558654978257918
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1089, 1947, 1938, 2299, 2663, 3312, 1473, 1101]
	| approx positives in sample 512: 39
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7] [3, 7, 9, 6, 6, 3, 5]
episode: 728 -> reward: -124.99999999998994, steps:67104, time-elasped: 150607.39s
-> berries picked: 67 of 800 | patches-visited: [3, 6] | positive-in-buffer: 15581 | amount-filled: 100.00%
	| epsilon: 0.11535424681494734
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1069, 1927, 1890, 2247, 2587, 3306, 1465, 1090]
	| approx positives in sample 512: 186
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 27, 25, 32, 28, 35, 16, 13]
episode: 729 -> reward: -124.9999999999917, steps:78336, time-elasped: 150798.98s
-> berries picked: 117 of 800 | patches-visited: [2, 3] | positive-in-buffer: 15921 | amount-filled: 100.00%
	| epsilon: 0.11512241072403148
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1098, 2011, 1911, 2270, 2662, 3348, 1491, 1130]
	| approx positives in sample 512: 152
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 24, 23, 20, 18, 21, 15, 15]
episode: 730 -> reward: -124.99999999999203, steps:57792, time-elasped: 150932.71s
-> berries picked: 36 of 800 | patches-visited: [2] | positive-in-buffer: 15987 | amount-filled: 100.00%
	| epsilon: 0.11489104057151435
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1095, 2036, 1931, 2266, 2667, 3365, 1485, 1142]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 16, 17, 19, 13, 25, 12, 2]
episode: 731 -> reward: -124.9999999999921, steps:65184, time-elasped: 151076.03s
-> berries picked: 76 of 800 | patches-visited: [2] | positive-in-buffer: 16148 | amount-filled: 100.00%
	| epsilon: 0.11466013542096459
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1127, 2053, 1944, 2295, 2669, 3389, 1538, 1133]
	| approx positives in sample 512: 43
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 7, 5, 6, 7, 8, 2, 2]
episode: 732 -> reward: -124.99999999999157, steps:51168, time-elasped: 151188.54s
-> berries picked: 12 of 800 | patches-visited: [0, 2, 4] | positive-in-buffer: 15329 | amount-filled: 100.00%
	| epsilon: 0.11442969433783287
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1069, 1920, 1857, 2190, 2525, 3187, 1481, 1100]
	| approx positives in sample 512: 63
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 9, 9, 8, 10, 16, 4, 6]
episode: 733 -> reward: -124.99999999999362, steps:62976, time-elasped: 151354.72s
-> berries picked: 53 of 800 | patches-visited: [4, 6] | positive-in-buffer: 15484 | amount-filled: 100.00%
	| epsilon: 0.114199716389448
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1105, 1936, 1870, 2198, 2552, 3216, 1510, 1097]
	| approx positives in sample 512: 55
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 10, 9, 10, 7, 9, 3, 1]
episode: 734 -> reward: -124.99999999999017, steps:66048, time-elasped: 151533.02s
-> berries picked: 77 of 800 | patches-visited: [2] | positive-in-buffer: 15596 | amount-filled: 100.00%
	| epsilon: 0.11397020064501333
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1139, 1982, 1851, 2215, 2571, 3224, 1523, 1091]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 37, 21, 27, 38, 46, 18, 15]
episode: 735 -> reward: -124.99999999999439, steps:108672, time-elasped: 151815.03s
-> berries picked: 229 of 800 | patches-visited: [2, 4, 7, 9] | positive-in-buffer: 16290 | amount-filled: 100.00%
	| epsilon: 0.11374114617560288
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1206, 2125, 1920, 2306, 2633, 3367, 1638, 1095]
	| approx positives in sample 512: 59
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 12, 1, 11, 11, 10, 4, 7]
episode: 736 -> reward: -124.99999999998379, steps:86688, time-elasped: 152038.09s
-> berries picked: 142 of 800 | patches-visited: [1, 9] | positive-in-buffer: 16040 | amount-filled: 100.00%
	| epsilon: 0.11351255205415763
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1137, 2052, 1875, 2266, 2589, 3450, 1607, 1064]
	| approx positives in sample 512: 43
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 8, 4, 6, 6, 10, 1, 3]
episode: 737 -> reward: -124.99999999999683, steps:90720, time-elasped: 152282.30s
-> berries picked: 165 of 800 | patches-visited: [0, 4, 5, 6, 9] | positive-in-buffer: 16106 | amount-filled: 100.00%
	| epsilon: 0.11328441735548164
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1185, 2046, 1850, 2233, 2702, 3366, 1631, 1093]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 10, 13, 17, 19, 23, 15, 11]
episode: 738 -> reward: -124.99999999999203, steps:58752, time-elasped: 152406.00s
-> berries picked: 42 of 800 | patches-visited: [0] | positive-in-buffer: 16100 | amount-filled: 100.00%
	| epsilon: 0.11305674115623854
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1195, 2056, 1885, 2218, 2678, 3340, 1629, 1099]
	| approx positives in sample 512: 88
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 15, 11, 13, 11, 18, 10, 7]
episode: 739 -> reward: -124.99999999998924, steps:66144, time-elasped: 152574.48s
-> berries picked: 64 of 800 | patches-visited: [2, 8] | positive-in-buffer: 16246 | amount-filled: 100.00%
	| epsilon: 0.11282952253494757
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1220, 2061, 1935, 2210, 2663, 3408, 1636, 1113]
	| approx positives in sample 512: 255
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 31, 24, 24, 42, 68, 26, 25]
episode: 740 -> reward: -124.99999999999211, steps:50592, time-elasped: 152699.59s
-> berries picked: 8 of 800 | patches-visited: [4] | positive-in-buffer: 16180 | amount-filled: 100.00%
	| epsilon: 0.11260276057197996
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1234, 2039, 1924, 2205, 2652, 3392, 1633, 1101]
	| approx positives in sample 512: 73
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 10, 6, 11, 12, 18, 6, 6]
episode: 741 -> reward: -124.99999999999213, steps:58848, time-elasped: 152818.21s
-> berries picked: 39 of 800 | patches-visited: [2, 3, 6] | positive-in-buffer: 16088 | amount-filled: 100.00%
	| epsilon: 0.11237645434955518
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1216, 2073, 1918, 2184, 2631, 3382, 1596, 1088]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 17, 12, 11, 17, 28, 9, 9]
episode: 742 -> reward: -124.9999999999917, steps:66432, time-elasped: 152960.74s
-> berries picked: 70 of 800 | patches-visited: [6] | positive-in-buffer: 16249 | amount-filled: 100.00%
	| epsilon: 0.11215060295173729
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1226, 2092, 1964, 2199, 2628, 3413, 1632, 1095]
	| approx positives in sample 512: 230
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 33, 35, 35, 34, 44, 23, 10]
episode: 743 -> reward: -124.99999999999194, steps:60864, time-elasped: 153116.85s
-> berries picked: 44 of 800 | patches-visited: [3] | positive-in-buffer: 16334 | amount-filled: 100.00%
	| epsilon: 0.11192520546443106
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1226, 2100, 1982, 2212, 2642, 3421, 1653, 1098]
	| approx positives in sample 512: 69
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 6, 9, 12, 14, 12, 6, 2]
episode: 744 -> reward: -124.99999999999203, steps:57120, time-elasped: 153233.64s
-> berries picked: 30 of 800 | patches-visited: [6] | positive-in-buffer: 16195 | amount-filled: 100.00%
	| epsilon: 0.1117002609753785
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1207, 2138, 1961, 2203, 2606, 3360, 1622, 1098]
	| approx positives in sample 512: 120
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 18, 16, 18, 19, 25, 10, 5]
episode: 745 -> reward: -124.99999999999204, steps:52992, time-elasped: 153329.74s
-> berries picked: 16 of 800 | patches-visited: [6] | positive-in-buffer: 16222 | amount-filled: 100.00%
	| epsilon: 0.11147576857415499
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1204, 2152, 1961, 2208, 2609, 3359, 1622, 1107]
	| approx positives in sample 512: 54
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 11, 5, 4, 9, 11, 4, 6]
episode: 746 -> reward: -124.99999999999203, steps:60480, time-elasped: 153444.09s
-> berries picked: 44 of 800 | patches-visited: [7] | positive-in-buffer: 15675 | amount-filled: 100.00%
	| epsilon: 0.11125172735216571
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1164, 2099, 1935, 2152, 2483, 3202, 1526, 1114]
	| approx positives in sample 512: 73
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 11, 6, 12, 7, 18, 6, 5]
episode: 747 -> reward: -124.99999999999167, steps:60768, time-elasped: 153577.30s
-> berries picked: 44 of 800 | patches-visited: [0, 4, 8] | positive-in-buffer: 15825 | amount-filled: 100.00%
	| epsilon: 0.11102813640264182
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1175, 2136, 1940, 2192, 2507, 3231, 1526, 1118]
	| approx positives in sample 512: 77
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 13, 5, 10, 15, 13, 7, 6]
episode: 748 -> reward: -124.99999999998876, steps:59808, time-elasped: 153717.01s
-> berries picked: 44 of 800 | patches-visited: [6] | positive-in-buffer: 15883 | amount-filled: 100.00%
	| epsilon: 0.11080499482063698
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1195, 2132, 1936, 2191, 2514, 3277, 1524, 1114]
	| approx positives in sample 512: 77
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 7, 11, 4, 16, 15, 4, 8]
episode: 749 -> reward: -124.99999999999211, steps:56640, time-elasped: 153849.93s
-> berries picked: 27 of 800 | patches-visited: [2] | positive-in-buffer: 15851 | amount-filled: 100.00%
	| epsilon: 0.11058230170302355
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1183, 2140, 1938, 2183, 2511, 3252, 1532, 1112]
	| approx positives in sample 512: 146
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 23, 22, 23, 23, 26, 12, 8]
episode: 750 -> reward: -124.99999999999032, steps:76800, time-elasped: 154032.14s
-> berries picked: 110 of 800 | patches-visited: [4, 7] | positive-in-buffer: 16081 | amount-filled: 100.00%
	| epsilon: 0.11036005614848894
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1221, 2168, 1976, 2211, 2527, 3288, 1559, 1131]
	| approx positives in sample 512: 39
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 6, 2, 3, 7, 11, 2, 4]
episode: 751 -> reward: -124.99999999999251, steps:53664, time-elasped: 154143.50s
-> berries picked: 19 of 800 | patches-visited: [0, 7] | positive-in-buffer: 15301 | amount-filled: 100.00%
	| epsilon: 0.11013825725753203
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1165, 2057, 1881, 2082, 2385, 3144, 1511, 1076]
	| approx positives in sample 512: 40
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 6, 3, 7, 3, 10, 5, 4]
episode: 752 -> reward: -124.99999999999233, steps:61248, time-elasped: 154263.01s
-> berries picked: 50 of 800 | patches-visited: [2, 3] | positive-in-buffer: 14530 | amount-filled: 100.00%
	| epsilon: 0.10991690413245954
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1112, 1938, 1770, 1991, 2259, 3020, 1425, 1015]
	| approx positives in sample 512: 45
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 6, 4, 7, 6, 9, 1, 9]
episode: 753 -> reward: -124.99999999999221, steps:51360, time-elasped: 154417.37s
-> berries picked: 11 of 800 | patches-visited: [1] | positive-in-buffer: 14526 | amount-filled: 100.00%
	| epsilon: 0.10969599587738224
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1108, 1936, 1774, 1991, 2252, 3018, 1422, 1025]
	| approx positives in sample 512: 47
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 9, 5, 7, 3, 11, 4, 6]
episode: 754 -> reward: -124.99999999999213, steps:60288, time-elasped: 154562.33s
-> berries picked: 39 of 800 | patches-visited: [5, 9] | positive-in-buffer: 14601 | amount-filled: 100.00%
	| epsilon: 0.10947553159821152
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1101, 1944, 1769, 1999, 2250, 3066, 1425, 1047]
	| approx positives in sample 512: 68
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 10, 9, 9, 7, 14, 5, 7]
episode: 755 -> reward: -124.99999999999228, steps:65184, time-elasped: 154705.14s
-> berries picked: 69 of 800 | patches-visited: [5] | positive-in-buffer: 14799 | amount-filled: 100.00%
	| epsilon: 0.10925551040265569
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1112, 1999, 1776, 2021, 2271, 3104, 1445, 1071]
	| approx positives in sample 512: 47
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 5, 6, 8, 2, 15, 7, 1]
episode: 756 -> reward: -124.99999999999204, steps:51360, time-elasped: 154797.25s
-> berries picked: 11 of 800 | patches-visited: [2] | positive-in-buffer: 14591 | amount-filled: 100.00%
	| epsilon: 0.10903593140021632
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1110, 1967, 1732, 1994, 2230, 3070, 1435, 1053]
	| approx positives in sample 512: 54
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 6, 8, 9, 10, 12, 3, 3]
episode: 757 -> reward: -124.99999999999058, steps:67008, time-elasped: 154951.96s
-> berries picked: 83 of 800 | patches-visited: [0, 4] | positive-in-buffer: 14825 | amount-filled: 100.00%
	| epsilon: 0.1088167937021847
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1131, 2004, 1725, 2009, 2245, 3188, 1466, 1057]
	| approx positives in sample 512: 180
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 26, 19, 25, 31, 32, 21, 9]
episode: 758 -> reward: -124.99999999999153, steps:59328, time-elasped: 155113.73s
-> berries picked: 38 of 800 | patches-visited: [4] | positive-in-buffer: 14927 | amount-filled: 100.00%
	| epsilon: 0.10859809642163823
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1129, 2013, 1728, 2005, 2272, 3236, 1482, 1062]
	| approx positives in sample 512: 78
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 13, 7, 5, 13, 20, 9, 7]
episode: 759 -> reward: -124.99999999999223, steps:61920, time-elasped: 155270.70s
-> berries picked: 59 of 800 | patches-visited: [7] | positive-in-buffer: 15009 | amount-filled: 100.00%
	| epsilon: 0.10837983867343684
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1128, 2033, 1726, 2004, 2304, 3258, 1477, 1079]
	| approx positives in sample 512: 52
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 11, 5, 5, 8, 9, 6, 5]
episode: 760 -> reward: -124.99999999999183, steps:59616, time-elasped: 155433.21s
-> berries picked: 46 of 800 | patches-visited: [3] | positive-in-buffer: 15052 | amount-filled: 100.00%
	| epsilon: 0.10816201957421935
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1121, 2053, 1741, 1998, 2295, 3254, 1475, 1115]
	| approx positives in sample 512: 94
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 15, 12, 19, 9, 19, 7, 4]
episode: 761 -> reward: -124.99999999999204, steps:58656, time-elasped: 155585.17s
-> berries picked: 36 of 800 | patches-visited: [7] | positive-in-buffer: 15119 | amount-filled: 100.00%
	| epsilon: 0.10794463824239996
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1120, 2055, 1725, 1990, 2334, 3275, 1481, 1139]
	| approx positives in sample 512: 85
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 8, 11, 10, 11, 19, 11, 6]
episode: 762 -> reward: -124.99999999999238, steps:57792, time-elasped: 155732.72s
-> berries picked: 36 of 800 | patches-visited: [7] | positive-in-buffer: 15060 | amount-filled: 100.00%
	| epsilon: 0.1077276937981647
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1124, 2052, 1698, 1977, 2309, 3276, 1491, 1133]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 17, 16, 9, 15, 28, 18, 6]
episode: 763 -> reward: -124.999999999992, steps:49728, time-elasped: 155843.57s
-> berries picked: 5 of 800 | patches-visited: [7] | positive-in-buffer: 14996 | amount-filled: 100.00%
	| epsilon: 0.10751118536346775
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1138, 2049, 1686, 1966, 2285, 3253, 1499, 1120]
	| approx positives in sample 512: 70
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 12, 4, 14, 14, 12, 8, 3]
episode: 764 -> reward: -124.99999999999186, steps:59712, time-elasped: 156002.70s
-> berries picked: 45 of 800 | patches-visited: [7] | positive-in-buffer: 14945 | amount-filled: 100.00%
	| epsilon: 0.107295112062028
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1133, 2071, 1700, 1928, 2282, 3236, 1495, 1100]
	| approx positives in sample 512: 85
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 17, 12, 11, 10, 21, 7, 4]
episode: 765 -> reward: -124.99999999998921, steps:71328, time-elasped: 156163.93s
-> berries picked: 83 of 800 | patches-visited: [4, 6] | positive-in-buffer: 15120 | amount-filled: 100.00%
	| epsilon: 0.10707947301932551
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1141, 2081, 1746, 1935, 2291, 3305, 1502, 1119]
	| approx positives in sample 512: 62
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 12, 9, 8, 9, 13, 6, 2]
episode: 766 -> reward: -124.99999999999191, steps:57024, time-elasped: 156285.12s
-> berries picked: 29 of 800 | patches-visited: [8, 9] | positive-in-buffer: 15023 | amount-filled: 100.00%
	| epsilon: 0.10686426736259788
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1134, 2050, 1717, 1924, 2291, 3266, 1508, 1133]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 22, 18, 22, 17, 26, 11, 13]
episode: 767 -> reward: -124.99999999999122, steps:75072, time-elasped: 156458.52s
-> berries picked: 100 of 800 | patches-visited: [1, 8] | positive-in-buffer: 15163 | amount-filled: 100.00%
	| epsilon: 0.10664949422083675
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1168, 2064, 1701, 1918, 2312, 3297, 1533, 1170]
	| approx positives in sample 512: 64
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 10, 7, 7, 9, 14, 9, 4]
episode: 768 -> reward: -124.99999999999189, steps:58848, time-elasped: 156591.93s
-> berries picked: 36 of 800 | patches-visited: [7] | positive-in-buffer: 14595 | amount-filled: 100.00%
	| epsilon: 0.10643515272478433
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1091, 1978, 1628, 1843, 2258, 3167, 1488, 1142]
	| approx positives in sample 512: 89
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 13, 8, 16, 17, 15, 10, 7]
episode: 769 -> reward: -124.99999999999203, steps:49248, time-elasped: 156736.52s
-> berries picked: 4 of 800 | patches-visited: [1] | positive-in-buffer: 14588 | amount-filled: 100.00%
	| epsilon: 0.10622124200692987
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1094, 1975, 1628, 1840, 2256, 3162, 1494, 1139]
	| approx positives in sample 512: 64
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 7, 9, 11, 8, 11, 9, 6]
episode: 770 -> reward: -124.99999999999206, steps:67872, time-elasped: 156897.60s
-> berries picked: 74 of 800 | patches-visited: [1, 7] | positive-in-buffer: 14793 | amount-filled: 100.00%
	| epsilon: 0.106007761201506
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1119, 1998, 1640, 1896, 2264, 3208, 1538, 1130]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 16, 19, 19, 18, 29, 8, 14]
episode: 771 -> reward: -124.99999999999474, steps:71328, time-elasped: 157053.62s
-> berries picked: 81 of 800 | patches-visited: [2, 5, 9] | positive-in-buffer: 14987 | amount-filled: 100.00%
	| epsilon: 0.10579470944448549
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1111, 2063, 1667, 1893, 2297, 3230, 1549, 1177]
	| approx positives in sample 512: 56
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 8, 6, 6, 9, 10, 5, 3]
episode: 772 -> reward: -124.999999999992, steps:63168, time-elasped: 157219.67s
-> berries picked: 54 of 800 | patches-visited: [9] | positive-in-buffer: 14935 | amount-filled: 100.00%
	| epsilon: 0.10558208587357754
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1108, 2068, 1662, 1897, 2259, 3236, 1539, 1166]
	| approx positives in sample 512: 58
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 5, 5, 7, 13, 11, 11, 2]
episode: 773 -> reward: -124.99999999999156, steps:65184, time-elasped: 157351.85s
-> berries picked: 71 of 800 | patches-visited: [4] | positive-in-buffer: 14801 | amount-filled: 100.00%
	| epsilon: 0.10536988962822437
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1139, 2030, 1636, 1877, 2210, 3210, 1537, 1162]
	| approx positives in sample 512: 50
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 9, 4, 6, 7, 13, 1, 6]
episode: 774 -> reward: -124.99999999999203, steps:54624, time-elasped: 157449.82s
-> berries picked: 23 of 800 | patches-visited: [6] | positive-in-buffer: 14440 | amount-filled: 100.00%
	| epsilon: 0.1051581198495977
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1089, 1967, 1598, 1852, 2146, 3133, 1502, 1153]
	| approx positives in sample 512: 50
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 3, 7, 5, 7, 15, 5, 5]
episode: 775 -> reward: -124.9999999999922, steps:65856, time-elasped: 157605.18s
-> berries picked: 68 of 800 | patches-visited: [6] | positive-in-buffer: 14499 | amount-filled: 100.00%
	| epsilon: 0.10494677568059538
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1086, 1965, 1631, 1832, 2149, 3161, 1496, 1179]
	| approx positives in sample 512: 45
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 7, 4, 3, 7, 9, 4, 8]
episode: 776 -> reward: -124.99999999999129, steps:64416, time-elasped: 157757.74s
-> berries picked: 62 of 800 | patches-visited: [9] | positive-in-buffer: 14395 | amount-filled: 100.00%
	| epsilon: 0.10473585626583776
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1072, 1981, 1588, 1805, 2103, 3135, 1509, 1202]
	| approx positives in sample 512: 36
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 5, 6, 5, 5, 5, 2, 3]
episode: 777 -> reward: -124.99999999999189, steps:59424, time-elasped: 157889.19s
-> berries picked: 46 of 800 | patches-visited: [4] | positive-in-buffer: 14345 | amount-filled: 100.00%
	| epsilon: 0.10452536075166434
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1053, 1972, 1567, 1786, 2117, 3151, 1488, 1211]
	| approx positives in sample 512: 78
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 9, 9, 7, 16, 21, 5, 6]
episode: 778 -> reward: -124.99999999998013, steps:108096, time-elasped: 158156.57s
-> berries picked: 219 of 800 | patches-visited: [1, 5, 6, 9] | positive-in-buffer: 14952 | amount-filled: 100.00%
	| epsilon: 0.10431528828613029
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1120, 2018, 1615, 1841, 2227, 3334, 1547, 1250]
	| approx positives in sample 512: 49
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 7, 5, 5, 12, 9, 4, 5]
episode: 779 -> reward: -124.99999999998886, steps:63744, time-elasped: 158309.52s
-> berries picked: 55 of 800 | patches-visited: [7] | positive-in-buffer: 14562 | amount-filled: 100.00%
	| epsilon: 0.10410563801900302
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1091, 1985, 1561, 1829, 2125, 3231, 1514, 1226]
	| approx positives in sample 512: 52
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 12, 5, 6, 6, 11, 5, 2]
episode: 780 -> reward: -124.99999999997979, steps:81888, time-elasped: 158522.16s
-> berries picked: 126 of 800 | patches-visited: [0, 2, 8] | positive-in-buffer: 14191 | amount-filled: 100.00%
	| epsilon: 0.10389640910175867
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1061, 1971, 1578, 1774, 2060, 3131, 1474, 1142]
	| approx positives in sample 512: 81
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 12, 13, 15, 9, 16, 5, 6]
episode: 781 -> reward: -124.99999999999204, steps:50016, time-elasped: 158645.65s
-> berries picked: 8 of 800 | patches-visited: [0] | positive-in-buffer: 14075 | amount-filled: 100.00%
	| epsilon: 0.10368760068757872
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1052, 1952, 1562, 1763, 2042, 3107, 1469, 1128]
	| approx positives in sample 512: 69
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 14, 3, 11, 13, 12, 5, 6]
episode: 782 -> reward: -124.9999999999897, steps:57600, time-elasped: 158796.40s
-> berries picked: 33 of 800 | patches-visited: [1, 7] | positive-in-buffer: 14032 | amount-filled: 100.00%
	| epsilon: 0.10347921193134664
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1082, 1933, 1558, 1748, 2024, 3080, 1455, 1152]
	| approx positives in sample 512: 96
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 16, 10, 14, 14, 25, 6, 4]
episode: 783 -> reward: -124.99999999999203, steps:50784, time-elasped: 158895.93s
-> berries picked: 10 of 800 | patches-visited: [5] | positive-in-buffer: 13950 | amount-filled: 100.00%
	| epsilon: 0.10327124198964434
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1056, 1920, 1559, 1736, 2016, 3061, 1457, 1145]
	| approx positives in sample 512: 44
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 6, 7, 6, 4, 11, 6, 3]
episode: 784 -> reward: -124.99999999999129, steps:65376, time-elasped: 159043.87s
-> berries picked: 59 of 800 | patches-visited: [3, 7] | positive-in-buffer: 13890 | amount-filled: 100.00%
	| epsilon: 0.10306369002074876
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1067, 1934, 1564, 1717, 2006, 3044, 1432, 1126]
	| approx positives in sample 512: 43
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6] [5, 4, 6, 4, 9, 12, 3]
episode: 785 -> reward: -124.99999999999106, steps:79872, time-elasped: 159227.90s
-> berries picked: 112 of 800 | patches-visited: [4, 9] | positive-in-buffer: 13747 | amount-filled: 100.00%
	| epsilon: 0.1028565551846286
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1084, 1906, 1611, 1647, 1984, 2960, 1415, 1140]
	| approx positives in sample 512: 91
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 16, 12, 12, 12, 19, 10, 3]
episode: 786 -> reward: -124.99999999998849, steps:70848, time-elasped: 159386.46s
-> berries picked: 83 of 800 | patches-visited: [3, 9] | positive-in-buffer: 13905 | amount-filled: 100.00%
	| epsilon: 0.10264983664294085
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1100, 1971, 1631, 1654, 2018, 2970, 1419, 1142]
	| approx positives in sample 512: 74
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 8, 10, 13, 6, 16, 5, 10]
episode: 787 -> reward: -124.99999999999065, steps:73248, time-elasped: 159548.90s
-> berries picked: 96 of 800 | patches-visited: [0, 1, 3, 4] | positive-in-buffer: 14151 | amount-filled: 100.00%
	| epsilon: 0.10244353355902724
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1127, 2014, 1639, 1659, 2051, 3044, 1446, 1171]
	| approx positives in sample 512: 56
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 5, 7, 6, 7, 13, 6, 4]
episode: 788 -> reward: -124.99999999999217, steps:58272, time-elasped: 159668.71s
-> berries picked: 35 of 800 | patches-visited: [5] | positive-in-buffer: 13974 | amount-filled: 100.00%
	| epsilon: 0.10223764509791114
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1100, 1985, 1606, 1648, 2003, 3036, 1432, 1164]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 15, 17, 14, 9, 16, 11, 7]
episode: 789 -> reward: -124.99999999999217, steps:63936, time-elasped: 159802.73s
-> berries picked: 62 of 800 | patches-visited: [4] | positive-in-buffer: 14158 | amount-filled: 100.00%
	| epsilon: 0.102032170426294
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1127, 1995, 1611, 1664, 2043, 3050, 1489, 1179]
	| approx positives in sample 512: 46
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 9, 9, 5, 4, 10, 4, 2]
episode: 790 -> reward: -124.99999999999345, steps:64032, time-elasped: 159953.86s
-> berries picked: 60 of 800 | patches-visited: [8] | positive-in-buffer: 13961 | amount-filled: 100.00%
	| epsilon: 0.10182710871255196
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1080, 1962, 1640, 1666, 2022, 2992, 1445, 1154]
	| approx positives in sample 512: 47
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 9, 6, 6, 4, 7, 5, 3]
episode: 791 -> reward: -124.99999999999507, steps:67296, time-elasped: 160123.12s
-> berries picked: 71 of 800 | patches-visited: [2, 5] | positive-in-buffer: 13849 | amount-filled: 100.00%
	| epsilon: 0.10162245912673258
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1074, 1957, 1627, 1675, 2009, 2932, 1422, 1153]
	| approx positives in sample 512: 117
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 17, 12, 19, 16, 30, 8, 8]
episode: 792 -> reward: -124.99999999999203, steps:48384, time-elasped: 160220.17s
-> berries picked: 1 of 800 | patches-visited: [4] | positive-in-buffer: 13841 | amount-filled: 100.00%
	| epsilon: 0.10141822084055144
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1074, 1954, 1625, 1675, 2006, 2931, 1417, 1159]
	| approx positives in sample 512: 76
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 14, 13, 14, 7, 15, 7, 3]
episode: 793 -> reward: -124.99999999999203, steps:48672, time-elasped: 160319.77s
-> berries picked: 2 of 800 | patches-visited: [3] | positive-in-buffer: 13828 | amount-filled: 100.00%
	| epsilon: 0.10121439302738879
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1072, 1952, 1623, 1672, 2000, 2930, 1425, 1154]
	| approx positives in sample 512: 65
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 12, 9, 9, 10, 13, 6, 4]
episode: 794 -> reward: -124.99999999999133, steps:53472, time-elasped: 160458.69s
-> berries picked: 17 of 800 | patches-visited: [5] | positive-in-buffer: 13874 | amount-filled: 100.00%
	| epsilon: 0.10101097486228613
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1073, 1961, 1627, 1673, 1996, 2934, 1448, 1162]
	| approx positives in sample 512: 32
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 2, 6, 4, 4, 8, 4, 1]
episode: 795 -> reward: -124.99999999999203, steps:57504, time-elasped: 160579.07s
-> berries picked: 32 of 800 | patches-visited: [4] | positive-in-buffer: 13739 | amount-filled: 100.00%
	| epsilon: 0.10080796552194306
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1058, 1961, 1596, 1660, 1986, 2899, 1443, 1136]
	| approx positives in sample 512: 107
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 15, 15, 19, 11, 20, 8, 10]
episode: 796 -> reward: -124.99999999999196, steps:55296, time-elasped: 160732.65s
-> berries picked: 22 of 800 | patches-visited: [7] | positive-in-buffer: 13801 | amount-filled: 100.00%
	| epsilon: 0.10060536418471373
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1056, 1979, 1604, 1664, 1980, 2906, 1448, 1164]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 33, 30, 28, 25, 49, 26, 7]
episode: 797 -> reward: -124.9999999999927, steps:55488, time-elasped: 160884.59s
-> berries picked: 24 of 800 | patches-visited: [2, 3] | positive-in-buffer: 13855 | amount-filled: 100.00%
	| epsilon: 0.10040317003060366
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1054, 1999, 1608, 1682, 1992, 2918, 1445, 1157]
	| approx positives in sample 512: 174
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 23, 18, 32, 17, 33, 14, 19]
episode: 798 -> reward: -124.99999999999068, steps:66144, time-elasped: 161070.22s
-> berries picked: 60 of 800 | patches-visited: [1, 2, 3] | positive-in-buffer: 14039 | amount-filled: 100.00%
	| epsilon: 0.10020138224126635
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1069, 2023, 1621, 1735, 2036, 2945, 1450, 1160]
	| approx positives in sample 512: 210
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 25, 32, 26, 17, 52, 24, 18]
episode: 799 -> reward: -124.9999999999952, steps:64992, time-elasped: 161244.86s
-> berries picked: 64 of 800 | patches-visited: [7] | positive-in-buffer: 14179 | amount-filled: 100.00%
	| epsilon: 0.10000000000000003
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1093, 2027, 1616, 1747, 2070, 2983, 1480, 1163]
	| approx positives in sample 512: 34
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 7, 3, 6, 5, 8, 3, 1]
total time elasped: 161244.8881341 s
evalEpisode: 0 -> reward: -124.99999999999218 steps: 62688
