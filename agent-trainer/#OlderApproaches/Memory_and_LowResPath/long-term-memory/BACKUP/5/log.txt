getBabyEnv :
	 logDir : .temp\2022-5-22 7-32-0
	 initial_juice : 0.5
	 end_on_boundary_hit : False
	 penalize_boundary_hit : False
	 allow_no_action : False
	 no_action_threshold : 0.7
	 field_size : (20000, 20000)
	 initial_pos_around_berry : True
	 living_cost : True
	 nberries : 80
	 num_patches : 10
	 patch_size : (2600, 2600)
	 show : False
	 spawn_radius : 100


with living cost, rewards scaled by 1/(berry_env.REWARD_RATE*MAXSIZE)
Agent :
	 self : <Agent.Agent object at 0x000002C2272240C8>
	 berryField : <BerryFieldEnv instance>
	 mode : train
	 field_grid_size : (40, 40)
	 angle : 45
	 persistence : 0.9
	 worth_offset : 0.0
	 noise : 0.01
	 state_transition_mode : single
	 positive_emphasis : True
	 emphasis_mode : replace
	 memory_alpha : 0.9995
	 time_memory_delta : 0.005
	 time_memory_exp : 1
	 disjoint : False
	 debug : False
	 debugDir : .temp


state_transition_mode is not 'all'. The state-transitions being appended 
            every action will be as [[state, action, sum-reward, nextState, done]] where:
            state is the one the model has taken action on,
            sum-reward is the sum of the rewards in the skip-trajectory,
            nextState is the new state after the action was repeated at most skip-steps times,
            done is wether the terminal state was reached.
total-params:  5529
net(
  (feedforward): ModuleList(
    (0): Linear(in_features=38, out_features=16, bias=True)
    (1): LeakyReLU(negative_slope=0.1)
    (2): Linear(in_features=16, out_features=8, bias=True)
    (3): LeakyReLU(negative_slope=0.1)
  )
  (memory_conv): ModuleList(
    (0): Conv2d(1, 8, kernel_size=(6, 6), stride=(4, 4), padding=(3, 3))
    (1): LeakyReLU(negative_slope=0.1)
    (2): Conv2d(8, 16, kernel_size=(4, 4), stride=(3, 3), padding=(1, 1))
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): LeakyReLU(negative_slope=0.1)
  )
  (final_stage): ModuleList(
    (0): Linear(in_features=136, out_features=16, bias=True)
    (1): LeakyReLU(negative_slope=0.1)
    (2): Linear(in_features=16, out_features=8, bias=True)
    (3): LeakyReLU(negative_slope=0.1)
  )
  (valueL): Linear(in_features=8, out_features=1, bias=True)
  (actadvs): Linear(in_features=8, out_features=8, bias=True)
)
lr used = 0.000025, num_gradient_steps= 500
optimizing the online-model after every episode (skipSteps=10)
batch size-1024, gamma=0.8
Using greedy strategy as evalExplortionStrategy.
episode: 0 -> reward: -124.99999999999204, steps:48000, time-elasped: 124.46s
-> berries picked: 0 of 800 | patches-visited: [2] | positive-in-buffer: 0 | amount-filled: 8.73%
	| epsilon: 0.49959780237162366
	| action-stats:  [] []
	| approx positives in sample 512: 0
	| approx action-dist in sample 512: [] []
episode: 1 -> reward: -124.99999999999227, steps:49056, time-elasped: 271.86s
-> berries picked: 3 of 800 | patches-visited: [4, 5] | positive-in-buffer: 3 | amount-filled: 17.65%
	| epsilon: 0.4991959282691119
	| action-stats:  [4, 5] [1, 2]
	| approx positives in sample 512: 0
	| approx action-dist in sample 512: [] []
episode: 2 -> reward: -124.99999999999204, steps:48384, time-elasped: 410.73s
-> berries picked: 2 of 800 | patches-visited: [6] | positive-in-buffer: 5 | amount-filled: 26.45%
	| epsilon: 0.498794377432222
	| action-stats:  [1, 4, 5, 7] [1, 1, 2, 1]
	| approx positives in sample 512: 2
	| approx action-dist in sample 512: [5, 7] [1, 1]
episode: 3 -> reward: -124.99999999999206, steps:48384, time-elasped: 541.48s
-> berries picked: 2 of 800 | patches-visited: [4, 5] | positive-in-buffer: 7 | amount-filled: 35.24%
	| epsilon: 0.4983931496009206
	| action-stats:  [1, 3, 4, 5, 7] [2, 1, 1, 2, 1]
	| approx positives in sample 512: 3
	| approx action-dist in sample 512: [5] [3]
episode: 4 -> reward: -124.99999999999204, steps:48000, time-elasped: 660.01s
-> berries picked: 0 of 800 | patches-visited: [1] | positive-in-buffer: 7 | amount-filled: 43.97%
	| epsilon: 0.4979922445153836
	| action-stats:  [1, 3, 4, 5, 7] [2, 1, 1, 2, 1]
	| approx positives in sample 512: 8
	| approx action-dist in sample 512: [4, 5, 7] [1, 5, 2]
episode: 5 -> reward: -124.99999999999204, steps:48000, time-elasped: 818.65s
-> berries picked: 0 of 800 | patches-visited: [] | positive-in-buffer: 7 | amount-filled: 52.70%
	| epsilon: 0.4975916619159958
	| action-stats:  [1, 3, 4, 5, 7] [2, 1, 1, 2, 1]
	| approx positives in sample 512: 4
	| approx action-dist in sample 512: [1, 5, 7] [1, 1, 2]
episode: 6 -> reward: -124.99999999999204, steps:48000, time-elasped: 969.25s
-> berries picked: 0 of 800 | patches-visited: [4, 6, 7] | positive-in-buffer: 7 | amount-filled: 61.43%
	| epsilon: 0.4971914015433509
	| action-stats:  [1, 3, 4, 5, 7] [2, 1, 1, 2, 1]
	| approx positives in sample 512: 11
	| approx action-dist in sample 512: [1, 3, 4, 5] [3, 1, 3, 4]
episode: 7 -> reward: -124.99999999999208, steps:49056, time-elasped: 1119.15s
-> berries picked: 3 of 800 | patches-visited: [5, 9] | positive-in-buffer: 10 | amount-filled: 70.35%
	| epsilon: 0.49679146313825123
	| action-stats:  [1, 3, 4, 5, 7] [2, 1, 3, 3, 1]
	| approx positives in sample 512: 5
	| approx action-dist in sample 512: [4, 5] [2, 3]
episode: 8 -> reward: -124.99999999999204, steps:48000, time-elasped: 1268.84s
-> berries picked: 0 of 800 | patches-visited: [7] | positive-in-buffer: 10 | amount-filled: 79.08%
	| epsilon: 0.49639184644170764
	| action-stats:  [1, 3, 4, 5, 7] [2, 1, 3, 3, 1]
	| approx positives in sample 512: 12
	| approx action-dist in sample 512: [1, 4, 5, 7] [2, 3, 6, 1]
episode: 9 -> reward: -124.99999999999211, steps:50112, time-elasped: 1409.48s
-> berries picked: 9 of 800 | patches-visited: [5, 6, 9] | positive-in-buffer: 19 | amount-filled: 88.19%
	| epsilon: 0.49599255119493924
	| action-stats:  [1, 3, 4, 5, 7] [2, 1, 7, 7, 2]
	| approx positives in sample 512: 12
	| approx action-dist in sample 512: [1, 4, 5, 7] [2, 6, 3, 1]
episode: 10 -> reward: -124.99999999999203, steps:48768, time-elasped: 1539.28s
-> berries picked: 3 of 800 | patches-visited: [0] | positive-in-buffer: 22 | amount-filled: 97.06%
	| epsilon: 0.49559357713937335
	| action-stats:  [1, 3, 4, 5, 6, 7] [2, 1, 7, 9, 1, 2]
	| approx positives in sample 512: 14
	| approx action-dist in sample 512: [4, 5, 6] [7, 5, 2]
episode: 11 -> reward: -124.99999999999203, steps:48192, time-elasped: 1677.49s
-> berries picked: 1 of 800 | patches-visited: [6] | positive-in-buffer: 23 | amount-filled: 100.00%
	| epsilon: 0.4951949240166454
	| action-stats:  [1, 3, 4, 5, 6, 7] [2, 1, 7, 10, 1, 2]
	| approx positives in sample 512: 15
	| approx action-dist in sample 512: [4, 5, 6] [6, 8, 1]
episode: 12 -> reward: -124.99999999999203, steps:48384, time-elasped: 1802.00s
-> berries picked: 1 of 800 | patches-visited: [8] | positive-in-buffer: 24 | amount-filled: 100.00%
	| epsilon: 0.4947965915685984
	| action-stats:  [1, 3, 4, 5, 6, 7] [2, 1, 7, 11, 1, 2]
	| approx positives in sample 512: 12
	| approx action-dist in sample 512: [1, 4, 5, 6, 7] [1, 3, 6, 1, 1]
episode: 13 -> reward: -124.99999999999204, steps:48000, time-elasped: 1956.64s
-> berries picked: 0 of 800 | patches-visited: [5] | positive-in-buffer: 24 | amount-filled: 100.00%
	| epsilon: 0.4943985795372832
	| action-stats:  [1, 3, 4, 5, 6, 7] [2, 1, 7, 11, 1, 2]
	| approx positives in sample 512: 20
	| approx action-dist in sample 512: [1, 4, 5, 7] [3, 6, 9, 2]
episode: 14 -> reward: -124.99999999999137, steps:51456, time-elasped: 2116.65s
-> berries picked: 12 of 800 | patches-visited: [0, 1, 2] | positive-in-buffer: 36 | amount-filled: 100.00%
	| epsilon: 0.4940008876649582
	| action-stats:  [1, 2, 3, 4, 5, 6, 7] [2, 1, 3, 8, 14, 3, 5]
	| approx positives in sample 512: 20
	| approx action-dist in sample 512: [3, 4, 5, 6, 7] [1, 3, 9, 3, 4]
episode: 15 -> reward: -124.99999999999295, steps:52896, time-elasped: 2258.28s
-> berries picked: 15 of 800 | patches-visited: [8, 9] | positive-in-buffer: 51 | amount-filled: 100.00%
	| epsilon: 0.4936035156940889
	| action-stats:  [1, 2, 3, 4, 5, 6, 7] [2, 1, 5, 10, 20, 4, 9]
	| approx positives in sample 512: 27
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7] [2, 1, 3, 6, 7, 5, 3]
episode: 16 -> reward: -124.99999999999217, steps:51648, time-elasped: 2394.64s
-> berries picked: 11 of 800 | patches-visited: [2] | positive-in-buffer: 62 | amount-filled: 100.00%
	| epsilon: 0.49320646336734814
	| action-stats:  [1, 2, 3, 4, 5, 6, 7] [2, 1, 5, 12, 24, 6, 12]
	| approx positives in sample 512: 29
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7] [1, 3, 1, 7, 13, 2, 2]
episode: 17 -> reward: -124.99999999999064, steps:52800, time-elasped: 2561.43s
-> berries picked: 16 of 800 | patches-visited: [1, 7, 8] | positive-in-buffer: 78 | amount-filled: 100.00%
	| epsilon: 0.49280973042761567
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1, 2, 1, 8, 14, 31, 6, 15]
	| approx positives in sample 512: 30
	| approx action-dist in sample 512: [1, 3, 4, 5, 6, 7] [1, 3, 7, 11, 2, 6]
episode: 18 -> reward: -124.9999999999918, steps:51648, time-elasped: 2711.96s
-> berries picked: 13 of 800 | patches-visited: [0, 2] | positive-in-buffer: 91 | amount-filled: 100.00%
	| epsilon: 0.49241331661797816
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2, 2, 1, 12, 16, 33, 6, 19]
	| approx positives in sample 512: 34
	| approx action-dist in sample 512: [3, 4, 5, 6, 7] [1, 9, 11, 3, 10]
episode: 19 -> reward: -124.99999999999177, steps:63264, time-elasped: 2881.69s
-> berries picked: 58 of 800 | patches-visited: [3] | positive-in-buffer: 149 | amount-filled: 100.00%
	| epsilon: 0.4920172216817288
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [6, 5, 7, 23, 22, 49, 9, 28]
	| approx positives in sample 512: 40
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 2, 2, 13, 8, 9, 3, 2]
episode: 20 -> reward: -124.99999999999044, steps:62208, time-elasped: 3037.85s
-> berries picked: 49 of 800 | patches-visited: [1, 8] | positive-in-buffer: 198 | amount-filled: 100.00%
	| epsilon: 0.4916214453623674
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [6, 8, 14, 33, 29, 56, 11, 41]
	| approx positives in sample 512: 41
	| approx action-dist in sample 512: [0, 2, 3, 4, 5, 6, 7] [1, 3, 9, 5, 7, 2, 14]
episode: 21 -> reward: -124.99999999998668, steps:73440, time-elasped: 3237.23s
-> berries picked: 88 of 800 | patches-visited: [3, 8] | positive-in-buffer: 286 | amount-filled: 100.00%
	| epsilon: 0.4912259874036
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [7, 10, 26, 43, 42, 80, 16, 62]
	| approx positives in sample 512: 42
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 2, 1, 5, 6, 15, 2, 9]
episode: 22 -> reward: -124.99999999999186, steps:63648, time-elasped: 3407.43s
-> berries picked: 53 of 800 | patches-visited: [2, 5] | positive-in-buffer: 339 | amount-filled: 100.00%
	| epsilon: 0.4908308475493389
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [10, 11, 33, 53, 46, 92, 18, 76]
	| approx positives in sample 512: 50
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 3, 7, 7, 8, 9, 4, 11]
episode: 23 -> reward: -124.99999999999217, steps:53088, time-elasped: 3555.56s
-> berries picked: 16 of 800 | patches-visited: [0] | positive-in-buffer: 355 | amount-filled: 100.00%
	| epsilon: 0.49043602554370236
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [10, 14, 36, 55, 46, 96, 19, 79]
	| approx positives in sample 512: 50
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 1, 5, 9, 5, 12, 3, 12]
episode: 24 -> reward: -124.99999999999343, steps:63168, time-elasped: 3722.15s
-> berries picked: 49 of 800 | patches-visited: [2] | positive-in-buffer: 403 | amount-filled: 100.00%
	| epsilon: 0.4900415211310144
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [13, 17, 42, 59, 48, 110, 21, 93]
	| approx positives in sample 512: 42
	| approx action-dist in sample 512: [0, 2, 3, 4, 5, 6, 7] [2, 6, 9, 1, 10, 1, 13]
episode: 25 -> reward: -124.99999999998768, steps:70080, time-elasped: 3906.29s
-> berries picked: 78 of 800 | patches-visited: [3, 6] | positive-in-buffer: 481 | amount-filled: 100.00%
	| epsilon: 0.48964733405580474
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [14, 26, 53, 66, 59, 119, 21, 123]
	| approx positives in sample 512: 58
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 6, 11, 7, 3, 10, 1, 16]
episode: 26 -> reward: -124.99999999998833, steps:71424, time-elasped: 4120.18s
-> berries picked: 76 of 800 | patches-visited: [1, 2, 6] | positive-in-buffer: 556 | amount-filled: 100.00%
	| epsilon: 0.4892534640628087
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [17, 32, 67, 86, 63, 133, 22, 136]
	| approx positives in sample 512: 48
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 3, 6, 6, 4, 13, 2, 12]
episode: 27 -> reward: -124.99999999999211, steps:52608, time-elasped: 4265.74s
-> berries picked: 15 of 800 | patches-visited: [5] | positive-in-buffer: 571 | amount-filled: 100.00%
	| epsilon: 0.48885991089696673
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [18, 33, 71, 87, 63, 137, 22, 140]
	| approx positives in sample 512: 53
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 2, 7, 6, 4, 16, 3, 13]
episode: 28 -> reward: -124.99999999999093, steps:71328, time-elasped: 4453.12s
-> berries picked: 87 of 800 | patches-visited: [3, 8] | positive-in-buffer: 658 | amount-filled: 100.00%
	| epsilon: 0.48846667430342466
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [20, 47, 82, 112, 67, 148, 23, 159]
	| approx positives in sample 512: 68
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 7] [1, 3, 4, 13, 9, 15, 23]
episode: 29 -> reward: -124.99999999999213, steps:53472, time-elasped: 4604.55s
-> berries picked: 18 of 800 | patches-visited: [1] | positive-in-buffer: 674 | amount-filled: 100.00%
	| epsilon: 0.4880737540275333
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [20, 47, 85, 115, 67, 150, 23, 167]
	| approx positives in sample 512: 56
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 4, 7, 4, 4, 16, 5, 10]
episode: 30 -> reward: -124.99999999999334, steps:56736, time-elasped: 4765.89s
-> berries picked: 33 of 800 | patches-visited: [0, 8, 9] | positive-in-buffer: 706 | amount-filled: 100.00%
	| epsilon: 0.48768114981484806
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [21, 49, 87, 122, 67, 155, 24, 181]
	| approx positives in sample 512: 57
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7] [5, 5, 9, 1, 17, 3, 17]
episode: 31 -> reward: -124.99999999999346, steps:60096, time-elasped: 4938.43s
-> berries picked: 40 of 800 | patches-visited: [6, 9] | positive-in-buffer: 746 | amount-filled: 100.00%
	| epsilon: 0.4872888614111293
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [22, 52, 93, 129, 67, 160, 25, 198]
	| approx positives in sample 512: 63
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 7] [3, 3, 11, 16, 4, 11, 15]
episode: 32 -> reward: -124.9999999999939, steps:57216, time-elasped: 5117.76s
-> berries picked: 32 of 800 | patches-visited: [6, 7] | positive-in-buffer: 778 | amount-filled: 100.00%
	| epsilon: 0.4868968885623418
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [22, 55, 101, 134, 67, 164, 27, 208]
	| approx positives in sample 512: 62
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 5, 13, 12, 5, 8, 2, 15]
episode: 33 -> reward: -124.99999999999204, steps:49344, time-elasped: 5247.83s
-> berries picked: 4 of 800 | patches-visited: [0] | positive-in-buffer: 782 | amount-filled: 100.00%
	| epsilon: 0.4865052310146546
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [22, 55, 102, 136, 67, 164, 27, 209]
	| approx positives in sample 512: 52
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 7] [2, 5, 9, 8, 3, 11, 14]
episode: 34 -> reward: -124.99999999999208, steps:51168, time-elasped: 5385.81s
-> berries picked: 10 of 800 | patches-visited: [8] | positive-in-buffer: 792 | amount-filled: 100.00%
	| epsilon: 0.4861138885144411
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [22, 56, 105, 137, 67, 165, 28, 212]
	| approx positives in sample 512: 56
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7] [8, 12, 8, 2, 7, 4, 15]
episode: 35 -> reward: -124.99999999999369, steps:68448, time-elasped: 5569.95s
-> berries picked: 69 of 800 | patches-visited: [2, 4, 7] | positive-in-buffer: 861 | amount-filled: 100.00%
	| epsilon: 0.4857228608082785
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [24, 60, 111, 159, 71, 178, 30, 228]
	| approx positives in sample 512: 70
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 7, 8, 14, 7, 9, 2, 21]
episode: 36 -> reward: -124.9999999999921, steps:51264, time-elasped: 5719.90s
-> berries picked: 15 of 800 | patches-visited: [8] | positive-in-buffer: 876 | amount-filled: 100.00%
	| epsilon: 0.48533214764294796
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [25, 63, 115, 160, 71, 178, 31, 233]
	| approx positives in sample 512: 60
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 5, 11, 11, 4, 11, 3, 14]
episode: 37 -> reward: -124.99999999998954, steps:67776, time-elasped: 5907.57s
-> berries picked: 68 of 800 | patches-visited: [1, 4, 8] | positive-in-buffer: 941 | amount-filled: 100.00%
	| epsilon: 0.4849417487654344
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [27, 71, 128, 169, 79, 184, 32, 251]
	| approx positives in sample 512: 70
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 5, 11, 18, 3, 10, 3, 18]
episode: 38 -> reward: -124.99999999999207, steps:54336, time-elasped: 6089.90s
-> berries picked: 21 of 800 | patches-visited: [8] | positive-in-buffer: 962 | amount-filled: 100.00%
	| epsilon: 0.48455166392292615
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [27, 74, 131, 174, 79, 188, 34, 255]
	| approx positives in sample 512: 80
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 6, 9, 16, 5, 22, 1, 20]
episode: 39 -> reward: -124.99999999999245, steps:59616, time-elasped: 6261.79s
-> berries picked: 43 of 800 | patches-visited: [4, 6] | positive-in-buffer: 1005 | amount-filled: 100.00%
	| epsilon: 0.4841618928628149
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [29, 79, 136, 182, 79, 193, 34, 273]
	| approx positives in sample 512: 77
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 11, 6, 16, 7, 14, 2, 19]
episode: 40 -> reward: -124.99999999998775, steps:63840, time-elasped: 6428.56s
-> berries picked: 51 of 800 | patches-visited: [1, 9] | positive-in-buffer: 1055 | amount-filled: 100.00%
	| epsilon: 0.4837724353326957
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [30, 83, 145, 188, 81, 202, 34, 292]
	| approx positives in sample 512: 67
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 7, 8, 9, 7, 12, 1, 20]
episode: 41 -> reward: -124.99999999999284, steps:65568, time-elasped: 6588.96s
-> berries picked: 67 of 800 | patches-visited: [5, 6] | positive-in-buffer: 1122 | amount-filled: 100.00%
	| epsilon: 0.4833832910803664
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [31, 88, 157, 199, 83, 214, 35, 315]
	| approx positives in sample 512: 82
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 8, 16, 12, 5, 17, 3, 20]
episode: 42 -> reward: -124.99999999999251, steps:64128, time-elasped: 6762.51s
-> berries picked: 54 of 800 | patches-visited: [6, 7, 9] | positive-in-buffer: 1174 | amount-filled: 100.00%
	| epsilon: 0.48299445985382783
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [32, 95, 163, 208, 84, 225, 36, 331]
	| approx positives in sample 512: 77
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 5, 13, 11, 5, 16, 2, 23]
episode: 43 -> reward: -124.99999999999139, steps:56352, time-elasped: 6903.36s
-> berries picked: 30 of 800 | patches-visited: [0, 7] | positive-in-buffer: 1201 | amount-filled: 100.00%
	| epsilon: 0.4826059414012836
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [32, 104, 165, 216, 85, 227, 36, 336]
	| approx positives in sample 512: 74
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 9, 15, 11, 4, 7, 4, 22]
episode: 44 -> reward: -124.999999999992, steps:53760, time-elasped: 7087.81s
-> berries picked: 22 of 800 | patches-visited: [4] | positive-in-buffer: 1223 | amount-filled: 100.00%
	| epsilon: 0.4822177354711398
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [33, 108, 167, 220, 86, 231, 36, 342]
	| approx positives in sample 512: 70
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 6, 8, 9, 5, 13, 2, 23]
episode: 45 -> reward: -124.99999999999247, steps:63264, time-elasped: 7264.27s
-> berries picked: 53 of 800 | patches-visited: [3, 7, 9] | positive-in-buffer: 1275 | amount-filled: 100.00%
	| epsilon: 0.4818298418120048
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [35, 117, 175, 230, 87, 237, 37, 357]
	| approx positives in sample 512: 70
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7] [10, 7, 15, 4, 14, 1, 19]
episode: 46 -> reward: -124.99999999999213, steps:51456, time-elasped: 7455.32s
-> berries picked: 13 of 800 | patches-visited: [2] | positive-in-buffer: 1288 | amount-filled: 100.00%
	| epsilon: 0.4814422601726893
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [36, 118, 176, 233, 87, 239, 37, 362]
	| approx positives in sample 512: 65
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 7] [1, 5, 12, 11, 7, 9, 20]
episode: 47 -> reward: -124.99999999999201, steps:52416, time-elasped: 7649.55s
-> berries picked: 16 of 800 | patches-visited: [1] | positive-in-buffer: 1303 | amount-filled: 100.00%
	| epsilon: 0.48105499030220616
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [36, 122, 178, 236, 89, 241, 38, 363]
	| approx positives in sample 512: 82
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 9, 13, 16, 3, 16, 1, 23]
episode: 48 -> reward: -124.99999999999196, steps:53280, time-elasped: 7847.50s
-> berries picked: 18 of 800 | patches-visited: [4, 9] | positive-in-buffer: 1319 | amount-filled: 100.00%
	| epsilon: 0.48066803194976987
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [36, 125, 179, 238, 90, 245, 38, 368]
	| approx positives in sample 512: 55
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 4, 6, 16, 1, 10, 2, 12]
episode: 49 -> reward: -124.99999999999419, steps:71712, time-elasped: 8074.79s
-> berries picked: 83 of 800 | patches-visited: [3, 8] | positive-in-buffer: 1401 | amount-filled: 100.00%
	| epsilon: 0.4802813848647968
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [38, 138, 186, 252, 90, 259, 41, 397]
	| approx positives in sample 512: 94
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 14, 15, 14, 4, 17, 2, 25]
episode: 50 -> reward: -124.9999999999932, steps:68256, time-elasped: 8293.42s
-> berries picked: 69 of 800 | patches-visited: [3, 5, 8] | positive-in-buffer: 1469 | amount-filled: 100.00%
	| epsilon: 0.479895048796905
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [40, 153, 194, 267, 96, 267, 43, 409]
	| approx positives in sample 512: 72
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 7, 7, 10, 6, 17, 2, 20]
episode: 51 -> reward: -124.99999999999203, steps:53472, time-elasped: 8480.28s
-> berries picked: 20 of 800 | patches-visited: [4] | positive-in-buffer: 1488 | amount-filled: 100.00%
	| epsilon: 0.4795090234959137
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [40, 158, 195, 272, 97, 268, 43, 415]
	| approx positives in sample 512: 77
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7] [12, 11, 11, 6, 12, 3, 22]
episode: 52 -> reward: -124.9999999999918, steps:54624, time-elasped: 8658.74s
-> berries picked: 23 of 800 | patches-visited: [1, 5] | positive-in-buffer: 1511 | amount-filled: 100.00%
	| epsilon: 0.47912330871184344
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [42, 162, 197, 277, 97, 271, 44, 421]
	| approx positives in sample 512: 84
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 8, 8, 17, 13, 13, 2, 21]
episode: 53 -> reward: -124.99999999999201, steps:52512, time-elasped: 8848.72s
-> berries picked: 14 of 800 | patches-visited: [6] | positive-in-buffer: 1524 | amount-filled: 100.00%
	| epsilon: 0.478737904194916
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [42, 165, 197, 281, 98, 274, 45, 422]
	| approx positives in sample 512: 87
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 8, 15, 25, 6, 12, 4, 14]
episode: 54 -> reward: -124.99999999999189, steps:57888, time-elasped: 9054.85s
-> berries picked: 34 of 800 | patches-visited: [4] | positive-in-buffer: 1555 | amount-filled: 100.00%
	| epsilon: 0.4783528096955539
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [42, 172, 197, 286, 100, 277, 46, 435]
	| approx positives in sample 512: 82
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 13, 9, 18, 3, 13, 4, 20]
episode: 55 -> reward: -124.99999999999159, steps:58752, time-elasped: 9233.50s
-> berries picked: 35 of 800 | patches-visited: [9] | positive-in-buffer: 1590 | amount-filled: 100.00%
	| epsilon: 0.4779680249643805
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [43, 179, 199, 292, 102, 282, 47, 446]
	| approx positives in sample 512: 76
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 7] [3, 10, 8, 15, 10, 8, 22]
episode: 56 -> reward: -124.99999999999179, steps:56160, time-elasped: 9419.23s
-> berries picked: 29 of 800 | patches-visited: [1] | positive-in-buffer: 1618 | amount-filled: 100.00%
	| epsilon: 0.4775835497522197
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [44, 184, 202, 298, 102, 288, 47, 453]
	| approx positives in sample 512: 79
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 10, 9, 17, 4, 12, 2, 24]
episode: 57 -> reward: -124.99999999998984, steps:70272, time-elasped: 9596.55s
-> berries picked: 70 of 800 | patches-visited: [2, 3, 8] | positive-in-buffer: 1684 | amount-filled: 100.00%
	| epsilon: 0.4771993838100959
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [45, 194, 205, 320, 103, 300, 51, 466]
	| approx positives in sample 512: 76
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 12, 8, 14, 5, 16, 1, 18]
episode: 58 -> reward: -124.99999999999064, steps:70752, time-elasped: 9752.32s
-> berries picked: 77 of 800 | patches-visited: [2, 4] | positive-in-buffer: 1759 | amount-filled: 100.00%
	| epsilon: 0.4768155268892338
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [47, 206, 215, 335, 108, 313, 51, 484]
	| approx positives in sample 512: 99
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 15, 9, 17, 5, 14, 4, 29]
episode: 59 -> reward: -124.99999999999204, steps:54432, time-elasped: 9888.90s
-> berries picked: 21 of 800 | patches-visited: [2] | positive-in-buffer: 1777 | amount-filled: 100.00%
	| epsilon: 0.4764319787410581
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [47, 209, 216, 340, 110, 317, 51, 487]
	| approx positives in sample 512: 100
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 9, 13, 17, 10, 14, 6, 28]
episode: 60 -> reward: -124.99999999999223, steps:55104, time-elasped: 10024.05s
-> berries picked: 28 of 800 | patches-visited: [3] | positive-in-buffer: 1804 | amount-filled: 100.00%
	| epsilon: 0.4760487391171935
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [48, 211, 218, 344, 110, 327, 52, 494]
	| approx positives in sample 512: 97
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 10, 10, 17, 6, 20, 6, 26]
episode: 61 -> reward: -124.99999999999201, steps:60192, time-elasped: 10175.84s
-> berries picked: 49 of 800 | patches-visited: [1, 4, 9] | positive-in-buffer: 1849 | amount-filled: 100.00%
	| epsilon: 0.47566580776946454
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [48, 219, 223, 353, 116, 333, 53, 504]
	| approx positives in sample 512: 87
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 12, 10, 16, 7, 18, 5, 18]
episode: 62 -> reward: -124.99999999999217, steps:54816, time-elasped: 10320.49s
-> berries picked: 24 of 800 | patches-visited: [1] | positive-in-buffer: 1869 | amount-filled: 100.00%
	| epsilon: 0.47528318444989537
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [49, 222, 221, 360, 116, 339, 55, 507]
	| approx positives in sample 512: 90
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 11, 14, 23, 3, 11, 1, 25]
episode: 63 -> reward: -124.99999999999204, steps:52800, time-elasped: 10462.63s
-> berries picked: 16 of 800 | patches-visited: [2] | positive-in-buffer: 1882 | amount-filled: 100.00%
	| epsilon: 0.4749008689107096
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [50, 225, 220, 365, 117, 341, 55, 509]
	| approx positives in sample 512: 80
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 14, 9, 7, 6, 20, 2, 21]
episode: 64 -> reward: -124.99999999999287, steps:61440, time-elasped: 10618.31s
-> berries picked: 51 of 800 | patches-visited: [7, 9] | positive-in-buffer: 1931 | amount-filled: 100.00%
	| epsilon: 0.4745188609043301
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [53, 236, 220, 373, 123, 351, 55, 520]
	| approx positives in sample 512: 90
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 7] [1, 9, 11, 19, 4, 22, 24]
episode: 65 -> reward: -124.99999999999179, steps:54816, time-elasped: 10763.41s
-> berries picked: 23 of 800 | patches-visited: [0, 4] | positive-in-buffer: 1953 | amount-filled: 100.00%
	| epsilon: 0.474137160183379
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [53, 238, 220, 382, 124, 357, 56, 523]
	| approx positives in sample 512: 86
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 10, 7, 22, 8, 14, 2, 20]
episode: 66 -> reward: -124.99999999998941, steps:65472, time-elasped: 10925.07s
-> berries picked: 66 of 800 | patches-visited: [7, 9] | positive-in-buffer: 2016 | amount-filled: 100.00%
	| epsilon: 0.4737557665006773
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [57, 246, 221, 397, 127, 369, 56, 543]
	| approx positives in sample 512: 76
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 12, 7, 15, 3, 15, 4, 15]
episode: 67 -> reward: -124.99999999999216, steps:78240, time-elasped: 11085.63s
-> berries picked: 110 of 800 | patches-visited: [0, 2] | positive-in-buffer: 2117 | amount-filled: 100.00%
	| epsilon: 0.4733746796092449
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [60, 258, 224, 425, 130, 395, 56, 569]
	| approx positives in sample 512: 89
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 9, 12, 27, 6, 12, 2, 13]
episode: 68 -> reward: -124.99999999998653, steps:62400, time-elasped: 11236.19s
-> berries picked: 50 of 800 | patches-visited: [0, 4] | positive-in-buffer: 2161 | amount-filled: 100.00%
	| epsilon: 0.47299389926230045
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [61, 265, 227, 431, 134, 401, 59, 583]
	| approx positives in sample 512: 90
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 7, 17, 22, 4, 11, 1, 26]
episode: 69 -> reward: -124.99999999999183, steps:64704, time-elasped: 11384.82s
-> berries picked: 62 of 800 | patches-visited: [2] | positive-in-buffer: 2220 | amount-filled: 100.00%
	| epsilon: 0.4726134252132609
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [62, 271, 229, 445, 139, 414, 60, 600]
	| approx positives in sample 512: 82
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 10, 13, 17, 5, 10, 3, 23]
episode: 70 -> reward: -124.99999999999235, steps:59712, time-elasped: 11526.23s
-> berries picked: 47 of 800 | patches-visited: [9] | positive-in-buffer: 2263 | amount-filled: 100.00%
	| epsilon: 0.4722332572157417
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [66, 280, 230, 450, 142, 423, 62, 610]
	| approx positives in sample 512: 95
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 10, 11, 16, 10, 22, 2, 23]
episode: 71 -> reward: -124.9999999999918, steps:58848, time-elasped: 11657.92s
-> berries picked: 43 of 800 | patches-visited: [7] | positive-in-buffer: 2304 | amount-filled: 100.00%
	| epsilon: 0.4718533950235565
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [67, 288, 231, 459, 146, 429, 63, 621]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 9, 12, 24, 6, 15, 3, 32]
episode: 72 -> reward: -124.99999999998786, steps:71904, time-elasped: 11815.70s
-> berries picked: 91 of 800 | patches-visited: [2, 8] | positive-in-buffer: 2378 | amount-filled: 100.00%
	| epsilon: 0.47147383839071694
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [74, 299, 231, 469, 148, 442, 66, 649]
	| approx positives in sample 512: 89
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 13, 10, 23, 6, 11, 1, 24]
episode: 73 -> reward: -124.9999999999899, steps:61632, time-elasped: 11969.07s
-> berries picked: 50 of 800 | patches-visited: [3, 9] | positive-in-buffer: 2424 | amount-filled: 100.00%
	| epsilon: 0.4710945870714325
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [78, 302, 231, 480, 148, 455, 70, 660]
	| approx positives in sample 512: 89
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 12, 7, 21, 8, 16, 5, 19]
episode: 74 -> reward: -124.99999999999166, steps:76128, time-elasped: 12148.58s
-> berries picked: 117 of 800 | patches-visited: [2, 5] | positive-in-buffer: 2529 | amount-filled: 100.00%
	| epsilon: 0.47071564082011036
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [84, 317, 237, 508, 160, 472, 75, 676]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 15, 10, 17, 14, 13, 2, 29]
episode: 75 -> reward: -124.99999999999218, steps:56544, time-elasped: 12290.10s
-> berries picked: 31 of 800 | patches-visited: [3] | positive-in-buffer: 2558 | amount-filled: 100.00%
	| epsilon: 0.47033699939135537
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [85, 323, 237, 513, 164, 478, 76, 682]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 21, 15, 18, 7, 15, 4, 29]
episode: 76 -> reward: -124.99999999999211, steps:57600, time-elasped: 12430.57s
-> berries picked: 33 of 800 | patches-visited: [2] | positive-in-buffer: 2581 | amount-filled: 100.00%
	| epsilon: 0.4699586625399697
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [90, 326, 237, 514, 167, 486, 74, 687]
	| approx positives in sample 512: 91
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 8, 15, 13, 8, 22, 2, 21]
episode: 77 -> reward: -124.99999999999116, steps:64032, time-elasped: 12574.66s
-> berries picked: 54 of 800 | patches-visited: [1] | positive-in-buffer: 2628 | amount-filled: 100.00%
	| epsilon: 0.46958063002095274
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [95, 332, 236, 525, 168, 495, 74, 703]
	| approx positives in sample 512: 90
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 8, 10, 18, 8, 15, 1, 24]
episode: 78 -> reward: -124.9999999999922, steps:65088, time-elasped: 12731.13s
-> berries picked: 68 of 800 | patches-visited: [7] | positive-in-buffer: 2686 | amount-filled: 100.00%
	| epsilon: 0.46920290158950095
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [95, 338, 241, 534, 173, 507, 82, 716]
	| approx positives in sample 512: 96
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 15, 7, 22, 5, 8, 4, 33]
episode: 79 -> reward: -124.99999999998923, steps:81312, time-elasped: 12892.82s
-> berries picked: 126 of 800 | patches-visited: [1, 4] | positive-in-buffer: 2794 | amount-filled: 100.00%
	| epsilon: 0.46882547700100774
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [97, 350, 245, 554, 182, 528, 93, 745]
	| approx positives in sample 512: 102
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 15, 14, 16, 5, 14, 5, 31]
episode: 80 -> reward: -124.9999999999891, steps:63456, time-elasped: 13040.32s
-> berries picked: 53 of 800 | patches-visited: [1, 2] | positive-in-buffer: 2840 | amount-filled: 100.00%
	| epsilon: 0.4684483560110633
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [105, 357, 244, 561, 187, 536, 95, 755]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 15, 9, 30, 10, 10, 3, 28]
episode: 81 -> reward: -124.99999999998612, steps:76032, time-elasped: 13203.55s
-> berries picked: 102 of 800 | patches-visited: [0, 6] | positive-in-buffer: 2927 | amount-filled: 100.00%
	| epsilon: 0.46807153837545445
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [111, 372, 246, 578, 194, 554, 101, 771]
	| approx positives in sample 512: 90
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 9, 6, 11, 11, 17, 4, 27]
episode: 82 -> reward: -124.99999999999201, steps:54432, time-elasped: 13357.67s
-> berries picked: 24 of 800 | patches-visited: [5] | positive-in-buffer: 2948 | amount-filled: 100.00%
	| epsilon: 0.4676950238501643
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [112, 376, 247, 582, 194, 558, 101, 778]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 16, 9, 18, 14, 13, 2, 36]
episode: 83 -> reward: -124.99999999999241, steps:59040, time-elasped: 13508.99s
-> berries picked: 36 of 800 | patches-visited: [5] | positive-in-buffer: 2974 | amount-filled: 100.00%
	| epsilon: 0.46731881219137245
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [111, 383, 250, 587, 198, 559, 101, 785]
	| approx positives in sample 512: 91
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 12, 10, 19, 6, 16, 5, 21]
episode: 84 -> reward: -124.99999999999211, steps:51744, time-elasped: 13654.61s
-> berries picked: 14 of 800 | patches-visited: [8] | positive-in-buffer: 2987 | amount-filled: 100.00%
	| epsilon: 0.4669429031554544
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [112, 386, 250, 588, 199, 561, 103, 788]
	| approx positives in sample 512: 106
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 12, 8, 20, 17, 9, 2, 32]
episode: 85 -> reward: -124.9999999999888, steps:62208, time-elasped: 13804.49s
-> berries picked: 46 of 800 | patches-visited: [2, 5] | positive-in-buffer: 3022 | amount-filled: 100.00%
	| epsilon: 0.4665672964989819
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [113, 400, 247, 595, 203, 565, 106, 793]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 18, 7, 23, 6, 18, 1, 32]
episode: 86 -> reward: -124.99999999999068, steps:71424, time-elasped: 13975.51s
-> berries picked: 81 of 800 | patches-visited: [3, 6] | positive-in-buffer: 3092 | amount-filled: 100.00%
	| epsilon: 0.4661919919787222
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [120, 408, 249, 610, 209, 578, 111, 807]
	| approx positives in sample 512: 90
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 13, 9, 15, 3, 19, 4, 22]
episode: 87 -> reward: -124.99999999999025, steps:65952, time-elasped: 14136.91s
-> berries picked: 72 of 800 | patches-visited: [2] | positive-in-buffer: 3147 | amount-filled: 100.00%
	| epsilon: 0.4658169893516384
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [128, 418, 254, 623, 211, 585, 114, 814]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 15, 3, 22, 4, 20, 3, 38]
episode: 88 -> reward: -124.9999999999925, steps:63744, time-elasped: 14285.53s
-> berries picked: 62 of 800 | patches-visited: [8] | positive-in-buffer: 3200 | amount-filled: 100.00%
	| epsilon: 0.46544228837488916
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [130, 433, 255, 629, 217, 593, 120, 823]
	| approx positives in sample 512: 108
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 14, 10, 24, 9, 12, 9, 26]
episode: 89 -> reward: -124.99999999999206, steps:52416, time-elasped: 14416.86s
-> berries picked: 16 of 800 | patches-visited: [9] | positive-in-buffer: 3209 | amount-filled: 100.00%
	| epsilon: 0.4650678888058283
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [131, 434, 255, 629, 218, 593, 121, 828]
	| approx positives in sample 512: 105
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 15, 9, 18, 8, 17, 8, 25]
episode: 90 -> reward: -124.99999999998934, steps:73152, time-elasped: 14578.20s
-> berries picked: 91 of 800 | patches-visited: [3, 5, 6, 7] | positive-in-buffer: 3281 | amount-filled: 100.00%
	| epsilon: 0.4646937904020049
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [135, 446, 260, 642, 219, 612, 126, 841]
	| approx positives in sample 512: 99
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 15, 7, 22, 4, 17, 5, 23]
episode: 91 -> reward: -124.9999999999928, steps:62304, time-elasped: 14731.94s
-> berries picked: 48 of 800 | patches-visited: [3, 7] | positive-in-buffer: 3322 | amount-filled: 100.00%
	| epsilon: 0.4643199929211631
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [136, 454, 262, 648, 224, 617, 128, 853]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 20, 6, 24, 9, 22, 3, 27]
episode: 92 -> reward: -124.999999999992, steps:53760, time-elasped: 14874.34s
-> berries picked: 23 of 800 | patches-visited: [4] | positive-in-buffer: 3343 | amount-filled: 100.00%
	| epsilon: 0.4639464961212419
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [136, 458, 264, 655, 224, 621, 129, 856]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 15, 12, 22, 6, 27, 3, 27]
episode: 93 -> reward: -124.9999999999792, steps:90816, time-elasped: 15052.21s
-> berries picked: 151 of 800 | patches-visited: [3, 4, 7, 8] | positive-in-buffer: 3469 | amount-filled: 100.00%
	| epsilon: 0.463573299760375
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [138, 476, 271, 677, 239, 642, 133, 893]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 11, 10, 24, 8, 15, 3, 22]
episode: 94 -> reward: -124.9999999999917, steps:63648, time-elasped: 15190.79s
-> berries picked: 54 of 800 | patches-visited: [6] | positive-in-buffer: 3514 | amount-filled: 100.00%
	| epsilon: 0.4632004035968905
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [143, 481, 272, 687, 246, 648, 138, 899]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 12, 9, 26, 15, 19, 1, 35]
episode: 95 -> reward: -124.99999999999194, steps:57792, time-elasped: 15338.20s
-> berries picked: 33 of 800 | patches-visited: [0] | positive-in-buffer: 3539 | amount-filled: 100.00%
	| epsilon: 0.4628278073893113
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [145, 482, 273, 695, 247, 657, 141, 899]
	| approx positives in sample 512: 100
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 8, 6, 22, 4, 16, 3, 39]
episode: 96 -> reward: -124.99999999999274, steps:60096, time-elasped: 15490.70s
-> berries picked: 43 of 800 | patches-visited: [4] | positive-in-buffer: 3575 | amount-filled: 100.00%
	| epsilon: 0.4624555108963541
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [147, 487, 273, 706, 249, 665, 145, 903]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 12, 7, 23, 8, 15, 7, 36]
episode: 97 -> reward: -124.99999999999196, steps:56352, time-elasped: 15627.53s
-> berries picked: 29 of 800 | patches-visited: [3] | positive-in-buffer: 3598 | amount-filled: 100.00%
	| epsilon: 0.4620835138769299
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [147, 491, 273, 710, 253, 672, 147, 905]
	| approx positives in sample 512: 112
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 17, 5, 21, 9, 19, 7, 27]
episode: 98 -> reward: -124.99999999999184, steps:59136, time-elasped: 15760.20s
-> berries picked: 40 of 800 | patches-visited: [4] | positive-in-buffer: 3629 | amount-filled: 100.00%
	| epsilon: 0.4617118160901437
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [148, 494, 274, 715, 257, 673, 152, 916]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 23, 9, 30, 11, 21, 3, 41]
episode: 99 -> reward: -124.99999999998748, steps:75936, time-elasped: 15925.34s
-> berries picked: 100 of 800 | patches-visited: [0, 5] | positive-in-buffer: 3714 | amount-filled: 100.00%
	| epsilon: 0.4613404172952942
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [160, 509, 275, 726, 266, 693, 161, 924]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 18, 5, 30, 9, 22, 3, 28]
episode: 100 -> reward: -124.99999999999201, steps:51264, time-elasped: 16049.14s
-> berries picked: 9 of 800 | patches-visited: [8] | positive-in-buffer: 3719 | amount-filled: 100.00%
	| epsilon: 0.46096931725187357
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [160, 508, 275, 726, 268, 693, 164, 925]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 15, 11, 30, 9, 22, 6, 34]
episode: 101 -> reward: -124.99999999999018, steps:72576, time-elasped: 16223.75s
-> berries picked: 94 of 800 | patches-visited: [4, 6] | positive-in-buffer: 3789 | amount-filled: 100.00%
	| epsilon: 0.4605985157195676
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [160, 517, 278, 754, 277, 705, 164, 934]
	| approx positives in sample 512: 113
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 9, 9, 24, 14, 19, 6, 25]
episode: 102 -> reward: -124.99999999999201, steps:50496, time-elasped: 16345.39s
-> berries picked: 8 of 800 | patches-visited: [2] | positive-in-buffer: 3791 | amount-filled: 100.00%
	| epsilon: 0.4602280124582555
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [160, 518, 278, 752, 278, 706, 165, 934]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 13, 13, 21, 8, 16, 6, 22]
episode: 103 -> reward: -124.99999999999203, steps:49536, time-elasped: 16474.92s
-> berries picked: 7 of 800 | patches-visited: [4] | positive-in-buffer: 3795 | amount-filled: 100.00%
	| epsilon: 0.45985780722800934
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [160, 520, 278, 752, 279, 704, 166, 936]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 13, 9, 28, 11, 21, 1, 23]
episode: 104 -> reward: -124.99999999999199, steps:52896, time-elasped: 16620.71s
-> berries picked: 17 of 800 | patches-visited: [7] | positive-in-buffer: 3808 | amount-filled: 100.00%
	| epsilon: 0.4594878997890945
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [161, 524, 279, 754, 280, 705, 166, 939]
	| approx positives in sample 512: 111
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 14, 7, 23, 6, 20, 7, 29]
episode: 105 -> reward: -124.99999999999307, steps:62208, time-elasped: 16777.53s
-> berries picked: 52 of 800 | patches-visited: [2] | positive-in-buffer: 3850 | amount-filled: 100.00%
	| epsilon: 0.4591182899019689
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [166, 529, 279, 761, 283, 711, 170, 951]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 14, 11, 24, 12, 22, 5, 32]
episode: 106 -> reward: -124.99999999999216, steps:54144, time-elasped: 16912.15s
-> berries picked: 20 of 800 | patches-visited: [5] | positive-in-buffer: 3867 | amount-filled: 100.00%
	| epsilon: 0.45874897732728337
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [165, 534, 280, 763, 283, 715, 171, 956]
	| approx positives in sample 512: 116
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 17, 11, 17, 12, 19, 3, 32]
episode: 107 -> reward: -124.99999999998875, steps:66816, time-elasped: 17068.17s
-> berries picked: 64 of 800 | patches-visited: [0, 1] | positive-in-buffer: 3907 | amount-filled: 100.00%
	| epsilon: 0.45837996182588114
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [169, 541, 284, 772, 282, 724, 172, 963]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 11, 11, 25, 6, 17, 6, 27]
episode: 108 -> reward: -124.99999999999174, steps:61728, time-elasped: 17222.96s
-> berries picked: 53 of 800 | patches-visited: [9] | positive-in-buffer: 3952 | amount-filled: 100.00%
	| epsilon: 0.45801124315879793
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [171, 549, 285, 783, 283, 734, 182, 965]
	| approx positives in sample 512: 109
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 12, 5, 22, 12, 21, 6, 20]
episode: 109 -> reward: -124.99999999998906, steps:77280, time-elasped: 17401.44s
-> berries picked: 116 of 800 | patches-visited: [4, 7, 9] | positive-in-buffer: 4051 | amount-filled: 100.00%
	| epsilon: 0.4576428210872616
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [187, 555, 303, 798, 290, 749, 189, 980]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 16, 6, 18, 8, 29, 5, 28]
episode: 110 -> reward: -124.99999999999199, steps:53856, time-elasped: 17527.65s
-> berries picked: 21 of 800 | patches-visited: [7] | positive-in-buffer: 4062 | amount-filled: 100.00%
	| epsilon: 0.4572746953726921
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [188, 560, 304, 798, 291, 749, 190, 982]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 9, 12, 23, 14, 31, 9, 28]
episode: 111 -> reward: -124.999999999992, steps:60000, time-elasped: 17680.14s
-> berries picked: 40 of 800 | patches-visited: [5] | positive-in-buffer: 4097 | amount-filled: 100.00%
	| epsilon: 0.4569068657767013
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [192, 565, 308, 799, 290, 760, 192, 991]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 21, 13, 19, 9, 22, 5, 25]
episode: 112 -> reward: -124.99999999998923, steps:67392, time-elasped: 17841.88s
-> berries picked: 72 of 800 | patches-visited: [0, 7] | positive-in-buffer: 4141 | amount-filled: 100.00%
	| epsilon: 0.4565393320610928
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [192, 577, 310, 809, 292, 761, 203, 997]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 15, 9, 26, 6, 17, 9, 37]
episode: 113 -> reward: -124.99999999999271, steps:60288, time-elasped: 17978.29s
-> berries picked: 44 of 800 | patches-visited: [2, 7] | positive-in-buffer: 4183 | amount-filled: 100.00%
	| epsilon: 0.45617209398786185
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [196, 582, 312, 817, 297, 771, 204, 1004]
	| approx positives in sample 512: 115
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 15, 7, 32, 7, 18, 4, 22]
episode: 114 -> reward: -124.9999999999906, steps:68448, time-elasped: 18127.93s
-> berries picked: 83 of 800 | patches-visited: [6, 9] | positive-in-buffer: 4248 | amount-filled: 100.00%
	| epsilon: 0.4558051513191951
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [198, 591, 310, 834, 304, 781, 215, 1015]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 17, 7, 29, 14, 19, 6, 31]
episode: 115 -> reward: -124.99999999999405, steps:65952, time-elasped: 18280.82s
-> berries picked: 58 of 800 | patches-visited: [2, 6] | positive-in-buffer: 4281 | amount-filled: 100.00%
	| epsilon: 0.45543850381747053
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [203, 597, 313, 836, 308, 786, 216, 1022]
	| approx positives in sample 512: 147
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 15, 10, 34, 18, 20, 7, 36]
episode: 116 -> reward: -124.99999999998674, steps:79200, time-elasped: 18473.28s
-> berries picked: 108 of 800 | patches-visited: [0, 2, 3] | positive-in-buffer: 4369 | amount-filled: 100.00%
	| epsilon: 0.4550721512452572
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [211, 615, 318, 858, 308, 795, 224, 1040]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 17, 14, 22, 8, 22, 6, 35]
episode: 117 -> reward: -124.99999999999177, steps:62016, time-elasped: 18622.33s
-> berries picked: 51 of 800 | patches-visited: [0, 4] | positive-in-buffer: 4416 | amount-filled: 100.00%
	| epsilon: 0.4547060933653153
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [213, 622, 324, 859, 310, 803, 235, 1050]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 22, 11, 24, 10, 19, 5, 36]
episode: 118 -> reward: -124.99999999999176, steps:67488, time-elasped: 18798.73s
-> berries picked: 77 of 800 | patches-visited: [4, 8] | positive-in-buffer: 4478 | amount-filled: 100.00%
	| epsilon: 0.4543403299405957
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [215, 623, 333, 872, 320, 808, 243, 1064]
	| approx positives in sample 512: 118
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 22, 11, 20, 9, 20, 7, 25]
episode: 119 -> reward: -124.99999999999359, steps:73728, time-elasped: 18961.14s
-> berries picked: 95 of 800 | patches-visited: [3, 8] | positive-in-buffer: 4540 | amount-filled: 100.00%
	| epsilon: 0.45397486073424004
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [224, 638, 336, 887, 327, 807, 246, 1075]
	| approx positives in sample 512: 114
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 15, 7, 20, 4, 17, 9, 38]
episode: 120 -> reward: -124.99999999999238, steps:63744, time-elasped: 19106.38s
-> berries picked: 64 of 800 | patches-visited: [7] | positive-in-buffer: 4595 | amount-filled: 100.00%
	| epsilon: 0.4536096855095805
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [233, 641, 341, 891, 338, 814, 253, 1084]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 21, 14, 31, 7, 18, 8, 30]
episode: 121 -> reward: -124.9999999999933, steps:62880, time-elasped: 19253.25s
-> berries picked: 52 of 800 | patches-visited: [4, 7] | positive-in-buffer: 4630 | amount-filled: 100.00%
	| epsilon: 0.4532448040301395
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [232, 647, 345, 896, 343, 823, 255, 1089]
	| approx positives in sample 512: 139
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 22, 10, 28, 14, 27, 9, 24]
episode: 122 -> reward: -124.99999999999305, steps:64896, time-elasped: 19397.17s
-> berries picked: 72 of 800 | patches-visited: [0] | positive-in-buffer: 4688 | amount-filled: 100.00%
	| epsilon: 0.45288021605962986
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [237, 647, 352, 905, 350, 830, 270, 1097]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 12, 8, 24, 12, 29, 11, 33]
episode: 123 -> reward: -124.99999999998698, steps:77952, time-elasped: 19565.95s
-> berries picked: 106 of 800 | patches-visited: [4, 6] | positive-in-buffer: 4765 | amount-filled: 100.00%
	| epsilon: 0.4525159213619544
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [241, 654, 366, 916, 354, 852, 274, 1108]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 17, 9, 26, 11, 28, 9, 31]
episode: 124 -> reward: -124.9999999999914, steps:67584, time-elasped: 19713.46s
-> berries picked: 72 of 800 | patches-visited: [7] | positive-in-buffer: 4828 | amount-filled: 100.00%
	| epsilon: 0.4521519197012058
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [248, 657, 376, 925, 358, 860, 283, 1121]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 10, 4, 27, 14, 22, 7, 35]
episode: 125 -> reward: -124.99999999999332, steps:62976, time-elasped: 19858.94s
-> berries picked: 57 of 800 | patches-visited: [4] | positive-in-buffer: 4867 | amount-filled: 100.00%
	| epsilon: 0.45178821084166654
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [248, 662, 379, 936, 361, 866, 291, 1124]
	| approx positives in sample 512: 151
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 30, 10, 26, 10, 18, 5, 42]
episode: 126 -> reward: -124.9999999999923, steps:59040, time-elasped: 19997.12s
-> berries picked: 38 of 800 | patches-visited: [6] | positive-in-buffer: 4891 | amount-filled: 100.00%
	| epsilon: 0.4514247945478087
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [250, 667, 381, 940, 361, 874, 292, 1126]
	| approx positives in sample 512: 125
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 15, 8, 23, 6, 25, 6, 34]
episode: 127 -> reward: -124.99999999998741, steps:78816, time-elasped: 20177.23s
-> berries picked: 109 of 800 | patches-visited: [4, 5, 9] | positive-in-buffer: 4979 | amount-filled: 100.00%
	| epsilon: 0.4510616705842939
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [259, 680, 390, 950, 373, 885, 299, 1143]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 18, 7, 30, 9, 24, 2, 31]
episode: 128 -> reward: -124.99999999999139, steps:67200, time-elasped: 20337.80s
-> berries picked: 79 of 800 | patches-visited: [4] | positive-in-buffer: 5052 | amount-filled: 100.00%
	| epsilon: 0.450698838715973
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [267, 685, 404, 966, 381, 895, 304, 1150]
	| approx positives in sample 512: 129
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 20, 12, 25, 14, 21, 8, 27]
episode: 129 -> reward: -124.99999999999254, steps:65568, time-elasped: 20496.73s
-> berries picked: 58 of 800 | patches-visited: [0, 5] | positive-in-buffer: 5092 | amount-filled: 100.00%
	| epsilon: 0.45033629870788594
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [273, 689, 403, 977, 385, 894, 311, 1160]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 21, 8, 30, 8, 32, 8, 23]
episode: 130 -> reward: -124.99999999999123, steps:61056, time-elasped: 20659.34s
-> berries picked: 44 of 800 | patches-visited: [2] | positive-in-buffer: 5126 | amount-filled: 100.00%
	| epsilon: 0.4499740503252617
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [275, 689, 415, 982, 388, 903, 312, 1162]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 10, 11, 21, 13, 21, 11, 34]
episode: 131 -> reward: -124.99999999999366, steps:72576, time-elasped: 20823.78s
-> berries picked: 92 of 800 | patches-visited: [0, 7] | positive-in-buffer: 5200 | amount-filled: 100.00%
	| epsilon: 0.4496120933335183
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [284, 698, 426, 1001, 386, 912, 319, 1174]
	| approx positives in sample 512: 145
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 25, 7, 33, 13, 19, 7, 29]
episode: 132 -> reward: -124.99999999998722, steps:77760, time-elasped: 21000.21s
-> berries picked: 119 of 800 | patches-visited: [1, 7] | positive-in-buffer: 5294 | amount-filled: 100.00%
	| epsilon: 0.4492504274982622
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [291, 706, 443, 1017, 393, 925, 327, 1192]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 17, 12, 26, 13, 24, 7, 20]
episode: 133 -> reward: -124.99999999999308, steps:65088, time-elasped: 21154.23s
-> berries picked: 72 of 800 | patches-visited: [0] | positive-in-buffer: 5348 | amount-filled: 100.00%
	| epsilon: 0.4488890525852885
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [305, 711, 444, 1022, 399, 931, 336, 1200]
	| approx positives in sample 512: 147
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 24, 10, 29, 15, 24, 2, 31]
episode: 134 -> reward: -124.99999999998896, steps:75840, time-elasped: 21322.13s
-> berries picked: 99 of 800 | patches-visited: [1, 4, 6] | positive-in-buffer: 5419 | amount-filled: 100.00%
	| epsilon: 0.4485279683605807
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [312, 722, 454, 1031, 405, 940, 345, 1210]
	| approx positives in sample 512: 122
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 18, 12, 17, 7, 23, 4, 37]
episode: 135 -> reward: -124.99999999998458, steps:80544, time-elasped: 21503.25s
-> berries picked: 117 of 800 | patches-visited: [0, 7] | positive-in-buffer: 5514 | amount-filled: 100.00%
	| epsilon: 0.4481671745903105
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [324, 736, 454, 1045, 410, 951, 364, 1230]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 10, 14, 28, 16, 27, 9, 31]
episode: 136 -> reward: -124.99999999999118, steps:67200, time-elasped: 21700.91s
-> berries picked: 76 of 800 | patches-visited: [7] | positive-in-buffer: 5575 | amount-filled: 100.00%
	| epsilon: 0.4478066710408379
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [333, 744, 462, 1060, 412, 954, 375, 1235]
	| approx positives in sample 512: 139
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 13, 19, 23, 10, 27, 8, 34]
episode: 137 -> reward: -124.99999999999214, steps:55488, time-elasped: 21860.98s
-> berries picked: 29 of 800 | patches-visited: [8] | positive-in-buffer: 5588 | amount-filled: 100.00%
	| epsilon: 0.4474464574787104
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [331, 747, 461, 1063, 414, 955, 379, 1238]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 16, 12, 41, 6, 22, 8, 34]
episode: 138 -> reward: -124.99999999998681, steps:82656, time-elasped: 22130.48s
-> berries picked: 127 of 800 | patches-visited: [2, 3, 9] | positive-in-buffer: 5696 | amount-filled: 100.00%
	| epsilon: 0.44708653367066375
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [339, 759, 478, 1084, 434, 964, 388, 1250]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 22, 12, 27, 9, 20, 8, 27]
episode: 139 -> reward: -124.99999999999075, steps:60192, time-elasped: 22346.27s
-> berries picked: 45 of 800 | patches-visited: [1] | positive-in-buffer: 5724 | amount-filled: 100.00%
	| epsilon: 0.4467268993836211
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [345, 761, 480, 1089, 439, 968, 394, 1248]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 21, 11, 20, 18, 25, 14, 23]
episode: 140 -> reward: -124.99999999999146, steps:62784, time-elasped: 22567.22s
-> berries picked: 62 of 800 | patches-visited: [2] | positive-in-buffer: 5780 | amount-filled: 100.00%
	| epsilon: 0.4463675543846931
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [346, 768, 490, 1099, 443, 979, 398, 1257]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 12, 12, 30, 10, 26, 14, 30]
episode: 141 -> reward: -124.999999999991, steps:64896, time-elasped: 22784.76s
-> berries picked: 72 of 800 | patches-visited: [4] | positive-in-buffer: 5830 | amount-filled: 100.00%
	| epsilon: 0.44600849844117774
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [354, 779, 497, 1113, 443, 984, 406, 1254]
	| approx positives in sample 512: 145
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 19, 13, 22, 12, 18, 9, 42]
episode: 142 -> reward: -124.99999999999199, steps:63264, time-elasped: 23012.47s
-> berries picked: 57 of 800 | patches-visited: [3] | positive-in-buffer: 5858 | amount-filled: 100.00%
	| epsilon: 0.4456497313205603
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [358, 781, 498, 1114, 451, 989, 407, 1260]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 15, 11, 24, 7, 23, 9, 38]
episode: 143 -> reward: -124.99999999998562, steps:78912, time-elasped: 23264.97s
-> berries picked: 112 of 800 | patches-visited: [1, 5] | positive-in-buffer: 5944 | amount-filled: 100.00%
	| epsilon: 0.44529125279051296
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [363, 793, 505, 1131, 462, 1001, 413, 1276]
	| approx positives in sample 512: 149
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 27, 12, 19, 14, 23, 13, 34]
episode: 144 -> reward: -124.99999999999199, steps:57120, time-elasped: 23435.76s
-> berries picked: 32 of 800 | patches-visited: [8] | positive-in-buffer: 5961 | amount-filled: 100.00%
	| epsilon: 0.4449330626188948
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [365, 791, 505, 1138, 463, 1006, 415, 1278]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 28, 12, 25, 12, 20, 5, 28]
episode: 145 -> reward: -124.9999999999913, steps:66336, time-elasped: 23633.85s
-> berries picked: 69 of 800 | patches-visited: [1] | positive-in-buffer: 6021 | amount-filled: 100.00%
	| epsilon: 0.44457516057375174
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [376, 799, 513, 1152, 469, 1011, 421, 1280]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 27, 13, 26, 8, 13, 7, 36]
episode: 146 -> reward: -124.9999999999921, steps:64992, time-elasped: 23815.47s
-> berries picked: 69 of 800 | patches-visited: [2, 8] | positive-in-buffer: 6073 | amount-filled: 100.00%
	| epsilon: 0.4442175464233162
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [380, 804, 529, 1161, 467, 1026, 418, 1288]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 17, 17, 24, 18, 23, 8, 30]
episode: 147 -> reward: -124.99999999999142, steps:63936, time-elasped: 23969.95s
-> berries picked: 60 of 800 | patches-visited: [8] | positive-in-buffer: 6114 | amount-filled: 100.00%
	| epsilon: 0.44386021993600694
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [381, 806, 533, 1173, 476, 1034, 423, 1288]
	| approx positives in sample 512: 150
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 27, 12, 28, 13, 24, 12, 27]
episode: 148 -> reward: -124.99999999998771, steps:77952, time-elasped: 24141.92s
-> berries picked: 126 of 800 | patches-visited: [0, 2] | positive-in-buffer: 6227 | amount-filled: 100.00%
	| epsilon: 0.4435031808804292
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [390, 829, 542, 1197, 479, 1046, 445, 1299]
	| approx positives in sample 512: 145
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 23, 17, 20, 14, 24, 8, 23]
episode: 149 -> reward: -124.99999999999211, steps:54624, time-elasped: 24274.49s
-> berries picked: 22 of 800 | patches-visited: [6] | positive-in-buffer: 6223 | amount-filled: 100.00%
	| epsilon: 0.44314642902537427
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [392, 825, 545, 1196, 481, 1048, 436, 1300]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 23, 12, 20, 8, 29, 12, 21]
episode: 150 -> reward: -124.99999999998852, steps:71424, time-elasped: 24436.57s
-> berries picked: 90 of 800 | patches-visited: [3, 4] | positive-in-buffer: 6299 | amount-filled: 100.00%
	| epsilon: 0.4427899641398194
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [409, 831, 555, 1201, 489, 1058, 445, 1311]
	| approx positives in sample 512: 159
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 14, 16, 35, 10, 23, 11, 37]
episode: 151 -> reward: -124.99999999999106, steps:68256, time-elasped: 24592.01s
-> berries picked: 78 of 800 | patches-visited: [0] | positive-in-buffer: 6357 | amount-filled: 100.00%
	| epsilon: 0.44243378599292765
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [419, 833, 572, 1208, 490, 1068, 447, 1320]
	| approx positives in sample 512: 152
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 26, 10, 31, 14, 22, 7, 31]
episode: 152 -> reward: -124.99999999998498, steps:82080, time-elasped: 24775.04s
-> berries picked: 129 of 800 | patches-visited: [1, 6] | positive-in-buffer: 6440 | amount-filled: 100.00%
	| epsilon: 0.4420778943540478
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [429, 845, 579, 1222, 509, 1070, 454, 1332]
	| approx positives in sample 512: 150
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 22, 12, 34, 11, 21, 9, 30]
episode: 153 -> reward: -124.99999999998995, steps:59232, time-elasped: 24964.69s
-> berries picked: 41 of 800 | patches-visited: [2, 4, 9] | positive-in-buffer: 6463 | amount-filled: 100.00%
	| epsilon: 0.4417222889927142
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [430, 847, 581, 1228, 503, 1078, 460, 1336]
	| approx positives in sample 512: 155
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 20, 14, 34, 6, 22, 10, 39]
episode: 154 -> reward: -124.99999999998604, steps:78912, time-elasped: 25196.60s
-> berries picked: 121 of 800 | patches-visited: [5, 6] | positive-in-buffer: 6554 | amount-filled: 100.00%
	| epsilon: 0.4413669696786466
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [445, 854, 589, 1234, 511, 1086, 475, 1360]
	| approx positives in sample 512: 161
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 14, 23, 26, 19, 28, 13, 31]
episode: 155 -> reward: -124.99999999999048, steps:61248, time-elasped: 25455.13s
-> berries picked: 52 of 800 | patches-visited: [2] | positive-in-buffer: 6581 | amount-filled: 100.00%
	| epsilon: 0.4410119361817498
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [448, 856, 598, 1238, 517, 1086, 479, 1359]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 26, 21, 26, 8, 24, 10, 20]
episode: 156 -> reward: -124.99999999998728, steps:75264, time-elasped: 25699.77s
-> berries picked: 101 of 800 | patches-visited: [1, 8] | positive-in-buffer: 6658 | amount-filled: 100.00%
	| epsilon: 0.44065718827211386
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [459, 875, 601, 1255, 520, 1089, 490, 1369]
	| approx positives in sample 512: 166
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 19, 14, 32, 13, 22, 10, 41]
episode: 157 -> reward: -124.99999999999055, steps:67968, time-elasped: 25885.93s
-> berries picked: 80 of 800 | patches-visited: [5] | positive-in-buffer: 6721 | amount-filled: 100.00%
	| epsilon: 0.44030272572001383
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [462, 874, 620, 1263, 535, 1094, 493, 1380]
	| approx positives in sample 512: 147
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 25, 11, 18, 12, 30, 14, 28]
episode: 158 -> reward: -124.99999999998563, steps:85056, time-elasped: 26088.75s
-> berries picked: 131 of 800 | patches-visited: [4, 6] | positive-in-buffer: 6802 | amount-filled: 100.00%
	| epsilon: 0.43994854829590935
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [474, 890, 628, 1273, 541, 1095, 518, 1383]
	| approx positives in sample 512: 147
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 23, 9, 32, 8, 25, 11, 31]
episode: 159 -> reward: -124.99999999999025, steps:67872, time-elasped: 26266.19s
-> berries picked: 80 of 800 | patches-visited: [4] | positive-in-buffer: 6870 | amount-filled: 100.00%
	| epsilon: 0.43959465577044493
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [484, 900, 629, 1285, 543, 1099, 536, 1394]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 18, 12, 21, 15, 16, 8, 29]
episode: 160 -> reward: -124.99999999998832, steps:72480, time-elasped: 26443.92s
-> berries picked: 89 of 800 | patches-visited: [0, 2] | positive-in-buffer: 6936 | amount-filled: 100.00%
	| epsilon: 0.43924104791444935
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [494, 911, 642, 1285, 549, 1103, 539, 1413]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 20, 11, 31, 13, 25, 11, 24]
episode: 161 -> reward: -124.99999999998805, steps:80544, time-elasped: 26624.84s
-> berries picked: 125 of 800 | patches-visited: [2, 6] | positive-in-buffer: 7025 | amount-filled: 100.00%
	| epsilon: 0.4388877244989359
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [505, 928, 645, 1313, 557, 1109, 546, 1422]
	| approx positives in sample 512: 165
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 21, 20, 26, 9, 20, 6, 49]
episode: 162 -> reward: -124.9999999999913, steps:66816, time-elasped: 26796.70s
-> berries picked: 78 of 800 | patches-visited: [2] | positive-in-buffer: 7082 | amount-filled: 100.00%
	| epsilon: 0.438534685295102
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [512, 931, 660, 1318, 563, 1116, 547, 1435]
	| approx positives in sample 512: 152
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 17, 15, 32, 12, 21, 11, 34]
episode: 163 -> reward: -124.99999999999012, steps:63648, time-elasped: 26961.90s
-> berries picked: 63 of 800 | patches-visited: [8] | positive-in-buffer: 7111 | amount-filled: 100.00%
	| epsilon: 0.4381819300743291
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [512, 931, 660, 1327, 565, 1128, 550, 1438]
	| approx positives in sample 512: 168
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 22, 12, 39, 14, 31, 6, 39]
episode: 164 -> reward: -124.99999999998504, steps:80928, time-elasped: 27140.98s
-> berries picked: 128 of 800 | patches-visited: [3, 8] | positive-in-buffer: 7197 | amount-filled: 100.00%
	| epsilon: 0.43782945860818256
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [526, 945, 671, 1335, 573, 1131, 567, 1449]
	| approx positives in sample 512: 147
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 22, 24, 21, 14, 19, 11, 23]
episode: 165 -> reward: -124.99999999999267, steps:66624, time-elasped: 27316.31s
-> berries picked: 66 of 800 | patches-visited: [4] | positive-in-buffer: 7239 | amount-filled: 100.00%
	| epsilon: 0.4374772706684116
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [532, 951, 679, 1340, 577, 1138, 564, 1458]
	| approx positives in sample 512: 162
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 22, 17, 33, 13, 24, 11, 30]
episode: 166 -> reward: -124.99999999999132, steps:62688, time-elasped: 27490.37s
-> berries picked: 61 of 800 | patches-visited: [8] | positive-in-buffer: 7284 | amount-filled: 100.00%
	| epsilon: 0.4371253660269488
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [537, 957, 687, 1347, 585, 1138, 572, 1461]
	| approx positives in sample 512: 164
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 20, 13, 45, 15, 24, 15, 23]
episode: 167 -> reward: -124.99999999999243, steps:66048, time-elasped: 27658.25s
-> berries picked: 74 of 800 | patches-visited: [6] | positive-in-buffer: 7335 | amount-filled: 100.00%
	| epsilon: 0.43677374445591044
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [543, 965, 691, 1356, 587, 1144, 575, 1474]
	| approx positives in sample 512: 150
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 22, 12, 27, 10, 32, 4, 31]
episode: 168 -> reward: -124.99999999999187, steps:59616, time-elasped: 27826.87s
-> berries picked: 42 of 800 | patches-visited: [1] | positive-in-buffer: 7356 | amount-filled: 100.00%
	| epsilon: 0.436422405727596
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [545, 967, 695, 1360, 593, 1142, 575, 1479]
	| approx positives in sample 512: 164
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 16, 15, 35, 15, 24, 16, 30]
episode: 169 -> reward: -124.99999999999093, steps:62496, time-elasped: 27997.46s
-> berries picked: 56 of 800 | patches-visited: [8] | positive-in-buffer: 7395 | amount-filled: 100.00%
	| epsilon: 0.4360713496144882
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [546, 972, 702, 1363, 603, 1140, 583, 1486]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 17, 14, 29, 9, 19, 7, 28]
episode: 170 -> reward: -124.99999999998897, steps:65856, time-elasped: 28169.87s
-> berries picked: 71 of 800 | patches-visited: [0] | positive-in-buffer: 7427 | amount-filled: 100.00%
	| epsilon: 0.43572057588925256
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [550, 979, 701, 1364, 607, 1139, 591, 1496]
	| approx positives in sample 512: 156
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 25, 10, 33, 15, 19, 11, 25]
episode: 171 -> reward: -124.99999999998538, steps:90816, time-elasped: 28354.44s
-> berries picked: 158 of 800 | patches-visited: [1, 2, 6, 8] | positive-in-buffer: 7525 | amount-filled: 100.00%
	| epsilon: 0.43537008432473767
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [562, 1005, 709, 1377, 612, 1146, 598, 1516]
	| approx positives in sample 512: 145
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 18, 13, 26, 11, 20, 10, 35]
episode: 172 -> reward: -124.99999999998931, steps:71232, time-elasped: 28532.58s
-> berries picked: 87 of 800 | patches-visited: [4, 9] | positive-in-buffer: 7596 | amount-filled: 100.00%
	| epsilon: 0.43501987469397485
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [573, 1016, 717, 1396, 622, 1146, 607, 1519]
	| approx positives in sample 512: 169
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 24, 14, 32, 15, 31, 17, 22]
episode: 173 -> reward: -124.99999999999095, steps:62496, time-elasped: 28700.24s
-> berries picked: 51 of 800 | patches-visited: [5] | positive-in-buffer: 7621 | amount-filled: 100.00%
	| epsilon: 0.4346699467701779
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [576, 1017, 717, 1401, 626, 1150, 615, 1519]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 15, 12, 31, 11, 22, 11, 33]
episode: 174 -> reward: -124.99999999999227, steps:55296, time-elasped: 28862.96s
-> berries picked: 26 of 800 | patches-visited: [8] | positive-in-buffer: 7637 | amount-filled: 100.00%
	| epsilon: 0.434320300326743
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [582, 1018, 718, 1405, 630, 1152, 611, 1521]
	| approx positives in sample 512: 165
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 16, 10, 32, 11, 24, 14, 39]
episode: 175 -> reward: -124.99999999998792, steps:80448, time-elasped: 29039.01s
-> berries picked: 119 of 800 | patches-visited: [0, 6] | positive-in-buffer: 7686 | amount-filled: 100.00%
	| epsilon: 0.4339709351372488
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [592, 1033, 700, 1416, 634, 1157, 624, 1530]
	| approx positives in sample 512: 153
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 22, 11, 34, 11, 28, 9, 30]
episode: 176 -> reward: -124.99999999999312, steps:66432, time-elasped: 29211.33s
-> berries picked: 75 of 800 | patches-visited: [4] | positive-in-buffer: 7742 | amount-filled: 100.00%
	| epsilon: 0.4336218509754559
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [599, 1032, 709, 1419, 647, 1161, 634, 1541]
	| approx positives in sample 512: 170
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 21, 13, 32, 21, 15, 18, 38]
episode: 177 -> reward: -124.9999999999873, steps:78144, time-elasped: 29388.45s
-> berries picked: 122 of 800 | patches-visited: [3, 5] | positive-in-buffer: 7815 | amount-filled: 100.00%
	| epsilon: 0.43327304761530694
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [610, 1043, 722, 1433, 661, 1165, 639, 1542]
	| approx positives in sample 512: 154
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 14, 20, 21, 9, 29, 15, 39]
episode: 178 -> reward: -124.99999999999154, steps:64032, time-elasped: 29551.88s
-> berries picked: 65 of 800 | patches-visited: [0] | positive-in-buffer: 7857 | amount-filled: 100.00%
	| epsilon: 0.4329245248309264
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [613, 1046, 728, 1442, 666, 1177, 637, 1548]
	| approx positives in sample 512: 162
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 22, 10, 39, 20, 23, 6, 28]
episode: 179 -> reward: -124.99999999999035, steps:64320, time-elasped: 29718.74s
-> berries picked: 62 of 800 | patches-visited: [0] | positive-in-buffer: 7898 | amount-filled: 100.00%
	| epsilon: 0.4325762823966205
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [624, 1050, 730, 1447, 671, 1180, 645, 1551]
	| approx positives in sample 512: 166
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 18, 11, 28, 13, 29, 14, 36]
episode: 180 -> reward: -124.99999999999011, steps:76800, time-elasped: 29898.41s
-> berries picked: 114 of 800 | patches-visited: [1, 3] | positive-in-buffer: 7965 | amount-filled: 100.00%
	| epsilon: 0.432228320086877
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [633, 1060, 736, 1452, 676, 1188, 652, 1568]
	| approx positives in sample 512: 172
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 24, 15, 33, 15, 27, 12, 37]
episode: 181 -> reward: -124.9999999999927, steps:67200, time-elasped: 30071.78s
-> berries picked: 72 of 800 | patches-visited: [6] | positive-in-buffer: 8004 | amount-filled: 100.00%
	| epsilon: 0.4318806376763649
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [637, 1067, 743, 1467, 673, 1192, 655, 1570]
	| approx positives in sample 512: 175
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 22, 16, 35, 17, 27, 16, 27]
episode: 182 -> reward: -124.99999999998968, steps:62016, time-elasped: 30238.24s
-> berries picked: 58 of 800 | patches-visited: [6] | positive-in-buffer: 8044 | amount-filled: 100.00%
	| epsilon: 0.43153323493993473
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [642, 1070, 753, 1469, 680, 1203, 657, 1570]
	| approx positives in sample 512: 160
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 22, 14, 33, 9, 26, 11, 31]
episode: 183 -> reward: -124.99999999999203, steps:66336, time-elasped: 30403.45s
-> berries picked: 74 of 800 | patches-visited: [4] | positive-in-buffer: 8076 | amount-filled: 100.00%
	| epsilon: 0.43118611165261794
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [647, 1080, 748, 1480, 682, 1208, 660, 1571]
	| approx positives in sample 512: 162
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 27, 11, 36, 11, 28, 14, 24]
episode: 184 -> reward: -124.99999999999035, steps:64800, time-elasped: 30570.49s
-> berries picked: 72 of 800 | patches-visited: [7] | positive-in-buffer: 8108 | amount-filled: 100.00%
	| epsilon: 0.43083926758962693
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [653, 1083, 745, 1486, 690, 1209, 669, 1573]
	| approx positives in sample 512: 159
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 22, 9, 32, 16, 24, 15, 31]
episode: 185 -> reward: -124.9999999999917, steps:59616, time-elasped: 30740.54s
-> berries picked: 43 of 800 | patches-visited: [5, 6] | positive-in-buffer: 8138 | amount-filled: 100.00%
	| epsilon: 0.4304927025263551
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [658, 1090, 752, 1488, 690, 1210, 674, 1576]
	| approx positives in sample 512: 169
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 26, 22, 36, 16, 23, 11, 24]
episode: 186 -> reward: -124.99999999999116, steps:57216, time-elasped: 30912.26s
-> berries picked: 37 of 800 | patches-visited: [8] | positive-in-buffer: 8159 | amount-filled: 100.00%
	| epsilon: 0.43014641623837624
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [660, 1096, 754, 1491, 697, 1210, 673, 1578]
	| approx positives in sample 512: 174
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 22, 9, 24, 12, 32, 18, 46]
episode: 187 -> reward: -124.99999999999211, steps:59328, time-elasped: 31066.02s
-> berries picked: 41 of 800 | patches-visited: [4] | positive-in-buffer: 8176 | amount-filled: 100.00%
	| epsilon: 0.4298004085014449
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [661, 1103, 753, 1493, 700, 1209, 678, 1579]
	| approx positives in sample 512: 178
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 26, 14, 38, 7, 30, 17, 35]
episode: 188 -> reward: -124.99999999999179, steps:62880, time-elasped: 31234.84s
-> berries picked: 58 of 800 | patches-visited: [8] | positive-in-buffer: 8187 | amount-filled: 100.00%
	| epsilon: 0.429454679091496
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [668, 1105, 759, 1494, 700, 1208, 674, 1579]
	| approx positives in sample 512: 165
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 20, 14, 34, 19, 26, 11, 30]
episode: 189 -> reward: -124.99999999998657, steps:76128, time-elasped: 31414.75s
-> berries picked: 115 of 800 | patches-visited: [1, 8] | positive-in-buffer: 8248 | amount-filled: 100.00%
	| epsilon: 0.42910922778464455
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [679, 1106, 774, 1509, 700, 1227, 672, 1581]
	| approx positives in sample 512: 163
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 16, 7, 25, 18, 27, 19, 33]
episode: 190 -> reward: -124.99999999999204, steps:53184, time-elasped: 31567.49s
-> berries picked: 19 of 800 | patches-visited: [9] | positive-in-buffer: 8243 | amount-filled: 100.00%
	| epsilon: 0.4287640543571858
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [679, 1108, 768, 1507, 701, 1223, 675, 1582]
	| approx positives in sample 512: 168
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 21, 15, 23, 13, 29, 15, 41]
episode: 191 -> reward: -124.99999999998695, steps:80352, time-elasped: 31752.46s
-> berries picked: 125 of 800 | patches-visited: [2, 9] | positive-in-buffer: 8299 | amount-filled: 100.00%
	| epsilon: 0.4284191585855949
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [682, 1122, 761, 1512, 712, 1237, 672, 1601]
	| approx positives in sample 512: 155
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 19, 23, 23, 11, 21, 8, 36]
episode: 192 -> reward: -124.99999999998894, steps:81120, time-elasped: 31946.68s
-> berries picked: 119 of 800 | patches-visited: [0, 1, 7, 8] | positive-in-buffer: 8366 | amount-filled: 100.00%
	| epsilon: 0.42807454024652664
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [704, 1120, 766, 1517, 714, 1246, 687, 1612]
	| approx positives in sample 512: 175
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 26, 14, 29, 14, 27, 15, 33]
episode: 193 -> reward: -124.99999999999243, steps:63840, time-elasped: 32109.51s
-> berries picked: 66 of 800 | patches-visited: [6] | positive-in-buffer: 8419 | amount-filled: 100.00%
	| epsilon: 0.42773019911681576
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [709, 1125, 770, 1532, 716, 1257, 691, 1619]
	| approx positives in sample 512: 172
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 21, 18, 32, 13, 27, 8, 33]
episode: 194 -> reward: -124.99999999999157, steps:66048, time-elasped: 32276.13s
-> berries picked: 69 of 800 | patches-visited: [3] | positive-in-buffer: 8460 | amount-filled: 100.00%
	| epsilon: 0.42738613497347633
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [708, 1141, 779, 1536, 718, 1254, 695, 1629]
	| approx positives in sample 512: 158
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 24, 13, 27, 18, 22, 13, 28]
episode: 195 -> reward: -124.99999999999204, steps:52800, time-elasped: 32440.52s
-> berries picked: 15 of 800 | patches-visited: [1] | positive-in-buffer: 8460 | amount-filled: 100.00%
	| epsilon: 0.4270423475937018
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [712, 1139, 778, 1533, 718, 1255, 696, 1629]
	| approx positives in sample 512: 173
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 19, 13, 36, 12, 23, 15, 38]
episode: 196 -> reward: -124.99999999999294, steps:67584, time-elasped: 32607.60s
-> berries picked: 68 of 800 | patches-visited: [4] | positive-in-buffer: 8503 | amount-filled: 100.00%
	| epsilon: 0.4266988367548649
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [719, 1146, 787, 1541, 721, 1258, 699, 1632]
	| approx positives in sample 512: 151
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 22, 17, 16, 8, 29, 13, 36]
episode: 197 -> reward: -124.99999999998818, steps:86304, time-elasped: 32793.46s
-> berries picked: 140 of 800 | patches-visited: [3, 4, 6] | positive-in-buffer: 8542 | amount-filled: 100.00%
	| epsilon: 0.4263556022345174
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [739, 1136, 789, 1545, 719, 1280, 698, 1636]
	| approx positives in sample 512: 157
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 17, 9, 29, 11, 26, 14, 33]
episode: 198 -> reward: -124.99999999999204, steps:70752, time-elasped: 32972.78s
-> berries picked: 95 of 800 | patches-visited: [2, 6] | positive-in-buffer: 8620 | amount-filled: 100.00%
	| epsilon: 0.42601264381039006
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [747, 1149, 797, 1562, 725, 1290, 704, 1646]
	| approx positives in sample 512: 162
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 22, 11, 27, 14, 26, 17, 30]
episode: 199 -> reward: -124.99999999999179, steps:54720, time-elasped: 33127.74s
-> berries picked: 25 of 800 | patches-visited: [6] | positive-in-buffer: 8623 | amount-filled: 100.00%
	| epsilon: 0.4256699612603923
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [748, 1148, 796, 1562, 724, 1289, 704, 1652]
	| approx positives in sample 512: 167
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 21, 17, 30, 12, 37, 9, 26]
episode: 200 -> reward: -124.99999999998977, steps:79104, time-elasped: 33307.68s
-> berries picked: 125 of 800 | patches-visited: [0, 1, 5] | positive-in-buffer: 8705 | amount-filled: 100.00%
	| epsilon: 0.4253275543626124
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [763, 1164, 798, 1574, 736, 1296, 710, 1664]
	| approx positives in sample 512: 172
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 22, 11, 33, 14, 21, 10, 39]
episode: 201 -> reward: -124.99999999998529, steps:78720, time-elasped: 33485.00s
-> berries picked: 114 of 800 | patches-visited: [5, 6] | positive-in-buffer: 8764 | amount-filled: 100.00%
	| epsilon: 0.4249854228953169
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [773, 1168, 804, 1580, 741, 1309, 708, 1681]
	| approx positives in sample 512: 172
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 28, 13, 29, 11, 27, 11, 36]
episode: 202 -> reward: -124.99999999999247, steps:64608, time-elasped: 33644.20s
-> berries picked: 64 of 800 | patches-visited: [8] | positive-in-buffer: 8806 | amount-filled: 100.00%
	| epsilon: 0.42464356663695085
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [771, 1179, 806, 1586, 749, 1315, 716, 1684]
	| approx positives in sample 512: 166
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 15, 9, 33, 10, 32, 18, 37]
episode: 203 -> reward: -124.99999999998788, steps:81696, time-elasped: 33835.27s
-> berries picked: 129 of 800 | patches-visited: [6, 7] | positive-in-buffer: 8840 | amount-filled: 100.00%
	| epsilon: 0.42430198536613756
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [776, 1182, 803, 1590, 754, 1313, 727, 1695]
	| approx positives in sample 512: 177
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 14, 14, 32, 14, 28, 18, 40]
episode: 204 -> reward: -124.99999999999174, steps:63072, time-elasped: 33999.85s
-> berries picked: 54 of 800 | patches-visited: [3] | positive-in-buffer: 8876 | amount-filled: 100.00%
	| epsilon: 0.4239606788616783
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [782, 1185, 808, 1596, 758, 1317, 728, 1702]
	| approx positives in sample 512: 191
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 34, 21, 24, 13, 29, 11, 44]
episode: 205 -> reward: -124.99999999998654, steps:68448, time-elasped: 34152.84s
-> berries picked: 78 of 800 | patches-visited: [1, 5, 8] | positive-in-buffer: 8933 | amount-filled: 100.00%
	| epsilon: 0.4236196469025523
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [781, 1206, 813, 1604, 761, 1331, 727, 1710]
	| approx positives in sample 512: 155
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 22, 18, 28, 11, 23, 7, 35]
episode: 206 -> reward: -124.99999999998876, steps:71040, time-elasped: 34326.07s
-> berries picked: 84 of 800 | patches-visited: [1, 5] | positive-in-buffer: 8966 | amount-filled: 100.00%
	| epsilon: 0.4232788892679167
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [784, 1201, 817, 1604, 765, 1332, 745, 1718]
	| approx positives in sample 512: 161
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 20, 15, 24, 18, 18, 18, 27]
episode: 207 -> reward: -124.99999999998934, steps:73536, time-elasped: 34551.90s
-> berries picked: 100 of 800 | patches-visited: [2, 4] | positive-in-buffer: 9030 | amount-filled: 100.00%
	| epsilon: 0.42293840573710606
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [800, 1209, 829, 1606, 771, 1350, 743, 1722]
	| approx positives in sample 512: 149
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 22, 14, 24, 17, 14, 10, 34]
episode: 208 -> reward: -124.99999999998796, steps:75264, time-elasped: 34782.44s
-> berries picked: 103 of 800 | patches-visited: [4, 6] | positive-in-buffer: 9081 | amount-filled: 100.00%
	| epsilon: 0.42259819608963256
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [814, 1208, 839, 1612, 782, 1354, 747, 1725]
	| approx positives in sample 512: 175
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 21, 13, 36, 18, 31, 16, 31]
episode: 209 -> reward: -124.99999999998975, steps:64224, time-elasped: 35001.32s
-> berries picked: 65 of 800 | patches-visited: [2] | positive-in-buffer: 9121 | amount-filled: 100.00%
	| epsilon: 0.42225826010518586
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [822, 1221, 841, 1619, 781, 1365, 747, 1725]
	| approx positives in sample 512: 177
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 23, 22, 35, 9, 28, 12, 34]
episode: 210 -> reward: -124.99999999999197, steps:62496, time-elasped: 35216.93s
-> berries picked: 55 of 800 | patches-visited: [4] | positive-in-buffer: 9150 | amount-filled: 100.00%
	| epsilon: 0.4219185975636326
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [825, 1226, 846, 1622, 781, 1370, 751, 1729]
	| approx positives in sample 512: 172
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 24, 11, 27, 17, 29, 10, 33]
episode: 211 -> reward: -124.99999999999228, steps:64800, time-elasped: 35435.10s
-> berries picked: 71 of 800 | patches-visited: [6] | positive-in-buffer: 9147 | amount-filled: 100.00%
	| epsilon: 0.4215792082450167
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [819, 1242, 845, 1621, 784, 1361, 751, 1724]
	| approx positives in sample 512: 162
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 20, 22, 33, 11, 26, 10, 23]
episode: 212 -> reward: -124.99999999999177, steps:73440, time-elasped: 35667.42s
-> berries picked: 94 of 800 | patches-visited: [5, 9] | positive-in-buffer: 9177 | amount-filled: 100.00%
	| epsilon: 0.42124009192955886
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [819, 1238, 849, 1628, 784, 1369, 752, 1738]
	| approx positives in sample 512: 174
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 27, 9, 28, 24, 26, 9, 36]
episode: 213 -> reward: -124.99999999998742, steps:76032, time-elasped: 35905.00s
-> berries picked: 106 of 800 | patches-visited: [0, 4] | positive-in-buffer: 9219 | amount-filled: 100.00%
	| epsilon: 0.4209012483976567
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [825, 1255, 850, 1630, 794, 1366, 758, 1741]
	| approx positives in sample 512: 187
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 22, 18, 29, 23, 26, 6, 41]
episode: 214 -> reward: -124.99999999999172, steps:62016, time-elasped: 36119.65s
-> berries picked: 50 of 800 | patches-visited: [5, 7, 8] | positive-in-buffer: 9249 | amount-filled: 100.00%
	| epsilon: 0.42056267742988435
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [825, 1259, 851, 1634, 796, 1371, 763, 1750]
	| approx positives in sample 512: 163
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 22, 14, 33, 12, 31, 12, 30]
episode: 215 -> reward: -124.99999999999197, steps:52704, time-elasped: 36308.28s
-> berries picked: 16 of 800 | patches-visited: [5] | positive-in-buffer: 9259 | amount-filled: 100.00%
	| epsilon: 0.42022437880699254
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [826, 1265, 852, 1636, 796, 1370, 763, 1751]
	| approx positives in sample 512: 176
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 26, 17, 22, 16, 32, 14, 35]
episode: 216 -> reward: -124.9999999999844, steps:76704, time-elasped: 36523.42s
-> berries picked: 102 of 800 | patches-visited: [5, 8, 9] | positive-in-buffer: 9311 | amount-filled: 100.00%
	| epsilon: 0.41988635230990834
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [837, 1267, 848, 1647, 797, 1382, 772, 1761]
	| approx positives in sample 512: 178
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 21, 18, 36, 9, 28, 11, 42]
episode: 217 -> reward: -124.99999999999035, steps:70944, time-elasped: 36682.82s
-> berries picked: 94 of 800 | patches-visited: [0, 3] | positive-in-buffer: 9376 | amount-filled: 100.00%
	| epsilon: 0.4195485977197351
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [844, 1270, 856, 1658, 802, 1394, 775, 1777]
	| approx positives in sample 512: 161
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 23, 14, 32, 12, 23, 12, 34]
episode: 218 -> reward: -124.99999999999211, steps:57120, time-elasped: 36812.18s
-> berries picked: 34 of 800 | patches-visited: [7] | positive-in-buffer: 9377 | amount-filled: 100.00%
	| epsilon: 0.4192111148177521
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [844, 1276, 859, 1654, 804, 1391, 774, 1775]
	| approx positives in sample 512: 161
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 19, 10, 38, 15, 22, 9, 29]
episode: 219 -> reward: -124.99999999998703, steps:88800, time-elasped: 37054.24s
-> berries picked: 148 of 800 | patches-visited: [0, 7, 8] | positive-in-buffer: 9428 | amount-filled: 100.00%
	| epsilon: 0.4188739033854147
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [864, 1269, 861, 1663, 805, 1411, 773, 1782]
	| approx positives in sample 512: 178
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 26, 10, 35, 13, 33, 18, 35]
episode: 220 -> reward: -124.99999999999096, steps:63936, time-elasped: 37257.79s
-> berries picked: 65 of 800 | patches-visited: [1] | positive-in-buffer: 9477 | amount-filled: 100.00%
	| epsilon: 0.418536963204354
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [876, 1277, 865, 1664, 810, 1420, 775, 1790]
	| approx positives in sample 512: 161
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 19, 15, 27, 12, 29, 14, 21]
episode: 221 -> reward: -124.99999999999099, steps:69888, time-elasped: 37471.71s
-> berries picked: 81 of 800 | patches-visited: [0, 5] | positive-in-buffer: 9532 | amount-filled: 100.00%
	| epsilon: 0.41820029405637676
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [875, 1294, 866, 1669, 825, 1430, 778, 1795]
	| approx positives in sample 512: 173
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 20, 21, 25, 17, 29, 13, 36]
episode: 222 -> reward: -124.99999999999312, steps:73248, time-elasped: 37680.73s
-> berries picked: 97 of 800 | patches-visited: [2, 4] | positive-in-buffer: 9564 | amount-filled: 100.00%
	| epsilon: 0.4178638957234653
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [885, 1300, 867, 1678, 824, 1433, 776, 1801]
	| approx positives in sample 512: 157
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 23, 19, 27, 16, 18, 17, 21]
episode: 223 -> reward: -124.99999999998892, steps:75264, time-elasped: 37911.25s
-> berries picked: 101 of 800 | patches-visited: [0, 9] | positive-in-buffer: 9618 | amount-filled: 100.00%
	| epsilon: 0.41752776798777713
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [887, 1296, 878, 1690, 835, 1440, 784, 1808]
	| approx positives in sample 512: 180
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 34, 14, 36, 14, 18, 13, 35]
episode: 224 -> reward: -124.99999999999034, steps:92352, time-elasped: 38179.80s
-> berries picked: 155 of 800 | patches-visited: [0, 2, 9] | positive-in-buffer: 9675 | amount-filled: 100.00%
	| epsilon: 0.41719191063164524
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [891, 1325, 875, 1686, 836, 1451, 784, 1827]
	| approx positives in sample 512: 194
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 22, 15, 30, 17, 36, 14, 47]
episode: 225 -> reward: -124.99999999999145, steps:63072, time-elasped: 38401.86s
-> berries picked: 59 of 800 | patches-visited: [5, 9] | positive-in-buffer: 9720 | amount-filled: 100.00%
	| epsilon: 0.41685632343757756
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [896, 1327, 885, 1693, 843, 1457, 791, 1828]
	| approx positives in sample 512: 180
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 22, 16, 37, 18, 26, 12, 26]
episode: 226 -> reward: -124.99999999998902, steps:80736, time-elasped: 38638.41s
-> berries picked: 129 of 800 | patches-visited: [4, 8] | positive-in-buffer: 9801 | amount-filled: 100.00%
	| epsilon: 0.416521006188257
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [913, 1337, 892, 1705, 847, 1477, 792, 1838]
	| approx positives in sample 512: 189
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 25, 11, 34, 17, 37, 15, 36]
episode: 227 -> reward: -124.99999999999207, steps:59616, time-elasped: 38847.55s
-> berries picked: 41 of 800 | patches-visited: [4] | positive-in-buffer: 9820 | amount-filled: 100.00%
	| epsilon: 0.41618595866654134
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [908, 1347, 898, 1706, 853, 1476, 793, 1839]
	| approx positives in sample 512: 174
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 23, 16, 32, 9, 26, 12, 39]
episode: 228 -> reward: -124.99999999998687, steps:79488, time-elasped: 39097.39s
-> berries picked: 112 of 800 | patches-visited: [1, 2, 5] | positive-in-buffer: 9854 | amount-filled: 100.00%
	| epsilon: 0.4158511806554629
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [920, 1343, 903, 1709, 852, 1480, 806, 1841]
	| approx positives in sample 512: 180
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 22, 22, 34, 18, 27, 11, 32]
episode: 229 -> reward: -124.99999999999271, steps:63264, time-elasped: 39318.55s
-> berries picked: 65 of 800 | patches-visited: [8] | positive-in-buffer: 9912 | amount-filled: 100.00%
	| epsilon: 0.41551667193822867
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [919, 1353, 908, 1721, 858, 1493, 810, 1850]
	| approx positives in sample 512: 184
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 18, 16, 35, 13, 25, 16, 44]
episode: 230 -> reward: -124.99999999999035, steps:67008, time-elasped: 39534.22s
-> berries picked: 73 of 800 | patches-visited: [7] | positive-in-buffer: 9945 | amount-filled: 100.00%
	| epsilon: 0.4151824322982199
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [921, 1356, 911, 1725, 866, 1498, 819, 1849]
	| approx positives in sample 512: 187
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 28, 18, 31, 17, 28, 17, 36]
episode: 231 -> reward: -124.99999999998764, steps:77952, time-elasped: 39725.58s
-> berries picked: 104 of 800 | patches-visited: [1, 3, 4] | positive-in-buffer: 9966 | amount-filled: 100.00%
	| epsilon: 0.4148484615189922
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [924, 1345, 915, 1727, 862, 1508, 824, 1861]
	| approx positives in sample 512: 171
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 31, 13, 26, 15, 25, 15, 32]
episode: 232 -> reward: -124.99999999999216, steps:66240, time-elasped: 39900.11s
-> berries picked: 68 of 800 | patches-visited: [9] | positive-in-buffer: 10013 | amount-filled: 100.00%
	| epsilon: 0.4145147593842752
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [934, 1356, 916, 1737, 865, 1515, 825, 1865]
	| approx positives in sample 512: 175
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 20, 19, 33, 18, 29, 14, 31]
episode: 233 -> reward: -124.9999999999919, steps:60000, time-elasped: 40069.56s
-> berries picked: 47 of 800 | patches-visited: [2] | positive-in-buffer: 10032 | amount-filled: 100.00%
	| epsilon: 0.4141813256779725
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [938, 1357, 919, 1741, 869, 1514, 829, 1865]
	| approx positives in sample 512: 204
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 37, 23, 34, 20, 23, 11, 38]
episode: 234 -> reward: -124.99999999999292, steps:65280, time-elasped: 40241.68s
-> berries picked: 72 of 800 | patches-visited: [8] | positive-in-buffer: 10054 | amount-filled: 100.00%
	| epsilon: 0.4138481601841616
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [946, 1365, 920, 1737, 868, 1520, 830, 1868]
	| approx positives in sample 512: 182
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 19, 12, 37, 13, 27, 20, 36]
episode: 235 -> reward: -124.99999999999359, steps:74688, time-elasped: 40420.90s
-> berries picked: 101 of 800 | patches-visited: [5, 8] | positive-in-buffer: 10064 | amount-filled: 100.00%
	| epsilon: 0.41351526268709365
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [936, 1354, 929, 1737, 870, 1541, 831, 1866]
	| approx positives in sample 512: 188
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 33, 17, 24, 23, 30, 12, 34]
episode: 236 -> reward: -124.99999999999191, steps:70176, time-elasped: 40592.84s
-> berries picked: 80 of 800 | patches-visited: [8, 9] | positive-in-buffer: 10121 | amount-filled: 100.00%
	| epsilon: 0.41318263297119334
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [942, 1357, 931, 1751, 876, 1537, 850, 1877]
	| approx positives in sample 512: 188
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 21, 20, 42, 15, 23, 20, 41]
episode: 237 -> reward: -124.99999999999177, steps:66528, time-elasped: 40769.06s
-> berries picked: 73 of 800 | patches-visited: [0] | positive-in-buffer: 10165 | amount-filled: 100.00%
	| epsilon: 0.41285027082105874
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [952, 1362, 940, 1759, 880, 1543, 851, 1878]
	| approx positives in sample 512: 175
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 22, 16, 32, 11, 31, 16, 29]
episode: 238 -> reward: -124.99999999998757, steps:77280, time-elasped: 40955.16s
-> berries picked: 123 of 800 | patches-visited: [0, 7] | positive-in-buffer: 10155 | amount-filled: 100.00%
	| epsilon: 0.41251817602146124
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [949, 1366, 934, 1752, 891, 1536, 855, 1872]
	| approx positives in sample 512: 184
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 21, 18, 32, 13, 34, 16, 31]
episode: 239 -> reward: -124.9999999999912, steps:82272, time-elasped: 41142.47s
-> berries picked: 131 of 800 | patches-visited: [2, 5] | positive-in-buffer: 10194 | amount-filled: 100.00%
	| epsilon: 0.4121863483573453
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [965, 1359, 958, 1754, 883, 1551, 847, 1877]
	| approx positives in sample 512: 187
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 27, 14, 32, 16, 29, 19, 31]
episode: 240 -> reward: -124.9999999999862, steps:76320, time-elasped: 41333.29s
-> berries picked: 108 of 800 | patches-visited: [1, 5] | positive-in-buffer: 10273 | amount-filled: 100.00%
	| epsilon: 0.41185478761382843
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [975, 1366, 967, 1766, 890, 1568, 849, 1892]
	| approx positives in sample 512: 183
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 16, 19, 34, 16, 33, 12, 34]
episode: 241 -> reward: -124.99999999999173, steps:60192, time-elasped: 41497.84s
-> berries picked: 46 of 800 | patches-visited: [6] | positive-in-buffer: 10296 | amount-filled: 100.00%
	| epsilon: 0.411523493576201
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [972, 1373, 969, 1770, 897, 1572, 850, 1893]
	| approx positives in sample 512: 193
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 27, 14, 41, 25, 24, 16, 31]
episode: 242 -> reward: -124.99999999999196, steps:59712, time-elasped: 41638.72s
-> berries picked: 46 of 800 | patches-visited: [4] | positive-in-buffer: 10309 | amount-filled: 100.00%
	| epsilon: 0.41119246602992604
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [971, 1372, 967, 1773, 899, 1570, 861, 1896]
	| approx positives in sample 512: 182
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 33, 16, 26, 22, 26, 19, 25]
episode: 243 -> reward: -124.99999999999204, steps:53760, time-elasped: 41762.21s
-> berries picked: 22 of 800 | patches-visited: [7] | positive-in-buffer: 10318 | amount-filled: 100.00%
	| epsilon: 0.4108617047606391
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [970, 1375, 967, 1774, 902, 1574, 858, 1898]
	| approx positives in sample 512: 192
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 33, 17, 32, 16, 28, 18, 25]
episode: 244 -> reward: -124.99999999998457, steps:82272, time-elasped: 41925.36s
-> berries picked: 138 of 800 | patches-visited: [3, 7] | positive-in-buffer: 10364 | amount-filled: 100.00%
	| epsilon: 0.41053120955414835
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [976, 1372, 977, 1783, 910, 1587, 864, 1895]
	| approx positives in sample 512: 163
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 14, 15, 25, 21, 23, 19, 33]
episode: 245 -> reward: -124.99999999998697, steps:68736, time-elasped: 42204.95s
-> berries picked: 80 of 800 | patches-visited: [0, 2, 3] | positive-in-buffer: 10416 | amount-filled: 100.00%
	| epsilon: 0.4102009801964341
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [986, 1372, 986, 1785, 926, 1593, 863, 1905]
	| approx positives in sample 512: 169
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 26, 14, 29, 18, 25, 13, 27]
episode: 246 -> reward: -124.99999999999181, steps:63840, time-elasped: 42421.78s
-> berries picked: 57 of 800 | patches-visited: [3] | positive-in-buffer: 10450 | amount-filled: 100.00%
	| epsilon: 0.40987101647364876
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [992, 1375, 990, 1790, 922, 1608, 861, 1912]
	| approx positives in sample 512: 187
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 23, 30, 31, 8, 27, 11, 43]
episode: 247 -> reward: -124.99999999999504, steps:65760, time-elasped: 42586.18s
-> berries picked: 68 of 800 | patches-visited: [3, 7] | positive-in-buffer: 10448 | amount-filled: 100.00%
	| epsilon: 0.409541318172117
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [984, 1376, 989, 1799, 918, 1607, 860, 1915]
	| approx positives in sample 512: 187
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 26, 17, 37, 16, 26, 15, 37]
episode: 248 -> reward: -124.99999999999216, steps:65280, time-elasped: 42765.47s
-> berries picked: 67 of 800 | patches-visited: [6] | positive-in-buffer: 10474 | amount-filled: 100.00%
	| epsilon: 0.4092118850783351
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [992, 1377, 999, 1798, 922, 1611, 860, 1915]
	| approx positives in sample 512: 186
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 24, 23, 24, 19, 28, 19, 28]
episode: 249 -> reward: -124.99999999998893, steps:82080, time-elasped: 42943.67s
-> berries picked: 129 of 800 | patches-visited: [1, 4] | positive-in-buffer: 10500 | amount-filled: 100.00%
	| epsilon: 0.4088827169789713
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [991, 1371, 1013, 1806, 928, 1616, 863, 1912]
	| approx positives in sample 512: 180
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 26, 15, 30, 11, 32, 9, 37]
episode: 250 -> reward: -124.99999999999197, steps:82368, time-elasped: 43130.08s
-> berries picked: 139 of 800 | patches-visited: [6, 9] | positive-in-buffer: 10591 | amount-filled: 100.00%
	| epsilon: 0.40855381366086524
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [989, 1395, 1016, 1816, 942, 1629, 871, 1933]
	| approx positives in sample 512: 187
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 23, 17, 41, 9, 34, 16, 33]
episode: 251 -> reward: -124.9999999999914, steps:64704, time-elasped: 43293.46s
-> berries picked: 65 of 800 | patches-visited: [7] | positive-in-buffer: 10618 | amount-filled: 100.00%
	| epsilon: 0.4082251749110282
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [992, 1395, 1021, 1823, 940, 1633, 874, 1940]
	| approx positives in sample 512: 198
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 23, 21, 39, 22, 25, 12, 38]
episode: 252 -> reward: -124.99999999999169, steps:63648, time-elasped: 43460.68s
-> berries picked: 65 of 800 | patches-visited: [1] | positive-in-buffer: 10630 | amount-filled: 100.00%
	| epsilon: 0.4078968005166428
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [999, 1388, 1029, 1823, 936, 1638, 874, 1943]
	| approx positives in sample 512: 177
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 19, 16, 33, 15, 28, 15, 36]
episode: 253 -> reward: -124.9999999999906, steps:85248, time-elasped: 43647.14s
-> berries picked: 142 of 800 | patches-visited: [7, 9] | positive-in-buffer: 10682 | amount-filled: 100.00%
	| epsilon: 0.4075686902650626
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [995, 1403, 1018, 1821, 945, 1659, 889, 1952]
	| approx positives in sample 512: 179
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 26, 21, 34, 15, 22, 11, 33]
episode: 254 -> reward: -124.99999999999248, steps:61056, time-elasped: 43811.51s
-> berries picked: 53 of 800 | patches-visited: [1] | positive-in-buffer: 10708 | amount-filled: 100.00%
	| epsilon: 0.4072408439438125
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [996, 1403, 1021, 1825, 948, 1663, 890, 1962]
	| approx positives in sample 512: 192
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 28, 25, 31, 15, 29, 12, 36]
episode: 255 -> reward: -124.99999999999203, steps:66240, time-elasped: 43987.81s
-> berries picked: 75 of 800 | patches-visited: [5] | positive-in-buffer: 10760 | amount-filled: 100.00%
	| epsilon: 0.40691326134058814
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1007, 1408, 1026, 1835, 949, 1677, 894, 1964]
	| approx positives in sample 512: 194
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 36, 22, 27, 19, 32, 15, 30]
episode: 256 -> reward: -124.99999999998957, steps:78432, time-elasped: 44165.11s
-> berries picked: 118 of 800 | patches-visited: [0, 9] | positive-in-buffer: 10793 | amount-filled: 100.00%
	| epsilon: 0.406585942243256
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1012, 1414, 1027, 1839, 950, 1678, 904, 1969]
	| approx positives in sample 512: 189
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 28, 25, 28, 15, 28, 12, 32]
episode: 257 -> reward: -124.99999999999194, steps:57120, time-elasped: 44318.80s
-> berries picked: 32 of 800 | patches-visited: [1] | positive-in-buffer: 10803 | amount-filled: 100.00%
	| epsilon: 0.40625888643985325
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1009, 1421, 1027, 1842, 952, 1673, 904, 1975]
	| approx positives in sample 512: 192
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 22, 16, 31, 17, 39, 16, 37]
episode: 258 -> reward: -124.9999999999919, steps:65184, time-elasped: 44486.70s
-> berries picked: 56 of 800 | patches-visited: [8] | positive-in-buffer: 10845 | amount-filled: 100.00%
	| epsilon: 0.4059320937185874
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1020, 1422, 1035, 1847, 954, 1682, 905, 1980]
	| approx positives in sample 512: 180
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 27, 20, 32, 17, 28, 11, 27]
episode: 259 -> reward: -124.99999999999199, steps:60864, time-elasped: 44651.44s
-> berries picked: 47 of 800 | patches-visited: [4] | positive-in-buffer: 10877 | amount-filled: 100.00%
	| epsilon: 0.40560556386783647
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1026, 1423, 1037, 1853, 957, 1690, 906, 1985]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 26, 22, 37, 16, 30, 7, 33]
episode: 260 -> reward: -124.9999999999921, steps:59328, time-elasped: 44820.88s
-> berries picked: 39 of 800 | patches-visited: [3] | positive-in-buffer: 10878 | amount-filled: 100.00%
	| epsilon: 0.4052792966761487
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1021, 1424, 1038, 1853, 957, 1690, 904, 1991]
	| approx positives in sample 512: 199
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 35, 19, 43, 19, 25, 11, 32]
episode: 261 -> reward: -124.99999999998995, steps:79488, time-elasped: 44998.43s
-> berries picked: 126 of 800 | patches-visited: [2, 5] | positive-in-buffer: 10883 | amount-filled: 100.00%
	| epsilon: 0.4049532919322424
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1020, 1420, 1044, 1849, 957, 1710, 898, 1985]
	| approx positives in sample 512: 187
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 23, 16, 34, 19, 24, 17, 36]
episode: 262 -> reward: -124.99999999999211, steps:76032, time-elasped: 45177.68s
-> berries picked: 101 of 800 | patches-visited: [2, 9] | positive-in-buffer: 10929 | amount-filled: 100.00%
	| epsilon: 0.40462754942500573
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1028, 1425, 1054, 1852, 958, 1722, 893, 1997]
	| approx positives in sample 512: 189
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 29, 16, 33, 18, 30, 19, 32]
episode: 263 -> reward: -124.99999999999274, steps:72672, time-elasped: 45352.98s
-> berries picked: 92 of 800 | patches-visited: [2, 8] | positive-in-buffer: 10994 | amount-filled: 100.00%
	| epsilon: 0.4043020689434968
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1040, 1436, 1054, 1859, 959, 1733, 895, 2018]
	| approx positives in sample 512: 186
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 24, 20, 36, 26, 29, 11, 26]
episode: 264 -> reward: -124.99999999999186, steps:64416, time-elasped: 45517.99s
-> berries picked: 68 of 800 | patches-visited: [4] | positive-in-buffer: 11038 | amount-filled: 100.00%
	| epsilon: 0.40397685027694336
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1040, 1443, 1056, 1864, 967, 1738, 896, 2034]
	| approx positives in sample 512: 191
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 21, 17, 38, 22, 24, 23, 28]
episode: 265 -> reward: -124.99999999998774, steps:83520, time-elasped: 45703.78s
-> berries picked: 148 of 800 | patches-visited: [0, 1, 3] | positive-in-buffer: 11050 | amount-filled: 100.00%
	| epsilon: 0.4036518932147427
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1032, 1456, 1054, 1855, 967, 1739, 907, 2040]
	| approx positives in sample 512: 195
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 23, 16, 32, 13, 27, 21, 46]
episode: 266 -> reward: -124.99999999998798, steps:68160, time-elasped: 45881.93s
-> berries picked: 80 of 800 | patches-visited: [1, 5] | positive-in-buffer: 11096 | amount-filled: 100.00%
	| epsilon: 0.4033271975464615
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1039, 1458, 1060, 1859, 975, 1740, 918, 2047]
	| approx positives in sample 512: 186
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 23, 13, 32, 12, 38, 13, 36]
episode: 267 -> reward: -124.99999999998651, steps:81024, time-elasped: 46063.51s
-> berries picked: 128 of 800 | patches-visited: [1, 9] | positive-in-buffer: 11105 | amount-filled: 100.00%
	| epsilon: 0.4030027630618358
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1040, 1457, 1071, 1879, 981, 1729, 917, 2031]
	| approx positives in sample 512: 194
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 25, 19, 28, 22, 28, 21, 32]
episode: 268 -> reward: -124.99999999999203, steps:50880, time-elasped: 46205.30s
-> berries picked: 10 of 800 | patches-visited: [4] | positive-in-buffer: 11094 | amount-filled: 100.00%
	| epsilon: 0.4026785895507707
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1040, 1455, 1069, 1873, 981, 1730, 917, 2029]
	| approx positives in sample 512: 203
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 27, 15, 31, 15, 35, 22, 36]
episode: 269 -> reward: -124.99999999999227, steps:72096, time-elasped: 46369.47s
-> berries picked: 84 of 800 | patches-visited: [7, 9] | positive-in-buffer: 11165 | amount-filled: 100.00%
	| epsilon: 0.4023546768033402
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1052, 1468, 1074, 1883, 983, 1744, 916, 2045]
	| approx positives in sample 512: 194
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 18, 15, 34, 16, 35, 13, 39]
episode: 270 -> reward: -124.99999999998714, steps:75744, time-elasped: 46540.96s
-> berries picked: 115 of 800 | patches-visited: [4, 7] | positive-in-buffer: 11195 | amount-filled: 100.00%
	| epsilon: 0.4020310246097873
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1045, 1477, 1075, 1891, 990, 1749, 911, 2057]
	| approx positives in sample 512: 172
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 29, 12, 32, 24, 22, 13, 26]
episode: 271 -> reward: -124.99999999998707, steps:70272, time-elasped: 46700.83s
-> berries picked: 89 of 800 | patches-visited: [0, 2] | positive-in-buffer: 11236 | amount-filled: 100.00%
	| epsilon: 0.4017076327605238
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1052, 1480, 1081, 1896, 998, 1759, 915, 2055]
	| approx positives in sample 512: 207
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 21, 20, 33, 22, 35, 20, 32]
episode: 272 -> reward: -124.99999999999183, steps:61728, time-elasped: 46853.80s
-> berries picked: 56 of 800 | patches-visited: [8] | positive-in-buffer: 11270 | amount-filled: 100.00%
	| epsilon: 0.4013845010461299
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1058, 1484, 1082, 1902, 1001, 1768, 917, 2058]
	| approx positives in sample 512: 183
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 27, 12, 27, 11, 34, 14, 34]
episode: 273 -> reward: -124.99999999999183, steps:61056, time-elasped: 47008.12s
-> berries picked: 51 of 800 | patches-visited: [5] | positive-in-buffer: 11282 | amount-filled: 100.00%
	| epsilon: 0.40106162925735434
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1057, 1496, 1079, 1908, 1005, 1765, 918, 2054]
	| approx positives in sample 512: 156
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 20, 11, 29, 15, 26, 13, 31]
episode: 274 -> reward: -124.99999999999177, steps:74592, time-elasped: 47172.70s
-> berries picked: 106 of 800 | patches-visited: [1, 4] | positive-in-buffer: 11301 | amount-filled: 100.00%
	| epsilon: 0.40073901718511423
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1050, 1493, 1082, 1915, 1009, 1768, 924, 2060]
	| approx positives in sample 512: 177
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 27, 14, 23, 15, 21, 24, 32]
episode: 275 -> reward: -124.9999999999852, steps:81792, time-elasped: 47340.15s
-> berries picked: 123 of 800 | patches-visited: [1, 6] | positive-in-buffer: 11311 | amount-filled: 100.00%
	| epsilon: 0.4004166646204948
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1057, 1487, 1095, 1916, 1010, 1767, 919, 2060]
	| approx positives in sample 512: 184
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 24, 9, 40, 18, 29, 20, 28]
episode: 276 -> reward: -124.99999999999164, steps:63168, time-elasped: 47499.25s
-> berries picked: 57 of 800 | patches-visited: [7] | positive-in-buffer: 11346 | amount-filled: 100.00%
	| epsilon: 0.40009457135474935
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1058, 1493, 1094, 1921, 1022, 1774, 922, 2062]
	| approx positives in sample 512: 182
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 30, 16, 39, 16, 24, 10, 32]
episode: 277 -> reward: -124.99999999999241, steps:65664, time-elasped: 47653.18s
-> berries picked: 71 of 800 | patches-visited: [6] | positive-in-buffer: 11380 | amount-filled: 100.00%
	| epsilon: 0.3997727371792991
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1065, 1494, 1097, 1929, 1030, 1778, 925, 2062]
	| approx positives in sample 512: 191
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 29, 21, 31, 24, 33, 14, 26]
episode: 278 -> reward: -124.99999999999186, steps:62208, time-elasped: 47813.98s
-> berries picked: 50 of 800 | patches-visited: [7] | positive-in-buffer: 11401 | amount-filled: 100.00%
	| epsilon: 0.39945116188573304
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1060, 1498, 1098, 1940, 1031, 1785, 925, 2064]
	| approx positives in sample 512: 187
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 25, 20, 29, 15, 30, 17, 37]
episode: 279 -> reward: -124.99999999999164, steps:63264, time-elasped: 47972.37s
-> berries picked: 55 of 800 | patches-visited: [4] | positive-in-buffer: 11430 | amount-filled: 100.00%
	| epsilon: 0.39912984526580786
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1060, 1505, 1096, 1947, 1037, 1788, 927, 2070]
	| approx positives in sample 512: 189
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 29, 13, 31, 16, 27, 15, 44]
episode: 280 -> reward: -124.99999999999194, steps:57696, time-elasped: 48123.34s
-> berries picked: 39 of 800 | patches-visited: [7] | positive-in-buffer: 11461 | amount-filled: 100.00%
	| epsilon: 0.3988087871114476
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1068, 1508, 1097, 1952, 1045, 1790, 928, 2073]
	| approx positives in sample 512: 201
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 28, 16, 32, 19, 35, 23, 35]
episode: 281 -> reward: -124.99999999998695, steps:87744, time-elasped: 48304.52s
-> berries picked: 151 of 800 | patches-visited: [3, 5, 7] | positive-in-buffer: 11482 | amount-filled: 100.00%
	| epsilon: 0.3984879872147439
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1077, 1513, 1094, 1950, 1063, 1791, 934, 2060]
	| approx positives in sample 512: 205
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 25, 28, 44, 21, 25, 15, 32]
episode: 282 -> reward: -124.99999999999193, steps:61728, time-elasped: 48470.42s
-> berries picked: 56 of 800 | patches-visited: [4, 8] | positive-in-buffer: 11510 | amount-filled: 100.00%
	| epsilon: 0.3981674453679554
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1076, 1516, 1096, 1952, 1063, 1803, 934, 2070]
	| approx positives in sample 512: 190
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 29, 17, 27, 14, 31, 9, 36]
episode: 283 -> reward: -124.9999999999938, steps:72768, time-elasped: 48640.12s
-> berries picked: 89 of 800 | patches-visited: [2, 3] | positive-in-buffer: 11566 | amount-filled: 100.00%
	| epsilon: 0.3978471613635081
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1088, 1526, 1101, 1964, 1068, 1804, 937, 2078]
	| approx positives in sample 512: 195
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 25, 12, 36, 17, 33, 16, 28]
episode: 284 -> reward: -124.99999999999272, steps:68256, time-elasped: 48804.67s
-> berries picked: 75 of 800 | patches-visited: [4] | positive-in-buffer: 11614 | amount-filled: 100.00%
	| epsilon: 0.3975271349939948
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1096, 1537, 1106, 1965, 1070, 1807, 939, 2094]
	| approx positives in sample 512: 192
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 29, 16, 37, 14, 34, 12, 29]
episode: 285 -> reward: -124.9999999999845, steps:98112, time-elasped: 49003.55s
-> berries picked: 182 of 800 | patches-visited: [2, 3, 8] | positive-in-buffer: 11587 | amount-filled: 100.00%
	| epsilon: 0.39720736605217516
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1101, 1546, 1103, 1969, 1061, 1792, 939, 2076]
	| approx positives in sample 512: 205
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 27, 14, 35, 19, 25, 20, 44]
episode: 286 -> reward: -124.99999999999254, steps:82560, time-elasped: 49182.65s
-> berries picked: 135 of 800 | patches-visited: [1, 3] | positive-in-buffer: 11693 | amount-filled: 100.00%
	| epsilon: 0.39688785433097556
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1121, 1568, 1109, 1981, 1064, 1804, 951, 2095]
	| approx positives in sample 512: 207
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 19, 26, 40, 23, 27, 13, 40]
episode: 287 -> reward: -124.99999999999199, steps:63168, time-elasped: 49339.48s
-> berries picked: 50 of 800 | patches-visited: [8] | positive-in-buffer: 11709 | amount-filled: 100.00%
	| epsilon: 0.396568599623489
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1132, 1563, 1110, 1983, 1064, 1813, 948, 2096]
	| approx positives in sample 512: 193
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 24, 23, 37, 14, 19, 17, 36]
episode: 288 -> reward: -124.99999999998838, steps:74400, time-elasped: 49504.38s
-> berries picked: 110 of 800 | patches-visited: [0, 5] | positive-in-buffer: 11775 | amount-filled: 100.00%
	| epsilon: 0.3962496017229748
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1136, 1580, 1113, 1992, 1074, 1826, 949, 2105]
	| approx positives in sample 512: 193
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 30, 19, 34, 11, 31, 13, 34]
episode: 289 -> reward: -124.99999999999206, steps:65184, time-elasped: 49664.26s
-> berries picked: 66 of 800 | patches-visited: [7, 9] | positive-in-buffer: 11815 | amount-filled: 100.00%
	| epsilon: 0.39593086042285874
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1137, 1588, 1118, 1993, 1081, 1833, 955, 2110]
	| approx positives in sample 512: 204
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 39, 14, 38, 16, 32, 11, 31]
episode: 290 -> reward: -124.99999999998305, steps:86400, time-elasped: 49842.79s
-> berries picked: 145 of 800 | patches-visited: [1, 4, 8] | positive-in-buffer: 11775 | amount-filled: 100.00%
	| epsilon: 0.39561237551673256
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1127, 1596, 1109, 1994, 1084, 1821, 956, 2088]
	| approx positives in sample 512: 173
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 16, 13, 26, 17, 36, 19, 29]
episode: 291 -> reward: -124.99999999998792, steps:95232, time-elasped: 50029.54s
-> berries picked: 173 of 800 | patches-visited: [2, 4, 5] | positive-in-buffer: 11765 | amount-filled: 100.00%
	| epsilon: 0.3952941467983543
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1122, 1576, 1115, 2002, 1091, 1828, 947, 2084]
	| approx positives in sample 512: 183
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 20, 13, 38, 19, 27, 16, 36]
episode: 292 -> reward: -124.99999999998893, steps:91584, time-elasped: 50212.07s
-> berries picked: 167 of 800 | patches-visited: [1, 5, 8] | positive-in-buffer: 11848 | amount-filled: 100.00%
	| epsilon: 0.3949761740616476
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1116, 1582, 1127, 2020, 1099, 1847, 957, 2100]
	| approx positives in sample 512: 187
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 29, 18, 26, 17, 29, 18, 32]
episode: 293 -> reward: -124.99999999998849, steps:81984, time-elasped: 50391.98s
-> berries picked: 116 of 800 | patches-visited: [0, 3, 8] | positive-in-buffer: 11907 | amount-filled: 100.00%
	| epsilon: 0.3946584571007021
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1146, 1582, 1125, 2013, 1103, 1857, 967, 2114]
	| approx positives in sample 512: 186
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 28, 17, 29, 19, 27, 14, 35]
episode: 294 -> reward: -124.99999999998967, steps:79200, time-elasped: 50566.41s
-> berries picked: 115 of 800 | patches-visited: [6, 7, 8] | positive-in-buffer: 11987 | amount-filled: 100.00%
	| epsilon: 0.394340995709773
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1151, 1593, 1135, 2026, 1115, 1869, 972, 2126]
	| approx positives in sample 512: 204
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 29, 18, 32, 28, 30, 15, 39]
episode: 295 -> reward: -124.99999999999119, steps:65952, time-elasped: 50725.96s
-> berries picked: 68 of 800 | patches-visited: [7, 9] | positive-in-buffer: 12029 | amount-filled: 100.00%
	| epsilon: 0.3940237896832809
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1153, 1596, 1139, 2031, 1120, 1878, 976, 2136]
	| approx positives in sample 512: 178
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 12, 17, 34, 28, 27, 10, 35]
episode: 296 -> reward: -124.99999999998822, steps:82656, time-elasped: 50907.63s
-> berries picked: 130 of 800 | patches-visited: [1, 9] | positive-in-buffer: 12053 | amount-filled: 100.00%
	| epsilon: 0.393706838815812
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1150, 1599, 1140, 2040, 1127, 1887, 975, 2135]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 22, 24, 39, 26, 45, 16, 30]
episode: 297 -> reward: -124.99999999999321, steps:69216, time-elasped: 51068.14s
-> berries picked: 81 of 800 | patches-visited: [1, 7] | positive-in-buffer: 12113 | amount-filled: 100.00%
	| epsilon: 0.39339014290211743
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1170, 1606, 1142, 2044, 1130, 1889, 988, 2144]
	| approx positives in sample 512: 194
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 27, 16, 38, 19, 38, 13, 26]
episode: 298 -> reward: -124.99999999999218, steps:60096, time-elasped: 51221.79s
-> berries picked: 48 of 800 | patches-visited: [6] | positive-in-buffer: 12139 | amount-filled: 100.00%
	| epsilon: 0.3930737017371137
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1169, 1617, 1144, 2047, 1130, 1898, 986, 2148]
	| approx positives in sample 512: 170
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 31, 11, 26, 21, 22, 16, 31]
episode: 299 -> reward: -124.99999999999285, steps:82752, time-elasped: 51397.49s
-> berries picked: 129 of 800 | patches-visited: [0, 3, 6] | positive-in-buffer: 12139 | amount-filled: 100.00%
	| epsilon: 0.3927575151158822
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1178, 1607, 1146, 2047, 1122, 1904, 980, 2155]
	| approx positives in sample 512: 193
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 25, 25, 28, 12, 27, 19, 37]
episode: 300 -> reward: -124.99999999999223, steps:62304, time-elasped: 51552.53s
-> berries picked: 61 of 800 | patches-visited: [2] | positive-in-buffer: 12178 | amount-filled: 100.00%
	| epsilon: 0.39244158283366903
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1177, 1622, 1145, 2057, 1127, 1908, 982, 2160]
	| approx positives in sample 512: 197
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 21, 20, 38, 16, 27, 13, 39]
episode: 301 -> reward: -124.99999999998491, steps:80256, time-elasped: 51727.59s
-> berries picked: 129 of 800 | patches-visited: [2, 3] | positive-in-buffer: 12228 | amount-filled: 100.00%
	| epsilon: 0.3921259046858851
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1181, 1627, 1154, 2077, 1130, 1922, 983, 2154]
	| approx positives in sample 512: 205
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 25, 24, 43, 12, 35, 14, 41]
episode: 302 -> reward: -124.99999999999159, steps:66816, time-elasped: 51890.46s
-> berries picked: 68 of 800 | patches-visited: [2, 8] | positive-in-buffer: 12261 | amount-filled: 100.00%
	| epsilon: 0.39181048046810596
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1183, 1634, 1153, 2074, 1142, 1924, 993, 2158]
	| approx positives in sample 512: 202
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 30, 17, 30, 14, 26, 19, 47]
episode: 303 -> reward: -124.99999999999041, steps:81216, time-elasped: 52067.69s
-> berries picked: 131 of 800 | patches-visited: [3, 6] | positive-in-buffer: 12265 | amount-filled: 100.00%
	| epsilon: 0.3914953099760714
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1179, 1636, 1148, 2091, 1140, 1930, 999, 2142]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 31, 20, 28, 20, 33, 16, 36]
episode: 304 -> reward: -124.99999999999206, steps:82080, time-elasped: 52244.23s
-> berries picked: 133 of 800 | patches-visited: [5, 8] | positive-in-buffer: 12327 | amount-filled: 100.00%
	| epsilon: 0.39118039300568574
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1194, 1640, 1160, 2103, 1139, 1936, 1001, 2154]
	| approx positives in sample 512: 207
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 18, 19, 42, 15, 39, 14, 36]
episode: 305 -> reward: -124.99999999999228, steps:66240, time-elasped: 52400.65s
-> berries picked: 74 of 800 | patches-visited: [4] | positive-in-buffer: 12370 | amount-filled: 100.00%
	| epsilon: 0.39086572935301733
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1195, 1647, 1160, 2106, 1147, 1937, 1017, 2161]
	| approx positives in sample 512: 205
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 30, 24, 31, 18, 32, 14, 33]
episode: 306 -> reward: -124.99999999999234, steps:74880, time-elasped: 52573.77s
-> berries picked: 101 of 800 | patches-visited: [6, 7, 9] | positive-in-buffer: 12415 | amount-filled: 100.00%
	| epsilon: 0.3905513188142986
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1197, 1661, 1164, 2110, 1149, 1945, 1014, 2175]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 29, 18, 34, 19, 40, 16, 37]
episode: 307 -> reward: -124.99999999999224, steps:67872, time-elasped: 52734.43s
-> berries picked: 78 of 800 | patches-visited: [1, 2] | positive-in-buffer: 12458 | amount-filled: 100.00%
	| epsilon: 0.3902371611859259
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1208, 1667, 1162, 2118, 1150, 1946, 1019, 2188]
	| approx positives in sample 512: 199
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 31, 11, 29, 18, 37, 17, 38]
episode: 308 -> reward: -124.99999999998802, steps:80448, time-elasped: 52903.09s
-> berries picked: 120 of 800 | patches-visited: [0, 4] | positive-in-buffer: 12446 | amount-filled: 100.00%
	| epsilon: 0.3899232562644593
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1221, 1664, 1166, 2111, 1145, 1950, 1014, 2175]
	| approx positives in sample 512: 189
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 22, 22, 37, 20, 28, 16, 20]
episode: 309 -> reward: -124.99999999999197, steps:53760, time-elasped: 53047.43s
-> berries picked: 20 of 800 | patches-visited: [1] | positive-in-buffer: 12445 | amount-filled: 100.00%
	| epsilon: 0.38960960384662263
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1219, 1664, 1167, 2112, 1145, 1948, 1013, 2177]
	| approx positives in sample 512: 208
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 26, 19, 33, 16, 41, 14, 42]
episode: 310 -> reward: -124.99999999998882, steps:86016, time-elasped: 53228.20s
-> berries picked: 137 of 800 | patches-visited: [1, 3, 7] | positive-in-buffer: 12483 | amount-filled: 100.00%
	| epsilon: 0.3892962037293031
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1234, 1664, 1164, 2108, 1145, 1961, 1016, 2191]
	| approx positives in sample 512: 182
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 21, 14, 28, 18, 34, 17, 27]
episode: 311 -> reward: -124.999999999992, steps:61920, time-elasped: 53381.75s
-> berries picked: 50 of 800 | patches-visited: [9] | positive-in-buffer: 12512 | amount-filled: 100.00%
	| epsilon: 0.38898305570955144
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1239, 1671, 1166, 2113, 1151, 1960, 1023, 2189]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 21, 26, 29, 19, 31, 21, 35]
episode: 312 -> reward: -124.99999999999298, steps:68352, time-elasped: 53557.85s
-> berries picked: 74 of 800 | patches-visited: [2, 3] | positive-in-buffer: 12566 | amount-filled: 100.00%
	| epsilon: 0.3886701595845815
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1239, 1678, 1174, 2121, 1156, 1972, 1030, 2196]
	| approx positives in sample 512: 193
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 19, 27, 32, 21, 19, 19, 35]
episode: 313 -> reward: -124.999999999992, steps:65088, time-elasped: 53712.71s
-> berries picked: 64 of 800 | patches-visited: [3] | positive-in-buffer: 12608 | amount-filled: 100.00%
	| epsilon: 0.38835751515177036
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1251, 1684, 1177, 2130, 1158, 1976, 1030, 2202]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 26, 21, 38, 25, 33, 15, 33]
episode: 314 -> reward: -124.99999999999194, steps:64992, time-elasped: 53870.62s
-> berries picked: 71 of 800 | patches-visited: [8] | positive-in-buffer: 12648 | amount-filled: 100.00%
	| epsilon: 0.38804512220865806
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1258, 1694, 1182, 2136, 1165, 1980, 1027, 2206]
	| approx positives in sample 512: 202
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 26, 14, 30, 20, 33, 19, 35]
episode: 315 -> reward: -124.99999999999203, steps:62400, time-elasped: 54027.85s
-> berries picked: 63 of 800 | patches-visited: [3] | positive-in-buffer: 12677 | amount-filled: 100.00%
	| epsilon: 0.3877329805529474
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1262, 1702, 1182, 2136, 1167, 1985, 1032, 2211]
	| approx positives in sample 512: 204
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 39, 23, 39, 12, 29, 8, 36]
episode: 316 -> reward: -124.99999999999253, steps:66624, time-elasped: 54190.12s
-> berries picked: 77 of 800 | patches-visited: [2] | positive-in-buffer: 12691 | amount-filled: 100.00%
	| epsilon: 0.387421089982504
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1262, 1692, 1192, 2143, 1166, 1985, 1035, 2216]
	| approx positives in sample 512: 199
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 29, 13, 34, 13, 39, 15, 38]
episode: 317 -> reward: -124.99999999999184, steps:60096, time-elasped: 54341.72s
-> berries picked: 47 of 800 | patches-visited: [4] | positive-in-buffer: 12710 | amount-filled: 100.00%
	| epsilon: 0.3871094502953562
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1263, 1705, 1189, 2144, 1169, 1985, 1038, 2217]
	| approx positives in sample 512: 211
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 21, 22, 37, 27, 40, 16, 33]
episode: 318 -> reward: -124.99999999999221, steps:64416, time-elasped: 54502.33s
-> berries picked: 52 of 800 | patches-visited: [1, 5] | positive-in-buffer: 12692 | amount-filled: 100.00%
	| epsilon: 0.38679806128969446
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1262, 1700, 1187, 2141, 1168, 1982, 1034, 2218]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 26, 17, 35, 15, 37, 30, 42]
episode: 319 -> reward: -124.99999999999176, steps:65664, time-elasped: 54661.72s
-> berries picked: 69 of 800 | patches-visited: [3] | positive-in-buffer: 12707 | amount-filled: 100.00%
	| epsilon: 0.3864869227638719
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1272, 1698, 1187, 2140, 1169, 1980, 1035, 2226]
	| approx positives in sample 512: 183
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 19, 17, 28, 16, 36, 14, 33]
episode: 320 -> reward: -124.99999999998538, steps:77472, time-elasped: 54833.76s
-> berries picked: 112 of 800 | patches-visited: [4, 7] | positive-in-buffer: 12675 | amount-filled: 100.00%
	| epsilon: 0.3861760345164037
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1270, 1692, 1184, 2137, 1168, 1983, 1024, 2217]
	| approx positives in sample 512: 193
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 19, 19, 36, 20, 29, 20, 36]
episode: 321 -> reward: -124.99999999998455, steps:80160, time-elasped: 55011.34s
-> berries picked: 129 of 800 | patches-visited: [0, 2] | positive-in-buffer: 12695 | amount-filled: 100.00%
	| epsilon: 0.38586539634596717
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1275, 1698, 1192, 2148, 1159, 1997, 1019, 2207]
	| approx positives in sample 512: 181
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 24, 23, 26, 16, 26, 15, 29]
episode: 322 -> reward: -124.9999999999939, steps:81312, time-elasped: 55188.13s
-> berries picked: 122 of 800 | patches-visited: [1, 6, 8] | positive-in-buffer: 12709 | amount-filled: 100.00%
	| epsilon: 0.38555500805140147
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1275, 1697, 1193, 2141, 1170, 1989, 1027, 2217]
	| approx positives in sample 512: 201
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 24, 17, 35, 19, 37, 15, 32]
episode: 323 -> reward: -124.99999999999011, steps:65088, time-elasped: 55349.44s
-> berries picked: 65 of 800 | patches-visited: [5, 9] | positive-in-buffer: 12743 | amount-filled: 100.00%
	| epsilon: 0.3852448694317077
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1279, 1702, 1193, 2147, 1168, 1992, 1033, 2229]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 26, 23, 33, 13, 28, 22, 35]
episode: 324 -> reward: -124.99999999999228, steps:66432, time-elasped: 55508.43s
-> berries picked: 69 of 800 | patches-visited: [0] | positive-in-buffer: 12787 | amount-filled: 100.00%
	| epsilon: 0.38493498028604856
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1297, 1706, 1198, 2155, 1170, 1997, 1034, 2230]
	| approx positives in sample 512: 179
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 29, 19, 26, 13, 28, 11, 41]
episode: 325 -> reward: -124.99999999999208, steps:60672, time-elasped: 55667.50s
-> berries picked: 50 of 800 | patches-visited: [8] | positive-in-buffer: 12821 | amount-filled: 100.00%
	| epsilon: 0.3846253404137483
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1303, 1721, 1200, 2154, 1173, 1999, 1035, 2236]
	| approx positives in sample 512: 208
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 26, 17, 43, 21, 33, 18, 32]
episode: 326 -> reward: -124.99999999999207, steps:62976, time-elasped: 55821.68s
-> berries picked: 54 of 800 | patches-visited: [2] | positive-in-buffer: 12841 | amount-filled: 100.00%
	| epsilon: 0.3843159496142926
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1307, 1719, 1197, 2157, 1174, 1999, 1042, 2246]
	| approx positives in sample 512: 208
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 27, 25, 31, 25, 40, 5, 36]
episode: 327 -> reward: -124.99999999999221, steps:60384, time-elasped: 55975.44s
-> berries picked: 47 of 800 | patches-visited: [7] | positive-in-buffer: 12837 | amount-filled: 100.00%
	| epsilon: 0.3840068076873285
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1300, 1717, 1199, 2160, 1172, 1989, 1044, 2256]
	| approx positives in sample 512: 210
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 16, 23, 44, 27, 30, 14, 37]
episode: 328 -> reward: -124.99999999999217, steps:58368, time-elasped: 56127.59s
-> berries picked: 38 of 800 | patches-visited: [3] | positive-in-buffer: 12842 | amount-filled: 100.00%
	| epsilon: 0.38369791443266404
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1301, 1718, 1201, 2158, 1173, 1991, 1045, 2255]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 28, 22, 42, 24, 31, 17, 37]
episode: 329 -> reward: -124.99999999998548, steps:80256, time-elasped: 56302.38s
-> berries picked: 121 of 800 | patches-visited: [2, 5] | positive-in-buffer: 12839 | amount-filled: 100.00%
	| epsilon: 0.38338926965026854
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1293, 1713, 1186, 2156, 1176, 1990, 1068, 2257]
	| approx positives in sample 512: 196
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 20, 23, 33, 14, 26, 11, 47]
episode: 330 -> reward: -124.99999999999017, steps:82848, time-elasped: 56478.48s
-> berries picked: 135 of 800 | patches-visited: [0, 9] | positive-in-buffer: 12869 | amount-filled: 100.00%
	| epsilon: 0.383080873140272
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1297, 1716, 1201, 2159, 1174, 1985, 1073, 2264]
	| approx positives in sample 512: 207
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 28, 21, 34, 20, 33, 24, 34]
episode: 331 -> reward: -124.99999999999295, steps:76224, time-elasped: 56639.28s
-> berries picked: 106 of 800 | patches-visited: [3, 6] | positive-in-buffer: 12937 | amount-filled: 100.00%
	| epsilon: 0.38277272470296525
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1306, 1727, 1198, 2171, 1175, 1997, 1091, 2272]
	| approx positives in sample 512: 193
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 26, 9, 29, 21, 33, 22, 36]
episode: 332 -> reward: -124.99999999999433, steps:79584, time-elasped: 56808.38s
-> berries picked: 108 of 800 | patches-visited: [4, 6] | positive-in-buffer: 12953 | amount-filled: 100.00%
	| epsilon: 0.3824648241387999
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1302, 1742, 1208, 2176, 1175, 1996, 1083, 2271]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 24, 19, 34, 25, 27, 24, 44]
episode: 333 -> reward: -124.99999999999135, steps:87744, time-elasped: 56986.68s
-> berries picked: 154 of 800 | patches-visited: [5, 6] | positive-in-buffer: 12984 | amount-filled: 100.00%
	| epsilon: 0.38215717124838794
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1324, 1731, 1204, 2176, 1169, 2003, 1106, 2271]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 24, 19, 33, 17, 27, 23, 33]
episode: 334 -> reward: -124.9999999999916, steps:55392, time-elasped: 57137.06s
-> berries picked: 30 of 800 | patches-visited: [4] | positive-in-buffer: 12987 | amount-filled: 100.00%
	| epsilon: 0.3818497658325017
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1321, 1739, 1205, 2173, 1174, 2002, 1102, 2271]
	| approx positives in sample 512: 199
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 38, 25, 27, 16, 29, 12, 32]
episode: 335 -> reward: -124.99999999998941, steps:77280, time-elasped: 57307.95s
-> berries picked: 107 of 800 | patches-visited: [0, 1, 3] | positive-in-buffer: 13065 | amount-filled: 100.00%
	| epsilon: 0.38154260769207393
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1320, 1755, 1210, 2186, 1188, 2017, 1110, 2279]
	| approx positives in sample 512: 205
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 31, 21, 30, 21, 31, 14, 27]
episode: 336 -> reward: -124.99999999999187, steps:63072, time-elasped: 57456.41s
-> berries picked: 67 of 800 | patches-visited: [3] | positive-in-buffer: 13108 | amount-filled: 100.00%
	| epsilon: 0.3812356966281974
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1323, 1764, 1215, 2191, 1188, 2020, 1117, 2290]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 31, 27, 40, 24, 24, 21, 40]
episode: 337 -> reward: -124.99999999999126, steps:79584, time-elasped: 57626.51s
-> berries picked: 118 of 800 | patches-visited: [1, 7] | positive-in-buffer: 13098 | amount-filled: 100.00%
	| epsilon: 0.3809290324421249
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1329, 1756, 1213, 2185, 1189, 2027, 1121, 2278]
	| approx positives in sample 512: 206
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 23, 9, 30, 23, 32, 19, 40]
episode: 338 -> reward: -124.99999999999201, steps:57504, time-elasped: 57782.11s
-> berries picked: 34 of 800 | patches-visited: [0] | positive-in-buffer: 13113 | amount-filled: 100.00%
	| epsilon: 0.38062261493526905
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1334, 1757, 1213, 2186, 1191, 2026, 1125, 2281]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 22, 27, 38, 23, 39, 16, 34]
episode: 339 -> reward: -124.99999999999113, steps:79200, time-elasped: 57962.54s
-> berries picked: 118 of 800 | patches-visited: [0, 2, 3] | positive-in-buffer: 13141 | amount-filled: 100.00%
	| epsilon: 0.38031644390920233
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1343, 1746, 1216, 2181, 1195, 2027, 1139, 2294]
	| approx positives in sample 512: 197
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 28, 16, 23, 21, 30, 16, 36]
episode: 340 -> reward: -124.99999999999201, steps:60576, time-elasped: 58117.19s
-> berries picked: 49 of 800 | patches-visited: [9] | positive-in-buffer: 13162 | amount-filled: 100.00%
	| epsilon: 0.3800105191656567
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1342, 1753, 1217, 2182, 1193, 2033, 1143, 2299]
	| approx positives in sample 512: 199
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 16, 20, 47, 16, 26, 22, 32]
episode: 341 -> reward: -124.99999999998391, steps:81696, time-elasped: 58297.52s
-> berries picked: 122 of 800 | patches-visited: [0, 3, 9] | positive-in-buffer: 13183 | amount-filled: 100.00%
	| epsilon: 0.37970484050652376
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1350, 1772, 1223, 2180, 1198, 2024, 1138, 2298]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 31, 28, 25, 21, 32, 24, 41]
episode: 342 -> reward: -124.99999999999339, steps:62400, time-elasped: 58462.13s
-> berries picked: 52 of 800 | patches-visited: [6] | positive-in-buffer: 13210 | amount-filled: 100.00%
	| epsilon: 0.3793994077338543
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1356, 1776, 1222, 2180, 1203, 2032, 1141, 2300]
	| approx positives in sample 512: 179
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 27, 10, 32, 16, 32, 8, 38]
episode: 343 -> reward: -124.9999999999919, steps:59424, time-elasped: 58618.05s
-> berries picked: 41 of 800 | patches-visited: [1] | positive-in-buffer: 13236 | amount-filled: 100.00%
	| epsilon: 0.37909422064985837
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1362, 1781, 1227, 2184, 1207, 2035, 1141, 2299]
	| approx positives in sample 512: 210
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 27, 18, 31, 20, 33, 19, 46]
episode: 344 -> reward: -124.99999999998575, steps:92928, time-elasped: 58796.81s
-> berries picked: 182 of 800 | patches-visited: [1, 3, 9] | positive-in-buffer: 13219 | amount-filled: 100.00%
	| epsilon: 0.3787892790569053
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1358, 1788, 1224, 2182, 1193, 2035, 1134, 2305]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 26, 20, 34, 18, 37, 20, 35]
episode: 345 -> reward: -124.99999999999012, steps:66240, time-elasped: 58967.82s
-> berries picked: 67 of 800 | patches-visited: [5, 8] | positive-in-buffer: 13255 | amount-filled: 100.00%
	| epsilon: 0.37848458275752317
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1358, 1792, 1231, 2187, 1203, 2035, 1138, 2311]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 34, 20, 44, 28, 33, 17, 34]
episode: 346 -> reward: -124.9999999999922, steps:73344, time-elasped: 59133.89s
-> berries picked: 87 of 800 | patches-visited: [3, 9] | positive-in-buffer: 13313 | amount-filled: 100.00%
	| epsilon: 0.378180131554399
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1368, 1801, 1240, 2201, 1204, 2039, 1139, 2321]
	| approx positives in sample 512: 201
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 30, 24, 34, 17, 22, 14, 39]
episode: 347 -> reward: -124.99999999998074, steps:93408, time-elasped: 59326.47s
-> berries picked: 176 of 800 | patches-visited: [0, 2, 3, 5] | positive-in-buffer: 13312 | amount-filled: 100.00%
	| epsilon: 0.37787592525037855
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1352, 1797, 1244, 2196, 1210, 2058, 1141, 2314]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 28, 23, 30, 20, 26, 20, 32]
episode: 348 -> reward: -124.99999999999142, steps:76704, time-elasped: 59528.40s
-> berries picked: 97 of 800 | patches-visited: [8, 9] | positive-in-buffer: 13366 | amount-filled: 100.00%
	| epsilon: 0.3775719636484661
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1360, 1805, 1250, 2210, 1211, 2061, 1146, 2323]
	| approx positives in sample 512: 206
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 36, 21, 33, 16, 24, 18, 38]
episode: 349 -> reward: -124.99999999998784, steps:84192, time-elasped: 59703.94s
-> berries picked: 129 of 800 | patches-visited: [2, 6, 9] | positive-in-buffer: 13444 | amount-filled: 100.00%
	| epsilon: 0.37726824655182456
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1373, 1807, 1251, 2230, 1220, 2074, 1166, 2323]
	| approx positives in sample 512: 196
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 22, 26, 41, 17, 23, 12, 33]
episode: 350 -> reward: -124.99999999999187, steps:98208, time-elasped: 59895.50s
-> berries picked: 183 of 800 | patches-visited: [0, 1, 3, 7] | positive-in-buffer: 13400 | amount-filled: 100.00%
	| epsilon: 0.37696477376377485
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1375, 1804, 1246, 2210, 1225, 2057, 1171, 2312]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 25, 21, 34, 21, 31, 21, 35]
episode: 351 -> reward: -124.99999999999203, steps:65952, time-elasped: 60054.90s
-> berries picked: 78 of 800 | patches-visited: [7] | positive-in-buffer: 13439 | amount-filled: 100.00%
	| epsilon: 0.3766615450877964
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1371, 1817, 1245, 2214, 1234, 2061, 1175, 2322]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 32, 15, 28, 19, 26, 19, 44]
episode: 352 -> reward: -124.99999999998799, steps:94752, time-elasped: 60239.44s
-> berries picked: 172 of 800 | patches-visited: [0, 1, 9] | positive-in-buffer: 13460 | amount-filled: 100.00%
	| epsilon: 0.3763585603275267
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1382, 1818, 1239, 2206, 1224, 2066, 1182, 2343]
	| approx positives in sample 512: 188
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 28, 13, 34, 15, 26, 17, 32]
episode: 353 -> reward: -124.99999999999413, steps:83520, time-elasped: 60416.15s
-> berries picked: 129 of 800 | patches-visited: [5, 7, 9] | positive-in-buffer: 13544 | amount-filled: 100.00%
	| epsilon: 0.37605581928676096
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1397, 1836, 1244, 2216, 1234, 2082, 1188, 2347]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 26, 18, 36, 19, 29, 21, 36]
episode: 354 -> reward: -124.99999999999248, steps:61824, time-elasped: 60567.60s
-> berries picked: 47 of 800 | patches-visited: [1] | positive-in-buffer: 13573 | amount-filled: 100.00%
	| epsilon: 0.3757533217694525
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1398, 1845, 1248, 2225, 1235, 2089, 1191, 2342]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 20, 24, 27, 22, 36, 20, 36]
episode: 355 -> reward: -124.9999999999919, steps:59808, time-elasped: 60723.59s
-> berries picked: 52 of 800 | patches-visited: [0] | positive-in-buffer: 13602 | amount-filled: 100.00%
	| epsilon: 0.3754510675797121
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1408, 1849, 1250, 2225, 1240, 2090, 1192, 2348]
	| approx positives in sample 512: 205
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 15, 19, 44, 20, 27, 16, 39]
episode: 356 -> reward: -124.99999999998738, steps:100992, time-elasped: 60912.30s
-> berries picked: 186 of 800 | patches-visited: [1, 4, 5, 8] | positive-in-buffer: 13592 | amount-filled: 100.00%
	| epsilon: 0.3751490565218082
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1406, 1859, 1252, 2220, 1247, 2072, 1187, 2349]
	| approx positives in sample 512: 206
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 26, 13, 36, 30, 32, 30, 23]
episode: 357 -> reward: -124.99999999998869, steps:108768, time-elasped: 61106.36s
-> berries picked: 228 of 800 | patches-visited: [0, 1, 4, 9] | positive-in-buffer: 13529 | amount-filled: 100.00%
	| epsilon: 0.37484728840016684
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1401, 1840, 1242, 2206, 1225, 2086, 1176, 2353]
	| approx positives in sample 512: 199
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 27, 12, 42, 19, 25, 17, 33]
episode: 358 -> reward: -124.99999999999329, steps:80544, time-elasped: 61281.96s
-> berries picked: 120 of 800 | patches-visited: [8, 9] | positive-in-buffer: 13617 | amount-filled: 100.00%
	| epsilon: 0.37454576301937115
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1408, 1856, 1245, 2225, 1237, 2091, 1195, 2360]
	| approx positives in sample 512: 197
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 23, 18, 39, 18, 33, 18, 28]
episode: 359 -> reward: -124.9999999999874, steps:75936, time-elasped: 61447.33s
-> berries picked: 114 of 800 | patches-visited: [0, 6] | positive-in-buffer: 13678 | amount-filled: 100.00%
	| epsilon: 0.37424448018416157
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1417, 1868, 1246, 2228, 1239, 2094, 1216, 2370]
	| approx positives in sample 512: 198
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 19, 21, 33, 17, 26, 16, 43]
episode: 360 -> reward: -124.99999999999203, steps:52224, time-elasped: 61586.61s
-> berries picked: 18 of 800 | patches-visited: [7] | positive-in-buffer: 13678 | amount-filled: 100.00%
	| epsilon: 0.37394343969943555
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1418, 1866, 1247, 2227, 1241, 2098, 1213, 2368]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 22, 25, 33, 17, 32, 14, 35]
episode: 361 -> reward: -124.99999999999353, steps:61152, time-elasped: 61747.54s
-> berries picked: 49 of 800 | patches-visited: [0, 5] | positive-in-buffer: 13706 | amount-filled: 100.00%
	| epsilon: 0.37364264137024755
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1424, 1868, 1252, 2228, 1242, 2103, 1218, 2371]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 30, 18, 37, 20, 34, 22, 32]
episode: 362 -> reward: -124.9999999999881, steps:93024, time-elasped: 61938.91s
-> berries picked: 179 of 800 | patches-visited: [3, 4, 7] | positive-in-buffer: 13780 | amount-filled: 100.00%
	| epsilon: 0.37334208500180877
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1418, 1888, 1253, 2248, 1254, 2118, 1226, 2375]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 28, 23, 34, 24, 41, 12, 32]
episode: 363 -> reward: -124.99999999998816, steps:91104, time-elasped: 62124.56s
-> berries picked: 160 of 800 | patches-visited: [0, 7, 8] | positive-in-buffer: 13818 | amount-filled: 100.00%
	| epsilon: 0.3730417703994872
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1426, 1890, 1268, 2240, 1253, 2122, 1232, 2387]
	| approx positives in sample 512: 208
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 26, 25, 44, 11, 25, 23, 31]
episode: 364 -> reward: -124.99999999998626, steps:81024, time-elasped: 62299.12s
-> berries picked: 126 of 800 | patches-visited: [4, 5] | positive-in-buffer: 13901 | amount-filled: 100.00%
	| epsilon: 0.37274169736880725
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1438, 1896, 1284, 2245, 1270, 2136, 1240, 2392]
	| approx positives in sample 512: 185
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 21, 20, 26, 16, 26, 21, 34]
episode: 365 -> reward: -124.99999999999184, steps:75264, time-elasped: 62470.53s
-> berries picked: 106 of 800 | patches-visited: [2, 7] | positive-in-buffer: 13941 | amount-filled: 100.00%
	| epsilon: 0.37244186571544985
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1446, 1898, 1279, 2258, 1277, 2143, 1245, 2395]
	| approx positives in sample 512: 188
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 28, 17, 22, 21, 32, 20, 30]
episode: 366 -> reward: -124.99999999998789, steps:92064, time-elasped: 62654.12s
-> berries picked: 154 of 800 | patches-visited: [3, 5, 7, 8, 9] | positive-in-buffer: 13897 | amount-filled: 100.00%
	| epsilon: 0.37214227524525223
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1430, 1903, 1273, 2258, 1264, 2134, 1244, 2391]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 30, 28, 27, 29, 30, 19, 34]
episode: 367 -> reward: -124.9999999999915, steps:88512, time-elasped: 62832.33s
-> berries picked: 145 of 800 | patches-visited: [1, 2, 5] | positive-in-buffer: 13953 | amount-filled: 100.00%
	| epsilon: 0.3718429257642078
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1436, 1909, 1294, 2270, 1265, 2130, 1252, 2397]
	| approx positives in sample 512: 203
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 31, 16, 33, 16, 26, 18, 33]
episode: 368 -> reward: -124.99999999999196, steps:55872, time-elasped: 62980.25s
-> berries picked: 32 of 800 | patches-visited: [5] | positive-in-buffer: 13967 | amount-filled: 100.00%
	| epsilon: 0.371543817078466
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1440, 1911, 1290, 2271, 1271, 2134, 1250, 2400]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 25, 21, 28, 22, 43, 17, 38]
episode: 369 -> reward: -124.9999999999834, steps:104544, time-elasped: 63174.66s
-> berries picked: 210 of 800 | patches-visited: [1, 3, 7, 8] | positive-in-buffer: 13964 | amount-filled: 100.00%
	| epsilon: 0.37124494899433236
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1444, 1901, 1291, 2255, 1276, 2136, 1250, 2411]
	| approx positives in sample 512: 207
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 26, 19, 32, 20, 35, 23, 27]
episode: 370 -> reward: -124.99999999998944, steps:101472, time-elasped: 63368.58s
-> berries picked: 191 of 800 | patches-visited: [1, 2, 5, 8] | positive-in-buffer: 14068 | amount-filled: 100.00%
	| epsilon: 0.37094632131826794
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1440, 1925, 1303, 2264, 1281, 2159, 1256, 2440]
	| approx positives in sample 512: 202
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 31, 18, 30, 15, 31, 14, 43]
episode: 371 -> reward: -124.99999999998929, steps:92640, time-elasped: 63545.89s
-> berries picked: 170 of 800 | patches-visited: [7, 8, 9] | positive-in-buffer: 14207 | amount-filled: 100.00%
	| epsilon: 0.37064793385688966
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1462, 1958, 1315, 2276, 1295, 2180, 1269, 2452]
	| approx positives in sample 512: 198
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 26, 20, 33, 20, 38, 10, 35]
episode: 372 -> reward: -124.99999999999216, steps:59712, time-elasped: 63695.74s
-> berries picked: 39 of 800 | patches-visited: [1] | positive-in-buffer: 14198 | amount-filled: 100.00%
	| epsilon: 0.37034978641697
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1461, 1960, 1312, 2279, 1290, 2177, 1269, 2450]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 25, 18, 40, 14, 32, 26, 24]
episode: 373 -> reward: -124.99999999998956, steps:88416, time-elasped: 63873.70s
-> berries picked: 150 of 800 | patches-visited: [3, 5, 7] | positive-in-buffer: 14253 | amount-filled: 100.00%
	| epsilon: 0.37005187880543683
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1465, 1965, 1325, 2289, 1294, 2182, 1277, 2456]
	| approx positives in sample 512: 206
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 28, 22, 32, 11, 40, 18, 37]
episode: 374 -> reward: -124.99999999999204, steps:51168, time-elasped: 64023.38s
-> berries picked: 10 of 800 | patches-visited: [2] | positive-in-buffer: 14239 | amount-filled: 100.00%
	| epsilon: 0.3697542108293733
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1462, 1961, 1320, 2291, 1292, 2179, 1277, 2457]
	| approx positives in sample 512: 210
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 28, 18, 32, 13, 33, 30, 32]
episode: 375 -> reward: -124.99999999998428, steps:88896, time-elasped: 64207.07s
-> berries picked: 166 of 800 | patches-visited: [0, 3, 4] | positive-in-buffer: 14304 | amount-filled: 100.00%
	| epsilon: 0.36945678229601786
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1468, 1966, 1326, 2304, 1295, 2204, 1293, 2448]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 27, 16, 42, 20, 36, 25, 36]
episode: 376 -> reward: -124.99999999998629, steps:85248, time-elasped: 64384.86s
-> berries picked: 142 of 800 | patches-visited: [0, 4, 8] | positive-in-buffer: 14375 | amount-filled: 100.00%
	| epsilon: 0.36915959301276385
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1474, 1981, 1333, 2318, 1304, 2207, 1299, 2459]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 39, 20, 39, 16, 28, 24, 37]
episode: 377 -> reward: -124.99999999999213, steps:67008, time-elasped: 64546.02s
-> berries picked: 75 of 800 | patches-visited: [2] | positive-in-buffer: 14413 | amount-filled: 100.00%
	| epsilon: 0.36886264278715963
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1478, 1996, 1334, 2324, 1306, 2209, 1299, 2467]
	| approx positives in sample 512: 203
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 30, 19, 25, 21, 39, 13, 28]
episode: 378 -> reward: -124.9999999999923, steps:59040, time-elasped: 64699.04s
-> berries picked: 38 of 800 | patches-visited: [4] | positive-in-buffer: 14426 | amount-filled: 100.00%
	| epsilon: 0.3685659314269084
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1480, 1990, 1335, 2325, 1309, 2220, 1301, 2466]
	| approx positives in sample 512: 184
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 25, 14, 31, 22, 23, 15, 25]
episode: 379 -> reward: -124.99999999998693, steps:88800, time-elasped: 64881.23s
-> berries picked: 156 of 800 | patches-visited: [0, 3, 6] | positive-in-buffer: 14382 | amount-filled: 100.00%
	| epsilon: 0.36826945873986794
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1484, 1982, 1322, 2305, 1310, 2208, 1312, 2459]
	| approx positives in sample 512: 208
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 27, 26, 32, 23, 30, 20, 28]
episode: 380 -> reward: -124.99999999999203, steps:53952, time-elasped: 65030.64s
-> berries picked: 25 of 800 | patches-visited: [2] | positive-in-buffer: 14385 | amount-filled: 100.00%
	| epsilon: 0.36797322453405074
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1485, 1978, 1322, 2304, 1309, 2209, 1315, 2463]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 28, 21, 27, 24, 39, 22, 35]
episode: 381 -> reward: -124.99999999998651, steps:87552, time-elasped: 65208.53s
-> berries picked: 151 of 800 | patches-visited: [4, 6, 9] | positive-in-buffer: 14445 | amount-filled: 100.00%
	| epsilon: 0.3676772286176236
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1503, 1978, 1338, 2317, 1310, 2214, 1309, 2476]
	| approx positives in sample 512: 239
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 34, 20, 46, 18, 43, 18, 37]
episode: 382 -> reward: -124.99999999998705, steps:94656, time-elasped: 65397.53s
-> berries picked: 165 of 800 | patches-visited: [3, 4, 6, 9] | positive-in-buffer: 14389 | amount-filled: 100.00%
	| epsilon: 0.3673814707989076
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1500, 1979, 1339, 2310, 1307, 2202, 1306, 2446]
	| approx positives in sample 512: 195
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 21, 13, 28, 16, 43, 22, 30]
episode: 383 -> reward: -124.99999999999203, steps:56736, time-elasped: 65544.46s
-> berries picked: 29 of 800 | patches-visited: [3] | positive-in-buffer: 14392 | amount-filled: 100.00%
	| epsilon: 0.36708595088637813
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1499, 1979, 1337, 2312, 1307, 2203, 1310, 2445]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 31, 14, 42, 14, 35, 18, 39]
episode: 384 -> reward: -124.9999999999871, steps:79104, time-elasped: 65721.48s
-> berries picked: 125 of 800 | patches-visited: [3, 9] | positive-in-buffer: 14499 | amount-filled: 100.00%
	| epsilon: 0.3667906686886646
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1511, 1998, 1345, 2324, 1312, 2223, 1329, 2457]
	| approx positives in sample 512: 210
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 27, 16, 32, 16, 29, 16, 47]
episode: 385 -> reward: -124.99999999999211, steps:66720, time-elasped: 65877.36s
-> berries picked: 69 of 800 | patches-visited: [0] | positive-in-buffer: 14521 | amount-filled: 100.00%
	| epsilon: 0.3664956240145503
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1520, 2004, 1350, 2323, 1313, 2226, 1324, 2461]
	| approx positives in sample 512: 197
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 23, 17, 31, 20, 30, 20, 28]
episode: 386 -> reward: -124.99999999999176, steps:63456, time-elasped: 66033.09s
-> berries picked: 59 of 800 | patches-visited: [3, 8] | positive-in-buffer: 14553 | amount-filled: 100.00%
	| epsilon: 0.3662008166729724
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1521, 2004, 1352, 2326, 1316, 2238, 1329, 2467]
	| approx positives in sample 512: 204
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 19, 19, 35, 22, 35, 19, 30]
episode: 387 -> reward: -124.99999999999194, steps:64896, time-elasped: 66193.45s
-> berries picked: 66 of 800 | patches-visited: [6] | positive-in-buffer: 14557 | amount-filled: 100.00%
	| epsilon: 0.3659062464730217
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1525, 1996, 1356, 2333, 1315, 2232, 1327, 2473]
	| approx positives in sample 512: 202
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 21, 24, 40, 12, 33, 17, 34]
episode: 388 -> reward: -124.99999999998786, steps:73920, time-elasped: 66360.24s
-> berries picked: 91 of 800 | patches-visited: [2, 7] | positive-in-buffer: 14573 | amount-filled: 100.00%
	| epsilon: 0.36561191322394265
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1523, 2007, 1356, 2338, 1319, 2237, 1325, 2468]
	| approx positives in sample 512: 210
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 29, 21, 22, 25, 31, 28, 34]
episode: 389 -> reward: -124.99999999999145, steps:64992, time-elasped: 66521.23s
-> berries picked: 62 of 800 | patches-visited: [7] | positive-in-buffer: 14619 | amount-filled: 100.00%
	| epsilon: 0.365317816735133
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1527, 2014, 1366, 2342, 1321, 2247, 1325, 2477]
	| approx positives in sample 512: 236
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 28, 16, 36, 23, 33, 25, 49]
episode: 390 -> reward: -124.99999999999196, steps:66240, time-elasped: 66681.03s
-> berries picked: 68 of 800 | patches-visited: [4] | positive-in-buffer: 14657 | amount-filled: 100.00%
	| epsilon: 0.365023956816144
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1531, 2022, 1371, 2344, 1325, 2253, 1329, 2482]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 30, 23, 30, 18, 36, 20, 28]
episode: 391 -> reward: -124.99999999999454, steps:77856, time-elasped: 66853.39s
-> berries picked: 110 of 800 | patches-visited: [2, 9] | positive-in-buffer: 14654 | amount-filled: 100.00%
	| epsilon: 0.3647303332766801
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1518, 2029, 1369, 2334, 1322, 2255, 1341, 2486]
	| approx positives in sample 512: 186
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 23, 16, 25, 22, 32, 12, 35]
episode: 392 -> reward: -124.99999999998829, steps:91584, time-elasped: 67034.50s
-> berries picked: 163 of 800 | patches-visited: [0, 4, 6, 8] | positive-in-buffer: 14565 | amount-filled: 100.00%
	| epsilon: 0.3644369459265985
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1510, 2030, 1363, 2313, 1313, 2242, 1326, 2468]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 29, 10, 31, 22, 34, 24, 36]
episode: 393 -> reward: -124.99999999999203, steps:51648, time-elasped: 67179.85s
-> berries picked: 13 of 800 | patches-visited: [0] | positive-in-buffer: 14550 | amount-filled: 100.00%
	| epsilon: 0.3641437945759097
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1507, 2024, 1361, 2312, 1312, 2244, 1324, 2466]
	| approx positives in sample 512: 201
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 30, 18, 34, 13, 34, 17, 35]
episode: 394 -> reward: -124.99999999998994, steps:92448, time-elasped: 67369.16s
-> berries picked: 165 of 800 | patches-visited: [3, 4, 5] | positive-in-buffer: 14594 | amount-filled: 100.00%
	| epsilon: 0.3638508790347769
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1523, 2031, 1369, 2313, 1309, 2256, 1321, 2472]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 35, 18, 46, 19, 30, 20, 28]
episode: 395 -> reward: -124.99999999999163, steps:80448, time-elasped: 67535.73s
-> berries picked: 110 of 800 | patches-visited: [2, 3, 6] | positive-in-buffer: 14657 | amount-filled: 100.00%
	| epsilon: 0.36355819911351606
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1524, 2048, 1373, 2324, 1315, 2265, 1326, 2482]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 28, 15, 36, 20, 26, 23, 45]
episode: 396 -> reward: -124.99999999998042, steps:108480, time-elasped: 67728.29s
-> berries picked: 230 of 800 | patches-visited: [5, 6, 7, 9] | positive-in-buffer: 14616 | amount-filled: 100.00%
	| epsilon: 0.36326575462259564
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1535, 2034, 1364, 2305, 1303, 2273, 1329, 2473]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 30, 28, 28, 23, 37, 21, 34]
episode: 397 -> reward: -124.99999999999018, steps:84480, time-elasped: 67905.59s
-> berries picked: 126 of 800 | patches-visited: [0, 5, 6] | positive-in-buffer: 14678 | amount-filled: 100.00%
	| epsilon: 0.36297354537263654
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1542, 2053, 1375, 2310, 1312, 2277, 1335, 2474]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 27, 15, 36, 19, 35, 19, 41]
episode: 398 -> reward: -124.99999999999244, steps:75840, time-elasped: 68072.06s
-> berries picked: 108 of 800 | patches-visited: [0, 8] | positive-in-buffer: 14755 | amount-filled: 100.00%
	| epsilon: 0.3626815711744121
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1552, 2067, 1384, 2318, 1315, 2282, 1352, 2485]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 24, 30, 30, 18, 44, 21, 38]
episode: 399 -> reward: -124.99999999998158, steps:87744, time-elasped: 68247.13s
-> berries picked: 155 of 800 | patches-visited: [2, 6, 8] | positive-in-buffer: 14843 | amount-filled: 100.00%
	| epsilon: 0.36238983183884776
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1563, 2084, 1387, 2328, 1324, 2297, 1366, 2494]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 26, 13, 39, 21, 28, 19, 46]
episode: 400 -> reward: -124.99999999999307, steps:79296, time-elasped: 68422.18s
-> berries picked: 112 of 800 | patches-visited: [3, 5, 7] | positive-in-buffer: 14917 | amount-filled: 100.00%
	| epsilon: 0.36209832717702123
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1570, 2098, 1404, 2330, 1334, 2308, 1366, 2507]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 37, 20, 37, 23, 22, 16, 41]
episode: 401 -> reward: -124.99999999999251, steps:74208, time-elasped: 68592.17s
-> berries picked: 87 of 800 | patches-visited: [3, 8] | positive-in-buffer: 14961 | amount-filled: 100.00%
	| epsilon: 0.36180705700016197
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1573, 2104, 1400, 2341, 1336, 2323, 1368, 2516]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 33, 21, 32, 18, 37, 21, 36]
episode: 402 -> reward: -124.9999999999916, steps:87360, time-elasped: 68777.52s
-> berries picked: 139 of 800 | patches-visited: [0, 2, 7, 8] | positive-in-buffer: 14882 | amount-filled: 100.00%
	| epsilon: 0.36151602111965137
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1560, 2089, 1402, 2339, 1320, 2313, 1361, 2498]
	| approx positives in sample 512: 203
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 25, 16, 45, 16, 32, 17, 35]
episode: 403 -> reward: -124.99999999999291, steps:67968, time-elasped: 68935.52s
-> berries picked: 70 of 800 | patches-visited: [2, 7] | positive-in-buffer: 14933 | amount-filled: 100.00%
	| epsilon: 0.3612252193470227
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1567, 2094, 1409, 2351, 1321, 2323, 1369, 2499]
	| approx positives in sample 512: 211
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 24, 25, 29, 19, 41, 20, 27]
episode: 404 -> reward: -124.99999999998292, steps:98016, time-elasped: 69122.27s
-> berries picked: 181 of 800 | patches-visited: [2, 5, 6, 9] | positive-in-buffer: 14937 | amount-filled: 100.00%
	| epsilon: 0.3609346514939605
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1569, 2087, 1413, 2352, 1317, 2323, 1371, 2505]
	| approx positives in sample 512: 207
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 32, 16, 33, 18, 37, 16, 35]
episode: 405 -> reward: -124.99999999999271, steps:66048, time-elasped: 69287.21s
-> berries picked: 73 of 800 | patches-visited: [1] | positive-in-buffer: 14983 | amount-filled: 100.00%
	| epsilon: 0.360644317372301
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1574, 2098, 1415, 2359, 1319, 2335, 1379, 2504]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 34, 15, 41, 18, 43, 16, 34]
episode: 406 -> reward: -124.99999999999372, steps:77856, time-elasped: 69458.71s
-> berries picked: 111 of 800 | patches-visited: [7, 9] | positive-in-buffer: 15036 | amount-filled: 100.00%
	| epsilon: 0.36035421679403196
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1579, 2102, 1435, 2367, 1323, 2336, 1387, 2507]
	| approx positives in sample 512: 208
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 27, 27, 42, 23, 25, 19, 24]
episode: 407 -> reward: -124.99999999998514, steps:81120, time-elasped: 69633.56s
-> berries picked: 135 of 800 | patches-visited: [2, 4] | positive-in-buffer: 15090 | amount-filled: 100.00%
	| epsilon: 0.360064349571292
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1580, 2106, 1433, 2369, 1327, 2368, 1392, 2515]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 23, 20, 37, 20, 29, 20, 38]
episode: 408 -> reward: -124.99999999999514, steps:71712, time-elasped: 69794.37s
-> berries picked: 88 of 800 | patches-visited: [4, 7] | positive-in-buffer: 15128 | amount-filled: 100.00%
	| epsilon: 0.35977471551637114
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1587, 2111, 1435, 2379, 1328, 2371, 1396, 2521]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 30, 20, 26, 25, 28, 24, 33]
episode: 409 -> reward: -124.99999999999446, steps:82464, time-elasped: 69968.94s
-> berries picked: 122 of 800 | patches-visited: [0, 1] | positive-in-buffer: 15136 | amount-filled: 100.00%
	| epsilon: 0.3594853144417102
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1596, 2108, 1440, 2381, 1332, 2367, 1390, 2522]
	| approx positives in sample 512: 210
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 26, 17, 31, 18, 26, 26, 39]
episode: 410 -> reward: -124.99999999999096, steps:87552, time-elasped: 70153.79s
-> berries picked: 140 of 800 | patches-visited: [0, 5, 8] | positive-in-buffer: 15058 | amount-filled: 100.00%
	| epsilon: 0.3591961461599011
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1590, 2094, 1429, 2362, 1327, 2352, 1384, 2520]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 29, 26, 38, 12, 35, 29, 25]
episode: 411 -> reward: -124.99999999999054, steps:75744, time-elasped: 70322.96s
-> berries picked: 111 of 800 | patches-visited: [0, 1] | positive-in-buffer: 15138 | amount-filled: 100.00%
	| epsilon: 0.35890721048368623
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1597, 2112, 1430, 2366, 1333, 2364, 1405, 2531]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 33, 17, 32, 21, 37, 30, 34]
episode: 412 -> reward: -124.99999999999311, steps:82080, time-elasped: 70490.51s
-> berries picked: 129 of 800 | patches-visited: [5, 9] | positive-in-buffer: 15172 | amount-filled: 100.00%
	| epsilon: 0.35861850722595884
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1602, 2124, 1437, 2363, 1335, 2367, 1401, 2543]
	| approx positives in sample 512: 206
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 28, 18, 27, 20, 33, 22, 39]
episode: 413 -> reward: -124.99999999998866, steps:101280, time-elasped: 70674.63s
-> berries picked: 192 of 800 | patches-visited: [0, 2, 6, 8] | positive-in-buffer: 15052 | amount-filled: 100.00%
	| epsilon: 0.35833003619976256
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1577, 2096, 1452, 2346, 1323, 2351, 1388, 2519]
	| approx positives in sample 512: 211
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 27, 12, 32, 17, 40, 25, 40]
episode: 414 -> reward: -124.9999999999921, steps:59520, time-elasped: 70823.71s
-> berries picked: 38 of 800 | patches-visited: [2] | positive-in-buffer: 15066 | amount-filled: 100.00%
	| epsilon: 0.35804179721829144
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1581, 2100, 1453, 2347, 1322, 2356, 1387, 2520]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 29, 18, 25, 21, 35, 21, 40]
episode: 415 -> reward: -124.99999999999169, steps:65856, time-elasped: 70988.26s
-> berries picked: 72 of 800 | patches-visited: [7] | positive-in-buffer: 15125 | amount-filled: 100.00%
	| epsilon: 0.3577537900948899
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1584, 2108, 1460, 2354, 1329, 2364, 1397, 2529]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 26, 19, 37, 15, 29, 17, 46]
episode: 416 -> reward: -124.9999999999853, steps:87456, time-elasped: 71166.42s
-> berries picked: 155 of 800 | patches-visited: [1, 2, 7] | positive-in-buffer: 15210 | amount-filled: 100.00%
	| epsilon: 0.3574660146430523
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1594, 2122, 1467, 2362, 1339, 2384, 1409, 2533]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 30, 17, 38, 27, 36, 19, 30]
episode: 417 -> reward: -124.99999999999201, steps:54144, time-elasped: 71315.01s
-> berries picked: 19 of 800 | patches-visited: [8] | positive-in-buffer: 15206 | amount-filled: 100.00%
	| epsilon: 0.3571784706764231
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1597, 2116, 1467, 2358, 1339, 2388, 1409, 2532]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 33, 15, 38, 26, 30, 18, 33]
episode: 418 -> reward: -124.99999999999204, steps:58944, time-elasped: 71465.58s
-> berries picked: 37 of 800 | patches-visited: [2] | positive-in-buffer: 15235 | amount-filled: 100.00%
	| epsilon: 0.35689115800879684
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1597, 2122, 1470, 2360, 1340, 2397, 1415, 2534]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 26, 27, 32, 17, 39, 16, 41]
episode: 419 -> reward: -124.99999999998678, steps:74592, time-elasped: 71629.98s
-> berries picked: 104 of 800 | patches-visited: [4, 6] | positive-in-buffer: 15301 | amount-filled: 100.00%
	| epsilon: 0.35660407645411757
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1603, 2138, 1474, 2370, 1344, 2410, 1420, 2542]
	| approx positives in sample 512: 194
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 17, 15, 23, 25, 38, 23, 30]
episode: 420 -> reward: -124.99999999999258, steps:73824, time-elasped: 71796.48s
-> berries picked: 94 of 800 | patches-visited: [3, 9] | positive-in-buffer: 15326 | amount-filled: 100.00%
	| epsilon: 0.35631722582647923
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1609, 2147, 1474, 2370, 1345, 2415, 1419, 2547]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 30, 20, 39, 21, 33, 16, 36]
episode: 421 -> reward: -124.99999999999359, steps:75456, time-elasped: 71968.48s
-> berries picked: 101 of 800 | patches-visited: [4, 7] | positive-in-buffer: 15340 | amount-filled: 100.00%
	| epsilon: 0.35603060594012514
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1609, 2151, 1478, 2359, 1343, 2426, 1421, 2553]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 32, 17, 35, 22, 40, 25, 28]
episode: 422 -> reward: -124.99999999999216, steps:67392, time-elasped: 72127.43s
-> berries picked: 66 of 800 | patches-visited: [4, 9] | positive-in-buffer: 15381 | amount-filled: 100.00%
	| epsilon: 0.35574421660944816
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1620, 2155, 1479, 2371, 1347, 2435, 1426, 2548]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 32, 22, 39, 19, 24, 25, 45]
episode: 423 -> reward: -124.99999999999145, steps:67584, time-elasped: 72288.59s
-> berries picked: 71 of 800 | patches-visited: [9] | positive-in-buffer: 15397 | amount-filled: 100.00%
	| epsilon: 0.3554580576489903
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1624, 2158, 1479, 2369, 1347, 2436, 1428, 2556]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 35, 18, 34, 20, 39, 22, 40]
episode: 424 -> reward: -124.99999999999237, steps:68064, time-elasped: 72446.42s
-> berries picked: 79 of 800 | patches-visited: [3] | positive-in-buffer: 15424 | amount-filled: 100.00%
	| epsilon: 0.35517212887344296
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1631, 2160, 1491, 2366, 1350, 2434, 1428, 2564]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 30, 25, 32, 20, 31, 17, 38]
episode: 425 -> reward: -124.99999999999218, steps:62400, time-elasped: 72599.82s
-> berries picked: 59 of 800 | patches-visited: [9] | positive-in-buffer: 15452 | amount-filled: 100.00%
	| epsilon: 0.3548864300976464
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1633, 2163, 1492, 2381, 1350, 2439, 1429, 2565]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 36, 19, 23, 15, 39, 27, 50]
episode: 426 -> reward: -124.99999999999153, steps:61536, time-elasped: 72754.45s
-> berries picked: 55 of 800 | patches-visited: [6] | positive-in-buffer: 15479 | amount-filled: 100.00%
	| epsilon: 0.35460096113659
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1636, 2166, 1506, 2376, 1347, 2445, 1435, 2568]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 28, 22, 31, 20, 46, 17, 26]
episode: 427 -> reward: -124.99999999999226, steps:64800, time-elasped: 72912.39s
-> berries picked: 70 of 800 | patches-visited: [1] | positive-in-buffer: 15439 | amount-filled: 100.00%
	| epsilon: 0.35431572180541177
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1631, 2166, 1506, 2368, 1334, 2434, 1428, 2572]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 28, 14, 33, 22, 42, 22, 29]
episode: 428 -> reward: -124.99999999998903, steps:87744, time-elasped: 73093.94s
-> berries picked: 153 of 800 | patches-visited: [1, 7, 9] | positive-in-buffer: 15366 | amount-filled: 100.00%
	| epsilon: 0.3540307119193986
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1640, 2170, 1486, 2345, 1315, 2426, 1418, 2566]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 34, 21, 33, 14, 38, 16, 40]
episode: 429 -> reward: -124.99999999998671, steps:79392, time-elasped: 73270.22s
-> berries picked: 119 of 800 | patches-visited: [2, 3, 5] | positive-in-buffer: 15434 | amount-filled: 100.00%
	| epsilon: 0.3537459312939859
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1643, 2173, 1506, 2361, 1322, 2432, 1428, 2569]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 26, 24, 32, 20, 42, 23, 30]
episode: 430 -> reward: -124.99999999999424, steps:80256, time-elasped: 73444.16s
-> berries picked: 122 of 800 | patches-visited: [2, 9] | positive-in-buffer: 15476 | amount-filled: 100.00%
	| epsilon: 0.35346137974475744
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1652, 2178, 1512, 2365, 1321, 2433, 1438, 2577]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 27, 22, 35, 12, 33, 22, 37]
episode: 431 -> reward: -124.99999999999157, steps:75936, time-elasped: 73610.73s
-> berries picked: 112 of 800 | patches-visited: [2, 7] | positive-in-buffer: 15542 | amount-filled: 100.00%
	| epsilon: 0.3531770570874455
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1656, 2184, 1519, 2373, 1329, 2451, 1440, 2590]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 20, 27, 32, 17, 36, 23, 40]
episode: 432 -> reward: -124.99999999998566, steps:77280, time-elasped: 73783.27s
-> berries picked: 108 of 800 | patches-visited: [3, 8] | positive-in-buffer: 15502 | amount-filled: 100.00%
	| epsilon: 0.3528929631379305
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1647, 2190, 1514, 2360, 1325, 2445, 1434, 2587]
	| approx positives in sample 512: 239
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 29, 17, 31, 26, 42, 18, 54]
episode: 433 -> reward: -124.99999999998624, steps:86976, time-elasped: 73965.11s
-> berries picked: 149 of 800 | patches-visited: [0, 6, 8] | positive-in-buffer: 15368 | amount-filled: 100.00%
	| epsilon: 0.35260909771224097
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1638, 2169, 1491, 2328, 1313, 2413, 1435, 2581]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 32, 16, 31, 22, 28, 15, 44]
episode: 434 -> reward: -124.99999999998032, steps:91488, time-elasped: 74151.40s
-> berries picked: 153 of 800 | patches-visited: [0, 4, 5] | positive-in-buffer: 15370 | amount-filled: 100.00%
	| epsilon: 0.3523254606265534
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1649, 2166, 1495, 2325, 1311, 2410, 1434, 2580]
	| approx positives in sample 512: 207
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 28, 24, 25, 23, 31, 19, 30]
episode: 435 -> reward: -124.999999999992, steps:65760, time-elasped: 74310.57s
-> berries picked: 66 of 800 | patches-visited: [5] | positive-in-buffer: 15403 | amount-filled: 100.00%
	| epsilon: 0.3520420516971922
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1661, 2166, 1497, 2330, 1315, 2414, 1438, 2582]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 22, 21, 29, 16, 39, 14, 50]
episode: 436 -> reward: -124.99999999999164, steps:64512, time-elasped: 74475.38s
-> berries picked: 54 of 800 | patches-visited: [1, 5] | positive-in-buffer: 15430 | amount-filled: 100.00%
	| epsilon: 0.3517588707406295
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1661, 2166, 1494, 2333, 1324, 2424, 1441, 2587]
	| approx positives in sample 512: 248
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 34, 19, 40, 18, 36, 33, 39]
episode: 437 -> reward: -124.99999999999203, steps:67104, time-elasped: 74631.99s
-> berries picked: 71 of 800 | patches-visited: [1] | positive-in-buffer: 15474 | amount-filled: 100.00%
	| epsilon: 0.35147591757348506
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1667, 2183, 1502, 2337, 1323, 2429, 1448, 2585]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 26, 22, 33, 22, 44, 21, 32]
episode: 438 -> reward: -124.99999999998927, steps:68448, time-elasped: 74797.77s
-> berries picked: 76 of 800 | patches-visited: [4, 7] | positive-in-buffer: 15512 | amount-filled: 100.00%
	| epsilon: 0.3511931920125262
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1667, 2192, 1513, 2342, 1320, 2434, 1450, 2594]
	| approx positives in sample 512: 233
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 33, 16, 44, 18, 44, 22, 40]
episode: 439 -> reward: -124.99999999999218, steps:59136, time-elasped: 74947.70s
-> berries picked: 44 of 800 | patches-visited: [3] | positive-in-buffer: 15532 | amount-filled: 100.00%
	| epsilon: 0.35091069387466745
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1672, 2192, 1510, 2347, 1325, 2440, 1451, 2595]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 28, 19, 33, 18, 35, 21, 39]
episode: 440 -> reward: -124.99999999998641, steps:72960, time-elasped: 75113.16s
-> berries picked: 88 of 800 | patches-visited: [5, 6] | positive-in-buffer: 15549 | amount-filled: 100.00%
	| epsilon: 0.3506284229769709
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1673, 2197, 1509, 2343, 1335, 2442, 1452, 2598]
	| approx positives in sample 512: 208
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 33, 22, 33, 13, 33, 16, 33]
episode: 441 -> reward: -124.99999999999207, steps:64704, time-elasped: 75274.70s
-> berries picked: 66 of 800 | patches-visited: [1] | positive-in-buffer: 15598 | amount-filled: 100.00%
	| epsilon: 0.35034637913664557
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1674, 2201, 1516, 2349, 1332, 2457, 1459, 2610]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 29, 22, 45, 17, 32, 17, 35]
episode: 442 -> reward: -124.99999999999348, steps:73056, time-elasped: 75449.19s
-> berries picked: 101 of 800 | patches-visited: [1, 9] | positive-in-buffer: 15537 | amount-filled: 100.00%
	| epsilon: 0.3500645621710476
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1671, 2190, 1502, 2331, 1326, 2455, 1460, 2602]
	| approx positives in sample 512: 250
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 30, 18, 44, 18, 39, 29, 39]
episode: 443 -> reward: -124.999999999988, steps:96000, time-elasped: 75634.75s
-> berries picked: 186 of 800 | patches-visited: [2, 4, 7] | positive-in-buffer: 15390 | amount-filled: 100.00%
	| epsilon: 0.34978297189768
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1663, 2165, 1489, 2300, 1310, 2434, 1453, 2576]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 22, 24, 37, 16, 38, 16, 48]
episode: 444 -> reward: -124.99999999999206, steps:60864, time-elasped: 75789.77s
-> berries picked: 44 of 800 | patches-visited: [1] | positive-in-buffer: 15398 | amount-filled: 100.00%
	| epsilon: 0.3495016081341927
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1660, 2164, 1489, 2301, 1310, 2442, 1455, 2577]
	| approx positives in sample 512: 242
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 38, 25, 38, 28, 30, 27, 32]
episode: 445 -> reward: -124.99999999999196, steps:58848, time-elasped: 75945.81s
-> berries picked: 43 of 800 | patches-visited: [3] | positive-in-buffer: 15434 | amount-filled: 100.00%
	| epsilon: 0.3492204706983821
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1663, 2168, 1491, 2306, 1313, 2450, 1458, 2585]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 24, 18, 42, 19, 26, 27, 39]
episode: 446 -> reward: -124.99999999999169, steps:59712, time-elasped: 76100.81s
-> berries picked: 44 of 800 | patches-visited: [9] | positive-in-buffer: 15453 | amount-filled: 100.00%
	| epsilon: 0.3489395594081914
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1663, 2173, 1492, 2309, 1318, 2452, 1463, 2583]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 35, 25, 31, 19, 34, 18, 36]
episode: 447 -> reward: -124.99999999999255, steps:62400, time-elasped: 76254.66s
-> berries picked: 54 of 800 | patches-visited: [2] | positive-in-buffer: 15456 | amount-filled: 100.00%
	| epsilon: 0.3486588740817101
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1661, 2172, 1491, 2308, 1318, 2458, 1463, 2585]
	| approx positives in sample 512: 197
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 27, 23, 38, 21, 23, 18, 26]
episode: 448 -> reward: -124.99999999999187, steps:67776, time-elasped: 76415.54s
-> berries picked: 78 of 800 | patches-visited: [4] | positive-in-buffer: 15508 | amount-filled: 100.00%
	| epsilon: 0.348378414537174
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1667, 2177, 1492, 2313, 1321, 2473, 1468, 2597]
	| approx positives in sample 512: 204
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 28, 23, 31, 17, 24, 24, 34]
episode: 449 -> reward: -124.99999999998812, steps:88224, time-elasped: 76601.12s
-> berries picked: 154 of 800 | patches-visited: [2, 5, 7] | positive-in-buffer: 15519 | amount-filled: 100.00%
	| epsilon: 0.3480981805929653
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1665, 2186, 1505, 2307, 1318, 2470, 1471, 2597]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 27, 26, 25, 16, 42, 26, 29]
episode: 450 -> reward: -124.9999999999926, steps:84096, time-elasped: 76779.79s
-> berries picked: 143 of 800 | patches-visited: [3, 6, 8] | positive-in-buffer: 15589 | amount-filled: 100.00%
	| epsilon: 0.3478181720676121
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1674, 2193, 1511, 2323, 1322, 2478, 1482, 2606]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 23, 19, 44, 20, 31, 17, 35]
episode: 451 -> reward: -124.99999999999103, steps:59712, time-elasped: 76919.57s
-> berries picked: 41 of 800 | patches-visited: [4, 7] | positive-in-buffer: 15595 | amount-filled: 100.00%
	| epsilon: 0.34753838877978854
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1672, 2194, 1517, 2321, 1325, 2481, 1481, 2604]
	| approx positives in sample 512: 234
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 42, 9, 30, 19, 41, 29, 43]
episode: 452 -> reward: -124.99999999998812, steps:85440, time-elasped: 77181.85s
-> berries picked: 127 of 800 | patches-visited: [7, 8, 9] | positive-in-buffer: 15536 | amount-filled: 100.00%
	| epsilon: 0.3472588305483146
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1677, 2193, 1502, 2311, 1310, 2483, 1467, 2593]
	| approx positives in sample 512: 208
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 37, 19, 29, 20, 29, 22, 34]
episode: 453 -> reward: -124.99999999999058, steps:82752, time-elasped: 77415.25s
-> berries picked: 129 of 800 | patches-visited: [0, 4, 5, 7] | positive-in-buffer: 15575 | amount-filled: 100.00%
	| epsilon: 0.3469794971921561
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1677, 2203, 1512, 2313, 1320, 2477, 1475, 2598]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 34, 22, 29, 20, 32, 20, 29]
episode: 454 -> reward: -124.99999999998973, steps:84576, time-elasped: 77573.33s
-> berries picked: 128 of 800 | patches-visited: [2, 4, 6] | positive-in-buffer: 15607 | amount-filled: 100.00%
	| epsilon: 0.3467003885304243
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1676, 2211, 1517, 2308, 1326, 2495, 1478, 2596]
	| approx positives in sample 512: 246
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 28, 22, 36, 27, 42, 24, 42]
episode: 455 -> reward: -124.99999999998236, steps:103488, time-elasped: 77856.49s
-> berries picked: 206 of 800 | patches-visited: [0, 2, 5, 6, 9] | positive-in-buffer: 15532 | amount-filled: 100.00%
	| epsilon: 0.3464215043823761
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1678, 2214, 1495, 2279, 1318, 2487, 1463, 2598]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 31, 35, 22, 17, 36, 13, 33]
episode: 456 -> reward: -124.99999999999397, steps:73632, time-elasped: 78087.71s
-> berries picked: 94 of 800 | patches-visited: [0, 1, 5] | positive-in-buffer: 15589 | amount-filled: 100.00%
	| epsilon: 0.3461428445674138
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1684, 2214, 1512, 2291, 1317, 2498, 1466, 2607]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 21, 18, 37, 19, 27, 22, 48]
episode: 457 -> reward: -124.99999999999203, steps:54336, time-elasped: 78204.07s
-> berries picked: 21 of 800 | patches-visited: [1] | positive-in-buffer: 15585 | amount-filled: 100.00%
	| epsilon: 0.3458644089050849
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1683, 2210, 1511, 2290, 1321, 2498, 1466, 2606]
	| approx positives in sample 512: 226
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 25, 23, 35, 15, 43, 23, 31]
episode: 458 -> reward: -124.99999999999267, steps:64992, time-elasped: 78378.66s
-> berries picked: 64 of 800 | patches-visited: [0] | positive-in-buffer: 15627 | amount-filled: 100.00%
	| epsilon: 0.3455861972150821
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1690, 2218, 1515, 2293, 1324, 2505, 1469, 2613]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 26, 17, 31, 18, 33, 23, 42]
episode: 459 -> reward: -124.99999999999159, steps:75552, time-elasped: 78614.28s
-> berries picked: 111 of 800 | patches-visited: [0, 9] | positive-in-buffer: 15700 | amount-filled: 100.00%
	| epsilon: 0.3453082093172431
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1705, 2222, 1525, 2300, 1330, 2515, 1478, 2625]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 37, 21, 38, 14, 32, 17, 40]
episode: 460 -> reward: -124.99999999999184, steps:59328, time-elasped: 78823.13s
-> berries picked: 44 of 800 | patches-visited: [5] | positive-in-buffer: 15712 | amount-filled: 100.00%
	| epsilon: 0.34503044503155056
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1706, 2222, 1524, 2303, 1334, 2516, 1477, 2630]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 24, 22, 34, 8, 32, 26, 41]
episode: 461 -> reward: -124.99999999999272, steps:93792, time-elasped: 79075.83s
-> berries picked: 162 of 800 | patches-visited: [4, 5, 7] | positive-in-buffer: 15688 | amount-filled: 100.00%
	| epsilon: 0.3447529041781319
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1704, 2212, 1538, 2299, 1315, 2520, 1484, 2616]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 30, 16, 27, 15, 38, 25, 41]
episode: 462 -> reward: -124.99999999999179, steps:63936, time-elasped: 79282.55s
-> berries picked: 59 of 800 | patches-visited: [5] | positive-in-buffer: 15719 | amount-filled: 100.00%
	| epsilon: 0.3444755865772593
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1707, 2217, 1548, 2301, 1318, 2528, 1483, 2617]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 36, 17, 40, 28, 29, 17, 36]
episode: 463 -> reward: -124.99999999999112, steps:66048, time-elasped: 79494.70s
-> berries picked: 60 of 800 | patches-visited: [2, 8] | positive-in-buffer: 15763 | amount-filled: 100.00%
	| epsilon: 0.3441984920493495
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1712, 2219, 1549, 2310, 1326, 2531, 1491, 2625]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 25, 19, 36, 13, 32, 21, 45]
episode: 464 -> reward: -124.99999999999105, steps:69984, time-elasped: 79712.72s
-> berries picked: 78 of 800 | patches-visited: [6, 7] | positive-in-buffer: 15818 | amount-filled: 100.00%
	| epsilon: 0.34392162041496355
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1717, 2224, 1553, 2315, 1329, 2545, 1491, 2644]
	| approx positives in sample 512: 235
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 35, 25, 34, 15, 42, 23, 40]
episode: 465 -> reward: -124.99999999999247, steps:68832, time-elasped: 79932.08s
-> berries picked: 77 of 800 | patches-visited: [3] | positive-in-buffer: 15862 | amount-filled: 100.00%
	| epsilon: 0.3436449714948071
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1720, 2227, 1563, 2320, 1334, 2556, 1500, 2642]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 33, 19, 36, 9, 34, 26, 39]
episode: 466 -> reward: -124.99999999999118, steps:72768, time-elasped: 80157.88s
-> berries picked: 85 of 800 | patches-visited: [3, 7, 9] | positive-in-buffer: 15877 | amount-filled: 100.00%
	| epsilon: 0.34336854510972975
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1718, 2236, 1564, 2317, 1338, 2557, 1501, 2646]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 29, 16, 26, 21, 38, 21, 34]
episode: 467 -> reward: -124.99999999999473, steps:68544, time-elasped: 80375.40s
-> berries picked: 75 of 800 | patches-visited: [5, 6] | positive-in-buffer: 15925 | amount-filled: 100.00%
	| epsilon: 0.3430923410807254
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1724, 2238, 1573, 2320, 1345, 2568, 1508, 2649]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 30, 17, 46, 18, 28, 27, 36]
episode: 468 -> reward: -124.99999999999206, steps:65088, time-elasped: 80590.65s
-> berries picked: 61 of 800 | patches-visited: [2] | positive-in-buffer: 15959 | amount-filled: 100.00%
	| epsilon: 0.34281635922893194
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1727, 2237, 1575, 2327, 1344, 2580, 1514, 2655]
	| approx positives in sample 512: 243
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 33, 28, 40, 20, 41, 19, 38]
episode: 469 -> reward: -124.99999999999335, steps:68544, time-elasped: 80809.29s
-> berries picked: 78 of 800 | patches-visited: [1, 3] | positive-in-buffer: 15942 | amount-filled: 100.00%
	| epsilon: 0.34254059937563097
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1730, 2244, 1569, 2316, 1341, 2572, 1516, 2654]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 38, 26, 23, 14, 45, 28, 34]
episode: 470 -> reward: -124.99999999999132, steps:64032, time-elasped: 81017.48s
-> berries picked: 64 of 800 | patches-visited: [6] | positive-in-buffer: 15969 | amount-filled: 100.00%
	| epsilon: 0.342265061342248
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1737, 2243, 1580, 2319, 1340, 2580, 1521, 2649]
	| approx positives in sample 512: 236
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 36, 26, 40, 21, 36, 16, 40]
episode: 471 -> reward: -124.99999999999193, steps:62784, time-elasped: 81218.20s
-> berries picked: 45 of 800 | patches-visited: [5] | positive-in-buffer: 15971 | amount-filled: 100.00%
	| epsilon: 0.3419897449503521
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1735, 2253, 1573, 2323, 1338, 2576, 1519, 2654]
	| approx positives in sample 512: 207
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 17, 25, 22, 17, 49, 20, 36]
episode: 472 -> reward: -124.99999999999268, steps:78432, time-elasped: 81439.97s
-> berries picked: 119 of 800 | patches-visited: [4, 6] | positive-in-buffer: 15824 | amount-filled: 100.00%
	| epsilon: 0.341714650021656
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1731, 2240, 1555, 2288, 1318, 2542, 1516, 2634]
	| approx positives in sample 512: 210
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 26, 16, 29, 21, 34, 24, 35]
episode: 473 -> reward: -124.9999999999914, steps:62304, time-elasped: 81612.08s
-> berries picked: 63 of 800 | patches-visited: [7] | positive-in-buffer: 15849 | amount-filled: 100.00%
	| epsilon: 0.3414397763780157
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1730, 2246, 1563, 2290, 1320, 2544, 1519, 2637]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 35, 28, 22, 15, 43, 21, 34]
episode: 474 -> reward: -124.99999999998549, steps:79488, time-elasped: 81800.88s
-> berries picked: 115 of 800 | patches-visited: [4, 8, 9] | positive-in-buffer: 15833 | amount-filled: 100.00%
	| epsilon: 0.34116512384143055
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1733, 2251, 1559, 2281, 1309, 2539, 1523, 2638]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 36, 21, 27, 24, 34, 21, 44]
episode: 475 -> reward: -124.99999999999196, steps:55488, time-elasped: 81963.51s
-> berries picked: 24 of 800 | patches-visited: [7] | positive-in-buffer: 15841 | amount-filled: 100.00%
	| epsilon: 0.34089069223404306
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1735, 2253, 1557, 2282, 1310, 2545, 1519, 2640]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 44, 20, 25, 19, 30, 17, 31]
episode: 476 -> reward: -124.99999999999295, steps:74112, time-elasped: 82140.26s
-> berries picked: 96 of 800 | patches-visited: [1, 2, 4] | positive-in-buffer: 15906 | amount-filled: 100.00%
	| epsilon: 0.3406164813781389
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1745, 2263, 1561, 2284, 1317, 2560, 1530, 2646]
	| approx positives in sample 512: 210
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 30, 22, 22, 16, 38, 16, 43]
episode: 477 -> reward: -124.99999999999224, steps:61248, time-elasped: 82298.58s
-> berries picked: 50 of 800 | patches-visited: [6] | positive-in-buffer: 15935 | amount-filled: 100.00%
	| epsilon: 0.3403424910961465
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1750, 2268, 1567, 2291, 1320, 2562, 1529, 2648]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 38, 18, 31, 22, 38, 14, 39]
episode: 478 -> reward: -124.99999999999184, steps:62784, time-elasped: 82463.08s
-> berries picked: 51 of 800 | patches-visited: [7] | positive-in-buffer: 15966 | amount-filled: 100.00%
	| epsilon: 0.3400687212106374
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1750, 2272, 1568, 2299, 1323, 2567, 1534, 2653]
	| approx positives in sample 512: 238
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 33, 20, 41, 17, 45, 21, 37]
episode: 479 -> reward: -124.99999999998477, steps:84864, time-elasped: 82649.55s
-> berries picked: 143 of 800 | patches-visited: [1, 2] | positive-in-buffer: 15890 | amount-filled: 100.00%
	| epsilon: 0.3397951715443256
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1750, 2255, 1571, 2280, 1307, 2558, 1529, 2640]
	| approx positives in sample 512: 211
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 27, 21, 24, 19, 42, 26, 27]
episode: 480 -> reward: -124.99999999998764, steps:72768, time-elasped: 82815.68s
-> berries picked: 88 of 800 | patches-visited: [0, 2] | positive-in-buffer: 15933 | amount-filled: 100.00%
	| epsilon: 0.3395218419200679
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1754, 2263, 1567, 2288, 1310, 2566, 1534, 2651]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 26, 21, 27, 15, 27, 28, 40]
episode: 481 -> reward: -124.99999999998798, steps:87840, time-elasped: 83010.03s
-> berries picked: 152 of 800 | patches-visited: [0, 2, 5, 6] | positive-in-buffer: 15861 | amount-filled: 100.00%
	| epsilon: 0.3392487321608635
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1747, 2264, 1551, 2257, 1301, 2561, 1529, 2651]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 31, 27, 22, 19, 45, 21, 34]
episode: 482 -> reward: -124.99999999999207, steps:60192, time-elasped: 83139.01s
-> berries picked: 41 of 800 | patches-visited: [9] | positive-in-buffer: 15876 | amount-filled: 100.00%
	| epsilon: 0.33897584208985393
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1751, 2267, 1556, 2258, 1302, 2560, 1526, 2656]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 36, 18, 24, 16, 40, 24, 43]
episode: 483 -> reward: -124.9999999999918, steps:65184, time-elasped: 83280.23s
-> berries picked: 64 of 800 | patches-visited: [4] | positive-in-buffer: 15926 | amount-filled: 100.00%
	| epsilon: 0.3387031715303231
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1758, 2269, 1575, 2265, 1304, 2569, 1527, 2659]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 34, 16, 28, 17, 30, 21, 41]
episode: 484 -> reward: -124.99999999999298, steps:65280, time-elasped: 83450.60s
-> berries picked: 68 of 800 | patches-visited: [7, 9] | positive-in-buffer: 15959 | amount-filled: 100.00%
	| epsilon: 0.33843072030569704
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1759, 2276, 1576, 2275, 1304, 2572, 1533, 2664]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 29, 25, 30, 14, 34, 20, 39]
episode: 485 -> reward: -124.99999999998572, steps:82560, time-elasped: 83626.42s
-> berries picked: 124 of 800 | patches-visited: [1, 2, 9] | positive-in-buffer: 15941 | amount-filled: 100.00%
	| epsilon: 0.33815848823954375
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1758, 2275, 1577, 2266, 1298, 2560, 1530, 2677]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 37, 26, 29, 16, 38, 26, 34]
episode: 486 -> reward: -124.999999999992, steps:60288, time-elasped: 83789.13s
-> berries picked: 44 of 800 | patches-visited: [5] | positive-in-buffer: 15963 | amount-filled: 100.00%
	| epsilon: 0.3378864751555732
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1763, 2281, 1581, 2268, 1301, 2562, 1530, 2677]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 23, 28, 26, 21, 27, 33, 39]
episode: 487 -> reward: -124.99999999999203, steps:56064, time-elasped: 83966.29s
-> berries picked: 29 of 800 | patches-visited: [6] | positive-in-buffer: 15969 | amount-filled: 100.00%
	| epsilon: 0.3376146808776372
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1762, 2280, 1579, 2271, 1302, 2567, 1532, 2676]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 20, 18, 32, 21, 33, 19, 42]
episode: 488 -> reward: -124.99999999998509, steps:80736, time-elasped: 84146.57s
-> berries picked: 134 of 800 | patches-visited: [2, 3] | positive-in-buffer: 15982 | amount-filled: 100.00%
	| epsilon: 0.33734310522972916
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1771, 2282, 1582, 2268, 1304, 2566, 1534, 2675]
	| approx positives in sample 512: 239
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 34, 29, 29, 30, 40, 22, 28]
episode: 489 -> reward: -124.99999999999088, steps:67776, time-elasped: 84330.95s
-> berries picked: 72 of 800 | patches-visited: [4, 5] | positive-in-buffer: 16008 | amount-filled: 100.00%
	| epsilon: 0.33707174803598416
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1771, 2286, 1584, 2271, 1313, 2571, 1536, 2676]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 30, 22, 23, 9, 40, 22, 48]
episode: 490 -> reward: -124.99999999999206, steps:54816, time-elasped: 84495.55s
-> berries picked: 23 of 800 | patches-visited: [7] | positive-in-buffer: 16009 | amount-filled: 100.00%
	| epsilon: 0.33680060912067866
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1773, 2289, 1583, 2268, 1310, 2571, 1537, 2678]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 23, 22, 33, 18, 43, 22, 30]
episode: 491 -> reward: -124.99999999998793, steps:98496, time-elasped: 84709.90s
-> berries picked: 188 of 800 | patches-visited: [1, 4, 6] | positive-in-buffer: 15867 | amount-filled: 100.00%
	| epsilon: 0.3365296883082306
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1759, 2247, 1564, 2236, 1296, 2558, 1519, 2688]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 35, 21, 28, 20, 42, 26, 33]
episode: 492 -> reward: -124.99999999999199, steps:63168, time-elasped: 84876.88s
-> berries picked: 49 of 800 | patches-visited: [8] | positive-in-buffer: 15879 | amount-filled: 100.00%
	| epsilon: 0.336258985423199
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1764, 2249, 1571, 2238, 1295, 2560, 1515, 2687]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 32, 26, 39, 17, 32, 20, 40]
episode: 493 -> reward: -124.99999999999203, steps:51840, time-elasped: 85052.21s
-> berries picked: 13 of 800 | patches-visited: [1] | positive-in-buffer: 15882 | amount-filled: 100.00%
	| epsilon: 0.3359885002902841
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1764, 2250, 1570, 2239, 1296, 2561, 1515, 2687]
	| approx positives in sample 512: 237
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 32, 20, 31, 27, 44, 23, 30]
episode: 494 -> reward: -124.99999999999194, steps:60000, time-elasped: 85232.53s
-> berries picked: 45 of 800 | patches-visited: [0] | positive-in-buffer: 15922 | amount-filled: 100.00%
	| epsilon: 0.33571823273432716
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1765, 2255, 1577, 2241, 1302, 2569, 1521, 2692]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 31, 33, 22, 21, 31, 22, 27]
episode: 495 -> reward: -124.99999999999201, steps:62112, time-elasped: 85398.24s
-> berries picked: 51 of 800 | patches-visited: [1] | positive-in-buffer: 15954 | amount-filled: 100.00%
	| epsilon: 0.3354481825803103
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1772, 2259, 1576, 2246, 1301, 2574, 1528, 2698]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 31, 26, 29, 14, 32, 28, 37]
episode: 496 -> reward: -124.99999999999201, steps:59232, time-elasped: 85560.64s
-> berries picked: 37 of 800 | patches-visited: [9] | positive-in-buffer: 15966 | amount-filled: 100.00%
	| epsilon: 0.3351783496533564
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1774, 2258, 1577, 2243, 1301, 2580, 1527, 2706]
	| approx positives in sample 512: 210
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 39, 17, 25, 17, 39, 21, 35]
episode: 497 -> reward: -124.99999999999201, steps:55392, time-elasped: 85727.56s
-> berries picked: 28 of 800 | patches-visited: [7] | positive-in-buffer: 15981 | amount-filled: 100.00%
	| epsilon: 0.33490873377872904
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1780, 2259, 1576, 2245, 1303, 2580, 1529, 2709]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 30, 21, 36, 18, 29, 17, 42]
episode: 498 -> reward: -124.99999999998671, steps:93504, time-elasped: 85926.90s
-> berries picked: 170 of 800 | patches-visited: [2, 5, 6] | positive-in-buffer: 15949 | amount-filled: 100.00%
	| epsilon: 0.3346393347818324
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1777, 2259, 1585, 2230, 1296, 2579, 1522, 2701]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 25, 21, 31, 11, 47, 18, 36]
episode: 499 -> reward: -124.99999999999204, steps:50016, time-elasped: 86085.29s
-> berries picked: 6 of 800 | patches-visited: [5] | positive-in-buffer: 15932 | amount-filled: 100.00%
	| epsilon: 0.33437015248821106
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1776, 2256, 1582, 2225, 1293, 2577, 1522, 2701]
	| approx positives in sample 512: 201
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 33, 16, 25, 13, 40, 17, 33]
episode: 500 -> reward: -124.99999999999149, steps:58656, time-elasped: 86272.44s
-> berries picked: 41 of 800 | patches-visited: [4] | positive-in-buffer: 15970 | amount-filled: 100.00%
	| epsilon: 0.3341011867235499
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1786, 2260, 1587, 2229, 1294, 2585, 1525, 2704]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 34, 19, 25, 22, 34, 16, 48]
episode: 501 -> reward: -124.99999999999201, steps:66432, time-elasped: 86433.88s
-> berries picked: 71 of 800 | patches-visited: [9] | positive-in-buffer: 16013 | amount-filled: 100.00%
	| epsilon: 0.333832437313674
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1786, 2269, 1594, 2230, 1298, 2596, 1525, 2715]
	| approx positives in sample 512: 230
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 34, 22, 29, 21, 32, 16, 48]
episode: 502 -> reward: -124.99999999999201, steps:57024, time-elasped: 86642.23s
-> berries picked: 30 of 800 | patches-visited: [4] | positive-in-buffer: 16011 | amount-filled: 100.00%
	| epsilon: 0.3335639040845487
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1789, 2269, 1593, 2230, 1296, 2595, 1528, 2711]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 27, 19, 41, 16, 41, 19, 41]
episode: 503 -> reward: -124.99999999999193, steps:80832, time-elasped: 86827.46s
-> berries picked: 132 of 800 | patches-visited: [4, 5] | positive-in-buffer: 16070 | amount-filled: 100.00%
	| epsilon: 0.3332955868622792
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1795, 2272, 1607, 2228, 1302, 2603, 1533, 2730]
	| approx positives in sample 512: 235
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 31, 20, 39, 21, 39, 22, 44]
episode: 504 -> reward: -124.99999999998855, steps:79488, time-elasped: 87046.24s
-> berries picked: 117 of 800 | patches-visited: [2, 5] | positive-in-buffer: 16085 | amount-filled: 100.00%
	| epsilon: 0.33302748547311056
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1809, 2270, 1607, 2238, 1295, 2610, 1537, 2719]
	| approx positives in sample 512: 223
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 30, 21, 22, 24, 50, 20, 32]
episode: 505 -> reward: -124.99999999999204, steps:50016, time-elasped: 87208.92s
-> berries picked: 7 of 800 | patches-visited: [8] | positive-in-buffer: 16075 | amount-filled: 100.00%
	| epsilon: 0.3327595997434277
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1806, 2269, 1607, 2238, 1295, 2608, 1535, 2717]
	| approx positives in sample 512: 234
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 28, 34, 29, 15, 40, 24, 44]
episode: 506 -> reward: -124.99999999999228, steps:64800, time-elasped: 87420.95s
-> berries picked: 65 of 800 | patches-visited: [6] | positive-in-buffer: 16122 | amount-filled: 100.00%
	| epsilon: 0.33249192949975526
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1816, 2273, 1612, 2246, 1300, 2612, 1540, 2723]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 33, 18, 30, 17, 44, 28, 30]
episode: 507 -> reward: -124.99999999999059, steps:71136, time-elasped: 87619.69s
-> berries picked: 80 of 800 | patches-visited: [0, 1] | positive-in-buffer: 16125 | amount-filled: 100.00%
	| epsilon: 0.3322244745687571
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1817, 2266, 1613, 2243, 1297, 2619, 1542, 2728]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 26, 28, 23, 22, 37, 25, 42]
episode: 508 -> reward: -124.99999999998434, steps:81120, time-elasped: 87859.15s
-> berries picked: 127 of 800 | patches-visited: [0, 9] | positive-in-buffer: 16042 | amount-filled: 100.00%
	| epsilon: 0.3319572347772368
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1797, 2254, 1602, 2246, 1284, 2602, 1549, 2708]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 21, 19, 27, 24, 40, 21, 32]
episode: 509 -> reward: -124.99999999999197, steps:59040, time-elasped: 88056.41s
-> berries picked: 37 of 800 | patches-visited: [0] | positive-in-buffer: 16039 | amount-filled: 100.00%
	| epsilon: 0.33169020995213727
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1800, 2249, 1603, 2244, 1284, 2601, 1549, 2709]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 27, 17, 34, 12, 50, 22, 27]
episode: 510 -> reward: -124.99999999998771, steps:99456, time-elasped: 88306.32s
-> berries picked: 184 of 800 | patches-visited: [4, 8, 9] | positive-in-buffer: 15841 | amount-filled: 100.00%
	| epsilon: 0.3314233999205405
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1794, 2239, 1575, 2173, 1246, 2571, 1531, 2712]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 31, 20, 35, 21, 28, 21, 36]
episode: 511 -> reward: -124.99999999998204, steps:88224, time-elasped: 88523.47s
-> berries picked: 151 of 800 | patches-visited: [4, 7, 8] | positive-in-buffer: 15944 | amount-filled: 100.00%
	| epsilon: 0.33115680450966756
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1802, 2254, 1602, 2184, 1255, 2585, 1541, 2721]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 33, 21, 22, 18, 49, 28, 41]
episode: 512 -> reward: -124.99999999999197, steps:63648, time-elasped: 88704.16s
-> berries picked: 58 of 800 | patches-visited: [4] | positive-in-buffer: 15967 | amount-filled: 100.00%
	| epsilon: 0.33089042354687864
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1804, 2260, 1598, 2185, 1258, 2592, 1541, 2729]
	| approx positives in sample 512: 223
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 30, 23, 23, 12, 43, 19, 42]
episode: 513 -> reward: -124.99999999999368, steps:79968, time-elasped: 88913.78s
-> berries picked: 125 of 800 | patches-visited: [0, 2] | positive-in-buffer: 16036 | amount-filled: 100.00%
	| epsilon: 0.3306242568596726
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1813, 2272, 1599, 2195, 1268, 2605, 1544, 2740]
	| approx positives in sample 512: 206
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 37, 17, 28, 19, 34, 12, 36]
episode: 514 -> reward: -124.99999999998856, steps:90528, time-elasped: 89184.28s
-> berries picked: 154 of 800 | patches-visited: [0, 6, 7, 9] | positive-in-buffer: 16033 | amount-filled: 100.00%
	| epsilon: 0.33035830427568735
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1810, 2268, 1604, 2193, 1262, 2616, 1545, 2735]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 28, 22, 32, 19, 42, 14, 40]
episode: 515 -> reward: -124.99999999998664, steps:72288, time-elasped: 89397.83s
-> berries picked: 82 of 800 | patches-visited: [0, 5] | positive-in-buffer: 16081 | amount-filled: 100.00%
	| epsilon: 0.3300925656226991
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1817, 2279, 1606, 2197, 1266, 2621, 1551, 2744]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 31, 19, 26, 16, 37, 24, 41]
episode: 516 -> reward: -124.99999999999204, steps:53664, time-elasped: 89624.76s
-> berries picked: 20 of 800 | patches-visited: [5] | positive-in-buffer: 16084 | amount-filled: 100.00%
	| epsilon: 0.3298270407286229
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1819, 2279, 1604, 2197, 1266, 2625, 1552, 2742]
	| approx positives in sample 512: 203
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 26, 20, 26, 19, 30, 23, 29]
episode: 517 -> reward: -124.99999999999216, steps:60288, time-elasped: 89803.30s
-> berries picked: 50 of 800 | patches-visited: [4] | positive-in-buffer: 16116 | amount-filled: 100.00%
	| epsilon: 0.3295617294215121
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1822, 2280, 1607, 2199, 1268, 2630, 1556, 2754]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 27, 21, 31, 21, 36, 24, 34]
episode: 518 -> reward: -124.99999999999197, steps:72960, time-elasped: 89998.16s
-> berries picked: 90 of 800 | patches-visited: [0, 2] | positive-in-buffer: 16173 | amount-filled: 100.00%
	| epsilon: 0.3292966315295582
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1825, 2278, 1615, 2208, 1274, 2651, 1557, 2765]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 29, 13, 25, 21, 41, 23, 39]
episode: 519 -> reward: -124.99999999999199, steps:59904, time-elasped: 90171.81s
-> berries picked: 45 of 800 | patches-visited: [0] | positive-in-buffer: 16192 | amount-filled: 100.00%
	| epsilon: 0.32903174688109116
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1827, 2286, 1620, 2211, 1274, 2649, 1560, 2765]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 27, 24, 30, 19, 45, 23, 33]
episode: 520 -> reward: -124.9999999999933, steps:74880, time-elasped: 90361.48s
-> berries picked: 94 of 800 | patches-visited: [4, 5, 6] | positive-in-buffer: 16211 | amount-filled: 100.00%
	| epsilon: 0.328767075304579
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1831, 2284, 1623, 2207, 1271, 2652, 1573, 2770]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 27, 26, 19, 19, 42, 14, 28]
episode: 521 -> reward: -124.99999999999145, steps:73248, time-elasped: 90555.40s
-> berries picked: 93 of 800 | patches-visited: [0, 4, 9] | positive-in-buffer: 16249 | amount-filled: 100.00%
	| epsilon: 0.32850261662862756
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1840, 2289, 1626, 2210, 1274, 2656, 1576, 2778]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 28, 25, 37, 20, 29, 24, 30]
episode: 522 -> reward: -124.99999999999416, steps:92256, time-elasped: 90778.75s
-> berries picked: 146 of 800 | patches-visited: [1, 2, 6, 8] | positive-in-buffer: 15965 | amount-filled: 100.00%
	| epsilon: 0.32823837068198064
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1826, 2240, 1577, 2175, 1257, 2599, 1564, 2727]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 22, 29, 31, 24, 40, 31, 27]
episode: 523 -> reward: -124.99999999998398, steps:85536, time-elasped: 91037.16s
-> berries picked: 143 of 800 | patches-visited: [6, 9] | positive-in-buffer: 16065 | amount-filled: 100.00%
	| epsilon: 0.3279743372935198
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1835, 2249, 1594, 2186, 1263, 2621, 1579, 2738]
	| approx positives in sample 512: 233
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 26, 29, 45, 20, 33, 19, 41]
episode: 524 -> reward: -124.99999999999308, steps:63168, time-elasped: 91244.51s
-> berries picked: 54 of 800 | patches-visited: [4, 6] | positive-in-buffer: 16086 | amount-filled: 100.00%
	| epsilon: 0.32771051629226433
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1839, 2252, 1594, 2189, 1268, 2630, 1578, 2736]
	| approx positives in sample 512: 242
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 30, 26, 30, 20, 44, 25, 43]
episode: 525 -> reward: -124.99999999999302, steps:66144, time-elasped: 91469.77s
-> berries picked: 66 of 800 | patches-visited: [0, 6, 7] | positive-in-buffer: 16128 | amount-filled: 100.00%
	| epsilon: 0.3274469075073709
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1840, 2264, 1598, 2196, 1274, 2632, 1583, 2741]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 33, 24, 23, 18, 37, 17, 39]
episode: 526 -> reward: -124.99999999999204, steps:52320, time-elasped: 91652.29s
-> berries picked: 18 of 800 | patches-visited: [2] | positive-in-buffer: 16126 | amount-filled: 100.00%
	| epsilon: 0.3271835107681336
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1841, 2262, 1601, 2192, 1273, 2632, 1583, 2742]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 35, 20, 35, 20, 30, 19, 47]
episode: 527 -> reward: -124.999999999988, steps:78432, time-elasped: 91866.68s
-> berries picked: 113 of 800 | patches-visited: [0, 2, 4] | positive-in-buffer: 16163 | amount-filled: 100.00%
	| epsilon: 0.32692032590398407
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1846, 2275, 1602, 2188, 1277, 2635, 1594, 2746]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 30, 15, 36, 16, 38, 24, 47]
episode: 528 -> reward: -124.99999999999129, steps:71616, time-elasped: 92081.33s
-> berries picked: 85 of 800 | patches-visited: [2, 9] | positive-in-buffer: 16206 | amount-filled: 100.00%
	| epsilon: 0.32665735274449087
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1855, 2279, 1609, 2189, 1278, 2644, 1603, 2749]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 33, 23, 23, 23, 42, 20, 33]
episode: 529 -> reward: -124.99999999999162, steps:64800, time-elasped: 92290.10s
-> berries picked: 57 of 800 | patches-visited: [1, 3] | positive-in-buffer: 16233 | amount-filled: 100.00%
	| epsilon: 0.3263945911193598
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1858, 2282, 1608, 2192, 1282, 2649, 1605, 2757]
	| approx positives in sample 512: 233
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 29, 15, 32, 14, 42, 35, 38]
episode: 530 -> reward: -124.99999999999204, steps:55200, time-elasped: 92471.68s
-> berries picked: 26 of 800 | patches-visited: [3] | positive-in-buffer: 16245 | amount-filled: 100.00%
	| epsilon: 0.32613204085843367
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1859, 2281, 1612, 2189, 1286, 2651, 1608, 2759]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 35, 20, 27, 15, 39, 26, 43]
episode: 531 -> reward: -124.999999999992, steps:70464, time-elasped: 92674.69s
-> berries picked: 75 of 800 | patches-visited: [0, 9] | positive-in-buffer: 16251 | amount-filled: 100.00%
	| epsilon: 0.3258697017916921
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1857, 2281, 1608, 2193, 1283, 2660, 1607, 2762]
	| approx positives in sample 512: 230
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 30, 27, 33, 17, 46, 19, 32]
episode: 532 -> reward: -124.99999999999257, steps:61632, time-elasped: 92871.13s
-> berries picked: 57 of 800 | patches-visited: [8] | positive-in-buffer: 16298 | amount-filled: 100.00%
	| epsilon: 0.3256075737492514
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1862, 2290, 1612, 2200, 1286, 2672, 1609, 2767]
	| approx positives in sample 512: 234
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 40, 24, 22, 16, 45, 22, 39]
episode: 533 -> reward: -124.99999999998845, steps:80256, time-elasped: 93099.35s
-> berries picked: 113 of 800 | patches-visited: [2, 3, 4] | positive-in-buffer: 16214 | amount-filled: 100.00%
	| epsilon: 0.3253456565613648
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1859, 2279, 1610, 2183, 1277, 2656, 1600, 2750]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 29, 23, 25, 21, 38, 25, 35]
episode: 534 -> reward: -124.99999999999483, steps:70080, time-elasped: 93303.98s
-> berries picked: 85 of 800 | patches-visited: [5, 8] | positive-in-buffer: 16271 | amount-filled: 100.00%
	| epsilon: 0.3250839500584218
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1862, 2281, 1619, 2186, 1284, 2668, 1609, 2762]
	| approx positives in sample 512: 226
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 28, 22, 32, 18, 43, 14, 42]
episode: 535 -> reward: -124.99999999999204, steps:51168, time-elasped: 93471.24s
-> berries picked: 11 of 800 | patches-visited: [2] | positive-in-buffer: 16266 | amount-filled: 100.00%
	| epsilon: 0.32482245407094834
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1862, 2283, 1621, 2183, 1281, 2665, 1607, 2764]
	| approx positives in sample 512: 234
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 27, 30, 21, 18, 46, 19, 47]
episode: 536 -> reward: -124.99999999998909, steps:94944, time-elasped: 93711.21s
-> berries picked: 183 of 800 | patches-visited: [0, 7, 9] | positive-in-buffer: 16183 | amount-filled: 100.00%
	| epsilon: 0.3245611684296069
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1855, 2262, 1617, 2159, 1279, 2646, 1600, 2765]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 21, 21, 30, 15, 46, 22, 44]
episode: 537 -> reward: -124.99999999999207, steps:57984, time-elasped: 93889.10s
-> berries picked: 41 of 800 | patches-visited: [4] | positive-in-buffer: 16197 | amount-filled: 100.00%
	| epsilon: 0.3243000929651961
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1857, 2267, 1621, 2157, 1284, 2646, 1598, 2767]
	| approx positives in sample 512: 247
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 34, 25, 38, 21, 42, 24, 37]
episode: 538 -> reward: -124.99999999999203, steps:51456, time-elasped: 94042.91s
-> berries picked: 12 of 800 | patches-visited: [3] | positive-in-buffer: 16195 | amount-filled: 100.00%
	| epsilon: 0.3240392275086504
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1857, 2268, 1618, 2157, 1282, 2648, 1597, 2768]
	| approx positives in sample 512: 226
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 25, 29, 39, 10, 39, 19, 30]
episode: 539 -> reward: -124.99999999999173, steps:66720, time-elasped: 94219.33s
-> berries picked: 65 of 800 | patches-visited: [8, 9] | positive-in-buffer: 16246 | amount-filled: 100.00%
	| epsilon: 0.32377857189104065
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1863, 2278, 1624, 2163, 1288, 2652, 1602, 2776]
	| approx positives in sample 512: 242
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 41, 23, 34, 21, 39, 22, 35]
episode: 540 -> reward: -124.99999999999235, steps:80928, time-elasped: 94439.11s
-> berries picked: 115 of 800 | patches-visited: [1, 4, 6, 8] | positive-in-buffer: 16304 | amount-filled: 100.00%
	| epsilon: 0.3235181259435734
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1863, 2289, 1629, 2168, 1291, 2661, 1614, 2789]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 25, 28, 36, 14, 38, 22, 40]
episode: 541 -> reward: -124.99999999999203, steps:49536, time-elasped: 94628.80s
-> berries picked: 4 of 800 | patches-visited: [7] | positive-in-buffer: 16292 | amount-filled: 100.00%
	| epsilon: 0.3232578894975908
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1862, 2286, 1628, 2167, 1290, 2656, 1615, 2788]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 31, 18, 23, 22, 35, 22, 41]
episode: 542 -> reward: -124.9999999999946, steps:65952, time-elasped: 94821.74s
-> berries picked: 63 of 800 | patches-visited: [2, 5] | positive-in-buffer: 16344 | amount-filled: 100.00%
	| epsilon: 0.32299786238457107
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1870, 2291, 1642, 2170, 1293, 2667, 1621, 2790]
	| approx positives in sample 512: 250
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 33, 22, 33, 26, 46, 22, 44]
episode: 543 -> reward: -124.99999999999206, steps:57792, time-elasped: 94984.43s
-> berries picked: 33 of 800 | patches-visited: [1] | positive-in-buffer: 16359 | amount-filled: 100.00%
	| epsilon: 0.3227380444361277
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1871, 2292, 1638, 2176, 1297, 2669, 1623, 2793]
	| approx positives in sample 512: 234
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 30, 20, 32, 19, 31, 26, 41]
episode: 544 -> reward: -124.99999999999287, steps:81312, time-elasped: 95214.99s
-> berries picked: 118 of 800 | patches-visited: [1, 4, 6] | positive-in-buffer: 16367 | amount-filled: 100.00%
	| epsilon: 0.3224784354840096
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1878, 2300, 1630, 2171, 1286, 2680, 1622, 2800]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 36, 18, 32, 20, 41, 31, 34]
episode: 545 -> reward: -124.99999999999193, steps:62304, time-elasped: 95413.48s
-> berries picked: 47 of 800 | patches-visited: [7] | positive-in-buffer: 16392 | amount-filled: 100.00%
	| epsilon: 0.32221903536010127
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1875, 2302, 1637, 2180, 1291, 2680, 1622, 2805]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 34, 17, 34, 16, 44, 20, 45]
episode: 546 -> reward: -124.99999999999226, steps:58560, time-elasped: 95586.26s
-> berries picked: 36 of 800 | patches-visited: [5] | positive-in-buffer: 16418 | amount-filled: 100.00%
	| epsilon: 0.3219598438964222
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1877, 2307, 1639, 2181, 1294, 2689, 1626, 2805]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 31, 27, 34, 15, 42, 21, 28]
episode: 547 -> reward: -124.99999999999224, steps:58752, time-elasped: 95768.80s
-> berries picked: 38 of 800 | patches-visited: [9] | positive-in-buffer: 16442 | amount-filled: 100.00%
	| epsilon: 0.32170086092512706
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1878, 2307, 1640, 2185, 1297, 2698, 1627, 2810]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 27, 18, 28, 17, 42, 31, 35]
episode: 548 -> reward: -124.99999999999363, steps:70272, time-elasped: 95962.92s
-> berries picked: 72 of 800 | patches-visited: [5, 6] | positive-in-buffer: 16485 | amount-filled: 100.00%
	| epsilon: 0.3214420862785057
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1880, 2322, 1646, 2186, 1303, 2706, 1627, 2815]
	| approx positives in sample 512: 237
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 34, 22, 23, 14, 47, 22, 42]
episode: 549 -> reward: -124.99999999999201, steps:59328, time-elasped: 96128.73s
-> berries picked: 35 of 800 | patches-visited: [1] | positive-in-buffer: 16509 | amount-filled: 100.00%
	| epsilon: 0.3211835197889826
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1890, 2325, 1649, 2191, 1300, 2709, 1628, 2817]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 28, 18, 30, 18, 33, 22, 43]
episode: 550 -> reward: -124.99999999998893, steps:83808, time-elasped: 96332.16s
-> berries picked: 123 of 800 | patches-visited: [1, 4, 7, 8] | positive-in-buffer: 16384 | amount-filled: 100.00%
	| epsilon: 0.3209251612891172
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1879, 2297, 1636, 2176, 1294, 2703, 1613, 2786]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 20, 28, 29, 17, 47, 23, 30]
episode: 551 -> reward: -124.99999999999189, steps:58944, time-elasped: 96506.28s
-> berries picked: 44 of 800 | patches-visited: [4] | positive-in-buffer: 16409 | amount-filled: 100.00%
	| epsilon: 0.32066701061160363
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1881, 2298, 1644, 2179, 1292, 2712, 1616, 2787]
	| approx positives in sample 512: 233
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 39, 15, 21, 18, 44, 27, 42]
episode: 552 -> reward: -124.99999999999342, steps:76896, time-elasped: 96700.91s
-> berries picked: 104 of 800 | patches-visited: [0, 1] | positive-in-buffer: 16470 | amount-filled: 100.00%
	| epsilon: 0.3204090675892706
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1882, 2310, 1654, 2191, 1295, 2719, 1625, 2794]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 22, 22, 27, 17, 55, 22, 34]
episode: 553 -> reward: -124.99999999999145, steps:65280, time-elasped: 96890.87s
-> berries picked: 69 of 800 | patches-visited: [6] | positive-in-buffer: 16513 | amount-filled: 100.00%
	| epsilon: 0.3201513320550813
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1885, 2317, 1658, 2196, 1298, 2722, 1633, 2804]
	| approx positives in sample 512: 236
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 27, 24, 36, 15, 50, 32, 28]
episode: 554 -> reward: -124.99999999999176, steps:70080, time-elasped: 97069.28s
-> berries picked: 74 of 800 | patches-visited: [2, 5] | positive-in-buffer: 16528 | amount-filled: 100.00%
	| epsilon: 0.3198938038421331
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1894, 2320, 1655, 2196, 1299, 2730, 1628, 2806]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 25, 22, 26, 19, 45, 20, 28]
episode: 555 -> reward: -124.99999999999184, steps:76704, time-elasped: 97267.96s
-> berries picked: 98 of 800 | patches-visited: [0, 1, 9] | positive-in-buffer: 16470 | amount-filled: 100.00%
	| epsilon: 0.3196364827836579
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1893, 2310, 1631, 2180, 1300, 2731, 1630, 2795]
	| approx positives in sample 512: 242
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 28, 19, 38, 19, 41, 23, 41]
episode: 556 -> reward: -124.99999999999069, steps:75168, time-elasped: 97464.59s
-> berries picked: 92 of 800 | patches-visited: [3, 4] | positive-in-buffer: 16484 | amount-filled: 100.00%
	| epsilon: 0.31937936871302164
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1902, 2305, 1635, 2187, 1290, 2735, 1632, 2798]
	| approx positives in sample 512: 242
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 29, 26, 25, 19, 39, 26, 47]
episode: 557 -> reward: -124.99999999999149, steps:64704, time-elasped: 97649.58s
-> berries picked: 61 of 800 | patches-visited: [6, 7] | positive-in-buffer: 16528 | amount-filled: 100.00%
	| epsilon: 0.31912246146372425
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1902, 2315, 1640, 2190, 1296, 2745, 1637, 2803]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 31, 26, 21, 24, 39, 28, 30]
episode: 558 -> reward: -124.99999999998595, steps:77856, time-elasped: 97866.67s
-> berries picked: 108 of 800 | patches-visited: [4, 9] | positive-in-buffer: 16482 | amount-filled: 100.00%
	| epsilon: 0.3188657608693996
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1892, 2314, 1630, 2170, 1294, 2742, 1636, 2804]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [37, 35, 19, 26, 11, 40, 12, 39]
episode: 559 -> reward: -124.99999999999207, steps:68736, time-elasped: 98052.82s
-> berries picked: 72 of 800 | patches-visited: [2, 5] | positive-in-buffer: 16523 | amount-filled: 100.00%
	| epsilon: 0.3186092667638154
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1902, 2324, 1620, 2175, 1301, 2746, 1643, 2812]
	| approx positives in sample 512: 249
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 37, 29, 34, 14, 42, 28, 39]
episode: 560 -> reward: -124.99999999998785, steps:74016, time-elasped: 98270.50s
-> berries picked: 104 of 800 | patches-visited: [1, 9] | positive-in-buffer: 16555 | amount-filled: 100.00%
	| epsilon: 0.31835297898087317
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1906, 2317, 1632, 2181, 1304, 2755, 1643, 2817]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 31, 20, 23, 19, 41, 26, 34]
episode: 561 -> reward: -124.99999999999191, steps:57696, time-elasped: 98452.95s
-> berries picked: 35 of 800 | patches-visited: [3] | positive-in-buffer: 16556 | amount-filled: 100.00%
	| epsilon: 0.3180968973546079
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1905, 2327, 1624, 2181, 1304, 2757, 1644, 2814]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 22, 28, 30, 14, 22, 28, 47]
episode: 562 -> reward: -124.99999999999201, steps:57216, time-elasped: 98637.04s
-> berries picked: 31 of 800 | patches-visited: [4] | positive-in-buffer: 16563 | amount-filled: 100.00%
	| epsilon: 0.3178410217191881
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1909, 2323, 1624, 2178, 1303, 2760, 1649, 2817]
	| approx positives in sample 512: 208
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 17, 24, 37, 18, 37, 21, 28]
episode: 563 -> reward: -124.99999999999112, steps:63552, time-elasped: 98848.68s
-> berries picked: 69 of 800 | patches-visited: [3, 6] | positive-in-buffer: 16611 | amount-filled: 100.00%
	| epsilon: 0.31758535190891574
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1908, 2329, 1631, 2182, 1306, 2768, 1662, 2825]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 35, 15, 32, 11, 40, 24, 43]
episode: 564 -> reward: -124.99999999999199, steps:60576, time-elasped: 99027.94s
-> berries picked: 45 of 800 | patches-visited: [9] | positive-in-buffer: 16618 | amount-filled: 100.00%
	| epsilon: 0.3173298877582261
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1913, 2327, 1637, 2186, 1305, 2770, 1659, 2821]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 28, 24, 31, 24, 40, 20, 31]
episode: 565 -> reward: -124.99999999998458, steps:79680, time-elasped: 99235.75s
-> berries picked: 115 of 800 | patches-visited: [6, 9] | positive-in-buffer: 16533 | amount-filled: 100.00%
	| epsilon: 0.31707462910168754
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1898, 2311, 1626, 2172, 1290, 2768, 1654, 2814]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 27, 29, 25, 15, 32, 23, 42]
episode: 566 -> reward: -124.99999999999214, steps:65472, time-elasped: 99413.19s
-> berries picked: 60 of 800 | patches-visited: [2] | positive-in-buffer: 16570 | amount-filled: 100.00%
	| epsilon: 0.31681957577400155
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1905, 2319, 1631, 2174, 1293, 2768, 1658, 2822]
	| approx positives in sample 512: 233
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 33, 19, 22, 18, 52, 30, 35]
episode: 567 -> reward: -124.99999999999221, steps:63360, time-elasped: 99604.45s
-> berries picked: 59 of 800 | patches-visited: [9] | positive-in-buffer: 16605 | amount-filled: 100.00%
	| epsilon: 0.31656472761000254
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1910, 2321, 1637, 2179, 1296, 2774, 1661, 2827]
	| approx positives in sample 512: 234
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 37, 20, 32, 14, 40, 18, 44]
episode: 568 -> reward: -124.99999999999204, steps:56160, time-elasped: 99782.39s
-> berries picked: 23 of 800 | patches-visited: [8] | positive-in-buffer: 16603 | amount-filled: 100.00%
	| epsilon: 0.31631008444465786
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1908, 2321, 1632, 2177, 1295, 2780, 1663, 2827]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 32, 18, 25, 17, 42, 24, 39]
episode: 569 -> reward: -124.99999999998992, steps:78912, time-elasped: 99992.41s
-> berries picked: 112 of 800 | patches-visited: [0, 1, 3] | positive-in-buffer: 16544 | amount-filled: 100.00%
	| epsilon: 0.3160556461130675
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1909, 2315, 1619, 2148, 1283, 2774, 1662, 2834]
	| approx positives in sample 512: 205
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 26, 18, 19, 19, 38, 23, 39]
episode: 570 -> reward: -124.99999999999207, steps:60864, time-elasped: 100169.92s
-> berries picked: 51 of 800 | patches-visited: [3, 6] | positive-in-buffer: 16571 | amount-filled: 100.00%
	| epsilon: 0.3158014124504643
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1908, 2315, 1615, 2156, 1284, 2787, 1665, 2841]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 19, 24, 34, 18, 34, 22, 42]
episode: 571 -> reward: -124.999999999992, steps:62112, time-elasped: 100340.92s
-> berries picked: 52 of 800 | patches-visited: [7] | positive-in-buffer: 16607 | amount-filled: 100.00%
	| epsilon: 0.3155473832922133
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1910, 2319, 1621, 2160, 1284, 2797, 1670, 2846]
	| approx positives in sample 512: 234
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 24, 24, 36, 19, 39, 22, 44]
episode: 572 -> reward: -124.99999999999018, steps:88800, time-elasped: 100554.10s
-> berries picked: 148 of 800 | patches-visited: [1, 6, 9] | positive-in-buffer: 16499 | amount-filled: 100.00%
	| epsilon: 0.31529355847381235
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1901, 2299, 1614, 2144, 1277, 2773, 1655, 2836]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 28, 22, 28, 16, 34, 19, 49]
episode: 573 -> reward: -124.99999999999206, steps:54816, time-elasped: 100716.83s
-> berries picked: 27 of 800 | patches-visited: [1] | positive-in-buffer: 16500 | amount-filled: 100.00%
	| epsilon: 0.31503993783089135
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1905, 2299, 1614, 2139, 1276, 2774, 1653, 2840]
	| approx positives in sample 512: 230
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 34, 14, 29, 17, 43, 24, 41]
episode: 574 -> reward: -124.99999999999156, steps:66528, time-elasped: 100901.13s
-> berries picked: 66 of 800 | patches-visited: [4] | positive-in-buffer: 16551 | amount-filled: 100.00%
	| epsilon: 0.3147865211992126
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1910, 2308, 1622, 2140, 1280, 2786, 1658, 2847]
	| approx positives in sample 512: 226
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 31, 19, 35, 13, 43, 28, 36]
episode: 575 -> reward: -124.9999999999925, steps:65568, time-elasped: 101080.41s
-> berries picked: 67 of 800 | patches-visited: [8, 9] | positive-in-buffer: 16587 | amount-filled: 100.00%
	| epsilon: 0.31453330841467025
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1913, 2314, 1630, 2143, 1283, 2791, 1662, 2851]
	| approx positives in sample 512: 226
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 20, 18, 28, 10, 44, 30, 53]
episode: 576 -> reward: -124.99999999998866, steps:75840, time-elasped: 101281.29s
-> berries picked: 114 of 800 | patches-visited: [4, 9] | positive-in-buffer: 16653 | amount-filled: 100.00%
	| epsilon: 0.31428029931329077
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1915, 2310, 1636, 2155, 1287, 2819, 1669, 2862]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 24, 24, 28, 15, 42, 28, 38]
episode: 577 -> reward: -124.99999999999214, steps:79200, time-elasped: 101502.35s
-> berries picked: 109 of 800 | patches-visited: [0, 5, 7] | positive-in-buffer: 16598 | amount-filled: 100.00%
	| epsilon: 0.31402749373123234
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1920, 2297, 1636, 2157, 1282, 2800, 1659, 2847]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 34, 24, 29, 15, 40, 19, 38]
episode: 578 -> reward: -124.99999999998795, steps:79584, time-elasped: 101755.34s
-> berries picked: 118 of 800 | patches-visited: [1, 6, 9] | positive-in-buffer: 16619 | amount-filled: 100.00%
	| epsilon: 0.313774891504785
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1919, 2295, 1638, 2158, 1286, 2812, 1667, 2844]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 38, 26, 29, 15, 25, 14, 39]
episode: 579 -> reward: -124.99999999999439, steps:65760, time-elasped: 101979.16s
-> berries picked: 67 of 800 | patches-visited: [2, 5] | positive-in-buffer: 16658 | amount-filled: 100.00%
	| epsilon: 0.3135224924703705
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1921, 2301, 1637, 2167, 1294, 2815, 1675, 2848]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 31, 20, 29, 14, 48, 20, 34]
episode: 580 -> reward: -124.99999999998565, steps:75744, time-elasped: 102173.63s
-> berries picked: 97 of 800 | patches-visited: [4, 8] | positive-in-buffer: 16714 | amount-filled: 100.00%
	| epsilon: 0.3132702964645421
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1931, 2309, 1643, 2165, 1297, 2829, 1677, 2863]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 39, 22, 28, 18, 50, 22, 31]
episode: 581 -> reward: -124.99999999999204, steps:55200, time-elasped: 102349.68s
-> berries picked: 26 of 800 | patches-visited: [1] | positive-in-buffer: 16720 | amount-filled: 100.00%
	| epsilon: 0.31301830332398445
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1931, 2309, 1642, 2166, 1297, 2834, 1677, 2864]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 25, 19, 24, 19, 36, 27, 35]
episode: 582 -> reward: -124.99999999999146, steps:66336, time-elasped: 102540.81s
-> berries picked: 63 of 800 | patches-visited: [4, 5] | positive-in-buffer: 16748 | amount-filled: 100.00%
	| epsilon: 0.3127665128855139
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1942, 2306, 1644, 2166, 1303, 2838, 1681, 2868]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 34, 18, 30, 16, 40, 18, 45]
episode: 583 -> reward: -124.99999999999203, steps:53472, time-elasped: 102703.81s
-> berries picked: 18 of 800 | patches-visited: [4] | positive-in-buffer: 16754 | amount-filled: 100.00%
	| epsilon: 0.31251492498607775
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1943, 2310, 1643, 2165, 1304, 2841, 1679, 2869]
	| approx positives in sample 512: 237
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 30, 17, 32, 21, 46, 26, 33]
episode: 584 -> reward: -124.999999999994, steps:66720, time-elasped: 102895.82s
-> berries picked: 68 of 800 | patches-visited: [2, 5] | positive-in-buffer: 16786 | amount-filled: 100.00%
	| epsilon: 0.3122635394627545
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1945, 2309, 1652, 2169, 1299, 2851, 1684, 2877]
	| approx positives in sample 512: 235
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 26, 22, 31, 21, 35, 29, 44]
episode: 585 -> reward: -124.99999999999687, steps:91680, time-elasped: 103134.36s
-> berries picked: 148 of 800 | patches-visited: [5, 6, 7, 8] | positive-in-buffer: 16546 | amount-filled: 100.00%
	| epsilon: 0.31201235615275386
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1924, 2256, 1619, 2156, 1267, 2804, 1666, 2854]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 20, 19, 30, 23, 35, 23, 40]
episode: 586 -> reward: -124.99999999999501, steps:73440, time-elasped: 103352.09s
-> berries picked: 87 of 800 | patches-visited: [4, 9] | positive-in-buffer: 16609 | amount-filled: 100.00%
	| epsilon: 0.3117613748934164
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1929, 2258, 1624, 2164, 1278, 2816, 1681, 2859]
	| approx positives in sample 512: 235
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 24, 24, 29, 13, 44, 26, 47]
episode: 587 -> reward: -124.99999999999204, steps:56352, time-elasped: 103556.61s
-> berries picked: 29 of 800 | patches-visited: [3] | positive-in-buffer: 16618 | amount-filled: 100.00%
	| epsilon: 0.31151059552221344
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1931, 2260, 1625, 2164, 1278, 2819, 1681, 2860]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 29, 18, 30, 16, 32, 21, 41]
episode: 588 -> reward: -124.99999999999204, steps:56736, time-elasped: 103744.30s
-> berries picked: 27 of 800 | patches-visited: [7] | positive-in-buffer: 16633 | amount-filled: 100.00%
	| epsilon: 0.3112600178767472
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1935, 2262, 1626, 2164, 1278, 2820, 1685, 2863]
	| approx positives in sample 512: 233
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 29, 22, 41, 15, 29, 33, 42]
episode: 589 -> reward: -124.99999999999321, steps:72480, time-elasped: 103974.71s
-> berries picked: 93 of 800 | patches-visited: [1, 4] | positive-in-buffer: 16700 | amount-filled: 100.00%
	| epsilon: 0.3110096417947504
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1950, 2274, 1625, 2171, 1283, 2833, 1697, 2867]
	| approx positives in sample 512: 237
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 28, 18, 36, 20, 47, 27, 32]
episode: 590 -> reward: -124.99999999999206, steps:60480, time-elasped: 104177.27s
-> berries picked: 48 of 800 | patches-visited: [1] | positive-in-buffer: 16720 | amount-filled: 100.00%
	| epsilon: 0.3107594671140863
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1950, 2272, 1630, 2174, 1283, 2843, 1697, 2871]
	| approx positives in sample 512: 226
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 29, 16, 34, 12, 44, 23, 39]
episode: 591 -> reward: -124.9999999999911, steps:75936, time-elasped: 104387.87s
-> berries picked: 98 of 800 | patches-visited: [4, 8] | positive-in-buffer: 16759 | amount-filled: 100.00%
	| epsilon: 0.31050949367274877
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1948, 2282, 1632, 2187, 1288, 2853, 1695, 2874]
	| approx positives in sample 512: 223
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 29, 20, 29, 14, 28, 26, 53]
episode: 592 -> reward: -124.99999999999052, steps:77280, time-elasped: 104598.69s
-> berries picked: 103 of 800 | patches-visited: [1, 6, 9] | positive-in-buffer: 16740 | amount-filled: 100.00%
	| epsilon: 0.31025972130886176
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1949, 2287, 1636, 2169, 1284, 2837, 1700, 2878]
	| approx positives in sample 512: 234
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 25, 24, 38, 10, 44, 22, 45]
episode: 593 -> reward: -124.99999999999201, steps:50976, time-elasped: 104770.23s
-> berries picked: 13 of 800 | patches-visited: [7] | positive-in-buffer: 16739 | amount-filled: 100.00%
	| epsilon: 0.3100101498606795
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1950, 2283, 1636, 2168, 1285, 2836, 1699, 2882]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 27, 24, 33, 11, 38, 20, 35]
episode: 594 -> reward: -124.99999999999241, steps:79296, time-elasped: 105001.29s
-> berries picked: 109 of 800 | patches-visited: [2, 6] | positive-in-buffer: 16763 | amount-filled: 100.00%
	| epsilon: 0.30976077916658634
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1955, 2288, 1641, 2171, 1286, 2844, 1695, 2883]
	| approx positives in sample 512: 239
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 24, 27, 33, 16, 39, 28, 46]
episode: 595 -> reward: -124.99999999999375, steps:74784, time-elasped: 105241.22s
-> berries picked: 93 of 800 | patches-visited: [1, 6, 8] | positive-in-buffer: 16819 | amount-filled: 100.00%
	| epsilon: 0.3095116090650968
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1959, 2289, 1646, 2182, 1288, 2863, 1697, 2895]
	| approx positives in sample 512: 211
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 28, 23, 26, 17, 41, 20, 39]
episode: 596 -> reward: -124.99999999999179, steps:55680, time-elasped: 105434.55s
-> berries picked: 27 of 800 | patches-visited: [2, 5] | positive-in-buffer: 16829 | amount-filled: 100.00%
	| epsilon: 0.30926263939485493
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1958, 2295, 1645, 2180, 1295, 2860, 1699, 2897]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 27, 22, 32, 17, 33, 27, 45]
episode: 597 -> reward: -124.99999999999196, steps:63840, time-elasped: 105650.96s
-> berries picked: 55 of 800 | patches-visited: [0, 5] | positive-in-buffer: 16852 | amount-filled: 100.00%
	| epsilon: 0.30901386999463487
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1959, 2302, 1647, 2178, 1295, 2865, 1709, 2897]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 33, 24, 34, 13, 25, 27, 41]
episode: 598 -> reward: -124.99999999999203, steps:55584, time-elasped: 105830.12s
-> berries picked: 26 of 800 | patches-visited: [7] | positive-in-buffer: 16861 | amount-filled: 100.00%
	| epsilon: 0.3087653007033404
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1963, 2301, 1647, 2176, 1296, 2865, 1711, 2902]
	| approx positives in sample 512: 239
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 28, 15, 28, 30, 47, 27, 44]
episode: 599 -> reward: -124.99999999999368, steps:77280, time-elasped: 106043.99s
-> berries picked: 108 of 800 | patches-visited: [1, 2, 5] | positive-in-buffer: 16820 | amount-filled: 100.00%
	| epsilon: 0.30851693136000485
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1959, 2285, 1642, 2162, 1292, 2863, 1718, 2899]
	| approx positives in sample 512: 237
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 40, 20, 38, 16, 40, 14, 40]
episode: 600 -> reward: -124.99999999999147, steps:67584, time-elasped: 106260.24s
-> berries picked: 71 of 800 | patches-visited: [2, 5] | positive-in-buffer: 16867 | amount-filled: 100.00%
	| epsilon: 0.308268761803791
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1967, 2287, 1644, 2178, 1300, 2871, 1721, 2899]
	| approx positives in sample 512: 254
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 28, 28, 41, 16, 49, 25, 41]
episode: 601 -> reward: -124.99999999998708, steps:76032, time-elasped: 106469.07s
-> berries picked: 106 of 800 | patches-visited: [5, 8] | positive-in-buffer: 16878 | amount-filled: 100.00%
	| epsilon: 0.308020791873991
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1974, 2285, 1646, 2166, 1299, 2883, 1724, 2901]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 32, 21, 16, 21, 44, 23, 39]
episode: 602 -> reward: -124.99999999999127, steps:60384, time-elasped: 106671.24s
-> berries picked: 44 of 800 | patches-visited: [3, 8] | positive-in-buffer: 16892 | amount-filled: 100.00%
	| epsilon: 0.3077730214100263
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1974, 2289, 1646, 2167, 1301, 2881, 1729, 2905]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 21, 26, 27, 12, 37, 19, 51]
episode: 603 -> reward: -124.99999999999199, steps:57504, time-elasped: 106854.76s
-> berries picked: 32 of 800 | patches-visited: [7] | positive-in-buffer: 16911 | amount-filled: 100.00%
	| epsilon: 0.3075254502514477
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1977, 2294, 1645, 2170, 1302, 2884, 1732, 2907]
	| approx positives in sample 512: 243
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 27, 27, 35, 17, 50, 24, 35]
episode: 604 -> reward: -124.99999999998715, steps:73536, time-elasped: 107044.85s
-> berries picked: 95 of 800 | patches-visited: [3, 5] | positive-in-buffer: 16926 | amount-filled: 100.00%
	| epsilon: 0.3072780782379347
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1989, 2298, 1649, 2164, 1293, 2887, 1739, 2907]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 38, 20, 29, 11, 31, 21, 43]
episode: 605 -> reward: -124.99999999999189, steps:78912, time-elasped: 107272.36s
-> berries picked: 114 of 800 | patches-visited: [6, 9] | positive-in-buffer: 16821 | amount-filled: 100.00%
	| epsilon: 0.30703090520929605
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1981, 2280, 1643, 2155, 1281, 2863, 1726, 2892]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 26, 15, 24, 18, 52, 17, 44]
episode: 606 -> reward: -124.99999999999184, steps:58272, time-elasped: 107456.51s
-> berries picked: 36 of 800 | patches-visited: [6, 8] | positive-in-buffer: 16842 | amount-filled: 100.00%
	| epsilon: 0.3067839310054692
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1988, 2286, 1646, 2156, 1279, 2863, 1729, 2895]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 20, 11, 33, 18, 36, 25, 44]
episode: 607 -> reward: -124.9999999999921, steps:59520, time-elasped: 107640.59s
-> berries picked: 41 of 800 | patches-visited: [8] | positive-in-buffer: 16866 | amount-filled: 100.00%
	| epsilon: 0.3065371554665205
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1991, 2287, 1648, 2159, 1280, 2869, 1731, 2901]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 32, 18, 26, 13, 42, 33, 32]
episode: 608 -> reward: -124.9999999999929, steps:60864, time-elasped: 107831.74s
-> berries picked: 46 of 800 | patches-visited: [7, 8] | positive-in-buffer: 16895 | amount-filled: 100.00%
	| epsilon: 0.30629057843264473
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1993, 2293, 1646, 2165, 1282, 2875, 1735, 2906]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 24, 21, 31, 16, 33, 32, 39]
episode: 609 -> reward: -124.99999999999143, steps:56256, time-elasped: 108010.06s
-> berries picked: 30 of 800 | patches-visited: [0, 4] | positive-in-buffer: 16907 | amount-filled: 100.00%
	| epsilon: 0.3060441997441655
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2001, 2290, 1647, 2163, 1282, 2882, 1734, 2908]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 29, 17, 26, 12, 54, 15, 36]
episode: 610 -> reward: -124.99999999999162, steps:72480, time-elasped: 108233.43s
-> berries picked: 96 of 800 | patches-visited: [3, 9] | positive-in-buffer: 16931 | amount-filled: 100.00%
	| epsilon: 0.30579801924153466
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2003, 2290, 1647, 2166, 1283, 2888, 1740, 2914]
	| approx positives in sample 512: 223
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 26, 26, 26, 19, 43, 22, 33]
episode: 611 -> reward: -124.99999999999203, steps:54240, time-elasped: 108397.85s
-> berries picked: 20 of 800 | patches-visited: [5] | positive-in-buffer: 16924 | amount-filled: 100.00%
	| epsilon: 0.3055520367653324
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2002, 2285, 1648, 2167, 1281, 2891, 1739, 2911]
	| approx positives in sample 512: 234
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 24, 24, 30, 13, 43, 34, 39]
episode: 612 -> reward: -124.99999999999139, steps:84480, time-elasped: 108615.70s
-> berries picked: 131 of 800 | patches-visited: [0, 2, 7] | positive-in-buffer: 16800 | amount-filled: 100.00%
	| epsilon: 0.3053062521562672
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1983, 2248, 1641, 2146, 1267, 2873, 1743, 2899]
	| approx positives in sample 512: 205
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 31, 22, 24, 15, 40, 21, 34]
episode: 613 -> reward: -124.99999999999203, steps:53760, time-elasped: 108828.78s
-> berries picked: 23 of 800 | patches-visited: [1] | positive-in-buffer: 16799 | amount-filled: 100.00%
	| epsilon: 0.30506066525517583
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1982, 2249, 1641, 2149, 1267, 2874, 1738, 2899]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 28, 25, 20, 18, 37, 21, 48]
episode: 614 -> reward: -124.99999999999203, steps:52896, time-elasped: 109012.95s
-> berries picked: 17 of 800 | patches-visited: [8] | positive-in-buffer: 16810 | amount-filled: 100.00%
	| epsilon: 0.30481527590302276
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1984, 2252, 1641, 2149, 1267, 2876, 1739, 2902]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 22, 23, 31, 11, 37, 26, 39]
episode: 615 -> reward: -124.99999999999196, steps:59712, time-elasped: 109207.19s
-> berries picked: 46 of 800 | patches-visited: [6] | positive-in-buffer: 16851 | amount-filled: 100.00%
	| epsilon: 0.30457008394090057
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1990, 2255, 1643, 2152, 1271, 2885, 1744, 2911]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 32, 13, 27, 16, 34, 32, 44]
episode: 616 -> reward: -124.99999999999193, steps:66528, time-elasped: 109394.14s
-> berries picked: 73 of 800 | patches-visited: [9] | positive-in-buffer: 16881 | amount-filled: 100.00%
	| epsilon: 0.30432508921002976
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1988, 2263, 1647, 2151, 1272, 2893, 1744, 2923]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 34, 21, 18, 22, 53, 25, 31]
episode: 617 -> reward: -124.99999999999538, steps:71328, time-elasped: 109574.48s
-> berries picked: 88 of 800 | patches-visited: [3, 7] | positive-in-buffer: 16902 | amount-filled: 100.00%
	| epsilon: 0.3040802915517584
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1997, 2274, 1646, 2155, 1267, 2888, 1751, 2924]
	| approx positives in sample 512: 211
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 28, 23, 25, 15, 37, 26, 37]
episode: 618 -> reward: -124.99999999999208, steps:59232, time-elasped: 109771.89s
-> berries picked: 44 of 800 | patches-visited: [0, 2] | positive-in-buffer: 16922 | amount-filled: 100.00%
	| epsilon: 0.3038356908075622
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2000, 2272, 1650, 2161, 1266, 2897, 1750, 2926]
	| approx positives in sample 512: 238
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 36, 22, 29, 19, 38, 19, 43]
episode: 619 -> reward: -124.99999999999208, steps:57216, time-elasped: 109950.65s
-> berries picked: 37 of 800 | patches-visited: [7] | positive-in-buffer: 16939 | amount-filled: 100.00%
	| epsilon: 0.3035912868190444
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2001, 2275, 1648, 2163, 1267, 2904, 1751, 2930]
	| approx positives in sample 512: 236
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 34, 15, 36, 11, 45, 36, 35]
episode: 620 -> reward: -124.99999999999334, steps:77088, time-elasped: 110171.61s
-> berries picked: 113 of 800 | patches-visited: [6, 8] | positive-in-buffer: 16920 | amount-filled: 100.00%
	| epsilon: 0.30334707942793576
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1992, 2259, 1651, 2171, 1266, 2915, 1751, 2915]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 32, 17, 36, 18, 30, 25, 31]
episode: 621 -> reward: -124.9999999999941, steps:66240, time-elasped: 110397.51s
-> berries picked: 65 of 800 | patches-visited: [6, 7] | positive-in-buffer: 16947 | amount-filled: 100.00%
	| epsilon: 0.30310306847609414
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1992, 2269, 1648, 2173, 1271, 2917, 1756, 2921]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 27, 18, 28, 14, 36, 22, 45]
episode: 622 -> reward: -124.99999999999231, steps:63168, time-elasped: 110633.95s
-> berries picked: 59 of 800 | patches-visited: [2] | positive-in-buffer: 16972 | amount-filled: 100.00%
	| epsilon: 0.3028592538055048
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1991, 2268, 1654, 2183, 1269, 2924, 1755, 2928]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 35, 24, 23, 19, 33, 33, 32]
episode: 623 -> reward: -124.99999999999437, steps:80352, time-elasped: 110872.63s
-> berries picked: 116 of 800 | patches-visited: [4, 6, 8] | positive-in-buffer: 16843 | amount-filled: 100.00%
	| epsilon: 0.30261563525828
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1977, 2221, 1645, 2189, 1258, 2906, 1743, 2904]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 21, 26, 21, 21, 38, 25, 43]
episode: 624 -> reward: -124.99999999999386, steps:70560, time-elasped: 111075.01s
-> berries picked: 83 of 800 | patches-visited: [1, 6] | positive-in-buffer: 16900 | amount-filled: 100.00%
	| epsilon: 0.30237221267665904
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1982, 2229, 1650, 2194, 1260, 2921, 1754, 2910]
	| approx positives in sample 512: 236
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 34, 26, 33, 17, 35, 28, 38]
episode: 625 -> reward: -124.99999999999204, steps:60096, time-elasped: 111256.12s
-> berries picked: 46 of 800 | patches-visited: [6] | positive-in-buffer: 16926 | amount-filled: 100.00%
	| epsilon: 0.3021289859030082
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1983, 2233, 1651, 2196, 1262, 2928, 1755, 2918]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 34, 23, 31, 25, 42, 18, 30]
episode: 626 -> reward: -124.99999999999197, steps:66912, time-elasped: 111418.75s
-> berries picked: 63 of 800 | patches-visited: [0, 2] | positive-in-buffer: 16957 | amount-filled: 100.00%
	| epsilon: 0.3018859547798203
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1984, 2239, 1658, 2206, 1265, 2931, 1754, 2920]
	| approx positives in sample 512: 223
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 29, 25, 31, 14, 38, 20, 41]
episode: 627 -> reward: -124.99999999999196, steps:62976, time-elasped: 111601.04s
-> berries picked: 53 of 800 | patches-visited: [5] | positive-in-buffer: 16965 | amount-filled: 100.00%
	| epsilon: 0.30164311914971514
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1986, 2237, 1658, 2209, 1267, 2926, 1760, 2922]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 25, 25, 39, 17, 39, 23, 39]
episode: 628 -> reward: -124.99999999999201, steps:55008, time-elasped: 111792.69s
-> berries picked: 25 of 800 | patches-visited: [9] | positive-in-buffer: 16981 | amount-filled: 100.00%
	| epsilon: 0.301400478855439
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1990, 2241, 1658, 2212, 1265, 2927, 1759, 2929]
	| approx positives in sample 512: 237
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 35, 27, 32, 18, 44, 20, 36]
episode: 629 -> reward: -124.99999999999203, steps:49344, time-elasped: 111957.88s
-> berries picked: 6 of 800 | patches-visited: [1] | positive-in-buffer: 16980 | amount-filled: 100.00%
	| epsilon: 0.3011580337398647
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1989, 2239, 1657, 2210, 1265, 2928, 1759, 2933]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 27, 26, 18, 22, 37, 16, 51]
episode: 630 -> reward: -124.99999999999204, steps:51360, time-elasped: 112131.45s
-> berries picked: 12 of 800 | patches-visited: [9] | positive-in-buffer: 16984 | amount-filled: 100.00%
	| epsilon: 0.3009157836459914
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1991, 2238, 1657, 2210, 1265, 2928, 1761, 2934]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 25, 25, 35, 19, 33, 34, 35]
episode: 631 -> reward: -124.99999999999194, steps:66144, time-elasped: 112321.16s
-> berries picked: 68 of 800 | patches-visited: [9] | positive-in-buffer: 16970 | amount-filled: 100.00%
	| epsilon: 0.3006737284169446
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1984, 2228, 1658, 2210, 1266, 2926, 1764, 2934]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 25, 15, 30, 15, 44, 23, 52]
episode: 632 -> reward: -124.99999999999196, steps:63360, time-elasped: 112514.58s
-> berries picked: 54 of 800 | patches-visited: [1, 6] | positive-in-buffer: 16993 | amount-filled: 100.00%
	| epsilon: 0.30043186789597587
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1991, 2234, 1655, 2215, 1263, 2929, 1769, 2937]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 35, 32, 19, 16, 49, 24, 32]
episode: 633 -> reward: -124.999999999992, steps:60288, time-elasped: 112693.09s
-> berries picked: 47 of 800 | patches-visited: [7] | positive-in-buffer: 17018 | amount-filled: 100.00%
	| epsilon: 0.300190201926463
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1994, 2235, 1662, 2218, 1264, 2937, 1770, 2938]
	| approx positives in sample 512: 238
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 29, 14, 40, 18, 44, 29, 42]
episode: 634 -> reward: -124.99999999999595, steps:79488, time-elasped: 112913.88s
-> berries picked: 118 of 800 | patches-visited: [6, 9] | positive-in-buffer: 16806 | amount-filled: 100.00%
	| epsilon: 0.2999487303519097
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1961, 2181, 1651, 2190, 1240, 2914, 1766, 2903]
	| approx positives in sample 512: 205
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 22, 16, 29, 9, 45, 17, 43]
episode: 635 -> reward: -124.9999999999937, steps:77184, time-elasped: 113107.62s
-> berries picked: 115 of 800 | patches-visited: [5, 6] | positive-in-buffer: 16863 | amount-filled: 100.00%
	| epsilon: 0.2997074530159457
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1962, 2188, 1655, 2209, 1240, 2945, 1757, 2907]
	| approx positives in sample 512: 236
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 18, 28, 38, 18, 44, 27, 37]
episode: 636 -> reward: -124.999999999992, steps:63360, time-elasped: 113299.19s
-> berries picked: 55 of 800 | patches-visited: [9] | positive-in-buffer: 16882 | amount-filled: 100.00%
	| epsilon: 0.2994663697623262
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1965, 2187, 1657, 2211, 1240, 2943, 1765, 2914]
	| approx positives in sample 512: 238
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 21, 26, 23, 19, 58, 21, 43]
episode: 637 -> reward: -124.99999999998795, steps:70080, time-elasped: 113523.43s
-> berries picked: 84 of 800 | patches-visited: [1, 5] | positive-in-buffer: 16907 | amount-filled: 100.00%
	| epsilon: 0.29922548043493247
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1967, 2192, 1657, 2219, 1244, 2947, 1771, 2910]
	| approx positives in sample 512: 243
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 29, 20, 30, 23, 49, 29, 35]
episode: 638 -> reward: -124.99999999999088, steps:75552, time-elasped: 113748.42s
-> berries picked: 105 of 800 | patches-visited: [4, 9] | positive-in-buffer: 16858 | amount-filled: 100.00%
	| epsilon: 0.2989847848777711
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1961, 2182, 1647, 2216, 1238, 2951, 1760, 2903]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 27, 24, 27, 17, 36, 28, 42]
episode: 639 -> reward: -124.99999999999226, steps:64800, time-elasped: 113944.38s
-> berries picked: 58 of 800 | patches-visited: [2] | positive-in-buffer: 16887 | amount-filled: 100.00%
	| epsilon: 0.2987442829349742
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1966, 2187, 1649, 2222, 1237, 2953, 1767, 2906]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 19, 17, 30, 15, 45, 22, 39]
episode: 640 -> reward: -124.99999999999197, steps:61152, time-elasped: 114130.19s
-> berries picked: 50 of 800 | patches-visited: [5] | positive-in-buffer: 16920 | amount-filled: 100.00%
	| epsilon: 0.2985039744507993
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1967, 2192, 1655, 2229, 1237, 2960, 1765, 2915]
	| approx positives in sample 512: 211
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 29, 19, 29, 18, 40, 30, 27]
episode: 641 -> reward: -124.99999999999203, steps:58752, time-elasped: 114320.67s
-> berries picked: 36 of 800 | patches-visited: [8] | positive-in-buffer: 16940 | amount-filled: 100.00%
	| epsilon: 0.2982638592696293
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1968, 2193, 1656, 2233, 1239, 2967, 1767, 2917]
	| approx positives in sample 512: 199
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 28, 19, 19, 17, 38, 19, 33]
episode: 642 -> reward: -124.99999999999167, steps:57312, time-elasped: 114514.57s
-> berries picked: 35 of 800 | patches-visited: [5] | positive-in-buffer: 16962 | amount-filled: 100.00%
	| epsilon: 0.29802393723597204
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1970, 2195, 1657, 2233, 1242, 2974, 1767, 2924]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 29, 26, 24, 19, 39, 31, 39]
episode: 643 -> reward: -124.99999999999173, steps:63360, time-elasped: 114700.73s
-> berries picked: 59 of 800 | patches-visited: [1] | positive-in-buffer: 16977 | amount-filled: 100.00%
	| epsilon: 0.2977842081944607
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1968, 2194, 1661, 2238, 1242, 2975, 1773, 2926]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 21, 21, 24, 19, 43, 31, 32]
episode: 644 -> reward: -124.99999999999174, steps:63456, time-elasped: 114904.40s
-> berries picked: 60 of 800 | patches-visited: [3] | positive-in-buffer: 16946 | amount-filled: 100.00%
	| epsilon: 0.2975446719898532
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1961, 2179, 1661, 2238, 1242, 2982, 1767, 2916]
	| approx positives in sample 512: 242
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 24, 21, 25, 19, 44, 34, 43]
episode: 645 -> reward: -124.99999999999233, steps:63648, time-elasped: 115122.87s
-> berries picked: 58 of 800 | patches-visited: [3] | positive-in-buffer: 16946 | amount-filled: 100.00%
	| epsilon: 0.29730532846703256
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1961, 2179, 1661, 2237, 1243, 2985, 1768, 2912]
	| approx positives in sample 512: 241
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 28, 25, 34, 19, 37, 21, 46]
episode: 646 -> reward: -124.99999999999204, steps:52224, time-elasped: 115325.16s
-> berries picked: 12 of 800 | patches-visited: [2] | positive-in-buffer: 16945 | amount-filled: 100.00%
	| epsilon: 0.2970661774710064
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1961, 2177, 1660, 2237, 1244, 2987, 1768, 2911]
	| approx positives in sample 512: 234
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 26, 28, 27, 20, 46, 18, 41]
episode: 647 -> reward: -124.9999999999933, steps:66912, time-elasped: 115538.62s
-> berries picked: 71 of 800 | patches-visited: [8, 9] | positive-in-buffer: 16871 | amount-filled: 100.00%
	| epsilon: 0.29682721884690705
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1941, 2154, 1656, 2234, 1239, 2987, 1765, 2895]
	| approx positives in sample 512: 241
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 28, 24, 22, 27, 41, 28, 38]
episode: 648 -> reward: -124.99999999999221, steps:74688, time-elasped: 115732.24s
-> berries picked: 90 of 800 | patches-visited: [4, 8, 9] | positive-in-buffer: 16777 | amount-filled: 100.00%
	| epsilon: 0.29658845243999155
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1929, 2126, 1651, 2222, 1235, 2991, 1761, 2862]
	| approx positives in sample 512: 230
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 34, 19, 26, 17, 48, 23, 38]
episode: 649 -> reward: -124.99999999999214, steps:66048, time-elasped: 115929.25s
-> berries picked: 75 of 800 | patches-visited: [7] | positive-in-buffer: 16834 | amount-filled: 100.00%
	| epsilon: 0.2963498780956412
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1933, 2136, 1659, 2233, 1240, 2999, 1763, 2871]
	| approx positives in sample 512: 241
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 32, 21, 31, 16, 50, 30, 33]
episode: 650 -> reward: -124.99999999999336, steps:84096, time-elasped: 116144.22s
-> berries picked: 139 of 800 | patches-visited: [1, 6] | positive-in-buffer: 16778 | amount-filled: 100.00%
	| epsilon: 0.2961114956593618
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1916, 2122, 1660, 2230, 1240, 3001, 1755, 2854]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 27, 25, 35, 19, 40, 26, 33]
episode: 651 -> reward: -124.99999999999201, steps:65088, time-elasped: 116327.44s
-> berries picked: 57 of 800 | patches-visited: [4, 8] | positive-in-buffer: 16785 | amount-filled: 100.00%
	| epsilon: 0.2958733049767835
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1922, 2122, 1658, 2229, 1239, 2999, 1761, 2855]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 20, 19, 35, 11, 46, 22, 50]
episode: 652 -> reward: -124.999999999995, steps:80256, time-elasped: 116532.63s
-> berries picked: 127 of 800 | patches-visited: [7, 8] | positive-in-buffer: 16768 | amount-filled: 100.00%
	| epsilon: 0.29563530589366044
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1898, 2103, 1664, 2252, 1235, 3004, 1759, 2853]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 27, 17, 33, 15, 46, 26, 42]
episode: 653 -> reward: -124.99999999999204, steps:61728, time-elasped: 116712.68s
-> berries picked: 49 of 800 | patches-visited: [8] | positive-in-buffer: 16787 | amount-filled: 100.00%
	| epsilon: 0.29539749825587097
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1899, 2110, 1662, 2249, 1235, 3012, 1763, 2857]
	| approx positives in sample 512: 233
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 32, 20, 37, 22, 44, 22, 37]
episode: 654 -> reward: -124.99999999998529, steps:97152, time-elasped: 116990.19s
-> berries picked: 192 of 800 | patches-visited: [0, 1, 6] | positive-in-buffer: 16617 | amount-filled: 100.00%
	| epsilon: 0.29515988190941733
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1854, 2073, 1638, 2239, 1233, 3004, 1753, 2823]
	| approx positives in sample 512: 234
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 26, 31, 29, 18, 48, 18, 43]
episode: 655 -> reward: -124.99999999999383, steps:76416, time-elasped: 117213.43s
-> berries picked: 110 of 800 | patches-visited: [2, 7] | positive-in-buffer: 16696 | amount-filled: 100.00%
	| epsilon: 0.2949224567004257
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1866, 2083, 1641, 2250, 1241, 3021, 1759, 2835]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 26, 28, 24, 14, 43, 35, 34]
episode: 656 -> reward: -124.99999999999405, steps:72288, time-elasped: 117412.25s
-> berries picked: 91 of 800 | patches-visited: [3, 8] | positive-in-buffer: 16752 | amount-filled: 100.00%
	| epsilon: 0.29468522247514606
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1874, 2095, 1644, 2259, 1235, 3039, 1763, 2843]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 17, 21, 28, 16, 35, 26, 45]
episode: 657 -> reward: -124.99999999999122, steps:82176, time-elasped: 117609.76s
-> berries picked: 139 of 800 | patches-visited: [1, 4] | positive-in-buffer: 16818 | amount-filled: 100.00%
	| epsilon: 0.29444817907995197
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1882, 2096, 1652, 2275, 1238, 3052, 1774, 2849]
	| approx positives in sample 512: 239
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 32, 31, 32, 12, 48, 27, 34]
episode: 658 -> reward: -124.99999999999206, steps:57792, time-elasped: 117801.52s
-> berries picked: 31 of 800 | patches-visited: [8] | positive-in-buffer: 16820 | amount-filled: 100.00%
	| epsilon: 0.29421132636134056
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1883, 2093, 1652, 2274, 1237, 3054, 1777, 2850]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 24, 22, 37, 13, 41, 27, 43]
episode: 659 -> reward: -124.99999999999191, steps:74496, time-elasped: 117996.86s
-> berries picked: 99 of 800 | patches-visited: [4, 6] | positive-in-buffer: 16877 | amount-filled: 100.00%
	| epsilon: 0.2939746641659326
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1886, 2095, 1655, 2292, 1247, 3068, 1777, 2857]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 23, 24, 29, 18, 40, 29, 38]
episode: 660 -> reward: -124.99999999999191, steps:61632, time-elasped: 118178.62s
-> berries picked: 58 of 800 | patches-visited: [7] | positive-in-buffer: 16917 | amount-filled: 100.00%
	| epsilon: 0.2937381923404721
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1887, 2105, 1655, 2300, 1246, 3078, 1783, 2863]
	| approx positives in sample 512: 239
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 23, 22, 32, 20, 44, 21, 46]
episode: 661 -> reward: -124.99999999999211, steps:58656, time-elasped: 118368.73s
-> berries picked: 34 of 800 | patches-visited: [7] | positive-in-buffer: 16926 | amount-filled: 100.00%
	| epsilon: 0.2935019107318263
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1889, 2103, 1658, 2297, 1249, 3082, 1781, 2867]
	| approx positives in sample 512: 236
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 36, 14, 30, 21, 46, 27, 43]
episode: 662 -> reward: -124.99999999999358, steps:62880, time-elasped: 118571.02s
-> berries picked: 52 of 800 | patches-visited: [0, 3] | positive-in-buffer: 16918 | amount-filled: 100.00%
	| epsilon: 0.2932658191869858
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1883, 2096, 1661, 2304, 1246, 3083, 1783, 2862]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 31, 18, 42, 10, 32, 30, 43]
episode: 663 -> reward: -124.99999999999211, steps:63360, time-elasped: 118765.85s
-> berries picked: 55 of 800 | patches-visited: [1] | positive-in-buffer: 16916 | amount-filled: 100.00%
	| epsilon: 0.29302991755306407
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1880, 2091, 1661, 2301, 1249, 3096, 1780, 2858]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 34, 23, 31, 11, 34, 25, 40]
episode: 664 -> reward: -124.9999999999913, steps:72672, time-elasped: 118992.97s
-> berries picked: 91 of 800 | patches-visited: [3, 4, 5, 9] | positive-in-buffer: 16873 | amount-filled: 100.00%
	| epsilon: 0.29279420567729775
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1866, 2083, 1662, 2299, 1251, 3092, 1779, 2841]
	| approx positives in sample 512: 226
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 28, 23, 31, 15, 48, 21, 43]
episode: 665 -> reward: -124.99999999999123, steps:70848, time-elasped: 119194.17s
-> berries picked: 78 of 800 | patches-visited: [2, 5] | positive-in-buffer: 16902 | amount-filled: 100.00%
	| epsilon: 0.29255868340704627
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1870, 2082, 1662, 2303, 1250, 3107, 1784, 2844]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 31, 30, 25, 16, 37, 23, 38]
episode: 666 -> reward: -124.99999999999103, steps:72576, time-elasped: 119394.62s
-> berries picked: 81 of 800 | patches-visited: [1, 5] | positive-in-buffer: 16876 | amount-filled: 100.00%
	| epsilon: 0.29232335058979186
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1867, 2078, 1655, 2307, 1245, 3110, 1783, 2831]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 27, 28, 30, 22, 34, 24, 36]
episode: 667 -> reward: -124.99999999999218, steps:60768, time-elasped: 119587.99s
-> berries picked: 46 of 800 | patches-visited: [8] | positive-in-buffer: 16902 | amount-filled: 100.00%
	| epsilon: 0.2920882070731394
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1870, 2083, 1655, 2313, 1248, 3115, 1784, 2834]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 19, 20, 25, 15, 40, 24, 42]
episode: 668 -> reward: -124.9999999999901, steps:96000, time-elasped: 119828.88s
-> berries picked: 183 of 800 | patches-visited: [0, 3, 6, 8] | positive-in-buffer: 16606 | amount-filled: 100.00%
	| epsilon: 0.2918532527048164
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1797, 2009, 1647, 2287, 1227, 3078, 1772, 2789]
	| approx positives in sample 512: 235
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 23, 18, 36, 14, 46, 30, 43]
episode: 669 -> reward: -124.99999999998903, steps:79776, time-elasped: 120050.84s
-> berries picked: 119 of 800 | patches-visited: [2, 5, 6] | positive-in-buffer: 16694 | amount-filled: 100.00%
	| epsilon: 0.29161848733267276
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1807, 2020, 1655, 2302, 1243, 3094, 1783, 2790]
	| approx positives in sample 512: 237
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 25, 31, 31, 10, 43, 27, 43]
episode: 670 -> reward: -124.99999999999224, steps:59712, time-elasped: 120278.29s
-> berries picked: 40 of 800 | patches-visited: [4, 9] | positive-in-buffer: 16713 | amount-filled: 100.00%
	| epsilon: 0.291383910804681
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1808, 2020, 1658, 2310, 1242, 3097, 1786, 2792]
	| approx positives in sample 512: 239
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 26, 24, 30, 19, 44, 32, 38]
episode: 671 -> reward: -124.99999999999254, steps:61536, time-elasped: 120471.70s
-> berries picked: 46 of 800 | patches-visited: [7] | positive-in-buffer: 16740 | amount-filled: 100.00%
	| epsilon: 0.29114952296893565
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1814, 2020, 1666, 2310, 1246, 3107, 1786, 2791]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 21, 21, 26, 17, 43, 19, 46]
episode: 672 -> reward: -124.99999999999243, steps:68448, time-elasped: 120660.91s
-> berries picked: 79 of 800 | patches-visited: [4, 6] | positive-in-buffer: 16779 | amount-filled: 100.00%
	| epsilon: 0.2909153236736537
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1818, 2025, 1666, 2319, 1245, 3119, 1794, 2793]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 22, 15, 30, 12, 50, 26, 33]
episode: 673 -> reward: -124.99999999999164, steps:62304, time-elasped: 120879.76s
-> berries picked: 51 of 800 | patches-visited: [7] | positive-in-buffer: 16804 | amount-filled: 100.00%
	| epsilon: 0.2906813127671739
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1818, 2029, 1666, 2325, 1246, 3128, 1795, 2797]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 23, 20, 23, 17, 43, 29, 41]
episode: 674 -> reward: -124.99999999999017, steps:84000, time-elasped: 121136.55s
-> berries picked: 133 of 800 | patches-visited: [1, 6, 9] | positive-in-buffer: 16780 | amount-filled: 100.00%
	| epsilon: 0.2904474900979574
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1804, 2021, 1668, 2331, 1249, 3143, 1792, 2772]
	| approx positives in sample 512: 236
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 29, 21, 35, 16, 40, 42, 34]
episode: 675 -> reward: -124.99999999999255, steps:83520, time-elasped: 121320.41s
-> berries picked: 127 of 800 | patches-visited: [0, 5, 6, 8, 9] | positive-in-buffer: 16761 | amount-filled: 100.00%
	| epsilon: 0.29021385551458684
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1791, 2011, 1663, 2336, 1245, 3156, 1795, 2764]
	| approx positives in sample 512: 236
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 24, 23, 40, 24, 40, 23, 39]
episode: 676 -> reward: -124.99999999999295, steps:57312, time-elasped: 121475.44s
-> berries picked: 32 of 800 | patches-visited: [1, 7] | positive-in-buffer: 16778 | amount-filled: 100.00%
	| epsilon: 0.28998040886576704
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1792, 2011, 1664, 2337, 1246, 3165, 1796, 2767]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 27, 24, 26, 17, 54, 21, 32]
episode: 677 -> reward: -124.99999999999194, steps:65280, time-elasped: 121642.29s
-> berries picked: 66 of 800 | patches-visited: [3] | positive-in-buffer: 16824 | amount-filled: 100.00%
	| epsilon: 0.2897471500003242
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1794, 2015, 1673, 2347, 1251, 3180, 1795, 2769]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 30, 21, 34, 10, 43, 18, 32]
episode: 678 -> reward: -124.99999999999157, steps:84384, time-elasped: 121817.06s
-> berries picked: 145 of 800 | patches-visited: [4, 6] | positive-in-buffer: 16754 | amount-filled: 100.00%
	| epsilon: 0.28951407876720636
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1766, 2010, 1675, 2335, 1240, 3176, 1791, 2761]
	| approx positives in sample 512: 211
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 22, 20, 22, 12, 48, 28, 41]
episode: 679 -> reward: -124.99999999998936, steps:93120, time-elasped: 122011.83s
-> berries picked: 168 of 800 | patches-visited: [0, 1, 5, 7] | positive-in-buffer: 16531 | amount-filled: 100.00%
	| epsilon: 0.2892811950154829
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1697, 1945, 1672, 2343, 1226, 3174, 1772, 2702]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 25, 27, 24, 21, 49, 21, 39]
episode: 680 -> reward: -124.9999999999913, steps:86016, time-elasped: 122192.67s
-> berries picked: 129 of 800 | patches-visited: [5, 6, 8] | positive-in-buffer: 16602 | amount-filled: 100.00%
	| epsilon: 0.2890484985943447
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1695, 1969, 1680, 2353, 1230, 3193, 1776, 2706]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 29, 23, 37, 15, 39, 18, 35]
episode: 681 -> reward: -124.99999999998508, steps:81792, time-elasped: 122377.67s
-> berries picked: 124 of 800 | patches-visited: [2, 7, 9] | positive-in-buffer: 16672 | amount-filled: 100.00%
	| epsilon: 0.28881598935310393
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1701, 1970, 1697, 2371, 1229, 3210, 1776, 2718]
	| approx positives in sample 512: 226
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 20, 22, 35, 18, 38, 38, 34]
episode: 682 -> reward: -124.9999999999922, steps:60576, time-elasped: 122546.24s
-> berries picked: 44 of 800 | patches-visited: [0] | positive-in-buffer: 16696 | amount-filled: 100.00%
	| epsilon: 0.28858366714119393
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1703, 1980, 1696, 2375, 1231, 3216, 1779, 2716]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 30, 23, 26, 15, 35, 35, 29]
episode: 683 -> reward: -124.99999999999177, steps:64512, time-elasped: 122717.99s
-> berries picked: 68 of 800 | patches-visited: [8] | positive-in-buffer: 16747 | amount-filled: 100.00%
	| epsilon: 0.2883515318081693
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1709, 1986, 1702, 2382, 1235, 3227, 1780, 2726]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 22, 30, 28, 17, 58, 15, 32]
episode: 684 -> reward: -124.9999999999909, steps:65760, time-elasped: 122885.70s
-> berries picked: 68 of 800 | patches-visited: [1] | positive-in-buffer: 16765 | amount-filled: 100.00%
	| epsilon: 0.28811958320370545
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1707, 1985, 1704, 2381, 1237, 3241, 1783, 2727]
	| approx positives in sample 512: 230
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 33, 33, 35, 10, 36, 33, 27]
episode: 685 -> reward: -124.99999999999166, steps:66720, time-elasped: 123059.94s
-> berries picked: 79 of 800 | patches-visited: [3, 7] | positive-in-buffer: 16798 | amount-filled: 100.00%
	| epsilon: 0.2878878211775988
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1703, 1991, 1705, 2388, 1239, 3253, 1787, 2732]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 24, 18, 37, 20, 38, 29, 33]
episode: 686 -> reward: -124.99999999999216, steps:66240, time-elasped: 123225.01s
-> berries picked: 76 of 800 | patches-visited: [5] | positive-in-buffer: 16826 | amount-filled: 100.00%
	| epsilon: 0.2876562455797667
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1711, 1990, 1713, 2390, 1239, 3258, 1788, 2737]
	| approx positives in sample 512: 247
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 26, 26, 44, 16, 52, 27, 39]
episode: 687 -> reward: -124.99999999998758, steps:92064, time-elasped: 123421.96s
-> berries picked: 160 of 800 | patches-visited: [0, 2, 3] | positive-in-buffer: 16625 | amount-filled: 100.00%
	| epsilon: 0.28742485626024705
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1671, 1961, 1710, 2378, 1225, 3234, 1760, 2686]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 22, 23, 30, 21, 61, 17, 21]
episode: 688 -> reward: -124.99999999999095, steps:69120, time-elasped: 123626.92s
-> berries picked: 79 of 800 | patches-visited: [6, 7] | positive-in-buffer: 16677 | amount-filled: 100.00%
	| epsilon: 0.2871936530691985
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1675, 1975, 1718, 2375, 1223, 3253, 1766, 2692]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 22, 15, 37, 20, 45, 26, 38]
episode: 689 -> reward: -124.99999999999203, steps:52608, time-elasped: 123795.94s
-> berries picked: 15 of 800 | patches-visited: [0] | positive-in-buffer: 16677 | amount-filled: 100.00%
	| epsilon: 0.2869626358569002
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1675, 1972, 1719, 2376, 1225, 3257, 1766, 2687]
	| approx positives in sample 512: 242
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 31, 24, 35, 21, 38, 28, 44]
episode: 690 -> reward: -124.99999999999207, steps:65952, time-elasped: 123994.15s
-> berries picked: 74 of 800 | patches-visited: [6] | positive-in-buffer: 16739 | amount-filled: 100.00%
	| epsilon: 0.28673180447375163
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1680, 1983, 1720, 2395, 1224, 3278, 1766, 2693]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 27, 29, 30, 17, 41, 24, 48]
episode: 691 -> reward: -124.99999999998492, steps:93600, time-elasped: 124224.98s
-> berries picked: 183 of 800 | patches-visited: [2, 4, 6] | positive-in-buffer: 16603 | amount-filled: 100.00%
	| epsilon: 0.2865011587702728
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1642, 1944, 1726, 2387, 1224, 3268, 1767, 2645]
	| approx positives in sample 512: 239
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 32, 26, 38, 20, 47, 29, 34]
episode: 692 -> reward: -124.99999999999505, steps:81024, time-elasped: 124420.93s
-> berries picked: 129 of 800 | patches-visited: [1, 9] | positive-in-buffer: 16677 | amount-filled: 100.00%
	| epsilon: 0.2862706985971039
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1652, 1953, 1724, 2414, 1229, 3279, 1771, 2655]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 17, 27, 19, 15, 45, 25, 36]
episode: 693 -> reward: -124.99999999999214, steps:67488, time-elasped: 124604.40s
-> berries picked: 76 of 800 | patches-visited: [7] | positive-in-buffer: 16723 | amount-filled: 100.00%
	| epsilon: 0.2860404238050051
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1657, 1962, 1732, 2420, 1229, 3290, 1770, 2663]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 22, 24, 24, 10, 48, 32, 45]
episode: 694 -> reward: -124.9999999999927, steps:78432, time-elasped: 124817.90s
-> berries picked: 116 of 800 | patches-visited: [1, 8] | positive-in-buffer: 16761 | amount-filled: 100.00%
	| epsilon: 0.28581033424485686
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1660, 1963, 1736, 2419, 1237, 3298, 1775, 2673]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 29, 21, 26, 13, 37, 21, 44]
episode: 695 -> reward: -124.99999999998377, steps:83616, time-elasped: 125013.02s
-> berries picked: 145 of 800 | patches-visited: [2, 4] | positive-in-buffer: 16751 | amount-filled: 100.00%
	| epsilon: 0.2855804297676594
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1653, 1958, 1739, 2423, 1240, 3295, 1779, 2664]
	| approx positives in sample 512: 226
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 14, 24, 30, 29, 37, 26, 44]
episode: 696 -> reward: -124.99999999999204, steps:56064, time-elasped: 125186.87s
-> berries picked: 28 of 800 | patches-visited: [4] | positive-in-buffer: 16750 | amount-filled: 100.00%
	| epsilon: 0.2853507102245329
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1656, 1956, 1739, 2427, 1239, 3295, 1775, 2663]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 17, 25, 38, 14, 39, 37, 42]
episode: 697 -> reward: -124.99999999999193, steps:68352, time-elasped: 125375.02s
-> berries picked: 78 of 800 | patches-visited: [6] | positive-in-buffer: 16784 | amount-filled: 100.00%
	| epsilon: 0.2851211754667173
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1652, 1955, 1742, 2435, 1241, 3310, 1781, 2668]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 32, 15, 27, 16, 44, 31, 36]
episode: 698 -> reward: -124.99999999998452, steps:103008, time-elasped: 125616.38s
-> berries picked: 215 of 800 | patches-visited: [2, 8, 9] | positive-in-buffer: 16556 | amount-filled: 100.00%
	| epsilon: 0.2848918253455721
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1597, 1910, 1726, 2415, 1234, 3291, 1764, 2619]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 21, 21, 40, 20, 45, 27, 28]
episode: 699 -> reward: -124.99999999999189, steps:67584, time-elasped: 125815.49s
-> berries picked: 78 of 800 | patches-visited: [6] | positive-in-buffer: 16601 | amount-filled: 100.00%
	| epsilon: 0.28466265971257654
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1602, 1920, 1726, 2425, 1238, 3294, 1771, 2625]
	| approx positives in sample 512: 223
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 30, 14, 35, 20, 52, 22, 31]
episode: 700 -> reward: -124.99999999999267, steps:71520, time-elasped: 125995.11s
-> berries picked: 85 of 800 | patches-visited: [5, 7] | positive-in-buffer: 16662 | amount-filled: 100.00%
	| epsilon: 0.2844336784193291
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1608, 1925, 1736, 2436, 1239, 3310, 1776, 2632]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 24, 25, 32, 21, 46, 19, 33]
episode: 701 -> reward: -124.99999999999152, steps:62976, time-elasped: 126173.61s
-> berries picked: 66 of 800 | patches-visited: [6] | positive-in-buffer: 16707 | amount-filled: 100.00%
	| epsilon: 0.2842048813175479
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1612, 1931, 1743, 2444, 1240, 3321, 1776, 2640]
	| approx positives in sample 512: 235
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 27, 27, 38, 16, 48, 19, 39]
episode: 702 -> reward: -124.99999999999208, steps:60000, time-elasped: 126350.37s
-> berries picked: 44 of 800 | patches-visited: [9] | positive-in-buffer: 16710 | amount-filled: 100.00%
	| epsilon: 0.28397626825907013
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1608, 1931, 1742, 2449, 1244, 3318, 1786, 2632]
	| approx positives in sample 512: 206
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 22, 25, 36, 20, 41, 16, 29]
episode: 703 -> reward: -124.99999999999164, steps:70176, time-elasped: 126531.38s
-> berries picked: 84 of 800 | patches-visited: [3, 4] | positive-in-buffer: 16770 | amount-filled: 100.00%
	| epsilon: 0.2837478390958522
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1609, 1944, 1745, 2459, 1249, 3335, 1790, 2639]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 27, 20, 35, 14, 38, 28, 38]
episode: 704 -> reward: -124.99999999999122, steps:86496, time-elasped: 126734.73s
-> berries picked: 143 of 800 | patches-visited: [3, 5] | positive-in-buffer: 16752 | amount-filled: 100.00%
	| epsilon: 0.2835195936799697
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1603, 1935, 1750, 2460, 1255, 3336, 1780, 2633]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 26, 19, 39, 23, 48, 20, 41]
episode: 705 -> reward: -124.99999999999206, steps:66720, time-elasped: 126914.43s
-> berries picked: 67 of 800 | patches-visited: [9] | positive-in-buffer: 16793 | amount-filled: 100.00%
	| epsilon: 0.2832915318636171
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1604, 1943, 1755, 2467, 1254, 3343, 1784, 2643]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 26, 23, 24, 16, 44, 21, 52]
episode: 706 -> reward: -124.99999999999201, steps:57696, time-elasped: 127091.53s
-> berries picked: 33 of 800 | patches-visited: [4] | positive-in-buffer: 16812 | amount-filled: 100.00%
	| epsilon: 0.2830636534991078
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1604, 1944, 1757, 2469, 1254, 3352, 1788, 2644]
	| approx positives in sample 512: 243
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 29, 17, 34, 20, 42, 19, 54]
episode: 707 -> reward: -124.99999999998886, steps:85728, time-elasped: 127305.90s
-> berries picked: 139 of 800 | patches-visited: [6, 7, 8] | positive-in-buffer: 16767 | amount-filled: 100.00%
	| epsilon: 0.28283595843887405
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1595, 1927, 1757, 2472, 1260, 3343, 1784, 2629]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 24, 19, 44, 18, 42, 28, 33]
episode: 708 -> reward: -124.99999999998252, steps:83904, time-elasped: 127522.36s
-> berries picked: 138 of 800 | patches-visited: [3, 5] | positive-in-buffer: 16798 | amount-filled: 100.00%
	| epsilon: 0.2826084465354667
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1590, 1924, 1769, 2474, 1266, 3353, 1779, 2643]
	| approx positives in sample 512: 244
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 21, 17, 50, 20, 47, 27, 43]
episode: 709 -> reward: -124.99999999999467, steps:83136, time-elasped: 127735.20s
-> berries picked: 126 of 800 | patches-visited: [4, 5] | positive-in-buffer: 16781 | amount-filled: 100.00%
	| epsilon: 0.2823811176415553
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1578, 1929, 1774, 2470, 1267, 3348, 1784, 2631]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 29, 26, 35, 16, 48, 15, 39]
episode: 710 -> reward: -124.99999999999395, steps:63936, time-elasped: 127939.65s
-> berries picked: 62 of 800 | patches-visited: [4] | positive-in-buffer: 16821 | amount-filled: 100.00%
	| epsilon: 0.282153971609928
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1582, 1936, 1778, 2475, 1271, 3359, 1782, 2638]
	| approx positives in sample 512: 241
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 36, 22, 40, 16, 48, 26, 34]
episode: 711 -> reward: -124.99999999999412, steps:87360, time-elasped: 128161.67s
-> berries picked: 143 of 800 | patches-visited: [1, 2, 8] | positive-in-buffer: 16784 | amount-filled: 100.00%
	| epsilon: 0.28192700829349104
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1569, 1918, 1782, 2468, 1271, 3359, 1787, 2630]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 16, 20, 35, 14, 36, 40, 31]
episode: 712 -> reward: -124.99999999999265, steps:70656, time-elasped: 128369.30s
-> berries picked: 83 of 800 | patches-visited: [1, 2, 4, 7] | positive-in-buffer: 16851 | amount-filled: 100.00%
	| epsilon: 0.28170022754526924
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1573, 1927, 1784, 2484, 1276, 3372, 1802, 2633]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 15, 28, 41, 18, 49, 29, 29]
episode: 713 -> reward: -124.99999999999206, steps:74880, time-elasped: 128572.99s
-> berries picked: 103 of 800 | patches-visited: [2, 7] | positive-in-buffer: 16807 | amount-filled: 100.00%
	| epsilon: 0.2814736292184057
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1550, 1913, 1790, 2492, 1272, 3374, 1794, 2622]
	| approx positives in sample 512: 234
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 20, 20, 38, 17, 54, 28, 37]
episode: 714 -> reward: -124.99999999999461, steps:80352, time-elasped: 128774.25s
-> berries picked: 122 of 800 | patches-visited: [3, 9] | positive-in-buffer: 16777 | amount-filled: 100.00%
	| epsilon: 0.28124721316616147
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1542, 1900, 1792, 2487, 1268, 3379, 1792, 2617]
	| approx positives in sample 512: 235
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 20, 20, 39, 20, 38, 34, 47]
episode: 715 -> reward: -124.9999999999922, steps:66624, time-elasped: 128959.28s
-> berries picked: 79 of 800 | patches-visited: [8] | positive-in-buffer: 16824 | amount-filled: 100.00%
	| epsilon: 0.2810209792419157
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1547, 1908, 1799, 2499, 1273, 3378, 1797, 2623]
	| approx positives in sample 512: 235
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 29, 27, 35, 15, 59, 22, 31]
episode: 716 -> reward: -124.99999999999186, steps:59904, time-elasped: 129137.51s
-> berries picked: 39 of 800 | patches-visited: [4] | positive-in-buffer: 16833 | amount-filled: 100.00%
	| epsilon: 0.28079492729916555
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1548, 1906, 1800, 2504, 1271, 3382, 1798, 2624]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 17, 25, 49, 17, 44, 30, 34]
episode: 717 -> reward: -124.99999999999044, steps:75840, time-elasped: 129332.35s
-> berries picked: 97 of 800 | patches-visited: [1, 6] | positive-in-buffer: 16839 | amount-filled: 100.00%
	| epsilon: 0.28056905719152586
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1552, 1902, 1804, 2499, 1272, 3383, 1808, 2619]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 17, 30, 37, 8, 42, 27, 42]
episode: 718 -> reward: -124.9999999999949, steps:78720, time-elasped: 129533.37s
-> berries picked: 118 of 800 | patches-visited: [4, 9] | positive-in-buffer: 16880 | amount-filled: 100.00%
	| epsilon: 0.2803433687727294
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1547, 1913, 1811, 2510, 1276, 3395, 1805, 2623]
	| approx positives in sample 512: 210
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 19, 22, 29, 11, 48, 25, 39]
episode: 719 -> reward: -124.99999999999145, steps:63840, time-elasped: 129700.28s
-> berries picked: 66 of 800 | patches-visited: [1] | positive-in-buffer: 16918 | amount-filled: 100.00%
	| epsilon: 0.2801178618966266
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1549, 1917, 1814, 2521, 1281, 3402, 1808, 2626]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 28, 26, 29, 15, 37, 29, 35]
episode: 720 -> reward: -124.9999999999905, steps:105888, time-elasped: 129943.61s
-> berries picked: 212 of 800 | patches-visited: [1, 3, 5, 6, 7, 8] | positive-in-buffer: 16694 | amount-filled: 100.00%
	| epsilon: 0.27989253641718526
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1504, 1896, 1802, 2491, 1255, 3386, 1793, 2567]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 24, 22, 24, 23, 51, 20, 33]
episode: 721 -> reward: -124.99999999999213, steps:66624, time-elasped: 130129.57s
-> berries picked: 64 of 800 | patches-visited: [4] | positive-in-buffer: 16731 | amount-filled: 100.00%
	| epsilon: 0.2796673921884908
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1506, 1897, 1807, 2501, 1259, 3389, 1798, 2574]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 33, 25, 27, 16, 38, 32, 33]
episode: 722 -> reward: -124.9999999999919, steps:66240, time-elasped: 130326.79s
-> berries picked: 68 of 800 | patches-visited: [5] | positive-in-buffer: 16777 | amount-filled: 100.00%
	| epsilon: 0.279442429064746
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1512, 1902, 1810, 2512, 1262, 3391, 1810, 2578]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 19, 29, 38, 15, 39, 27, 31]
episode: 723 -> reward: -124.99999999999204, steps:62016, time-elasped: 130508.83s
-> berries picked: 53 of 800 | patches-visited: [0] | positive-in-buffer: 16819 | amount-filled: 100.00%
	| epsilon: 0.2792176469002709
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1513, 1911, 1813, 2521, 1263, 3396, 1814, 2588]
	| approx positives in sample 512: 234
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 21, 34, 33, 18, 42, 22, 40]
episode: 724 -> reward: -124.99999999999267, steps:64128, time-elasped: 130699.81s
-> berries picked: 66 of 800 | patches-visited: [1] | positive-in-buffer: 16863 | amount-filled: 100.00%
	| epsilon: 0.27899304554950266
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1515, 1918, 1819, 2526, 1266, 3404, 1817, 2598]
	| approx positives in sample 512: 237
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 25, 23, 37, 24, 49, 31, 32]
episode: 725 -> reward: -124.99999999999261, steps:83232, time-elasped: 130912.53s
-> berries picked: 141 of 800 | patches-visited: [0, 9] | positive-in-buffer: 16948 | amount-filled: 100.00%
	| epsilon: 0.27876862486699566
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1518, 1932, 1829, 2537, 1272, 3425, 1827, 2608]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 20, 29, 24, 10, 54, 32, 28]
episode: 726 -> reward: -124.99999999998576, steps:69024, time-elasped: 131109.58s
-> berries picked: 80 of 800 | patches-visited: [1, 3] | positive-in-buffer: 16993 | amount-filled: 100.00%
	| epsilon: 0.27854438470742116
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1525, 1942, 1828, 2550, 1273, 3432, 1832, 2611]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 22, 23, 32, 17, 40, 25, 43]
episode: 727 -> reward: -124.99999999999257, steps:64800, time-elasped: 131301.09s
-> berries picked: 70 of 800 | patches-visited: [0] | positive-in-buffer: 17002 | amount-filled: 100.00%
	| epsilon: 0.27832032492556746
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1523, 1942, 1835, 2547, 1277, 3428, 1840, 2610]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 13, 18, 34, 13, 55, 32, 29]
episode: 728 -> reward: -124.9999999999931, steps:65952, time-elasped: 131509.20s
-> berries picked: 71 of 800 | patches-visited: [4] | positive-in-buffer: 17030 | amount-filled: 100.00%
	| epsilon: 0.2780964453763395
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1532, 1955, 1838, 2550, 1280, 3425, 1842, 2608]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 22, 18, 39, 15, 43, 25, 35]
episode: 729 -> reward: -124.99999999998433, steps:105984, time-elasped: 131765.42s
-> berries picked: 220 of 800 | patches-visited: [1, 3, 4, 8] | positive-in-buffer: 16733 | amount-filled: 100.00%
	| epsilon: 0.27787274591475897
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1481, 1901, 1795, 2516, 1254, 3383, 1825, 2578]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 26, 26, 29, 14, 42, 21, 31]
episode: 730 -> reward: -124.99999999999014, steps:80448, time-elasped: 131984.17s
-> berries picked: 124 of 800 | patches-visited: [7, 8] | positive-in-buffer: 16824 | amount-filled: 100.00%
	| epsilon: 0.2776492263959643
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1482, 1918, 1805, 2531, 1257, 3408, 1835, 2588]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 20, 19, 35, 22, 39, 34, 33]
episode: 731 -> reward: -124.9999999999867, steps:79008, time-elasped: 132192.34s
-> berries picked: 117 of 800 | patches-visited: [1, 5] | positive-in-buffer: 16899 | amount-filled: 100.00%
	| epsilon: 0.27742588667521034
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1487, 1933, 1812, 2544, 1260, 3415, 1844, 2604]
	| approx positives in sample 512: 236
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 24, 23, 39, 22, 48, 37, 24]
episode: 732 -> reward: -124.99999999999228, steps:67584, time-elasped: 132384.83s
-> berries picked: 77 of 800 | patches-visited: [0, 7] | positive-in-buffer: 16943 | amount-filled: 100.00%
	| epsilon: 0.2772027266078684
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1490, 1943, 1815, 2547, 1262, 3427, 1847, 2612]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 26, 27, 35, 15, 45, 23, 35]
episode: 733 -> reward: -124.99999999998565, steps:81024, time-elasped: 132606.29s
-> berries picked: 129 of 800 | patches-visited: [1, 4] | positive-in-buffer: 17004 | amount-filled: 100.00%
	| epsilon: 0.2769797460494261
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1488, 1948, 1818, 2563, 1266, 3446, 1854, 2621]
	| approx positives in sample 512: 238
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 25, 23, 36, 17, 49, 22, 41]
episode: 734 -> reward: -124.9999999999908, steps:92544, time-elasped: 132845.69s
-> berries picked: 184 of 800 | patches-visited: [0, 3, 6] | positive-in-buffer: 16976 | amount-filled: 100.00%
	| epsilon: 0.2767569448554874
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1483, 1937, 1822, 2565, 1268, 3430, 1857, 2614]
	| approx positives in sample 512: 245
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 23, 20, 34, 17, 64, 32, 35]
episode: 735 -> reward: -124.99999999998836, steps:72960, time-elasped: 133051.98s
-> berries picked: 98 of 800 | patches-visited: [0, 7] | positive-in-buffer: 17035 | amount-filled: 100.00%
	| epsilon: 0.2765343228817723
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1486, 1947, 1831, 2574, 1272, 3446, 1864, 2615]
	| approx positives in sample 512: 239
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 24, 29, 31, 19, 54, 31, 30]
episode: 736 -> reward: -124.99999999999487, steps:75360, time-elasped: 133255.49s
-> berries picked: 103 of 800 | patches-visited: [4, 7] | positive-in-buffer: 17067 | amount-filled: 100.00%
	| epsilon: 0.2763118799841169
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1488, 1958, 1836, 2572, 1269, 3459, 1866, 2619]
	| approx positives in sample 512: 235
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 35, 20, 32, 13, 50, 33, 36]
episode: 737 -> reward: -124.99999999998796, steps:83136, time-elasped: 133459.04s
-> berries picked: 146 of 800 | patches-visited: [6, 9] | positive-in-buffer: 17008 | amount-filled: 100.00%
	| epsilon: 0.27608961601847326
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1467, 1943, 1838, 2580, 1272, 3443, 1861, 2604]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 21, 26, 31, 16, 50, 24, 29]
episode: 738 -> reward: -124.9999999999929, steps:71904, time-elasped: 133662.40s
-> berries picked: 94 of 800 | patches-visited: [3, 7] | positive-in-buffer: 17064 | amount-filled: 100.00%
	| epsilon: 0.2758675308409093
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1468, 1959, 1842, 2588, 1275, 3458, 1866, 2608]
	| approx positives in sample 512: 241
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 18, 32, 31, 13, 52, 34, 35]
episode: 739 -> reward: -124.99999999998761, steps:58752, time-elasped: 133855.55s
-> berries picked: 40 of 800 | patches-visited: [7] | positive-in-buffer: 17073 | amount-filled: 100.00%
	| epsilon: 0.27564562430760886
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1470, 1958, 1843, 2590, 1274, 3460, 1868, 2610]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 25, 16, 45, 24, 42, 26, 22]
episode: 740 -> reward: -124.99999999998631, steps:64704, time-elasped: 134072.61s
-> berries picked: 54 of 800 | patches-visited: [4, 5] | positive-in-buffer: 17099 | amount-filled: 100.00%
	| epsilon: 0.2754238962748712
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1472, 1969, 1848, 2592, 1277, 3458, 1873, 2610]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 11, 28, 36, 13, 50, 23, 46]
episode: 741 -> reward: -124.99999999999193, steps:53472, time-elasped: 134253.69s
-> berries picked: 20 of 800 | patches-visited: [8] | positive-in-buffer: 17115 | amount-filled: 100.00%
	| epsilon: 0.27520234659911136
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1472, 1971, 1849, 2595, 1278, 3463, 1874, 2613]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 25, 30, 23, 14, 53, 27, 33]
episode: 742 -> reward: -124.99999999999126, steps:63264, time-elasped: 134436.42s
-> berries picked: 51 of 800 | patches-visited: [3] | positive-in-buffer: 17112 | amount-filled: 100.00%
	| epsilon: 0.2749809751368598
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1466, 1972, 1851, 2601, 1275, 3459, 1877, 2611]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 22, 16, 50, 16, 41, 29, 26]
episode: 743 -> reward: -124.99999999998727, steps:73824, time-elasped: 134637.39s
-> berries picked: 108 of 800 | patches-visited: [3, 5] | positive-in-buffer: 17112 | amount-filled: 100.00%
	| epsilon: 0.27475978174476245
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1462, 1964, 1846, 2604, 1275, 3464, 1887, 2610]
	| approx positives in sample 512: 235
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 18, 20, 37, 10, 50, 43, 33]
episode: 744 -> reward: -124.99999999999207, steps:67872, time-elasped: 134818.65s
-> berries picked: 77 of 800 | patches-visited: [7] | positive-in-buffer: 17152 | amount-filled: 100.00%
	| epsilon: 0.2745387662795806
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1461, 1972, 1860, 2611, 1275, 3472, 1878, 2623]
	| approx positives in sample 512: 208
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 24, 23, 31, 13, 45, 29, 34]
episode: 745 -> reward: -124.99999999999119, steps:86592, time-elasped: 135052.56s
-> berries picked: 144 of 800 | patches-visited: [4, 7, 9] | positive-in-buffer: 16940 | amount-filled: 100.00%
	| epsilon: 0.2743179285981906
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1437, 1925, 1848, 2572, 1259, 3469, 1870, 2560]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 27, 15, 42, 14, 52, 29, 32]
episode: 746 -> reward: -124.99999999999194, steps:65280, time-elasped: 135247.01s
-> berries picked: 63 of 800 | patches-visited: [7] | positive-in-buffer: 16985 | amount-filled: 100.00%
	| epsilon: 0.274097268557584
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1439, 1933, 1851, 2575, 1267, 3482, 1874, 2564]
	| approx positives in sample 512: 226
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 20, 23, 33, 22, 47, 28, 38]
episode: 747 -> reward: -124.99999999998681, steps:77856, time-elasped: 135449.69s
-> berries picked: 117 of 800 | patches-visited: [7, 8] | positive-in-buffer: 17060 | amount-filled: 100.00%
	| epsilon: 0.2738767860148674
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1447, 1950, 1856, 2580, 1269, 3498, 1888, 2572]
	| approx positives in sample 512: 223
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 15, 23, 25, 20, 64, 25, 30]
episode: 748 -> reward: -124.99999999998552, steps:85344, time-elasped: 135664.42s
-> berries picked: 150 of 800 | patches-visited: [6, 7] | positive-in-buffer: 16995 | amount-filled: 100.00%
	| epsilon: 0.2736564808272624
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1415, 1941, 1845, 2590, 1264, 3485, 1888, 2567]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 28, 32, 28, 10, 41, 35, 31]
episode: 749 -> reward: -124.99999999998596, steps:82848, time-elasped: 135880.35s
-> berries picked: 156 of 800 | patches-visited: [1, 6] | positive-in-buffer: 17041 | amount-filled: 100.00%
	| epsilon: 0.2734363528521053
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1413, 1954, 1842, 2610, 1267, 3480, 1890, 2585]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 19, 30, 31, 24, 42, 27, 25]
episode: 750 -> reward: -124.9999999999937, steps:71904, time-elasped: 136089.73s
-> berries picked: 90 of 800 | patches-visited: [2, 5] | positive-in-buffer: 17063 | amount-filled: 100.00%
	| epsilon: 0.2732164019468473
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1420, 1948, 1849, 2621, 1267, 3487, 1892, 2579]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 25, 18, 45, 20, 46, 22, 41]
episode: 751 -> reward: -124.9999999999957, steps:84192, time-elasped: 136300.52s
-> berries picked: 143 of 800 | patches-visited: [0, 4] | positive-in-buffer: 17037 | amount-filled: 100.00%
	| epsilon: 0.2729966279690543
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1410, 1936, 1845, 2610, 1272, 3480, 1903, 2581]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 20, 29, 33, 11, 50, 33, 38]
episode: 752 -> reward: -124.9999999999921, steps:67008, time-elasped: 136479.51s
-> berries picked: 78 of 800 | patches-visited: [7] | positive-in-buffer: 17082 | amount-filled: 100.00%
	| epsilon: 0.27277703077640647
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1413, 1937, 1851, 2623, 1275, 3497, 1898, 2588]
	| approx positives in sample 512: 245
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 25, 35, 36, 15, 52, 32, 39]
episode: 753 -> reward: -124.99999999998809, steps:88512, time-elasped: 136699.05s
-> berries picked: 152 of 800 | patches-visited: [0, 5, 8] | positive-in-buffer: 16913 | amount-filled: 100.00%
	| epsilon: 0.2725576102266989
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1373, 1906, 1827, 2589, 1260, 3505, 1892, 2561]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 16, 23, 35, 20, 59, 29, 29]
episode: 754 -> reward: -124.99999999999513, steps:84672, time-elasped: 136906.21s
-> berries picked: 152 of 800 | patches-visited: [0, 5] | positive-in-buffer: 17016 | amount-filled: 100.00%
	| epsilon: 0.2723383661778407
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1375, 1925, 1834, 2608, 1269, 3525, 1902, 2578]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 30, 22, 33, 14, 49, 29, 35]
episode: 755 -> reward: -124.99999999998478, steps:83424, time-elasped: 137131.14s
-> berries picked: 150 of 800 | patches-visited: [3, 5] | positive-in-buffer: 17044 | amount-filled: 100.00%
	| epsilon: 0.27211929848785543
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1374, 1929, 1838, 2624, 1280, 3525, 1909, 2565]
	| approx positives in sample 512: 234
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 19, 26, 37, 23, 47, 25, 42]
episode: 756 -> reward: -124.99999999999217, steps:61344, time-elasped: 137338.71s
-> berries picked: 50 of 800 | patches-visited: [2] | positive-in-buffer: 17060 | amount-filled: 100.00%
	| epsilon: 0.27190040701488094
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1374, 1936, 1840, 2628, 1279, 3524, 1909, 2570]
	| approx positives in sample 512: 230
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 26, 16, 44, 15, 53, 27, 37]
episode: 757 -> reward: -124.99999999999176, steps:61824, time-elasped: 137537.83s
-> berries picked: 54 of 800 | patches-visited: [9] | positive-in-buffer: 17098 | amount-filled: 100.00%
	| epsilon: 0.2716816916171691
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1378, 1948, 1844, 2628, 1284, 3533, 1915, 2568]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 27, 25, 32, 13, 54, 31, 32]
episode: 758 -> reward: -124.99999999999187, steps:60960, time-elasped: 137718.31s
-> berries picked: 51 of 800 | patches-visited: [9] | positive-in-buffer: 17117 | amount-filled: 100.00%
	| epsilon: 0.2714631521530857
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1378, 1954, 1843, 2632, 1282, 3538, 1913, 2577]
	| approx positives in sample 512: 253
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 25, 32, 39, 12, 58, 30, 36]
episode: 759 -> reward: -124.99999999998428, steps:98496, time-elasped: 137955.71s
-> berries picked: 199 of 800 | patches-visited: [3, 6, 7, 9] | positive-in-buffer: 16827 | amount-filled: 100.00%
	| epsilon: 0.2712447884811106
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1309, 1916, 1831, 2590, 1253, 3500, 1905, 2523]
	| approx positives in sample 512: 203
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 26, 21, 31, 17, 43, 21, 29]
episode: 760 -> reward: -124.99999999998866, steps:98496, time-elasped: 138166.92s
-> berries picked: 186 of 800 | patches-visited: [2, 3, 6, 7] | positive-in-buffer: 16825 | amount-filled: 100.00%
	| epsilon: 0.27102660045983756
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1307, 1901, 1841, 2607, 1249, 3503, 1909, 2508]
	| approx positives in sample 512: 207
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 23, 20, 23, 24, 43, 29, 27]
episode: 761 -> reward: -124.99999999998649, steps:79488, time-elasped: 138373.66s
-> berries picked: 116 of 800 | patches-visited: [1, 2] | positive-in-buffer: 16908 | amount-filled: 100.00%
	| epsilon: 0.27080858794797386
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1312, 1917, 1841, 2620, 1256, 3526, 1915, 2521]
	| approx positives in sample 512: 234
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 25, 28, 43, 16, 42, 29, 33]
episode: 762 -> reward: -124.9999999999842, steps:89184, time-elasped: 138575.91s
-> berries picked: 160 of 800 | patches-visited: [2, 4, 7] | positive-in-buffer: 16968 | amount-filled: 100.00%
	| epsilon: 0.2705907508043406
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1323, 1931, 1847, 2641, 1257, 3524, 1921, 2524]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 29, 21, 29, 22, 48, 30, 31]
episode: 763 -> reward: -124.99999999999162, steps:67200, time-elasped: 138742.15s
-> berries picked: 72 of 800 | patches-visited: [7] | positive-in-buffer: 17009 | amount-filled: 100.00%
	| epsilon: 0.2703730888878725
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1319, 1939, 1853, 2644, 1262, 3544, 1921, 2527]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 33, 15, 31, 13, 48, 29, 41]
episode: 764 -> reward: -124.99999999998445, steps:80160, time-elasped: 138939.92s
-> berries picked: 128 of 800 | patches-visited: [6, 7] | positive-in-buffer: 17056 | amount-filled: 100.00%
	| epsilon: 0.2701556020576175
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1324, 1936, 1850, 2643, 1267, 3569, 1925, 2542]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 27, 18, 42, 13, 48, 23, 36]
episode: 765 -> reward: -124.9999999999881, steps:86976, time-elasped: 139182.00s
-> berries picked: 155 of 800 | patches-visited: [1, 3, 5] | positive-in-buffer: 16993 | amount-filled: 100.00%
	| epsilon: 0.2699382901727372
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1313, 1937, 1852, 2634, 1264, 3552, 1930, 2511]
	| approx positives in sample 512: 205
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 17, 20, 38, 17, 55, 16, 28]
episode: 766 -> reward: -124.99999999999147, steps:69504, time-elasped: 139396.47s
-> berries picked: 81 of 800 | patches-visited: [0, 9] | positive-in-buffer: 17040 | amount-filled: 100.00%
	| epsilon: 0.2697211530925063
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1316, 1943, 1856, 2645, 1267, 3563, 1936, 2514]
	| approx positives in sample 512: 210
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 30, 24, 22, 19, 41, 30, 36]
episode: 767 -> reward: -124.99999999998312, steps:84288, time-elasped: 139604.56s
-> berries picked: 140 of 800 | patches-visited: [4, 8] | positive-in-buffer: 16999 | amount-filled: 100.00%
	| epsilon: 0.26950419067631287
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1295, 1931, 1859, 2650, 1271, 3554, 1940, 2499]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 16, 29, 53, 14, 43, 31, 29]
episode: 768 -> reward: -124.99999999998973, steps:61152, time-elasped: 139795.64s
-> berries picked: 51 of 800 | patches-visited: [5] | positive-in-buffer: 17029 | amount-filled: 100.00%
	| epsilon: 0.26928740278365787
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1297, 1936, 1861, 2659, 1273, 3558, 1941, 2504]
	| approx positives in sample 512: 238
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 19, 33, 37, 13, 59, 29, 33]
episode: 769 -> reward: -124.99999999999221, steps:60576, time-elasped: 139975.93s
-> berries picked: 45 of 800 | patches-visited: [0] | positive-in-buffer: 17055 | amount-filled: 100.00%
	| epsilon: 0.26907078927415545
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1299, 1945, 1862, 2665, 1277, 3555, 1945, 2507]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 9, 30, 41, 25, 50, 25, 33]
episode: 770 -> reward: -124.9999999999856, steps:100608, time-elasped: 140201.59s
-> berries picked: 206 of 800 | patches-visited: [0, 6, 7] | positive-in-buffer: 16837 | amount-filled: 100.00%
	| epsilon: 0.2688543500075326
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1262, 1932, 1857, 2642, 1264, 3537, 1914, 2429]
	| approx positives in sample 512: 240
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 29, 30, 36, 13, 49, 30, 39]
episode: 771 -> reward: -124.99999999998607, steps:76800, time-elasped: 140404.30s
-> berries picked: 105 of 800 | patches-visited: [7, 9] | positive-in-buffer: 16893 | amount-filled: 100.00%
	| epsilon: 0.2686380848436292
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1265, 1944, 1857, 2653, 1271, 3546, 1918, 2439]
	| approx positives in sample 512: 241
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 27, 27, 42, 29, 60, 25, 21]
episode: 772 -> reward: -124.9999999999927, steps:66624, time-elasped: 140590.39s
-> berries picked: 71 of 800 | patches-visited: [0] | positive-in-buffer: 16938 | amount-filled: 100.00%
	| epsilon: 0.26842199364239794
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1270, 1944, 1858, 2660, 1276, 3564, 1928, 2438]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 21, 27, 35, 19, 45, 24, 31]
episode: 773 -> reward: -124.99999999998448, steps:92736, time-elasped: 140807.06s
-> berries picked: 174 of 800 | patches-visited: [2, 7, 8] | positive-in-buffer: 16942 | amount-filled: 100.00%
	| epsilon: 0.26820607626390386
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1256, 1942, 1864, 2677, 1272, 3560, 1933, 2438]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 23, 24, 36, 11, 51, 28, 40]
episode: 774 -> reward: -124.99999999999243, steps:65664, time-elasped: 141002.66s
-> berries picked: 72 of 800 | patches-visited: [5] | positive-in-buffer: 16982 | amount-filled: 100.00%
	| epsilon: 0.26799033256832494
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1257, 1947, 1865, 2687, 1276, 3564, 1943, 2443]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 31, 26, 33, 14, 50, 21, 38]
episode: 775 -> reward: -124.99999999999197, steps:65760, time-elasped: 141198.11s
-> berries picked: 80 of 800 | patches-visited: [2] | positive-in-buffer: 17035 | amount-filled: 100.00%
	| epsilon: 0.2677747624159514
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1258, 1960, 1865, 2690, 1282, 3578, 1953, 2449]
	| approx positives in sample 512: 223
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 30, 20, 37, 16, 48, 26, 35]
episode: 776 -> reward: -124.99999999999206, steps:68256, time-elasped: 141384.74s
-> berries picked: 80 of 800 | patches-visited: [1] | positive-in-buffer: 17066 | amount-filled: 100.00%
	| epsilon: 0.26755936566718597
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1258, 1972, 1868, 2694, 1282, 3581, 1954, 2457]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 29, 20, 26, 21, 54, 22, 34]
episode: 777 -> reward: -124.9999999999951, steps:81216, time-elasped: 141572.60s
-> berries picked: 124 of 800 | patches-visited: [7, 9] | positive-in-buffer: 17014 | amount-filled: 100.00%
	| epsilon: 0.26734414218254354
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1250, 1953, 1861, 2692, 1275, 3583, 1949, 2451]
	| approx positives in sample 512: 246
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 37, 26, 49, 11, 45, 29, 35]
episode: 778 -> reward: -124.99999999998388, steps:100032, time-elasped: 141811.00s
-> berries picked: 195 of 800 | patches-visited: [4, 5, 9] | positive-in-buffer: 16757 | amount-filled: 100.00%
	| epsilon: 0.26712909182265127
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1205, 1920, 1850, 2643, 1258, 3553, 1937, 2391]
	| approx positives in sample 512: 239
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 27, 21, 30, 24, 52, 30, 36]
episode: 779 -> reward: -124.99999999999199, steps:62496, time-elasped: 142011.20s
-> berries picked: 63 of 800 | patches-visited: [9] | positive-in-buffer: 16793 | amount-filled: 100.00%
	| epsilon: 0.2669142144482485
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1213, 1919, 1854, 2645, 1262, 3560, 1944, 2396]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 20, 27, 34, 16, 57, 25, 26]
episode: 780 -> reward: -124.99999999999193, steps:62016, time-elasped: 142181.19s
-> berries picked: 57 of 800 | patches-visited: [3] | positive-in-buffer: 16831 | amount-filled: 100.00%
	| epsilon: 0.26669950992018643
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1214, 1924, 1857, 2654, 1263, 3575, 1946, 2398]
	| approx positives in sample 512: 234
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 26, 28, 41, 20, 43, 30, 38]
episode: 781 -> reward: -124.99999999999214, steps:68160, time-elasped: 142373.28s
-> berries picked: 81 of 800 | patches-visited: [1, 2] | positive-in-buffer: 16872 | amount-filled: 100.00%
	| epsilon: 0.2664849780994284
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1215, 1931, 1858, 2658, 1266, 3583, 1946, 2415]
	| approx positives in sample 512: 223
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 23, 31, 27, 22, 42, 29, 37]
episode: 782 -> reward: -124.99999999998414, steps:77472, time-elasped: 142584.91s
-> berries picked: 105 of 800 | patches-visited: [4, 8, 9] | positive-in-buffer: 16912 | amount-filled: 100.00%
	| epsilon: 0.2662706188470494
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1219, 1939, 1859, 2665, 1262, 3598, 1954, 2416]
	| approx positives in sample 512: 242
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 18, 24, 43, 15, 59, 29, 33]
episode: 783 -> reward: -124.99999999998418, steps:92928, time-elasped: 142793.01s
-> berries picked: 165 of 800 | patches-visited: [0, 1, 9] | positive-in-buffer: 16861 | amount-filled: 100.00%
	| epsilon: 0.26605643202423623
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1205, 1931, 1854, 2670, 1257, 3585, 1943, 2416]
	| approx positives in sample 512: 226
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 29, 25, 32, 16, 47, 31, 28]
episode: 784 -> reward: -124.99999999999203, steps:51360, time-elasped: 142951.46s
-> berries picked: 11 of 800 | patches-visited: [3] | positive-in-buffer: 16845 | amount-filled: 100.00%
	| epsilon: 0.2658424174922874
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1202, 1929, 1854, 2668, 1256, 3584, 1944, 2408]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 20, 34, 34, 15, 46, 23, 28]
episode: 785 -> reward: -124.99999999999203, steps:50784, time-elasped: 143110.10s
-> berries picked: 10 of 800 | patches-visited: [4] | positive-in-buffer: 16853 | amount-filled: 100.00%
	| epsilon: 0.26562857511261295
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1202, 1930, 1855, 2670, 1256, 3584, 1945, 2411]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 25, 22, 37, 15, 54, 23, 32]
episode: 786 -> reward: -124.99999999999119, steps:91488, time-elasped: 143327.07s
-> berries picked: 166 of 800 | patches-visited: [2, 3, 7] | positive-in-buffer: 16869 | amount-filled: 100.00%
	| epsilon: 0.26541490474673435
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1191, 1928, 1856, 2676, 1255, 3591, 1963, 2409]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 33, 21, 28, 14, 54, 29, 34]
episode: 787 -> reward: -124.9999999999912, steps:77184, time-elasped: 143541.97s
-> berries picked: 114 of 800 | patches-visited: [0, 6] | positive-in-buffer: 16943 | amount-filled: 100.00%
	| epsilon: 0.26520140625628463
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1196, 1952, 1862, 2689, 1259, 3601, 1962, 2422]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 27, 23, 26, 14, 59, 28, 30]
episode: 788 -> reward: -124.9999999999921, steps:57312, time-elasped: 143728.53s
-> berries picked: 34 of 800 | patches-visited: [3] | positive-in-buffer: 16951 | amount-filled: 100.00%
	| epsilon: 0.26498807950300796
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1195, 1949, 1862, 2695, 1262, 3604, 1966, 2418]
	| approx positives in sample 512: 230
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 23, 32, 39, 17, 53, 24, 28]
episode: 789 -> reward: -124.99999999998826, steps:68544, time-elasped: 143919.22s
-> berries picked: 75 of 800 | patches-visited: [6, 8] | positive-in-buffer: 17003 | amount-filled: 100.00%
	| epsilon: 0.26477492434875977
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1197, 1953, 1868, 2704, 1268, 3612, 1974, 2427]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 18, 23, 40, 14, 58, 23, 30]
episode: 790 -> reward: -124.99999999999164, steps:70464, time-elasped: 144117.17s
-> berries picked: 87 of 800 | patches-visited: [1, 7] | positive-in-buffer: 17046 | amount-filled: 100.00%
	| epsilon: 0.2645619406555066
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1195, 1967, 1873, 2720, 1270, 3618, 1978, 2425]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 27, 21, 38, 24, 56, 26, 22]
episode: 791 -> reward: -124.99999999999103, steps:67104, time-elasped: 144325.17s
-> berries picked: 77 of 800 | patches-visited: [0] | positive-in-buffer: 17065 | amount-filled: 100.00%
	| epsilon: 0.26434912828532603
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1197, 1964, 1875, 2720, 1270, 3634, 1981, 2424]
	| approx positives in sample 512: 242
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 21, 27, 45, 12, 58, 39, 27]
episode: 792 -> reward: -124.99999999999206, steps:64224, time-elasped: 144522.66s
-> berries picked: 56 of 800 | patches-visited: [2, 8] | positive-in-buffer: 17076 | amount-filled: 100.00%
	| epsilon: 0.26413648710040655
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1200, 1969, 1880, 2720, 1271, 3637, 1979, 2420]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 27, 28, 33, 17, 45, 28, 33]
episode: 793 -> reward: -124.99999999999247, steps:63744, time-elasped: 144716.08s
-> berries picked: 63 of 800 | patches-visited: [7] | positive-in-buffer: 17098 | amount-filled: 100.00%
	| epsilon: 0.2639240169630477
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1199, 1966, 1879, 2726, 1271, 3650, 1985, 2422]
	| approx positives in sample 512: 210
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 18, 19, 34, 14, 42, 26, 46]
episode: 794 -> reward: -124.99999999999235, steps:63552, time-elasped: 144906.26s
-> berries picked: 72 of 800 | patches-visited: [2] | positive-in-buffer: 17105 | amount-filled: 100.00%
	| epsilon: 0.2637117177356595
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1197, 1970, 1879, 2729, 1274, 3649, 1988, 2419]
	| approx positives in sample 512: 241
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 32, 19, 41, 11, 53, 23, 35]
episode: 795 -> reward: -124.99999999998803, steps:94464, time-elasped: 145115.31s
-> berries picked: 172 of 800 | patches-visited: [5, 6, 7] | positive-in-buffer: 16902 | amount-filled: 100.00%
	| epsilon: 0.26349958928076284
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1153, 1942, 1876, 2709, 1263, 3626, 1969, 2364]
	| approx positives in sample 512: 246
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 32, 27, 37, 19, 62, 22, 26]
episode: 796 -> reward: -124.99999999999059, steps:90432, time-elasped: 145344.77s
-> berries picked: 162 of 800 | patches-visited: [0, 3, 8] | positive-in-buffer: 16989 | amount-filled: 100.00%
	| epsilon: 0.26328763146098916
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1152, 1947, 1883, 2731, 1268, 3663, 1973, 2372]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 19, 29, 27, 12, 54, 22, 36]
episode: 797 -> reward: -124.99999999998921, steps:76896, time-elasped: 145548.41s
-> berries picked: 117 of 800 | patches-visited: [8, 9] | positive-in-buffer: 17049 | amount-filled: 100.00%
	| epsilon: 0.2630758441390803
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1151, 1964, 1890, 2739, 1268, 3681, 1982, 2374]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 32, 28, 29, 19, 52, 28, 27]
episode: 798 -> reward: -124.99999999998634, steps:76416, time-elasped: 145753.76s
-> berries picked: 104 of 800 | patches-visited: [5, 7] | positive-in-buffer: 17075 | amount-filled: 100.00%
	| epsilon: 0.2628642271778886
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1162, 1973, 1894, 2745, 1269, 3677, 1983, 2372]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 28, 27, 32, 21, 52, 26, 30]
episode: 799 -> reward: -124.99999999999221, steps:66336, time-elasped: 145940.90s
-> berries picked: 74 of 800 | patches-visited: [6] | positive-in-buffer: 17113 | amount-filled: 100.00%
	| epsilon: 0.26265278044037677
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1163, 1980, 1895, 2756, 1275, 3679, 1986, 2379]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 23, 26, 33, 20, 58, 23, 32]
episode: 800 -> reward: -124.999999999992, steps:62688, time-elasped: 146118.09s
-> berries picked: 66 of 800 | patches-visited: [1] | positive-in-buffer: 17152 | amount-filled: 100.00%
	| epsilon: 0.2624415037896176
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1166, 1988, 1897, 2756, 1280, 3689, 1991, 2385]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 22, 30, 46, 12, 50, 20, 22]
episode: 801 -> reward: -124.9999999999863, steps:89376, time-elasped: 146334.07s
-> berries picked: 164 of 800 | patches-visited: [0, 3, 6] | positive-in-buffer: 16919 | amount-filled: 100.00%
	| epsilon: 0.2622303970887942
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1117, 1941, 1877, 2740, 1274, 3663, 1973, 2334]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 20, 25, 35, 22, 50, 29, 31]
episode: 802 -> reward: -124.99999999998784, steps:71808, time-elasped: 146540.56s
-> berries picked: 92 of 800 | patches-visited: [2, 5, 9] | positive-in-buffer: 16976 | amount-filled: 100.00%
	| epsilon: 0.26201946020119965
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1126, 1941, 1880, 2745, 1280, 3680, 1981, 2343]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 34, 23, 21, 18, 54, 25, 25]
episode: 803 -> reward: -124.9999999999917, steps:65568, time-elasped: 146729.50s
-> berries picked: 67 of 800 | patches-visited: [1] | positive-in-buffer: 17008 | amount-filled: 100.00%
	| epsilon: 0.2618086929902369
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1126, 1943, 1881, 2757, 1282, 3678, 1992, 2349]
	| approx positives in sample 512: 233
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 23, 26, 30, 23, 46, 30, 38]
episode: 804 -> reward: -124.999999999992, steps:57888, time-elasped: 146914.78s
-> berries picked: 35 of 800 | patches-visited: [5] | positive-in-buffer: 17030 | amount-filled: 100.00%
	| epsilon: 0.26159809531941897
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1128, 1947, 1883, 2759, 1282, 3686, 1995, 2350]
	| approx positives in sample 512: 238
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 25, 25, 30, 16, 63, 28, 39]
episode: 805 -> reward: -124.99999999999392, steps:79104, time-elasped: 147110.53s
-> berries picked: 125 of 800 | patches-visited: [4, 6] | positive-in-buffer: 17058 | amount-filled: 100.00%
	| epsilon: 0.26138766705236843
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1127, 1958, 1884, 2761, 1280, 3697, 2006, 2345]
	| approx positives in sample 512: 245
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 26, 28, 32, 17, 57, 36, 33]
episode: 806 -> reward: -124.9999999999893, steps:71520, time-elasped: 147309.47s
-> berries picked: 93 of 800 | patches-visited: [2, 7] | positive-in-buffer: 17108 | amount-filled: 100.00%
	| epsilon: 0.26117740805281786
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1125, 1975, 1886, 2772, 1285, 3705, 2008, 2352]
	| approx positives in sample 512: 230
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 22, 23, 43, 19, 55, 28, 25]
episode: 807 -> reward: -124.99999999998455, steps:85536, time-elasped: 147503.47s
-> berries picked: 141 of 800 | patches-visited: [3, 5] | positive-in-buffer: 16942 | amount-filled: 100.00%
	| epsilon: 0.2609673181846093
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1100, 1945, 1874, 2752, 1280, 3679, 1993, 2319]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 21, 33, 33, 17, 54, 34, 27]
episode: 808 -> reward: -124.99999999999174, steps:62496, time-elasped: 147689.26s
-> berries picked: 60 of 800 | patches-visited: [4] | positive-in-buffer: 16970 | amount-filled: 100.00%
	| epsilon: 0.2607573973116941
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1099, 1951, 1875, 2762, 1282, 3687, 1991, 2323]
	| approx positives in sample 512: 235
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 24, 24, 39, 11, 58, 26, 40]
episode: 809 -> reward: -124.99999999999353, steps:66912, time-elasped: 147882.84s
-> berries picked: 75 of 800 | patches-visited: [9] | positive-in-buffer: 17014 | amount-filled: 100.00%
	| epsilon: 0.2605476452981334
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1101, 1957, 1879, 2773, 1283, 3701, 1994, 2326]
	| approx positives in sample 512: 226
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 21, 26, 36, 19, 48, 31, 34]
episode: 810 -> reward: -124.99999999998454, steps:80352, time-elasped: 148076.23s
-> berries picked: 123 of 800 | patches-visited: [3, 4, 6, 7] | positive-in-buffer: 17016 | amount-filled: 100.00%
	| epsilon: 0.2603380620080975
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1108, 1968, 1872, 2768, 1283, 3705, 1995, 2317]
	| approx positives in sample 512: 235
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 21, 36, 33, 19, 58, 35, 23]
episode: 811 -> reward: -124.99999999999272, steps:76032, time-elasped: 148265.89s
-> berries picked: 112 of 800 | patches-visited: [0, 2, 4] | positive-in-buffer: 17086 | amount-filled: 100.00%
	| epsilon: 0.260128647305866
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1112, 1972, 1873, 2783, 1298, 3718, 1999, 2331]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 23, 22, 43, 13, 53, 35, 24]
episode: 812 -> reward: -124.9999999999854, steps:85536, time-elasped: 148461.89s
-> berries picked: 134 of 800 | patches-visited: [1, 8, 9] | positive-in-buffer: 16977 | amount-filled: 100.00%
	| epsilon: 0.25991940105582767
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1089, 1945, 1871, 2774, 1297, 3715, 1984, 2302]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 29, 21, 29, 25, 55, 29, 30]
episode: 813 -> reward: -124.99999999999189, steps:56064, time-elasped: 148646.84s
-> berries picked: 25 of 800 | patches-visited: [1] | positive-in-buffer: 16974 | amount-filled: 100.00%
	| epsilon: 0.2597103231224804
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1090, 1947, 1871, 2774, 1297, 3715, 1982, 2298]
	| approx positives in sample 512: 211
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 13, 29, 39, 16, 49, 30, 22]
episode: 814 -> reward: -124.99999999999226, steps:63744, time-elasped: 148844.02s
-> berries picked: 54 of 800 | patches-visited: [1] | positive-in-buffer: 17018 | amount-filled: 100.00%
	| epsilon: 0.259501413370431
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1093, 1952, 1876, 2777, 1302, 3727, 1985, 2306]
	| approx positives in sample 512: 237
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 26, 31, 30, 17, 61, 32, 26]
episode: 815 -> reward: -124.99999999998776, steps:76896, time-elasped: 149049.11s
-> berries picked: 107 of 800 | patches-visited: [3, 4, 5, 9] | positive-in-buffer: 17057 | amount-filled: 100.00%
	| epsilon: 0.2592926716643952
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1090, 1950, 1880, 2791, 1298, 3754, 1988, 2306]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 19, 22, 40, 19, 54, 28, 34]
episode: 816 -> reward: -124.99999999999204, steps:54816, time-elasped: 149233.85s
-> berries picked: 26 of 800 | patches-visited: [2] | positive-in-buffer: 17067 | amount-filled: 100.00%
	| epsilon: 0.2590840978691976
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1090, 1952, 1880, 2789, 1296, 3761, 1994, 2305]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 20, 17, 35, 15, 51, 25, 33]
episode: 817 -> reward: -124.99999999998724, steps:84576, time-elasped: 149455.06s
-> berries picked: 146 of 800 | patches-visited: [5, 6] | positive-in-buffer: 17010 | amount-filled: 100.00%
	| epsilon: 0.2588756918497716
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1076, 1944, 1873, 2783, 1294, 3770, 1989, 2281]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 27, 18, 35, 12, 53, 23, 22]
episode: 818 -> reward: -124.99999999999095, steps:64224, time-elasped: 149646.00s
-> berries picked: 70 of 800 | patches-visited: [6] | positive-in-buffer: 17057 | amount-filled: 100.00%
	| epsilon: 0.25866745347115905
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1080, 1951, 1879, 2792, 1299, 3779, 1988, 2289]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 27, 19, 34, 22, 53, 29, 29]
episode: 819 -> reward: -124.9999999999921, steps:58464, time-elasped: 149823.11s
-> berries picked: 37 of 800 | patches-visited: [7] | positive-in-buffer: 17055 | amount-filled: 100.00%
	| epsilon: 0.2584593825985106
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1079, 1949, 1881, 2795, 1302, 3772, 1990, 2287]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 21, 29, 45, 19, 57, 22, 30]
episode: 820 -> reward: -124.99999999998897, steps:80064, time-elasped: 150044.52s
-> berries picked: 115 of 800 | patches-visited: [2, 7, 9] | positive-in-buffer: 17057 | amount-filled: 100.00%
	| epsilon: 0.2582514790970851
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1079, 1960, 1883, 2793, 1302, 3770, 1992, 2278]
	| approx positives in sample 512: 244
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 22, 33, 35, 25, 55, 28, 36]
episode: 821 -> reward: -124.99999999999059, steps:79680, time-elasped: 150247.45s
-> berries picked: 113 of 800 | patches-visited: [0, 7] | positive-in-buffer: 17087 | amount-filled: 100.00%
	| epsilon: 0.25804374283225007
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1069, 1968, 1880, 2797, 1307, 3792, 1995, 2279]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 29, 22, 36, 15, 48, 30, 28]
episode: 822 -> reward: -124.99999999999203, steps:50592, time-elasped: 150427.75s
-> berries picked: 10 of 800 | patches-visited: [3] | positive-in-buffer: 17089 | amount-filled: 100.00%
	| epsilon: 0.25783617366948114
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1069, 1968, 1879, 2798, 1306, 3795, 1996, 2278]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 18, 28, 27, 15, 55, 32, 33]
episode: 823 -> reward: -124.99999999999369, steps:75264, time-elasped: 150625.56s
-> berries picked: 102 of 800 | patches-visited: [0, 8] | positive-in-buffer: 17149 | amount-filled: 100.00%
	| epsilon: 0.2576287714743621
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1075, 1974, 1881, 2805, 1310, 3819, 1997, 2288]
	| approx positives in sample 512: 226
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 25, 29, 40, 17, 50, 28, 24]
episode: 824 -> reward: -124.99999999998964, steps:69120, time-elasped: 150817.63s
-> berries picked: 78 of 800 | patches-visited: [3, 5] | positive-in-buffer: 17201 | amount-filled: 100.00%
	| epsilon: 0.2574215361125851
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1078, 1984, 1890, 2809, 1313, 3823, 2010, 2294]
	| approx positives in sample 512: 236
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 24, 22, 30, 17, 66, 27, 34]
episode: 825 -> reward: -124.99999999999137, steps:59424, time-elasped: 150974.14s
-> berries picked: 41 of 800 | patches-visited: [2] | positive-in-buffer: 17226 | amount-filled: 100.00%
	| epsilon: 0.2572144674499502
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1082, 1988, 1889, 2814, 1315, 3825, 2016, 2297]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 23, 26, 33, 23, 49, 25, 32]
episode: 826 -> reward: -124.99999999999193, steps:61536, time-elasped: 151154.51s
-> berries picked: 48 of 800 | patches-visited: [9] | positive-in-buffer: 17256 | amount-filled: 100.00%
	| epsilon: 0.2570075653523653
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1081, 1995, 1890, 2818, 1318, 3838, 2021, 2295]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 33, 23, 23, 12, 60, 25, 34]
episode: 827 -> reward: -124.99999999999193, steps:63840, time-elasped: 151325.22s
-> berries picked: 55 of 800 | patches-visited: [8] | positive-in-buffer: 17227 | amount-filled: 100.00%
	| epsilon: 0.2568008296858463
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1072, 1990, 1886, 2816, 1314, 3837, 2019, 2293]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 26, 15, 27, 20, 59, 31, 28]
episode: 828 -> reward: -124.99999999999292, steps:66528, time-elasped: 151496.02s
-> berries picked: 71 of 800 | patches-visited: [9] | positive-in-buffer: 17221 | amount-filled: 100.00%
	| epsilon: 0.2565942603165169
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1067, 1987, 1885, 2811, 1311, 3845, 2027, 2288]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 24, 19, 36, 20, 65, 17, 32]
episode: 829 -> reward: -124.99999999999204, steps:56448, time-elasped: 151687.62s
-> berries picked: 28 of 800 | patches-visited: [0] | positive-in-buffer: 17231 | amount-filled: 100.00%
	| epsilon: 0.2563878571106083
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1068, 1991, 1887, 2812, 1312, 3846, 2025, 2290]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 19, 21, 33, 18, 43, 41, 31]
episode: 830 -> reward: -124.99999999998562, steps:83808, time-elasped: 151895.58s
-> berries picked: 138 of 800 | patches-visited: [0, 4, 5] | positive-in-buffer: 17099 | amount-filled: 100.00%
	| epsilon: 0.25618161993445954
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1056, 1966, 1857, 2794, 1308, 3845, 2007, 2266]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 25, 26, 27, 8, 41, 33, 31]
episode: 831 -> reward: -124.99999999999145, steps:64800, time-elasped: 152066.22s
-> berries picked: 66 of 800 | patches-visited: [3] | positive-in-buffer: 17144 | amount-filled: 100.00%
	| epsilon: 0.25597554865451705
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1060, 1973, 1858, 2805, 1311, 3856, 2015, 2266]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 11, 25, 39, 15, 55, 33, 24]
episode: 832 -> reward: -124.99999999999095, steps:65856, time-elasped: 152257.91s
-> berries picked: 68 of 800 | patches-visited: [8] | positive-in-buffer: 17187 | amount-filled: 100.00%
	| epsilon: 0.2557696431373347
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1064, 1981, 1859, 2809, 1311, 3869, 2027, 2267]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 34, 19, 31, 16, 42, 33, 32]
episode: 833 -> reward: -124.99999999999176, steps:54432, time-elasped: 152426.81s
-> berries picked: 28 of 800 | patches-visited: [2] | positive-in-buffer: 17197 | amount-filled: 100.00%
	| epsilon: 0.25556390324957373
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1064, 1981, 1859, 2810, 1314, 3870, 2030, 2269]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 20, 30, 31, 16, 55, 31, 31]
episode: 834 -> reward: -124.9999999999926, steps:63744, time-elasped: 152607.80s
-> berries picked: 67 of 800 | patches-visited: [6] | positive-in-buffer: 17236 | amount-filled: 100.00%
	| epsilon: 0.2553583288580026
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1062, 1989, 1862, 2817, 1317, 3879, 2034, 2276]
	| approx positives in sample 512: 243
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 30, 20, 50, 16, 58, 32, 27]
episode: 835 -> reward: -124.99999999999356, steps:75360, time-elasped: 152816.39s
-> berries picked: 101 of 800 | patches-visited: [1, 3] | positive-in-buffer: 17204 | amount-filled: 100.00%
	| epsilon: 0.2551529198294969
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1058, 1991, 1861, 2824, 1313, 3865, 2022, 2270]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 23, 30, 28, 10, 58, 25, 32]
episode: 836 -> reward: -124.99999999998971, steps:68256, time-elasped: 153008.21s
-> berries picked: 77 of 800 | patches-visited: [1, 5] | positive-in-buffer: 17260 | amount-filled: 100.00%
	| epsilon: 0.25494767603103946
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1059, 1995, 1866, 2834, 1314, 3888, 2029, 2275]
	| approx positives in sample 512: 241
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 23, 27, 35, 18, 66, 25, 32]
episode: 837 -> reward: -124.99999999999243, steps:64224, time-elasped: 153206.27s
-> berries picked: 70 of 800 | patches-visited: [9] | positive-in-buffer: 17309 | amount-filled: 100.00%
	| epsilon: 0.25474259732972
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1062, 2001, 1865, 2842, 1314, 3908, 2037, 2280]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 25, 21, 35, 19, 55, 28, 27]
episode: 838 -> reward: -124.99999999998866, steps:75648, time-elasped: 153419.01s
-> berries picked: 106 of 800 | patches-visited: [7, 9] | positive-in-buffer: 17202 | amount-filled: 100.00%
	| epsilon: 0.2545376835927351
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1038, 2000, 1864, 2829, 1294, 3884, 2033, 2260]
	| approx positives in sample 512: 233
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 25, 28, 33, 13, 38, 41, 37]
episode: 839 -> reward: -124.99999999999179, steps:65856, time-elasped: 153605.14s
-> berries picked: 80 of 800 | patches-visited: [6] | positive-in-buffer: 17254 | amount-filled: 100.00%
	| epsilon: 0.25433293468738827
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1039, 2004, 1866, 2842, 1296, 3902, 2039, 2266]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 18, 18, 36, 11, 67, 35, 24]
episode: 840 -> reward: -124.99999999999214, steps:55680, time-elasped: 153763.35s
-> berries picked: 29 of 800 | patches-visited: [0] | positive-in-buffer: 17259 | amount-filled: 100.00%
	| epsilon: 0.2541283504810898
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1039, 2006, 1865, 2842, 1297, 3902, 2040, 2268]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 18, 17, 33, 29, 55, 25, 33]
episode: 841 -> reward: -124.99999999999437, steps:69024, time-elasped: 153955.56s
-> berries picked: 78 of 800 | patches-visited: [2, 4] | positive-in-buffer: 17260 | amount-filled: 100.00%
	| epsilon: 0.2539239308413564
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1039, 2007, 1864, 2844, 1294, 3902, 2046, 2264]
	| approx positives in sample 512: 223
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 24, 24, 30, 18, 50, 38, 25]
episode: 842 -> reward: -124.99999999999052, steps:67488, time-elasped: 154146.06s
-> berries picked: 75 of 800 | patches-visited: [4, 9] | positive-in-buffer: 17279 | amount-filled: 100.00%
	| epsilon: 0.2537196756358116
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1039, 2010, 1866, 2848, 1299, 3900, 2046, 2271]
	| approx positives in sample 512: 235
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 21, 25, 31, 16, 75, 23, 34]
episode: 843 -> reward: -124.99999999999119, steps:62592, time-elasped: 154312.54s
-> berries picked: 59 of 800 | patches-visited: [2] | positive-in-buffer: 17317 | amount-filled: 100.00%
	| epsilon: 0.25351558473218533
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1041, 2017, 1867, 2851, 1305, 3909, 2052, 2275]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 33, 21, 29, 17, 63, 25, 26]
episode: 844 -> reward: -124.99999999998627, steps:74112, time-elasped: 154505.08s
-> berries picked: 94 of 800 | patches-visited: [4, 8] | positive-in-buffer: 17226 | amount-filled: 100.00%
	| epsilon: 0.2533116579983139
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1027, 1999, 1854, 2835, 1303, 3905, 2040, 2263]
	| approx positives in sample 512: 240
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 21, 34, 45, 17, 55, 31, 23]
episode: 845 -> reward: -124.99999999999174, steps:60672, time-elasped: 154667.91s
-> berries picked: 45 of 800 | patches-visited: [5] | positive-in-buffer: 17249 | amount-filled: 100.00%
	| epsilon: 0.2531078953021399
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1031, 2005, 1853, 2840, 1304, 3905, 2049, 2262]
	| approx positives in sample 512: 249
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 23, 28, 36, 18, 66, 30, 34]
episode: 846 -> reward: -124.99999999999176, steps:58368, time-elasped: 154843.30s
-> berries picked: 33 of 800 | patches-visited: [0, 2] | positive-in-buffer: 17262 | amount-filled: 100.00%
	| epsilon: 0.25290429651171226
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1034, 2009, 1853, 2841, 1303, 3911, 2046, 2265]
	| approx positives in sample 512: 223
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 25, 32, 37, 14, 54, 27, 27]
episode: 847 -> reward: -124.99999999999201, steps:53472, time-elasped: 155015.32s
-> berries picked: 19 of 800 | patches-visited: [5] | positive-in-buffer: 17280 | amount-filled: 100.00%
	| epsilon: 0.25270086149518584
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1036, 2011, 1856, 2841, 1306, 3918, 2046, 2266]
	| approx positives in sample 512: 208
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 23, 25, 27, 14, 57, 27, 24]
episode: 848 -> reward: -124.99999999997979, steps:87552, time-elasped: 155213.42s
-> berries picked: 138 of 800 | patches-visited: [4, 7, 8] | positive-in-buffer: 17120 | amount-filled: 100.00%
	| epsilon: 0.2524975901208218
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1034, 2018, 1825, 2815, 1289, 3880, 2030, 2229]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 16, 22, 37, 13, 57, 31, 24]
episode: 849 -> reward: -124.99999999999203, steps:53760, time-elasped: 155420.27s
-> berries picked: 22 of 800 | patches-visited: [9] | positive-in-buffer: 17133 | amount-filled: 100.00%
	| epsilon: 0.25229448225698714
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1034, 2019, 1825, 2816, 1292, 3884, 2032, 2231]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 36, 29, 30, 17, 51, 27, 27]
episode: 850 -> reward: -124.99999999998741, steps:91296, time-elasped: 155652.50s
-> berries picked: 160 of 800 | patches-visited: [2, 5, 6, 8] | positive-in-buffer: 17056 | amount-filled: 100.00%
	| epsilon: 0.25209153777215476
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1016, 2009, 1814, 2800, 1286, 3875, 2034, 2222]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 34, 18, 37, 20, 55, 23, 28]
episode: 851 -> reward: -124.99999999998775, steps:76128, time-elasped: 155834.24s
-> berries picked: 104 of 800 | patches-visited: [0, 1] | positive-in-buffer: 17134 | amount-filled: 100.00%
	| epsilon: 0.25188875653490334
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1020, 2026, 1815, 2820, 1292, 3891, 2046, 2224]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 25, 18, 30, 22, 50, 26, 33]
episode: 852 -> reward: -124.99999999998873, steps:76512, time-elasped: 156007.13s
-> berries picked: 108 of 800 | patches-visited: [4, 8] | positive-in-buffer: 17207 | amount-filled: 100.00%
	| epsilon: 0.25168613841391735
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1029, 2031, 1820, 2833, 1295, 3909, 2064, 2226]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 18, 24, 33, 20, 62, 27, 27]
episode: 853 -> reward: -124.99999999999044, steps:55104, time-elasped: 156197.08s
-> berries picked: 25 of 800 | patches-visited: [4] | positive-in-buffer: 17216 | amount-filled: 100.00%
	| epsilon: 0.2514836832779868
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1027, 2034, 1824, 2835, 1300, 3908, 2062, 2226]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 27, 24, 32, 18, 51, 26, 31]
episode: 854 -> reward: -124.99999999998752, steps:73152, time-elasped: 156398.81s
-> berries picked: 102 of 800 | patches-visited: [1, 3] | positive-in-buffer: 17283 | amount-filled: 100.00%
	| epsilon: 0.25128139099600727
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1027, 2048, 1828, 2845, 1303, 3930, 2067, 2235]
	| approx positives in sample 512: 199
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 23, 24, 31, 13, 49, 25, 27]
episode: 855 -> reward: -124.9999999999934, steps:75360, time-elasped: 156602.81s
-> berries picked: 95 of 800 | patches-visited: [0, 2, 4] | positive-in-buffer: 17293 | amount-filled: 100.00%
	| epsilon: 0.2510792614369799
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1026, 2045, 1825, 2855, 1302, 3932, 2070, 2238]
	| approx positives in sample 512: 230
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 32, 31, 33, 15, 50, 32, 27]
episode: 856 -> reward: -124.99999999999135, steps:62880, time-elasped: 156793.32s
-> berries picked: 52 of 800 | patches-visited: [2, 4] | positive-in-buffer: 17329 | amount-filled: 100.00%
	| epsilon: 0.250877294470011
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1027, 2053, 1826, 2857, 1311, 3943, 2073, 2239]
	| approx positives in sample 512: 230
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 31, 27, 37, 18, 51, 23, 30]
episode: 857 -> reward: -124.9999999999924, steps:71136, time-elasped: 157001.63s
-> berries picked: 84 of 800 | patches-visited: [2, 4, 7] | positive-in-buffer: 17331 | amount-filled: 100.00%
	| epsilon: 0.25067548996431244
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1031, 2058, 1832, 2853, 1308, 3935, 2071, 2243]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 32, 19, 33, 15, 65, 24, 27]
episode: 858 -> reward: -124.99999999998886, steps:65472, time-elasped: 157223.04s
-> berries picked: 64 of 800 | patches-visited: [4] | positive-in-buffer: 17383 | amount-filled: 100.00%
	| epsilon: 0.25047384778920095
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1034, 2068, 1836, 2858, 1315, 3952, 2075, 2245]
	| approx positives in sample 512: 235
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 26, 23, 36, 15, 64, 29, 28]
episode: 859 -> reward: -124.99999999999054, steps:59424, time-elasped: 157411.92s
-> berries picked: 44 of 800 | patches-visited: [8] | positive-in-buffer: 17410 | amount-filled: 100.00%
	| epsilon: 0.2502723678140988
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1032, 2081, 1835, 2862, 1315, 3962, 2077, 2246]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 22, 27, 31, 12, 59, 29, 27]
episode: 860 -> reward: -124.99999999998705, steps:69216, time-elasped: 157621.45s
-> berries picked: 74 of 800 | patches-visited: [1, 6] | positive-in-buffer: 17354 | amount-filled: 100.00%
	| epsilon: 0.2500710499085328
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1015, 2063, 1833, 2854, 1316, 3960, 2080, 2233]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 27, 28, 45, 12, 53, 24, 28]
episode: 861 -> reward: -124.99999999999199, steps:53952, time-elasped: 157817.74s
-> berries picked: 22 of 800 | patches-visited: [4] | positive-in-buffer: 17365 | amount-filled: 100.00%
	| epsilon: 0.24986989394213524
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1015, 2065, 1833, 2853, 1317, 3964, 2084, 2234]
	| approx positives in sample 512: 206
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 23, 25, 31, 16, 49, 35, 15]
episode: 862 -> reward: -124.99999999998917, steps:72576, time-elasped: 158037.67s
-> berries picked: 91 of 800 | patches-visited: [3, 7] | positive-in-buffer: 17292 | amount-filled: 100.00%
	| epsilon: 0.2496688997846429
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [993, 2059, 1832, 2841, 1320, 3964, 2088, 2195]
	| approx positives in sample 512: 238
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 26, 29, 31, 17, 59, 28, 34]
episode: 863 -> reward: -124.99999999999149, steps:61536, time-elasped: 158196.72s
-> berries picked: 45 of 800 | patches-visited: [7, 9] | positive-in-buffer: 17324 | amount-filled: 100.00%
	| epsilon: 0.2494680673058975
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [996, 2070, 1832, 2851, 1319, 3967, 2092, 2197]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 26, 21, 38, 22, 43, 34, 23]
episode: 864 -> reward: -124.99999999999199, steps:55008, time-elasped: 158346.85s
-> berries picked: 27 of 800 | patches-visited: [6] | positive-in-buffer: 17343 | amount-filled: 100.00%
	| epsilon: 0.24926739637584538
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [996, 2078, 1833, 2851, 1322, 3969, 2096, 2198]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 34, 23, 43, 15, 44, 29, 23]
episode: 865 -> reward: -124.99999999999206, steps:52512, time-elasped: 158519.19s
-> berries picked: 16 of 800 | patches-visited: [1] | positive-in-buffer: 17347 | amount-filled: 100.00%
	| epsilon: 0.24906688686453757
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [996, 2078, 1833, 2853, 1320, 3969, 2098, 2200]
	| approx positives in sample 512: 211
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 25, 16, 35, 12, 51, 30, 29]
episode: 866 -> reward: -124.999999999992, steps:64704, time-elasped: 158674.45s
-> berries picked: 60 of 800 | patches-visited: [4, 6] | positive-in-buffer: 17360 | amount-filled: 100.00%
	| epsilon: 0.24886653864212957
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [991, 2087, 1832, 2857, 1319, 3972, 2098, 2204]
	| approx positives in sample 512: 240
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 24, 31, 46, 16, 52, 28, 27]
episode: 867 -> reward: -124.99999999999197, steps:57120, time-elasped: 158834.83s
-> berries picked: 35 of 800 | patches-visited: [2] | positive-in-buffer: 17382 | amount-filled: 100.00%
	| epsilon: 0.2486663515788814
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [990, 2092, 1833, 2861, 1322, 3973, 2103, 2208]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 27, 16, 29, 25, 61, 32, 31]
episode: 868 -> reward: -124.99999999999257, steps:61632, time-elasped: 159009.48s
-> berries picked: 48 of 800 | patches-visited: [0] | positive-in-buffer: 17398 | amount-filled: 100.00%
	| epsilon: 0.24846632554515735
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [988, 2094, 1833, 2862, 1325, 3978, 2107, 2211]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 19, 26, 32, 20, 62, 26, 28]
episode: 869 -> reward: -124.9999999999863, steps:74016, time-elasped: 159195.53s
-> berries picked: 93 of 800 | patches-visited: [0, 9] | positive-in-buffer: 17311 | amount-filled: 100.00%
	| epsilon: 0.24826646041142605
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [983, 2092, 1821, 2847, 1314, 3955, 2099, 2200]
	| approx positives in sample 512: 201
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 26, 27, 40, 12, 41, 20, 24]
episode: 870 -> reward: -124.99999999999197, steps:52224, time-elasped: 159364.99s
-> berries picked: 13 of 800 | patches-visited: [5] | positive-in-buffer: 17314 | amount-filled: 100.00%
	| epsilon: 0.24806675604826034
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [983, 2094, 1822, 2850, 1315, 3951, 2099, 2200]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 24, 17, 34, 16, 53, 24, 36]
episode: 871 -> reward: -124.99999999999065, steps:64704, time-elasped: 159544.46s
-> berries picked: 66 of 800 | patches-visited: [0] | positive-in-buffer: 17369 | amount-filled: 100.00%
	| epsilon: 0.2478672123263371
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [984, 2104, 1827, 2854, 1319, 3965, 2111, 2205]
	| approx positives in sample 512: 208
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 17, 27, 22, 19, 50, 27, 35]
episode: 872 -> reward: -124.99999999999206, steps:54912, time-elasped: 159710.41s
-> berries picked: 28 of 800 | patches-visited: [1] | positive-in-buffer: 17377 | amount-filled: 100.00%
	| epsilon: 0.24766782911643728
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [984, 2105, 1827, 2857, 1318, 3966, 2111, 2209]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 27, 23, 45, 19, 55, 18, 26]
episode: 873 -> reward: -124.99999999999346, steps:68640, time-elasped: 159899.77s
-> berries picked: 77 of 800 | patches-visited: [3] | positive-in-buffer: 17369 | amount-filled: 100.00%
	| epsilon: 0.2474686062894458
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [985, 2107, 1826, 2850, 1315, 3970, 2112, 2204]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 28, 31, 22, 18, 54, 26, 36]
episode: 874 -> reward: -124.99999999999227, steps:51840, time-elasped: 160065.57s
-> berries picked: 17 of 800 | patches-visited: [7] | positive-in-buffer: 17376 | amount-filled: 100.00%
	| epsilon: 0.24726954371635138
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [986, 2110, 1826, 2852, 1315, 3973, 2111, 2203]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 26, 26, 34, 15, 58, 29, 23]
episode: 875 -> reward: -124.99999999999015, steps:65856, time-elasped: 160246.05s
-> berries picked: 63 of 800 | patches-visited: [2, 7] | positive-in-buffer: 17394 | amount-filled: 100.00%
	| epsilon: 0.24707064126824654
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [988, 2117, 1826, 2856, 1319, 3975, 2112, 2201]
	| approx positives in sample 512: 208
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 18, 20, 42, 15, 55, 23, 30]
episode: 876 -> reward: -124.99999999998964, steps:71232, time-elasped: 160438.34s
-> berries picked: 87 of 800 | patches-visited: [3, 6, 8] | positive-in-buffer: 17335 | amount-filled: 100.00%
	| epsilon: 0.24687189881632754
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [975, 2115, 1813, 2853, 1312, 3959, 2120, 2188]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 21, 18, 38, 15, 56, 28, 25]
episode: 877 -> reward: -124.99999999999223, steps:64032, time-elasped: 160615.31s
-> berries picked: 65 of 800 | patches-visited: [0] | positive-in-buffer: 17386 | amount-filled: 100.00%
	| epsilon: 0.24667331623189417
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [978, 2123, 1816, 2864, 1318, 3965, 2119, 2203]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 23, 25, 35, 13, 57, 30, 24]
episode: 878 -> reward: -124.99999999999005, steps:60480, time-elasped: 160808.76s
-> berries picked: 46 of 800 | patches-visited: [2] | positive-in-buffer: 17413 | amount-filled: 100.00%
	| epsilon: 0.24647489338634979
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [978, 2132, 1815, 2868, 1323, 3969, 2122, 2206]
	| approx positives in sample 512: 245
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 21, 22, 36, 16, 74, 31, 36]
episode: 879 -> reward: -124.99999999999203, steps:50976, time-elasped: 160979.71s
-> berries picked: 9 of 800 | patches-visited: [9] | positive-in-buffer: 17410 | amount-filled: 100.00%
	| epsilon: 0.2462766301512012
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [980, 2131, 1815, 2870, 1321, 3968, 2122, 2203]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 25, 27, 38, 15, 63, 25, 23]
episode: 880 -> reward: -124.99999999999204, steps:50112, time-elasped: 161146.76s
-> berries picked: 7 of 800 | patches-visited: [7] | positive-in-buffer: 17414 | amount-filled: 100.00%
	| epsilon: 0.24607852639805852
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [979, 2132, 1816, 2872, 1321, 3970, 2122, 2202]
	| approx positives in sample 512: 238
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 26, 23, 37, 18, 57, 31, 30]
episode: 881 -> reward: -124.99999999999179, steps:60864, time-elasped: 161350.57s
-> berries picked: 49 of 800 | patches-visited: [9] | positive-in-buffer: 17423 | amount-filled: 100.00%
	| epsilon: 0.24588058199863524
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [980, 2136, 1817, 2868, 1319, 3970, 2126, 2207]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 26, 22, 30, 20, 51, 32, 34]
episode: 882 -> reward: -124.99999999999204, steps:52032, time-elasped: 161530.01s
-> berries picked: 16 of 800 | patches-visited: [4, 7] | positive-in-buffer: 17429 | amount-filled: 100.00%
	| epsilon: 0.24568279682474797
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [980, 2137, 1818, 2868, 1320, 3973, 2128, 2205]
	| approx positives in sample 512: 250
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 37, 19, 38, 21, 69, 23, 31]
episode: 883 -> reward: -124.99999999999216, steps:52800, time-elasped: 161700.97s
-> berries picked: 17 of 800 | patches-visited: [5] | positive-in-buffer: 17435 | amount-filled: 100.00%
	| epsilon: 0.2454851707483164
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [981, 2138, 1820, 2870, 1319, 3971, 2130, 2206]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 26, 18, 31, 19, 59, 34, 29]
episode: 884 -> reward: -124.99999999999204, steps:51456, time-elasped: 161881.86s
-> berries picked: 10 of 800 | patches-visited: [7] | positive-in-buffer: 17441 | amount-filled: 100.00%
	| epsilon: 0.24528770364136337
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [982, 2137, 1822, 2873, 1318, 3971, 2130, 2208]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 22, 26, 36, 17, 60, 27, 35]
episode: 885 -> reward: -124.99999999999183, steps:62688, time-elasped: 162074.55s
-> berries picked: 51 of 800 | patches-visited: [6, 8] | positive-in-buffer: 17394 | amount-filled: 100.00%
	| epsilon: 0.24509039537601449
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [984, 2125, 1818, 2865, 1312, 3956, 2127, 2207]
	| approx positives in sample 512: 237
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 19, 23, 43, 28, 55, 24, 33]
episode: 886 -> reward: -124.99999999999211, steps:60480, time-elasped: 162274.47s
-> berries picked: 47 of 800 | patches-visited: [0] | positive-in-buffer: 17418 | amount-filled: 100.00%
	| epsilon: 0.24489324582449837
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [982, 2130, 1818, 2869, 1310, 3962, 2134, 2213]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 17, 21, 29, 16, 56, 30, 30]
episode: 887 -> reward: -124.9999999999906, steps:81024, time-elasped: 162511.66s
-> berries picked: 122 of 800 | patches-visited: [1, 2, 3, 5] | positive-in-buffer: 17263 | amount-filled: 100.00%
	| epsilon: 0.2446962548591464
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [977, 2117, 1788, 2829, 1292, 3937, 2124, 2199]
	| approx positives in sample 512: 223
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 24, 21, 38, 13, 52, 31, 35]
episode: 888 -> reward: -124.999999999992, steps:52224, time-elasped: 162704.71s
-> berries picked: 13 of 800 | patches-visited: [5] | positive-in-buffer: 17264 | amount-filled: 100.00%
	| epsilon: 0.24449942235239255
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [977, 2118, 1788, 2828, 1293, 3935, 2126, 2199]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 24, 30, 41, 19, 54, 28, 22]
episode: 889 -> reward: -124.99999999999162, steps:62304, time-elasped: 162937.72s
-> berries picked: 50 of 800 | patches-visited: [3] | positive-in-buffer: 17305 | amount-filled: 100.00%
	| epsilon: 0.24430274817677353
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [980, 2134, 1789, 2835, 1293, 3944, 2129, 2201]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 17, 28, 35, 13, 69, 33, 28]
episode: 890 -> reward: -124.99999999999113, steps:57792, time-elasped: 163178.88s
-> berries picked: 35 of 800 | patches-visited: [3] | positive-in-buffer: 17329 | amount-filled: 100.00%
	| epsilon: 0.2441062322049285
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [980, 2137, 1789, 2841, 1296, 3951, 2132, 2203]
	| approx positives in sample 512: 226
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 23, 25, 33, 18, 63, 29, 26]
episode: 891 -> reward: -124.99999999998995, steps:69696, time-elasped: 163402.35s
-> berries picked: 80 of 800 | patches-visited: [1, 4] | positive-in-buffer: 17365 | amount-filled: 100.00%
	| epsilon: 0.24390987430959907
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [986, 2144, 1788, 2847, 1297, 3960, 2135, 2208]
	| approx positives in sample 512: 236
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 30, 19, 34, 18, 60, 30, 29]
episode: 892 -> reward: -124.99999999998431, steps:79104, time-elasped: 163657.43s
-> berries picked: 110 of 800 | patches-visited: [1, 6, 8] | positive-in-buffer: 17252 | amount-filled: 100.00%
	| epsilon: 0.2437136743636293
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [975, 2124, 1774, 2840, 1285, 3948, 2122, 2184]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 28, 24, 36, 21, 56, 35, 25]
episode: 893 -> reward: -124.99999999999365, steps:62400, time-elasped: 163860.43s
-> berries picked: 59 of 800 | patches-visited: [0, 1] | positive-in-buffer: 17296 | amount-filled: 100.00%
	| epsilon: 0.24351763223996545
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [977, 2128, 1778, 2848, 1288, 3960, 2126, 2191]
	| approx positives in sample 512: 241
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 29, 21, 39, 10, 76, 37, 21]
episode: 894 -> reward: -124.99999999999203, steps:51264, time-elasped: 164054.00s
-> berries picked: 11 of 800 | patches-visited: [1] | positive-in-buffer: 17291 | amount-filled: 100.00%
	| epsilon: 0.24332174781165597
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [977, 2128, 1777, 2847, 1289, 3957, 2123, 2193]
	| approx positives in sample 512: 230
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 30, 24, 38, 20, 41, 31, 32]
episode: 895 -> reward: -124.99999999999064, steps:82752, time-elasped: 164290.42s
-> berries picked: 132 of 800 | patches-visited: [3, 5, 7] | positive-in-buffer: 17199 | amount-filled: 100.00%
	| epsilon: 0.2431260209518515
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [969, 2138, 1759, 2824, 1279, 3930, 2117, 2183]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 36, 19, 35, 14, 49, 24, 25]
episode: 896 -> reward: -124.9999999999916, steps:55968, time-elasped: 164514.97s
-> berries picked: 30 of 800 | patches-visited: [7] | positive-in-buffer: 17210 | amount-filled: 100.00%
	| epsilon: 0.24293045153380471
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [972, 2139, 1758, 2828, 1277, 3939, 2117, 2180]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 27, 28, 43, 13, 53, 27, 29]
episode: 897 -> reward: -124.99999999998612, steps:72768, time-elasped: 164750.99s
-> berries picked: 91 of 800 | patches-visited: [2, 5, 6] | positive-in-buffer: 17262 | amount-filled: 100.00%
	| epsilon: 0.2427350394308701
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [974, 2155, 1756, 2833, 1281, 3952, 2127, 2184]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 30, 17, 34, 12, 63, 27, 27]
episode: 898 -> reward: -124.99999999999203, steps:49824, time-elasped: 164937.88s
-> berries picked: 5 of 800 | patches-visited: [7] | positive-in-buffer: 17262 | amount-filled: 100.00%
	| epsilon: 0.24253978451650426
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [974, 2156, 1756, 2832, 1281, 3950, 2127, 2186]
	| approx positives in sample 512: 235
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 33, 23, 34, 12, 68, 32, 20]
episode: 899 -> reward: -124.99999999998889, steps:65856, time-elasped: 165174.07s
-> berries picked: 63 of 800 | patches-visited: [2, 8] | positive-in-buffer: 17311 | amount-filled: 100.00%
	| epsilon: 0.24234468666426537
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [974, 2170, 1763, 2837, 1281, 3966, 2135, 2185]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 22, 26, 32, 23, 57, 30, 29]
episode: 900 -> reward: -124.99999999998799, steps:65376, time-elasped: 165387.63s
-> berries picked: 71 of 800 | patches-visited: [3] | positive-in-buffer: 17339 | amount-filled: 100.00%
	| epsilon: 0.24214974574781345
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [977, 2172, 1763, 2838, 1290, 3972, 2141, 2186]
	| approx positives in sample 512: 248
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 30, 27, 36, 15, 65, 32, 24]
episode: 901 -> reward: -124.99999999999204, steps:59424, time-elasped: 165580.04s
-> berries picked: 45 of 800 | patches-visited: [0] | positive-in-buffer: 17357 | amount-filled: 100.00%
	| epsilon: 0.24195496164091004
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [975, 2178, 1767, 2842, 1295, 3970, 2142, 2188]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 27, 28, 38, 18, 53, 20, 31]
episode: 902 -> reward: -124.99999999999194, steps:56640, time-elasped: 165786.33s
-> berries picked: 34 of 800 | patches-visited: [0] | positive-in-buffer: 17378 | amount-filled: 100.00%
	| epsilon: 0.24176033421741833
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [977, 2180, 1769, 2848, 1294, 3974, 2146, 2190]
	| approx positives in sample 512: 238
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 26, 19, 53, 19, 43, 35, 28]
episode: 903 -> reward: -124.99999999999208, steps:55968, time-elasped: 166007.54s
-> berries picked: 27 of 800 | patches-visited: [7, 9] | positive-in-buffer: 17377 | amount-filled: 100.00%
	| epsilon: 0.24156586335130287
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [977, 2184, 1770, 2848, 1294, 3969, 2145, 2190]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 31, 21, 36, 12, 53, 34, 23]
episode: 904 -> reward: -124.99999999999169, steps:58368, time-elasped: 166226.65s
-> berries picked: 38 of 800 | patches-visited: [9] | positive-in-buffer: 17389 | amount-filled: 100.00%
	| epsilon: 0.24137154891662974
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [978, 2189, 1769, 2847, 1291, 3978, 2147, 2190]
	| approx positives in sample 512: 237
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 33, 19, 41, 22, 59, 24, 28]
episode: 905 -> reward: -124.99999999999201, steps:55584, time-elasped: 166421.41s
-> berries picked: 30 of 800 | patches-visited: [2] | positive-in-buffer: 17404 | amount-filled: 100.00%
	| epsilon: 0.24117739078756614
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [976, 2190, 1770, 2852, 1292, 3986, 2151, 2187]
	| approx positives in sample 512: 226
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 24, 26, 34, 14, 58, 34, 27]
episode: 906 -> reward: -124.99999999999208, steps:57696, time-elasped: 166647.00s
-> berries picked: 32 of 800 | patches-visited: [7] | positive-in-buffer: 17388 | amount-filled: 100.00%
	| epsilon: 0.24098338883838066
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [975, 2197, 1768, 2853, 1289, 3974, 2148, 2184]
	| approx positives in sample 512: 238
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 27, 23, 35, 14, 60, 28, 33]
episode: 907 -> reward: -124.99999999999193, steps:54432, time-elasped: 166842.60s
-> berries picked: 25 of 800 | patches-visited: [8] | positive-in-buffer: 17400 | amount-filled: 100.00%
	| epsilon: 0.24078954294344287
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [977, 2201, 1768, 2854, 1291, 3975, 2149, 2185]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 30, 22, 24, 16, 53, 36, 29]
episode: 908 -> reward: -124.99999999999173, steps:56736, time-elasped: 167042.25s
-> berries picked: 29 of 800 | patches-visited: [1, 9] | positive-in-buffer: 17382 | amount-filled: 100.00%
	| epsilon: 0.24059585297722355
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [977, 2201, 1768, 2850, 1285, 3974, 2142, 2185]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 25, 30, 29, 13, 44, 32, 40]
episode: 909 -> reward: -124.99999999999203, steps:49824, time-elasped: 167225.87s
-> berries picked: 7 of 800 | patches-visited: [0] | positive-in-buffer: 17387 | amount-filled: 100.00%
	| epsilon: 0.24040231881429427
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [978, 2203, 1769, 2852, 1285, 3974, 2142, 2184]
	| approx positives in sample 512: 238
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 30, 20, 29, 21, 59, 38, 29]
episode: 910 -> reward: -124.99999999999216, steps:57504, time-elasped: 167429.95s
-> berries picked: 29 of 800 | patches-visited: [1, 2] | positive-in-buffer: 17363 | amount-filled: 100.00%
	| epsilon: 0.24020894032932774
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [977, 2200, 1765, 2854, 1286, 3966, 2141, 2174]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 29, 15, 38, 24, 56, 32, 23]
episode: 911 -> reward: -124.999999999992, steps:50976, time-elasped: 167619.65s
-> berries picked: 11 of 800 | patches-visited: [7] | positive-in-buffer: 17372 | amount-filled: 100.00%
	| epsilon: 0.24001571739709723
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [978, 2201, 1768, 2855, 1286, 3968, 2142, 2174]
	| approx positives in sample 512: 236
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 24, 22, 41, 13, 63, 33, 25]
episode: 912 -> reward: -124.99999999999204, steps:50592, time-elasped: 167825.81s
-> berries picked: 10 of 800 | patches-visited: [2] | positive-in-buffer: 17377 | amount-filled: 100.00%
	| epsilon: 0.23982264989247692
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [979, 2202, 1768, 2856, 1287, 3968, 2143, 2174]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 27, 14, 32, 20, 56, 32, 35]
episode: 913 -> reward: -124.99999999998795, steps:85152, time-elasped: 168064.61s
-> berries picked: 142 of 800 | patches-visited: [0, 2] | positive-in-buffer: 17157 | amount-filled: 100.00%
	| epsilon: 0.23962973769044157
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [973, 2167, 1742, 2819, 1265, 3932, 2130, 2129]
	| approx positives in sample 512: 244
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 35, 30, 33, 13, 59, 33, 29]
episode: 914 -> reward: -124.99999999999034, steps:60192, time-elasped: 168268.76s
-> berries picked: 46 of 800 | patches-visited: [8] | positive-in-buffer: 17190 | amount-filled: 100.00%
	| epsilon: 0.2394369806660665
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [980, 2175, 1742, 2825, 1267, 3937, 2135, 2129]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 28, 19, 39, 13, 54, 31, 39]
episode: 915 -> reward: -124.99999999999162, steps:57984, time-elasped: 168486.39s
-> berries picked: 33 of 800 | patches-visited: [5] | positive-in-buffer: 17215 | amount-filled: 100.00%
	| epsilon: 0.23924437869452755
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [979, 2188, 1742, 2827, 1267, 3947, 2134, 2131]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 31, 26, 36, 13, 59, 30, 19]
episode: 916 -> reward: -124.99999999998788, steps:66048, time-elasped: 168712.20s
-> berries picked: 62 of 800 | patches-visited: [4, 8] | positive-in-buffer: 17261 | amount-filled: 100.00%
	| epsilon: 0.23905193165110092
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [979, 2195, 1748, 2836, 1269, 3961, 2139, 2134]
	| approx positives in sample 512: 211
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 33, 22, 32, 12, 56, 30, 18]
episode: 917 -> reward: -124.99999999998933, steps:61440, time-elasped: 168921.20s
-> berries picked: 48 of 800 | patches-visited: [3] | positive-in-buffer: 17287 | amount-filled: 100.00%
	| epsilon: 0.23885963941116323
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [981, 2210, 1749, 2842, 1269, 3965, 2135, 2136]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 21, 22, 30, 15, 54, 29, 34]
episode: 918 -> reward: -124.99999999999207, steps:58176, time-elasped: 169125.99s
-> berries picked: 36 of 800 | patches-visited: [5] | positive-in-buffer: 17309 | amount-filled: 100.00%
	| epsilon: 0.23866750185019123
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [984, 2211, 1748, 2847, 1271, 3973, 2133, 2142]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 20, 19, 46, 17, 56, 28, 31]
episode: 919 -> reward: -124.99999999999093, steps:63360, time-elasped: 169318.09s
-> berries picked: 56 of 800 | patches-visited: [4, 7] | positive-in-buffer: 17309 | amount-filled: 100.00%
	| epsilon: 0.23847551884376195
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [975, 2218, 1751, 2852, 1269, 3973, 2132, 2139]
	| approx positives in sample 512: 245
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 23, 22, 50, 17, 56, 29, 34]
episode: 920 -> reward: -124.9999999999917, steps:57024, time-elasped: 169553.27s
-> berries picked: 35 of 800 | patches-visited: [4, 5] | positive-in-buffer: 17331 | amount-filled: 100.00%
	| epsilon: 0.2382836902675524
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [981, 2221, 1750, 2856, 1270, 3978, 2134, 2141]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 35, 20, 33, 13, 56, 28, 27]
episode: 921 -> reward: -124.99999999999186, steps:52032, time-elasped: 169767.34s
-> berries picked: 15 of 800 | patches-visited: [5] | positive-in-buffer: 17325 | amount-filled: 100.00%
	| epsilon: 0.23809201599733965
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [980, 2225, 1751, 2857, 1272, 3967, 2132, 2141]
	| approx positives in sample 512: 246
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 28, 23, 31, 18, 63, 44, 26]
episode: 922 -> reward: -124.99999999999159, steps:63936, time-elasped: 169976.49s
-> berries picked: 58 of 800 | patches-visited: [1] | positive-in-buffer: 17248 | amount-filled: 100.00%
	| epsilon: 0.2379004959090007
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [979, 2222, 1745, 2846, 1261, 3935, 2119, 2141]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 29, 25, 37, 16, 59, 36, 22]
episode: 923 -> reward: -124.99999999999253, steps:69984, time-elasped: 170203.04s
-> berries picked: 84 of 800 | patches-visited: [1, 7] | positive-in-buffer: 17233 | amount-filled: 100.00%
	| epsilon: 0.2377091298785124
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [981, 2231, 1746, 2842, 1256, 3920, 2126, 2131]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 27, 28, 27, 16, 56, 26, 25]
episode: 924 -> reward: -124.99999999999132, steps:66048, time-elasped: 170431.45s
-> berries picked: 74 of 800 | patches-visited: [2] | positive-in-buffer: 17280 | amount-filled: 100.00%
	| epsilon: 0.23751791778195133
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [981, 2240, 1746, 2852, 1256, 3931, 2138, 2136]
	| approx positives in sample 512: 208
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 22, 25, 32, 15, 59, 25, 24]
episode: 925 -> reward: -124.99999999999201, steps:52416, time-elasped: 170626.75s
-> berries picked: 15 of 800 | patches-visited: [7] | positive-in-buffer: 17288 | amount-filled: 100.00%
	| epsilon: 0.23732685949549376
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [980, 2243, 1747, 2854, 1256, 3932, 2138, 2138]
	| approx positives in sample 512: 239
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 29, 26, 33, 16, 51, 30, 37]
episode: 926 -> reward: -124.9999999999857, steps:78432, time-elasped: 170888.86s
-> berries picked: 112 of 800 | patches-visited: [2, 3, 5] | positive-in-buffer: 17134 | amount-filled: 100.00%
	| epsilon: 0.23713595489541558
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [972, 2239, 1730, 2811, 1244, 3876, 2129, 2133]
	| approx positives in sample 512: 233
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 18, 32, 31, 20, 53, 37, 30]
episode: 927 -> reward: -124.99999999999203, steps:72288, time-elasped: 171122.81s
-> berries picked: 94 of 800 | patches-visited: [2, 4] | positive-in-buffer: 17198 | amount-filled: 100.00%
	| epsilon: 0.2369452038580922
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [972, 2251, 1733, 2827, 1249, 3888, 2134, 2144]
	| approx positives in sample 512: 238
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 33, 21, 38, 13, 54, 38, 30]
episode: 928 -> reward: -124.99999999999402, steps:69504, time-elasped: 171339.61s
-> berries picked: 79 of 800 | patches-visited: [3, 8] | positive-in-buffer: 17232 | amount-filled: 100.00%
	| epsilon: 0.23675460625999845
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [973, 2270, 1734, 2831, 1257, 3888, 2135, 2144]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 25, 27, 27, 15, 68, 28, 26]
episode: 929 -> reward: -124.99999999999201, steps:55296, time-elasped: 171564.35s
-> berries picked: 26 of 800 | patches-visited: [4] | positive-in-buffer: 17239 | amount-filled: 100.00%
	| epsilon: 0.23656416197770855
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [977, 2266, 1734, 2836, 1257, 3889, 2136, 2144]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 24, 18, 36, 19, 58, 25, 30]
episode: 930 -> reward: -124.9999999999911, steps:57792, time-elasped: 171795.42s
-> berries picked: 35 of 800 | patches-visited: [7] | positive-in-buffer: 17248 | amount-filled: 100.00%
	| epsilon: 0.23637387088789602
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [977, 2264, 1735, 2838, 1260, 3895, 2133, 2146]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 29, 25, 31, 17, 53, 34, 21]
episode: 931 -> reward: -124.99999999999204, steps:61440, time-elasped: 172000.57s
-> berries picked: 52 of 800 | patches-visited: [6] | positive-in-buffer: 17239 | amount-filled: 100.00%
	| epsilon: 0.23618373286733355
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [983, 2272, 1736, 2835, 1253, 3882, 2133, 2145]
	| approx positives in sample 512: 237
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 35, 18, 35, 16, 72, 24, 25]
episode: 932 -> reward: -124.99999999998624, steps:80832, time-elasped: 172250.43s
-> berries picked: 134 of 800 | patches-visited: [1, 6] | positive-in-buffer: 17069 | amount-filled: 100.00%
	| epsilon: 0.23599374779289292
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [987, 2277, 1724, 2798, 1216, 3820, 2112, 2135]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 38, 13, 36, 16, 52, 27, 18]
episode: 933 -> reward: -124.99999999999268, steps:58080, time-elasped: 172468.58s
-> berries picked: 42 of 800 | patches-visited: [6] | positive-in-buffer: 17098 | amount-filled: 100.00%
	| epsilon: 0.23580391554154503
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [987, 2284, 1725, 2801, 1220, 3826, 2114, 2141]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 27, 28, 28, 15, 56, 25, 36]
episode: 934 -> reward: -124.99999999999201, steps:57504, time-elasped: 172667.80s
-> berries picked: 33 of 800 | patches-visited: [0] | positive-in-buffer: 17116 | amount-filled: 100.00%
	| epsilon: 0.2356142359903597
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [987, 2292, 1727, 2805, 1221, 3825, 2115, 2144]
	| approx positives in sample 512: 235
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 27, 26, 42, 21, 48, 27, 37]
episode: 935 -> reward: -124.99999999999203, steps:58656, time-elasped: 172868.89s
-> berries picked: 36 of 800 | patches-visited: [3] | positive-in-buffer: 17133 | amount-filled: 100.00%
	| epsilon: 0.23542470901650567
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [991, 2294, 1729, 2807, 1220, 3824, 2120, 2148]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 23, 25, 32, 18, 60, 31, 28]
episode: 936 -> reward: -124.99999999999204, steps:69408, time-elasped: 173098.45s
-> berries picked: 82 of 800 | patches-visited: [6, 8] | positive-in-buffer: 17149 | amount-filled: 100.00%
	| epsilon: 0.2352353344972504
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [999, 2297, 1731, 2810, 1214, 3823, 2125, 2150]
	| approx positives in sample 512: 234
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 34, 21, 41, 20, 50, 28, 28]
episode: 937 -> reward: -124.99999999998336, steps:93888, time-elasped: 173351.28s
-> berries picked: 177 of 800 | patches-visited: [4, 5, 8] | positive-in-buffer: 16885 | amount-filled: 100.00%
	| epsilon: 0.2350461123099602
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [973, 2268, 1721, 2772, 1168, 3742, 2112, 2129]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 32, 21, 40, 20, 51, 27, 19]
episode: 938 -> reward: -124.9999999999868, steps:65568, time-elasped: 173562.86s
-> berries picked: 74 of 800 | patches-visited: [5] | positive-in-buffer: 16953 | amount-filled: 100.00%
	| epsilon: 0.23485704233209992
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [974, 2285, 1723, 2781, 1170, 3759, 2116, 2145]
	| approx positives in sample 512: 234
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 34, 13, 37, 12, 64, 37, 28]
episode: 939 -> reward: -124.99999999998303, steps:71232, time-elasped: 173797.02s
-> berries picked: 87 of 800 | patches-visited: [1, 6] | positive-in-buffer: 17004 | amount-filled: 100.00%
	| epsilon: 0.23466812444123303
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [980, 2291, 1726, 2785, 1171, 3778, 2125, 2148]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 27, 13, 55, 8, 45, 33, 35]
episode: 940 -> reward: -124.99999999999204, steps:63648, time-elasped: 174008.06s
-> berries picked: 63 of 800 | patches-visited: [1] | positive-in-buffer: 17045 | amount-filled: 100.00%
	| epsilon: 0.23447935851502144
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [981, 2305, 1727, 2793, 1176, 3786, 2127, 2150]
	| approx positives in sample 512: 242
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 36, 28, 34, 21, 49, 33, 29]
episode: 941 -> reward: -124.99999999998793, steps:68064, time-elasped: 174237.03s
-> berries picked: 78 of 800 | patches-visited: [2] | positive-in-buffer: 17083 | amount-filled: 100.00%
	| epsilon: 0.23429074443122555
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [985, 2317, 1730, 2803, 1177, 3782, 2132, 2157]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 25, 21, 35, 17, 54, 28, 25]
episode: 942 -> reward: -124.99999999999099, steps:59520, time-elasped: 174464.12s
-> berries picked: 45 of 800 | patches-visited: [0] | positive-in-buffer: 17113 | amount-filled: 100.00%
	| epsilon: 0.23410228206770403
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [986, 2324, 1731, 2804, 1178, 3789, 2136, 2165]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 21, 26, 30, 18, 44, 36, 31]
episode: 943 -> reward: -124.99999999999201, steps:56448, time-elasped: 174662.21s
-> berries picked: 29 of 800 | patches-visited: [0, 9] | positive-in-buffer: 17127 | amount-filled: 100.00%
	| epsilon: 0.2339139713024138
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [985, 2330, 1732, 2809, 1181, 3792, 2136, 2162]
	| approx positives in sample 512: 241
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 33, 20, 32, 11, 72, 32, 30]
episode: 944 -> reward: -124.9999999999922, steps:67680, time-elasped: 174886.31s
-> berries picked: 85 of 800 | patches-visited: [8, 9] | positive-in-buffer: 17112 | amount-filled: 100.00%
	| epsilon: 0.23372581201340997
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [982, 2334, 1729, 2816, 1178, 3773, 2146, 2154]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 35, 18, 26, 20, 55, 32, 33]
episode: 945 -> reward: -124.9999999999895, steps:57312, time-elasped: 175112.97s
-> berries picked: 38 of 800 | patches-visited: [3, 9] | positive-in-buffer: 17132 | amount-filled: 100.00%
	| epsilon: 0.23353780407884572
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [984, 2337, 1729, 2818, 1179, 3781, 2143, 2161]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 30, 23, 44, 11, 43, 35, 24]
episode: 946 -> reward: -124.99999999999096, steps:57024, time-elasped: 175333.17s
-> berries picked: 32 of 800 | patches-visited: [3] | positive-in-buffer: 17138 | amount-filled: 100.00%
	| epsilon: 0.23334994737697223
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [987, 2344, 1729, 2816, 1180, 3779, 2143, 2160]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 26, 16, 41, 12, 56, 30, 31]
episode: 947 -> reward: -124.99999999999088, steps:61152, time-elasped: 175551.74s
-> berries picked: 45 of 800 | patches-visited: [9] | positive-in-buffer: 17086 | amount-filled: 100.00%
	| epsilon: 0.23316224178613873
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [988, 2329, 1726, 2812, 1176, 3756, 2137, 2162]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 33, 23, 43, 14, 41, 35, 28]
episode: 948 -> reward: -124.99999999999227, steps:61152, time-elasped: 175751.70s
-> berries picked: 48 of 800 | patches-visited: [0] | positive-in-buffer: 17084 | amount-filled: 100.00%
	| epsilon: 0.23297468718479214
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [988, 2332, 1726, 2817, 1170, 3746, 2136, 2169]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 27, 20, 38, 13, 45, 28, 35]
episode: 949 -> reward: -124.99999999999163, steps:81216, time-elasped: 175979.42s
-> berries picked: 123 of 800 | patches-visited: [6, 9] | positive-in-buffer: 16891 | amount-filled: 100.00%
	| epsilon: 0.23278728345147726
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [967, 2312, 1710, 2783, 1156, 3696, 2126, 2141]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 31, 24, 42, 18, 51, 23, 29]
episode: 950 -> reward: -124.99999999999044, steps:70944, time-elasped: 176206.56s
-> berries picked: 96 of 800 | patches-visited: [6, 8] | positive-in-buffer: 16962 | amount-filled: 100.00%
	| epsilon: 0.23260003046483657
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [970, 2336, 1709, 2787, 1156, 3715, 2135, 2154]
	| approx positives in sample 512: 246
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 29, 18, 44, 15, 50, 30, 33]
episode: 951 -> reward: -124.99999999999203, steps:53952, time-elasped: 176418.46s
-> berries picked: 21 of 800 | patches-visited: [0] | positive-in-buffer: 16969 | amount-filled: 100.00%
	| epsilon: 0.23241292810361014
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [974, 2337, 1710, 2787, 1157, 3716, 2134, 2154]
	| approx positives in sample 512: 223
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 30, 18, 34, 15, 56, 33, 29]
episode: 952 -> reward: -124.99999999999305, steps:71040, time-elasped: 176637.19s
-> berries picked: 89 of 800 | patches-visited: [0, 3] | positive-in-buffer: 16947 | amount-filled: 100.00%
	| epsilon: 0.2322259762466356
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [975, 2342, 1710, 2780, 1151, 3692, 2132, 2165]
	| approx positives in sample 512: 234
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 28, 22, 41, 16, 62, 29, 26]
episode: 953 -> reward: -124.99999999999189, steps:66336, time-elasped: 176859.94s
-> berries picked: 76 of 800 | patches-visited: [2, 8] | positive-in-buffer: 16924 | amount-filled: 100.00%
	| epsilon: 0.23203917477284802
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [968, 2342, 1709, 2779, 1144, 3683, 2136, 2163]
	| approx positives in sample 512: 245
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 29, 28, 40, 15, 61, 38, 24]
episode: 954 -> reward: -124.99999999998991, steps:64704, time-elasped: 177066.00s
-> berries picked: 66 of 800 | patches-visited: [0] | positive-in-buffer: 16948 | amount-filled: 100.00%
	| epsilon: 0.23185252356127994
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [967, 2344, 1708, 2789, 1146, 3684, 2139, 2171]
	| approx positives in sample 512: 238
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 26, 22, 42, 14, 52, 34, 29]
episode: 955 -> reward: -124.99999999999001, steps:55584, time-elasped: 177286.62s
-> berries picked: 26 of 800 | patches-visited: [4] | positive-in-buffer: 16966 | amount-filled: 100.00%
	| epsilon: 0.23166602249106114
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [967, 2344, 1710, 2788, 1150, 3690, 2144, 2173]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 34, 31, 42, 11, 46, 22, 31]
episode: 956 -> reward: -124.99999999998768, steps:86496, time-elasped: 177537.29s
-> berries picked: 143 of 800 | patches-visited: [0, 3, 6, 7] | positive-in-buffer: 16706 | amount-filled: 100.00%
	| epsilon: 0.23147967144141857
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [959, 2289, 1696, 2741, 1114, 3631, 2129, 2147]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 28, 13, 43, 16, 57, 31, 23]
episode: 957 -> reward: -124.99999999999221, steps:56640, time-elasped: 177763.81s
-> berries picked: 32 of 800 | patches-visited: [3, 4] | positive-in-buffer: 16733 | amount-filled: 100.00%
	| epsilon: 0.23129347029167643
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [961, 2295, 1697, 2744, 1115, 3634, 2134, 2153]
	| approx positives in sample 512: 237
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 23, 29, 46, 19, 58, 29, 24]
episode: 958 -> reward: -124.99999999998826, steps:59424, time-elasped: 177974.29s
-> berries picked: 43 of 800 | patches-visited: [3] | positive-in-buffer: 16769 | amount-filled: 100.00%
	| epsilon: 0.23110741892125594
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [963, 2302, 1700, 2748, 1116, 3641, 2139, 2160]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 20, 23, 35, 13, 56, 28, 28]
episode: 959 -> reward: -124.99999999999109, steps:71136, time-elasped: 178201.83s
-> berries picked: 90 of 800 | patches-visited: [7, 8] | positive-in-buffer: 16806 | amount-filled: 100.00%
	| epsilon: 0.23092151720967533
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [962, 2313, 1708, 2757, 1113, 3644, 2148, 2161]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 27, 24, 39, 15, 46, 22, 33]
episode: 960 -> reward: -124.99999999999308, steps:56928, time-elasped: 178409.89s
-> berries picked: 28 of 800 | patches-visited: [3, 7] | positive-in-buffer: 16820 | amount-filled: 100.00%
	| epsilon: 0.23073576503654974
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [967, 2316, 1713, 2758, 1113, 3644, 2147, 2162]
	| approx positives in sample 512: 202
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 27, 19, 27, 16, 52, 26, 26]
episode: 961 -> reward: -124.99999999999054, steps:64416, time-elasped: 178624.15s
-> berries picked: 66 of 800 | patches-visited: [1] | positive-in-buffer: 16843 | amount-filled: 100.00%
	| epsilon: 0.23055016228159114
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [970, 2317, 1716, 2766, 1116, 3645, 2147, 2166]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 34, 18, 37, 17, 57, 27, 20]
episode: 962 -> reward: -124.99999999998637, steps:71040, time-elasped: 178842.90s
-> berries picked: 80 of 800 | patches-visited: [0, 3, 8] | positive-in-buffer: 16787 | amount-filled: 100.00%
	| epsilon: 0.23036470882460827
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [962, 2319, 1712, 2765, 1110, 3625, 2147, 2147]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 31, 27, 33, 20, 36, 22, 32]
episode: 963 -> reward: -124.99999999999211, steps:57888, time-elasped: 179063.14s
-> berries picked: 33 of 800 | patches-visited: [9] | positive-in-buffer: 16813 | amount-filled: 100.00%
	| epsilon: 0.23017940454550656
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [970, 2325, 1713, 2766, 1111, 3627, 2149, 2152]
	| approx positives in sample 512: 210
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 17, 20, 33, 17, 49, 27, 35]
episode: 964 -> reward: -124.99999999998957, steps:65088, time-elasped: 179279.88s
-> berries picked: 71 of 800 | patches-visited: [6] | positive-in-buffer: 16849 | amount-filled: 100.00%
	| epsilon: 0.22999424932428802
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [970, 2342, 1717, 2769, 1114, 3630, 2150, 2157]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 33, 18, 39, 15, 41, 35, 30]
episode: 965 -> reward: -124.99999999999045, steps:67200, time-elasped: 179499.87s
-> berries picked: 78 of 800 | patches-visited: [6, 7] | positive-in-buffer: 16836 | amount-filled: 100.00%
	| epsilon: 0.22980924304105113
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [976, 2346, 1715, 2769, 1109, 3615, 2151, 2155]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 18, 24, 35, 25, 56, 27, 28]
episode: 966 -> reward: -124.99999999999079, steps:61440, time-elasped: 179714.00s
-> berries picked: 51 of 800 | patches-visited: [9] | positive-in-buffer: 16871 | amount-filled: 100.00%
	| epsilon: 0.22962438557599102
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [975, 2356, 1718, 2776, 1112, 3620, 2155, 2159]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 18, 21, 32, 22, 36, 29, 50]
episode: 967 -> reward: -124.99999999999031, steps:53376, time-elasped: 179932.41s
-> berries picked: 19 of 800 | patches-visited: [0] | positive-in-buffer: 16880 | amount-filled: 100.00%
	| epsilon: 0.22943967680939895
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [975, 2360, 1721, 2780, 1111, 3620, 2154, 2159]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 18, 20, 36, 18, 54, 41, 23]
episode: 968 -> reward: -124.99999999999166, steps:63936, time-elasped: 180147.71s
-> berries picked: 65 of 800 | patches-visited: [4] | positive-in-buffer: 16874 | amount-filled: 100.00%
	| epsilon: 0.2292551166216626
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [969, 2359, 1717, 2780, 1113, 3620, 2156, 2160]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 34, 16, 39, 19, 39, 34, 25]
episode: 969 -> reward: -124.99999999999208, steps:68064, time-elasped: 180349.75s
-> berries picked: 73 of 800 | patches-visited: [9] | positive-in-buffer: 16801 | amount-filled: 100.00%
	| epsilon: 0.22907070489326586
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [966, 2353, 1715, 2781, 1110, 3584, 2153, 2139]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 28, 35, 34, 14, 35, 33, 24]
episode: 970 -> reward: -124.99999999999065, steps:75936, time-elasped: 180585.66s
-> berries picked: 109 of 800 | patches-visited: [4, 8] | positive-in-buffer: 16736 | amount-filled: 100.00%
	| epsilon: 0.22888644150478873
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [962, 2345, 1714, 2783, 1101, 3572, 2135, 2124]
	| approx positives in sample 512: 204
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 36, 23, 35, 10, 34, 23, 32]
episode: 971 -> reward: -124.99999999998798, steps:75072, time-elasped: 180810.27s
-> berries picked: 108 of 800 | patches-visited: [4, 6, 7] | positive-in-buffer: 16770 | amount-filled: 100.00%
	| epsilon: 0.22870232633690726
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [971, 2348, 1716, 2789, 1104, 3577, 2137, 2128]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 30, 14, 36, 18, 44, 35, 26]
episode: 972 -> reward: -124.99999999999204, steps:51936, time-elasped: 181013.78s
-> berries picked: 17 of 800 | patches-visited: [0] | positive-in-buffer: 16782 | amount-filled: 100.00%
	| epsilon: 0.22851835927039357
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [973, 2352, 1717, 2790, 1104, 3579, 2137, 2130]
	| approx positives in sample 512: 235
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 33, 27, 25, 16, 47, 38, 35]
episode: 973 -> reward: -124.99999999999052, steps:56256, time-elasped: 181243.81s
-> berries picked: 29 of 800 | patches-visited: [6] | positive-in-buffer: 16804 | amount-filled: 100.00%
	| epsilon: 0.22833454018611557
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [974, 2354, 1717, 2794, 1109, 3585, 2136, 2135]
	| approx positives in sample 512: 234
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 28, 13, 33, 15, 54, 32, 42]
episode: 974 -> reward: -124.99999999999352, steps:62304, time-elasped: 181470.31s
-> berries picked: 51 of 800 | patches-visited: [7, 8] | positive-in-buffer: 16822 | amount-filled: 100.00%
	| epsilon: 0.22815086896503706
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [977, 2360, 1717, 2794, 1109, 3591, 2136, 2138]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 36, 24, 35, 19, 52, 27, 22]
episode: 975 -> reward: -124.99999999998765, steps:80064, time-elasped: 181696.28s
-> berries picked: 126 of 800 | patches-visited: [1, 2, 3, 8] | positive-in-buffer: 16663 | amount-filled: 100.00%
	| epsilon: 0.2279673454882176
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [954, 2354, 1696, 2766, 1090, 3552, 2118, 2133]
	| approx positives in sample 512: 242
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 31, 20, 46, 17, 49, 34, 28]
episode: 976 -> reward: -124.99999999998921, steps:60672, time-elasped: 181907.65s
-> berries picked: 45 of 800 | patches-visited: [3, 6] | positive-in-buffer: 16686 | amount-filled: 100.00%
	| epsilon: 0.22778396963681238
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [960, 2359, 1699, 2769, 1090, 3555, 2113, 2141]
	| approx positives in sample 512: 238
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 26, 28, 42, 16, 53, 31, 33]
episode: 977 -> reward: -124.99999999999123, steps:65568, time-elasped: 182113.96s
-> berries picked: 72 of 800 | patches-visited: [7] | positive-in-buffer: 16733 | amount-filled: 100.00%
	| epsilon: 0.22760074129207222
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [962, 2367, 1700, 2776, 1096, 3562, 2120, 2150]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 31, 35, 35, 10, 47, 16, 35]
episode: 978 -> reward: -124.99999999999274, steps:64800, time-elasped: 182335.11s
-> berries picked: 58 of 800 | patches-visited: [2, 9] | positive-in-buffer: 16748 | amount-filled: 100.00%
	| epsilon: 0.2274176603353435
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [964, 2373, 1702, 2782, 1097, 3561, 2116, 2153]
	| approx positives in sample 512: 223
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 36, 27, 40, 13, 48, 28, 20]
episode: 979 -> reward: -124.9999999999921, steps:65664, time-elasped: 182539.51s
-> berries picked: 74 of 800 | patches-visited: [7] | positive-in-buffer: 16778 | amount-filled: 100.00%
	| epsilon: 0.22723472664806796
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [963, 2388, 1706, 2787, 1093, 3564, 2119, 2158]
	| approx positives in sample 512: 223
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 42, 23, 25, 10, 54, 29, 33]
episode: 980 -> reward: -124.99999999999218, steps:56160, time-elasped: 182727.31s
-> berries picked: 28 of 800 | patches-visited: [2] | positive-in-buffer: 16789 | amount-filled: 100.00%
	| epsilon: 0.22705194011178276
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [966, 2389, 1707, 2792, 1093, 3563, 2121, 2158]
	| approx positives in sample 512: 211
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 34, 16, 36, 12, 57, 22, 21]
episode: 981 -> reward: -124.99999999999203, steps:51936, time-elasped: 182926.39s
-> berries picked: 16 of 800 | patches-visited: [0] | positive-in-buffer: 16801 | amount-filled: 100.00%
	| epsilon: 0.22686930060812036
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [968, 2394, 1707, 2792, 1093, 3566, 2121, 2160]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 25, 20, 31, 20, 43, 30, 31]
episode: 982 -> reward: -124.99999999999177, steps:72096, time-elasped: 183132.59s
-> berries picked: 93 of 800 | patches-visited: [5, 7] | positive-in-buffer: 16691 | amount-filled: 100.00%
	| epsilon: 0.22668680801880842
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [963, 2389, 1692, 2780, 1090, 3532, 2110, 2135]
	| approx positives in sample 512: 223
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 29, 22, 42, 19, 44, 31, 19]
episode: 983 -> reward: -124.99999999999187, steps:73056, time-elasped: 183362.58s
-> berries picked: 99 of 800 | patches-visited: [0, 4, 9] | positive-in-buffer: 16672 | amount-filled: 100.00%
	| epsilon: 0.22650446222566967
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [958, 2394, 1695, 2777, 1087, 3524, 2106, 2131]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 35, 21, 35, 16, 45, 28, 23]
episode: 984 -> reward: -124.9999999999917, steps:58272, time-elasped: 183578.15s
-> berries picked: 38 of 800 | patches-visited: [1] | positive-in-buffer: 16701 | amount-filled: 100.00%
	| epsilon: 0.226322263110622
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [962, 2396, 1697, 2782, 1088, 3532, 2106, 2138]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 25, 27, 35, 12, 47, 21, 31]
episode: 985 -> reward: -124.99999999998845, steps:84384, time-elasped: 183810.63s
-> berries picked: 143 of 800 | patches-visited: [7, 8, 9] | positive-in-buffer: 16530 | amount-filled: 100.00%
	| epsilon: 0.22614021055567832
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [951, 2367, 1682, 2763, 1085, 3499, 2079, 2104]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 39, 20, 37, 13, 51, 30, 27]
episode: 986 -> reward: -124.99999999998788, steps:63168, time-elasped: 184032.19s
-> berries picked: 55 of 800 | patches-visited: [2] | positive-in-buffer: 16571 | amount-filled: 100.00%
	| epsilon: 0.2259583044429463
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [952, 2375, 1685, 2766, 1091, 3504, 2086, 2112]
	| approx positives in sample 512: 196
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 32, 18, 27, 14, 33, 26, 32]
episode: 987 -> reward: -124.99999999999156, steps:60864, time-elasped: 184259.87s
-> berries picked: 46 of 800 | patches-visited: [7] | positive-in-buffer: 16602 | amount-filled: 100.00%
	| epsilon: 0.2257765446546285
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [953, 2386, 1686, 2768, 1092, 3511, 2090, 2116]
	| approx positives in sample 512: 239
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 28, 16, 39, 24, 62, 36, 22]
episode: 988 -> reward: -124.99999999999201, steps:54528, time-elasped: 184451.34s
-> berries picked: 23 of 800 | patches-visited: [7] | positive-in-buffer: 16618 | amount-filled: 100.00%
	| epsilon: 0.22559493107302234
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [957, 2390, 1687, 2768, 1093, 3517, 2091, 2115]
	| approx positives in sample 512: 223
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 33, 23, 36, 16, 42, 37, 26]
episode: 989 -> reward: -124.99999999999173, steps:54240, time-elasped: 184644.70s
-> berries picked: 33 of 800 | patches-visited: [7] | positive-in-buffer: 16639 | amount-filled: 100.00%
	| epsilon: 0.22541346358051975
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [961, 2390, 1693, 2768, 1092, 3523, 2089, 2123]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 23, 22, 47, 12, 47, 30, 26]
episode: 990 -> reward: -124.99999999999247, steps:60768, time-elasped: 184831.27s
-> berries picked: 56 of 800 | patches-visited: [2] | positive-in-buffer: 16660 | amount-filled: 100.00%
	| epsilon: 0.22523214205960737
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [960, 2396, 1696, 2771, 1091, 3525, 2089, 2132]
	| approx positives in sample 512: 230
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 45, 31, 37, 10, 39, 32, 26]
episode: 991 -> reward: -124.99999999998738, steps:82944, time-elasped: 185077.55s
-> berries picked: 142 of 800 | patches-visited: [0, 4, 9] | positive-in-buffer: 16522 | amount-filled: 100.00%
	| epsilon: 0.22505096639286637
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [951, 2385, 1680, 2762, 1080, 3476, 2080, 2108]
	| approx positives in sample 512: 244
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 29, 25, 41, 19, 52, 24, 33]
episode: 992 -> reward: -124.999999999991, steps:68736, time-elasped: 185308.48s
-> berries picked: 78 of 800 | patches-visited: [0, 6, 7] | positive-in-buffer: 16576 | amount-filled: 100.00%
	| epsilon: 0.22486993646297238
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [966, 2392, 1678, 2769, 1081, 3487, 2082, 2121]
	| approx positives in sample 512: 208
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 28, 18, 36, 12, 36, 32, 30]
episode: 993 -> reward: -124.99999999999207, steps:55104, time-elasped: 185500.74s
-> berries picked: 23 of 800 | patches-visited: [8] | positive-in-buffer: 16596 | amount-filled: 100.00%
	| epsilon: 0.22468905215269527
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [970, 2394, 1678, 2769, 1082, 3490, 2084, 2129]
	| approx positives in sample 512: 230
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 23, 23, 35, 22, 51, 28, 32]
episode: 994 -> reward: -124.99999999998835, steps:72384, time-elasped: 185726.13s
-> berries picked: 90 of 800 | patches-visited: [5, 7, 8] | positive-in-buffer: 16605 | amount-filled: 100.00%
	| epsilon: 0.2245083133448994
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [969, 2400, 1682, 2773, 1086, 3489, 2081, 2125]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 23, 32, 39, 14, 49, 29, 28]
episode: 995 -> reward: -124.99999999998786, steps:76032, time-elasped: 185984.77s
-> berries picked: 111 of 800 | patches-visited: [1, 7] | positive-in-buffer: 16566 | amount-filled: 100.00%
	| epsilon: 0.22432771992254325
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [962, 2399, 1672, 2773, 1088, 3479, 2072, 2121]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 33, 24, 44, 15, 43, 24, 36]
episode: 996 -> reward: -124.99999999999234, steps:65856, time-elasped: 186198.85s
-> berries picked: 70 of 800 | patches-visited: [4] | positive-in-buffer: 16612 | amount-filled: 100.00%
	| epsilon: 0.22414727176867938
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [973, 2404, 1673, 2779, 1092, 3484, 2073, 2134]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 26, 34, 37, 13, 48, 20, 33]
episode: 997 -> reward: -124.99999999998634, steps:72576, time-elasped: 186427.40s
-> berries picked: 91 of 800 | patches-visited: [1, 7] | positive-in-buffer: 16574 | amount-filled: 100.00%
	| epsilon: 0.2239669687664546
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [966, 2391, 1665, 2774, 1092, 3472, 2079, 2135]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 29, 21, 33, 17, 45, 26, 33]
episode: 998 -> reward: -124.99999999999417, steps:66240, time-elasped: 186657.39s
-> berries picked: 71 of 800 | patches-visited: [1, 6] | positive-in-buffer: 16624 | amount-filled: 100.00%
	| epsilon: 0.22378681079910961
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [967, 2395, 1675, 2783, 1095, 3474, 2089, 2146]
	| approx positives in sample 512: 233
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 41, 22, 36, 12, 58, 31, 24]
episode: 999 -> reward: -124.99999999999362, steps:75840, time-elasped: 186874.14s
-> berries picked: 112 of 800 | patches-visited: [0, 7] | positive-in-buffer: 16578 | amount-filled: 100.00%
	| epsilon: 0.223606797749979
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [957, 2395, 1670, 2776, 1091, 3469, 2089, 2131]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 30, 17, 44, 10, 44, 30, 29]
episode: 1000 -> reward: -124.99999999998849, steps:75456, time-elasped: 187090.27s
-> berries picked: 107 of 800 | patches-visited: [4, 5] | positive-in-buffer: 16614 | amount-filled: 100.00%
	| epsilon: 0.22342692950249127
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [957, 2413, 1674, 2786, 1094, 3466, 2091, 2133]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 27, 33, 29, 12, 53, 33, 34]
episode: 1001 -> reward: -124.99999999998784, steps:64416, time-elasped: 187330.80s
-> berries picked: 68 of 800 | patches-visited: [6] | positive-in-buffer: 16668 | amount-filled: 100.00%
	| epsilon: 0.22324720594016867
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [963, 2421, 1678, 2791, 1099, 3476, 2093, 2147]
	| approx positives in sample 512: 240
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 32, 26, 43, 13, 45, 38, 31]
episode: 1002 -> reward: -124.9999999999877, steps:72096, time-elasped: 187548.92s
-> berries picked: 95 of 800 | patches-visited: [0, 5] | positive-in-buffer: 16649 | amount-filled: 100.00%
	| epsilon: 0.2230676269466271
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [959, 2418, 1675, 2788, 1099, 3477, 2088, 2145]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 40, 21, 39, 13, 49, 25, 27]
episode: 1003 -> reward: -124.99999999999162, steps:58080, time-elasped: 187746.77s
-> berries picked: 40 of 800 | patches-visited: [7] | positive-in-buffer: 16682 | amount-filled: 100.00%
	| epsilon: 0.22288819240557617
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [965, 2426, 1679, 2791, 1098, 3483, 2089, 2151]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 30, 21, 34, 19, 51, 29, 25]
episode: 1004 -> reward: -124.99999999999162, steps:67392, time-elasped: 187959.61s
-> berries picked: 74 of 800 | patches-visited: [5] | positive-in-buffer: 16720 | amount-filled: 100.00%
	| epsilon: 0.22270890220081893
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [967, 2436, 1685, 2793, 1100, 3489, 2088, 2162]
	| approx positives in sample 512: 223
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 33, 24, 30, 15, 55, 33, 25]
episode: 1005 -> reward: -124.99999999999265, steps:58464, time-elasped: 188171.57s
-> berries picked: 40 of 800 | patches-visited: [6, 9] | positive-in-buffer: 16741 | amount-filled: 100.00%
	| epsilon: 0.222529756216252
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [970, 2435, 1690, 2797, 1099, 3497, 2091, 2162]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 34, 27, 34, 10, 42, 26, 31]
episode: 1006 -> reward: -124.99999999998957, steps:72768, time-elasped: 188403.83s
-> berries picked: 101 of 800 | patches-visited: [1, 4, 5] | positive-in-buffer: 16646 | amount-filled: 100.00%
	| epsilon: 0.22235075433586535
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [958, 2408, 1691, 2785, 1094, 3482, 2085, 2143]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 37, 20, 44, 7, 54, 26, 25]
episode: 1007 -> reward: -124.99999999999542, steps:73440, time-elasped: 188620.06s
-> berries picked: 99 of 800 | patches-visited: [4, 8] | positive-in-buffer: 16634 | amount-filled: 100.00%
	| epsilon: 0.2221718964437422
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [961, 2401, 1690, 2788, 1095, 3479, 2086, 2134]
	| approx positives in sample 512: 230
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 29, 19, 44, 19, 51, 29, 26]
episode: 1008 -> reward: -124.99999999999055, steps:78432, time-elasped: 188864.36s
-> berries picked: 127 of 800 | patches-visited: [3, 9] | positive-in-buffer: 16628 | amount-filled: 100.00%
	| epsilon: 0.22199318242405908
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [956, 2404, 1692, 2794, 1097, 3469, 2091, 2125]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 30, 18, 38, 20, 46, 19, 29]
episode: 1009 -> reward: -124.99999999999281, steps:63552, time-elasped: 189066.66s
-> berries picked: 57 of 800 | patches-visited: [4] | positive-in-buffer: 16668 | amount-filled: 100.00%
	| epsilon: 0.22181461216108575
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [967, 2413, 1691, 2799, 1097, 3474, 2090, 2137]
	| approx positives in sample 512: 202
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 24, 23, 38, 12, 41, 31, 22]
episode: 1010 -> reward: -124.99999999999164, steps:61248, time-elasped: 189271.50s
-> berries picked: 46 of 800 | patches-visited: [8] | positive-in-buffer: 16687 | amount-filled: 100.00%
	| epsilon: 0.22163618553918496
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [963, 2422, 1696, 2800, 1101, 3477, 2088, 2140]
	| approx positives in sample 512: 219
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 27, 20, 42, 11, 55, 22, 24]
episode: 1011 -> reward: -124.99999999999076, steps:65664, time-elasped: 189505.58s
-> berries picked: 72 of 800 | patches-visited: [0, 6] | positive-in-buffer: 16700 | amount-filled: 100.00%
	| epsilon: 0.2214579024428125
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [966, 2428, 1697, 2802, 1104, 3477, 2089, 2137]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [10, 30, 17, 40, 25, 36, 27, 36]
episode: 1012 -> reward: -124.99999999999159, steps:62400, time-elasped: 189713.74s
-> berries picked: 55 of 800 | patches-visited: [1, 6, 8] | positive-in-buffer: 16711 | amount-filled: 100.00%
	| epsilon: 0.2212797627565171
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [970, 2422, 1700, 2799, 1105, 3477, 2089, 2149]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 35, 25, 41, 8, 54, 29, 30]
episode: 1013 -> reward: -124.9999999999855, steps:69120, time-elasped: 189932.51s
-> berries picked: 85 of 800 | patches-visited: [2, 6, 9] | positive-in-buffer: 16661 | amount-filled: 100.00%
	| epsilon: 0.22110176636494042
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [968, 2418, 1701, 2782, 1106, 3467, 2083, 2136]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 27, 36, 43, 19, 41, 26, 23]
episode: 1014 -> reward: -124.999999999992, steps:52800, time-elasped: 190128.33s
-> berries picked: 19 of 800 | patches-visited: [6] | positive-in-buffer: 16672 | amount-filled: 100.00%
	| epsilon: 0.2209239131528168
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [968, 2423, 1701, 2782, 1105, 3468, 2082, 2143]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 38, 27, 26, 17, 40, 29, 26]
episode: 1015 -> reward: -124.9999999999904, steps:64800, time-elasped: 190351.06s
-> berries picked: 67 of 800 | patches-visited: [8] | positive-in-buffer: 16691 | amount-filled: 100.00%
	| epsilon: 0.22074620300497344
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [978, 2422, 1702, 2787, 1104, 3477, 2078, 2143]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 24, 24, 40, 20, 43, 29, 29]
episode: 1016 -> reward: -124.9999999999918, steps:54912, time-elasped: 190560.12s
-> berries picked: 29 of 800 | patches-visited: [8] | positive-in-buffer: 16716 | amount-filled: 100.00%
	| epsilon: 0.22056863580633007
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [981, 2428, 1702, 2787, 1104, 3481, 2078, 2155]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 32, 35, 37, 16, 40, 31, 24]
episode: 1017 -> reward: -124.99999999999115, steps:62112, time-elasped: 190762.66s
-> berries picked: 53 of 800 | patches-visited: [6] | positive-in-buffer: 16708 | amount-filled: 100.00%
	| epsilon: 0.22039121144189908
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [977, 2429, 1700, 2788, 1103, 3473, 2086, 2152]
	| approx positives in sample 512: 230
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 26, 22, 40, 14, 48, 38, 23]
episode: 1018 -> reward: -124.99999999999454, steps:63168, time-elasped: 190982.90s
-> berries picked: 58 of 800 | patches-visited: [0, 7, 8] | positive-in-buffer: 16690 | amount-filled: 100.00%
	| epsilon: 0.22021392979678522
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [976, 2429, 1695, 2784, 1099, 3470, 2084, 2153]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 35, 19, 34, 17, 44, 25, 30]
episode: 1019 -> reward: -124.99999999999103, steps:67296, time-elasped: 191156.65s
-> berries picked: 74 of 800 | patches-visited: [2, 9] | positive-in-buffer: 16684 | amount-filled: 100.00%
	| epsilon: 0.22003679075618585
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [974, 2425, 1694, 2787, 1101, 3458, 2090, 2155]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 24, 22, 48, 11, 54, 33, 25]
episode: 1020 -> reward: -124.99999999998793, steps:68352, time-elasped: 191379.12s
-> berries picked: 77 of 800 | patches-visited: [3, 7] | positive-in-buffer: 16682 | amount-filled: 100.00%
	| epsilon: 0.21985979420539048
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [986, 2428, 1694, 2780, 1102, 3460, 2077, 2155]
	| approx positives in sample 512: 233
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 38, 16, 40, 16, 56, 21, 38]
