training on randomly generated env
getBabyEnv :
	 logDir : .temp\2022-6-10 8-31-58
	 initial_juice : 0.5
	 end_on_boundary_hit : False
	 penalize_boundary_hit : False
	 allow_no_action : False
	 no_action_threshold : 0.7
	 field_size : (20000, 20000)
	 initial_pos_around_berry : True
	 nberries : 80
	 num_patches : 10
	 patch_size : (2600, 2600)
	 sampling_type : 0
	 seperation : 2400
	 show : False
	 spawn_radius : 100


with living cost, rewards scaled by 2/(berry_env.REWARD_RATE*MAXSIZE)
rewards are clipped between -2 and 2
Agent :
	 self : <Agent.Agent object at 0x000001D22D4B5808>
	 berryField : <BerryFieldEnv instance>
	 mode : train
	 angle : 45
	 persistence : 0.8
	 worth_offset : 0.0
	 noise : 0.01
	 field_grid_size : (40, 40)
	 memory_alpha : 0.9965
	 time_memory_delta : 0.005
	 time_memory_exp : 1
	 nstep_transition : [1, 30, 60]
	 reward_patch_discovery : False
	 debug : False
	 debugDir : .temp


The state-transitions being appended 
            every action will be as [[state, action, sum-reward, nextState, done]] where:
            state is the one the model has taken action on,
            sum-reward is the sum of the rewards in the skip-trajectory,
            nextState is the new state after the action was repeated at most skip-steps times,
            done is wether the terminal state was reached.
agent now aware of total-juice
seperate conv-nets for berry and path memory
total-params:  10641
net(
  (feedforward): ModuleList(
    (0): Linear(in_features=39, out_features=16, bias=True)
    (1): LeakyReLU(negative_slope=0.1)
    (2): Linear(in_features=16, out_features=8, bias=True)
    (3): LeakyReLU(negative_slope=0.1)
  )
  (memory_conv1): ModuleList(
    (0): Conv2d(1, 8, kernel_size=(4, 4), stride=(2, 2), padding=(3, 3))
    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (2): LeakyReLU(negative_slope=0.1)
    (3): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))
    (4): LeakyReLU(negative_slope=0.1)
    (5): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): LeakyReLU(negative_slope=0.1)
  )
  (memory_conv2): ModuleList(
    (0): Conv2d(1, 8, kernel_size=(4, 4), stride=(2, 2), padding=(3, 3))
    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (2): LeakyReLU(negative_slope=0.1)
    (3): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))
    (4): LeakyReLU(negative_slope=0.1)
    (5): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): LeakyReLU(negative_slope=0.1)
  )
  (final_stage): ModuleList(
    (0): Linear(in_features=136, out_features=16, bias=True)
    (1): LeakyReLU(negative_slope=0.1)
    (2): Linear(in_features=16, out_features=16, bias=True)
    (3): LeakyReLU(negative_slope=0.1)
  )
  (valueL): Linear(in_features=16, out_features=1, bias=True)
  (actadvs): Linear(in_features=16, out_features=8, bias=True)
)
lr used = 0.00002, num_gradient_steps= 500
optimizing the online-model after every 2000 actions
batch size=512, gamma=0.8, alpha=0.96
polyak_tau=0.1, update_freq=5
episode: 0/2000 -> reward: -249.99999999998332, steps:49920, time-taken: 2.32min, time-elasped: 2.32min
-> berries picked: 7 of 800 | patches-visited: [6, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20 | amount-filled: 22.55%
	| action-stats:  [5, 6, 7] [6, 9, 5]
	| approx positives in sample 512: 5
	| approx action-dist in sample 512: [5, 6, 7] [2, 1, 2]
	Time taken saving stuff: 17.67s

==================================================
eval-episode: 0 -> reward: -0.4999999999999447, steps: 48000.0, wall-time: 40.17s
-> berries picked: 0 of 800 | patches-visited: [1] | juice left:-0.00
==================================================

episode: 1/2000 -> reward: -249.99999999998403, steps:48960, time-taken: 2.21min, time-elasped: 5.50min
-> berries picked: 3 of 800 | patches-visited: [1, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 29 | amount-filled: 44.66%
	| action-stats:  [5, 6, 7] [6, 18, 5]
	| approx positives in sample 512: 7
	| approx action-dist in sample 512: [5, 6] [2, 5]
	Time taken saving stuff: 0.01s
episode: 2/2000 -> reward: -249.99999999998383, steps:49440, time-taken: 2.20min, time-elasped: 7.71min
-> berries picked: 5 of 800 | patches-visited: [6, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 44 | amount-filled: 66.98%
	| action-stats:  [5, 6, 7] [6, 30, 8]
	| approx positives in sample 512: 8
	| approx action-dist in sample 512: [6] [8]
	Time taken saving stuff: 0.01s
episode: 3/2000 -> reward: -249.9999999999833, steps:50112, time-taken: 2.56min, time-elasped: 10.28min
-> berries picked: 9 of 800 | patches-visited: [0, 3, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 71 | amount-filled: 89.62%
	| action-stats:  [4, 5, 6, 7] [6, 6, 48, 11]
	| approx positives in sample 512: 4
	| approx action-dist in sample 512: [5, 6] [1, 3]
	Time taken saving stuff: 0.01s
episode: 4/2000 -> reward: -249.99999999998406, steps:48480, time-taken: 2.33min, time-elasped: 12.61min
-> berries picked: 2 of 800 | patches-visited: [1, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 77 | amount-filled: 100.00%
	| action-stats:  [3, 4, 5, 6, 7] [3, 6, 6, 51, 11]
	| approx positives in sample 512: 9
	| approx action-dist in sample 512: [4, 6, 7] [2, 6, 1]
	Time taken saving stuff: 0.01s
episode: 5/2000 -> reward: -249.9999999999841, steps:48288, time-taken: 2.28min, time-elasped: 14.90min
-> berries picked: 2 of 800 | patches-visited: [4, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 83 | amount-filled: 100.00%
	| action-stats:  [3, 4, 5, 6, 7] [3, 6, 6, 51, 17]
	| approx positives in sample 512: 10
	| approx action-dist in sample 512: [6, 7] [9, 1]
	Time taken saving stuff: 0.01s
episode: 6/2000 -> reward: -249.99999999998406, steps:48576, time-taken: 2.49min, time-elasped: 17.38min
-> berries picked: 2 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 89 | amount-filled: 100.00%
	| action-stats:  [3, 4, 5, 6, 7] [3, 6, 9, 54, 17]
	| approx positives in sample 512: 15
	| approx action-dist in sample 512: [5, 6, 7] [1, 12, 2]
	Time taken saving stuff: 0.01s
episode: 7/2000 -> reward: -249.99999999998326, steps:48960, time-taken: 2.48min, time-elasped: 19.88min
-> berries picked: 3 of 800 | patches-visited: [5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 98 | amount-filled: 100.00%
	| action-stats:  [0, 3, 4, 5, 6, 7] [3, 9, 6, 9, 54, 17]
	| approx positives in sample 512: 12
	| approx action-dist in sample 512: [3, 5, 6, 7] [1, 2, 7, 2]
	Time taken saving stuff: 0.01s
episode: 8/2000 -> reward: -249.99999999998332, steps:48864, time-taken: 2.44min, time-elasped: 22.32min
-> berries picked: 3 of 800 | patches-visited: [4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 107 | amount-filled: 100.00%
	| action-stats:  [0, 1, 3, 4, 5, 6, 7] [3, 3, 12, 6, 9, 54, 20]
	| approx positives in sample 512: 13
	| approx action-dist in sample 512: [0, 1, 3, 5, 6, 7] [1, 1, 3, 1, 5, 2]
	Time taken saving stuff: 0.01s
episode: 9/2000 -> reward: -249.99999999998423, steps:49248, time-taken: 2.26min, time-elasped: 24.58min
-> berries picked: 4 of 800 | patches-visited: [5, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 119 | amount-filled: 100.00%
	| action-stats:  [0, 1, 3, 4, 5, 6, 7] [3, 9, 12, 6, 9, 57, 23]
	| approx positives in sample 512: 15
	| approx action-dist in sample 512: [0, 1, 3, 5, 6, 7] [1, 3, 1, 1, 7, 2]
	Time taken saving stuff: 0.01s
episode: 10/2000 -> reward: -249.99999999998408, steps:48384, time-taken: 2.26min, time-elasped: 26.84min
-> berries picked: 2 of 800 | patches-visited: [5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 125 | amount-filled: 100.00%
	| action-stats:  [0, 1, 3, 4, 5, 6, 7] [6, 12, 12, 6, 9, 57, 23]
	| approx positives in sample 512: 13
	| approx action-dist in sample 512: [3, 4, 6, 7] [2, 1, 6, 4]
	Time taken saving stuff: 17.07s

==================================================
eval-episode: 10 -> reward: -0.4999999999999447, steps: 49152.0, wall-time: 31.50s
-> berries picked: 4 of 800 | patches-visited: [1] | juice left:-0.00
==================================================

episode: 11/2000 -> reward: -249.99999999998408, steps:48864, time-taken: 2.06min, time-elasped: 29.71min
-> berries picked: 4 of 800 | patches-visited: [3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 137 | amount-filled: 100.00%
	| action-stats:  [0, 1, 3, 4, 5, 6, 7] [12, 12, 12, 6, 9, 57, 29]
	| approx positives in sample 512: 11
	| approx action-dist in sample 512: [0, 5, 6, 7] [1, 1, 7, 2]
	Time taken saving stuff: 0.01s
episode: 12/2000 -> reward: -249.99999999998406, steps:48384, time-taken: 2.36min, time-elasped: 32.08min
-> berries picked: 1 of 800 | patches-visited: [4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 140 | amount-filled: 100.00%
	| action-stats:  [0, 1, 3, 4, 5, 6, 7] [12, 12, 12, 6, 9, 57, 32]
	| approx positives in sample 512: 14
	| approx action-dist in sample 512: [0, 3, 5, 6, 7] [1, 3, 2, 6, 2]
	Time taken saving stuff: 0.01s
episode: 13/2000 -> reward: -249.99999999998406, steps:48288, time-taken: 2.22min, time-elasped: 34.30min
-> berries picked: 1 of 800 | patches-visited: [5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 143 | amount-filled: 100.00%
	| action-stats:  [0, 1, 3, 4, 5, 6, 7] [12, 12, 12, 6, 9, 57, 35]
	| approx positives in sample 512: 22
	| approx action-dist in sample 512: [0, 1, 3, 4, 5, 6, 7] [5, 1, 2, 2, 1, 4, 7]
	Time taken saving stuff: 0.01s
episode: 14/2000 -> reward: -249.9999999999837, steps:51264, time-taken: 2.48min, time-elasped: 36.78min
-> berries picked: 9 of 800 | patches-visited: [5, 6, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 170 | amount-filled: 100.00%
	| action-stats:  [0, 1, 3, 4, 5, 6, 7] [15, 15, 18, 6, 9, 63, 44]
	| approx positives in sample 512: 13
	| approx action-dist in sample 512: [0, 1, 3, 6, 7] [1, 1, 2, 5, 4]
	Time taken saving stuff: 0.01s
episode: 15/2000 -> reward: -249.9999999999806, steps:57120, time-taken: 2.53min, time-elasped: 39.32min
-> berries picked: 36 of 800 | patches-visited: [3, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 278 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [45, 18, 12, 45, 9, 9, 87, 53]
	| approx positives in sample 512: 22
	| approx action-dist in sample 512: [0, 1, 3, 5, 6, 7] [2, 3, 2, 1, 7, 7]
	Time taken saving stuff: 0.01s
episode: 16/2000 -> reward: -249.99999999997948, steps:58656, time-taken: 2.64min, time-elasped: 41.96min
-> berries picked: 36 of 800 | patches-visited: [2, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 386 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [69, 21, 15, 69, 15, 12, 117, 68]
	| approx positives in sample 512: 13
	| approx action-dist in sample 512: [0, 3, 5, 6, 7] [4, 3, 3, 2, 1]
	Time taken saving stuff: 0.01s
episode: 17/2000 -> reward: -249.9999999999813, steps:54720, time-taken: 2.56min, time-elasped: 44.52min
-> berries picked: 25 of 800 | patches-visited: [4, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 461 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [84, 21, 24, 90, 18, 18, 132, 74]
	| approx positives in sample 512: 33
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 2, 2, 5, 1, 3, 15, 2]
	Time taken saving stuff: 0.01s
episode: 18/2000 -> reward: -249.99999999998403, steps:50304, time-taken: 2.42min, time-elasped: 46.96min
-> berries picked: 8 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 485 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [87, 24, 33, 96, 18, 18, 132, 77]
	| approx positives in sample 512: 28
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 6, 7] [7, 4, 2, 7, 1, 5, 2]
	Time taken saving stuff: 0.01s
episode: 19/2000 -> reward: -249.99999999997584, steps:59712, time-taken: 2.74min, time-elasped: 49.70min
-> berries picked: 40 of 800 | patches-visited: [4, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 605 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [102, 42, 36, 117, 42, 21, 153, 92]
	| approx positives in sample 512: 30
	| approx action-dist in sample 512: [0, 1, 3, 4, 5, 6] [6, 4, 7, 4, 2, 7]
	Time taken saving stuff: 0.01s
episode: 20/2000 -> reward: -249.99999999998354, steps:51456, time-taken: 2.48min, time-elasped: 52.19min
-> berries picked: 11 of 800 | patches-visited: [2, 5, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 636 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [102, 42, 39, 120, 57, 21, 163, 92]
	| approx positives in sample 512: 28
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 6, 7] [4, 5, 1, 6, 3, 6, 3]
	Time taken saving stuff: 18.23s

==================================================
eval-episode: 20 -> reward: -0.49999999999994477, steps: 48864.0, wall-time: 37.00s
-> berries picked: 3 of 800 | patches-visited: [1] | juice left:-0.00
==================================================

episode: 21/2000 -> reward: -249.99999999998406, steps:48576, time-taken: 2.31min, time-elasped: 55.43min
-> berries picked: 2 of 800 | patches-visited: [8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 642 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [102, 42, 39, 120, 57, 24, 166, 92]
	| approx positives in sample 512: 39
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 1, 3, 4, 5, 3, 14, 5]
	Time taken saving stuff: 0.01s
episode: 22/2000 -> reward: -249.99999999998383, steps:57408, time-taken: 2.42min, time-elasped: 57.85min
-> berries picked: 30 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 732 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [105, 54, 42, 132, 81, 33, 178, 107]
	| approx positives in sample 512: 33
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 1, 2, 6, 4, 1, 11, 6]
	Time taken saving stuff: 0.01s
episode: 23/2000 -> reward: -249.9999999999831, steps:49152, time-taken: 2.33min, time-elasped: 60.18min
-> berries picked: 4 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 744 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [105, 54, 42, 132, 84, 36, 184, 107]
	| approx positives in sample 512: 43
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 3, 3, 7, 6, 5, 7, 8]
	Time taken saving stuff: 0.01s
episode: 24/2000 -> reward: -249.99999999998585, steps:57504, time-taken: 2.52min, time-elasped: 62.70min
-> berries picked: 32 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 840 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [111, 63, 45, 156, 108, 45, 202, 110]
	| approx positives in sample 512: 37
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7] [6, 1, 8, 7, 1, 9, 5]
	Time taken saving stuff: 0.01s
episode: 25/2000 -> reward: -249.99999999998408, steps:48000, time-taken: 2.28min, time-elasped: 64.99min
-> berries picked: 0 of 800 | patches-visited: [6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 840 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [111, 63, 45, 156, 108, 45, 202, 110]
	| approx positives in sample 512: 60
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 4, 3, 15, 9, 2, 14, 8]
	Time taken saving stuff: 0.01s
episode: 26/2000 -> reward: -249.9999999999835, steps:53376, time-taken: 2.45min, time-elasped: 67.45min
-> berries picked: 21 of 800 | patches-visited: [1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 903 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [111, 72, 45, 156, 120, 51, 208, 140]
	| approx positives in sample 512: 39
	| approx action-dist in sample 512: [0, 1, 3, 4, 5, 6, 7] [6, 2, 5, 9, 4, 8, 5]
	Time taken saving stuff: 0.01s
episode: 27/2000 -> reward: -249.99999999998371, steps:51360, time-taken: 2.45min, time-elasped: 69.91min
-> berries picked: 11 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 936 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [111, 75, 45, 159, 132, 54, 214, 146]
	| approx positives in sample 512: 56
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 4, 3, 7, 7, 4, 12, 10]
	Time taken saving stuff: 0.01s
episode: 28/2000 -> reward: -249.99999999998604, steps:58176, time-taken: 2.78min, time-elasped: 72.69min
-> berries picked: 31 of 800 | patches-visited: [3, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 1029 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [117, 90, 45, 189, 135, 63, 232, 158]
	| approx positives in sample 512: 50
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 6, 1, 9, 7, 4, 7, 12]
	Time taken saving stuff: 0.01s
episode: 29/2000 -> reward: -249.99999999998252, steps:53664, time-taken: 2.51min, time-elasped: 75.20min
-> berries picked: 17 of 800 | patches-visited: [4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 1080 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [117, 96, 45, 192, 144, 63, 253, 170]
	| approx positives in sample 512: 42
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 2, 3, 7, 2, 1, 15, 5]
	Time taken saving stuff: 0.01s
episode: 30/2000 -> reward: -249.9999999999821, steps:53664, time-taken: 2.41min, time-elasped: 77.63min
-> berries picked: 19 of 800 | patches-visited: [8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 1137 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [117, 102, 54, 198, 150, 81, 256, 179]
	| approx positives in sample 512: 32
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 4, 3, 3, 1, 3, 12, 3]
	Time taken saving stuff: 17.58s

==================================================
eval-episode: 30 -> reward: -0.4999999999999447, steps: 48000.0, wall-time: 58.99s
-> berries picked: 0 of 800 | patches-visited: [1] | juice left:-0.00
==================================================

episode: 31/2000 -> reward: -249.99999999997667, steps:58272, time-taken: 2.66min, time-elasped: 81.57min
-> berries picked: 35 of 800 | patches-visited: [3, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 1242 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [117, 111, 69, 222, 159, 96, 274, 194]
	| approx positives in sample 512: 37
	| approx action-dist in sample 512: [0, 1, 3, 4, 5, 6, 7] [2, 5, 7, 5, 6, 7, 5]
	Time taken saving stuff: 0.01s
episode: 32/2000 -> reward: -249.9999999999842, steps:52032, time-taken: 2.32min, time-elasped: 83.89min
-> berries picked: 16 of 800 | patches-visited: [5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 1290 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [120, 120, 78, 225, 159, 96, 286, 206]
	| approx positives in sample 512: 54
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 8, 5, 6, 10, 4, 15, 5]
	Time taken saving stuff: 0.01s
episode: 33/2000 -> reward: -249.9999999999842, steps:53856, time-taken: 2.88min, time-elasped: 86.78min
-> berries picked: 20 of 800 | patches-visited: [8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 1348 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [126, 120, 87, 234, 162, 105, 293, 221]
	| approx positives in sample 512: 56
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 7, 4, 15, 5, 3, 10, 10]
	Time taken saving stuff: 0.01s
episode: 34/2000 -> reward: -249.9999999999787, steps:64896, time-taken: 2.88min, time-elasped: 89.66min
-> berries picked: 59 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 1524 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [132, 135, 114, 252, 189, 120, 319, 263]
	| approx positives in sample 512: 39
	| approx action-dist in sample 512: [1, 2, 3, 4, 5, 6, 7] [4, 2, 8, 7, 1, 8, 9]
	Time taken saving stuff: 0.01s
episode: 35/2000 -> reward: -249.99999999998334, steps:57984, time-taken: 3.24min, time-elasped: 92.90min
-> berries picked: 46 of 800 | patches-visited: [4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 1662 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [147, 159, 123, 264, 201, 135, 331, 302]
	| approx positives in sample 512: 54
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 6, 5, 15, 5, 1, 13, 6]
	Time taken saving stuff: 0.01s
episode: 36/2000 -> reward: -249.999999999985, steps:57312, time-taken: 2.76min, time-elasped: 95.68min
-> berries picked: 40 of 800 | patches-visited: [6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 1782 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [153, 180, 129, 279, 201, 150, 355, 335]
	| approx positives in sample 512: 64
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 8, 4, 10, 13, 3, 12, 12]
	Time taken saving stuff: 0.01s
episode: 37/2000 -> reward: -249.9999999999843, steps:53280, time-taken: 2.69min, time-elasped: 98.38min
-> berries picked: 15 of 800 | patches-visited: [7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 1826 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [156, 182, 135, 294, 204, 150, 358, 347]
	| approx positives in sample 512: 68
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 4, 6, 11, 7, 7, 15, 16]
	Time taken saving stuff: 0.01s
episode: 38/2000 -> reward: -249.9999999999842, steps:54048, time-taken: 2.85min, time-elasped: 101.23min
-> berries picked: 19 of 800 | patches-visited: [1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 1883 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [159, 194, 135, 303, 219, 150, 361, 362]
	| approx positives in sample 512: 83
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 6, 3, 14, 12, 11, 19, 9]
	Time taken saving stuff: 0.01s
episode: 39/2000 -> reward: -249.99999999998437, steps:57312, time-taken: 2.86min, time-elasped: 104.10min
-> berries picked: 31 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 1976 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [159, 209, 135, 330, 225, 156, 370, 392]
	| approx positives in sample 512: 59
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 8, 6, 11, 6, 4, 11, 10]
	Time taken saving stuff: 0.01s
episode: 40/2000 -> reward: -249.99999999998434, steps:57024, time-taken: 2.92min, time-elasped: 107.02min
-> berries picked: 33 of 800 | patches-visited: [8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 2075 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [162, 215, 138, 345, 234, 168, 388, 425]
	| approx positives in sample 512: 72
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [1, 8, 5, 11, 9, 6, 13, 19]
	Time taken saving stuff: 18.60s

==================================================
eval-episode: 40 -> reward: -0.4999999999999448, steps: 51264.0, wall-time: 55.22s
-> berries picked: 12 of 800 | patches-visited: [1] | juice left:-0.00
==================================================

episode: 41/2000 -> reward: -249.9999999999853, steps:64416, time-taken: 3.25min, time-elasped: 111.51min
-> berries picked: 57 of 800 | patches-visited: [8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 2246 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [168, 221, 153, 369, 243, 192, 418, 482]
	| approx positives in sample 512: 58
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 7, 4, 11, 9, 2, 9, 10]
	Time taken saving stuff: 0.01s
episode: 42/2000 -> reward: -249.99999999997897, steps:64800, time-taken: 2.92min, time-elasped: 114.43min
-> berries picked: 62 of 800 | patches-visited: [9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 2432 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [174, 254, 153, 387, 261, 213, 454, 536]
	| approx positives in sample 512: 63
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [2, 10, 3, 13, 8, 4, 8, 15]
	Time taken saving stuff: 0.01s
episode: 43/2000 -> reward: -249.9999999999842, steps:52224, time-taken: 2.48min, time-elasped: 116.92min
-> berries picked: 16 of 800 | patches-visited: [6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 2480 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [177, 254, 165, 399, 267, 219, 457, 542]
	| approx positives in sample 512: 88
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 2, 6, 10, 13, 5, 22, 24]
	Time taken saving stuff: 0.01s
episode: 44/2000 -> reward: -249.9999999999844, steps:59232, time-taken: 3.65min, time-elasped: 120.57min
-> berries picked: 39 of 800 | patches-visited: [5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 2597 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [177, 263, 198, 417, 282, 225, 472, 563]
	| approx positives in sample 512: 90
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 7, 8, 16, 9, 11, 14, 16]
	Time taken saving stuff: 0.01s
episode: 45/2000 -> reward: -249.9999999999824, steps:64992, time-taken: 3.33min, time-elasped: 123.91min
-> berries picked: 72 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 2810 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [194, 281, 225, 462, 312, 252, 502, 582]
	| approx positives in sample 512: 79
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 5, 6, 16, 7, 9, 16, 14]
	Time taken saving stuff: 0.02s
episode: 46/2000 -> reward: -249.99999999998192, steps:66240, time-taken: 8.18min, time-elasped: 132.10min
-> berries picked: 70 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 3020 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [221, 296, 234, 486, 327, 285, 544, 627]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 19, 9, 23, 15, 9, 26, 30]
	Time taken saving stuff: 0.02s
episode: 47/2000 -> reward: -249.99999999998388, steps:65088, time-taken: 4.95min, time-elasped: 137.06min
-> berries picked: 60 of 800 | patches-visited: [2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 3197 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [242, 320, 261, 501, 333, 303, 583, 654]
	| approx positives in sample 512: 84
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 12, 4, 12, 13, 4, 23, 10]
	Time taken saving stuff: 0.02s
episode: 48/2000 -> reward: -249.99999999998417, steps:56640, time-taken: 3.17min, time-elasped: 140.24min
-> berries picked: 30 of 800 | patches-visited: [2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 3287 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [260, 329, 270, 525, 339, 309, 595, 660]
	| approx positives in sample 512: 96
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 9, 8, 16, 9, 5, 17, 24]
	Time taken saving stuff: 0.01s
episode: 49/2000 -> reward: -249.99999999997593, steps:75744, time-taken: 4.82min, time-elasped: 145.06min
-> berries picked: 96 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 3572 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [287, 392, 303, 537, 381, 315, 640, 717]
	| approx positives in sample 512: 119
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 8, 8, 19, 23, 6, 22, 21]
	Time taken saving stuff: 0.02s
episode: 50/2000 -> reward: -249.99999999998303, steps:64416, time-taken: 3.40min, time-elasped: 148.47min
-> berries picked: 73 of 800 | patches-visited: [2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 3788 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [326, 410, 330, 561, 402, 336, 688, 735]
	| approx positives in sample 512: 99
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [4, 11, 3, 12, 9, 11, 27, 22]
	Time taken saving stuff: 18.26s

==================================================
eval-episode: 50 -> reward: -0.4999999999999465, steps: 69504.0, wall-time: 73.45s
-> berries picked: 81 of 800 | patches-visited: [1, 2] | juice left:-0.00
==================================================

episode: 51/2000 -> reward: -249.9999999999849, steps:58368, time-taken: 2.87min, time-elasped: 152.88min
-> berries picked: 39 of 800 | patches-visited: [4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 3901 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [335, 431, 339, 584, 417, 338, 707, 750]
	| approx positives in sample 512: 103
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [3, 8, 6, 17, 12, 12, 22, 23]
	Time taken saving stuff: 0.01s
episode: 52/2000 -> reward: -249.9999999999857, steps:62208, time-taken: 3.00min, time-elasped: 155.89min
-> berries picked: 55 of 800 | patches-visited: [8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 4066 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [353, 437, 351, 602, 432, 359, 746, 786]
	| approx positives in sample 512: 99
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 11, 5, 19, 6, 8, 26, 15]
	Time taken saving stuff: 0.01s
episode: 53/2000 -> reward: -249.99999999998192, steps:65568, time-taken: 3.08min, time-elasped: 158.97min
-> berries picked: 76 of 800 | patches-visited: [2, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 4294 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [389, 449, 393, 632, 456, 374, 785, 816]
	| approx positives in sample 512: 91
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 12, 4, 19, 8, 3, 16, 21]
	Time taken saving stuff: 0.01s
episode: 54/2000 -> reward: -249.99999999998354, steps:56160, time-taken: 2.55min, time-elasped: 161.54min
-> berries picked: 31 of 800 | patches-visited: [6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 4385 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [388, 452, 402, 647, 474, 392, 790, 840]
	| approx positives in sample 512: 123
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [6, 17, 8, 15, 21, 9, 17, 30]
	Time taken saving stuff: 0.01s
episode: 55/2000 -> reward: -249.9999999999729, steps:77472, time-taken: 4.01min, time-elasped: 165.55min
-> berries picked: 108 of 800 | patches-visited: [3, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 4707 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [435, 494, 447, 674, 500, 422, 826, 909]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 15, 20, 16, 13, 13, 23, 20]
	Time taken saving stuff: 0.01s
episode: 56/2000 -> reward: -249.99999999998437, steps:66432, time-taken: 3.61min, time-elasped: 169.17min
-> berries picked: 79 of 800 | patches-visited: [3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 4943 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [447, 548, 486, 707, 521, 470, 843, 921]
	| approx positives in sample 512: 198
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 21, 16, 26, 22, 22, 37, 36]
	Time taken saving stuff: 0.01s
episode: 57/2000 -> reward: -249.99999999998366, steps:64704, time-taken: 3.07min, time-elasped: 172.24min
-> berries picked: 65 of 800 | patches-visited: [9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 5137 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [459, 575, 531, 722, 547, 485, 873, 945]
	| approx positives in sample 512: 132
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [5, 19, 6, 22, 21, 17, 18, 24]
	Time taken saving stuff: 0.05s
episode: 58/2000 -> reward: -249.9999999999821, steps:65280, time-taken: 3.34min, time-elasped: 175.60min
-> berries picked: 72 of 800 | patches-visited: [1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 5350 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [486, 593, 564, 742, 574, 531, 894, 966]
	| approx positives in sample 512: 110
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [9, 10, 14, 19, 9, 7, 21, 21]
	Time taken saving stuff: 0.01s
episode: 59/2000 -> reward: -249.99999999998164, steps:64608, time-taken: 2.67min, time-elasped: 178.28min
-> berries picked: 62 of 800 | patches-visited: [6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 5533 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [512, 617, 594, 763, 598, 546, 919, 984]
	| approx positives in sample 512: 98
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [8, 9, 9, 13, 15, 5, 17, 22]
	Time taken saving stuff: 0.01s
episode: 60/2000 -> reward: -249.9999999999832, steps:66624, time-taken: 3.60min, time-elasped: 181.88min
-> berries picked: 79 of 800 | patches-visited: [9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 5770 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [536, 653, 642, 790, 619, 576, 943, 1011]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 41, 20, 30, 28, 21, 26, 34]
	Time taken saving stuff: 18.57s

==================================================
eval-episode: 60 -> reward: -0.4999999999999454, steps: 59904.0, wall-time: 56.91s
-> berries picked: 41 of 800 | patches-visited: [1, 2] | juice left:-0.00
==================================================

episode: 61/2000 -> reward: -249.99999999998215, steps:65184, time-taken: 2.75min, time-elasped: 185.90min
-> berries picked: 65 of 800 | patches-visited: [9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 5965 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [575, 686, 678, 814, 622, 603, 958, 1029]
	| approx positives in sample 512: 124
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [7, 15, 14, 19, 12, 11, 19, 27]
	Time taken saving stuff: 0.01s
episode: 62/2000 -> reward: -249.99999999998514, steps:58464, time-taken: 2.59min, time-elasped: 188.50min
-> berries picked: 38 of 800 | patches-visited: [6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 6077 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [581, 710, 690, 830, 640, 612, 967, 1047]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 16, 14, 24, 12, 18, 23, 17]
	Time taken saving stuff: 0.01s
episode: 63/2000 -> reward: -249.99999999998425, steps:66720, time-taken: 3.73min, time-elasped: 192.23min
-> berries picked: 76 of 800 | patches-visited: [8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 6305 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [605, 722, 714, 842, 688, 654, 1000, 1080]
	| approx positives in sample 512: 223
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 37, 23, 32, 22, 23, 25, 35]
	Time taken saving stuff: 0.01s
episode: 64/2000 -> reward: -249.99999999998164, steps:66240, time-taken: 3.59min, time-elasped: 195.82min
-> berries picked: 75 of 800 | patches-visited: [6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 6528 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [638, 743, 750, 875, 703, 714, 1013, 1092]
	| approx positives in sample 512: 233
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 26, 17, 40, 34, 24, 29, 41]
	Time taken saving stuff: 0.01s
episode: 65/2000 -> reward: -249.999999999986, steps:64608, time-taken: 3.02min, time-elasped: 198.84min
-> berries picked: 65 of 800 | patches-visited: [6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 6720 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [656, 776, 774, 899, 730, 751, 1021, 1113]
	| approx positives in sample 512: 150
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 21, 21, 20, 13, 16, 21, 17]
	Time taken saving stuff: 0.01s
episode: 66/2000 -> reward: -249.99999999998136, steps:64704, time-taken: 2.60min, time-elasped: 201.44min
-> berries picked: 73 of 800 | patches-visited: [3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 6938 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [674, 782, 807, 941, 750, 787, 1051, 1146]
	| approx positives in sample 512: 151
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 14, 20, 16, 16, 23, 22, 26]
	Time taken saving stuff: 0.01s
episode: 67/2000 -> reward: -249.99999999997425, steps:62400, time-taken: 3.54min, time-elasped: 204.98min
-> berries picked: 59 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 7114 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [704, 815, 831, 965, 750, 829, 1056, 1164]
	| approx positives in sample 512: 139
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 20, 22, 16, 18, 10, 18, 24]
	Time taken saving stuff: 0.01s
episode: 68/2000 -> reward: -249.99999999998363, steps:56832, time-taken: 2.59min, time-elasped: 207.58min
-> berries picked: 32 of 800 | patches-visited: [6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 7210 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [719, 821, 852, 971, 753, 841, 1077, 1176]
	| approx positives in sample 512: 164
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 21, 25, 17, 25, 18, 25, 21]
	Time taken saving stuff: 0.01s
episode: 69/2000 -> reward: -249.9999999999822, steps:66240, time-taken: 3.52min, time-elasped: 211.11min
-> berries picked: 77 of 800 | patches-visited: [4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 7440 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [748, 857, 885, 998, 777, 877, 1098, 1200]
	| approx positives in sample 512: 246
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 35, 29, 30, 23, 28, 41, 33]
	Time taken saving stuff: 0.01s
episode: 70/2000 -> reward: -249.99999999998397, steps:63840, time-taken: 2.74min, time-elasped: 213.85min
-> berries picked: 62 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 7622 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [753, 884, 912, 1007, 807, 895, 1131, 1233]
	| approx positives in sample 512: 150
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 22, 20, 15, 19, 19, 23, 19]
	Time taken saving stuff: 18.63s

==================================================
eval-episode: 70 -> reward: -0.4999999999999461, steps: 68448.0, wall-time: 109.27s
-> berries picked: 71 of 800 | patches-visited: [1, 2] | juice left:-0.00
==================================================

episode: 71/2000 -> reward: -249.99999999998434, steps:64608, time-taken: 3.21min, time-elasped: 219.20min
-> berries picked: 74 of 800 | patches-visited: [3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 7839 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [783, 902, 960, 1028, 824, 927, 1154, 1261]
	| approx positives in sample 512: 151
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 30, 14, 19, 12, 7, 32, 20]
	Time taken saving stuff: 0.01s
episode: 72/2000 -> reward: -249.99999999997848, steps:65376, time-taken: 3.55min, time-elasped: 222.75min
-> berries picked: 68 of 800 | patches-visited: [9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 8036 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [789, 929, 993, 1064, 843, 960, 1179, 1279]
	| approx positives in sample 512: 147
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [12, 26, 19, 17, 13, 11, 21, 28]
	Time taken saving stuff: 0.01s
episode: 73/2000 -> reward: -249.99999999998508, steps:65760, time-taken: 2.69min, time-elasped: 225.45min
-> berries picked: 70 of 800 | patches-visited: [6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 8231 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [825, 948, 1017, 1081, 843, 997, 1199, 1321]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [11, 17, 22, 19, 18, 13, 14, 19]
	Time taken saving stuff: 0.01s
episode: 74/2000 -> reward: -249.99999999998263, steps:66432, time-taken: 3.75min, time-elasped: 229.21min
-> berries picked: 78 of 800 | patches-visited: [3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 8458 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [834, 984, 1053, 1120, 875, 1042, 1219, 1331]
	| approx positives in sample 512: 252
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 31, 41, 34, 22, 29, 37, 38]
	Time taken saving stuff: 0.01s
episode: 75/2000 -> reward: -249.99999999998528, steps:63360, time-taken: 2.77min, time-elasped: 231.99min
-> berries picked: 55 of 800 | patches-visited: [3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 8623 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [837, 1011, 1080, 1135, 920, 1060, 1234, 1346]
	| approx positives in sample 512: 172
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 22, 27, 20, 16, 15, 34, 17]
	Time taken saving stuff: 0.01s
episode: 76/2000 -> reward: -249.99999999997817, steps:73536, time-taken: 4.45min, time-elasped: 236.44min
-> berries picked: 98 of 800 | patches-visited: [8, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 8899 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [863, 1062, 1095, 1161, 953, 1092, 1274, 1399]
	| approx positives in sample 512: 208
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 28, 26, 31, 20, 26, 23, 33]
	Time taken saving stuff: 0.01s
episode: 77/2000 -> reward: -249.99999999998354, steps:63264, time-taken: 3.14min, time-elasped: 239.59min
-> berries picked: 56 of 800 | patches-visited: [1, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 9060 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [881, 1101, 1115, 1173, 956, 1122, 1275, 1437]
	| approx positives in sample 512: 155
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 19, 17, 29, 12, 20, 18, 22]
	Time taken saving stuff: 0.01s
episode: 78/2000 -> reward: -249.9999999999811, steps:67488, time-taken: 3.74min, time-elasped: 243.34min
-> berries picked: 78 of 800 | patches-visited: [5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 9267 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [933, 1139, 1133, 1182, 971, 1150, 1280, 1479]
	| approx positives in sample 512: 234
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [37, 33, 26, 34, 24, 28, 22, 30]
	Time taken saving stuff: 0.02s
episode: 79/2000 -> reward: -249.99999999998306, steps:67776, time-taken: 3.75min, time-elasped: 247.10min
-> berries picked: 77 of 800 | patches-visited: [5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 9492 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [966, 1169, 1158, 1215, 994, 1207, 1287, 1496]
	| approx positives in sample 512: 243
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 31, 27, 26, 28, 32, 36, 39]
	Time taken saving stuff: 0.01s
episode: 80/2000 -> reward: -249.99999999998298, steps:62976, time-taken: 3.03min, time-elasped: 250.12min
-> berries picked: 64 of 800 | patches-visited: [2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 9678 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [996, 1247, 1164, 1230, 1024, 1217, 1290, 1510]
	| approx positives in sample 512: 166
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 21, 22, 18, 19, 20, 23, 27]
	Time taken saving stuff: 121.29s

==================================================
eval-episode: 80 -> reward: -0.4999999999999458, steps: 62112.0, wall-time: 49.07s
-> berries picked: 46 of 800 | patches-visited: [1, 2] | juice left:-0.00
==================================================

episode: 81/2000 -> reward: -249.9999999999845, steps:66240, time-taken: 3.50min, time-elasped: 256.47min
-> berries picked: 71 of 800 | patches-visited: [8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 9850 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1032, 1287, 1201, 1235, 1033, 1219, 1301, 1542]
	| approx positives in sample 512: 237
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 37, 29, 38, 19, 26, 39, 34]
	Time taken saving stuff: 0.01s
episode: 82/2000 -> reward: -249.99999999998133, steps:65184, time-taken: 2.85min, time-elasped: 259.31min
-> berries picked: 74 of 800 | patches-visited: [8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 10065 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1071, 1302, 1222, 1259, 1045, 1269, 1331, 1566]
	| approx positives in sample 512: 149
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 21, 16, 30, 15, 17, 9, 26]
	Time taken saving stuff: 0.01s
episode: 83/2000 -> reward: -249.9999999999851, steps:68640, time-taken: 3.88min, time-elasped: 263.20min
-> berries picked: 80 of 800 | patches-visited: [7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 10270 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1113, 1344, 1237, 1278, 1074, 1295, 1345, 1584]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 27, 25, 31, 30, 25, 19, 36]
	Time taken saving stuff: 0.01s
episode: 84/2000 -> reward: -249.99999999998295, steps:69888, time-taken: 3.87min, time-elasped: 267.08min
-> berries picked: 85 of 800 | patches-visited: [1, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 10513 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1163, 1386, 1257, 1299, 1089, 1324, 1357, 1638]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 39, 25, 28, 24, 22, 23, 31]
	Time taken saving stuff: 0.01s
episode: 85/2000 -> reward: -249.9999999999812, steps:66432, time-taken: 4.17min, time-elasped: 271.25min
-> berries picked: 79 of 800 | patches-visited: [1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 10689 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1180, 1409, 1294, 1309, 1129, 1324, 1377, 1667]
	| approx positives in sample 512: 239
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 39, 19, 31, 28, 22, 30, 35]
	Time taken saving stuff: 0.01s
episode: 86/2000 -> reward: -249.99999999998553, steps:64032, time-taken: 2.77min, time-elasped: 274.03min
-> berries picked: 63 of 800 | patches-visited: [6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 10841 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1202, 1441, 1297, 1331, 1138, 1331, 1400, 1701]
	| approx positives in sample 512: 162
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 21, 16, 17, 20, 18, 24, 25]
	Time taken saving stuff: 0.01s
episode: 87/2000 -> reward: -249.9999999999836, steps:53952, time-taken: 2.51min, time-elasped: 276.54min
-> berries picked: 20 of 800 | patches-visited: [6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 10789 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1200, 1447, 1298, 1322, 1139, 1304, 1383, 1696]
	| approx positives in sample 512: 196
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 30, 18, 23, 20, 22, 33, 26]
	Time taken saving stuff: 0.01s
episode: 88/2000 -> reward: -249.9999999999834, steps:54528, time-taken: 2.60min, time-elasped: 279.15min
-> berries picked: 24 of 800 | patches-visited: [4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 10859 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1203, 1471, 1304, 1328, 1139, 1313, 1394, 1707]
	| approx positives in sample 512: 186
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 37, 21, 29, 16, 20, 18, 24]
	Time taken saving stuff: 0.01s
episode: 89/2000 -> reward: -249.9999999999844, steps:62784, time-taken: 2.94min, time-elasped: 282.11min
-> berries picked: 54 of 800 | patches-visited: [3, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 11017 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1238, 1501, 1325, 1343, 1139, 1340, 1395, 1736]
	| approx positives in sample 512: 164
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 28, 18, 22, 17, 17, 17, 28]
	Time taken saving stuff: 0.01s
episode: 90/2000 -> reward: -249.99999999998298, steps:64512, time-taken: 2.87min, time-elasped: 284.98min
-> berries picked: 64 of 800 | patches-visited: [7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 11097 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1270, 1514, 1338, 1332, 1137, 1340, 1396, 1770]
	| approx positives in sample 512: 172
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 24, 15, 19, 17, 21, 26, 32]
	Time taken saving stuff: 13.88s

==================================================
eval-episode: 90 -> reward: -0.49999999999994404, steps: 67584.0, wall-time: 68.84s
-> berries picked: 79 of 800 | patches-visited: [1, 2] | juice left:-0.00
==================================================

episode: 91/2000 -> reward: -249.9999999999818, steps:64416, time-taken: 2.61min, time-elasped: 288.98min
-> berries picked: 63 of 800 | patches-visited: [4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 11232 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1281, 1555, 1361, 1337, 1161, 1333, 1407, 1797]
	| approx positives in sample 512: 151
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 29, 24, 16, 15, 15, 14, 21]
	Time taken saving stuff: 0.01s
episode: 92/2000 -> reward: -249.99999999998025, steps:67776, time-taken: 3.47min, time-elasped: 292.46min
-> berries picked: 79 of 800 | patches-visited: [9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 11404 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1315, 1601, 1383, 1344, 1189, 1354, 1416, 1802]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 43, 40, 28, 26, 18, 24, 35]
	Time taken saving stuff: 0.01s
episode: 93/2000 -> reward: -249.99999999997684, steps:60960, time-taken: 2.71min, time-elasped: 295.18min
-> berries picked: 44 of 800 | patches-visited: [6, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 11530 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1336, 1619, 1404, 1356, 1192, 1381, 1425, 1817]
	| approx positives in sample 512: 165
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 26, 15, 19, 17, 20, 21, 32]
	Time taken saving stuff: 0.01s
episode: 94/2000 -> reward: -249.9999999999847, steps:65664, time-taken: 2.78min, time-elasped: 297.96min
-> berries picked: 63 of 800 | patches-visited: [1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 11669 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1358, 1635, 1414, 1377, 1220, 1391, 1433, 1841]
	| approx positives in sample 512: 159
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 26, 23, 22, 20, 12, 17, 25]
	Time taken saving stuff: 0.01s
episode: 95/2000 -> reward: -249.999999999983, steps:66144, time-taken: 3.74min, time-elasped: 301.71min
-> berries picked: 79 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 11652 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1328, 1636, 1418, 1381, 1224, 1380, 1443, 1842]
	| approx positives in sample 512: 238
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 30, 31, 31, 23, 29, 22, 49]
	Time taken saving stuff: 0.01s
episode: 96/2000 -> reward: -249.99999999998337, steps:65568, time-taken: 2.75min, time-elasped: 304.47min
-> berries picked: 80 of 800 | patches-visited: [1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 11882 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1348, 1672, 1460, 1404, 1272, 1390, 1479, 1857]
	| approx positives in sample 512: 156
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 26, 24, 21, 14, 16, 19, 19]
	Time taken saving stuff: 0.01s
episode: 97/2000 -> reward: -249.99999999997996, steps:57792, time-taken: 2.67min, time-elasped: 307.14min
-> berries picked: 37 of 800 | patches-visited: [1, 3, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 11929 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1370, 1677, 1477, 1407, 1272, 1385, 1476, 1865]
	| approx positives in sample 512: 177
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 23, 18, 28, 15, 25, 25, 23]
	Time taken saving stuff: 0.01s
episode: 98/2000 -> reward: -249.99999999997655, steps:74976, time-taken: 3.75min, time-elasped: 310.90min
-> berries picked: 101 of 800 | patches-visited: [7, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 12225 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1430, 1713, 1511, 1437, 1295, 1445, 1493, 1901]
	| approx positives in sample 512: 204
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 41, 30, 19, 26, 18, 20, 26]
	Time taken saving stuff: 0.01s
episode: 99/2000 -> reward: -249.99999999998602, steps:65280, time-taken: 2.75min, time-elasped: 313.64min
-> berries picked: 72 of 800 | patches-visited: [1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 12414 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1462, 1772, 1534, 1454, 1316, 1455, 1507, 1914]
	| approx positives in sample 512: 166
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 19, 18, 18, 25, 23, 26, 19]
	Time taken saving stuff: 0.01s
episode: 100/2000 -> reward: -249.99999999998496, steps:66240, time-taken: 3.54min, time-elasped: 317.19min
-> berries picked: 75 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 12396 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1467, 1812, 1511, 1468, 1293, 1435, 1492, 1918]
	| approx positives in sample 512: 230
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 38, 31, 26, 21, 29, 27, 29]
	Time taken saving stuff: 18.28s

==================================================
eval-episode: 100 -> reward: -0.49999999999992645, steps: 76032.0, wall-time: 71.78s
-> berries picked: 106 of 800 | patches-visited: [1, 2, 9] | juice left:-0.00
==================================================

episode: 101/2000 -> reward: -249.99999999998394, steps:62784, time-taken: 2.57min, time-elasped: 321.26min
-> berries picked: 56 of 800 | patches-visited: [8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 12535 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1481, 1830, 1538, 1486, 1313, 1446, 1500, 1941]
	| approx positives in sample 512: 158
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 18, 20, 17, 16, 20, 18, 26]
	Time taken saving stuff: 0.01s
episode: 102/2000 -> reward: -249.99999999997473, steps:65472, time-taken: 2.64min, time-elasped: 323.91min
-> berries picked: 60 of 800 | patches-visited: [8, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 12558 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1474, 1869, 1527, 1485, 1308, 1457, 1487, 1951]
	| approx positives in sample 512: 155
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 29, 18, 21, 15, 16, 14, 20]
	Time taken saving stuff: 0.01s
episode: 103/2000 -> reward: -249.99999999998448, steps:64512, time-taken: 2.65min, time-elasped: 326.57min
-> berries picked: 65 of 800 | patches-visited: [8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 12659 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1480, 1886, 1544, 1487, 1343, 1456, 1498, 1965]
	| approx positives in sample 512: 171
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 27, 15, 26, 28, 18, 20, 20]
	Time taken saving stuff: 0.01s
episode: 104/2000 -> reward: -249.9999999999828, steps:68736, time-taken: 3.68min, time-elasped: 330.25min
-> berries picked: 79 of 800 | patches-visited: [3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 12791 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1508, 1954, 1555, 1506, 1329, 1475, 1479, 1985]
	| approx positives in sample 512: 244
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 40, 29, 29, 18, 25, 31, 49]
	Time taken saving stuff: 0.01s
episode: 105/2000 -> reward: -249.99999999998417, steps:53856, time-taken: 3.07min, time-elasped: 333.33min
-> berries picked: 17 of 800 | patches-visited: [3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 12833 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1516, 1969, 1558, 1511, 1333, 1481, 1478, 1987]
	| approx positives in sample 512: 184
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 31, 27, 19, 18, 26, 15, 27]
	Time taken saving stuff: 0.02s
episode: 106/2000 -> reward: -249.99999999998232, steps:54240, time-taken: 3.62min, time-elasped: 336.95min
-> berries picked: 21 of 800 | patches-visited: [1, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 12841 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1514, 1971, 1569, 1502, 1348, 1471, 1482, 1984]
	| approx positives in sample 512: 203
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 21, 25, 24, 22, 21, 36, 25]
	Time taken saving stuff: 0.01s
episode: 107/2000 -> reward: -249.99999999998442, steps:55008, time-taken: 2.60min, time-elasped: 339.56min
-> berries picked: 26 of 800 | patches-visited: [8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 12897 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1521, 1976, 1583, 1502, 1356, 1470, 1498, 1991]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 34, 20, 27, 19, 22, 17, 29]
	Time taken saving stuff: 0.01s
episode: 108/2000 -> reward: -249.99999999998397, steps:64800, time-taken: 2.64min, time-elasped: 342.21min
-> berries picked: 58 of 800 | patches-visited: [1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 13025 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1556, 1992, 1604, 1506, 1378, 1480, 1505, 2004]
	| approx positives in sample 512: 169
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 28, 14, 16, 22, 26, 21, 20]
	Time taken saving stuff: 0.01s
episode: 109/2000 -> reward: -249.99999999998494, steps:67680, time-taken: 3.60min, time-elasped: 345.81min
-> berries picked: 77 of 800 | patches-visited: [2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 13114 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1559, 2019, 1607, 1534, 1390, 1497, 1497, 2011]
	| approx positives in sample 512: 251
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [39, 34, 36, 27, 31, 19, 25, 40]
	Time taken saving stuff: 0.01s
episode: 110/2000 -> reward: -249.99999999998616, steps:63360, time-taken: 2.74min, time-elasped: 348.55min
-> berries picked: 58 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 13268 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1581, 2056, 1627, 1534, 1410, 1519, 1513, 2028]
	| approx positives in sample 512: 144
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 30, 13, 29, 20, 14, 10, 13]
	Time taken saving stuff: 14.42s

==================================================
eval-episode: 110 -> reward: -0.49999999999991696, steps: 74208.0, wall-time: 62.65s
-> berries picked: 96 of 800 | patches-visited: [1, 8] | juice left:-0.00
==================================================

episode: 111/2000 -> reward: -249.999999999981, steps:66336, time-taken: 3.56min, time-elasped: 353.41min
-> berries picked: 71 of 800 | patches-visited: [8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 13261 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1560, 2132, 1613, 1521, 1428, 1497, 1486, 2024]
	| approx positives in sample 512: 247
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 34, 29, 32, 23, 28, 25, 41]
	Time taken saving stuff: 0.01s
episode: 112/2000 -> reward: -249.99999999998244, steps:59712, time-taken: 2.60min, time-elasped: 356.01min
-> berries picked: 39 of 800 | patches-visited: [0, 2, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 13368 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1573, 2158, 1622, 1542, 1440, 1499, 1498, 2036]
	| approx positives in sample 512: 170
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 33, 18, 18, 19, 14, 21, 29]
	Time taken saving stuff: 0.01s
episode: 113/2000 -> reward: -249.99999999998266, steps:58560, time-taken: 2.73min, time-elasped: 358.74min
-> berries picked: 41 of 800 | patches-visited: [1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 13309 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1576, 2147, 1618, 1524, 1433, 1485, 1505, 2021]
	| approx positives in sample 512: 188
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 36, 21, 24, 18, 26, 22, 27]
	Time taken saving stuff: 0.01s
episode: 114/2000 -> reward: -249.9999999999771, steps:61632, time-taken: 2.67min, time-elasped: 361.42min
-> berries picked: 47 of 800 | patches-visited: [3, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 13426 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1589, 2176, 1641, 1542, 1439, 1499, 1506, 2034]
	| approx positives in sample 512: 172
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 30, 26, 27, 13, 15, 19, 20]
	Time taken saving stuff: 0.01s
episode: 115/2000 -> reward: -249.9999999999818, steps:63840, time-taken: 2.70min, time-elasped: 364.13min
-> berries picked: 61 of 800 | patches-visited: [8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 13518 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1595, 2206, 1650, 1558, 1460, 1493, 1521, 2035]
	| approx positives in sample 512: 187
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 32, 23, 21, 16, 14, 22, 32]
	Time taken saving stuff: 0.01s
episode: 116/2000 -> reward: -249.99999999998244, steps:74688, time-taken: 3.63min, time-elasped: 367.76min
-> berries picked: 93 of 800 | patches-visited: [3, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 13618 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1601, 2265, 1663, 1571, 1479, 1503, 1495, 2041]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 41, 20, 29, 22, 20, 25, 29]
	Time taken saving stuff: 0.01s
episode: 117/2000 -> reward: -249.999999999981, steps:65760, time-taken: 2.80min, time-elasped: 370.57min
-> berries picked: 63 of 800 | patches-visited: [5, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 13791 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1625, 2298, 1678, 1589, 1502, 1538, 1501, 2060]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 35, 11, 20, 12, 11, 13, 16]
	Time taken saving stuff: 0.01s
episode: 118/2000 -> reward: -249.99999999998204, steps:66048, time-taken: 3.58min, time-elasped: 374.16min
-> berries picked: 64 of 800 | patches-visited: [8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 13871 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1646, 2325, 1676, 1591, 1511, 1555, 1512, 2055]
	| approx positives in sample 512: 261
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [36, 48, 26, 32, 28, 34, 23, 34]
	Time taken saving stuff: 0.01s
episode: 119/2000 -> reward: -249.99999999997846, steps:67392, time-taken: 3.59min, time-elasped: 377.75min
-> berries picked: 63 of 800 | patches-visited: [7, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 14045 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1681, 2347, 1706, 1594, 1533, 1565, 1526, 2093]
	| approx positives in sample 512: 244
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 50, 25, 37, 31, 20, 20, 39]
	Time taken saving stuff: 0.01s
episode: 120/2000 -> reward: -249.99999999997584, steps:68832, time-taken: 3.66min, time-elasped: 381.41min
-> berries picked: 76 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 14218 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1709, 2391, 1731, 1612, 1579, 1558, 1533, 2105]
	| approx positives in sample 512: 238
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 50, 28, 34, 21, 28, 22, 31]
	Time taken saving stuff: 18.45s

==================================================
eval-episode: 120 -> reward: -0.4999999999999407, steps: 66528.0, wall-time: 65.19s
-> berries picked: 69 of 800 | patches-visited: [0, 1] | juice left:-0.00
==================================================

episode: 121/2000 -> reward: -249.99999999998533, steps:62208, time-taken: 2.53min, time-elasped: 385.34min
-> berries picked: 50 of 800 | patches-visited: [1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 14283 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1710, 2405, 1752, 1627, 1600, 1553, 1532, 2104]
	| approx positives in sample 512: 164
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 29, 21, 24, 17, 16, 15, 18]
	Time taken saving stuff: 0.01s
episode: 122/2000 -> reward: -249.99999999997527, steps:67680, time-taken: 3.48min, time-elasped: 388.82min
-> berries picked: 68 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 14273 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1728, 2392, 1746, 1614, 1598, 1578, 1521, 2096]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 41, 33, 29, 31, 31, 19, 30]
	Time taken saving stuff: 0.01s
episode: 123/2000 -> reward: -249.99999999998423, steps:59328, time-taken: 2.52min, time-elasped: 391.35min
-> berries picked: 39 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 14374 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1745, 2421, 1745, 1623, 1618, 1593, 1529, 2100]
	| approx positives in sample 512: 190
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 39, 17, 10, 21, 25, 18, 33]
	Time taken saving stuff: 0.01s
episode: 124/2000 -> reward: -249.9999999999841, steps:54144, time-taken: 2.37min, time-elasped: 393.72min
-> berries picked: 21 of 800 | patches-visited: [1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 14307 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1738, 2419, 1736, 1615, 1619, 1572, 1514, 2094]
	| approx positives in sample 512: 192
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 35, 27, 24, 23, 18, 16, 32]
	Time taken saving stuff: 0.01s
episode: 125/2000 -> reward: -249.9999999999801, steps:62112, time-taken: 2.76min, time-elasped: 396.49min
-> berries picked: 50 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 14455 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1744, 2433, 1763, 1642, 1640, 1590, 1532, 2111]
	| approx positives in sample 512: 202
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 30, 23, 28, 27, 16, 27, 23]
	Time taken saving stuff: 0.01s
episode: 126/2000 -> reward: -249.999999999985, steps:53472, time-taken: 2.47min, time-elasped: 398.97min
-> berries picked: 19 of 800 | patches-visited: [6, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 14435 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1736, 2439, 1763, 1635, 1642, 1587, 1527, 2106]
	| approx positives in sample 512: 181
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 32, 20, 18, 17, 17, 25, 27]
	Time taken saving stuff: 0.01s
episode: 127/2000 -> reward: -249.9999999999844, steps:57504, time-taken: 2.46min, time-elasped: 401.44min
-> berries picked: 33 of 800 | patches-visited: [1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 14532 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1745, 2463, 1766, 1641, 1657, 1602, 1537, 2121]
	| approx positives in sample 512: 173
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 35, 13, 25, 20, 12, 18, 30]
	Time taken saving stuff: 0.01s
episode: 128/2000 -> reward: -249.99999999998352, steps:53856, time-taken: 2.51min, time-elasped: 403.95min
-> berries picked: 23 of 800 | patches-visited: [8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 14577 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1758, 2480, 1774, 1634, 1670, 1601, 1537, 2123]
	| approx positives in sample 512: 194
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 40, 24, 28, 15, 16, 17, 27]
	Time taken saving stuff: 0.01s
episode: 129/2000 -> reward: -249.9999999999836, steps:61248, time-taken: 2.53min, time-elasped: 406.49min
-> berries picked: 47 of 800 | patches-visited: [3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 14705 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1773, 2495, 1795, 1652, 1674, 1615, 1559, 2142]
	| approx positives in sample 512: 152
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 27, 16, 15, 18, 9, 16, 32]
	Time taken saving stuff: 0.01s
episode: 130/2000 -> reward: -249.99999999998263, steps:64032, time-taken: 2.86min, time-elasped: 409.35min
-> berries picked: 58 of 800 | patches-visited: [7, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 14791 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1795, 2523, 1799, 1657, 1682, 1622, 1568, 2145]
	| approx positives in sample 512: 176
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 24, 27, 19, 18, 25, 13, 29]
	Time taken saving stuff: 14.22s

==================================================
eval-episode: 130 -> reward: -0.4999999999999177, steps: 64704.0, wall-time: 64.22s
-> berries picked: 56 of 800 | patches-visited: [0, 1] | juice left:-0.00
==================================================

episode: 131/2000 -> reward: -249.99999999998406, steps:53664, time-taken: 2.42min, time-elasped: 413.08min
-> berries picked: 18 of 800 | patches-visited: [8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 14722 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1786, 2513, 1799, 1654, 1686, 1609, 1545, 2130]
	| approx positives in sample 512: 204
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 39, 17, 27, 33, 19, 27, 24]
	Time taken saving stuff: 0.01s
episode: 132/2000 -> reward: -249.99999999998062, steps:63360, time-taken: 2.75min, time-elasped: 415.84min
-> berries picked: 56 of 800 | patches-visited: [2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 14888 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1837, 2537, 1825, 1663, 1709, 1612, 1545, 2160]
	| approx positives in sample 512: 177
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 37, 17, 28, 19, 20, 15, 23]
	Time taken saving stuff: 0.01s
episode: 133/2000 -> reward: -249.99999999997937, steps:56736, time-taken: 2.51min, time-elasped: 418.35min
-> berries picked: 37 of 800 | patches-visited: [4, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 14971 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1853, 2559, 1822, 1672, 1716, 1635, 1546, 2168]
	| approx positives in sample 512: 194
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 39, 26, 21, 26, 23, 13, 26]
	Time taken saving stuff: 0.01s
episode: 134/2000 -> reward: -249.99999999998198, steps:51648, time-taken: 2.51min, time-elasped: 420.87min
-> berries picked: 14 of 800 | patches-visited: [8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 15005 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1855, 2573, 1828, 1672, 1722, 1638, 1546, 2171]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 34, 29, 19, 20, 17, 25, 39]
	Time taken saving stuff: 0.01s
episode: 135/2000 -> reward: -249.9999999999751, steps:64992, time-taken: 2.76min, time-elasped: 423.63min
-> berries picked: 60 of 800 | patches-visited: [1, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 15155 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1863, 2594, 1859, 1680, 1736, 1663, 1555, 2205]
	| approx positives in sample 512: 174
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 29, 24, 14, 24, 21, 17, 18]
	Time taken saving stuff: 0.01s
episode: 136/2000 -> reward: -249.99999999998187, steps:58656, time-taken: 2.62min, time-elasped: 426.26min
-> berries picked: 41 of 800 | patches-visited: [2, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 15171 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1846, 2611, 1873, 1687, 1744, 1651, 1561, 2198]
	| approx positives in sample 512: 203
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 26, 32, 27, 29, 17, 24, 25]
	Time taken saving stuff: 0.01s
episode: 137/2000 -> reward: -249.9999999999841, steps:50304, time-taken: 2.32min, time-elasped: 428.58min
-> berries picked: 7 of 800 | patches-visited: [8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 15181 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1848, 2609, 1875, 1686, 1755, 1651, 1561, 2196]
	| approx positives in sample 512: 191
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 28, 21, 20, 22, 21, 23, 28]
	Time taken saving stuff: 0.01s
episode: 138/2000 -> reward: -249.99999999998252, steps:65568, time-taken: 2.85min, time-elasped: 431.44min
-> berries picked: 66 of 800 | patches-visited: [1, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 15370 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1863, 2667, 1893, 1707, 1773, 1675, 1582, 2210]
	| approx positives in sample 512: 167
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 24, 17, 15, 25, 18, 18, 29]
	Time taken saving stuff: 0.01s
episode: 139/2000 -> reward: -249.99999999998397, steps:54912, time-taken: 2.46min, time-elasped: 433.91min
-> berries picked: 24 of 800 | patches-visited: [3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 15347 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1863, 2671, 1894, 1705, 1764, 1668, 1575, 2207]
	| approx positives in sample 512: 208
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 37, 17, 29, 22, 16, 27, 29]
	Time taken saving stuff: 0.01s
episode: 140/2000 -> reward: -249.99999999998525, steps:59424, time-taken: 2.62min, time-elasped: 436.54min
-> berries picked: 43 of 800 | patches-visited: [9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 15473 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1887, 2695, 1916, 1717, 1773, 1685, 1584, 2216]
	| approx positives in sample 512: 165
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 31, 20, 16, 17, 19, 16, 23]
	Time taken saving stuff: 18.24s

==================================================
eval-episode: 140 -> reward: -0.4999999999999224, steps: 71328.0, wall-time: 68.01s
-> berries picked: 82 of 800 | patches-visited: [0, 1, 8] | juice left:-0.00
==================================================

episode: 141/2000 -> reward: -249.99999999998232, steps:63072, time-taken: 2.75min, time-elasped: 440.73min
-> berries picked: 65 of 800 | patches-visited: [3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 15643 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1911, 2736, 1927, 1736, 1789, 1699, 1609, 2236]
	| approx positives in sample 512: 181
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 26, 17, 23, 24, 25, 15, 27]
	Time taken saving stuff: 0.01s
episode: 142/2000 -> reward: -249.99999999998388, steps:66144, time-taken: 3.39min, time-elasped: 444.13min
-> berries picked: 75 of 800 | patches-visited: [9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 15805 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1939, 2766, 1944, 1749, 1798, 1725, 1602, 2282]
	| approx positives in sample 512: 239
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 48, 27, 32, 30, 17, 27, 32]
	Time taken saving stuff: 0.01s
episode: 143/2000 -> reward: -249.9999999999819, steps:63744, time-taken: 2.73min, time-elasped: 446.87min
-> berries picked: 59 of 800 | patches-visited: [1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 15960 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1959, 2799, 1963, 1773, 1809, 1746, 1609, 2302]
	| approx positives in sample 512: 164
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 21, 30, 21, 17, 17, 13, 25]
	Time taken saving stuff: 0.01s
episode: 144/2000 -> reward: -249.99999999998292, steps:67200, time-taken: 3.68min, time-elasped: 450.55min
-> berries picked: 74 of 800 | patches-visited: [2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 16007 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1969, 2815, 1967, 1774, 1829, 1740, 1627, 2286]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 41, 25, 30, 25, 19, 26, 34]
	Time taken saving stuff: 0.01s
episode: 145/2000 -> reward: -249.99999999998477, steps:54336, time-taken: 2.42min, time-elasped: 452.98min
-> berries picked: 29 of 800 | patches-visited: [4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 16075 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [1998, 2823, 1981, 1773, 1843, 1736, 1630, 2291]
	| approx positives in sample 512: 210
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 41, 25, 27, 16, 24, 24, 25]
	Time taken saving stuff: 0.01s
episode: 146/2000 -> reward: -249.99999999998275, steps:64800, time-taken: 3.05min, time-elasped: 456.03min
-> berries picked: 70 of 800 | patches-visited: [7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 16254 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2041, 2851, 2012, 1779, 1853, 1744, 1662, 2312]
	| approx positives in sample 512: 179
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 32, 14, 17, 20, 17, 24, 28]
	Time taken saving stuff: 0.01s
episode: 147/2000 -> reward: -249.9999999999808, steps:65376, time-taken: 3.00min, time-elasped: 459.04min
-> berries picked: 64 of 800 | patches-visited: [1, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 16269 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2031, 2842, 2011, 1783, 1872, 1741, 1662, 2327]
	| approx positives in sample 512: 175
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 32, 20, 22, 24, 14, 17, 21]
	Time taken saving stuff: 0.01s
episode: 148/2000 -> reward: -249.99999999998428, steps:51840, time-taken: 2.40min, time-elasped: 461.44min
-> berries picked: 15 of 800 | patches-visited: [2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 16134 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2016, 2816, 2007, 1777, 1862, 1716, 1638, 2302]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 36, 27, 35, 21, 19, 24, 29]
	Time taken saving stuff: 0.01s
episode: 149/2000 -> reward: -249.999999999985, steps:60192, time-taken: 2.59min, time-elasped: 464.04min
-> berries picked: 45 of 800 | patches-visited: [9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 16264 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2028, 2846, 2024, 1810, 1868, 1737, 1644, 2307]
	| approx positives in sample 512: 168
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 31, 19, 20, 18, 25, 19, 16]
	Time taken saving stuff: 0.01s
episode: 150/2000 -> reward: -249.9999999999837, steps:52032, time-taken: 2.34min, time-elasped: 466.39min
-> berries picked: 14 of 800 | patches-visited: [7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 16262 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2025, 2854, 2019, 1806, 1862, 1738, 1645, 2313]
	| approx positives in sample 512: 199
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 36, 21, 21, 21, 28, 22, 22]
	Time taken saving stuff: 14.10s

==================================================
eval-episode: 150 -> reward: -0.4999999999999452, steps: 52608.0, wall-time: 53.02s
-> berries picked: 16 of 800 | patches-visited: [1] | juice left:-0.00
==================================================

episode: 151/2000 -> reward: -249.99999999998056, steps:65760, time-taken: 3.46min, time-elasped: 470.97min
-> berries picked: 80 of 800 | patches-visited: [9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 16490 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2057, 2880, 2037, 1829, 1912, 1763, 1667, 2345]
	| approx positives in sample 512: 155
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 26, 17, 30, 13, 9, 14, 29]
	Time taken saving stuff: 0.01s
episode: 152/2000 -> reward: -249.99999999998425, steps:54336, time-taken: 2.64min, time-elasped: 473.61min
-> berries picked: 20 of 800 | patches-visited: [5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 16418 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2068, 2861, 2039, 1819, 1898, 1752, 1651, 2330]
	| approx positives in sample 512: 186
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 32, 33, 27, 21, 13, 13, 26]
	Time taken saving stuff: 0.01s
episode: 153/2000 -> reward: -249.99999999998383, steps:55104, time-taken: 3.54min, time-elasped: 477.16min
-> berries picked: 23 of 800 | patches-visited: [4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 16486 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2086, 2876, 2057, 1819, 1900, 1758, 1660, 2330]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 35, 25, 20, 30, 25, 22, 26]
	Time taken saving stuff: 0.01s
episode: 154/2000 -> reward: -249.9999999999828, steps:61632, time-taken: 3.16min, time-elasped: 480.32min
-> berries picked: 53 of 800 | patches-visited: [9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 16631 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2102, 2905, 2082, 1827, 1929, 1767, 1678, 2341]
	| approx positives in sample 512: 171
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 31, 22, 14, 23, 18, 17, 24]
	Time taken saving stuff: 0.01s
episode: 155/2000 -> reward: -249.99999999997698, steps:70560, time-taken: 4.17min, time-elasped: 484.49min
-> berries picked: 79 of 800 | patches-visited: [5, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 16701 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2104, 2912, 2122, 1814, 1954, 1768, 1689, 2338]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 45, 20, 22, 24, 22, 24, 27]
	Time taken saving stuff: 0.01s
episode: 156/2000 -> reward: -249.99999999998406, steps:62496, time-taken: 4.70min, time-elasped: 489.20min
-> berries picked: 64 of 800 | patches-visited: [3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 16875 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2103, 2936, 2146, 1821, 1992, 1776, 1711, 2390]
	| approx positives in sample 512: 183
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 35, 24, 21, 30, 9, 18, 15]
	Time taken saving stuff: 0.01s
episode: 157/2000 -> reward: -249.99999999998232, steps:60576, time-taken: 2.84min, time-elasped: 492.04min
-> berries picked: 44 of 800 | patches-visited: [6, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 16858 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2092, 2936, 2157, 1824, 1982, 1789, 1697, 2381]
	| approx positives in sample 512: 168
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 39, 25, 14, 13, 16, 23, 16]
	Time taken saving stuff: 0.01s
episode: 158/2000 -> reward: -249.99999999997078, steps:71616, time-taken: 4.36min, time-elasped: 496.41min
-> berries picked: 92 of 800 | patches-visited: [1, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 17075 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2146, 2960, 2200, 1840, 2008, 1808, 1706, 2407]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 45, 26, 24, 23, 19, 26, 34]
	Time taken saving stuff: 0.01s
episode: 159/2000 -> reward: -249.99999999998164, steps:67008, time-taken: 4.22min, time-elasped: 500.63min
-> berries picked: 69 of 800 | patches-visited: [6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 17198 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2179, 2974, 2200, 1841, 2033, 1815, 1730, 2426]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 37, 28, 24, 28, 16, 30, 33]
	Time taken saving stuff: 0.05s
episode: 160/2000 -> reward: -249.99999999998158, steps:65376, time-taken: 3.90min, time-elasped: 504.55min
-> berries picked: 76 of 800 | patches-visited: [3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 17317 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2196, 2982, 2204, 1872, 2044, 1829, 1752, 2438]
	| approx positives in sample 512: 177
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 24, 19, 18, 20, 29, 19, 27]
	Time taken saving stuff: 19.09s

==================================================
eval-episode: 160 -> reward: -0.4999999999999449, steps: 56448.0, wall-time: 84.47s
-> berries picked: 28 of 800 | patches-visited: [1] | juice left:-0.00
==================================================

episode: 161/2000 -> reward: -249.99999999998414, steps:54720, time-taken: 3.95min, time-elasped: 510.23min
-> berries picked: 22 of 800 | patches-visited: [3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 17043 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2176, 2931, 2169, 1855, 2023, 1797, 1719, 2373]
	| approx positives in sample 512: 203
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 37, 19, 37, 19, 21, 15, 31]
	Time taken saving stuff: 0.01s
episode: 162/2000 -> reward: -249.99999999998488, steps:69024, time-taken: 4.23min, time-elasped: 514.46min
-> berries picked: 77 of 800 | patches-visited: [6, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 17256 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2220, 2951, 2200, 1867, 2048, 1828, 1734, 2408]
	| approx positives in sample 512: 210
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 34, 27, 23, 23, 28, 26, 19]
	Time taken saving stuff: 0.01s
episode: 163/2000 -> reward: -249.99999999997956, steps:60288, time-taken: 2.88min, time-elasped: 517.35min
-> berries picked: 50 of 800 | patches-visited: [6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 17399 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2226, 2963, 2208, 1911, 2050, 1840, 1770, 2431]
	| approx positives in sample 512: 179
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 25, 24, 28, 25, 15, 14, 21]
	Time taken saving stuff: 0.01s
episode: 164/2000 -> reward: -249.99999999998383, steps:66912, time-taken: 4.64min, time-elasped: 521.99min
-> berries picked: 77 of 800 | patches-visited: [7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 17517 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2238, 2984, 2223, 1907, 2068, 1839, 1816, 2442]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 40, 21, 30, 31, 24, 19, 29]
	Time taken saving stuff: 0.01s
episode: 165/2000 -> reward: -249.99999999998258, steps:64512, time-taken: 2.59min, time-elasped: 524.59min
-> berries picked: 70 of 800 | patches-visited: [4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 17613 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2256, 2991, 2249, 1902, 2085, 1841, 1824, 2465]
	| approx positives in sample 512: 165
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 20, 21, 23, 21, 17, 16, 27]
	Time taken saving stuff: 0.01s
episode: 166/2000 -> reward: -249.99999999998533, steps:57312, time-taken: 2.80min, time-elasped: 527.40min
-> berries picked: 36 of 800 | patches-visited: [2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 17307 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2212, 2942, 2209, 1868, 2047, 1809, 1801, 2419]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 41, 29, 20, 18, 27, 19, 25]
	Time taken saving stuff: 0.01s
episode: 167/2000 -> reward: -249.99999999998496, steps:61344, time-taken: 2.67min, time-elasped: 530.07min
-> berries picked: 47 of 800 | patches-visited: [2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 17441 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2240, 2965, 2220, 1880, 2056, 1813, 1819, 2448]
	| approx positives in sample 512: 166
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 28, 14, 16, 17, 21, 19, 22]
	Time taken saving stuff: 0.01s
episode: 168/2000 -> reward: -249.99999999998545, steps:67296, time-taken: 3.66min, time-elasped: 533.74min
-> berries picked: 73 of 800 | patches-visited: [7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 17587 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2248, 2994, 2240, 1916, 2053, 1844, 1829, 2463]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 48, 17, 25, 35, 27, 20, 26]
	Time taken saving stuff: 0.01s
episode: 169/2000 -> reward: -249.99999999998363, steps:66240, time-taken: 3.54min, time-elasped: 537.29min
-> berries picked: 73 of 800 | patches-visited: [6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 17782 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2277, 3029, 2274, 1922, 2077, 1867, 1835, 2501]
	| approx positives in sample 512: 237
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 49, 30, 18, 23, 20, 22, 44]
	Time taken saving stuff: 0.01s
episode: 170/2000 -> reward: -249.99999999998215, steps:60576, time-taken: 2.80min, time-elasped: 540.09min
-> berries picked: 52 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 17906 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2298, 3035, 2282, 1939, 2099, 1889, 1850, 2514]
	| approx positives in sample 512: 175
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 33, 21, 15, 16, 32, 16, 18]
	Time taken saving stuff: 14.36s

==================================================
eval-episode: 170 -> reward: -0.4999999999999458, steps: 62208.0, wall-time: 68.19s
-> berries picked: 50 of 800 | patches-visited: [1, 2] | juice left:-0.00
==================================================

episode: 171/2000 -> reward: -249.9999999999844, steps:66528, time-taken: 3.48min, time-elasped: 544.95min
-> berries picked: 64 of 800 | patches-visited: [5, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 17893 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2297, 3021, 2274, 1932, 2105, 1896, 1860, 2508]
	| approx positives in sample 512: 223
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 34, 41, 23, 24, 19, 29, 37]
	Time taken saving stuff: 0.01s
episode: 172/2000 -> reward: -249.99999999998326, steps:62784, time-taken: 2.61min, time-elasped: 547.56min
-> berries picked: 53 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 17999 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2298, 3036, 2286, 1973, 2113, 1902, 1867, 2524]
	| approx positives in sample 512: 152
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 28, 23, 11, 20, 17, 10, 19]
	Time taken saving stuff: 0.01s
episode: 173/2000 -> reward: -249.99999999998082, steps:67488, time-taken: 3.66min, time-elasped: 551.23min
-> berries picked: 75 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 17991 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2298, 3029, 2278, 1961, 2101, 1894, 1896, 2534]
	| approx positives in sample 512: 241
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 43, 29, 32, 30, 25, 26, 33]
	Time taken saving stuff: 0.01s
episode: 174/2000 -> reward: -249.99999999998082, steps:62304, time-taken: 2.79min, time-elasped: 554.03min
-> berries picked: 57 of 800 | patches-visited: [2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 18147 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2323, 3064, 2289, 1988, 2108, 1908, 1902, 2565]
	| approx positives in sample 512: 179
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 41, 22, 29, 17, 19, 15, 17]
	Time taken saving stuff: 0.01s
episode: 175/2000 -> reward: -249.99999999997976, steps:64032, time-taken: 2.66min, time-elasped: 556.70min
-> berries picked: 65 of 800 | patches-visited: [2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 18236 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2322, 3088, 2300, 2027, 2114, 1910, 1916, 2559]
	| approx positives in sample 512: 178
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 29, 21, 29, 19, 14, 17, 27]
	Time taken saving stuff: 0.01s
episode: 176/2000 -> reward: -249.9999999999832, steps:66240, time-taken: 3.58min, time-elasped: 560.29min
-> berries picked: 73 of 800 | patches-visited: [1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 18320 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2330, 3099, 2322, 2024, 2134, 1896, 1931, 2584]
	| approx positives in sample 512: 238
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 48, 28, 26, 30, 18, 21, 37]
	Time taken saving stuff: 0.01s
episode: 177/2000 -> reward: -249.99999999998107, steps:59904, time-taken: 2.68min, time-elasped: 562.97min
-> berries picked: 45 of 800 | patches-visited: [4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 18445 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2348, 3112, 2358, 2035, 2140, 1910, 1948, 2594]
	| approx positives in sample 512: 170
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 30, 14, 24, 21, 19, 10, 22]
	Time taken saving stuff: 0.01s
episode: 178/2000 -> reward: -249.99999999998627, steps:62784, time-taken: 2.78min, time-elasped: 565.76min
-> berries picked: 56 of 800 | patches-visited: [9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 18527 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2373, 3112, 2379, 2045, 2140, 1926, 1952, 2600]
	| approx positives in sample 512: 171
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 34, 18, 20, 22, 14, 16, 21]
	Time taken saving stuff: 0.01s
episode: 179/2000 -> reward: -249.99999999997777, steps:65760, time-taken: 2.73min, time-elasped: 568.49min
-> berries picked: 70 of 800 | patches-visited: [3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 18537 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2399, 3091, 2356, 2071, 2134, 1921, 1966, 2599]
	| approx positives in sample 512: 181
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 30, 19, 24, 20, 16, 26, 25]
	Time taken saving stuff: 0.01s
episode: 180/2000 -> reward: -249.99999999997993, steps:59808, time-taken: 2.66min, time-elasped: 571.16min
-> berries picked: 39 of 800 | patches-visited: [3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 18487 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2391, 3088, 2324, 2084, 2129, 1932, 1952, 2587]
	| approx positives in sample 512: 180
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 37, 20, 30, 17, 19, 17, 18]
	Time taken saving stuff: 35.66s

==================================================
eval-episode: 180 -> reward: -0.49999999999993455, steps: 71040.0, wall-time: 70.07s
-> berries picked: 79 of 800 | patches-visited: [1, 2, 3] | juice left:-0.00
==================================================

episode: 181/2000 -> reward: -249.9999999999732, steps:67392, time-taken: 3.52min, time-elasped: 576.44min
-> berries picked: 76 of 800 | patches-visited: [5, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 18702 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2450, 3112, 2346, 2096, 2135, 1953, 1970, 2640]
	| approx positives in sample 512: 240
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 33, 29, 38, 25, 28, 21, 34]
	Time taken saving stuff: 0.01s
episode: 182/2000 -> reward: -249.99999999998371, steps:61440, time-taken: 2.66min, time-elasped: 579.10min
-> berries picked: 52 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 18842 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2481, 3140, 2358, 2093, 2147, 1971, 1991, 2661]
	| approx positives in sample 512: 180
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 33, 17, 24, 21, 21, 20, 22]
	Time taken saving stuff: 0.01s
episode: 183/2000 -> reward: -249.99999999998363, steps:61632, time-taken: 2.94min, time-elasped: 582.05min
-> berries picked: 53 of 800 | patches-visited: [5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 18785 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2467, 3135, 2364, 2095, 2141, 1969, 1977, 2637]
	| approx positives in sample 512: 156
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 29, 20, 19, 14, 12, 14, 25]
	Time taken saving stuff: 0.01s
episode: 184/2000 -> reward: -249.99999999998408, steps:55584, time-taken: 2.55min, time-elasped: 584.61min
-> berries picked: 24 of 800 | patches-visited: [4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 18758 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2477, 3127, 2363, 2088, 2144, 1964, 1973, 2622]
	| approx positives in sample 512: 184
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 28, 24, 16, 20, 17, 20, 33]
	Time taken saving stuff: 0.02s
episode: 185/2000 -> reward: -250.49479166665154, steps:64608, time-taken: 2.74min, time-elasped: 587.36min
-> berries picked: 60 of 800 | patches-visited: [5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 18932 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2498, 3175, 2384, 2120, 2150, 1992, 1979, 2634]
	| approx positives in sample 512: 161
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 21, 20, 18, 24, 14, 15, 21]
	Time taken saving stuff: 0.01s
episode: 186/2000 -> reward: -249.99999999998414, steps:61056, time-taken: 2.71min, time-elasped: 590.07min
-> berries picked: 47 of 800 | patches-visited: [9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 18865 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2479, 3159, 2374, 2113, 2137, 2016, 1977, 2610]
	| approx positives in sample 512: 184
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 25, 27, 20, 28, 21, 22, 20]
	Time taken saving stuff: 0.01s
episode: 187/2000 -> reward: -249.99999999998448, steps:56736, time-taken: 2.33min, time-elasped: 592.41min
-> berries picked: 34 of 800 | patches-visited: [1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 18942 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2492, 3169, 2390, 2127, 2136, 2024, 1977, 2627]
	| approx positives in sample 512: 206
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 41, 26, 19, 25, 13, 21, 26]
	Time taken saving stuff: 0.01s
episode: 188/2000 -> reward: -249.99999999997115, steps:71904, time-taken: 3.59min, time-elasped: 596.00min
-> berries picked: 87 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 19192 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2543, 3199, 2411, 2155, 2172, 2035, 1983, 2694]
	| approx positives in sample 512: 236
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 33, 30, 27, 29, 30, 19, 36]
	Time taken saving stuff: 0.01s
episode: 189/2000 -> reward: -249.99999999998184, steps:58080, time-taken: 2.66min, time-elasped: 598.67min
-> berries picked: 38 of 800 | patches-visited: [4, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 19280 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2549, 3202, 2425, 2197, 2178, 2040, 1989, 2700]
	| approx positives in sample 512: 184
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 25, 22, 23, 24, 13, 16, 32]
	Time taken saving stuff: 0.01s
episode: 190/2000 -> reward: -249.99999999997678, steps:63456, time-taken: 3.03min, time-elasped: 601.71min
-> berries picked: 55 of 800 | patches-visited: [9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 19288 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2555, 3209, 2450, 2175, 2177, 2031, 1991, 2700]
	| approx positives in sample 512: 169
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 23, 22, 11, 19, 16, 25, 33]
	Time taken saving stuff: 19.30s

==================================================
eval-episode: 190 -> reward: -0.4999999999999455, steps: 60384.0, wall-time: 51.62s
-> berries picked: 47 of 800 | patches-visited: [1] | juice left:-0.00
==================================================

episode: 191/2000 -> reward: -249.9999999999816, steps:65952, time-taken: 2.81min, time-elasped: 605.70min
-> berries picked: 74 of 800 | patches-visited: [8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 19081 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2544, 3169, 2394, 2184, 2159, 1992, 1975, 2664]
	| approx positives in sample 512: 164
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 30, 13, 19, 25, 19, 16, 22]
	Time taken saving stuff: 0.01s
episode: 192/2000 -> reward: -249.99999999998252, steps:59136, time-taken: 2.36min, time-elasped: 608.08min
-> berries picked: 38 of 800 | patches-visited: [7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 18922 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2537, 3099, 2388, 2164, 2138, 1964, 1978, 2654]
	| approx positives in sample 512: 184
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 26, 35, 15, 23, 16, 16, 24]
	Time taken saving stuff: 0.01s
episode: 193/2000 -> reward: -249.99999999998326, steps:55488, time-taken: 2.62min, time-elasped: 610.71min
-> berries picked: 29 of 800 | patches-visited: [5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 18983 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2540, 3124, 2402, 2169, 2142, 1970, 1974, 2662]
	| approx positives in sample 512: 187
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 32, 31, 16, 25, 11, 18, 30]
	Time taken saving stuff: 0.09s
episode: 194/2000 -> reward: -249.9999999999804, steps:67776, time-taken: 3.71min, time-elasped: 614.44min
-> berries picked: 70 of 800 | patches-visited: [6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 19173 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2582, 3151, 2421, 2178, 2150, 1990, 1985, 2716]
	| approx positives in sample 512: 234
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [36, 37, 40, 18, 21, 20, 24, 38]
	Time taken saving stuff: 0.02s
episode: 195/2000 -> reward: -249.99999999998175, steps:65376, time-taken: 2.71min, time-elasped: 617.15min
-> berries picked: 64 of 800 | patches-visited: [1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 19318 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2613, 3179, 2452, 2194, 2171, 1993, 1997, 2719]
	| approx positives in sample 512: 173
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 28, 17, 20, 16, 21, 22, 23]
	Time taken saving stuff: 0.03s
episode: 196/2000 -> reward: -249.99999999998465, steps:55488, time-taken: 2.60min, time-elasped: 619.77min
-> berries picked: 28 of 800 | patches-visited: [3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 18923 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2545, 3125, 2412, 2155, 2114, 1966, 1965, 2641]
	| approx positives in sample 512: 205
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 36, 24, 25, 25, 22, 20, 26]
	Time taken saving stuff: 0.03s
episode: 197/2000 -> reward: -249.99999999998465, steps:55968, time-taken: 2.64min, time-elasped: 622.42min
-> berries picked: 27 of 800 | patches-visited: [4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 18995 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2551, 3137, 2425, 2163, 2118, 1982, 1968, 2651]
	| approx positives in sample 512: 181
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 33, 28, 21, 23, 23, 17, 20]
	Time taken saving stuff: 0.01s
episode: 198/2000 -> reward: -249.99999999998687, steps:62208, time-taken: 2.81min, time-elasped: 625.23min
-> berries picked: 49 of 800 | patches-visited: [9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 19121 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2574, 3143, 2446, 2166, 2130, 1992, 1983, 2687]
	| approx positives in sample 512: 171
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 32, 19, 18, 19, 13, 12, 26]
	Time taken saving stuff: 0.10s
episode: 199/2000 -> reward: -249.99999999998232, steps:65952, time-taken: 2.85min, time-elasped: 628.08min
-> berries picked: 77 of 800 | patches-visited: [9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 19170 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2592, 3124, 2452, 2150, 2131, 2019, 2007, 2695]
	| approx positives in sample 512: 173
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 28, 26, 19, 20, 23, 16, 23]
	Time taken saving stuff: 0.01s
episode: 200/2000 -> reward: -249.99999999998465, steps:60864, time-taken: 2.45min, time-elasped: 630.54min
-> berries picked: 47 of 800 | patches-visited: [2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 19117 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2592, 3107, 2426, 2154, 2125, 2011, 2009, 2693]
	| approx positives in sample 512: 171
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 25, 25, 17, 16, 10, 17, 32]
	Time taken saving stuff: 18.85s

==================================================
eval-episode: 200 -> reward: -0.4999999999999454, steps: 59232.0, wall-time: 57.49s
-> berries picked: 42 of 800 | patches-visited: [1] | juice left:-0.00
==================================================

episode: 201/2000 -> reward: -249.9999999999761, steps:71904, time-taken: 3.38min, time-elasped: 635.19min
-> berries picked: 85 of 800 | patches-visited: [2, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 19310 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2639, 3129, 2453, 2153, 2147, 2038, 2023, 2728]
	| approx positives in sample 512: 199
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 29, 22, 30, 21, 24, 22, 23]
	Time taken saving stuff: 0.10s
episode: 202/2000 -> reward: -249.99999999997794, steps:74688, time-taken: 3.76min, time-elasped: 638.96min
-> berries picked: 95 of 800 | patches-visited: [5, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 19527 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2671, 3167, 2528, 2177, 2164, 2046, 2028, 2746]
	| approx positives in sample 512: 204
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 37, 30, 18, 19, 24, 14, 28]
	Time taken saving stuff: 0.02s
episode: 203/2000 -> reward: -249.9999999999831, steps:64992, time-taken: 2.50min, time-elasped: 641.48min
-> berries picked: 72 of 800 | patches-visited: [6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 19629 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2695, 3181, 2527, 2180, 2159, 2048, 2049, 2790]
	| approx positives in sample 512: 163
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 27, 13, 27, 15, 18, 19, 24]
	Time taken saving stuff: 0.01s
episode: 204/2000 -> reward: -249.99999999998403, steps:63936, time-taken: 2.46min, time-elasped: 643.95min
-> berries picked: 63 of 800 | patches-visited: [5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 19160 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2647, 3116, 2487, 2118, 2105, 2004, 1982, 2701]
	| approx positives in sample 512: 163
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 26, 20, 13, 14, 16, 24, 22]
	Time taken saving stuff: 0.08s
episode: 205/2000 -> reward: -249.99999999998005, steps:67296, time-taken: 3.21min, time-elasped: 647.16min
-> berries picked: 69 of 800 | patches-visited: [1, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 19308 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2671, 3128, 2517, 2115, 2110, 2029, 1998, 2740]
	| approx positives in sample 512: 245
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 51, 30, 28, 30, 22, 21, 31]
	Time taken saving stuff: 0.07s
episode: 206/2000 -> reward: -249.99999999998101, steps:66144, time-taken: 3.24min, time-elasped: 650.41min
-> berries picked: 74 of 800 | patches-visited: [6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 19502 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2705, 3153, 2537, 2137, 2136, 2035, 2020, 2779]
	| approx positives in sample 512: 234
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 30, 26, 34, 33, 25, 25, 32]
	Time taken saving stuff: 0.12s
episode: 207/2000 -> reward: -249.99999999998164, steps:63072, time-taken: 2.50min, time-elasped: 652.91min
-> berries picked: 61 of 800 | patches-visited: [1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 19629 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2720, 3156, 2552, 2143, 2149, 2065, 2049, 2795]
	| approx positives in sample 512: 167
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 25, 24, 25, 20, 15, 15, 22]
	Time taken saving stuff: 0.02s
episode: 208/2000 -> reward: -249.99999999997982, steps:56064, time-taken: 2.35min, time-elasped: 655.26min
-> berries picked: 31 of 800 | patches-visited: [0, 3, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 19494 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2704, 3117, 2534, 2138, 2154, 2054, 2029, 2764]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 37, 22, 27, 23, 19, 18, 23]
	Time taken saving stuff: 0.08s
episode: 209/2000 -> reward: -249.99999999998406, steps:56832, time-taken: 2.41min, time-elasped: 657.68min
-> berries picked: 33 of 800 | patches-visited: [1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 19558 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2717, 3115, 2556, 2135, 2161, 2068, 2035, 2771]
	| approx positives in sample 512: 172
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 29, 29, 15, 16, 13, 19, 19]
	Time taken saving stuff: 0.10s
episode: 210/2000 -> reward: -249.99999999998303, steps:67392, time-taken: 3.67min, time-elasped: 661.35min
-> berries picked: 72 of 800 | patches-visited: [5, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 19728 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2738, 3139, 2572, 2166, 2170, 2113, 2049, 2781]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 35, 35, 33, 23, 27, 18, 32]
	Time taken saving stuff: 15.57s

==================================================
eval-episode: 210 -> reward: -0.49999999999994654, steps: 72768.0, wall-time: 57.94s
-> berries picked: 92 of 800 | patches-visited: [1, 5] | juice left:-0.00
==================================================

episode: 211/2000 -> reward: -249.99999999998354, steps:67488, time-taken: 3.60min, time-elasped: 666.17min
-> berries picked: 79 of 800 | patches-visited: [2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 19908 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2783, 3171, 2574, 2174, 2194, 2128, 2072, 2812]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 35, 28, 27, 28, 20, 25, 27]
	Time taken saving stuff: 0.03s
episode: 212/2000 -> reward: -249.99999999998377, steps:64896, time-taken: 2.73min, time-elasped: 668.90min
-> berries picked: 63 of 800 | patches-visited: [7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20021 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2790, 3172, 2593, 2184, 2210, 2141, 2101, 2830]
	| approx positives in sample 512: 169
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 25, 19, 18, 14, 17, 19, 28]
	Time taken saving stuff: 0.01s
episode: 213/2000 -> reward: -249.99999999998454, steps:61920, time-taken: 2.44min, time-elasped: 671.35min
-> berries picked: 55 of 800 | patches-visited: [4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 19783 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2759, 3131, 2600, 2149, 2178, 2089, 2081, 2796]
	| approx positives in sample 512: 178
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 30, 17, 17, 16, 18, 26, 27]
	Time taken saving stuff: 0.08s
episode: 214/2000 -> reward: -249.99999999998454, steps:60768, time-taken: 2.44min, time-elasped: 673.80min
-> berries picked: 46 of 800 | patches-visited: [1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 19846 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2800, 3130, 2606, 2151, 2178, 2086, 2090, 2805]
	| approx positives in sample 512: 179
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 25, 25, 19, 25, 17, 22, 26]
	Time taken saving stuff: 0.01s
episode: 215/2000 -> reward: -249.99999999998465, steps:66144, time-taken: 3.36min, time-elasped: 677.17min
-> berries picked: 73 of 800 | patches-visited: [1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 19882 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2807, 3137, 2652, 2157, 2193, 2072, 2059, 2805]
	| approx positives in sample 512: 233
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [37, 35, 36, 21, 28, 25, 30, 21]
	Time taken saving stuff: 0.07s
episode: 216/2000 -> reward: -249.9999999999832, steps:65952, time-taken: 2.53min, time-elasped: 679.70min
-> berries picked: 73 of 800 | patches-visited: [6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20065 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2826, 3147, 2672, 2181, 2215, 2100, 2086, 2838]
	| approx positives in sample 512: 171
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 31, 20, 26, 22, 22, 14, 21]
	Time taken saving stuff: 0.01s
episode: 217/2000 -> reward: -249.999999999985, steps:63360, time-taken: 2.59min, time-elasped: 682.30min
-> berries picked: 60 of 800 | patches-visited: [6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 19910 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2800, 3115, 2654, 2170, 2224, 2082, 2079, 2786]
	| approx positives in sample 512: 176
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 21, 27, 14, 26, 19, 19, 22]
	Time taken saving stuff: 0.03s
episode: 218/2000 -> reward: -249.99999999998496, steps:61056, time-taken: 2.46min, time-elasped: 684.76min
-> berries picked: 46 of 800 | patches-visited: [3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 19983 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2826, 3124, 2656, 2168, 2227, 2094, 2097, 2791]
	| approx positives in sample 512: 169
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 22, 34, 15, 22, 15, 16, 24]
	Time taken saving stuff: 0.01s
episode: 219/2000 -> reward: -249.99999999997036, steps:70944, time-taken: 3.29min, time-elasped: 688.06min
-> berries picked: 82 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20118 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2885, 3128, 2689, 2155, 2222, 2100, 2118, 2821]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 37, 39, 8, 31, 16, 21, 29]
	Time taken saving stuff: 0.02s
episode: 220/2000 -> reward: -249.99999999998312, steps:67680, time-taken: 3.37min, time-elasped: 691.43min
-> berries picked: 77 of 800 | patches-visited: [5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20322 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2910, 3143, 2722, 2171, 2241, 2135, 2138, 2862]
	| approx positives in sample 512: 247
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 29, 40, 31, 25, 28, 24, 40]
	Time taken saving stuff: 18.83s

==================================================
eval-episode: 220 -> reward: -0.4999999999999453, steps: 59232.0, wall-time: 37.74s
-> berries picked: 42 of 800 | patches-visited: [1, 7] | juice left:-0.00
==================================================

episode: 221/2000 -> reward: -249.99999999998386, steps:65952, time-taken: 2.52min, time-elasped: 694.90min
-> berries picked: 67 of 800 | patches-visited: [3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20419 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2928, 3152, 2744, 2180, 2260, 2132, 2146, 2877]
	| approx positives in sample 512: 180
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 25, 24, 17, 21, 16, 17, 30]
	Time taken saving stuff: 0.09s
episode: 222/2000 -> reward: -249.99999999997192, steps:75360, time-taken: 3.35min, time-elasped: 698.25min
-> berries picked: 89 of 800 | patches-visited: [0, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20178 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2894, 3121, 2695, 2174, 2230, 2130, 2079, 2855]
	| approx positives in sample 512: 184
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 40, 23, 15, 25, 13, 24, 18]
	Time taken saving stuff: 0.10s
episode: 223/2000 -> reward: -249.99999999998144, steps:72000, time-taken: 3.51min, time-elasped: 701.78min
-> berries picked: 91 of 800 | patches-visited: [3, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20366 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2923, 3132, 2719, 2192, 2244, 2146, 2124, 2886]
	| approx positives in sample 512: 185
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 32, 32, 23, 24, 12, 20, 22]
	Time taken saving stuff: 0.08s
episode: 224/2000 -> reward: -249.9999999999829, steps:66336, time-taken: 3.36min, time-elasped: 705.14min
-> berries picked: 64 of 800 | patches-visited: [1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20441 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2917, 3132, 2739, 2208, 2261, 2150, 2147, 2887]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [37, 37, 41, 26, 19, 18, 25, 28]
	Time taken saving stuff: 0.08s
episode: 225/2000 -> reward: -249.99999999997206, steps:66336, time-taken: 3.34min, time-elasped: 708.49min
-> berries picked: 72 of 800 | patches-visited: [3, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20534 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2914, 3136, 2753, 2213, 2288, 2157, 2175, 2898]
	| approx positives in sample 512: 244
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [43, 39, 23, 35, 32, 25, 21, 26]
	Time taken saving stuff: 0.24s
episode: 226/2000 -> reward: -249.99999999998167, steps:65952, time-taken: 2.61min, time-elasped: 711.11min
-> berries picked: 76 of 800 | patches-visited: [7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20606 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2937, 3139, 2762, 2218, 2284, 2174, 2178, 2914]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 17, 19, 15, 26, 14, 13, 16]
	Time taken saving stuff: 0.03s
episode: 227/2000 -> reward: -249.99999999998397, steps:66336, time-taken: 3.32min, time-elasped: 714.43min
-> berries picked: 77 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20167 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2898, 3095, 2721, 2135, 2219, 2128, 2140, 2831]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [37, 34, 25, 25, 25, 21, 30, 28]
	Time taken saving stuff: 0.07s
episode: 228/2000 -> reward: -249.99999999998082, steps:64896, time-taken: 2.50min, time-elasped: 716.94min
-> berries picked: 69 of 800 | patches-visited: [6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20325 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2929, 3109, 2755, 2162, 2244, 2134, 2153, 2839]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 14, 18, 22, 15, 19, 9, 21]
	Time taken saving stuff: 0.10s
episode: 229/2000 -> reward: -249.9999999999841, steps:54432, time-taken: 2.32min, time-elasped: 719.27min
-> berries picked: 23 of 800 | patches-visited: [9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20136 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2901, 3084, 2734, 2133, 2221, 2134, 2122, 2807]
	| approx positives in sample 512: 177
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 30, 23, 25, 20, 13, 15, 19]
	Time taken saving stuff: 0.03s
episode: 230/2000 -> reward: -249.9999999999834, steps:61920, time-taken: 2.52min, time-elasped: 721.79min
-> berries picked: 46 of 800 | patches-visited: [5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20267 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2919, 3105, 2748, 2139, 2233, 2161, 2139, 2823]
	| approx positives in sample 512: 151
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 29, 10, 16, 18, 15, 15, 23]
	Time taken saving stuff: 18.04s

==================================================
eval-episode: 230 -> reward: -0.49999999999994604, steps: 73632.0, wall-time: 48.22s
-> berries picked: 96 of 800 | patches-visited: [1, 2] | juice left:-0.00
==================================================

episode: 231/2000 -> reward: -249.99999999998178, steps:68448, time-taken: 3.29min, time-elasped: 726.19min
-> berries picked: 82 of 800 | patches-visited: [0, 1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20454 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2957, 3121, 2777, 2144, 2243, 2194, 2162, 2856]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 40, 25, 25, 26, 20, 26, 31]
	Time taken saving stuff: 0.01s
episode: 232/2000 -> reward: -249.9999999999822, steps:66432, time-taken: 3.26min, time-elasped: 729.45min
-> berries picked: 75 of 800 | patches-visited: [9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20604 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2972, 3132, 2822, 2155, 2263, 2225, 2171, 2864]
	| approx positives in sample 512: 250
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [42, 41, 32, 26, 23, 24, 33, 29]
	Time taken saving stuff: 0.08s
episode: 233/2000 -> reward: -249.999999999977, steps:66816, time-taken: 3.25min, time-elasped: 732.71min
-> berries picked: 77 of 800 | patches-visited: [1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20721 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2987, 3144, 2826, 2154, 2271, 2253, 2192, 2894]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 32, 29, 28, 20, 22, 19, 37]
	Time taken saving stuff: 0.01s
episode: 234/2000 -> reward: -249.99999999998465, steps:66624, time-taken: 3.22min, time-elasped: 735.93min
-> berries picked: 69 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20819 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3010, 3148, 2846, 2175, 2289, 2265, 2194, 2892]
	| approx positives in sample 512: 226
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [37, 41, 34, 23, 28, 16, 24, 23]
	Time taken saving stuff: 0.02s
episode: 235/2000 -> reward: -249.9999999999806, steps:66720, time-taken: 3.38min, time-elasped: 739.31min
-> berries picked: 64 of 800 | patches-visited: [3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20945 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3033, 3164, 2860, 2185, 2309, 2284, 2213, 2897]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 34, 36, 29, 24, 22, 19, 29]
	Time taken saving stuff: 0.01s
episode: 236/2000 -> reward: -249.99999999998354, steps:57024, time-taken: 2.58min, time-elasped: 741.89min
-> berries picked: 32 of 800 | patches-visited: [8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20973 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3029, 3167, 2856, 2187, 2335, 2285, 2222, 2892]
	| approx positives in sample 512: 171
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 30, 29, 24, 20, 20, 15, 15]
	Time taken saving stuff: 0.09s
episode: 237/2000 -> reward: -249.9999999999855, steps:64800, time-taken: 2.48min, time-elasped: 744.38min
-> berries picked: 66 of 800 | patches-visited: [5, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20958 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3032, 3136, 2835, 2168, 2347, 2281, 2234, 2925]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 20, 23, 17, 7, 16, 10, 14]
	Time taken saving stuff: 0.01s
episode: 238/2000 -> reward: -249.99999999997928, steps:66048, time-taken: 3.34min, time-elasped: 747.73min
-> berries picked: 79 of 800 | patches-visited: [1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20649 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3003, 3060, 2810, 2134, 2319, 2255, 2209, 2859]
	| approx positives in sample 512: 252
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 41, 34, 33, 22, 30, 29, 31]
	Time taken saving stuff: 0.07s
episode: 239/2000 -> reward: -249.99999999998516, steps:61824, time-taken: 2.41min, time-elasped: 750.15min
-> berries picked: 47 of 800 | patches-visited: [8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20770 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3027, 3088, 2828, 2139, 2325, 2260, 2235, 2868]
	| approx positives in sample 512: 160
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 30, 20, 20, 19, 12, 14, 18]
	Time taken saving stuff: 0.01s
episode: 240/2000 -> reward: -249.99999999998187, steps:66240, time-taken: 3.21min, time-elasped: 753.37min
-> berries picked: 78 of 800 | patches-visited: [2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20830 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3052, 3095, 2817, 2146, 2331, 2267, 2243, 2879]
	| approx positives in sample 512: 235
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [36, 29, 36, 25, 26, 24, 32, 27]
	Time taken saving stuff: 16.89s

==================================================
eval-episode: 240 -> reward: -0.49999999999994776, steps: 81120.0, wall-time: 58.69s
-> berries picked: 131 of 800 | patches-visited: [1, 5] | juice left:-0.00
==================================================

episode: 241/2000 -> reward: -251.49479166665074, steps:64704, time-taken: 2.47min, time-elasped: 757.11min
-> berries picked: 63 of 800 | patches-visited: [1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20960 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3057, 3109, 2833, 2156, 2347, 2275, 2256, 2927]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 29, 16, 8, 15, 17, 17, 18]
	Time taken saving stuff: 0.01s
episode: 242/2000 -> reward: -249.99999999998664, steps:62112, time-taken: 2.41min, time-elasped: 759.52min
-> berries picked: 44 of 800 | patches-visited: [0, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20556 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2985, 3041, 2748, 2145, 2300, 2257, 2232, 2848]
	| approx positives in sample 512: 162
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 17, 24, 18, 19, 14, 19, 22]
	Time taken saving stuff: 0.02s
episode: 243/2000 -> reward: -249.99999999998408, steps:60384, time-taken: 2.45min, time-elasped: 761.97min
-> berries picked: 44 of 800 | patches-visited: [4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20655 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3014, 3057, 2771, 2154, 2306, 2263, 2234, 2856]
	| approx positives in sample 512: 169
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 31, 25, 24, 21, 14, 16, 22]
	Time taken saving stuff: 0.09s
episode: 244/2000 -> reward: -249.9999999999842, steps:66336, time-taken: 3.39min, time-elasped: 765.37min
-> berries picked: 77 of 800 | patches-visited: [8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20775 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3041, 3069, 2807, 2166, 2309, 2283, 2243, 2857]
	| approx positives in sample 512: 243
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [38, 41, 19, 31, 31, 31, 30, 22]
	Time taken saving stuff: 0.09s
episode: 245/2000 -> reward: -249.99999999998417, steps:55680, time-taken: 2.22min, time-elasped: 767.59min
-> berries picked: 27 of 800 | patches-visited: [1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20823 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3039, 3069, 2819, 2172, 2316, 2283, 2249, 2876]
	| approx positives in sample 512: 159
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 25, 23, 15, 18, 15, 21, 19]
	Time taken saving stuff: 0.09s
episode: 246/2000 -> reward: -249.9999999999852, steps:66528, time-taken: 3.30min, time-elasped: 770.89min
-> berries picked: 80 of 800 | patches-visited: [4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20946 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3051, 3075, 2834, 2207, 2330, 2287, 2265, 2897]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [37, 41, 32, 26, 19, 28, 18, 30]
	Time taken saving stuff: 0.12s
episode: 247/2000 -> reward: -249.9999999999868, steps:64224, time-taken: 2.58min, time-elasped: 773.48min
-> berries picked: 62 of 800 | patches-visited: [9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21053 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3068, 3086, 2848, 2215, 2331, 2294, 2280, 2931]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 18, 18, 21, 15, 15, 11, 23]
	Time taken saving stuff: 0.10s
episode: 248/2000 -> reward: -249.99999999998474, steps:65856, time-taken: 2.62min, time-elasped: 776.11min
-> berries picked: 77 of 800 | patches-visited: [7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20833 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3002, 3064, 2832, 2180, 2324, 2270, 2266, 2895]
	| approx positives in sample 512: 139
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 28, 26, 10, 11, 14, 11, 19]
	Time taken saving stuff: 0.09s
episode: 249/2000 -> reward: -249.9999999999833, steps:65856, time-taken: 2.55min, time-elasped: 778.66min
-> berries picked: 72 of 800 | patches-visited: [1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20573 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3006, 3032, 2794, 2121, 2284, 2240, 2245, 2851]
	| approx positives in sample 512: 159
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 21, 28, 18, 17, 13, 20, 14]
	Time taken saving stuff: 0.09s
episode: 250/2000 -> reward: -249.99999999998406, steps:66144, time-taken: 3.26min, time-elasped: 781.93min
-> berries picked: 75 of 800 | patches-visited: [2, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20486 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2970, 3009, 2805, 2101, 2265, 2230, 2237, 2869]
	| approx positives in sample 512: 228
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 34, 37, 17, 24, 23, 25, 37]
	Time taken saving stuff: 17.89s

==================================================
eval-episode: 250 -> reward: -0.49999999999994615, steps: 73632.0, wall-time: 49.71s
-> berries picked: 105 of 800 | patches-visited: [1, 2] | juice left:-0.00
==================================================

episode: 251/2000 -> reward: -249.9999999999812, steps:66816, time-taken: 3.18min, time-elasped: 786.24min
-> berries picked: 69 of 800 | patches-visited: [2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20658 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3014, 3034, 2827, 2114, 2277, 2238, 2243, 2911]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 35, 27, 24, 23, 23, 28, 38]
	Time taken saving stuff: 0.06s
episode: 252/2000 -> reward: -249.9999999999845, steps:63744, time-taken: 2.63min, time-elasped: 788.88min
-> berries picked: 61 of 800 | patches-visited: [2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20817 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3035, 3043, 2868, 2157, 2283, 2253, 2252, 2926]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 21, 17, 16, 15, 18, 19, 22]
	Time taken saving stuff: 0.01s
episode: 253/2000 -> reward: -249.99999999998462, steps:65280, time-taken: 2.50min, time-elasped: 791.39min
-> berries picked: 76 of 800 | patches-visited: [6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20768 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3043, 3029, 2852, 2159, 2266, 2239, 2242, 2938]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 22, 14, 18, 23, 6, 10, 20]
	Time taken saving stuff: 0.10s
episode: 254/2000 -> reward: -249.99999999997326, steps:66048, time-taken: 3.28min, time-elasped: 794.67min
-> berries picked: 63 of 800 | patches-visited: [3, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20597 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3022, 2990, 2807, 2111, 2231, 2266, 2248, 2922]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 24, 27, 28, 25, 28, 21, 35]
	Time taken saving stuff: 0.01s
episode: 255/2000 -> reward: -249.99999999998496, steps:67008, time-taken: 3.27min, time-elasped: 797.94min
-> berries picked: 76 of 800 | patches-visited: [6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20739 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3042, 3011, 2839, 2110, 2246, 2276, 2264, 2951]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 33, 29, 21, 21, 17, 31, 36]
	Time taken saving stuff: 0.09s
episode: 256/2000 -> reward: -249.99999999998184, steps:67680, time-taken: 3.26min, time-elasped: 801.21min
-> berries picked: 80 of 800 | patches-visited: [5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20902 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3063, 3025, 2863, 2128, 2259, 2274, 2298, 2992]
	| approx positives in sample 512: 235
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 44, 31, 28, 24, 23, 23, 29]
	Time taken saving stuff: 0.01s
episode: 257/2000 -> reward: -249.99999999998408, steps:59040, time-taken: 2.35min, time-elasped: 803.56min
-> berries picked: 37 of 800 | patches-visited: [1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20980 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3095, 3024, 2870, 2132, 2271, 2283, 2309, 2996]
	| approx positives in sample 512: 164
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 25, 12, 19, 22, 12, 25, 22]
	Time taken saving stuff: 0.10s
episode: 258/2000 -> reward: -249.99999999998118, steps:72768, time-taken: 3.36min, time-elasped: 806.93min
-> berries picked: 91 of 800 | patches-visited: [4, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20967 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3079, 3028, 2853, 2152, 2266, 2298, 2302, 2989]
	| approx positives in sample 512: 205
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 36, 21, 24, 20, 17, 23, 32]
	Time taken saving stuff: 0.01s
episode: 259/2000 -> reward: -249.999999999975, steps:73152, time-taken: 3.31min, time-elasped: 810.25min
-> berries picked: 93 of 800 | patches-visited: [1, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21214 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3098, 3042, 2889, 2188, 2294, 2324, 2345, 3034]
	| approx positives in sample 512: 183
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 28, 29, 19, 13, 22, 15, 28]
	Time taken saving stuff: 0.10s
episode: 260/2000 -> reward: -249.9999999999754, steps:68544, time-taken: 3.32min, time-elasped: 813.58min
-> berries picked: 78 of 800 | patches-visited: [1, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21364 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3120, 3057, 2928, 2197, 2327, 2333, 2349, 3053]
	| approx positives in sample 512: 208
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 32, 23, 27, 23, 19, 17, 38]
	Time taken saving stuff: 18.22s

==================================================
eval-episode: 260 -> reward: -0.4999999999999464, steps: 76224.0, wall-time: 51.18s
-> berries picked: 106 of 800 | patches-visited: [0, 1] | juice left:-0.00
==================================================

episode: 261/2000 -> reward: -249.99999999997257, steps:71712, time-taken: 3.24min, time-elasped: 817.98min
-> berries picked: 88 of 800 | patches-visited: [7, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21444 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3136, 3066, 2934, 2230, 2325, 2338, 2341, 3074]
	| approx positives in sample 512: 211
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 34, 28, 17, 22, 20, 27, 28]
	Time taken saving stuff: 0.01s
episode: 262/2000 -> reward: -249.99999999998366, steps:57024, time-taken: 2.29min, time-elasped: 820.27min
-> berries picked: 36 of 800 | patches-visited: [3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21435 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3141, 3061, 2936, 2223, 2330, 2330, 2351, 3063]
	| approx positives in sample 512: 173
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 34, 31, 13, 13, 18, 20, 25]
	Time taken saving stuff: 0.03s
episode: 263/2000 -> reward: -249.99999999998252, steps:65856, time-taken: 2.67min, time-elasped: 822.95min
-> berries picked: 76 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21348 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3135, 3035, 2907, 2204, 2320, 2342, 2364, 3041]
	| approx positives in sample 512: 137
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 21, 25, 9, 13, 20, 14, 16]
	Time taken saving stuff: 0.09s
episode: 264/2000 -> reward: -249.99999999998462, steps:63840, time-taken: 2.54min, time-elasped: 825.50min
-> berries picked: 66 of 800 | patches-visited: [6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20909 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3092, 2978, 2827, 2164, 2280, 2287, 2293, 2988]
	| approx positives in sample 512: 150
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 17, 31, 21, 15, 21, 13, 11]
	Time taken saving stuff: 0.01s
episode: 265/2000 -> reward: -249.9999999999841, steps:56064, time-taken: 2.29min, time-elasped: 827.79min
-> berries picked: 30 of 800 | patches-visited: [4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20891 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3075, 2975, 2831, 2159, 2290, 2281, 2306, 2974]
	| approx positives in sample 512: 186
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 30, 25, 16, 16, 21, 21, 24]
	Time taken saving stuff: 0.01s
episode: 266/2000 -> reward: -249.99999999998056, steps:70848, time-taken: 3.25min, time-elasped: 831.04min
-> berries picked: 84 of 800 | patches-visited: [1, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21119 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3106, 2995, 2874, 2191, 2323, 2301, 2342, 2987]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 37, 23, 23, 16, 19, 25, 38]
	Time taken saving stuff: 0.01s
episode: 267/2000 -> reward: -249.99999999998727, steps:65664, time-taken: 2.55min, time-elasped: 833.59min
-> berries picked: 68 of 800 | patches-visited: [3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21287 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3139, 3014, 2893, 2218, 2333, 2311, 2358, 3021]
	| approx positives in sample 512: 139
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 16, 17, 16, 19, 26, 10, 18]
	Time taken saving stuff: 0.01s
episode: 268/2000 -> reward: -249.9999999999843, steps:57984, time-taken: 2.38min, time-elasped: 835.97min
-> berries picked: 37 of 800 | patches-visited: [2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21028 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3101, 3001, 2870, 2177, 2308, 2272, 2319, 2980]
	| approx positives in sample 512: 177
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 22, 28, 21, 21, 23, 20, 17]
	Time taken saving stuff: 0.01s
episode: 269/2000 -> reward: -249.99999999998067, steps:65664, time-taken: 2.58min, time-elasped: 838.56min
-> berries picked: 79 of 800 | patches-visited: [5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21197 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3138, 3026, 2874, 2197, 2307, 2311, 2331, 3013]
	| approx positives in sample 512: 153
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 18, 24, 19, 16, 19, 18, 21]
	Time taken saving stuff: 0.01s
episode: 270/2000 -> reward: -249.99999999998187, steps:68736, time-taken: 3.30min, time-elasped: 841.86min
-> berries picked: 79 of 800 | patches-visited: [4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20877 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3081, 2980, 2821, 2181, 2273, 2308, 2282, 2951]
	| approx positives in sample 512: 203
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 35, 36, 23, 25, 20, 22, 20]
	Time taken saving stuff: 17.75s

==================================================
eval-episode: 270 -> reward: -0.4999999999999262, steps: 95136.0, wall-time: 66.13s
-> berries picked: 176 of 800 | patches-visited: [1, 2, 3] | juice left:-0.00
==================================================

episode: 271/2000 -> reward: -249.999999999982, steps:66144, time-taken: 3.38min, time-elasped: 846.64min
-> berries picked: 70 of 800 | patches-visited: [2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21039 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3092, 2986, 2833, 2183, 2288, 2324, 2327, 3006]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 34, 26, 23, 27, 26, 20, 33]
	Time taken saving stuff: 0.01s
episode: 272/2000 -> reward: -249.99999999998556, steps:64704, time-taken: 2.67min, time-elasped: 849.31min
-> berries picked: 65 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21125 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3113, 3009, 2841, 2202, 2294, 2328, 2324, 3014]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 19, 17, 10, 10, 20, 30, 16]
	Time taken saving stuff: 0.01s
episode: 273/2000 -> reward: -249.99999999998414, steps:65184, time-taken: 2.47min, time-elasped: 851.79min
-> berries picked: 76 of 800 | patches-visited: [4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20975 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3106, 2980, 2818, 2170, 2309, 2315, 2304, 2973]
	| approx positives in sample 512: 154
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 23, 22, 15, 15, 17, 20, 20]
	Time taken saving stuff: 0.01s
episode: 274/2000 -> reward: -249.9999999999806, steps:65760, time-taken: 2.54min, time-elasped: 854.34min
-> berries picked: 78 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20878 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3079, 2959, 2800, 2151, 2275, 2305, 2298, 3011]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 24, 18, 15, 12, 23, 18, 16]
	Time taken saving stuff: 0.01s
episode: 275/2000 -> reward: -249.99999999998187, steps:65568, time-taken: 2.47min, time-elasped: 856.81min
-> berries picked: 67 of 800 | patches-visited: [5, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20445 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3004, 2907, 2767, 2174, 2235, 2227, 2230, 2901]
	| approx positives in sample 512: 127
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 18, 21, 12, 16, 11, 11, 15]
	Time taken saving stuff: 0.01s
episode: 276/2000 -> reward: -249.99999999998317, steps:68832, time-taken: 3.37min, time-elasped: 860.18min
-> berries picked: 81 of 800 | patches-visited: [2, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20330 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2987, 2903, 2738, 2138, 2238, 2200, 2235, 2891]
	| approx positives in sample 512: 220
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 25, 31, 20, 34, 23, 27, 30]
	Time taken saving stuff: 0.01s
episode: 277/2000 -> reward: -249.99999999998283, steps:65472, time-taken: 2.89min, time-elasped: 863.08min
-> berries picked: 76 of 800 | patches-visited: [7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20512 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3010, 2907, 2749, 2158, 2259, 2227, 2298, 2904]
	| approx positives in sample 512: 131
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 20, 13, 9, 17, 13, 19, 13]
	Time taken saving stuff: 0.01s
episode: 278/2000 -> reward: -249.99999999998485, steps:57408, time-taken: 2.33min, time-elasped: 865.41min
-> berries picked: 33 of 800 | patches-visited: [8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20482 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2989, 2914, 2747, 2141, 2266, 2223, 2289, 2913]
	| approx positives in sample 512: 167
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 21, 24, 21, 22, 23, 14, 19]
	Time taken saving stuff: 0.01s
episode: 279/2000 -> reward: -249.99999999998465, steps:66336, time-taken: 3.29min, time-elasped: 868.71min
-> berries picked: 68 of 800 | patches-visited: [5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20660 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3005, 2922, 2763, 2149, 2278, 2272, 2326, 2945]
	| approx positives in sample 512: 246
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 37, 32, 26, 28, 32, 31, 32]
	Time taken saving stuff: 0.01s
episode: 280/2000 -> reward: -249.99999999998263, steps:68160, time-taken: 3.31min, time-elasped: 872.02min
-> berries picked: 80 of 800 | patches-visited: [6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20853 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3025, 2938, 2786, 2168, 2297, 2304, 2361, 2974]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 31, 35, 23, 15, 21, 31, 36]
	Time taken saving stuff: 18.45s

==================================================
eval-episode: 280 -> reward: -0.4999999999999064, steps: 83808.0, wall-time: 56.09s
-> berries picked: 142 of 800 | patches-visited: [1, 8] | juice left:-0.00
==================================================

episode: 281/2000 -> reward: -249.99999999998343, steps:63168, time-taken: 2.27min, time-elasped: 875.55min
-> berries picked: 54 of 800 | patches-visited: [1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20959 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3048, 2951, 2789, 2176, 2320, 2312, 2366, 2997]
	| approx positives in sample 512: 152
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 20, 17, 19, 15, 20, 21, 15]
	Time taken saving stuff: 0.01s
episode: 282/2000 -> reward: -249.99999999998306, steps:67104, time-taken: 3.30min, time-elasped: 878.86min
-> berries picked: 74 of 800 | patches-visited: [4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20978 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3040, 2963, 2765, 2167, 2323, 2317, 2364, 3039]
	| approx positives in sample 512: 235
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [37, 35, 34, 17, 22, 28, 26, 36]
	Time taken saving stuff: 0.01s
episode: 283/2000 -> reward: -249.99999999998508, steps:62112, time-taken: 2.56min, time-elasped: 881.43min
-> berries picked: 58 of 800 | patches-visited: [2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21113 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3071, 2984, 2770, 2191, 2331, 2331, 2382, 3053]
	| approx positives in sample 512: 158
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 23, 18, 10, 19, 21, 22, 21]
	Time taken saving stuff: 0.01s
episode: 284/2000 -> reward: -249.9999999999815, steps:68256, time-taken: 3.38min, time-elasped: 884.82min
-> berries picked: 80 of 800 | patches-visited: [2, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21110 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3052, 2986, 2768, 2192, 2323, 2351, 2393, 3045]
	| approx positives in sample 512: 205
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 24, 34, 25, 31, 22, 23, 28]
	Time taken saving stuff: 0.01s
episode: 285/2000 -> reward: -249.99999999998315, steps:67200, time-taken: 3.25min, time-elasped: 888.07min
-> berries picked: 77 of 800 | patches-visited: [5, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21309 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3080, 3002, 2798, 2234, 2337, 2373, 2410, 3075]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [39, 31, 35, 31, 21, 20, 25, 20]
	Time taken saving stuff: 0.01s
episode: 286/2000 -> reward: -249.9999999999851, steps:67104, time-taken: 3.26min, time-elasped: 891.34min
-> berries picked: 66 of 800 | patches-visited: [4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21419 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3099, 3010, 2805, 2232, 2359, 2414, 2422, 3078]
	| approx positives in sample 512: 242
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [41, 44, 31, 22, 23, 22, 26, 33]
	Time taken saving stuff: 0.01s
episode: 287/2000 -> reward: -249.99999999997, steps:70656, time-taken: 3.33min, time-elasped: 894.67min
-> berries picked: 86 of 800 | patches-visited: [2, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21608 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3148, 3028, 2809, 2252, 2389, 2425, 2449, 3108]
	| approx positives in sample 512: 197
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 30, 19, 21, 29, 20, 28, 21]
	Time taken saving stuff: 0.01s
episode: 288/2000 -> reward: -249.99999999998383, steps:68544, time-taken: 3.28min, time-elasped: 897.95min
-> berries picked: 78 of 800 | patches-visited: [5, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21682 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3149, 3006, 2817, 2256, 2392, 2453, 2481, 3128]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 27, 35, 19, 22, 25, 26, 39]
	Time taken saving stuff: 0.03s
episode: 289/2000 -> reward: -249.9999999999862, steps:65952, time-taken: 2.69min, time-elasped: 900.65min
-> berries picked: 72 of 800 | patches-visited: [1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21715 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3155, 2997, 2832, 2254, 2402, 2458, 2489, 3128]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 17, 19, 14, 17, 15, 18, 15]
	Time taken saving stuff: 0.01s
episode: 290/2000 -> reward: -249.9999999999842, steps:64512, time-taken: 2.53min, time-elasped: 903.19min
-> berries picked: 77 of 800 | patches-visited: [7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21424 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3133, 2946, 2783, 2233, 2342, 2423, 2462, 3102]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 23, 17, 13, 13, 15, 8, 15]
	Time taken saving stuff: 14.05s

==================================================
eval-episode: 290 -> reward: -0.49999999999993067, steps: 72864.0, wall-time: 50.91s
-> berries picked: 94 of 800 | patches-visited: [1, 7] | juice left:-0.00
==================================================

episode: 291/2000 -> reward: -249.9999999999815, steps:66144, time-taken: 3.19min, time-elasped: 907.47min
-> berries picked: 78 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21417 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3120, 2929, 2790, 2217, 2345, 2424, 2475, 3117]
	| approx positives in sample 512: 250
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [41, 32, 25, 24, 30, 33, 29, 36]
	Time taken saving stuff: 0.07s
episode: 292/2000 -> reward: -249.99999999998366, steps:63072, time-taken: 2.42min, time-elasped: 909.89min
-> berries picked: 55 of 800 | patches-visited: [2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21543 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3147, 2945, 2798, 2232, 2361, 2430, 2490, 3140]
	| approx positives in sample 512: 146
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 18, 19, 21, 11, 13, 18, 25]
	Time taken saving stuff: 0.01s
episode: 293/2000 -> reward: -249.99999999998394, steps:67776, time-taken: 3.26min, time-elasped: 913.16min
-> berries picked: 78 of 800 | patches-visited: [7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21481 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3132, 2921, 2799, 2225, 2366, 2435, 2480, 3123]
	| approx positives in sample 512: 236
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [36, 24, 32, 26, 32, 25, 34, 27]
	Time taken saving stuff: 0.04s
episode: 294/2000 -> reward: -249.99999999997857, steps:70944, time-taken: 3.47min, time-elasped: 916.63min
-> berries picked: 90 of 800 | patches-visited: [7, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21703 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3197, 2941, 2816, 2244, 2382, 2460, 2502, 3161]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [45, 36, 22, 22, 23, 22, 28, 29]
	Time taken saving stuff: 0.01s
episode: 295/2000 -> reward: -249.99999999997019, steps:81024, time-taken: 3.58min, time-elasped: 920.22min
-> berries picked: 119 of 800 | patches-visited: [1, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21981 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3234, 2964, 2830, 2289, 2415, 2510, 2544, 3195]
	| approx positives in sample 512: 171
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 23, 28, 19, 16, 14, 24, 19]
	Time taken saving stuff: 0.01s
episode: 296/2000 -> reward: -249.99999999998442, steps:66048, time-taken: 3.31min, time-elasped: 923.54min
-> berries picked: 77 of 800 | patches-visited: [2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21803 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3217, 2935, 2808, 2284, 2395, 2475, 2523, 3166]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [43, 23, 30, 27, 25, 23, 18, 32]
	Time taken saving stuff: 0.01s
episode: 297/2000 -> reward: -249.99999999998306, steps:66432, time-taken: 3.39min, time-elasped: 926.93min
-> berries picked: 74 of 800 | patches-visited: [4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21943 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3262, 2943, 2827, 2305, 2401, 2481, 2536, 3188]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 27, 37, 27, 29, 19, 27, 27]
	Time taken saving stuff: 0.07s
episode: 298/2000 -> reward: -249.99999999998226, steps:69408, time-taken: 3.36min, time-elasped: 930.29min
-> berries picked: 75 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22005 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3266, 2945, 2822, 2311, 2401, 2479, 2551, 3230]
	| approx positives in sample 512: 203
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [38, 33, 24, 17, 32, 19, 10, 30]
	Time taken saving stuff: 0.01s
episode: 299/2000 -> reward: -249.9999999999807, steps:67296, time-taken: 3.42min, time-elasped: 933.72min
-> berries picked: 82 of 800 | patches-visited: [2, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22024 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3252, 2948, 2804, 2334, 2425, 2477, 2563, 3221]
	| approx positives in sample 512: 210
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [39, 23, 25, 21, 24, 25, 28, 25]
	Time taken saving stuff: 0.10s
episode: 300/2000 -> reward: -249.99999999998377, steps:68064, time-taken: 3.36min, time-elasped: 937.09min
-> berries picked: 74 of 800 | patches-visited: [6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22065 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3255, 2940, 2805, 2342, 2428, 2506, 2571, 3218]
	| approx positives in sample 512: 246
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 27, 33, 27, 30, 31, 29, 38]
	Time taken saving stuff: 18.59s

==================================================
eval-episode: 300 -> reward: -0.4999999999999079, steps: 99360.0, wall-time: 73.98s
-> berries picked: 201 of 800 | patches-visited: [0, 1, 2, 8] | juice left:-0.00
==================================================

episode: 301/2000 -> reward: -249.9999999999733, steps:73440, time-taken: 3.18min, time-elasped: 941.82min
-> berries picked: 93 of 800 | patches-visited: [1, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22207 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3294, 2949, 2807, 2342, 2451, 2521, 2603, 3240]
	| approx positives in sample 512: 208
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 28, 29, 20, 23, 25, 28, 26]
	Time taken saving stuff: 0.02s
episode: 302/2000 -> reward: -249.99999999998371, steps:63072, time-taken: 2.45min, time-elasped: 944.28min
-> berries picked: 53 of 800 | patches-visited: [4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22188 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3270, 2939, 2809, 2349, 2463, 2520, 2602, 3236]
	| approx positives in sample 512: 136
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 19, 18, 16, 21, 10, 13, 21]
	Time taken saving stuff: 0.03s
episode: 303/2000 -> reward: -249.99999999998494, steps:67296, time-taken: 3.06min, time-elasped: 947.34min
-> berries picked: 80 of 800 | patches-visited: [1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21685 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3213, 2868, 2770, 2284, 2409, 2444, 2554, 3143]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 26, 44, 19, 22, 20, 20, 32]
	Time taken saving stuff: 0.24s
episode: 304/2000 -> reward: -249.99999999998465, steps:63744, time-taken: 2.58min, time-elasped: 949.93min
-> berries picked: 63 of 800 | patches-visited: [3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21773 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3214, 2871, 2770, 2298, 2424, 2472, 2569, 3155]
	| approx positives in sample 512: 166
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 24, 27, 19, 10, 18, 17, 25]
	Time taken saving stuff: 0.03s
episode: 305/2000 -> reward: -249.9999999999866, steps:68256, time-taken: 3.36min, time-elasped: 953.29min
-> berries picked: 76 of 800 | patches-visited: [8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20905 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3047, 2758, 2640, 2207, 2340, 2376, 2517, 3020]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [40, 27, 39, 32, 23, 22, 31, 17]
	Time taken saving stuff: 0.09s
episode: 306/2000 -> reward: -249.99999999997306, steps:78912, time-taken: 3.56min, time-elasped: 956.85min
-> berries picked: 113 of 800 | patches-visited: [4, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21204 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3078, 2784, 2665, 2279, 2374, 2425, 2537, 3062]
	| approx positives in sample 512: 195
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [37, 20, 24, 21, 19, 18, 27, 29]
	Time taken saving stuff: 0.09s
episode: 307/2000 -> reward: -249.9999999999819, steps:67776, time-taken: 3.42min, time-elasped: 960.27min
-> berries picked: 72 of 800 | patches-visited: [1, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21335 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3086, 2790, 2694, 2285, 2395, 2447, 2554, 3084]
	| approx positives in sample 512: 215
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 33, 27, 16, 24, 20, 33, 27]
	Time taken saving stuff: 0.09s
episode: 308/2000 -> reward: -249.99999999997817, steps:71136, time-taken: 3.34min, time-elasped: 963.62min
-> berries picked: 91 of 800 | patches-visited: [6, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21509 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3124, 2830, 2702, 2295, 2422, 2461, 2572, 3103]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 29, 19, 30, 17, 17, 32, 33]
	Time taken saving stuff: 0.03s
episode: 309/2000 -> reward: -249.99999999997937, steps:70560, time-taken: 3.52min, time-elasped: 967.14min
-> berries picked: 91 of 800 | patches-visited: [2, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21635 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3147, 2839, 2714, 2303, 2436, 2468, 2585, 3143]
	| approx positives in sample 512: 205
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 22, 26, 24, 25, 22, 32, 23]
	Time taken saving stuff: 0.01s
episode: 310/2000 -> reward: -249.99999999998403, steps:61728, time-taken: 2.52min, time-elasped: 969.67min
-> berries picked: 51 of 800 | patches-visited: [1, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21629 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3154, 2851, 2713, 2289, 2439, 2464, 2594, 3125]
	| approx positives in sample 512: 158
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 18, 17, 16, 15, 20, 17, 25]
	Time taken saving stuff: 18.56s

==================================================
eval-episode: 310 -> reward: -0.4999999999999457, steps: 65952.0, wall-time: 47.57s
-> berries picked: 71 of 800 | patches-visited: [1, 5] | juice left:-0.00
==================================================

episode: 311/2000 -> reward: -249.9999999999835, steps:66240, time-taken: 3.27min, time-elasped: 974.05min
-> berries picked: 73 of 800 | patches-visited: [9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21275 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3063, 2816, 2683, 2250, 2406, 2421, 2589, 3047]
	| approx positives in sample 512: 250
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 35, 34, 24, 27, 31, 38, 29]
	Time taken saving stuff: 0.01s
episode: 312/2000 -> reward: -249.99999999997635, steps:76128, time-taken: 3.50min, time-elasped: 977.56min
-> berries picked: 107 of 800 | patches-visited: [2, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21556 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3109, 2843, 2707, 2273, 2452, 2468, 2623, 3081]
	| approx positives in sample 512: 203
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [37, 20, 27, 31, 21, 19, 20, 28]
	Time taken saving stuff: 0.09s
episode: 313/2000 -> reward: -249.9999999999858, steps:64512, time-taken: 2.55min, time-elasped: 980.11min
-> berries picked: 66 of 800 | patches-visited: [2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21658 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3107, 2853, 2718, 2290, 2459, 2497, 2648, 3086]
	| approx positives in sample 512: 172
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 24, 26, 19, 17, 18, 18, 23]
	Time taken saving stuff: 0.01s
episode: 314/2000 -> reward: -249.99999999998403, steps:63072, time-taken: 2.49min, time-elasped: 982.60min
-> berries picked: 62 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21486 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3103, 2841, 2702, 2268, 2417, 2481, 2620, 3054]
	| approx positives in sample 512: 151
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 22, 18, 17, 18, 15, 19, 22]
	Time taken saving stuff: 0.10s
episode: 315/2000 -> reward: -249.99999999997996, steps:66432, time-taken: 3.24min, time-elasped: 985.85min
-> berries picked: 72 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21625 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3117, 2856, 2721, 2276, 2436, 2481, 2632, 3106]
	| approx positives in sample 512: 249
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 41, 31, 22, 29, 28, 29, 37]
	Time taken saving stuff: 0.01s
episode: 316/2000 -> reward: -249.999999999981, steps:69312, time-taken: 3.33min, time-elasped: 989.18min
-> berries picked: 83 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21814 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3133, 2877, 2744, 2305, 2449, 2510, 2662, 3134]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 33, 30, 28, 24, 22, 27, 29]
	Time taken saving stuff: 0.02s
episode: 317/2000 -> reward: -249.9999999999739, steps:73248, time-taken: 3.61min, time-elasped: 992.80min
-> berries picked: 89 of 800 | patches-visited: [5, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21991 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3148, 2880, 2751, 2332, 2482, 2541, 2679, 3178]
	| approx positives in sample 512: 197
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 25, 27, 20, 21, 17, 26, 33]
	Time taken saving stuff: 0.01s
episode: 318/2000 -> reward: -249.9999999999839, steps:67008, time-taken: 3.38min, time-elasped: 996.18min
-> berries picked: 76 of 800 | patches-visited: [6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22045 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3146, 2884, 2751, 2366, 2485, 2558, 2681, 3174]
	| approx positives in sample 512: 242
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 29, 37, 32, 28, 23, 28, 39]
	Time taken saving stuff: 0.05s
episode: 319/2000 -> reward: -249.99999999998056, steps:66528, time-taken: 3.36min, time-elasped: 999.55min
-> berries picked: 79 of 800 | patches-visited: [4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22163 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3178, 2884, 2763, 2379, 2477, 2557, 2723, 3202]
	| approx positives in sample 512: 232
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 28, 45, 23, 19, 23, 28, 35]
	Time taken saving stuff: 0.01s
episode: 320/2000 -> reward: -249.99999999998383, steps:65568, time-taken: 2.66min, time-elasped: 1002.20min
-> berries picked: 70 of 800 | patches-visited: [3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22215 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3191, 2880, 2762, 2394, 2492, 2563, 2725, 3208]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 14, 23, 17, 17, 10, 15, 12]
	Time taken saving stuff: 18.33s

==================================================
eval-episode: 320 -> reward: -0.49999999999994227, steps: 77856.0, wall-time: 57.35s
-> berries picked: 108 of 800 | patches-visited: [1, 2] | juice left:-0.00
==================================================

episode: 321/2000 -> reward: -249.9999999999848, steps:67488, time-taken: 3.05min, time-elasped: 1006.52min
-> berries picked: 76 of 800 | patches-visited: [4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21744 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3118, 2840, 2698, 2347, 2447, 2501, 2705, 3088]
	| approx positives in sample 512: 240
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 30, 39, 23, 25, 33, 40, 21]
	Time taken saving stuff: 0.06s
episode: 322/2000 -> reward: -249.99999999997783, steps:73536, time-taken: 3.57min, time-elasped: 1010.10min
-> berries picked: 104 of 800 | patches-visited: [6, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22005 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3145, 2884, 2729, 2374, 2483, 2524, 2749, 3117]
	| approx positives in sample 512: 193
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 16, 30, 20, 20, 23, 31, 28]
	Time taken saving stuff: 0.02s
episode: 323/2000 -> reward: -249.99999999998096, steps:66240, time-taken: 3.21min, time-elasped: 1013.31min
-> berries picked: 72 of 800 | patches-visited: [9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22100 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3170, 2895, 2738, 2398, 2490, 2524, 2754, 3131]
	| approx positives in sample 512: 221
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 36, 28, 22, 20, 22, 27, 33]
	Time taken saving stuff: 0.07s
episode: 324/2000 -> reward: -249.9999999999853, steps:61440, time-taken: 2.45min, time-elasped: 1015.77min
-> berries picked: 47 of 800 | patches-visited: [9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22166 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3168, 2916, 2754, 2415, 2489, 2522, 2773, 3129]
	| approx positives in sample 512: 152
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 21, 12, 20, 22, 16, 15, 26]
	Time taken saving stuff: 0.02s
episode: 325/2000 -> reward: -249.99999999998366, steps:58944, time-taken: 2.54min, time-elasped: 1018.31min
-> berries picked: 44 of 800 | patches-visited: [7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21792 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3116, 2864, 2707, 2388, 2441, 2486, 2720, 3070]
	| approx positives in sample 512: 163
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 25, 25, 19, 15, 17, 19, 18]
	Time taken saving stuff: 0.04s
episode: 326/2000 -> reward: -249.99999999998573, steps:65088, time-taken: 2.39min, time-elasped: 1020.70min
-> berries picked: 69 of 800 | patches-visited: [5, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21936 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3134, 2891, 2727, 2397, 2441, 2506, 2743, 3097]
	| approx positives in sample 512: 139
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 13, 21, 11, 16, 19, 25, 17]
	Time taken saving stuff: 0.09s
episode: 327/2000 -> reward: -249.99999999997263, steps:68736, time-taken: 3.48min, time-elasped: 1024.19min
-> berries picked: 77 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21751 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3094, 2848, 2703, 2382, 2450, 2491, 2721, 3062]
	| approx positives in sample 512: 223
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 31, 23, 34, 22, 31, 24, 30]
	Time taken saving stuff: 0.10s
episode: 328/2000 -> reward: -249.99999999997632, steps:63456, time-taken: 2.53min, time-elasped: 1026.72min
-> berries picked: 58 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21902 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3109, 2871, 2712, 2399, 2463, 2513, 2759, 3076]
	| approx positives in sample 512: 174
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 24, 26, 15, 23, 19, 20, 24]
	Time taken saving stuff: 0.02s
episode: 329/2000 -> reward: -249.99999999998474, steps:59328, time-taken: 2.29min, time-elasped: 1029.02min
-> berries picked: 46 of 800 | patches-visited: [9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21824 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3099, 2851, 2701, 2381, 2451, 2511, 2744, 3086]
	| approx positives in sample 512: 170
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 26, 25, 22, 16, 16, 24, 28]
	Time taken saving stuff: 0.09s
episode: 330/2000 -> reward: -249.99999999998212, steps:66816, time-taken: 3.25min, time-elasped: 1032.28min
-> berries picked: 80 of 800 | patches-visited: [8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21852 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3092, 2858, 2717, 2383, 2456, 2526, 2760, 3060]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 34, 34, 20, 25, 23, 31, 37]
	Time taken saving stuff: 18.52s

==================================================
eval-episode: 330 -> reward: -0.49999999999994504, steps: 64032.0, wall-time: 50.66s
-> berries picked: 56 of 800 | patches-visited: [0, 1] | juice left:-0.00
==================================================

episode: 331/2000 -> reward: -249.99999999998374, steps:65952, time-taken: 2.46min, time-elasped: 1035.90min
-> berries picked: 76 of 800 | patches-visited: [1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22002 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3109, 2881, 2750, 2403, 2464, 2534, 2780, 3081]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 18, 16, 16, 18, 14, 16, 33]
	Time taken saving stuff: 0.02s
episode: 332/2000 -> reward: -249.9999999999841, steps:63168, time-taken: 2.54min, time-elasped: 1038.45min
-> berries picked: 59 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21733 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3064, 2846, 2718, 2377, 2439, 2498, 2744, 3047]
	| approx positives in sample 512: 169
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 27, 27, 19, 18, 15, 23, 15]
	Time taken saving stuff: 0.01s
episode: 333/2000 -> reward: -249.99999999998056, steps:68064, time-taken: 3.40min, time-elasped: 1041.85min
-> berries picked: 83 of 800 | patches-visited: [5, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21797 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3076, 2867, 2730, 2371, 2469, 2497, 2739, 3048]
	| approx positives in sample 512: 223
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 22, 20, 23, 29, 22, 42, 33]
	Time taken saving stuff: 0.08s
episode: 334/2000 -> reward: -249.99999999997956, steps:67392, time-taken: 3.25min, time-elasped: 1045.11min
-> berries picked: 71 of 800 | patches-visited: [3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21936 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3099, 2873, 2746, 2379, 2490, 2524, 2773, 3052]
	| approx positives in sample 512: 190
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 34, 23, 20, 25, 13, 22, 25]
	Time taken saving stuff: 0.01s
episode: 335/2000 -> reward: -249.99999999998278, steps:65952, time-taken: 2.59min, time-elasped: 1047.70min
-> berries picked: 77 of 800 | patches-visited: [2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21980 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3097, 2859, 2742, 2382, 2502, 2537, 2791, 3070]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 22, 17, 16, 13, 15, 16, 22]
	Time taken saving stuff: 0.10s
episode: 336/2000 -> reward: -249.9999999999812, steps:69696, time-taken: 3.29min, time-elasped: 1051.00min
-> berries picked: 78 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21140 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2946, 2744, 2643, 2311, 2425, 2441, 2711, 2919]
	| approx positives in sample 512: 214
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [43, 30, 24, 16, 16, 18, 25, 42]
	Time taken saving stuff: 0.01s
episode: 337/2000 -> reward: -249.99999999998383, steps:66816, time-taken: 3.25min, time-elasped: 1054.26min
-> berries picked: 79 of 800 | patches-visited: [2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21335 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2973, 2766, 2653, 2332, 2456, 2479, 2731, 2945]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 29, 33, 27, 25, 20, 21, 24]
	Time taken saving stuff: 0.24s
episode: 338/2000 -> reward: -249.99999999998124, steps:67296, time-taken: 3.23min, time-elasped: 1057.50min
-> berries picked: 78 of 800 | patches-visited: [8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21520 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2978, 2799, 2682, 2339, 2459, 2506, 2774, 2983]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 29, 28, 31, 22, 26, 29, 31]
	Time taken saving stuff: 0.01s
episode: 339/2000 -> reward: -249.9999999999817, steps:67968, time-taken: 3.36min, time-elasped: 1060.87min
-> berries picked: 79 of 800 | patches-visited: [4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21667 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2997, 2826, 2705, 2360, 2481, 2505, 2787, 3006]
	| approx positives in sample 512: 217
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [17, 29, 38, 23, 26, 14, 29, 41]
	Time taken saving stuff: 0.03s
episode: 340/2000 -> reward: -249.99999999998332, steps:67296, time-taken: 3.19min, time-elasped: 1064.06min
-> berries picked: 79 of 800 | patches-visited: [4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21785 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2991, 2853, 2714, 2374, 2501, 2517, 2819, 3016]
	| approx positives in sample 512: 239
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 29, 37, 33, 27, 25, 28, 33]
	Time taken saving stuff: 18.43s

==================================================
eval-episode: 340 -> reward: -0.49999999999993866, steps: 81120.0, wall-time: 59.87s
-> berries picked: 129 of 800 | patches-visited: [1, 2, 9] | juice left:-0.00
==================================================

episode: 341/2000 -> reward: -249.99999999998235, steps:65472, time-taken: 2.52min, time-elasped: 1067.89min
-> berries picked: 76 of 800 | patches-visited: [5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21879 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2995, 2862, 2728, 2421, 2522, 2511, 2819, 3021]
	| approx positives in sample 512: 146
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 17, 16, 17, 17, 14, 26, 20]
	Time taken saving stuff: 0.02s
episode: 342/2000 -> reward: -249.99999999998118, steps:65376, time-taken: 2.40min, time-elasped: 1070.30min
-> berries picked: 74 of 800 | patches-visited: [6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21652 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2980, 2835, 2698, 2391, 2481, 2482, 2805, 2980]
	| approx positives in sample 512: 151
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 20, 20, 11, 17, 17, 24, 26]
	Time taken saving stuff: 0.03s
episode: 343/2000 -> reward: -249.99999999998116, steps:68736, time-taken: 3.20min, time-elasped: 1073.51min
-> berries picked: 79 of 800 | patches-visited: [5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21696 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2988, 2840, 2695, 2424, 2470, 2494, 2808, 2977]
	| approx positives in sample 512: 210
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 23, 31, 23, 29, 26, 26, 27]
	Time taken saving stuff: 0.03s
episode: 344/2000 -> reward: -249.9999999999872, steps:66144, time-taken: 3.36min, time-elasped: 1076.87min
-> berries picked: 71 of 800 | patches-visited: [2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21825 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3003, 2847, 2702, 2436, 2474, 2526, 2832, 3005]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 25, 27, 24, 35, 27, 32, 33]
	Time taken saving stuff: 0.09s
episode: 345/2000 -> reward: -249.99999999997985, steps:65664, time-taken: 2.70min, time-elasped: 1079.58min
-> berries picked: 73 of 800 | patches-visited: [2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21958 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3017, 2871, 2710, 2447, 2501, 2531, 2848, 3033]
	| approx positives in sample 512: 155
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 18, 20, 17, 14, 16, 18, 25]
	Time taken saving stuff: 0.10s
episode: 346/2000 -> reward: -249.99999999998602, steps:68448, time-taken: 3.51min, time-elasped: 1083.09min
-> berries picked: 78 of 800 | patches-visited: [5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21591 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2990, 2811, 2678, 2433, 2430, 2477, 2775, 2997]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 29, 31, 31, 27, 22, 35, 25]
	Time taken saving stuff: 0.08s
episode: 347/2000 -> reward: -249.9999999999856, steps:63072, time-taken: 2.56min, time-elasped: 1085.66min
-> berries picked: 61 of 800 | patches-visited: [4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21698 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3003, 2829, 2686, 2450, 2443, 2483, 2797, 3007]
	| approx positives in sample 512: 154
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 20, 15, 12, 23, 21, 26, 13]
	Time taken saving stuff: 0.02s
episode: 348/2000 -> reward: -249.99999999998366, steps:68256, time-taken: 3.63min, time-elasped: 1089.29min
-> berries picked: 79 of 800 | patches-visited: [7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21456 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2967, 2804, 2666, 2443, 2430, 2445, 2746, 2955]
	| approx positives in sample 512: 197
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 29, 26, 27, 19, 23, 19, 22]
	Time taken saving stuff: 0.03s
episode: 349/2000 -> reward: -249.99999999998224, steps:66528, time-taken: 3.59min, time-elasped: 1092.88min
-> berries picked: 80 of 800 | patches-visited: [8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21635 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3005, 2817, 2685, 2466, 2437, 2473, 2772, 2980]
	| approx positives in sample 512: 223
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 23, 29, 30, 26, 27, 26, 31]
	Time taken saving stuff: 0.08s
episode: 350/2000 -> reward: -249.99999999998622, steps:65472, time-taken: 2.64min, time-elasped: 1095.53min
-> berries picked: 59 of 800 | patches-visited: [3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21688 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3019, 2832, 2692, 2467, 2439, 2470, 2773, 2996]
	| approx positives in sample 512: 145
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 26, 16, 20, 19, 11, 18, 15]
	Time taken saving stuff: 14.59s

==================================================
eval-episode: 350 -> reward: -0.4999999999999449, steps: 59616.0, wall-time: 42.72s
-> berries picked: 44 of 800 | patches-visited: [1] | juice left:-0.00
==================================================

episode: 351/2000 -> reward: -249.99999999998423, steps:63456, time-taken: 2.66min, time-elasped: 1099.15min
-> berries picked: 60 of 800 | patches-visited: [3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 20953 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2888, 2741, 2615, 2391, 2407, 2388, 2696, 2827]
	| approx positives in sample 512: 139
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [18, 12, 22, 14, 18, 16, 15, 24]
	Time taken saving stuff: 0.01s
episode: 352/2000 -> reward: -249.9999999999831, steps:65856, time-taken: 2.71min, time-elasped: 1101.86min
-> berries picked: 74 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21109 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2900, 2743, 2624, 2419, 2437, 2409, 2740, 2837]
	| approx positives in sample 512: 149
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 17, 14, 20, 19, 19, 12, 22]
	Time taken saving stuff: 0.04s
episode: 353/2000 -> reward: -249.99999999998562, steps:65856, time-taken: 2.66min, time-elasped: 1104.52min
-> berries picked: 71 of 800 | patches-visited: [9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21189 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2922, 2745, 2638, 2441, 2455, 2404, 2738, 2846]
	| approx positives in sample 512: 143
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [13, 22, 16, 18, 18, 14, 22, 20]
	Time taken saving stuff: 0.01s
episode: 354/2000 -> reward: -249.99999999998585, steps:62880, time-taken: 2.62min, time-elasped: 1107.15min
-> berries picked: 57 of 800 | patches-visited: [4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21260 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2930, 2750, 2646, 2457, 2456, 2415, 2762, 2844]
	| approx positives in sample 512: 147
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 21, 20, 17, 19, 20, 17, 19]
	Time taken saving stuff: 0.09s
episode: 355/2000 -> reward: -249.99999999998656, steps:67200, time-taken: 3.49min, time-elasped: 1110.65min
-> berries picked: 80 of 800 | patches-visited: [7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21366 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2939, 2765, 2664, 2500, 2452, 2418, 2783, 2845]
	| approx positives in sample 512: 199
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 31, 26, 29, 21, 14, 23, 27]
	Time taken saving stuff: 0.01s
episode: 356/2000 -> reward: -251.49479166663951, steps:78048, time-taken: 3.72min, time-elasped: 1114.37min
-> berries picked: 109 of 800 | patches-visited: [7, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21657 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2964, 2795, 2703, 2550, 2475, 2480, 2826, 2864]
	| approx positives in sample 512: 163
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 21, 18, 19, 24, 17, 18, 20]
	Time taken saving stuff: 0.04s
episode: 357/2000 -> reward: -249.99999999998317, steps:68640, time-taken: 3.56min, time-elasped: 1117.95min
-> berries picked: 86 of 800 | patches-visited: [4, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21798 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2986, 2812, 2724, 2558, 2478, 2487, 2867, 2886]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 19, 26, 21, 30, 21, 36, 25]
	Time taken saving stuff: 0.01s
episode: 358/2000 -> reward: -249.9999999999846, steps:67104, time-taken: 3.42min, time-elasped: 1121.38min
-> berries picked: 73 of 800 | patches-visited: [8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21893 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2996, 2820, 2738, 2568, 2484, 2492, 2896, 2899]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 34, 30, 32, 20, 23, 30, 30]
	Time taken saving stuff: 0.07s
episode: 359/2000 -> reward: -249.99999999998582, steps:64800, time-taken: 2.62min, time-elasped: 1124.01min
-> berries picked: 74 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22020 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3036, 2837, 2749, 2583, 2499, 2488, 2920, 2908]
	| approx positives in sample 512: 134
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 19, 14, 20, 13, 21, 15, 16]
	Time taken saving stuff: 0.01s
episode: 360/2000 -> reward: -249.99999999998116, steps:68448, time-taken: 3.48min, time-elasped: 1127.49min
-> berries picked: 78 of 800 | patches-visited: [7, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21655 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2998, 2788, 2680, 2549, 2449, 2447, 2860, 2884]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 32, 35, 15, 25, 25, 29, 24]
	Time taken saving stuff: 18.06s

==================================================
eval-episode: 360 -> reward: -0.49999999999994604, steps: 70464.0, wall-time: 63.42s
-> berries picked: 85 of 800 | patches-visited: [0, 1] | juice left:-0.00
==================================================

episode: 361/2000 -> reward: -249.9999999999853, steps:66144, time-taken: 3.47min, time-elasped: 1132.32min
-> berries picked: 73 of 800 | patches-visited: [4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21784 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3013, 2825, 2688, 2562, 2452, 2462, 2876, 2906]
	| approx positives in sample 512: 247
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 33, 25, 29, 31, 30, 30, 39]
	Time taken saving stuff: 0.08s
episode: 362/2000 -> reward: -249.99999999997237, steps:76896, time-taken: 3.62min, time-elasped: 1135.95min
-> berries picked: 103 of 800 | patches-visited: [5, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22043 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3055, 2843, 2721, 2619, 2483, 2506, 2881, 2935]
	| approx positives in sample 512: 188
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 22, 17, 20, 21, 22, 31, 26]
	Time taken saving stuff: 0.10s
episode: 363/2000 -> reward: -249.9999999999733, steps:72096, time-taken: 3.71min, time-elasped: 1139.67min
-> berries picked: 85 of 800 | patches-visited: [5, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22157 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3074, 2849, 2726, 2629, 2505, 2522, 2901, 2951]
	| approx positives in sample 512: 184
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 26, 22, 23, 26, 14, 29, 21]
	Time taken saving stuff: 0.05s
episode: 364/2000 -> reward: -249.99999999997792, steps:71904, time-taken: 3.42min, time-elasped: 1143.09min
-> berries picked: 89 of 800 | patches-visited: [0, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22339 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3124, 2869, 2755, 2637, 2515, 2542, 2935, 2962]
	| approx positives in sample 512: 199
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 26, 23, 27, 21, 22, 30, 19]
	Time taken saving stuff: 0.23s
episode: 365/2000 -> reward: -249.99999999997752, steps:76800, time-taken: 3.65min, time-elasped: 1146.75min
-> berries picked: 99 of 800 | patches-visited: [2, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22450 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3111, 2853, 2771, 2646, 2542, 2574, 2971, 2982]
	| approx positives in sample 512: 171
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 23, 25, 17, 24, 15, 19, 19]
	Time taken saving stuff: 0.09s
episode: 366/2000 -> reward: -249.9999999999819, steps:69792, time-taken: 3.64min, time-elasped: 1150.40min
-> berries picked: 86 of 800 | patches-visited: [6, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22282 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3092, 2846, 2749, 2591, 2526, 2573, 2961, 2944]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 31, 31, 24, 29, 21, 27, 28]
	Time taken saving stuff: 0.07s
episode: 367/2000 -> reward: -249.9999999999797, steps:67008, time-taken: 4.35min, time-elasped: 1154.76min
-> berries picked: 75 of 800 | patches-visited: [5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22401 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3103, 2872, 2756, 2592, 2549, 2570, 2992, 2967]
	| approx positives in sample 512: 230
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [31, 35, 28, 17, 27, 29, 30, 33]
	Time taken saving stuff: 0.09s
episode: 368/2000 -> reward: -249.9999999999742, steps:78528, time-taken: 4.47min, time-elasped: 1159.25min
-> berries picked: 114 of 800 | patches-visited: [3, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22534 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3126, 2887, 2795, 2629, 2552, 2576, 2986, 2983]
	| approx positives in sample 512: 201
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 29, 34, 22, 23, 22, 20, 21]
	Time taken saving stuff: 0.08s
episode: 369/2000 -> reward: -249.9999999999822, steps:68352, time-taken: 4.14min, time-elasped: 1163.39min
-> berries picked: 80 of 800 | patches-visited: [8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22262 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3074, 2836, 2767, 2599, 2527, 2530, 2986, 2943]
	| approx positives in sample 512: 211
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 26, 39, 24, 25, 21, 21, 30]
	Time taken saving stuff: 0.01s
episode: 370/2000 -> reward: -249.99999999997416, steps:72000, time-taken: 5.19min, time-elasped: 1168.59min
-> berries picked: 99 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22475 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3139, 2843, 2793, 2612, 2560, 2551, 3029, 2948]
	| approx positives in sample 512: 176
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 22, 31, 20, 17, 18, 19, 25]
	Time taken saving stuff: 15.73s

==================================================
eval-episode: 370 -> reward: -0.499999999999945, steps: 69888.0, wall-time: 82.17s
-> berries picked: 83 of 800 | patches-visited: [0, 1] | juice left:-0.00
==================================================

episode: 371/2000 -> reward: -249.9999999999837, steps:66432, time-taken: 4.05min, time-elasped: 1174.27min
-> berries picked: 79 of 800 | patches-visited: [1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22537 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3140, 2860, 2800, 2609, 2569, 2549, 3042, 2968]
	| approx positives in sample 512: 243
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 28, 35, 36, 31, 23, 27, 30]
	Time taken saving stuff: 0.09s
episode: 372/2000 -> reward: -249.99999999998596, steps:63840, time-taken: 2.97min, time-elasped: 1177.24min
-> berries picked: 58 of 800 | patches-visited: [8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22616 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3151, 2862, 2804, 2632, 2577, 2560, 3059, 2971]
	| approx positives in sample 512: 148
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 10, 25, 20, 19, 14, 23, 14]
	Time taken saving stuff: 0.08s
episode: 373/2000 -> reward: -249.9999999999825, steps:65376, time-taken: 2.61min, time-elasped: 1179.86min
-> berries picked: 62 of 800 | patches-visited: [1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22085 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3082, 2785, 2769, 2577, 2520, 2478, 2983, 2891]
	| approx positives in sample 512: 130
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 16, 10, 24, 19, 10, 11, 15]
	Time taken saving stuff: 0.01s
episode: 374/2000 -> reward: -249.99999999998278, steps:65760, time-taken: 2.79min, time-elasped: 1182.65min
-> berries picked: 76 of 800 | patches-visited: [9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21535 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2989, 2733, 2688, 2505, 2456, 2418, 2945, 2801]
	| approx positives in sample 512: 128
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 15, 17, 14, 17, 10, 17, 11]
	Time taken saving stuff: 0.02s
episode: 375/2000 -> reward: -249.99999999998408, steps:63456, time-taken: 2.49min, time-elasped: 1185.15min
-> berries picked: 53 of 800 | patches-visited: [1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21199 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2946, 2696, 2631, 2485, 2432, 2369, 2892, 2748]
	| approx positives in sample 512: 140
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [23, 14, 11, 25, 20, 8, 23, 16]
	Time taken saving stuff: 0.09s
episode: 376/2000 -> reward: -249.99999999998514, steps:67872, time-taken: 3.42min, time-elasped: 1188.57min
-> berries picked: 80 of 800 | patches-visited: [5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21288 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2962, 2706, 2652, 2518, 2449, 2364, 2883, 2754]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 28, 25, 26, 31, 17, 32, 25]
	Time taken saving stuff: 0.07s
episode: 377/2000 -> reward: -249.99999999998016, steps:69120, time-taken: 4.33min, time-elasped: 1192.91min
-> berries picked: 79 of 800 | patches-visited: [1, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21467 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2973, 2727, 2662, 2534, 2459, 2391, 2915, 2806]
	| approx positives in sample 512: 200
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 33, 24, 24, 28, 23, 30, 23]
	Time taken saving stuff: 0.02s
episode: 378/2000 -> reward: -249.99999999997294, steps:79392, time-taken: 4.29min, time-elasped: 1197.20min
-> berries picked: 118 of 800 | patches-visited: [3, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21752 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2999, 2763, 2699, 2571, 2478, 2426, 2968, 2848]
	| approx positives in sample 512: 163
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 21, 22, 28, 12, 24, 20, 15]
	Time taken saving stuff: 0.11s
episode: 379/2000 -> reward: -249.99999999997826, steps:72672, time-taken: 3.83min, time-elasped: 1201.03min
-> berries picked: 91 of 800 | patches-visited: [5, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21816 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3006, 2790, 2728, 2598, 2470, 2421, 2974, 2829]
	| approx positives in sample 512: 180
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 23, 21, 15, 20, 23, 33, 19]
	Time taken saving stuff: 0.01s
episode: 380/2000 -> reward: -249.99999999998596, steps:65952, time-taken: 2.78min, time-elasped: 1203.82min
-> berries picked: 74 of 800 | patches-visited: [9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21960 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3009, 2809, 2735, 2621, 2500, 2443, 2996, 2847]
	| approx positives in sample 512: 139
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 18, 21, 9, 13, 13, 24, 20]
	Time taken saving stuff: 17.98s

==================================================
eval-episode: 380 -> reward: -0.499999999999946, steps: 71808.0, wall-time: 55.65s
-> berries picked: 90 of 800 | patches-visited: [1, 3] | juice left:-0.00
==================================================

episode: 381/2000 -> reward: -249.99999999998326, steps:68256, time-taken: 3.28min, time-elasped: 1208.33min
-> berries picked: 75 of 800 | patches-visited: [2, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21623 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2958, 2750, 2675, 2622, 2482, 2430, 2935, 2771]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 24, 25, 29, 21, 25, 25, 39]
	Time taken saving stuff: 0.02s
episode: 382/2000 -> reward: -249.99999999998485, steps:66528, time-taken: 3.38min, time-elasped: 1211.72min
-> berries picked: 78 of 800 | patches-visited: [5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21803 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2981, 2771, 2688, 2642, 2516, 2443, 2974, 2788]
	| approx positives in sample 512: 234
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 36, 31, 36, 30, 19, 28, 27]
	Time taken saving stuff: 0.01s
episode: 383/2000 -> reward: -249.999999999982, steps:65184, time-taken: 2.79min, time-elasped: 1214.52min
-> berries picked: 72 of 800 | patches-visited: [7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21947 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3001, 2795, 2716, 2666, 2520, 2449, 2986, 2814]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 21, 14, 13, 16, 20, 17, 15]
	Time taken saving stuff: 0.03s
episode: 384/2000 -> reward: -249.9999999999807, steps:60480, time-taken: 2.85min, time-elasped: 1217.38min
-> berries picked: 61 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21890 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3010, 2800, 2707, 2650, 2498, 2433, 2982, 2810]
	| approx positives in sample 512: 146
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 23, 16, 24, 17, 14, 17, 16]
	Time taken saving stuff: 0.01s
episode: 385/2000 -> reward: -249.9999999999831, steps:67200, time-taken: 5.37min, time-elasped: 1222.76min
-> berries picked: 80 of 800 | patches-visited: [8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22012 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3023, 2822, 2724, 2647, 2498, 2450, 3005, 2843]
	| approx positives in sample 512: 225
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 35, 29, 20, 25, 32, 30, 22]
	Time taken saving stuff: 0.08s
episode: 386/2000 -> reward: -251.49479166665193, steps:67296, time-taken: 3.54min, time-elasped: 1226.30min
-> berries picked: 78 of 800 | patches-visited: [1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22136 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3061, 2836, 2733, 2647, 2511, 2456, 3024, 2868]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 30, 34, 31, 22, 26, 30, 24]
	Time taken saving stuff: 0.01s
episode: 387/2000 -> reward: -249.99999999997996, steps:69312, time-taken: 3.91min, time-elasped: 1230.21min
-> berries picked: 90 of 800 | patches-visited: [0, 5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22301 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3072, 2850, 2760, 2645, 2536, 2483, 3057, 2898]
	| approx positives in sample 512: 223
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 33, 26, 37, 27, 23, 27, 24]
	Time taken saving stuff: 0.04s
episode: 388/2000 -> reward: -249.99999999998337, steps:67680, time-taken: 4.02min, time-elasped: 1234.24min
-> berries picked: 73 of 800 | patches-visited: [3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22393 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3064, 2847, 2773, 2677, 2542, 2498, 3085, 2907]
	| approx positives in sample 512: 237
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 35, 34, 27, 29, 21, 32, 24]
	Time taken saving stuff: 0.05s
episode: 389/2000 -> reward: -249.99999999998425, steps:64608, time-taken: 3.01min, time-elasped: 1237.25min
-> berries picked: 71 of 800 | patches-visited: [9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22527 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3075, 2866, 2783, 2686, 2555, 2532, 3101, 2929]
	| approx positives in sample 512: 135
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [16, 20, 18, 15, 16, 16, 9, 25]
	Time taken saving stuff: 0.02s
episode: 390/2000 -> reward: -249.9999999999872, steps:66432, time-taken: 3.99min, time-elasped: 1241.26min
-> berries picked: 75 of 800 | patches-visited: [7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22258 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3058, 2832, 2764, 2656, 2519, 2487, 3077, 2865]
	| approx positives in sample 512: 240
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 35, 29, 27, 21, 21, 41, 34]
	Time taken saving stuff: 15.13s

==================================================
eval-episode: 390 -> reward: -0.49999999999994654, steps: 77760.0, wall-time: 76.49s
-> berries picked: 116 of 800 | patches-visited: [1, 5] | juice left:-0.00
==================================================

episode: 391/2000 -> reward: -249.9999999999803, steps:71616, time-taken: 3.88min, time-elasped: 1246.67min
-> berries picked: 89 of 800 | patches-visited: [5, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22461 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3079, 2854, 2781, 2695, 2537, 2506, 3108, 2901]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [26, 38, 23, 24, 33, 26, 22, 20]
	Time taken saving stuff: 0.10s
episode: 392/2000 -> reward: -249.99999999998008, steps:67104, time-taken: 4.23min, time-elasped: 1250.90min
-> berries picked: 74 of 800 | patches-visited: [1, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22556 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3095, 2853, 2796, 2712, 2538, 2524, 3128, 2910]
	| approx positives in sample 512: 249
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [41, 40, 32, 21, 30, 22, 34, 29]
	Time taken saving stuff: 0.01s
episode: 393/2000 -> reward: -249.99999999998374, steps:67776, time-taken: 4.15min, time-elasped: 1255.05min
-> berries picked: 79 of 800 | patches-visited: [7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22600 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3130, 2848, 2810, 2717, 2551, 2514, 3124, 2906]
	| approx positives in sample 512: 205
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 27, 18, 20, 25, 26, 30, 29]
	Time taken saving stuff: 0.09s
episode: 394/2000 -> reward: -249.99999999998244, steps:65088, time-taken: 3.28min, time-elasped: 1258.34min
-> berries picked: 76 of 800 | patches-visited: [6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22652 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3128, 2849, 2807, 2721, 2566, 2543, 3132, 2906]
	| approx positives in sample 512: 139
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 17, 11, 22, 19, 16, 23, 17]
	Time taken saving stuff: 0.02s
episode: 395/2000 -> reward: -249.9999999999796, steps:69984, time-taken: 4.20min, time-elasped: 1262.55min
-> berries picked: 88 of 800 | patches-visited: [3, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22155 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3084, 2804, 2756, 2649, 2511, 2455, 3054, 2842]
	| approx positives in sample 512: 229
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 33, 23, 24, 31, 28, 26, 34]
	Time taken saving stuff: 0.02s
episode: 396/2000 -> reward: -249.99999999998218, steps:66528, time-taken: 4.87min, time-elasped: 1267.43min
-> berries picked: 74 of 800 | patches-visited: [8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22311 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3102, 2821, 2775, 2691, 2513, 2481, 3084, 2844]
	| approx positives in sample 512: 224
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [27, 36, 29, 21, 30, 25, 25, 31]
	Time taken saving stuff: 0.11s
episode: 397/2000 -> reward: -249.9999999999842, steps:64416, time-taken: 3.85min, time-elasped: 1271.30min
-> berries picked: 73 of 800 | patches-visited: [9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22375 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3104, 2817, 2795, 2694, 2529, 2506, 3092, 2838]
	| approx positives in sample 512: 147
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 17, 18, 22, 20, 12, 19, 18]
	Time taken saving stuff: 0.03s
episode: 398/2000 -> reward: -249.99999999998477, steps:66720, time-taken: 4.36min, time-elasped: 1275.66min
-> berries picked: 68 of 800 | patches-visited: [1, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21971 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3022, 2761, 2760, 2660, 2505, 2462, 3032, 2769]
	| approx positives in sample 512: 216
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 22, 26, 30, 30, 22, 27, 25]
	Time taken saving stuff: 0.07s
episode: 399/2000 -> reward: -249.99999999997655, steps:71904, time-taken: 4.08min, time-elasped: 1279.75min
-> berries picked: 88 of 800 | patches-visited: [5, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22190 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3040, 2783, 2792, 2697, 2517, 2502, 3050, 2809]
	| approx positives in sample 512: 213
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [33, 31, 29, 21, 19, 27, 29, 24]
	Time taken saving stuff: 0.09s
episode: 400/2000 -> reward: -249.9999999999838, steps:66816, time-taken: 4.36min, time-elasped: 1284.12min
-> berries picked: 74 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22337 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3062, 2805, 2796, 2710, 2521, 2530, 3087, 2826]
	| approx positives in sample 512: 203
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 22, 22, 24, 30, 15, 34, 28]
	Time taken saving stuff: 20.14s

==================================================
eval-episode: 400 -> reward: -0.4999999999999093, steps: 75744.0, wall-time: 75.73s
-> berries picked: 106 of 800 | patches-visited: [1, 5] | juice left:-0.00
==================================================

episode: 401/2000 -> reward: -249.99999999998482, steps:68832, time-taken: 3.54min, time-elasped: 1289.27min
-> berries picked: 80 of 800 | patches-visited: [0, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22474 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3075, 2813, 2805, 2731, 2544, 2545, 3121, 2840]
	| approx positives in sample 512: 218
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 25, 30, 29, 23, 23, 25, 34]
	Time taken saving stuff: 0.01s
episode: 402/2000 -> reward: -249.9999999999855, steps:62016, time-taken: 2.51min, time-elasped: 1291.78min
-> berries picked: 54 of 800 | patches-visited: [8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22545 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3076, 2808, 2818, 2748, 2555, 2562, 3119, 2859]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 18, 18, 25, 13, 10, 13, 12]
	Time taken saving stuff: 0.03s
episode: 403/2000 -> reward: -249.99999999998738, steps:65088, time-taken: 2.68min, time-elasped: 1294.47min
-> berries picked: 69 of 800 | patches-visited: [1] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22451 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3062, 2797, 2794, 2737, 2546, 2575, 3096, 2844]
	| approx positives in sample 512: 138
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 19, 19, 24, 13, 16, 16, 16]
	Time taken saving stuff: 0.02s
episode: 404/2000 -> reward: -249.99999999998386, steps:67488, time-taken: 3.45min, time-elasped: 1297.91min
-> berries picked: 77 of 800 | patches-visited: [8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22229 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3027, 2774, 2765, 2721, 2535, 2550, 3053, 2804]
	| approx positives in sample 512: 240
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 17, 34, 42, 27, 25, 35, 32]
	Time taken saving stuff: 0.08s
episode: 405/2000 -> reward: -249.9999999999782, steps:70944, time-taken: 3.62min, time-elasped: 1301.54min
-> berries picked: 96 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22455 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3057, 2786, 2785, 2750, 2555, 2600, 3094, 2828]
	| approx positives in sample 512: 197
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [42, 24, 22, 23, 23, 22, 24, 17]
	Time taken saving stuff: 0.01s
episode: 406/2000 -> reward: -249.99999999998101, steps:66240, time-taken: 3.39min, time-elasped: 1304.93min
-> berries picked: 68 of 800 | patches-visited: [2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22556 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3078, 2820, 2802, 2755, 2563, 2606, 3086, 2846]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [41, 22, 21, 38, 24, 25, 32, 28]
	Time taken saving stuff: 0.07s
episode: 407/2000 -> reward: -249.99999999998542, steps:61344, time-taken: 2.48min, time-elasped: 1307.42min
-> berries picked: 59 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22617 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3090, 2816, 2800, 2763, 2586, 2611, 3106, 2845]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 16, 12, 16, 13, 17, 20, 23]
	Time taken saving stuff: 0.03s
episode: 408/2000 -> reward: -249.99999999997885, steps:75072, time-taken: 3.85min, time-elasped: 1311.27min
-> berries picked: 101 of 800 | patches-visited: [2, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22362 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3054, 2773, 2773, 2756, 2572, 2588, 3071, 2775]
	| approx positives in sample 512: 211
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 18, 25, 26, 33, 21, 32, 24]
	Time taken saving stuff: 0.01s
episode: 409/2000 -> reward: -249.99999999997894, steps:70752, time-taken: 3.60min, time-elasped: 1314.88min
-> berries picked: 90 of 800 | patches-visited: [0, 4] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22525 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3065, 2790, 2791, 2764, 2589, 2618, 3106, 2802]
	| approx positives in sample 512: 192
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 25, 23, 22, 31, 22, 26, 22]
	Time taken saving stuff: 0.09s
episode: 410/2000 -> reward: -249.99999999997928, steps:71424, time-taken: 3.73min, time-elasped: 1318.61min
-> berries picked: 100 of 800 | patches-visited: [1, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22659 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3064, 2820, 2817, 2783, 2580, 2651, 3119, 2825]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [34, 27, 22, 30, 34, 20, 31, 24]
	Time taken saving stuff: 16.05s

==================================================
eval-episode: 410 -> reward: -0.4999999999999453, steps: 66336.0, wall-time: 58.18s
-> berries picked: 73 of 800 | patches-visited: [1] | juice left:-0.00
==================================================

episode: 411/2000 -> reward: -249.99999999998434, steps:65664, time-taken: 3.15min, time-elasped: 1323.01min
-> berries picked: 71 of 800 | patches-visited: [7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22632 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3081, 2809, 2820, 2795, 2572, 2640, 3111, 2804]
	| approx positives in sample 512: 141
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [14, 12, 19, 22, 16, 17, 20, 21]
	Time taken saving stuff: 0.10s
episode: 412/2000 -> reward: -249.99999999997414, steps:67584, time-taken: 3.57min, time-elasped: 1326.58min
-> berries picked: 79 of 800 | patches-visited: [5] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 21974 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2990, 2740, 2730, 2704, 2535, 2554, 3002, 2719]
	| approx positives in sample 512: 209
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 25, 24, 29, 28, 23, 26, 25]
	Time taken saving stuff: 0.19s
episode: 413/2000 -> reward: -249.9999999999867, steps:67392, time-taken: 3.50min, time-elasped: 1330.09min
-> berries picked: 73 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22113 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3008, 2764, 2737, 2713, 2550, 2573, 3022, 2746]
	| approx positives in sample 512: 222
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [44, 19, 29, 28, 27, 22, 22, 31]
	Time taken saving stuff: 0.09s
episode: 414/2000 -> reward: -249.99999999998354, steps:63168, time-taken: 2.73min, time-elasped: 1332.82min
-> berries picked: 55 of 800 | patches-visited: [2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22244 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3021, 2769, 2754, 2724, 2564, 2611, 3046, 2755]
	| approx positives in sample 512: 142
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [20, 16, 14, 14, 11, 20, 28, 19]
	Time taken saving stuff: 0.01s
episode: 415/2000 -> reward: -249.9999999999843, steps:67584, time-taken: 3.10min, time-elasped: 1365.63min
-> berries picked: 77 of 800 | patches-visited: [3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22131 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3003, 2745, 2719, 2716, 2551, 2592, 3046, 2759]
	| approx positives in sample 512: 223
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 29, 22, 24, 30, 31, 41, 27]
	Time taken saving stuff: 0.01s
episode: 416/2000 -> reward: -249.99999999998502, steps:64512, time-taken: 2.91min, time-elasped: 1368.55min
-> berries picked: 57 of 800 | patches-visited: [7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22274 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3004, 2749, 2753, 2748, 2567, 2619, 3055, 2779]
	| approx positives in sample 512: 159
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [19, 16, 24, 24, 20, 14, 26, 16]
	Time taken saving stuff: 0.01s
episode: 417/2000 -> reward: -249.99999999998164, steps:71232, time-taken: 3.58min, time-elasped: 1372.14min
-> berries picked: 86 of 800 | patches-visited: [8, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22360 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3008, 2753, 2739, 2765, 2573, 2639, 3090, 2793]
	| approx positives in sample 512: 180
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [25, 27, 29, 15, 25, 23, 15, 21]
	Time taken saving stuff: 0.01s
episode: 418/2000 -> reward: -249.9999999999812, steps:66144, time-taken: 3.46min, time-elasped: 1375.60min
-> berries picked: 73 of 800 | patches-visited: [2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22522 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3046, 2760, 2791, 2787, 2587, 2647, 3099, 2805]
	| approx positives in sample 512: 238
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [29, 35, 30, 29, 36, 23, 31, 25]
	Time taken saving stuff: 0.01s
episode: 419/2000 -> reward: -249.99999999998354, steps:65568, time-taken: 2.87min, time-elasped: 1378.49min
-> berries picked: 63 of 800 | patches-visited: [0] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22604 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3049, 2774, 2821, 2779, 2607, 2658, 3108, 2808]
	| approx positives in sample 512: 133
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [15, 17, 20, 19, 13, 19, 21, 9]
	Time taken saving stuff: 0.01s
episode: 420/2000 -> reward: -249.9999999999824, steps:66912, time-taken: 4.00min, time-elasped: 1382.52min
-> berries picked: 80 of 800 | patches-visited: [6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22167 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [2989, 2703, 2747, 2747, 2549, 2593, 3087, 2752]
	| approx positives in sample 512: 227
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 30, 35, 35, 20, 21, 34, 20]
	Time taken saving stuff: 18.13s

==================================================
eval-episode: 420 -> reward: -0.49999999999993766, steps: 66336.0, wall-time: 69.39s
-> berries picked: 73 of 800 | patches-visited: [1] | juice left:-0.00
==================================================

episode: 421/2000 -> reward: -249.9999999999803, steps:69312, time-taken: 3.81min, time-elasped: 1387.80min
-> berries picked: 86 of 800 | patches-visited: [5, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22356 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3022, 2721, 2777, 2764, 2551, 2611, 3128, 2782]
	| approx positives in sample 512: 208
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [30, 28, 17, 24, 29, 24, 34, 22]
	Time taken saving stuff: 0.01s
episode: 422/2000 -> reward: -249.9999999999859, steps:65568, time-taken: 3.15min, time-elasped: 1390.96min
-> berries picked: 70 of 800 | patches-visited: [6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22469 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3045, 2743, 2802, 2772, 2553, 2619, 3136, 2799]
	| approx positives in sample 512: 156
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 12, 18, 28, 21, 18, 19, 19]
	Time taken saving stuff: 0.02s
episode: 423/2000 -> reward: -249.99999999997013, steps:74208, time-taken: 3.92min, time-elasped: 1394.88min
-> berries picked: 96 of 800 | patches-visited: [5, 7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22305 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3023, 2723, 2782, 2762, 2512, 2588, 3107, 2808]
	| approx positives in sample 512: 194
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [22, 28, 26, 24, 22, 20, 27, 25]
	Time taken saving stuff: 0.01s
episode: 424/2000 -> reward: -249.99999999998505, steps:67296, time-taken: 3.56min, time-elasped: 1398.44min
-> berries picked: 79 of 800 | patches-visited: [7] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22471 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3043, 2740, 2790, 2777, 2526, 2624, 3129, 2842]
	| approx positives in sample 512: 231
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 29, 36, 31, 32, 21, 34, 24]
	Time taken saving stuff: 0.01s
episode: 425/2000 -> reward: -249.99999999996996, steps:81792, time-taken: 3.98min, time-elasped: 1402.43min
-> berries picked: 125 of 800 | patches-visited: [6, 8] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22732 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3113, 2754, 2830, 2796, 2556, 2657, 3168, 2858]
	| approx positives in sample 512: 152
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [21, 19, 14, 19, 18, 25, 21, 15]
	Time taken saving stuff: 0.01s
episode: 426/2000 -> reward: -249.9999999999836, steps:66528, time-taken: 6.06min, time-elasped: 1408.49min
-> berries picked: 78 of 800 | patches-visited: [3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22559 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3073, 2774, 2823, 2791, 2542, 2634, 3115, 2807]
	| approx positives in sample 512: 242
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [28, 49, 37, 22, 21, 18, 33, 34]
	Time taken saving stuff: 0.01s
episode: 427/2000 -> reward: -249.99999999998093, steps:66432, time-taken: 3.57min, time-elasped: 1412.06min
-> berries picked: 80 of 800 | patches-visited: [3] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22739 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3089, 2794, 2843, 2818, 2562, 2657, 3133, 2843]
	| approx positives in sample 512: 212
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [38, 30, 23, 29, 22, 19, 25, 26]
	Time taken saving stuff: 0.01s
episode: 428/2000 -> reward: -249.99999999997632, steps:73248, time-taken: 3.97min, time-elasped: 1416.04min
-> berries picked: 103 of 800 | patches-visited: [2, 9] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22892 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3085, 2811, 2860, 2825, 2585, 2704, 3160, 2862]
	| approx positives in sample 512: 191
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [32, 28, 20, 23, 24, 24, 23, 17]
	Time taken saving stuff: 0.01s
episode: 429/2000 -> reward: -249.99999999997246, steps:71328, time-taken: 3.78min, time-elasped: 1419.82min
-> berries picked: 86 of 800 | patches-visited: [0, 2] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 22975 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3105, 2807, 2880, 2818, 2614, 2723, 3170, 2858]
	| approx positives in sample 512: 210
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [24, 29, 36, 27, 28, 18, 30, 18]
	Time taken saving stuff: 0.01s
episode: 430/2000 -> reward: -249.99999999997982, steps:67488, time-taken: 3.48min, time-elasped: 1423.30min
-> berries picked: 81 of 800 | patches-visited: [1, 6] | juice left:-0.00
	| epsilon: 0.5
	| skipsteps: 10
	| positive-in-buffer: 23026 | amount-filled: 100.00%
	| action-stats:  [0, 1, 2, 3, 4, 5, 6, 7] [3112, 2814, 2879, 2822, 2603, 2744, 3172, 2880]
	| approx positives in sample 512: 243
	| approx action-dist in sample 512: [0, 1, 2, 3, 4, 5, 6, 7] [35, 28, 29, 35, 20, 37, 31, 28]
	Time taken saving stuff: 16.29s

==================================================
eval-episode: 430 -> reward: -0.4999999999999464, steps: 74784.0, wall-time: 71.74s
-> berries picked: 98 of 800 | patches-visited: [1, 3] | juice left:-0.00
==================================================

evalEpisode: 0 -> reward: -0.4999999999999267 steps: 75552
